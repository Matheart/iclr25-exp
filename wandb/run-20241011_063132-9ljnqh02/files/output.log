
  0%|                                                                     | 107/100000 [00:01<21:17, 78.20it/s]
epoch 0  training loss: 2.499045462903051e+21
epoch 0  clean testing loss: 2.4990288558794253e+21
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 100  training loss: 1.0716836745722452e+21

  0%|▏                                                                    | 262/100000 [00:03<20:49, 79.80it/s]
epoch 200  training loss: 5.127060983324135e+19
epoch 200  clean testing loss: 2.7810501755198767e+19
epoch 300  training loss: 6.267687436235571e+16

  0%|▎                                                                    | 421/100000 [00:05<20:52, 79.52it/s]
epoch 400  training loss: 1496129443201024.0

  1%|▍                                                                    | 581/100000 [00:07<20:36, 80.38it/s]
epoch 500  training loss: 769871814066176.0
epoch 500  clean testing loss: 5742459321581568.0
epoch 600  training loss: 672271366619136.0

  1%|▌                                                                    | 743/100000 [00:09<20:29, 80.74it/s]
epoch 700  training loss: 651852890767360.0

  1%|▋                                                                    | 907/100000 [00:11<20:51, 79.19it/s]
epoch 800  training loss: 492113326243840.0
epoch 800  clean testing loss: 3313846173302784.0
epoch 900  training loss: 461183287033856.0

  1%|▋                                                                   | 1067/100000 [00:13<20:29, 80.45it/s]
epoch 1000  training loss: 422558344151040.0
epoch 1000  clean testing loss: 2250206380818432.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 1100  training loss: 392583297630208.0

  1%|▊                                                                   | 1218/100000 [00:15<20:35, 79.92it/s]
epoch 1200  training loss: 378008829427712.0

  1%|▉                                                                   | 1386/100000 [00:17<20:38, 79.65it/s]
epoch 1300  training loss: 353437824843776.0
epoch 1300  clean testing loss: 1341805899546624.0
epoch 1400  training loss: 1045593279430656.0

  2%|█                                                                   | 1539/100000 [00:19<20:29, 80.07it/s]
epoch 1500  training loss: 323147970641920.0

  2%|█▏                                                                  | 1700/100000 [00:21<20:12, 81.08it/s]
epoch 1600  training loss: 1537702579142656.0
epoch 1600  clean testing loss: 3105353696804864.0
epoch 1700  training loss: 299239733198848.0

  2%|█▎                                                                  | 1862/100000 [00:23<20:17, 80.62it/s]
epoch 1800  training loss: 286757417385984.0
epoch 1800  clean testing loss: 751297020035072.0
epoch 1900  training loss: 297518860599296.0

  2%|█▎                                                                  | 2021/100000 [00:25<20:33, 79.43it/s]
epoch 2000  training loss: 268254446616576.0
epoch 2000  clean testing loss: 635629926875136.0

  2%|█▍                                                                  | 2182/100000 [00:27<20:24, 79.85it/s]
epoch 2100  training loss: 1.5587475699269632e+16
epoch 2100  clean testing loss: 4153929159933952.0
epoch 2200  training loss: 252782565130240.0

  2%|█▌                                                                  | 2347/100000 [00:29<20:28, 79.48it/s]
epoch 2300  training loss: 244223081185280.0

  3%|█▋                                                                  | 2506/100000 [00:31<20:20, 79.91it/s]
epoch 2400  training loss: 1217761741111296.0
epoch 2400  clean testing loss: 690878104469504.0
epoch 2500  training loss: 232066713124864.0

  3%|█▊                                                                  | 2664/100000 [00:33<20:19, 79.85it/s]
epoch 2600  training loss: 225916420620288.0
epoch 2600  clean testing loss: 452873263513600.0
epoch 2700  training loss: 234817421574144.0

  3%|█▉                                                                  | 2827/100000 [00:35<20:10, 80.27it/s]
epoch 2800  training loss: 215345465917440.0

  3%|██                                                                  | 2980/100000 [00:37<20:06, 80.42it/s]
epoch 2900  training loss: 307741788733440.0
epoch 2900  clean testing loss: 434808765284352.0
epoch 3000  training loss: 206967813439488.0
epoch 3000  clean testing loss: 393381154914304.0

  3%|██▏                                                                 | 3145/100000 [00:39<20:02, 80.52it/s]
epoch 3100  training loss: 203133481385984.0

  3%|██▏                                                                 | 3303/100000 [00:41<20:19, 79.29it/s]
epoch 3200  training loss: 199472860626944.0
epoch 3200  clean testing loss: 376957401300992.0
epoch 3300  training loss: 195690051403776.0

  3%|██▎                                                                 | 3462/100000 [00:43<19:49, 81.18it/s]
epoch 3400  training loss: 191852682674176.0
epoch 3400  clean testing loss: 357901839368192.0
epoch 3500  training loss: 187430695075840.0
  3%|██▎                                                                 | 3480/100000 [00:43<19:56, 80.64it/s][34m[1mwandb[39m[22m: 429 encountered (Filestream rate limit exceeded, retrying in 2.1 seconds.), retrying request
  4%|██▍                                                                 | 3623/100000 [00:45<20:10, 79.63it/s]
epoch 3600  training loss: 2.2514761878994944e+16

  4%|██▌                                                                 | 3789/100000 [00:47<20:05, 79.78it/s]
epoch 3700  training loss: 180289070432256.0
epoch 3700  clean testing loss: 326069588590592.0
epoch 3800  training loss: 174778056966144.0

  4%|██▋                                                                 | 3949/100000 [00:49<20:00, 80.04it/s]
epoch 3900  training loss: 170158685421568.0

  4%|██▊                                                                 | 4102/100000 [00:51<20:02, 79.72it/s]
epoch 4000  training loss: 171170284437504.0
epoch 4000  clean testing loss: 311989880487936.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 4100  training loss: 163703685120000.0

  4%|██▉                                                                 | 4265/100000 [00:53<20:01, 79.67it/s]
epoch 4200  training loss: 176483494526976.0
epoch 4200  clean testing loss: 317422645018624.0
epoch 4300  training loss: 160497173266432.0

  4%|███                                                                 | 4429/100000 [00:55<20:03, 79.42it/s]
epoch 4400  training loss: 155018808262656.0

  5%|███                                                                 | 4583/100000 [00:57<19:58, 79.59it/s]
epoch 4500  training loss: 222988846759936.0
epoch 4500  clean testing loss: 292775471874048.0
epoch 4600  training loss: 149813173682176.0

  5%|███▏                                                                | 4748/100000 [00:59<19:52, 79.87it/s]
epoch 4700  training loss: 3796558353006592.0

  5%|███▎                                                                | 4905/100000 [01:01<19:43, 80.35it/s]
epoch 4800  training loss: 145468596158464.0
epoch 4800  clean testing loss: 271265269022720.0
epoch 4900  training loss: 143004526444544.0

  5%|███▍                                                                | 5065/100000 [01:03<19:44, 80.16it/s]
epoch 5000  training loss: 6895335381139456.0
epoch 5000  clean testing loss: 9444825283690496.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 5100  training loss: 138916388667392.0

  5%|███▌                                                                | 5225/100000 [01:05<19:54, 79.37it/s]
epoch 5200  training loss: 136624369303552.0

  5%|███▋                                                                | 5385/100000 [01:07<19:39, 80.22it/s]
epoch 5300  training loss: 356462119354368.0
epoch 5300  clean testing loss: 683573036187648.0
epoch 5400  training loss: 134078108008448.0

  6%|███▊                                                                | 5551/100000 [01:09<19:48, 79.44it/s]
epoch 5500  training loss: 130311815954432.0

  6%|███▉                                                                | 5707/100000 [01:11<19:50, 79.23it/s]
epoch 5600  training loss: 128788193083392.0
epoch 5600  clean testing loss: 243712231735296.0
epoch 5700  training loss: 135177007267840.0

  6%|███▉                                                                | 5869/100000 [01:13<19:45, 79.42it/s]
epoch 5800  training loss: 124711690305536.0
epoch 5800  clean testing loss: 236109099433984.0
epoch 5900  training loss: 122765893959680.0

  6%|████                                                                | 6027/100000 [01:15<19:33, 80.11it/s]
epoch 6000  training loss: 1313743791194112.0
epoch 6000  clean testing loss: 332392686419968.0

  6%|████▏                                                               | 6189/100000 [01:17<19:28, 80.32it/s]
epoch 6100  training loss: 120748014305280.0
epoch 6100  clean testing loss: 225958564986880.0
epoch 6200  training loss: 118901740404736.0

  6%|████▎                                                               | 6346/100000 [01:19<19:27, 80.19it/s]
epoch 6300  training loss: 117325336412160.0

  7%|████▍                                                               | 6508/100000 [01:21<19:23, 80.33it/s]
epoch 6400  training loss: 115843228762112.0
epoch 6400  clean testing loss: 220936456372224.0
epoch 6500  training loss: 114380607848448.0

  7%|████▌                                                               | 6676/100000 [01:23<19:26, 80.01it/s]
epoch 6600  training loss: 113009682808832.0
epoch 6600  clean testing loss: 215847255670784.0
epoch 6700  training loss: 111020198592512.0

  7%|████▋                                                               | 6834/100000 [01:25<19:22, 80.14it/s]
epoch 6800  training loss: 144359487963136.0

  7%|████▊                                                               | 6996/100000 [01:27<19:12, 80.72it/s]
epoch 6900  training loss: 129149372989440.0
epoch 6900  clean testing loss: 235781121638400.0
epoch 7000  training loss: 110085514723328.0
epoch 7000  clean testing loss: 202368608108544.0

  7%|████▊                                                               | 7154/100000 [01:29<19:07, 80.88it/s]
epoch 7100  training loss: 172651158962176.0

  7%|████▉                                                               | 7316/100000 [01:31<19:12, 80.45it/s]
epoch 7200  training loss: 103496623849472.0
epoch 7200  clean testing loss: 197699055910912.0
epoch 7300  training loss: 1053828208132096.0

  7%|█████                                                               | 7478/100000 [01:33<18:59, 81.19it/s]
epoch 7400  training loss: 102451822723072.0
epoch 7400  clean testing loss: 190235812036608.0
epoch 7500  training loss: 99387841708032.0

  8%|█████▏                                                              | 7643/100000 [01:35<19:07, 80.50it/s]
epoch 7600  training loss: 97827644506112.0

  8%|█████▎                                                              | 7804/100000 [01:37<19:01, 80.77it/s]
epoch 7700  training loss: 319350347137024.0
epoch 7700  clean testing loss: 1249567181897728.0
epoch 7800  training loss: 94624664256512.0

  8%|█████▍                                                              | 7964/100000 [01:39<19:17, 79.52it/s]
epoch 7900  training loss: 92165728370688.0
epoch 7900  clean testing loss: 176710439927808.0
epoch 8000  training loss: 96059535654912.0
epoch 8000  clean testing loss: 173002910072832.0

  8%|█████▌                                                              | 8121/100000 [01:41<19:03, 80.32it/s]
epoch 8100  training loss: 89919645024256.0

  8%|█████▋                                                              | 8280/100000 [01:43<19:15, 79.41it/s]
epoch 8200  training loss: 88613228380160.0
epoch 8200  clean testing loss: 169855504351232.0
epoch 8300  training loss: 87290890158080.0

  8%|█████▋                                                              | 8440/100000 [01:45<19:14, 79.30it/s]
epoch 8400  training loss: 86635664375808.0

  9%|█████▊                                                              | 8607/100000 [01:47<19:06, 79.73it/s]
epoch 8500  training loss: 84719991521280.0
epoch 8500  clean testing loss: 162221132873728.0
epoch 8600  training loss: 1246062354366464.0

  9%|█████▉                                                              | 8765/100000 [01:49<19:07, 79.52it/s]
epoch 8700  training loss: 82628854153216.0
epoch 8700  clean testing loss: 157477324718080.0
epoch 8800  training loss: 81406977900544.0

  9%|██████                                                              | 8927/100000 [01:51<19:01, 79.79it/s]
epoch 8900  training loss: 80175135981568.0

  9%|██████▏                                                             | 9083/100000 [01:53<18:47, 80.61it/s]
epoch 9000  training loss: 95385217400832.0
epoch 9000  clean testing loss: 160163440885760.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 9100  training loss: 78566838501376.0

  9%|██████▎                                                             | 9244/100000 [01:55<18:49, 80.34it/s]
epoch 9200  training loss: 77694624595968.0

  9%|██████▍                                                             | 9403/100000 [01:57<18:43, 80.61it/s]
epoch 9300  training loss: 76614473875456.0
epoch 9300  clean testing loss: 146389396881408.0
epoch 9400  training loss: 75681971044352.0

 10%|██████▌                                                             | 9563/100000 [01:59<18:53, 79.82it/s]
epoch 9500  training loss: 74583021453312.0
epoch 9500  clean testing loss: 142437892751360.0
epoch 9600  training loss: 73067694915584.0

 10%|██████▌                                                             | 9726/100000 [02:01<18:37, 80.76it/s]
epoch 9700  training loss: 72039117357056.0

 10%|██████▋                                                             | 9888/100000 [02:03<18:29, 81.19it/s]
epoch 9800  training loss: 136111263318016.0
epoch 9800  clean testing loss: 138366473469952.0
epoch 9900  training loss: 70137738690560.0

 10%|██████▋                                                            | 10050/100000 [02:05<18:31, 80.92it/s]
epoch 10000  training loss: 69202329206784.0
epoch 10000  clean testing loss: 132847666987008.0

 10%|██████▊                                                            | 10211/100000 [02:07<18:36, 80.42it/s]
epoch 10100  training loss: 74124869238784.0
epoch 10100  clean testing loss: 136018820857856.0
epoch 10200  training loss: 67424879640576.0

 10%|██████▉                                                            | 10373/100000 [02:09<18:44, 79.71it/s]
epoch 10300  training loss: 66612841414656.0
epoch 10300  clean testing loss: 127481801605120.0
epoch 10400  training loss: 68146241208320.0

 11%|███████                                                            | 10535/100000 [02:11<18:37, 80.07it/s]
epoch 10500  training loss: 64646568476672.0

 11%|███████▏                                                           | 10696/100000 [02:13<18:37, 79.94it/s]
epoch 10600  training loss: 173981877403648.0
epoch 10600  clean testing loss: 306858870964224.0
epoch 10700  training loss: 62919706411008.0

 11%|███████▎                                                           | 10852/100000 [02:15<18:38, 79.72it/s]
epoch 10800  training loss: 311487771967488.0

 11%|███████▍                                                           | 11019/100000 [02:17<18:33, 79.92it/s]
epoch 10900  training loss: 62432533807104.0
epoch 10900  clean testing loss: 117921229570048.0
epoch 11000  training loss: 60352238714880.0
epoch 11000  clean testing loss: 116336755736576.0

 11%|███████▍                                                           | 11179/100000 [02:19<18:27, 80.21it/s]
epoch 11100  training loss: 59488690241536.0
epoch 11100  clean testing loss: 114709181235200.0
epoch 11200  training loss: 324526722252800.0

 11%|███████▌                                                           | 11336/100000 [02:21<18:24, 80.29it/s]
epoch 11300  training loss: 57999255142400.0

 11%|███████▋                                                           | 11498/100000 [02:23<18:18, 80.57it/s]
epoch 11400  training loss: 57082996850688.0
epoch 11400  clean testing loss: 110424246714368.0
epoch 11500  training loss: 58542904049664.0

 12%|███████▊                                                           | 11658/100000 [02:25<18:28, 79.69it/s]
epoch 11600  training loss: 55482806960128.0

 12%|███████▉                                                           | 11816/100000 [02:27<18:19, 80.18it/s]
epoch 11700  training loss: 54566812909568.0
epoch 11700  clean testing loss: 105838286995456.0
epoch 11800  training loss: 689527270146048.0

 12%|████████                                                           | 11978/100000 [02:29<18:09, 80.81it/s]
epoch 11900  training loss: 53279455182848.0
epoch 11900  clean testing loss: 103366105497600.0
epoch 12000  training loss: 52511926910976.0
epoch 12000  clean testing loss: 102386358026240.0

 12%|████████▏                                                          | 12140/100000 [02:31<18:07, 80.81it/s]
epoch 12100  training loss: 51717961940992.0

 12%|████████▏                                                          | 12301/100000 [02:33<18:19, 79.80it/s]
epoch 12200  training loss: 50961787650048.0
epoch 12200  clean testing loss: 99588715315200.0
epoch 12300  training loss: 50159379546112.0

 12%|████████▎                                                          | 12463/100000 [02:35<18:06, 80.58it/s]
epoch 12400  training loss: 49033238282240.0

 13%|████████▍                                                          | 12629/100000 [02:37<18:13, 79.91it/s]
epoch 12500  training loss: 47834153877504.0
epoch 12500  clean testing loss: 96139109990400.0
epoch 12600  training loss: 46511379447808.0

 13%|████████▌                                                          | 12789/100000 [02:39<18:13, 79.75it/s]
epoch 12700  training loss: 45664859848704.0
epoch 12700  clean testing loss: 93793026048000.0
epoch 12800  training loss: 45341013442560.0

 13%|████████▋                                                          | 12950/100000 [02:41<18:01, 80.47it/s]
epoch 12900  training loss: 44503964581888.0

 13%|████████▊                                                          | 13110/100000 [02:43<18:06, 79.99it/s]
epoch 13000  training loss: 43692232540160.0
epoch 13000  clean testing loss: 88130145222656.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 13100  training loss: 759973122408448.0

 13%|████████▉                                                          | 13269/100000 [02:45<18:00, 80.28it/s]
epoch 13200  training loss: 42389557215232.0
epoch 13200  clean testing loss: 84782914469888.0
epoch 13300  training loss: 41992419540992.0

 13%|████████▉                                                          | 13428/100000 [02:47<17:52, 80.70it/s]
epoch 13400  training loss: 41208155996160.0

 14%|█████████                                                          | 13595/100000 [02:50<17:48, 80.89it/s]
epoch 13500  training loss: 45523125927936.0
epoch 13500  clean testing loss: 81464246927360.0
epoch 13600  training loss: 40139149541376.0

 14%|█████████▏                                                         | 13755/100000 [02:52<17:57, 80.06it/s]
epoch 13700  training loss: 908821186740224.0

 14%|█████████▎                                                         | 13917/100000 [02:54<17:51, 80.37it/s]
epoch 13800  training loss: 38982083674112.0
epoch 13800  clean testing loss: 77863982202880.0
epoch 13900  training loss: 49252503912448.0

 14%|█████████▍                                                         | 14076/100000 [02:56<17:53, 80.02it/s]
epoch 14000  training loss: 38461813817344.0
epoch 14000  clean testing loss: 74611123290112.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 14100  training loss: 37310410260480.0

 14%|█████████▌                                                         | 14240/100000 [02:58<17:45, 80.47it/s]
epoch 14200  training loss: 247262038982656.0

 14%|█████████▋                                                         | 14397/100000 [03:00<17:54, 79.70it/s]
epoch 14300  training loss: 36363558715392.0
epoch 14300  clean testing loss: 71488262635520.0
epoch 14400  training loss: 48705147240448.0

 15%|█████████▊                                                         | 14558/100000 [03:02<17:46, 80.14it/s]
epoch 14500  training loss: 91505226153984.0

 15%|█████████▊                                                         | 14717/100000 [03:03<17:39, 80.50it/s]
epoch 14600  training loss: 34925258473472.0
epoch 14600  clean testing loss: 70405477892096.0
epoch 14700  training loss: 155865638240256.0

 15%|█████████▉                                                         | 14883/100000 [03:06<17:48, 79.68it/s]
epoch 14800  training loss: 36477253713920.0
epoch 14800  clean testing loss: 66873743900672.0
epoch 14900  training loss: 33325175537664.0

 15%|██████████                                                         | 15038/100000 [03:08<17:51, 79.30it/s]
epoch 15000  training loss: 2983146039541760.0
epoch 15000  clean testing loss: 734068362706944.0

 15%|██████████▏                                                        | 15199/100000 [03:10<17:48, 79.35it/s]
epoch 15100  training loss: 32329619734528.0

 15%|██████████▎                                                        | 15358/100000 [03:12<17:41, 79.75it/s]
epoch 15200  training loss: 31960661491712.0
epoch 15200  clean testing loss: 63280601104384.0
epoch 15300  training loss: 31522417541120.0

 16%|██████████▍                                                        | 15517/100000 [03:14<17:33, 80.23it/s]
epoch 15400  training loss: 31135897747456.0
epoch 15400  clean testing loss: 61358087340032.0
epoch 15500  training loss: 30660867653632.0

 16%|██████████▌                                                        | 15686/100000 [03:16<17:33, 80.06it/s]
epoch 15600  training loss: 32669287055360.0

 16%|██████████▌                                                        | 15846/100000 [03:18<17:35, 79.70it/s]
epoch 15700  training loss: 30066692063232.0
epoch 15700  clean testing loss: 61831984971776.0
epoch 15800  training loss: 29388521340928.0

 16%|██████████▋                                                        | 16000/100000 [03:20<17:40, 79.23it/s]
epoch 15900  training loss: 28975669706752.0

 16%|██████████▊                                                        | 16165/100000 [03:22<17:28, 79.95it/s]
epoch 16000  training loss: 1463900813918208.0
epoch 16000  clean testing loss: 1470128382279680.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 16100  training loss: 28316731965440.0

 16%|██████████▉                                                        | 16321/100000 [03:24<17:33, 79.43it/s]
epoch 16200  training loss: 27922245091328.0
epoch 16200  clean testing loss: 55109857837056.0
epoch 16300  training loss: 27598522417152.0

 16%|███████████                                                        | 16482/100000 [03:26<17:24, 79.97it/s]
epoch 16400  training loss: 169487730999296.0

 17%|███████████▏                                                       | 16637/100000 [03:28<17:25, 79.75it/s]
epoch 16500  training loss: 26945725136896.0
epoch 16500  clean testing loss: 52590813380608.0
epoch 16600  training loss: 87582763384832.0

 17%|███████████▎                                                       | 16797/100000 [03:30<17:26, 79.48it/s]
epoch 16700  training loss: 26163864928256.0

 17%|███████████▎                                                       | 16958/100000 [03:32<17:13, 80.38it/s]
epoch 16800  training loss: 72382949621760.0
epoch 16800  clean testing loss: 65837641760768.0
epoch 16900  training loss: 25468203958272.0

 17%|███████████▍                                                       | 17119/100000 [03:34<17:16, 79.95it/s]
epoch 17000  training loss: 43465719152640.0
epoch 17000  clean testing loss: 62567925940224.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 17100  training loss: 24818141364224.0

 17%|███████████▌                                                       | 17282/100000 [03:36<17:16, 79.83it/s]
epoch 17200  training loss: 2383212391170048.0

 17%|███████████▋                                                       | 17443/100000 [03:38<17:03, 80.68it/s]
epoch 17300  training loss: 24226090188800.0
epoch 17300  clean testing loss: 47091195838464.0
epoch 17400  training loss: 23845830393856.0

 18%|███████████▊                                                       | 17600/100000 [03:40<17:08, 80.11it/s]
epoch 17500  training loss: 31819678351360.0

 18%|███████████▉                                                       | 17766/100000 [03:42<17:09, 79.88it/s]
epoch 17600  training loss: 23085637959680.0
epoch 17600  clean testing loss: 45646895644672.0
epoch 17700  training loss: 23761011081216.0

 18%|████████████                                                       | 17924/100000 [03:44<17:09, 79.75it/s]
epoch 17800  training loss: 23823952904192.0
epoch 17800  clean testing loss: 49042809683968.0
epoch 17900  training loss: 22240846413824.0

 18%|████████████                                                       | 18086/100000 [03:46<17:02, 80.11it/s]
epoch 18000  training loss: 26877150363648.0
epoch 18000  clean testing loss: 42107175698432.0

 18%|████████████▏                                                      | 18247/100000 [03:48<16:54, 80.56it/s]
epoch 18100  training loss: 21650653315072.0
epoch 18100  clean testing loss: 42763500388352.0
epoch 18200  training loss: 21396874854400.0

 18%|████████████▎                                                      | 18408/100000 [03:50<17:01, 79.89it/s]
epoch 18300  training loss: 21118305959936.0

 19%|████████████▍                                                      | 18568/100000 [03:52<16:48, 80.71it/s]
epoch 18400  training loss: 20881560567808.0
epoch 18400  clean testing loss: 41179735392256.0
epoch 18500  training loss: 20604216410112.0

 19%|████████████▌                                                      | 18727/100000 [03:54<16:59, 79.76it/s]
epoch 18600  training loss: 33737244934144.0
epoch 18600  clean testing loss: 48351936512000.0
epoch 18700  training loss: 20564420853760.0

 19%|████████████▋                                                      | 18893/100000 [03:56<16:51, 80.15it/s]
epoch 18800  training loss: 19694096482304.0

 19%|████████████▊                                                      | 19048/100000 [03:58<16:51, 80.02it/s]
epoch 18900  training loss: 318590003707904.0
epoch 18900  clean testing loss: 493933620625408.0
epoch 19000  training loss: 19592135049216.0
epoch 19000  clean testing loss: 36548150034432.0

 19%|████████████▊                                                      | 19208/100000 [04:00<17:00, 79.19it/s]
epoch 19100  training loss: 34308653842432.0

 19%|████████████▉                                                      | 19372/100000 [04:02<16:50, 79.77it/s]
epoch 19200  training loss: 423031897849856.0
epoch 19200  clean testing loss: 512784399859712.0
epoch 19300  training loss: 450235952267264.0

 20%|█████████████                                                      | 19531/100000 [04:04<16:51, 79.59it/s]
epoch 19400  training loss: 18815660326912.0
epoch 19400  clean testing loss: 38838575562752.0
epoch 19500  training loss: 19038444978176.0

 20%|█████████████▏                                                     | 19692/100000 [04:06<16:48, 79.65it/s]
epoch 19600  training loss: 258818319581184.0

 20%|█████████████▎                                                     | 19852/100000 [04:08<16:41, 80.04it/s]
epoch 19700  training loss: 17478246727680.0
epoch 19700  clean testing loss: 34635625005056.0
epoch 19800  training loss: 89480987934720.0

 20%|█████████████▍                                                     | 20013/100000 [04:10<17:01, 78.32it/s]
epoch 19900  training loss: 17319616053248.0

 20%|█████████████▌                                                     | 20167/100000 [04:12<16:31, 80.53it/s]
epoch 20000  training loss: 379455629426688.0
epoch 20000  clean testing loss: 293971821592576.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 20100  training loss: 16506149666816.0

 20%|█████████████▌                                                     | 20328/100000 [04:14<16:29, 80.48it/s]
epoch 20200  training loss: 73858648375296.0
epoch 20200  clean testing loss: 81292179800064.0
epoch 20300  training loss: 16149580349440.0

 20%|█████████████▋                                                     | 20489/100000 [04:16<16:30, 80.24it/s]
epoch 20400  training loss: 4488910570782720.0

 21%|█████████████▊                                                     | 20611/100000 [04:17<16:32, 79.96it/s]
epoch 20500  training loss: 15668072153088.0
epoch 20500  clean testing loss: 30848042663936.0
epoch 20600  training loss: 15408503455744.0

 21%|█████████████▉                                                     | 20775/100000 [04:19<16:25, 80.40it/s]
epoch 20700  training loss: 16638600544256.0

 21%|██████████████                                                     | 20937/100000 [04:21<16:19, 80.75it/s]
epoch 20800  training loss: 16023569825792.0
epoch 20800  clean testing loss: 28240592764928.0
epoch 20900  training loss: 15471961178112.0

 21%|██████████████▏                                                    | 21099/100000 [04:23<16:10, 81.26it/s]
epoch 21000  training loss: 117863700496384.0
epoch 21000  clean testing loss: 87785037889536.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 21100  training loss: 14284340854784.0

 21%|██████████████▏                                                    | 21261/100000 [04:25<16:13, 80.89it/s]
epoch 21200  training loss: 14135349739520.0

 21%|██████████████▎                                                    | 21423/100000 [04:27<16:15, 80.53it/s]
epoch 21300  training loss: 13970277662720.0
epoch 21300  clean testing loss: 27228861628416.0
epoch 21400  training loss: 13792495796224.0

 22%|██████████████▍                                                    | 21585/100000 [04:29<16:03, 81.37it/s]
epoch 21500  training loss: 68231201030144.0

 22%|██████████████▌                                                    | 21746/100000 [04:31<16:19, 79.91it/s]
epoch 21600  training loss: 13442351104000.0
epoch 21600  clean testing loss: 26173455204352.0
epoch 21700  training loss: 13176883118080.0

 22%|██████████████▋                                                    | 21906/100000 [04:33<16:15, 80.10it/s]
epoch 21800  training loss: 13114872430592.0
epoch 21800  clean testing loss: 24409054117888.0
epoch 21900  training loss: 12858560610304.0

 22%|██████████████▊                                                    | 22067/100000 [04:35<16:06, 80.64it/s]
epoch 22000  training loss: 12724248510464.0
epoch 22000  clean testing loss: 24914302074880.0

 22%|██████████████▉                                                    | 22227/100000 [04:37<16:06, 80.46it/s]
epoch 22100  training loss: 12510604296192.0
epoch 22100  clean testing loss: 24445498425344.0
epoch 22200  training loss: 48062303043584.0

 22%|███████████████                                                    | 22389/100000 [04:39<15:55, 81.25it/s]
epoch 22300  training loss: 12171852382208.0
epoch 22300  clean testing loss: 23874037088256.0
epoch 22400  training loss: 155639833690112.0

 23%|███████████████                                                    | 22551/100000 [04:41<15:56, 80.95it/s]
epoch 22500  training loss: 11875733471232.0

 23%|███████████████▏                                                   | 22713/100000 [04:43<15:58, 80.60it/s]
epoch 22600  training loss: 24534379921408.0
epoch 22600  clean testing loss: 42507886919680.0
epoch 22700  training loss: 11869715693568.0

 23%|███████████████▎                                                   | 22870/100000 [04:45<16:01, 80.25it/s]
epoch 22800  training loss: 11417047531520.0

 23%|███████████████▍                                                   | 23037/100000 [04:47<16:03, 79.84it/s]
epoch 22900  training loss: 11280077291520.0
epoch 22900  clean testing loss: 21382595346432.0
epoch 23000  training loss: 11153875927040.0
epoch 23000  clean testing loss: 21206879174656.0

 23%|███████████████▌                                                   | 23191/100000 [04:49<16:00, 79.97it/s]
epoch 23100  training loss: 10950897827840.0
epoch 23100  clean testing loss: 21035204214784.0
epoch 23200  training loss: 15655979974656.0

 23%|███████████████▋                                                   | 23351/100000 [04:51<15:54, 80.29it/s]
epoch 23300  training loss: 10810087702528.0

 24%|███████████████▊                                                   | 23510/100000 [04:53<15:59, 79.73it/s]
epoch 23400  training loss: 10658232926208.0
epoch 23400  clean testing loss: 20263989149696.0
epoch 23500  training loss: 10526166876160.0

 24%|███████████████▊                                                   | 23669/100000 [04:55<15:55, 79.90it/s]
epoch 23600  training loss: 10349190316032.0

 24%|███████████████▉                                                   | 23832/100000 [04:57<15:57, 79.58it/s]
epoch 23700  training loss: 10252852396032.0
epoch 23700  clean testing loss: 19653634031616.0
epoch 23800  training loss: 15571745767424.0

 24%|████████████████                                                   | 23998/100000 [04:59<15:52, 79.80it/s]
epoch 23900  training loss: 9973028356096.0
epoch 23900  clean testing loss: 18810467778560.0
epoch 24000  training loss: 9759042306048.0
epoch 24000  clean testing loss: 18859404820480.0

 24%|████████████████▏                                                  | 24155/100000 [05:01<15:39, 80.73it/s]
epoch 24100  training loss: 9662939267072.0

 24%|████████████████▎                                                  | 24316/100000 [05:03<15:43, 80.20it/s]
epoch 24200  training loss: 9620795949056.0
epoch 24200  clean testing loss: 18414984757248.0
epoch 24300  training loss: 9478282936320.0

 24%|████████████████▍                                                  | 24474/100000 [05:05<15:37, 80.59it/s]
epoch 24400  training loss: 9390645051392.0

 25%|████████████████▌                                                  | 24634/100000 [05:07<15:44, 79.83it/s]
epoch 24500  training loss: 95579640168448.0
epoch 24500  clean testing loss: 84051411075072.0
epoch 24600  training loss: 9148227911680.0

 25%|████████████████▌                                                  | 24797/100000 [05:09<15:33, 80.55it/s]
epoch 24700  training loss: 801684032847872.0
epoch 24700  clean testing loss: 495273717530624.0
epoch 24800  training loss: 9025457487872.0

 25%|████████████████▋                                                  | 24952/100000 [05:11<15:44, 79.46it/s]
epoch 24900  training loss: 980833695432704.0

 25%|████████████████▊                                                  | 25120/100000 [05:13<15:35, 80.02it/s]
epoch 25000  training loss: 8771418456064.0
epoch 25000  clean testing loss: 17327632416768.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 25100  training loss: 71044069064704.0

 25%|████████████████▉                                                  | 25279/100000 [05:15<15:28, 80.48it/s]
epoch 25200  training loss: 229722634059776.0

 25%|█████████████████                                                  | 25437/100000 [05:17<15:29, 80.25it/s]
epoch 25300  training loss: 8451497394176.0
epoch 25300  clean testing loss: 17219103752192.0
epoch 25400  training loss: 8772550393856.0

 26%|█████████████████▏                                                 | 25596/100000 [05:19<15:31, 79.92it/s]
epoch 25500  training loss: 8227533094912.0
epoch 25500  clean testing loss: 15309162414080.0
epoch 25600  training loss: 8131147464704.0

 26%|█████████████████▎                                                 | 25754/100000 [05:21<15:30, 79.79it/s]
epoch 25700  training loss: 7952385179648.0

 26%|█████████████████▎                                                 | 25923/100000 [05:24<15:30, 79.64it/s]
epoch 25800  training loss: 8209559977984.0
epoch 25800  clean testing loss: 17108872200192.0
epoch 25900  training loss: 8453077073920.0

 26%|█████████████████▍                                                 | 26075/100000 [05:25<15:23, 80.05it/s]
epoch 26000  training loss: 7678160011264.0
epoch 26000  clean testing loss: 15219742998528.0

 26%|█████████████████▌                                                 | 26238/100000 [05:27<15:26, 79.63it/s]
epoch 26100  training loss: 9620370227200.0
epoch 26100  clean testing loss: 14130625904640.0
epoch 26200  training loss: 7502899970048.0

 26%|█████████████████▋                                                 | 26403/100000 [05:30<15:18, 80.09it/s]
epoch 26300  training loss: 7412245331968.0
epoch 26300  clean testing loss: 14556051013632.0
epoch 26400  training loss: 7317957902336.0

 27%|█████████████████▊                                                 | 26562/100000 [05:32<15:25, 79.34it/s]
epoch 26500  training loss: 11235967893504.0

 27%|█████████████████▉                                                 | 26721/100000 [05:34<15:12, 80.35it/s]
epoch 26600  training loss: 7129497862144.0
epoch 26600  clean testing loss: 13998452899840.0
epoch 26700  training loss: 7127393894400.0

 27%|██████████████████                                                 | 26879/100000 [05:36<15:15, 79.87it/s]
epoch 26800  training loss: 7006595317760.0

 27%|██████████████████                                                 | 27034/100000 [05:37<15:37, 77.80it/s]
epoch 26900  training loss: 8739106062336.0
epoch 26900  clean testing loss: 20103131299840.0
epoch 27000  training loss: 7615737757696.0
epoch 27000  clean testing loss: 22555578597376.0

 27%|██████████████████▏                                                | 27202/100000 [05:40<15:00, 80.86it/s]
epoch 27100  training loss: 6729140535296.0
epoch 27100  clean testing loss: 13446312624128.0
epoch 27200  training loss: 6666568859648.0

 27%|██████████████████▎                                                | 27362/100000 [05:42<15:05, 80.21it/s]
epoch 27300  training loss: 6612211728384.0

 28%|██████████████████▍                                                | 27524/100000 [05:44<15:06, 79.99it/s]
epoch 27400  training loss: 6517686796288.0
epoch 27400  clean testing loss: 13382229950464.0
epoch 27500  training loss: 6430938628096.0

 28%|██████████████████▌                                                | 27680/100000 [05:46<15:02, 80.10it/s]
epoch 27600  training loss: 48767361351680.0

 28%|██████████████████▋                                                | 27847/100000 [05:48<15:07, 79.52it/s]
epoch 27700  training loss: 6331304509440.0
epoch 27700  clean testing loss: 12680987410432.0
epoch 27800  training loss: 21086192271360.0

 28%|██████████████████▊                                                | 27997/100000 [05:49<14:49, 80.93it/s]
epoch 27900  training loss: 13283701555200.0
epoch 27900  clean testing loss: 18444523143168.0
epoch 28000  training loss: 6216485437440.0
epoch 28000  clean testing loss: 12321617346560.0

 28%|██████████████████▊                                                | 28158/100000 [05:52<14:54, 80.28it/s]
epoch 28100  training loss: 7041055719424.0

 28%|██████████████████▉                                                | 28319/100000 [05:54<14:52, 80.30it/s]
epoch 28200  training loss: 5945853739008.0
epoch 28200  clean testing loss: 12892915105792.0
epoch 28300  training loss: 6588392800256.0

 28%|███████████████████                                                | 28481/100000 [05:56<14:52, 80.13it/s]
epoch 28400  training loss: 5795552428032.0

 29%|███████████████████▏                                               | 28642/100000 [05:58<14:53, 79.86it/s]
epoch 28500  training loss: 168325371920384.0
epoch 28500  clean testing loss: 153344140115968.0
epoch 28600  training loss: 5766383665152.0

 29%|███████████████████▎                                               | 28805/100000 [06:00<14:45, 80.42it/s]
epoch 28700  training loss: 5646154465280.0
epoch 28700  clean testing loss: 12090681065472.0
epoch 28800  training loss: 12845822509056.0

 29%|███████████████████▍                                               | 28965/100000 [06:02<14:45, 80.23it/s]
epoch 28900  training loss: 5534943019008.0

 29%|███████████████████▌                                               | 29127/100000 [06:04<14:37, 80.73it/s]
epoch 29000  training loss: 257674516103168.0
epoch 29000  clean testing loss: 290221274955776.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 29100  training loss: 6612991344640.0

 29%|███████████████████▌                                               | 29289/100000 [06:06<14:37, 80.60it/s]
epoch 29200  training loss: 5601147486208.0

 29%|███████████████████▋                                               | 29451/100000 [06:08<14:33, 80.73it/s]
epoch 29300  training loss: 5282089926656.0
epoch 29300  clean testing loss: 12030161453056.0
epoch 29400  training loss: 464306701336576.0

 30%|███████████████████▊                                               | 29613/100000 [06:10<14:37, 80.24it/s]
epoch 29500  training loss: 5313419804672.0
epoch 29500  clean testing loss: 12658763890688.0
epoch 29600  training loss: 5131941707776.0

 30%|███████████████████▉                                               | 29770/100000 [06:12<14:33, 80.37it/s]
epoch 29700  training loss: 5070219902976.0

 30%|████████████████████                                               | 29932/100000 [06:14<14:30, 80.47it/s]
epoch 29800  training loss: 5025467203584.0
epoch 29800  clean testing loss: 11763743457280.0
epoch 29900  training loss: 5040289873920.0

 30%|████████████████████▏                                              | 30097/100000 [06:16<14:31, 80.24it/s]
epoch 30000  training loss: 5000452898816.0
epoch 30000  clean testing loss: 11471211724800.0

 30%|████████████████████▎                                              | 30257/100000 [06:18<14:36, 79.56it/s]
epoch 30100  training loss: 4875957567488.0
epoch 30100  clean testing loss: 11358963761152.0
epoch 30200  training loss: 4829762551808.0

 30%|████████████████████▍                                              | 30419/100000 [06:20<14:30, 79.92it/s]
epoch 30300  training loss: 4808935735296.0
epoch 30300  clean testing loss: 11554578759680.0
epoch 30400  training loss: 4748466978816.0

 31%|████████████████████▍                                              | 30578/100000 [06:22<14:19, 80.75it/s]
epoch 30500  training loss: 4731192213504.0

 31%|████████████████████▌                                              | 30739/100000 [06:24<14:19, 80.57it/s]
epoch 30600  training loss: 4704231751680.0
epoch 30600  clean testing loss: 11521295908864.0
epoch 30700  training loss: 260978184814592.0

 31%|████████████████████▋                                              | 30894/100000 [06:26<14:26, 79.76it/s]
epoch 30800  training loss: 4612755554304.0

 31%|████████████████████▊                                              | 31062/100000 [06:28<14:18, 80.29it/s]
epoch 30900  training loss: 4558393704448.0
epoch 30900  clean testing loss: 11416848302080.0
epoch 31000  training loss: 4535534223360.0
epoch 31000  clean testing loss: 12086141779968.0

 31%|████████████████████▉                                              | 31215/100000 [06:30<14:19, 79.99it/s]
epoch 31100  training loss: 4643623010304.0
epoch 31100  clean testing loss: 12128370032640.0
epoch 31200  training loss: 4414758715392.0

 31%|█████████████████████                                              | 31384/100000 [06:32<14:16, 80.07it/s]
epoch 31300  training loss: 88867319316480.0

 32%|█████████████████████▏                                             | 31542/100000 [06:34<14:13, 80.21it/s]
epoch 31400  training loss: 4382588665856.0
epoch 31400  clean testing loss: 11537830903808.0
epoch 31500  training loss: 4292215832576.0

 32%|█████████████████████▏                                             | 31703/100000 [06:36<14:12, 80.11it/s]
epoch 31600  training loss: 4276701626368.0

 32%|█████████████████████▎                                             | 31865/100000 [06:38<14:13, 79.82it/s]
epoch 31700  training loss: 4218030129152.0
epoch 31700  clean testing loss: 11224714575872.0
epoch 31800  training loss: 4200559017984.0

 32%|█████████████████████▍                                             | 32027/100000 [06:40<14:08, 80.14it/s]
epoch 31900  training loss: 4174477524992.0
epoch 31900  clean testing loss: 11264734527488.0
epoch 32000  training loss: 4168916140032.0
epoch 32000  clean testing loss: 11566708686848.0

 32%|█████████████████████▌                                             | 32189/100000 [06:42<14:08, 79.95it/s]
epoch 32100  training loss: 4109666615296.0

 32%|█████████████████████▋                                             | 32350/100000 [06:44<14:05, 80.01it/s]
epoch 32200  training loss: 36577027817472.0
epoch 32200  clean testing loss: 31122253676544.0
epoch 32300  training loss: 11447418486784.0

 33%|█████████████████████▊                                             | 32504/100000 [06:46<14:05, 79.84it/s]
epoch 32400  training loss: 7609195167744.0

 33%|█████████████████████▉                                             | 32664/100000 [06:48<14:05, 79.62it/s]
epoch 32500  training loss: 4146843615232.0
epoch 32500  clean testing loss: 12315764195328.0
epoch 32600  training loss: 3990693871616.0

 33%|█████████████████████▉                                             | 32826/100000 [06:50<13:48, 81.07it/s]
epoch 32700  training loss: 3880772173824.0
epoch 32700  clean testing loss: 10937862979584.0
epoch 32800  training loss: 3860548288512.0

 33%|██████████████████████                                             | 32987/100000 [06:52<13:52, 80.51it/s]
epoch 32900  training loss: 3915790155776.0

 33%|██████████████████████▏                                            | 33154/100000 [06:54<13:58, 79.72it/s]
epoch 33000  training loss: 3775937380352.0
epoch 33000  clean testing loss: 10435659038720.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 33100  training loss: 3748293246976.0

 33%|██████████████████████▎                                            | 33314/100000 [06:56<13:57, 79.65it/s]
epoch 33200  training loss: 3730958974976.0
epoch 33200  clean testing loss: 10881345781760.0
epoch 33300  training loss: 3708723920896.0

 33%|██████████████████████▍                                            | 33475/100000 [06:58<13:45, 80.55it/s]
epoch 33400  training loss: 3702113959936.0

 34%|██████████████████████▌                                            | 33636/100000 [07:00<13:48, 80.08it/s]
epoch 33500  training loss: 3672065179648.0
epoch 33500  clean testing loss: 10881800863744.0
epoch 33600  training loss: 3670384312320.0

 34%|██████████████████████▋                                            | 33795/100000 [07:02<13:55, 79.25it/s]
epoch 33700  training loss: 3586682781696.0

 34%|██████████████████████▋                                            | 33952/100000 [07:04<13:50, 79.48it/s]
epoch 33800  training loss: 3590989807616.0
epoch 33800  clean testing loss: 10789344772096.0
epoch 33900  training loss: 3726331609088.0

 34%|██████████████████████▊                                            | 34111/100000 [07:06<13:49, 79.43it/s]
epoch 34000  training loss: 3541025161216.0
epoch 34000  clean testing loss: 10895333785600.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 34100  training loss: 3484541517824.0

 34%|██████████████████████▉                                            | 34276/100000 [07:08<13:42, 79.95it/s]
epoch 34200  training loss: 19136648314880.0

 34%|███████████████████████                                            | 34431/100000 [07:10<13:46, 79.35it/s]
epoch 34300  training loss: 3420624519168.0
epoch 34300  clean testing loss: 10744097669120.0
epoch 34400  training loss: 3395076751360.0

 35%|███████████████████████▏                                           | 34590/100000 [07:12<13:27, 80.98it/s]
epoch 34500  training loss: 3371625349120.0

 35%|███████████████████████▎                                           | 34757/100000 [07:14<13:32, 80.27it/s]
epoch 34600  training loss: 3348180238336.0
epoch 34600  clean testing loss: 10765029343232.0
epoch 34700  training loss: 3310910963712.0

 35%|███████████████████████▍                                           | 34913/100000 [07:16<13:44, 78.95it/s]
epoch 34800  training loss: 3281564467200.0
epoch 34800  clean testing loss: 10691747512320.0
epoch 34900  training loss: 3954759434240.0

 35%|███████████████████████▌                                           | 35076/100000 [07:18<13:37, 79.37it/s]
epoch 35000  training loss: 8961074921472.0
epoch 35000  clean testing loss: 21650252759040.0

 35%|███████████████████████▌                                           | 35221/100000 [07:20<15:09, 71.25it/s]
epoch 35100  training loss: 14596079353856.0
epoch 35100  clean testing loss: 31161296355328.0
epoch 35200  training loss: 3184862167040.0

 35%|███████████████████████▋                                           | 35365/100000 [07:22<15:10, 71.02it/s]
epoch 35300  training loss: 3168434651136.0

 36%|███████████████████████▊                                           | 35509/100000 [07:24<14:50, 72.39it/s]
epoch 35400  training loss: 3776046956544.0

 36%|███████████████████████▉                                           | 35645/100000 [07:26<15:04, 71.17it/s]
epoch 35500  training loss: 3101856104448.0
epoch 35500  clean testing loss: 10837615968256.0
epoch 35600  training loss: 6825994878976.0

 36%|███████████████████████▉                                           | 35789/100000 [07:28<15:02, 71.16it/s]
epoch 35700  training loss: 106335437848576.0

 36%|████████████████████████                                           | 35933/100000 [07:30<15:12, 70.23it/s]
epoch 35800  training loss: 3144225128448.0
epoch 35800  clean testing loss: 10252830375936.0
epoch 35900  training loss: 28072178876416.0

 36%|████████████████████████▏                                          | 36074/100000 [07:32<15:13, 70.01it/s]
epoch 36000  training loss: 3016702033920.0
epoch 36000  clean testing loss: 10760654684160.0

 36%|████████████████████████▎                                          | 36218/100000 [07:34<15:07, 70.31it/s]
epoch 36100  training loss: 2980785422336.0
epoch 36100  clean testing loss: 10591722799104.0
epoch 36200  training loss: 2960276586496.0

 36%|████████████████████████▎                                          | 36362/100000 [07:36<15:14, 69.57it/s]
epoch 36300  training loss: 2934618193920.0

 36%|████████████████████████▍                                          | 36499/100000 [07:38<14:49, 71.37it/s]
epoch 36400  training loss: 2933052669952.0

 37%|████████████████████████▌                                          | 36642/100000 [07:40<15:01, 70.26it/s]
epoch 36500  training loss: 3322511622144.0
epoch 36500  clean testing loss: 10111351259136.0
epoch 36600  training loss: 2900897300480.0

 37%|████████████████████████▋                                          | 36778/100000 [07:42<14:58, 70.35it/s]
epoch 36700  training loss: 183814382944256.0

 37%|████████████████████████▋                                          | 36922/100000 [07:44<14:52, 70.66it/s]
epoch 36800  training loss: 2838028353536.0
epoch 36800  clean testing loss: 10512185163776.0
epoch 36900  training loss: 2806641065984.0

 37%|████████████████████████▊                                          | 37066/100000 [07:46<14:43, 71.19it/s]
epoch 37000  training loss: 2809160269824.0
epoch 37000  clean testing loss: 10715692793856.0

 37%|████████████████████████▉                                          | 37207/100000 [07:48<14:50, 70.54it/s]
epoch 37100  training loss: 2795898142720.0

 37%|█████████████████████████                                          | 37351/100000 [07:50<14:41, 71.10it/s]
epoch 37200  training loss: 2828160204800.0
epoch 37200  clean testing loss: 11002752008192.0
epoch 37300  training loss: 9818893975552.0

 37%|█████████████████████████                                          | 37495/100000 [07:52<14:34, 71.47it/s]
epoch 37400  training loss: 2827726618624.0

 38%|█████████████████████████▏                                         | 37639/100000 [07:54<14:35, 71.26it/s]
epoch 37500  training loss: 43840408911872.0
epoch 37500  clean testing loss: 27967965102080.0
epoch 37600  training loss: 2759229177856.0

 38%|█████████████████████████▎                                         | 37774/100000 [07:56<14:52, 69.69it/s]
epoch 37700  training loss: 78163354845184.0

 38%|█████████████████████████▍                                         | 37914/100000 [07:58<14:50, 69.71it/s]
epoch 37800  training loss: 2675050807296.0
epoch 37800  clean testing loss: 10881542914048.0
epoch 37900  training loss: 2638022705152.0

 38%|█████████████████████████▍                                         | 38058/100000 [08:00<14:32, 70.96it/s]
epoch 38000  training loss: 4279437623296.0
epoch 38000  clean testing loss: 12122076479488.0

 38%|█████████████████████████▌                                         | 38201/100000 [08:02<14:53, 69.19it/s]
epoch 38100  training loss: 2618682507264.0

 38%|█████████████████████████▋                                         | 38345/100000 [08:04<14:36, 70.32it/s]
epoch 38200  training loss: 2590340022272.0
epoch 38200  clean testing loss: 10708504805376.0
epoch 38300  training loss: 2570267394048.0

 38%|█████████████████████████▊                                         | 38489/100000 [08:06<14:30, 70.68it/s]
epoch 38400  training loss: 2607769452544.0

 39%|█████████████████████████▉                                         | 38625/100000 [08:08<14:21, 71.27it/s]
epoch 38500  training loss: 5355218665472.0
epoch 38500  clean testing loss: 11302171836416.0
epoch 38600  training loss: 2522277740544.0

 39%|█████████████████████████▉                                         | 38769/100000 [08:10<14:14, 71.64it/s]
epoch 38700  training loss: 2648561418240.0

 39%|██████████████████████████                                         | 38913/100000 [08:12<14:28, 70.37it/s]
epoch 38800  training loss: 4056389517312.0

 39%|██████████████████████████▏                                        | 39054/100000 [08:14<14:29, 70.13it/s]
epoch 38900  training loss: 14170088013824.0
epoch 38900  clean testing loss: 21425324818432.0
epoch 39000  training loss: 15739110031360.0
epoch 39000  clean testing loss: 18748297707520.0

 39%|██████████████████████████▎                                        | 39202/100000 [08:16<12:49, 79.00it/s]
epoch 39100  training loss: 2458326138880.0

 39%|██████████████████████████▎                                        | 39358/100000 [08:18<12:41, 79.67it/s]
epoch 39200  training loss: 2453712142336.0
epoch 39200  clean testing loss: 10838200025088.0
epoch 39300  training loss: 2454680764416.0

 40%|██████████████████████████▍                                        | 39524/100000 [08:20<12:33, 80.26it/s]
epoch 39400  training loss: 2419036782592.0

 40%|██████████████████████████▌                                        | 39681/100000 [08:22<12:40, 79.34it/s]
epoch 39500  training loss: 2598982909952.0
epoch 39500  clean testing loss: 10381487505408.0
epoch 39600  training loss: 2660086579200.0

 40%|██████████████████████████▋                                        | 39844/100000 [08:24<12:36, 79.52it/s]
epoch 39700  training loss: 2410764828672.0
epoch 39700  clean testing loss: 10494638292992.0
epoch 39800  training loss: 9428413710336.0

 40%|██████████████████████████▊                                        | 39998/100000 [08:26<12:36, 79.37it/s]
epoch 39900  training loss: 6671420620800.0

 40%|██████████████████████████▉                                        | 40155/100000 [08:28<12:32, 79.54it/s]
epoch 40000  training loss: 9709515964416.0
epoch 40000  clean testing loss: 16696954847232.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 40100  training loss: 7758081425408.0

 40%|███████████████████████████                                        | 40316/100000 [08:30<12:31, 79.46it/s]
epoch 40200  training loss: 11362016165888.0

 40%|███████████████████████████                                        | 40475/100000 [08:32<12:29, 79.44it/s]
epoch 40300  training loss: 15879439908864.0
epoch 40300  clean testing loss: 32225768767488.0
epoch 40400  training loss: 3268700536832.0

 41%|███████████████████████████▏                                       | 40640/100000 [08:34<12:14, 80.77it/s]
epoch 40500  training loss: 2287547973632.0
epoch 40500  clean testing loss: 10835096240128.0
epoch 40600  training loss: 22035103219712.0

 41%|███████████████████████████▎                                       | 40799/100000 [08:36<12:21, 79.84it/s]
epoch 40700  training loss: 2259214663680.0

 41%|███████████████████████████▍                                       | 40920/100000 [08:38<12:21, 79.72it/s]
epoch 40800  training loss: 72454403784704.0
epoch 40800  clean testing loss: 11062697000960.0
epoch 40900  training loss: 2233564659712.0

 41%|███████████████████████████▌                                       | 41082/100000 [08:40<12:23, 79.26it/s]
epoch 41000  training loss: 2218044948480.0
epoch 41000  clean testing loss: 10722944745472.0

 41%|███████████████████████████▋                                       | 41242/100000 [08:42<12:09, 80.51it/s]
epoch 41100  training loss: 9451493916672.0
epoch 41100  clean testing loss: 19579562622976.0
epoch 41200  training loss: 2260815577088.0

 41%|███████████████████████████▋                                       | 41403/100000 [08:44<12:09, 80.28it/s]
epoch 41300  training loss: 13402043842560.0
epoch 41300  clean testing loss: 29850576355328.0
epoch 41400  training loss: 8810556030976.0

 42%|███████████████████████████▊                                       | 41560/100000 [08:46<12:15, 79.47it/s]
epoch 41500  training loss: 2196188823552.0

 42%|███████████████████████████▉                                       | 41723/100000 [08:48<12:05, 80.36it/s]
epoch 41600  training loss: 3314612174848.0
epoch 41600  clean testing loss: 11228481060864.0
epoch 41700  training loss: 2169129926656.0

 42%|████████████████████████████                                       | 41885/100000 [08:50<12:07, 79.93it/s]
epoch 41800  training loss: 24295830978560.0

 42%|████████████████████████████▏                                      | 42045/100000 [08:52<12:05, 79.91it/s]
epoch 41900  training loss: 2129173282816.0
epoch 41900  clean testing loss: 10935738564608.0
epoch 42000  training loss: 3133556654080.0
epoch 42000  clean testing loss: 10721858420736.0

 42%|████████████████████████████▎                                      | 42207/100000 [08:54<12:10, 79.16it/s]
epoch 42100  training loss: 2098123898880.0
epoch 42100  clean testing loss: 10910430134272.0
epoch 42200  training loss: 2090986897408.0

 42%|████████████████████████████▍                                      | 42363/100000 [08:56<11:54, 80.64it/s]
epoch 42300  training loss: 2084001939456.0

 43%|████████████████████████████▍                                      | 42526/100000 [08:58<11:57, 80.13it/s]
epoch 42400  training loss: 2090072408064.0
epoch 42400  clean testing loss: 11028540686336.0
epoch 42500  training loss: 2152536080384.0

 43%|████████████████████████████▌                                      | 42685/100000 [09:00<11:56, 79.97it/s]
epoch 42600  training loss: 2155415732224.0

 43%|████████████████████████████▋                                      | 42842/100000 [09:02<11:58, 79.60it/s]
epoch 42700  training loss: 4204711641088.0
epoch 42700  clean testing loss: 15999602524160.0
epoch 42800  training loss: 2535254130688.0

 43%|████████████████████████████▊                                      | 43001/100000 [09:04<12:06, 78.42it/s]
epoch 42900  training loss: 3190400483328.0
epoch 42900  clean testing loss: 11551207587840.0
epoch 43000  training loss: 2293267955712.0
epoch 43000  clean testing loss: 10901436497920.0

 43%|████████████████████████████▉                                      | 43164/100000 [09:06<11:45, 80.56it/s]
epoch 43100  training loss: 2676572291072.0

 43%|█████████████████████████████                                      | 43329/100000 [09:08<11:50, 79.80it/s]
epoch 43200  training loss: 2404553850880.0
epoch 43200  clean testing loss: 11014463553536.0
epoch 43300  training loss: 1998350581760.0

 43%|█████████████████████████████▏                                     | 43482/100000 [09:10<11:49, 79.60it/s]
epoch 43400  training loss: 53159376453632.0

 44%|█████████████████████████████▏                                     | 43647/100000 [09:12<11:46, 79.78it/s]
epoch 43500  training loss: 1982019010560.0
epoch 43500  clean testing loss: 11129313034240.0
epoch 43600  training loss: 1972843708416.0

 44%|█████████████████████████████▎                                     | 43806/100000 [09:14<11:48, 79.34it/s]
epoch 43700  training loss: 1974072508416.0
epoch 43700  clean testing loss: 11160618270720.0
epoch 43800  training loss: 4100425252864.0

 44%|█████████████████████████████▍                                     | 43967/100000 [09:16<11:31, 81.08it/s]
epoch 43900  training loss: 1952685490176.0

 44%|█████████████████████████████▌                                     | 44129/100000 [09:18<11:34, 80.41it/s]
epoch 44000  training loss: 1959920533504.0
epoch 44000  clean testing loss: 11042546515968.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 44100  training loss: 2355965460480.0

 44%|█████████████████████████████▋                                     | 44291/100000 [09:20<11:40, 79.56it/s]
epoch 44200  training loss: 1947745255424.0

 44%|█████████████████████████████▊                                     | 44452/100000 [09:22<11:35, 79.92it/s]
epoch 44300  training loss: 1977992216576.0
epoch 44300  clean testing loss: 11617116880896.0
epoch 44400  training loss: 11876493688832.0

 45%|█████████████████████████████▉                                     | 44609/100000 [09:24<11:36, 79.47it/s]
epoch 44500  training loss: 6026210836480.0
epoch 44500  clean testing loss: 14634312531968.0
epoch 44600  training loss: 12424917811200.0

 45%|█████████████████████████████▉                                     | 44769/100000 [09:26<11:22, 80.92it/s]
epoch 44700  training loss: 1901025820672.0

 45%|██████████████████████████████                                     | 44931/100000 [09:28<11:21, 80.86it/s]
epoch 44800  training loss: 6167738712064.0
epoch 44800  clean testing loss: 15349439266816.0
epoch 44900  training loss: 1863397146624.0

 45%|██████████████████████████████▏                                    | 45091/100000 [09:30<11:22, 80.43it/s]
epoch 45000  training loss: 6121216540672.0
epoch 45000  clean testing loss: 13464706744320.0

 45%|██████████████████████████████▎                                    | 45253/100000 [09:32<11:20, 80.46it/s]
epoch 45100  training loss: 1850466369536.0
epoch 45100  clean testing loss: 11271319584768.0
epoch 45200  training loss: 1834011197440.0

 45%|██████████████████████████████▍                                    | 45415/100000 [09:34<11:19, 80.32it/s]
epoch 45300  training loss: 1832947154944.0
epoch 45300  clean testing loss: 11386423869440.0
epoch 45400  training loss: 1825683668992.0

 46%|██████████████████████████████▌                                    | 45574/100000 [09:36<11:21, 79.84it/s]
epoch 45500  training loss: 1988667375616.0

 46%|██████████████████████████████▋                                    | 45739/100000 [09:38<11:17, 80.13it/s]
epoch 45600  training loss: 2041005080576.0
epoch 45600  clean testing loss: 12117162852352.0
epoch 45700  training loss: 1811431030784.0

 46%|██████████████████████████████▊                                    | 45900/100000 [09:40<11:21, 79.37it/s]
epoch 45800  training loss: 3615776309248.0
epoch 45800  clean testing loss: 12386711896064.0
epoch 45900  training loss: 1775018049536.0

 46%|██████████████████████████████▊                                    | 46061/100000 [09:42<11:10, 80.48it/s]
epoch 46000  training loss: 179865881935872.0
epoch 46000  clean testing loss: 352083299532800.0

 46%|██████████████████████████████▉                                    | 46218/100000 [09:44<11:13, 79.90it/s]
epoch 46100  training loss: 1775555706880.0
epoch 46100  clean testing loss: 11482227015680.0
epoch 46200  training loss: 1762433695744.0

 46%|███████████████████████████████                                    | 46378/100000 [09:46<11:06, 80.43it/s]
epoch 46300  training loss: 1772757712896.0

 47%|███████████████████████████████▏                                   | 46541/100000 [09:48<11:08, 80.03it/s]
epoch 46400  training loss: 1771667980288.0
epoch 46400  clean testing loss: 11518624137216.0
epoch 46500  training loss: 1790229217280.0

 47%|███████████████████████████████▎                                   | 46700/100000 [09:50<11:05, 80.13it/s]
epoch 46600  training loss: 67865059262464.0
epoch 46600  clean testing loss: 95684313219072.0
epoch 46700  training loss: 1775879454720.0

 47%|███████████████████████████████▍                                   | 46855/100000 [09:52<10:59, 80.64it/s]
epoch 46800  training loss: 1747679969280.0

 47%|███████████████████████████████▌                                   | 47017/100000 [09:54<11:07, 79.35it/s]
epoch 46900  training loss: 1734081380352.0
epoch 46900  clean testing loss: 11649905852416.0
epoch 47000  training loss: 54551302373376.0
epoch 47000  clean testing loss: 64235518296064.0

 47%|███████████████████████████████▌                                   | 47183/100000 [09:56<11:00, 80.02it/s]
epoch 47100  training loss: 1739190960128.0

 47%|███████████████████████████████▋                                   | 47343/100000 [09:58<10:56, 80.19it/s]
epoch 47200  training loss: 1730449506304.0
epoch 47200  clean testing loss: 11742123917312.0
epoch 47300  training loss: 1723952791552.0

 48%|███████████████████████████████▊                                   | 47503/100000 [10:00<10:58, 79.71it/s]
epoch 47400  training loss: 1718203842560.0
epoch 47400  clean testing loss: 11730726944768.0
epoch 47500  training loss: 1719487299584.0

 48%|███████████████████████████████▉                                   | 47664/100000 [10:02<10:54, 79.92it/s]
epoch 47600  training loss: 1734778028032.0

 48%|████████████████████████████████                                   | 47824/100000 [10:04<10:44, 80.93it/s]
epoch 47700  training loss: 1710368227328.0
epoch 47700  clean testing loss: 11760210804736.0
epoch 47800  training loss: 1757406167040.0

 48%|████████████████████████████████▏                                  | 47986/100000 [10:06<10:50, 80.00it/s]
epoch 47900  training loss: 3745602076672.0

 48%|████████████████████████████████▎                                  | 48150/100000 [10:08<10:48, 79.97it/s]
epoch 48000  training loss: 4942874542080.0
epoch 48000  clean testing loss: 12406665248768.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 48100  training loss: 1696832421888.0

 48%|████████████████████████████████▎                                  | 48311/100000 [10:10<10:40, 80.70it/s]
epoch 48200  training loss: 1683696386048.0
epoch 48200  clean testing loss: 11996699295744.0
epoch 48300  training loss: 1680391667712.0

 48%|████████████████████████████████▍                                  | 48470/100000 [10:12<10:47, 79.58it/s]
epoch 48400  training loss: 1670897860608.0

 49%|████████████████████████████████▌                                  | 48628/100000 [10:14<10:43, 79.77it/s]
epoch 48500  training loss: 1897292890112.0
epoch 48500  clean testing loss: 11930798391296.0
epoch 48600  training loss: 1688210505728.0

 49%|████████████████████████████████▋                                  | 48793/100000 [10:16<10:31, 81.08it/s]
epoch 48700  training loss: 1657528909824.0

 49%|████████████████████████████████▊                                  | 48954/100000 [10:18<10:32, 80.74it/s]
epoch 48800  training loss: 1664933560320.0
epoch 48800  clean testing loss: 12602408173568.0
epoch 48900  training loss: 1643151360000.0

 49%|████████████████████████████████▉                                  | 49107/100000 [10:20<10:37, 79.79it/s]
epoch 49000  training loss: 1812873347072.0
epoch 49000  clean testing loss: 13149521575936.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 49100  training loss: 1637854740480.0

 49%|█████████████████████████████████                                  | 49268/100000 [10:22<10:27, 80.90it/s]
epoch 49200  training loss: 1638586646528.0

 49%|█████████████████████████████████                                  | 49435/100000 [10:24<10:31, 80.01it/s]
epoch 49300  training loss: 1742890205184.0
epoch 49300  clean testing loss: 12248969904128.0
epoch 49400  training loss: 1695989760000.0

 50%|█████████████████████████████████▏                                 | 49591/100000 [10:26<10:34, 79.40it/s]
epoch 49500  training loss: 1651886915584.0

 50%|█████████████████████████████████▎                                 | 49749/100000 [10:28<10:28, 79.90it/s]
epoch 49600  training loss: 1621853863936.0
epoch 49600  clean testing loss: 12522647191552.0
epoch 49700  training loss: 2647744315392.0

 50%|█████████████████████████████████▍                                 | 49912/100000 [10:30<10:27, 79.84it/s]
epoch 49800  training loss: 1607599390720.0
epoch 49800  clean testing loss: 12371737182208.0
epoch 49900  training loss: 1999910731776.0

 50%|█████████████████████████████████▌                                 | 50074/100000 [10:32<10:31, 79.09it/s]
epoch 50000  training loss: 1592722980864.0
epoch 50000  clean testing loss: 12492395773952.0

 50%|█████████████████████████████████▋                                 | 50228/100000 [10:34<10:22, 79.91it/s]
epoch 50100  training loss: 4403871350784.0
epoch 50100  clean testing loss: 13620690812928.0
epoch 50200  training loss: 1623882596352.0

 50%|█████████████████████████████████▊                                 | 50393/100000 [10:36<10:25, 79.35it/s]
epoch 50300  training loss: 1588302839808.0

 51%|█████████████████████████████████▊                                 | 50554/100000 [10:38<10:16, 80.25it/s]
epoch 50400  training loss: 1731872686080.0
epoch 50400  clean testing loss: 15856352362496.0
epoch 50500  training loss: 1634691448832.0

 51%|█████████████████████████████████▉                                 | 50716/100000 [10:40<10:12, 80.50it/s]
epoch 50600  training loss: 1685386297344.0
epoch 50600  clean testing loss: 12389979258880.0
epoch 50700  training loss: 1669998313472.0

 51%|██████████████████████████████████                                 | 50878/100000 [10:42<10:10, 80.42it/s]
epoch 50800  training loss: 2358637232128.0

 51%|██████████████████████████████████▏                                | 51040/100000 [10:44<10:10, 80.25it/s]
epoch 50900  training loss: 1566524964864.0
epoch 50900  clean testing loss: 12575295143936.0
epoch 51000  training loss: 1699633823744.0
epoch 51000  clean testing loss: 12872591605760.0

 51%|██████████████████████████████████▎                                | 51200/100000 [10:46<10:18, 78.89it/s]
epoch 51100  training loss: 1544574730240.0

 51%|██████████████████████████████████▍                                | 51358/100000 [10:48<10:08, 79.95it/s]
epoch 51200  training loss: 1540603510784.0
epoch 51200  clean testing loss: 12724144701440.0
epoch 51300  training loss: 1539064332288.0

 52%|██████████████████████████████████▌                                | 51521/100000 [10:50<10:07, 79.75it/s]
epoch 51400  training loss: 1533273440256.0
epoch 51400  clean testing loss: 12690192859136.0
epoch 51500  training loss: 1542030229504.0

 52%|██████████████████████████████████▋                                | 51680/100000 [10:52<09:59, 80.58it/s]
epoch 51600  training loss: 1672543600640.0

 52%|██████████████████████████████████▋                                | 51842/100000 [10:54<09:53, 81.12it/s]
epoch 51700  training loss: 1830731644928.0
epoch 51700  clean testing loss: 12609878228992.0
epoch 51800  training loss: 7944888385536.0

 52%|██████████████████████████████████▊                                | 52003/100000 [10:56<10:13, 78.25it/s]
epoch 51900  training loss: 1526787080192.0

 52%|██████████████████████████████████▉                                | 52159/100000 [10:58<09:59, 79.77it/s]
epoch 52000  training loss: 1684747583488.0
epoch 52000  clean testing loss: 13410086420480.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 52100  training loss: 1566697848832.0

 52%|███████████████████████████████████                                | 52324/100000 [11:00<09:56, 79.95it/s]
epoch 52200  training loss: 1527351214080.0
epoch 52200  clean testing loss: 12727987732480.0
epoch 52300  training loss: 1631498665984.0

 52%|███████████████████████████████████▏                               | 52481/100000 [11:02<09:55, 79.81it/s]
epoch 52400  training loss: 1501299998720.0

 53%|███████████████████████████████████▎                               | 52641/100000 [11:04<09:57, 79.24it/s]
epoch 52500  training loss: 1704926511104.0
epoch 52500  clean testing loss: 13482377347072.0
epoch 52600  training loss: 1558236889088.0

 53%|███████████████████████████████████▍                               | 52806/100000 [11:06<09:52, 79.68it/s]
epoch 52700  training loss: 1589758656512.0

 53%|███████████████████████████████████▍                               | 52960/100000 [11:08<09:45, 80.30it/s]
epoch 52800  training loss: 1524798586880.0
epoch 52800  clean testing loss: 12866549710848.0
epoch 52900  training loss: 1485379338240.0

 53%|███████████████████████████████████▌                               | 53121/100000 [11:10<09:46, 79.96it/s]
epoch 53000  training loss: 1488533454848.0
epoch 53000  clean testing loss: 12939058741248.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 53100  training loss: 1531827847168.0

 53%|███████████████████████████████████▋                               | 53279/100000 [11:12<09:47, 79.52it/s]
epoch 53200  training loss: 1494153691136.0

 53%|███████████████████████████████████▊                               | 53438/100000 [11:14<09:42, 79.95it/s]
epoch 53300  training loss: 1477289836544.0
epoch 53300  clean testing loss: 13005022560256.0
epoch 53400  training loss: 28385847803904.0

 54%|███████████████████████████████████▉                               | 53608/100000 [11:16<09:35, 80.67it/s]
epoch 53500  training loss: 1468607758336.0

 54%|████████████████████████████████████                               | 53761/100000 [11:18<09:32, 80.72it/s]
epoch 53600  training loss: 1577391095808.0
epoch 53600  clean testing loss: 13442168651776.0
epoch 53700  training loss: 1458970427392.0

 54%|████████████████████████████████████▏                              | 53923/100000 [11:20<09:34, 80.21it/s]
epoch 53800  training loss: 1449309372416.0
epoch 53800  clean testing loss: 13087259230208.0
epoch 53900  training loss: 7636103200768.0

 54%|████████████████████████████████████▏                              | 54085/100000 [11:22<09:30, 80.44it/s]
epoch 54000  training loss: 2580817117184.0
epoch 54000  clean testing loss: 14025960194048.0

 54%|████████████████████████████████████▎                              | 54247/100000 [11:24<09:28, 80.50it/s]
epoch 54100  training loss: 1441012645888.0
epoch 54100  clean testing loss: 13037473890304.0
epoch 54200  training loss: 1436956491776.0

 54%|████████████████████████████████████▍                              | 54409/100000 [11:26<09:28, 80.21it/s]
epoch 54300  training loss: 1445797167104.0

 55%|████████████████████████████████████▌                              | 54568/100000 [11:28<09:26, 80.14it/s]
epoch 54400  training loss: 1437120462848.0
epoch 54400  clean testing loss: 13137829953536.0
epoch 54500  training loss: 7626520788992.0

 55%|████████████████████████████████████▋                              | 54726/100000 [11:30<09:23, 80.30it/s]
epoch 54600  training loss: 1435309441024.0
epoch 54600  clean testing loss: 13337237651456.0
epoch 54700  training loss: 1596603629568.0

 55%|████████████████████████████████████▊                              | 54895/100000 [11:32<09:18, 80.81it/s]
epoch 54800  training loss: 1697068613632.0

 55%|████████████████████████████████████▉                              | 55053/100000 [11:34<09:28, 79.13it/s]
epoch 54900  training loss: 1441512685568.0
epoch 54900  clean testing loss: 13240622907392.0
epoch 55000  training loss: 1434861699072.0
epoch 55000  clean testing loss: 13315975675904.0

 55%|████████████████████████████████████▉                              | 55212/100000 [11:36<09:21, 79.73it/s]
epoch 55100  training loss: 1424131489792.0

 55%|█████████████████████████████████████                              | 55374/100000 [11:38<09:11, 80.85it/s]
epoch 55200  training loss: 1414156910592.0
epoch 55200  clean testing loss: 13269362278400.0
epoch 55300  training loss: 1415994933248.0

 56%|█████████████████████████████████████▏                             | 55536/100000 [11:40<09:15, 80.08it/s]
epoch 55400  training loss: 1411327066112.0
epoch 55400  clean testing loss: 13183641190400.0
epoch 55500  training loss: 1402046119936.0

 56%|█████████████████████████████████████▎                             | 55696/100000 [11:42<09:11, 80.38it/s]
epoch 55600  training loss: 1510926712832.0

 56%|█████████████████████████████████████▍                             | 55858/100000 [11:44<09:04, 81.04it/s]
epoch 55700  training loss: 1398324330496.0
epoch 55700  clean testing loss: 13378424668160.0
epoch 55800  training loss: 1396559708160.0

 56%|█████████████████████████████████████▌                             | 56016/100000 [11:46<09:13, 79.47it/s]
epoch 55900  training loss: 1398027583488.0
epoch 55900  clean testing loss: 13331624624128.0
epoch 56000  training loss: 1400555438080.0
epoch 56000  clean testing loss: 13273702334464.0

 56%|█████████████████████████████████████▋                             | 56178/100000 [11:48<09:03, 80.67it/s]
epoch 56100  training loss: 1391984902144.0

 56%|█████████████████████████████████████▋                             | 56340/100000 [11:50<09:04, 80.19it/s]
epoch 56200  training loss: 1388356435968.0
epoch 56200  clean testing loss: 13423548039168.0
epoch 56300  training loss: 1388621332480.0

 57%|█████████████████████████████████████▊                             | 56507/100000 [11:52<09:06, 79.56it/s]
epoch 56400  training loss: 1385544286208.0

 57%|█████████████████████████████████████▉                             | 56662/100000 [11:54<09:04, 79.63it/s]
epoch 56500  training loss: 1398160359424.0
epoch 56500  clean testing loss: 13548355846144.0
epoch 56600  training loss: 1376761806848.0

 57%|██████████████████████████████████████                             | 56824/100000 [11:56<08:59, 80.09it/s]
epoch 56700  training loss: 11113245704192.0
epoch 56700  clean testing loss: 19227010400256.0
epoch 56800  training loss: 1368961187840.0

 57%|██████████████████████████████████████▏                            | 56986/100000 [11:58<08:54, 80.55it/s]
epoch 56900  training loss: 1368277647360.0

 57%|██████████████████████████████████████▎                            | 57148/100000 [12:00<08:53, 80.39it/s]
epoch 57000  training loss: 1371493761024.0
epoch 57000  clean testing loss: 13504710967296.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 57100  training loss: 1375424610304.0

 57%|██████████████████████████████████████▍                            | 57306/100000 [12:02<08:53, 80.08it/s]
epoch 57200  training loss: 1364368424960.0

 57%|██████████████████████████████████████▌                            | 57465/100000 [12:04<08:53, 79.70it/s]
epoch 57300  training loss: 1355573231616.0
epoch 57300  clean testing loss: 13587701563392.0
epoch 57400  training loss: 1354389389312.0

 58%|██████████████████████████████████████▌                            | 57630/100000 [12:06<08:53, 79.39it/s]
epoch 57500  training loss: 1349566857216.0
epoch 57500  clean testing loss: 13552390766592.0
epoch 57600  training loss: 1472062291968.0

 58%|██████████████████████████████████████▋                            | 57784/100000 [12:08<08:50, 79.61it/s]
epoch 57700  training loss: 1355056545792.0

 58%|██████████████████████████████████████▊                            | 57945/100000 [12:10<08:50, 79.34it/s]
epoch 57800  training loss: 1354717069312.0
epoch 57800  clean testing loss: 13800466022400.0
epoch 57900  training loss: 1340673622016.0

 58%|██████████████████████████████████████▉                            | 58111/100000 [12:12<08:45, 79.77it/s]
epoch 58000  training loss: 1432672272384.0
epoch 58000  clean testing loss: 14094831714304.0

 58%|███████████████████████████████████████                            | 58267/100000 [12:14<08:40, 80.22it/s]
epoch 58100  training loss: 1368370970624.0
epoch 58100  clean testing loss: 13849195446272.0
epoch 58200  training loss: 1332140179456.0

 58%|███████████████████████████████████████▏                           | 58428/100000 [12:16<08:37, 80.41it/s]
epoch 58300  training loss: 1351585497088.0
epoch 58300  clean testing loss: 13817717194752.0
epoch 58400  training loss: 1378204123136.0

 59%|███████████████████████████████████████▎                           | 58590/100000 [12:18<08:31, 80.89it/s]
epoch 58500  training loss: 1409725235200.0

 59%|███████████████████████████████████████▎                           | 58752/100000 [12:20<08:29, 80.98it/s]
epoch 58600  training loss: 1326807777280.0
epoch 58600  clean testing loss: 13763578167296.0
epoch 58700  training loss: 1339692941312.0

 59%|███████████████████████████████████████▍                           | 58913/100000 [12:22<08:32, 80.19it/s]
epoch 58800  training loss: 1313172881408.0

 59%|███████████████████████████████████████▌                           | 59076/100000 [12:24<08:31, 80.00it/s]
epoch 58900  training loss: 2524450652160.0
epoch 58900  clean testing loss: 15007098077184.0
epoch 59000  training loss: 1563235319808.0
epoch 59000  clean testing loss: 14587946598400.0

 59%|███████████████████████████████████████▋                           | 59238/100000 [12:26<08:29, 80.07it/s]
epoch 59100  training loss: 1320773615616.0
epoch 59100  clean testing loss: 13720286658560.0
epoch 59200  training loss: 1373027041280.0

 59%|███████████████████████████████████████▊                           | 59399/100000 [12:28<08:26, 80.15it/s]
epoch 59300  training loss: 1519380987904.0

 60%|███████████████████████████████████████▉                           | 59556/100000 [12:30<08:22, 80.56it/s]
epoch 59400  training loss: 7797255176192.0
epoch 59400  clean testing loss: 23889014947840.0
epoch 59500  training loss: 1290945298432.0

 60%|████████████████████████████████████████                           | 59722/100000 [12:32<08:18, 80.75it/s]
epoch 59600  training loss: 1345467318272.0

 60%|████████████████████████████████████████                           | 59878/100000 [12:34<08:21, 79.93it/s]
epoch 59700  training loss: 1293423345664.0
epoch 59700  clean testing loss: 13923213377536.0
epoch 59800  training loss: 5580945620992.0

 60%|████████████████████████████████████████▏                          | 60037/100000 [12:36<08:18, 80.21it/s]
epoch 59900  training loss: 1296069558272.0
epoch 59900  clean testing loss: 13963150491648.0
epoch 60000  training loss: 1297472159744.0
epoch 60000  clean testing loss: 14000880353280.0

 60%|████████████████████████████████████████▎                          | 60197/100000 [12:38<08:17, 80.01it/s]
epoch 60100  training loss: 1292769689600.0

 60%|████████████████████████████████████████▍                          | 60363/100000 [12:40<08:15, 79.94it/s]
epoch 60200  training loss: 1294758969344.0
epoch 60200  clean testing loss: 13907952402432.0
epoch 60300  training loss: 1287516585984.0

 61%|████████████████████████████████████████▌                          | 60517/100000 [12:42<08:15, 79.74it/s]
epoch 60400  training loss: 1281415315456.0

 61%|████████████████████████████████████████▋                          | 60683/100000 [12:44<08:10, 80.14it/s]
epoch 60500  training loss: 1278588223488.0
epoch 60500  clean testing loss: 13974620864512.0
epoch 60600  training loss: 1277657743360.0

 61%|████████████████████████████████████████▊                          | 60839/100000 [12:46<08:10, 79.78it/s]
epoch 60700  training loss: 1275723513856.0
epoch 60700  clean testing loss: 14110224809984.0
epoch 60800  training loss: 1275990769664.0

 61%|████████████████████████████████████████▊                          | 60997/100000 [12:48<08:10, 79.55it/s]
epoch 60900  training loss: 1293458866176.0

 61%|████████████████████████████████████████▉                          | 61159/100000 [12:50<08:00, 80.85it/s]
epoch 61000  training loss: 1258326589440.0
epoch 61000  clean testing loss: 14021131501568.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 61100  training loss: 1463568039936.0

 61%|█████████████████████████████████████████                          | 61321/100000 [12:52<08:08, 79.23it/s]
epoch 61200  training loss: 1470049812480.0

 61%|█████████████████████████████████████████▏                         | 61477/100000 [12:54<08:04, 79.45it/s]
epoch 61300  training loss: 1376574111744.0
epoch 61300  clean testing loss: 14106570522624.0
epoch 61400  training loss: 1293393068032.0

 62%|█████████████████████████████████████████▎                         | 61601/100000 [12:56<08:00, 79.84it/s]
epoch 61500  training loss: 1382616399872.0
epoch 61500  clean testing loss: 14539451006976.0
epoch 61600  training loss: 1313850916864.0

 62%|█████████████████████████████████████████▍                         | 61756/100000 [12:58<07:56, 80.29it/s]
epoch 61700  training loss: 2792519368704.0

 62%|█████████████████████████████████████████▍                         | 61916/100000 [13:00<07:55, 80.08it/s]
epoch 61800  training loss: 1265889837056.0
epoch 61800  clean testing loss: 14109779165184.0
epoch 61900  training loss: 1237672132608.0

 62%|█████████████████████████████████████████▌                         | 62086/100000 [13:02<07:50, 80.54it/s]
epoch 62000  training loss: 1243022360576.0
epoch 62000  clean testing loss: 15419989557248.0

 62%|█████████████████████████████████████████▋                         | 62238/100000 [13:04<07:53, 79.83it/s]
epoch 62100  training loss: 1240708939776.0
epoch 62100  clean testing loss: 14269253943296.0
epoch 62200  training loss: 1237946859520.0

 62%|█████████████████████████████████████████▊                         | 62404/100000 [13:06<07:54, 79.27it/s]
epoch 62300  training loss: 1232366338048.0
epoch 62300  clean testing loss: 14233817317376.0
epoch 62400  training loss: 1227392024576.0

 63%|█████████████████████████████████████████▉                         | 62564/100000 [13:08<07:44, 80.60it/s]
epoch 62500  training loss: 1233659625472.0

 63%|██████████████████████████████████████████                         | 62726/100000 [13:10<07:43, 80.42it/s]
epoch 62600  training loss: 1233633411072.0
epoch 62600  clean testing loss: 14311812497408.0
epoch 62700  training loss: 1303693361152.0

 63%|██████████████████████████████████████████▏                        | 62888/100000 [13:12<07:44, 79.98it/s]
epoch 62800  training loss: 1232807395328.0

 63%|██████████████████████████████████████████▏                        | 63050/100000 [13:14<07:42, 79.86it/s]
epoch 62900  training loss: 1271611916288.0
epoch 62900  clean testing loss: 14514929008640.0
epoch 63000  training loss: 1398571270144.0
epoch 63000  clean testing loss: 14228609040384.0

 63%|██████████████████████████████████████████▎                        | 63212/100000 [13:16<07:31, 81.42it/s]
epoch 63100  training loss: 1201529552896.0
epoch 63100  clean testing loss: 14220276006912.0
epoch 63200  training loss: 1202015830016.0

 63%|██████████████████████████████████████████▍                        | 63373/100000 [13:18<07:34, 80.59it/s]
epoch 63300  training loss: 1199795208192.0

 64%|██████████████████████████████████████████▌                        | 63534/100000 [13:20<07:36, 79.83it/s]
epoch 63400  training loss: 1200825434112.0
epoch 63400  clean testing loss: 14224769155072.0
epoch 63500  training loss: 1646196424704.0

 64%|██████████████████████████████████████████▋                        | 63689/100000 [13:22<07:34, 79.95it/s]
epoch 63600  training loss: 1324781404160.0
epoch 63600  clean testing loss: 14637760249856.0
epoch 63700  training loss: 1214760747008.0

 64%|██████████████████████████████████████████▊                        | 63849/100000 [13:24<07:31, 80.02it/s]
epoch 63800  training loss: 1193175547904.0

 64%|██████████████████████████████████████████▉                        | 64011/100000 [13:26<07:39, 78.28it/s]
epoch 63900  training loss: 1469243719680.0
epoch 63900  clean testing loss: 14359191355392.0
epoch 64000  training loss: 1451198906368.0
epoch 64000  clean testing loss: 14512675618816.0

 64%|██████████████████████████████████████████▉                        | 64175/100000 [13:28<07:30, 79.45it/s]
epoch 64100  training loss: 1189873057792.0

 64%|███████████████████████████████████████████                        | 64335/100000 [13:30<07:26, 79.83it/s]
epoch 64200  training loss: 1182792810496.0
epoch 64200  clean testing loss: 14382556774400.0
epoch 64300  training loss: 1190113968128.0

 64%|███████████████████████████████████████████▏                       | 64493/100000 [13:32<07:22, 80.26it/s]
epoch 64400  training loss: 1181412098048.0
epoch 64400  clean testing loss: 14471650082816.0
epoch 64500  training loss: 1173379481600.0

 65%|███████████████████████████████████████████▎                       | 64655/100000 [13:34<07:22, 79.82it/s]
epoch 64600  training loss: 1191245774848.0

 65%|███████████████████████████████████████████▍                       | 64811/100000 [13:36<07:21, 79.78it/s]
epoch 64700  training loss: 1166015987712.0
epoch 64700  clean testing loss: 14344972664832.0
epoch 64800  training loss: 1160672837632.0

 65%|███████████████████████████████████████████▌                       | 64972/100000 [13:38<07:20, 79.50it/s]
epoch 64900  training loss: 1923472949248.0

 65%|███████████████████████████████████████████▋                       | 65130/100000 [13:40<07:13, 80.51it/s]
epoch 65000  training loss: 1157707857920.0
epoch 65000  clean testing loss: 14346389291008.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 65100  training loss: 1152174260224.0

 65%|███████████████████████████████████████████▋                       | 65296/100000 [13:42<07:15, 79.69it/s]
epoch 65200  training loss: 1159431847936.0
epoch 65200  clean testing loss: 14367111249920.0
epoch 65300  training loss: 1156608163840.0

 65%|███████████████████████████████████████████▊                       | 65455/100000 [13:44<07:09, 80.41it/s]
epoch 65400  training loss: 1155790667776.0

 66%|███████████████████████████████████████████▉                       | 65616/100000 [13:46<07:03, 81.17it/s]
epoch 65500  training loss: 1156130013184.0
epoch 65500  clean testing loss: 14395830697984.0
epoch 65600  training loss: 1157752946688.0

 66%|████████████████████████████████████████████                       | 65773/100000 [13:48<07:09, 79.64it/s]
epoch 65700  training loss: 1143368974336.0

 66%|████████████████████████████████████████████▏                      | 65935/100000 [13:50<06:57, 81.65it/s]
epoch 65800  training loss: 1142123921408.0
epoch 65800  clean testing loss: 14428779053056.0
epoch 65900  training loss: 1251876667392.0

 66%|████████████████████████████████████████████▎                      | 66097/100000 [13:52<07:01, 80.35it/s]
epoch 66000  training loss: 1144766332928.0
epoch 66000  clean testing loss: 14437897469952.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 66100  training loss: 1128024244224.0

 66%|████████████████████████████████████████████▍                      | 66257/100000 [13:54<07:00, 80.29it/s]
epoch 66200  training loss: 1126724141056.0

 66%|████████████████████████████████████████████▌                      | 66419/100000 [13:56<06:56, 80.70it/s]
epoch 66300  training loss: 1130947674112.0
epoch 66300  clean testing loss: 14395709063168.0
epoch 66400  training loss: 1169301176320.0

 67%|████████████████████████████████████████████▌                      | 66583/100000 [13:58<06:58, 79.93it/s]
epoch 66500  training loss: 1176505679872.0

 67%|████████████████████████████████████████████▋                      | 66741/100000 [14:00<06:55, 80.02it/s]
epoch 66600  training loss: 1124855578624.0
epoch 66600  clean testing loss: 14421533392896.0
epoch 66700  training loss: 1121507606528.0

 67%|████████████████████████████████████████████▊                      | 66903/100000 [14:02<06:57, 79.34it/s]
epoch 66800  training loss: 1122439135232.0
epoch 66800  clean testing loss: 14500348559360.0
epoch 66900  training loss: 1119158796288.0

 67%|████████████████████████████████████████████▉                      | 67063/100000 [14:04<06:53, 79.69it/s]
epoch 67000  training loss: 1127611498496.0
epoch 67000  clean testing loss: 14601167044608.0

 67%|█████████████████████████████████████████████                      | 67226/100000 [14:06<06:50, 79.90it/s]
epoch 67100  training loss: 1115325333504.0
epoch 67100  clean testing loss: 14473373941760.0
epoch 67200  training loss: 1124210180096.0

 67%|█████████████████████████████████████████████▏                     | 67387/100000 [14:08<06:45, 80.48it/s]
epoch 67300  training loss: 1108752203776.0

 68%|█████████████████████████████████████████████▎                     | 67549/100000 [14:10<06:40, 81.11it/s]
epoch 67400  training loss: 1108473544704.0
epoch 67400  clean testing loss: 14530256044032.0
epoch 67500  training loss: 1161630842880.0

 68%|█████████████████████████████████████████████▎                     | 67710/100000 [14:12<06:42, 80.20it/s]
epoch 67600  training loss: 1216298090496.0
epoch 67600  clean testing loss: 14464834338816.0
epoch 67700  training loss: 1136115449856.0

 68%|█████████████████████████████████████████████▍                     | 67863/100000 [14:14<06:41, 80.08it/s]
epoch 67800  training loss: 1094920765440.0

 68%|█████████████████████████████████████████████▌                     | 68030/100000 [14:16<06:39, 80.06it/s]
epoch 67900  training loss: 1279297847296.0
epoch 67900  clean testing loss: 14572321767424.0
epoch 68000  training loss: 1100071174144.0
epoch 68000  clean testing loss: 14513880432640.0

 68%|█████████████████████████████████████████████▋                     | 68192/100000 [14:18<06:32, 81.01it/s]
epoch 68100  training loss: 1101714292736.0

 68%|█████████████████████████████████████████████▊                     | 68354/100000 [14:20<06:34, 80.21it/s]
epoch 68200  training loss: 1094542688256.0
epoch 68200  clean testing loss: 14489884819456.0
epoch 68300  training loss: 1093760057344.0

 69%|█████████████████████████████████████████████▉                     | 68512/100000 [14:22<06:31, 80.46it/s]
epoch 68400  training loss: 3903872040960.0
epoch 68400  clean testing loss: 16258047148032.0
epoch 68500  training loss: 1090918612992.0

 69%|██████████████████████████████████████████████                     | 68674/100000 [14:24<06:29, 80.36it/s]
epoch 68600  training loss: 1086518853632.0

 69%|██████████████████████████████████████████████                     | 68834/100000 [14:26<06:30, 79.81it/s]
epoch 68700  training loss: 1086337515520.0
epoch 68700  clean testing loss: 14590159093760.0
epoch 68800  training loss: 1088831291392.0

 69%|██████████████████████████████████████████████▏                    | 68991/100000 [14:28<06:25, 80.38it/s]
epoch 68900  training loss: 1084007710720.0

 69%|██████████████████████████████████████████████▎                    | 69158/100000 [14:30<06:23, 80.35it/s]
epoch 69000  training loss: 1081557319680.0
epoch 69000  clean testing loss: 14640981475328.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 69100  training loss: 1084083339264.0

 69%|██████████████████████████████████████████████▍                    | 69315/100000 [14:32<06:26, 79.33it/s]
epoch 69200  training loss: 1076671741952.0
epoch 69200  clean testing loss: 14684171272192.0
epoch 69300  training loss: 1077062795264.0

 69%|██████████████████████████████████████████████▌                    | 69473/100000 [14:34<06:22, 79.86it/s]
epoch 69400  training loss: 1078130311168.0

 70%|██████████████████████████████████████████████▋                    | 69632/100000 [14:36<06:18, 80.17it/s]
epoch 69500  training loss: 1077229256704.0
epoch 69500  clean testing loss: 14648950652928.0
epoch 69600  training loss: 2272347291648.0

 70%|██████████████████████████████████████████████▊                    | 69792/100000 [14:38<06:17, 79.98it/s]
epoch 69700  training loss: 1068937379840.0

 70%|██████████████████████████████████████████████▊                    | 69951/100000 [14:40<06:12, 80.75it/s]
epoch 69800  training loss: 1073729110016.0
epoch 69800  clean testing loss: 14677314633728.0
epoch 69900  training loss: 1066046914560.0

 70%|██████████████████████████████████████████████▉                    | 70113/100000 [14:42<06:14, 79.86it/s]
epoch 70000  training loss: 1071443542016.0
epoch 70000  clean testing loss: 14720004259840.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 70100  training loss: 1082744373248.0

 70%|███████████████████████████████████████████████                    | 70277/100000 [14:44<06:15, 79.12it/s]
epoch 70200  training loss: 1062186254336.0

 70%|███████████████████████████████████████████████▏                   | 70436/100000 [14:46<06:12, 79.43it/s]
epoch 70300  training loss: 1061690277888.0
epoch 70300  clean testing loss: 14604435456000.0
epoch 70400  training loss: 1062078316544.0

 71%|███████████████████████████████████████████████▎                   | 70593/100000 [14:48<06:11, 79.21it/s]
epoch 70500  training loss: 1063021182976.0

 71%|███████████████████████████████████████████████▍                   | 70752/100000 [14:50<06:04, 80.23it/s]
epoch 70600  training loss: 1063997341696.0
epoch 70600  clean testing loss: 14647385128960.0
epoch 70700  training loss: 1064466776064.0

 71%|███████████████████████████████████████████████▌                   | 70919/100000 [14:52<06:02, 80.22it/s]
epoch 70800  training loss: 1055316115456.0
epoch 70800  clean testing loss: 14738228510720.0
epoch 70900  training loss: 1100722470912.0

 71%|███████████████████████████████████████████████▌                   | 71075/100000 [14:54<06:04, 79.41it/s]
epoch 71000  training loss: 1101665927168.0
epoch 71000  clean testing loss: 14579935477760.0

 71%|███████████████████████████████████████████████▋                   | 71236/100000 [14:56<05:59, 79.90it/s]
epoch 71100  training loss: 1097439182848.0
epoch 71100  clean testing loss: 14733630504960.0
epoch 71200  training loss: 1075004375040.0

 71%|███████████████████████████████████████████████▊                   | 71395/100000 [14:58<05:55, 80.43it/s]
epoch 71300  training loss: 1055225085952.0

 72%|███████████████████████████████████████████████▉                   | 71562/100000 [15:00<05:53, 80.49it/s]
epoch 71400  training loss: 1108540522496.0
epoch 71400  clean testing loss: 14824424603648.0
epoch 71500  training loss: 1108018593792.0

 72%|████████████████████████████████████████████████                   | 71721/100000 [15:02<05:54, 79.72it/s]
epoch 71600  training loss: 1055358844928.0
epoch 71600  clean testing loss: 14681353748480.0
epoch 71700  training loss: 1051112636416.0

 72%|████████████████████████████████████████████████▏                  | 71877/100000 [15:04<05:49, 80.54it/s]
epoch 71800  training loss: 4258725888000.0

 72%|████████████████████████████████████████████████▎                  | 72039/100000 [15:06<05:47, 80.39it/s]
epoch 71900  training loss: 1045708341248.0
epoch 71900  clean testing loss: 14648026857472.0
epoch 72000  training loss: 1043895943168.0
epoch 72000  clean testing loss: 14657363378176.0

 72%|████████████████████████████████████████████████▎                  | 72201/100000 [15:08<05:47, 80.03it/s]
epoch 72100  training loss: 1043649527808.0

 72%|████████████████████████████████████████████████▍                  | 72362/100000 [15:10<05:43, 80.37it/s]
epoch 72200  training loss: 1044750925824.0
epoch 72200  clean testing loss: 14716051128320.0
epoch 72300  training loss: 1048248320000.0

 73%|████████████████████████████████████████████████▌                  | 72524/100000 [15:12<05:39, 81.00it/s]
epoch 72400  training loss: 1044070465536.0
epoch 72400  clean testing loss: 14712125259776.0
epoch 72500  training loss: 1042571984896.0

 73%|████████████████████████████████████████████████▋                  | 72686/100000 [15:14<05:37, 80.86it/s]
epoch 72600  training loss: 1045427650560.0

 73%|████████████████████████████████████████████████▊                  | 72850/100000 [15:16<05:39, 79.90it/s]
epoch 72700  training loss: 1044533739520.0
epoch 72700  clean testing loss: 14737968463872.0
epoch 72800  training loss: 1037794344960.0

 73%|████████████████████████████████████████████████▉                  | 73008/100000 [15:18<05:44, 78.25it/s]
epoch 72900  training loss: 1037370720256.0
epoch 72900  clean testing loss: 14749346562048.0
epoch 73000  training loss: 1034045685760.0

epoch 73000  clean testing loss: 14732523208704.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 73100  training loss: 1026618294272.0

 73%|█████████████████████████████████████████████████▏                 | 73331/100000 [15:22<05:31, 80.39it/s]
epoch 73200  training loss: 1046691184640.0
epoch 73200  clean testing loss: 14754081931264.0
epoch 73300  training loss: 1049385500672.0

 73%|█████████████████████████████████████████████████▏                 | 73492/100000 [15:24<05:27, 80.85it/s]
epoch 73400  training loss: 1030043140096.0

 74%|█████████████████████████████████████████████████▎                 | 73654/100000 [15:26<05:26, 80.64it/s]
epoch 73500  training loss: 1029717098496.0
epoch 73500  clean testing loss: 14727909474304.0
epoch 73600  training loss: 1025848705024.0

 74%|█████████████████████████████████████████████████▍                 | 73811/100000 [15:28<05:26, 80.12it/s]
epoch 73700  training loss: 1030831603712.0
epoch 73700  clean testing loss: 14788404969472.0
epoch 73800  training loss: 1078394028032.0

 74%|█████████████████████████████████████████████████▌                 | 73975/100000 [15:30<05:26, 79.75it/s]
epoch 73900  training loss: 1020211691520.0

 74%|█████████████████████████████████████████████████▋                 | 74130/100000 [15:32<05:22, 80.24it/s]
epoch 74000  training loss: 1035862278144.0
epoch 74000  clean testing loss: 14645501886464.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 74100  training loss: 1017679511552.0

 74%|█████████████████████████████████████████████████▊                 | 74289/100000 [15:34<05:22, 79.80it/s]
epoch 74200  training loss: 1016522801152.0

 74%|█████████████████████████████████████████████████▉                 | 74455/100000 [15:36<05:19, 80.05it/s]
epoch 74300  training loss: 1017910984704.0
epoch 74300  clean testing loss: 14704272474112.0
epoch 74400  training loss: 1019424866304.0

 75%|█████████████████████████████████████████████████▉                 | 74612/100000 [15:38<05:15, 80.57it/s]
epoch 74500  training loss: 1011971653632.0
epoch 74500  clean testing loss: 14792386412544.0
epoch 74600  training loss: 1092720132096.0

 75%|██████████████████████████████████████████████████                 | 74773/100000 [15:40<05:11, 81.05it/s]
epoch 74700  training loss: 1006754988032.0

 75%|██████████████████████████████████████████████████▏                | 74935/100000 [15:42<05:14, 79.80it/s]
epoch 74800  training loss: 1006074003456.0
epoch 74800  clean testing loss: 14726223364096.0
epoch 74900  training loss: 1094083346432.0

 75%|██████████████████████████████████████████████████▎                | 75093/100000 [15:44<05:11, 79.89it/s]
epoch 75000  training loss: 1004693553152.0
epoch 75000  clean testing loss: 14724200660992.0

 75%|██████████████████████████████████████████████████▍                | 75258/100000 [15:46<05:07, 80.49it/s]
epoch 75100  training loss: 1021738680320.0
epoch 75100  clean testing loss: 14726250627072.0
epoch 75200  training loss: 1008186032128.0

 75%|██████████████████████████████████████████████████▌                | 75416/100000 [15:48<05:09, 79.55it/s]
epoch 75300  training loss: 1024995622912.0
epoch 75300  clean testing loss: 14680685805568.0
epoch 75400  training loss: 1009392025600.0

 76%|██████████████████████████████████████████████████▋                | 75575/100000 [15:50<05:04, 80.34it/s]
epoch 75500  training loss: 1003354849280.0

 76%|██████████████████████████████████████████████████▋                | 75742/100000 [15:52<05:08, 78.75it/s]
epoch 75600  training loss: 1002665934848.0
epoch 75600  clean testing loss: 14687246745600.0
epoch 75700  training loss: 1008816881664.0

 76%|██████████████████████████████████████████████████▊                | 75903/100000 [15:55<04:59, 80.51it/s]
epoch 75800  training loss: 1035258560512.0

 76%|██████████████████████████████████████████████████▉                | 76063/100000 [15:56<05:00, 79.66it/s]
epoch 75900  training loss: 1014931587072.0
epoch 75900  clean testing loss: 14685844799488.0
epoch 76000  training loss: 1087933841408.0
epoch 76000  clean testing loss: 14939392573440.0

 76%|███████████████████████████████████████████████████                | 76224/100000 [15:58<04:57, 80.00it/s]
epoch 76100  training loss: 1004156026880.0
epoch 76100  clean testing loss: 14786303623168.0
epoch 76200  training loss: 1001685057536.0

 76%|███████████████████████████████████████████████████▏               | 76385/100000 [16:00<04:51, 80.96it/s]
epoch 76300  training loss: 1009082368000.0

 77%|███████████████████████████████████████████████████▎               | 76541/100000 [16:02<04:55, 79.49it/s]
epoch 76400  training loss: 1029374607360.0
epoch 76400  clean testing loss: 14889320972288.0
epoch 76500  training loss: 1012218068992.0

 77%|███████████████████████████████████████████████████▍               | 76701/100000 [16:04<04:50, 80.28it/s]
epoch 76600  training loss: 1007224356864.0

 77%|███████████████████████████████████████████████████▌               | 76867/100000 [16:07<04:49, 79.89it/s]
epoch 76700  training loss: 1005967048704.0
epoch 76700  clean testing loss: 14838143123456.0
epoch 76800  training loss: 991140315136.0

 77%|███████████████████████████████████████████████████▌               | 77027/100000 [16:09<04:49, 79.40it/s]
epoch 76900  training loss: 992833241088.0
epoch 76900  clean testing loss: 14706219679744.0
epoch 77000  training loss: 991946211328.0
epoch 77000  clean testing loss: 14690737455104.0

 77%|███████████████████████████████████████████████████▋               | 77186/100000 [16:11<04:44, 80.30it/s]
epoch 77100  training loss: 1037844021248.0

 77%|███████████████████████████████████████████████████▊               | 77346/100000 [16:13<04:41, 80.46it/s]
epoch 77200  training loss: 992147210240.0
epoch 77200  clean testing loss: 14731823808512.0
epoch 77300  training loss: 987239350272.0

 78%|███████████████████████████████████████████████████▉               | 77508/100000 [16:15<04:39, 80.46it/s]
epoch 77400  training loss: 987210383360.0

 78%|████████████████████████████████████████████████████               | 77670/100000 [16:17<04:36, 80.63it/s]
epoch 77500  training loss: 986071433216.0
epoch 77500  clean testing loss: 14681474334720.0
epoch 77600  training loss: 983321149440.0

 78%|████████████████████████████████████████████████████▏              | 77831/100000 [16:19<04:37, 79.83it/s]
epoch 77700  training loss: 984160796672.0
epoch 77700  clean testing loss: 14733553958912.0
epoch 77800  training loss: 1011885604864.0

 78%|████████████████████████████████████████████████████▎              | 77994/100000 [16:21<04:30, 81.48it/s]
epoch 77900  training loss: 990048223232.0

 78%|████████████████████████████████████████████████████▎              | 78156/100000 [16:23<04:29, 81.12it/s]
epoch 78000  training loss: 978281627648.0
epoch 78000  clean testing loss: 14685185245184.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 78100  training loss: 982534782976.0

 78%|████████████████████████████████████████████████████▍              | 78318/100000 [16:25<04:28, 80.90it/s]
epoch 78200  training loss: 980446216192.0

 78%|████████████████████████████████████████████████████▌              | 78480/100000 [16:27<04:27, 80.36it/s]
epoch 78300  training loss: 976996925440.0
epoch 78300  clean testing loss: 14675513180160.0
epoch 78400  training loss: 977914626048.0

 79%|████████████████████████████████████████████████████▋              | 78633/100000 [16:29<04:25, 80.45it/s]
epoch 78500  training loss: 980118470656.0
epoch 78500  clean testing loss: 14711326244864.0
epoch 78600  training loss: 987694956544.0

 79%|████████████████████████████████████████████████████▊              | 78796/100000 [16:31<04:25, 80.01it/s]
epoch 78700  training loss: 984750817280.0

 79%|████████████████████████████████████████████████████▉              | 78961/100000 [16:33<04:23, 79.74it/s]
epoch 78800  training loss: 1030233980928.0
epoch 78800  clean testing loss: 14684210069504.0
epoch 78900  training loss: 975687385088.0

 79%|█████████████████████████████████████████████████████              | 79114/100000 [16:35<04:20, 80.24it/s]
epoch 79000  training loss: 975069839360.0
epoch 79000  clean testing loss: 14700865650688.0

 79%|█████████████████████████████████████████████████████              | 79280/100000 [16:37<04:20, 79.54it/s]
epoch 79100  training loss: 969600466944.0
epoch 79100  clean testing loss: 14743245946880.0
epoch 79200  training loss: 985352699904.0

 79%|█████████████████████████████████████████████████████▏             | 79436/100000 [16:39<04:17, 79.71it/s]
epoch 79300  training loss: 974040006656.0
epoch 79300  clean testing loss: 14738916376576.0
epoch 79400  training loss: 960163086336.0

 80%|█████████████████████████████████████████████████████▎             | 79601/100000 [16:41<04:13, 80.31it/s]
epoch 79500  training loss: 954156318720.0

 80%|█████████████████████████████████████████████████████▍             | 79758/100000 [16:43<04:12, 80.17it/s]
epoch 79600  training loss: 951795712000.0
epoch 79600  clean testing loss: 14750822957056.0
epoch 79700  training loss: 946208833536.0

 80%|█████████████████████████████████████████████████████▌             | 79922/100000 [16:45<04:13, 79.08it/s]
epoch 79800  training loss: 949844115456.0

 80%|█████████████████████████████████████████████████████▋             | 80079/100000 [16:47<04:10, 79.64it/s]
epoch 79900  training loss: 948677378048.0
epoch 79900  clean testing loss: 14706717753344.0
epoch 80000  training loss: 936707031040.0
epoch 80000  clean testing loss: 14669561462784.0

 80%|█████████████████████████████████████████████████████▊             | 80237/100000 [16:49<04:07, 79.85it/s]
epoch 80100  training loss: 937463709696.0
epoch 80100  clean testing loss: 14672622256128.0
epoch 80200  training loss: 946288197632.0

 80%|█████████████████████████████████████████████████████▊             | 80403/100000 [16:51<04:06, 79.58it/s]
epoch 80300  training loss: 927382110208.0

 81%|█████████████████████████████████████████████████████▉             | 80561/100000 [16:53<04:02, 80.22it/s]
epoch 80400  training loss: 997290082304.0
epoch 80400  clean testing loss: 14699933466624.0
epoch 80500  training loss: 925974593536.0

 81%|██████████████████████████████████████████████████████             | 80723/100000 [16:55<04:00, 80.19it/s]
epoch 80600  training loss: 923402829824.0

 81%|██████████████████████████████████████████████████████▏            | 80885/100000 [16:57<03:58, 80.01it/s]
epoch 80700  training loss: 1523298861056.0
epoch 80700  clean testing loss: 14801433526272.0
epoch 80800  training loss: 919547412480.0

 81%|██████████████████████████████████████████████████████▎            | 81041/100000 [16:59<03:56, 80.23it/s]
epoch 80900  training loss: 917442002944.0
epoch 80900  clean testing loss: 14709081243648.0
epoch 81000  training loss: 917073559552.0
epoch 81000  clean testing loss: 14694775521280.0

 81%|██████████████████████████████████████████████████████▍            | 81199/100000 [17:01<03:55, 79.91it/s]
epoch 81100  training loss: 910970781696.0

 81%|██████████████████████████████████████████████████████▌            | 81361/100000 [17:03<03:51, 80.64it/s]
epoch 81200  training loss: 910398259200.0
epoch 81200  clean testing loss: 14720906035200.0
epoch 81300  training loss: 907181555712.0

 82%|██████████████████████████████████████████████████████▌            | 81523/100000 [17:05<03:48, 80.78it/s]
epoch 81400  training loss: 911284502528.0
epoch 81400  clean testing loss: 14680664834048.0
epoch 81500  training loss: 905190440960.0

 82%|██████████████████████████████████████████████████████▋            | 81685/100000 [17:07<03:45, 81.35it/s]
epoch 81600  training loss: 916672217088.0

 82%|██████████████████████████████████████████████████████▊            | 81847/100000 [17:09<03:46, 80.15it/s]
epoch 81700  training loss: 914478989312.0
epoch 81700  clean testing loss: 14674542198784.0
epoch 81800  training loss: 905743171584.0

 82%|██████████████████████████████████████████████████████▉            | 82009/100000 [17:11<03:48, 78.88it/s]
epoch 81900  training loss: 899273195520.0

 82%|███████████████████████████████████████████████████████            | 82130/100000 [17:12<03:42, 80.47it/s]
epoch 82000  training loss: 902145376256.0
epoch 82000  clean testing loss: 14624210550784.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 82100  training loss: 896405078016.0

 82%|███████████████████████████████████████████████████████▏           | 82292/100000 [17:14<03:38, 80.93it/s]
epoch 82200  training loss: 894635999232.0
epoch 82200  clean testing loss: 14638001422336.0
epoch 82300  training loss: 895341690880.0

 82%|███████████████████████████████████████████████████████▏           | 82454/100000 [17:16<03:37, 80.58it/s]
epoch 82400  training loss: 894980390912.0

 83%|███████████████████████████████████████████████████████▎           | 82613/100000 [17:18<03:37, 79.81it/s]
epoch 82500  training loss: 897522925568.0
epoch 82500  clean testing loss: 14722058420224.0
epoch 82600  training loss: 909967491072.0

 83%|███████████████████████████████████████████████████████▍           | 82774/100000 [17:20<03:34, 80.21it/s]
epoch 82700  training loss: 928877838336.0

 83%|███████████████████████████████████████████████████████▌           | 82930/100000 [17:22<03:34, 79.67it/s]
epoch 82800  training loss: 906841423872.0
epoch 82800  clean testing loss: 14681179684864.0
epoch 82900  training loss: 893856776192.0

 83%|███████████████████████████████████████████████████████▋           | 83097/100000 [17:24<03:32, 79.65it/s]
epoch 83000  training loss: 893538205696.0
epoch 83000  clean testing loss: 14668295831552.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 83100  training loss: 917980184576.0

 83%|███████████████████████████████████████████████████████▊           | 83258/100000 [17:26<03:26, 81.01it/s]
epoch 83200  training loss: 893958422528.0

 83%|███████████████████████████████████████████████████████▉           | 83419/100000 [17:28<03:27, 79.96it/s]
epoch 83300  training loss: 904800174080.0
epoch 83300  clean testing loss: 14777583665152.0
epoch 83400  training loss: 891470741504.0

 84%|███████████████████████████████████████████████████████▉           | 83580/100000 [17:30<03:26, 79.67it/s]
epoch 83500  training loss: 892876357632.0

 84%|████████████████████████████████████████████████████████           | 83738/100000 [17:32<03:24, 79.65it/s]
epoch 83600  training loss: 883584204800.0
epoch 83600  clean testing loss: 14708588412928.0
epoch 83700  training loss: 889196445696.0

 84%|████████████████████████████████████████████████████████▏          | 83898/100000 [17:34<03:22, 79.37it/s]
epoch 83800  training loss: 885971419136.0
epoch 83800  clean testing loss: 14714860994560.0
epoch 83900  training loss: 884762476544.0

 84%|████████████████████████████████████████████████████████▎          | 84052/100000 [17:36<03:20, 79.36it/s]
epoch 84000  training loss: 885735817216.0
epoch 84000  clean testing loss: 14693079973888.0

 84%|████████████████████████████████████████████████████████▍          | 84217/100000 [17:38<03:16, 80.47it/s]
epoch 84100  training loss: 885270642688.0
epoch 84100  clean testing loss: 14679693852672.0
epoch 84200  training loss: 885295153152.0

 84%|████████████████████████████████████████████████████████▌          | 84377/100000 [17:40<03:15, 80.06it/s]
epoch 84300  training loss: 885929803776.0

 85%|████████████████████████████████████████████████████████▋          | 84534/100000 [17:42<03:14, 79.39it/s]
epoch 84400  training loss: 885904310272.0
epoch 84400  clean testing loss: 14676980137984.0
epoch 84500  training loss: 883072303104.0

 85%|████████████████████████████████████████████████████████▋          | 84695/100000 [17:44<03:10, 80.17it/s]
epoch 84600  training loss: 881918148608.0
epoch 84600  clean testing loss: 14657710456832.0
epoch 84700  training loss: 881972150272.0

 85%|████████████████████████████████████████████████████████▊          | 84855/100000 [17:46<03:08, 80.48it/s]
epoch 84800  training loss: 886819651584.0

 85%|████████████████████████████████████████████████████████▉          | 85016/100000 [17:48<03:09, 79.20it/s]
epoch 84900  training loss: 878346633216.0
epoch 84900  clean testing loss: 14679857430528.0
epoch 85000  training loss: 930398076928.0
epoch 85000  clean testing loss: 14666328702976.0

 85%|█████████████████████████████████████████████████████████          | 85177/100000 [17:50<03:06, 79.69it/s]
epoch 85100  training loss: 878304624640.0

 85%|█████████████████████████████████████████████████████████▏         | 85345/100000 [17:52<03:02, 80.47it/s]
epoch 85200  training loss: 876115853312.0
epoch 85200  clean testing loss: 14624313311232.0
epoch 85300  training loss: 873554640896.0

 86%|█████████████████████████████████████████████████████████▎         | 85504/100000 [17:54<03:00, 80.21it/s]
epoch 85400  training loss: 872596570112.0
epoch 85400  clean testing loss: 14648186241024.0
epoch 85500  training loss: 1036751994880.0

 86%|█████████████████████████████████████████████████████████▍         | 85662/100000 [17:56<02:57, 80.62it/s]
epoch 85600  training loss: 867411099648.0

 86%|█████████████████████████████████████████████████████████▌         | 85824/100000 [17:58<02:57, 80.05it/s]
epoch 85700  training loss: 870136807424.0
epoch 85700  clean testing loss: 14737256480768.0
epoch 85800  training loss: 871444185088.0

 86%|█████████████████████████████████████████████████████████▌         | 85984/100000 [18:00<02:55, 79.88it/s]
epoch 85900  training loss: 867927457792.0

 86%|█████████████████████████████████████████████████████████▋         | 86146/100000 [18:02<02:53, 79.90it/s]
epoch 86000  training loss: 868969545728.0
epoch 86000  clean testing loss: 14613356740608.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 86100  training loss: 890740539392.0

 86%|█████████████████████████████████████████████████████████▊         | 86310/100000 [18:04<02:50, 80.12it/s]
epoch 86200  training loss: 867421585408.0
epoch 86200  clean testing loss: 14611589890048.0
epoch 86300  training loss: 860919955456.0

 86%|█████████████████████████████████████████████████████████▉         | 86469/100000 [18:06<02:50, 79.28it/s]
epoch 86400  training loss: 863116656640.0

 87%|██████████████████████████████████████████████████████████         | 86625/100000 [18:08<02:48, 79.58it/s]
epoch 86500  training loss: 868680138752.0
epoch 86500  clean testing loss: 14757135384576.0
epoch 86600  training loss: 862588502016.0

 87%|██████████████████████████████████████████████████████████▏        | 86790/100000 [18:10<02:46, 79.17it/s]
epoch 86700  training loss: 861276143616.0

 87%|██████████████████████████████████████████████████████████▎        | 86949/100000 [18:12<02:43, 79.81it/s]
epoch 86800  training loss: 868224663552.0
epoch 86800  clean testing loss: 14729140502528.0
epoch 86900  training loss: 864274415616.0

 87%|██████████████████████████████████████████████████████████▎        | 87106/100000 [18:14<02:41, 79.94it/s]
epoch 87000  training loss: 861428056064.0
epoch 87000  clean testing loss: 14613303263232.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 87100  training loss: 859781267456.0

 87%|██████████████████████████████████████████████████████████▍        | 87272/100000 [18:16<02:39, 79.85it/s]
epoch 87200  training loss: 858524876800.0

 87%|██████████████████████████████████████████████████████████▌        | 87433/100000 [18:18<02:37, 79.63it/s]
epoch 87300  training loss: 859846475776.0
epoch 87300  clean testing loss: 14664854405120.0
epoch 87400  training loss: 856468357120.0

 88%|██████████████████████████████████████████████████████████▋        | 87587/100000 [18:20<02:34, 80.44it/s]
epoch 87500  training loss: 860889939968.0

 88%|██████████████████████████████████████████████████████████▊        | 87754/100000 [18:22<02:32, 80.17it/s]
epoch 87600  training loss: 857438617600.0
epoch 87600  clean testing loss: 14630321651712.0
epoch 87700  training loss: 854210969600.0

 88%|██████████████████████████████████████████████████████████▉        | 87910/100000 [18:24<02:29, 80.70it/s]
epoch 87800  training loss: 854992617472.0
epoch 87800  clean testing loss: 14600365932544.0
epoch 87900  training loss: 855836393472.0

 88%|███████████████████████████████████████████████████████████        | 88071/100000 [18:26<02:28, 80.57it/s]
epoch 88000  training loss: 855925391360.0
epoch 88000  clean testing loss: 14612320747520.0

 88%|███████████████████████████████████████████████████████████        | 88230/100000 [18:28<02:27, 79.89it/s]
epoch 88100  training loss: 856335843328.0
epoch 88100  clean testing loss: 14627841769472.0
epoch 88200  training loss: 853348843520.0

 88%|███████████████████████████████████████████████████████████▏       | 88392/100000 [18:30<02:22, 81.59it/s]
epoch 88300  training loss: 853111209984.0

 89%|███████████████████████████████████████████████████████████▎       | 88558/100000 [18:32<02:21, 81.12it/s]
epoch 88400  training loss: 854613557248.0
epoch 88400  clean testing loss: 14598140854272.0
epoch 88500  training loss: 855067656192.0

 89%|███████████████████████████████████████████████████████████▍       | 88718/100000 [18:34<02:21, 79.92it/s]
epoch 88600  training loss: 849811144704.0
epoch 88600  clean testing loss: 14562003779584.0
epoch 88700  training loss: 852468498432.0

 89%|███████████████████████████████████████████████████████████▌       | 88876/100000 [18:36<02:19, 79.56it/s]
epoch 88800  training loss: 849406459904.0

 89%|███████████████████████████████████████████████████████████▋       | 89039/100000 [18:39<02:16, 80.47it/s]
epoch 88900  training loss: 846161248256.0
epoch 88900  clean testing loss: 14623790071808.0
epoch 89000  training loss: 846335180800.0
epoch 89000  clean testing loss: 14596681236480.0

 89%|███████████████████████████████████████████████████████████▊       | 89201/100000 [18:41<02:14, 80.38it/s]
epoch 89100  training loss: 847876587520.0

 89%|███████████████████████████████████████████████████████████▊       | 89362/100000 [18:43<02:12, 80.07it/s]
epoch 89200  training loss: 847323529216.0
epoch 89200  clean testing loss: 14596865785856.0
epoch 89300  training loss: 846094598144.0

 90%|███████████████████████████████████████████████████████████▉       | 89515/100000 [18:44<02:10, 80.24it/s]
epoch 89400  training loss: 850088558592.0
epoch 89400  clean testing loss: 14583455547392.0
epoch 89500  training loss: 846655520768.0

 90%|████████████████████████████████████████████████████████████       | 89679/100000 [18:46<02:09, 79.65it/s]
epoch 89600  training loss: 845368262656.0

 90%|████████████████████████████████████████████████████████████▏      | 89843/100000 [18:49<02:06, 80.41it/s]
epoch 89700  training loss: 843106746368.0
epoch 89700  clean testing loss: 14589498490880.0
epoch 89800  training loss: 845237125120.0

 90%|████████████████████████████████████████████████████████████▎      | 90004/100000 [18:51<02:06, 78.80it/s]
epoch 89900  training loss: 844793905152.0
epoch 89900  clean testing loss: 14642928680960.0
epoch 90000  training loss: 841588277248.0
epoch 90000  clean testing loss: 14577770168320.0

 90%|████████████████████████████████████████████████████████████▍      | 90163/100000 [18:53<02:01, 80.98it/s]
epoch 90100  training loss: 838343458816.0

 90%|████████████████████████████████████████████████████████████▌      | 90320/100000 [18:54<02:02, 79.24it/s]
epoch 90200  training loss: 836783570944.0
epoch 90200  clean testing loss: 14575140339712.0
epoch 90300  training loss: 839921565696.0

 90%|████████████████████████████████████████████████████████████▌      | 90485/100000 [18:57<01:59, 79.79it/s]
epoch 90400  training loss: 843220647936.0

 91%|████████████████████████████████████████████████████████████▋      | 90640/100000 [18:58<01:57, 79.88it/s]
epoch 90500  training loss: 838342410240.0
epoch 90500  clean testing loss: 14571087593472.0
epoch 90600  training loss: 837240487936.0

 91%|████████████████████████████████████████████████████████████▊      | 90802/100000 [19:01<01:55, 79.62it/s]
epoch 90700  training loss: 840301608960.0
epoch 90700  clean testing loss: 14546307645440.0
epoch 90800  training loss: 838211534848.0

 91%|████████████████████████████████████████████████████████████▉      | 90961/100000 [19:03<01:52, 80.53it/s]
epoch 90900  training loss: 837305630720.0

 91%|█████████████████████████████████████████████████████████████      | 91121/100000 [19:05<01:52, 79.14it/s]
epoch 91000  training loss: 843078762496.0
epoch 91000  clean testing loss: 14631148978176.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 91100  training loss: 835280175104.0

 91%|█████████████████████████████████████████████████████████████▏     | 91283/100000 [19:07<01:49, 79.91it/s]
epoch 91200  training loss: 836195123200.0

 91%|█████████████████████████████████████████████████████████████▎     | 91443/100000 [19:09<01:46, 80.29it/s]
epoch 91300  training loss: 833756528640.0
epoch 91300  clean testing loss: 14563659481088.0
epoch 91400  training loss: 834090172416.0

 92%|█████████████████████████████████████████████████████████████▍     | 91609/100000 [19:11<01:37, 86.23it/s]
epoch 91500  training loss: 830975311872.0
epoch 91500  clean testing loss: 14549588639744.0
epoch 91600  training loss: 827440431104.0

 92%|█████████████████████████████████████████████████████████████▍     | 91780/100000 [19:13<01:35, 86.47it/s]
epoch 91700  training loss: 826828128256.0

 92%|█████████████████████████████████████████████████████████████▌     | 91960/100000 [19:15<01:32, 86.66it/s]
epoch 91800  training loss: 833320452096.0
epoch 91800  clean testing loss: 14522507067392.0
epoch 91900  training loss: 828297707520.0

 92%|█████████████████████████████████████████████████████████████▋     | 92131/100000 [19:17<01:30, 86.56it/s]
epoch 92000  training loss: 822843604992.0
epoch 92000  clean testing loss: 14500772184064.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 92100  training loss: 822610296832.0

 92%|█████████████████████████████████████████████████████████████▊     | 92302/100000 [19:19<01:29, 86.26it/s]
epoch 92200  training loss: 824865128448.0
epoch 92200  clean testing loss: 14513673863168.0
epoch 92300  training loss: 823595565056.0

 92%|█████████████████████████████████████████████████████████████▉     | 92482/100000 [19:21<01:26, 86.70it/s]
epoch 92400  training loss: 830881136640.0

 93%|██████████████████████████████████████████████████████████████     | 92653/100000 [19:23<01:24, 86.66it/s]
epoch 92500  training loss: 822609903616.0
epoch 92500  clean testing loss: 14538831298560.0
epoch 92600  training loss: 825494011904.0

 93%|██████████████████████████████████████████████████████████████▏    | 92824/100000 [19:25<01:23, 86.29it/s]
epoch 92700  training loss: 822850289664.0
epoch 92700  clean testing loss: 14546470174720.0
epoch 92800  training loss: 821928132608.0

 93%|██████████████████████████████████████████████████████████████▎    | 92995/100000 [19:27<01:20, 86.49it/s]
epoch 92900  training loss: 820297203712.0

 93%|██████████████████████████████████████████████████████████████▍    | 93175/100000 [19:29<01:19, 86.24it/s]
epoch 93000  training loss: 854875439104.0
epoch 93000  clean testing loss: 14540442959872.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 93100  training loss: 820585627648.0

 93%|██████████████████████████████████████████████████████████████▌    | 93346/100000 [19:31<01:17, 86.29it/s]
epoch 93200  training loss: 820997390336.0
epoch 93200  clean testing loss: 14539463589888.0
epoch 93300  training loss: 822174613504.0

 94%|██████████████████████████████████████████████████████████████▋    | 93517/100000 [19:33<01:15, 86.16it/s]
epoch 93400  training loss: 821418655744.0
epoch 93400  clean testing loss: 14478821294080.0
epoch 93500  training loss: 819640401920.0

 94%|██████████████████████████████████████████████████████████████▊    | 93688/100000 [19:35<01:13, 86.25it/s]
epoch 93600  training loss: 816435953664.0

 94%|██████████████████████████████████████████████████████████████▉    | 93868/100000 [19:37<01:10, 86.42it/s]
epoch 93700  training loss: 821451227136.0
epoch 93700  clean testing loss: 14481332633600.0
epoch 93800  training loss: 817598496768.0

 94%|███████████████████████████████████████████████████████████████    | 94039/100000 [19:39<01:08, 86.86it/s]
epoch 93900  training loss: 818749702144.0
epoch 93900  clean testing loss: 14543502704640.0
epoch 94000  training loss: 814671724544.0
epoch 94000  clean testing loss: 14470799687680.0

 94%|███████████████████████████████████████████████████████████████    | 94210/100000 [19:41<01:06, 86.99it/s]
epoch 94100  training loss: 815286452224.0
epoch 94100  clean testing loss: 14450459410432.0
epoch 94200  training loss: 814833074176.0

 94%|███████████████████████████████████████████████████████████████▏   | 94390/100000 [19:43<01:04, 87.30it/s]
epoch 94300  training loss: 815190769664.0

 95%|███████████████████████████████████████████████████████████████▎   | 94561/100000 [19:45<01:03, 86.24it/s]
epoch 94400  training loss: 816844308480.0
epoch 94400  clean testing loss: 14512652550144.0
epoch 94500  training loss: 815212331008.0

 95%|███████████████████████████████████████████████████████████████▍   | 94732/100000 [19:47<01:01, 86.25it/s]
epoch 94600  training loss: 813291143168.0
epoch 94600  clean testing loss: 14492344778752.0
epoch 94700  training loss: 814138589184.0

 95%|███████████████████████████████████████████████████████████████▌   | 94912/100000 [19:49<00:59, 86.09it/s]
epoch 94800  training loss: 811728830464.0

 95%|███████████████████████████████████████████████████████████████▋   | 95083/100000 [19:51<00:57, 86.22it/s]
epoch 94900  training loss: 812819808256.0
epoch 94900  clean testing loss: 14437663637504.0
epoch 95000  training loss: 809625649152.0
epoch 95000  clean testing loss: 14487825416192.0

 95%|███████████████████████████████████████████████████████████████▊   | 95254/100000 [19:53<00:55, 86.24it/s]
epoch 95100  training loss: 811565187072.0
epoch 95100  clean testing loss: 14451980894208.0
epoch 95200  training loss: 811395514368.0

 95%|███████████████████████████████████████████████████████████████▉   | 95425/100000 [19:55<00:53, 86.27it/s]
epoch 95300  training loss: 811555749888.0
epoch 95300  clean testing loss: 14478568587264.0
epoch 95400  training loss: 807559102464.0

 96%|████████████████████████████████████████████████████████████████   | 95596/100000 [19:57<00:51, 86.34it/s]
epoch 95500  training loss: 821393358848.0

 96%|████████████████████████████████████████████████████████████████▏  | 95776/100000 [19:59<00:48, 86.51it/s]
epoch 95600  training loss: 808602042368.0
epoch 95600  clean testing loss: 14401301118976.0
epoch 95700  training loss: 806357172224.0

 96%|████████████████████████████████████████████████████████████████▎  | 95947/100000 [20:01<00:46, 86.39it/s]
epoch 95800  training loss: 807678967808.0
epoch 95800  clean testing loss: 14405688360960.0
epoch 95900  training loss: 803111501824.0

 96%|████████████████████████████████████████████████████████████████▍  | 96118/100000 [20:03<00:44, 86.32it/s]
epoch 96000  training loss: 802742206464.0
epoch 96000  clean testing loss: 14432905199616.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 96100  training loss: 804289183744.0

 96%|████████████████████████████████████████████████████████████████▌  | 96289/100000 [20:05<00:42, 86.40it/s]
epoch 96200  training loss: 803468279808.0

 96%|████████████████████████████████████████████████████████████████▋  | 96469/100000 [20:07<00:40, 86.42it/s]
epoch 96300  training loss: 802188754944.0
epoch 96300  clean testing loss: 14358865248256.0
epoch 96400  training loss: 806197854208.0

 97%|████████████████████████████████████████████████████████████████▋  | 96640/100000 [20:09<00:38, 86.48it/s]
epoch 96500  training loss: 804819763200.0
epoch 96500  clean testing loss: 14372490444800.0
epoch 96600  training loss: 802863382528.0

 97%|████████████████████████████████████████████████████████████████▊  | 96811/100000 [20:11<00:36, 86.45it/s]
epoch 96700  training loss: 817230774272.0
epoch 96700  clean testing loss: 14403636297728.0
epoch 96800  training loss: 802219425792.0

 97%|████████████████████████████████████████████████████████████████▉  | 96991/100000 [20:13<00:34, 86.94it/s]
epoch 96900  training loss: 803229401088.0

 97%|█████████████████████████████████████████████████████████████████  | 97162/100000 [20:15<00:32, 86.59it/s]
epoch 97000  training loss: 800935772160.0
epoch 97000  clean testing loss: 14462951096320.0
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 97100  training loss: 818022842368.0

 97%|█████████████████████████████████████████████████████████████████▏ | 97333/100000 [20:17<00:30, 86.39it/s]
epoch 97200  training loss: 799439716352.0
epoch 97200  clean testing loss: 14415923511296.0
epoch 97300  training loss: 802597371904.0

 98%|█████████████████████████████████████████████████████████████████▎ | 97504/100000 [20:19<00:28, 86.43it/s]
epoch 97400  training loss: 800747421696.0

 98%|█████████████████████████████████████████████████████████████████▍ | 97684/100000 [20:21<00:26, 86.53it/s]
epoch 97500  training loss: 798171267072.0
epoch 97500  clean testing loss: 14428088041472.0
epoch 97600  training loss: 798089936896.0

 98%|█████████████████████████████████████████████████████████████████▌ | 97855/100000 [20:23<00:24, 86.71it/s]
epoch 97700  training loss: 797718020096.0
epoch 97700  clean testing loss: 14417194385408.0
epoch 97800  training loss: 805096259584.0

 98%|█████████████████████████████████████████████████████████████████▋ | 98026/100000 [20:25<00:22, 86.46it/s]
epoch 97900  training loss: 798112415744.0
epoch 97900  clean testing loss: 14437408833536.0
epoch 98000  training loss: 798799953920.0
epoch 98000  clean testing loss: 14394985545728.0

 98%|█████████████████████████████████████████████████████████████████▊ | 98206/100000 [20:27<00:20, 87.20it/s]
epoch 98100  training loss: 796270592000.0

 98%|█████████████████████████████████████████████████████████████████▉ | 98377/100000 [20:29<00:18, 86.81it/s]
epoch 98200  training loss: 795430354944.0
epoch 98200  clean testing loss: 14411951505408.0
epoch 98300  training loss: 799044468736.0

 99%|██████████████████████████████████████████████████████████████████ | 98557/100000 [20:31<00:16, 86.75it/s]
epoch 98400  training loss: 796704768000.0
epoch 98400  clean testing loss: 14422709895168.0
epoch 98500  training loss: 795575058432.0

 99%|██████████████████████████████████████████████████████████████████▏| 98728/100000 [20:33<00:14, 87.37it/s]
epoch 98600  training loss: 793114705920.0
epoch 98600  clean testing loss: 14360603787264.0
epoch 98700  training loss: 794046169088.0

 99%|██████████████████████████████████████████████████████████████████▎| 98899/100000 [20:35<00:12, 87.09it/s]
epoch 98800  training loss: 792994775040.0

 99%|██████████████████████████████████████████████████████████████████▍| 99079/100000 [20:37<00:10, 86.45it/s]
epoch 98900  training loss: 789818245120.0
epoch 98900  clean testing loss: 14362295140352.0
epoch 99000  training loss: 789376663552.0
epoch 99000  clean testing loss: 14389116665856.0

 99%|██████████████████████████████████████████████████████████████████▍| 99250/100000 [20:39<00:08, 87.14it/s]
epoch 99100  training loss: 790397255680.0
epoch 99100  clean testing loss: 14414364278784.0
epoch 99200  training loss: 790548250624.0

 99%|██████████████████████████████████████████████████████████████████▌| 99421/100000 [20:41<00:06, 86.13it/s]
epoch 99300  training loss: 790899851264.0
epoch 99300  clean testing loss: 14413822164992.0
epoch 99400  training loss: 790591438848.0

100%|██████████████████████████████████████████████████████████████████▋| 99592/100000 [20:43<00:04, 86.77it/s]
epoch 99500  training loss: 791938334720.0

100%|██████████████████████████████████████████████████████████████████▊| 99772/100000 [20:45<00:02, 86.83it/s]
epoch 99600  training loss: 798938169344.0
epoch 99600  clean testing loss: 14407380762624.0
epoch 99700  training loss: 792539824128.0

100%|██████████████████████████████████████████████████████████████████▉| 99943/100000 [20:47<00:00, 86.92it/s]
epoch 99800  training loss: 795592294400.0
epoch 99800  clean testing loss: 14409270296576.0
epoch 99900  training loss: 789368537088.0

100%|██████████████████████████████████████████████████████████████████| 100000/100000 [20:48<00:00, 80.13it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers2_relu3_size500_noise1.00e+00_invop1_lr5e-05 ...