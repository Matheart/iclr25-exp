
  0%|          | 15/100000 [00:01<2:17:00, 12.16it/s]
epoch 0  training loss: 195.47097778320312
epoch 0  clean testing loss: 2816.912841796875




  0%|          | 117/100000 [00:09<2:12:51, 12.53it/s]
epoch 100  training loss: 36.6937141418457



  0%|          | 191/100000 [00:15<2:12:50, 12.52it/s]
epoch 200  training loss: 35.85063171386719





  0%|          | 317/100000 [00:25<2:12:40, 12.52it/s]
epoch 300  training loss: 35.11231231689453




  0%|          | 417/100000 [00:33<2:12:27, 12.53it/s]
epoch 400  training loss: 29.57819366455078



  0%|          | 491/100000 [00:39<2:12:21, 12.53it/s]
epoch 500  training loss: 27.296987533569336





  1%|          | 617/100000 [00:49<2:12:15, 12.52it/s]
epoch 600  training loss: 25.48775863647461




  1%|          | 717/100000 [00:57<2:12:02, 12.53it/s]
epoch 700  training loss: 30.900177001953125




  1%|          | 817/100000 [01:05<2:11:56, 12.53it/s]
epoch 800  training loss: 22.654157638549805




  1%|          | 917/100000 [01:13<2:11:50, 12.53it/s]
epoch 900  training loss: 22.008636474609375



  1%|          | 993/100000 [01:19<2:11:37, 12.54it/s]
epoch 1000  training loss: 22.00468635559082
epoch 1000  clean testing loss: 22.687829971313477




  1%|          | 1093/100000 [01:27<2:11:22, 12.55it/s]
epoch 1100  training loss: 21.231109619140625




  1%|          | 1193/100000 [01:35<2:11:20, 12.54it/s]
epoch 1200  training loss: 20.965320587158203





  1%|▏         | 1319/100000 [01:45<2:11:13, 12.53it/s]
epoch 1300  training loss: 21.331130981445312




  1%|▏         | 1419/100000 [01:53<2:12:26, 12.41it/s]
epoch 1400  training loss: 20.668807983398438




  2%|▏         | 1519/100000 [02:01<2:10:59, 12.53it/s]
epoch 1500  training loss: 20.122407913208008




  2%|▏         | 1619/100000 [02:09<2:10:48, 12.53it/s]
epoch 1600  training loss: 19.732608795166016




  2%|▏         | 1719/100000 [02:17<2:10:38, 12.54it/s]
epoch 1700  training loss: 19.650177001953125




  2%|▏         | 1819/100000 [02:25<2:10:32, 12.54it/s]
epoch 1800  training loss: 18.637901306152344




  2%|▏         | 1919/100000 [02:33<2:10:33, 12.52it/s]
epoch 1900  training loss: 17.78014373779297




  2%|▏         | 2021/100000 [02:41<2:10:15, 12.54it/s]
epoch 2000  training loss: 19.93007469177246
epoch 2000  clean testing loss: 20.328590393066406




  2%|▏         | 2121/100000 [02:49<2:10:05, 12.54it/s]
epoch 2100  training loss: 15.197013854980469




  2%|▏         | 2221/100000 [02:57<2:09:54, 12.55it/s]
epoch 2200  training loss: 13.820952415466309




  2%|▏         | 2321/100000 [03:05<2:09:47, 12.54it/s]
epoch 2300  training loss: 12.680534362792969




  2%|▏         | 2421/100000 [03:13<2:09:38, 12.55it/s]
epoch 2400  training loss: 11.116459846496582




  3%|▎         | 2521/100000 [03:21<2:09:30, 12.54it/s]
epoch 2500  training loss: 11.476651191711426




  3%|▎         | 2621/100000 [03:29<2:09:25, 12.54it/s]
epoch 2600  training loss: 8.252047538757324




  3%|▎         | 2723/100000 [03:37<2:09:17, 12.54it/s]
epoch 2700  training loss: 5.554401397705078




  3%|▎         | 2823/100000 [03:45<2:09:16, 12.53it/s]
epoch 2800  training loss: 3.3923912048339844




  3%|▎         | 2923/100000 [03:53<2:11:57, 12.26it/s]
epoch 2900  training loss: 2.2939977645874023




  3%|▎         | 3023/100000 [04:01<2:08:56, 12.54it/s]
epoch 3000  training loss: 1.221274733543396
epoch 3000  clean testing loss: 1.1680911779403687




  3%|▎         | 3123/100000 [04:09<2:08:46, 12.54it/s]
epoch 3100  training loss: 1.0277235507965088




  3%|▎         | 3223/100000 [04:17<2:08:41, 12.53it/s]
epoch 3200  training loss: 0.9503539800643921




  3%|▎         | 3323/100000 [04:25<2:08:30, 12.54it/s]
epoch 3300  training loss: 0.9075721502304077




  3%|▎         | 3425/100000 [04:33<2:08:23, 12.54it/s]
epoch 3400  training loss: 0.8722343444824219




  4%|▎         | 3525/100000 [04:41<2:08:08, 12.55it/s]
epoch 3500  training loss: 1.3656343221664429



  4%|▎         | 3599/100000 [04:47<2:08:11, 12.53it/s]
epoch 3600  training loss: 0.8557900190353394





  4%|▎         | 3725/100000 [04:57<2:07:57, 12.54it/s]
epoch 3700  training loss: 0.8338108062744141



  4%|▍         | 3801/100000 [05:04<2:07:52, 12.54it/s]
epoch 3800  training loss: 0.8270436525344849




  4%|▍         | 3901/100000 [05:12<2:07:43, 12.54it/s]
epoch 3900  training loss: 0.9018366932868958




  4%|▍         | 4001/100000 [05:19<2:09:25, 12.36it/s]
epoch 4000  training loss: 0.7974594831466675
epoch 4000  clean testing loss: 0.7425612211227417




  4%|▍         | 4101/100000 [05:28<2:07:44, 12.51it/s]
epoch 4100  training loss: 0.8195929527282715




  4%|▍         | 4201/100000 [05:36<2:07:22, 12.54it/s]
epoch 4200  training loss: 0.772201418876648




  4%|▍         | 4301/100000 [05:43<2:07:16, 12.53it/s]
epoch 4300  training loss: 0.7484264373779297




  4%|▍         | 4403/100000 [05:52<2:07:27, 12.50it/s]
epoch 4400  training loss: 0.8962936997413635




  5%|▍         | 4503/100000 [06:00<2:07:23, 12.49it/s]
epoch 4500  training loss: 0.777704119682312




  5%|▍         | 4603/100000 [06:08<2:07:09, 12.50it/s]
epoch 4600  training loss: 0.7887014746665955




  5%|▍         | 4703/100000 [06:16<2:07:01, 12.50it/s]
epoch 4700  training loss: 1.6856862306594849




  5%|▍         | 4803/100000 [06:24<2:15:53, 11.68it/s]
epoch 4800  training loss: 1.4624528884887695




  5%|▍         | 4903/100000 [06:32<2:06:47, 12.50it/s]
epoch 4900  training loss: 0.7061260342597961




  5%|▌         | 5005/100000 [06:40<2:07:12, 12.45it/s]
epoch 5000  training loss: 0.7060569524765015
epoch 5000  clean testing loss: 0.6676109433174133




  5%|▌         | 5105/100000 [06:48<2:06:57, 12.46it/s]
epoch 5100  training loss: 0.6815885305404663




  5%|▌         | 5205/100000 [06:56<2:06:21, 12.50it/s]
epoch 5200  training loss: 0.7924468517303467




  5%|▌         | 5305/100000 [07:04<2:05:57, 12.53it/s]
epoch 5300  training loss: 0.6980190873146057




  5%|▌         | 5405/100000 [07:12<2:05:38, 12.55it/s]
epoch 5400  training loss: 0.7714550495147705




  6%|▌         | 5507/100000 [07:20<2:05:32, 12.54it/s]
epoch 5500  training loss: 0.7599419951438904




  6%|▌         | 5607/100000 [07:28<2:05:40, 12.52it/s]
epoch 5600  training loss: 0.6649350523948669




  6%|▌         | 5707/100000 [07:36<2:05:28, 12.53it/s]
epoch 5700  training loss: 0.6810777187347412




  6%|▌         | 5807/100000 [07:44<2:05:25, 12.52it/s]
epoch 5800  training loss: 0.6594345569610596




  6%|▌         | 5909/100000 [07:52<2:05:03, 12.54it/s]
epoch 5900  training loss: 0.8685465455055237




  6%|▌         | 6009/100000 [08:00<2:05:20, 12.50it/s]
epoch 6000  training loss: 2.229260206222534
epoch 6000  clean testing loss: 0.8023754954338074




  6%|▌         | 6109/100000 [08:08<2:04:56, 12.53it/s]
epoch 6100  training loss: 0.6312503814697266




  6%|▌         | 6209/100000 [08:16<2:04:36, 12.55it/s]
epoch 6200  training loss: 0.6288605332374573




  6%|▋         | 6311/100000 [08:24<2:04:21, 12.56it/s]
epoch 6300  training loss: 0.7652515172958374




  6%|▋         | 6411/100000 [08:32<2:04:20, 12.54it/s]
epoch 6400  training loss: 0.6009436249732971




  7%|▋         | 6511/100000 [08:40<2:04:06, 12.55it/s]
epoch 6500  training loss: 0.6326035857200623




  7%|▋         | 6611/100000 [08:48<2:04:19, 12.52it/s]
epoch 6600  training loss: 0.5860573053359985




  7%|▋         | 6713/100000 [08:56<2:04:25, 12.50it/s]
epoch 6700  training loss: 0.6393203139305115




  7%|▋         | 6813/100000 [09:04<2:03:43, 12.55it/s]
epoch 6800  training loss: 0.6380338668823242




  7%|▋         | 6913/100000 [09:12<2:03:37, 12.55it/s]
epoch 6900  training loss: 0.8900179266929626




  7%|▋         | 7013/100000 [09:20<2:03:35, 12.54it/s]
epoch 7000  training loss: 0.7240558862686157
epoch 7000  clean testing loss: 0.647162139415741




  7%|▋         | 7113/100000 [09:28<2:03:30, 12.53it/s]
epoch 7100  training loss: 0.627821683883667




  7%|▋         | 7215/100000 [09:36<2:03:08, 12.56it/s]
epoch 7200  training loss: 0.6153221726417542




  7%|▋         | 7315/100000 [09:44<2:03:08, 12.54it/s]
epoch 7300  training loss: 0.6361529231071472




  7%|▋         | 7415/100000 [09:52<2:02:57, 12.55it/s]
epoch 7400  training loss: 0.5995521545410156




  8%|▊         | 7515/100000 [10:00<2:02:48, 12.55it/s]
epoch 7500  training loss: 14.17365550994873




  8%|▊         | 7611/100000 [10:08<2:02:34, 12.56it/s]
epoch 7600  training loss: 0.576988935470581




  8%|▊         | 7711/100000 [10:16<2:02:31, 12.55it/s]
epoch 7700  training loss: 0.6199076175689697




  8%|▊         | 7811/100000 [10:24<2:02:23, 12.55it/s]
epoch 7800  training loss: 0.609081506729126




  8%|▊         | 7911/100000 [10:32<2:02:16, 12.55it/s]
epoch 7900  training loss: 0.5640003085136414




  8%|▊         | 8013/100000 [10:40<2:02:13, 12.54it/s]
epoch 8000  training loss: 2.059770345687866
epoch 8000  clean testing loss: 2.7788071632385254




  8%|▊         | 8113/100000 [10:48<2:02:02, 12.55it/s]
epoch 8100  training loss: 0.5768426656723022




  8%|▊         | 8213/100000 [10:56<2:04:09, 12.32it/s]
epoch 8200  training loss: 0.581661581993103




  8%|▊         | 8313/100000 [11:04<2:01:40, 12.56it/s]
epoch 8300  training loss: 0.5647087693214417




  8%|▊         | 8415/100000 [11:12<2:01:33, 12.56it/s]
epoch 8400  training loss: 3.582227945327759




  9%|▊         | 8515/100000 [11:20<2:01:26, 12.56it/s]
epoch 8500  training loss: 0.5567010641098022




  9%|▊         | 8615/100000 [11:28<2:01:16, 12.56it/s]
epoch 8600  training loss: 0.5738539099693298




  9%|▊         | 8715/100000 [11:36<2:01:08, 12.56it/s]
epoch 8700  training loss: 0.5267035961151123




  9%|▉         | 8817/100000 [11:44<2:01:01, 12.56it/s]
epoch 8800  training loss: 0.5887152552604675




  9%|▉         | 8917/100000 [11:52<2:00:54, 12.56it/s]
epoch 8900  training loss: 0.541030764579773




  9%|▉         | 9017/100000 [12:00<2:00:47, 12.55it/s]
epoch 9000  training loss: 0.5211985111236572
epoch 9000  clean testing loss: 0.46600252389907837




  9%|▉         | 9117/100000 [12:08<2:00:33, 12.56it/s]
epoch 9100  training loss: 0.5144771337509155




  9%|▉         | 9219/100000 [12:16<2:00:32, 12.55it/s]
epoch 9200  training loss: 0.5024557709693909



  9%|▉         | 9293/100000 [12:22<2:00:24, 12.56it/s]
epoch 9300  training loss: 0.5005961060523987





  9%|▉         | 9393/100000 [12:30<2:00:17, 12.55it/s]
epoch 9400  training loss: 0.49315184354782104




  9%|▉         | 9495/100000 [12:38<2:00:02, 12.57it/s]
epoch 9500  training loss: 0.5756916999816895




 10%|▉         | 9595/100000 [12:46<2:00:20, 12.52it/s]
epoch 9600  training loss: 0.49275824427604675




 10%|▉         | 9695/100000 [12:54<1:59:44, 12.57it/s]
epoch 9700  training loss: 0.5119886994361877




 10%|▉         | 9795/100000 [13:02<1:59:50, 12.55it/s]
epoch 9800  training loss: 0.6005653142929077




 10%|▉         | 9897/100000 [13:10<1:59:49, 12.53it/s]
epoch 9900  training loss: 0.48068368434906006




 10%|▉         | 9997/100000 [13:18<1:59:25, 12.56it/s]
epoch 10000  training loss: 1.7737505435943604
epoch 10000  clean testing loss: 2.5583906173706055




 10%|█         | 10097/100000 [13:26<2:05:55, 11.90it/s]
epoch 10100  training loss: 0.46082669496536255




 10%|█         | 10197/100000 [13:34<1:59:10, 12.56it/s]
epoch 10200  training loss: 0.44545242190361023




 10%|█         | 10299/100000 [13:42<1:59:10, 12.54it/s]
epoch 10300  training loss: 0.46595048904418945




 10%|█         | 10399/100000 [13:50<1:58:51, 12.56it/s]
epoch 10400  training loss: 0.5575116872787476




 10%|█         | 10499/100000 [13:58<1:58:54, 12.54it/s]
epoch 10500  training loss: 0.45178601145744324




 11%|█         | 10599/100000 [14:06<1:58:55, 12.53it/s]
epoch 10600  training loss: 0.44471660256385803




 11%|█         | 10701/100000 [14:14<1:58:40, 12.54it/s]
epoch 10700  training loss: 0.4771164059638977




 11%|█         | 10801/100000 [14:22<1:58:32, 12.54it/s]
epoch 10800  training loss: 0.45097699761390686




 11%|█         | 10901/100000 [14:30<1:58:36, 12.52it/s]
epoch 10900  training loss: 0.488043874502182




 11%|█         | 11001/100000 [14:38<1:59:45, 12.39it/s]
epoch 11000  training loss: 0.4470442235469818
epoch 11000  clean testing loss: 0.36717820167541504




 11%|█         | 11101/100000 [14:46<1:58:07, 12.54it/s]
epoch 11100  training loss: 0.45869728922843933




 11%|█         | 11203/100000 [14:54<1:58:19, 12.51it/s]
epoch 11200  training loss: 0.8455321788787842




 11%|█▏        | 11303/100000 [15:02<1:58:07, 12.51it/s]
epoch 11300  training loss: 0.4467143416404724




 11%|█▏        | 11403/100000 [15:10<1:57:55, 12.52it/s]
epoch 11400  training loss: 1.3923941850662231




 12%|█▏        | 11503/100000 [15:18<1:57:44, 12.53it/s]
epoch 11500  training loss: 0.4462777376174927




 12%|█▏        | 11605/100000 [15:26<2:01:17, 12.15it/s]
epoch 11600  training loss: 1.3817754983901978




 12%|█▏        | 11705/100000 [15:34<1:57:27, 12.53it/s]
epoch 11700  training loss: 0.40859147906303406




 12%|█▏        | 11805/100000 [15:42<1:57:13, 12.54it/s]
epoch 11800  training loss: 0.4181165397167206




 12%|█▏        | 11905/100000 [15:50<1:57:10, 12.53it/s]
epoch 11900  training loss: 0.4741881787776947




 12%|█▏        | 12005/100000 [15:58<1:57:52, 12.44it/s]
epoch 12000  training loss: 0.4124912917613983
epoch 12000  clean testing loss: 0.3337150812149048




 12%|█▏        | 12107/100000 [16:06<1:56:45, 12.55it/s]
epoch 12100  training loss: 0.41011562943458557




 12%|█▏        | 12207/100000 [16:14<1:56:48, 12.53it/s]
epoch 12200  training loss: 0.40594482421875




 12%|█▏        | 12307/100000 [16:22<1:56:36, 12.53it/s]
epoch 12300  training loss: 0.397208571434021




 12%|█▏        | 12407/100000 [16:30<1:56:24, 12.54it/s]
epoch 12400  training loss: 0.3940056562423706




 13%|█▎        | 12509/100000 [16:38<1:56:10, 12.55it/s]
epoch 12500  training loss: 0.6252385377883911




 13%|█▎        | 12609/100000 [16:46<1:55:59, 12.56it/s]
epoch 12600  training loss: 0.4205577075481415




 13%|█▎        | 12709/100000 [16:54<1:55:54, 12.55it/s]
epoch 12700  training loss: 0.40679681301116943




 13%|█▎        | 12809/100000 [17:02<1:55:49, 12.55it/s]
epoch 12800  training loss: 0.3871176838874817




 13%|█▎        | 12911/100000 [17:10<1:55:33, 12.56it/s]
epoch 12900  training loss: 0.3779444098472595




 13%|█▎        | 13011/100000 [17:18<1:55:48, 12.52it/s]
epoch 13000  training loss: 0.36490949988365173
epoch 13000  clean testing loss: 0.2954348623752594




 13%|█▎        | 13111/100000 [17:26<1:55:28, 12.54it/s]
epoch 13100  training loss: 0.4063343107700348




 13%|█▎        | 13211/100000 [17:34<1:55:13, 12.55it/s]
epoch 13200  training loss: 0.38955622911453247




 13%|█▎        | 13311/100000 [17:42<1:55:08, 12.55it/s]
epoch 13300  training loss: 0.36763525009155273




 13%|█▎        | 13413/100000 [17:50<1:54:53, 12.56it/s]
epoch 13400  training loss: 0.36143720149993896




 14%|█▎        | 13513/100000 [17:58<1:55:17, 12.50it/s]
epoch 13500  training loss: 0.36336222290992737




 14%|█▎        | 13613/100000 [18:06<1:54:38, 12.56it/s]
epoch 13600  training loss: 0.36550337076187134




 14%|█▎        | 13715/100000 [18:14<1:54:28, 12.56it/s]
epoch 13700  training loss: 0.3575367033481598




 14%|█▍        | 13815/100000 [18:22<1:54:30, 12.54it/s]
epoch 13800  training loss: 0.3635110855102539




 14%|█▍        | 13915/100000 [18:30<1:54:15, 12.56it/s]
epoch 13900  training loss: 0.35199832916259766




 14%|█▍        | 14015/100000 [18:38<1:54:10, 12.55it/s]
epoch 14000  training loss: 0.37785419821739197
epoch 14000  clean testing loss: 0.2958584427833557




 14%|█▍        | 14117/100000 [18:47<1:54:00, 12.56it/s]
epoch 14100  training loss: 0.5191327929496765




 14%|█▍        | 14217/100000 [18:55<1:53:50, 12.56it/s]
epoch 14200  training loss: 0.3403488099575043




 14%|█▍        | 14317/100000 [19:03<1:53:41, 12.56it/s]
epoch 14300  training loss: 0.37575656175613403




 14%|█▍        | 14417/100000 [19:10<1:53:37, 12.55it/s]
epoch 14400  training loss: 0.35781967639923096




 15%|█▍        | 14519/100000 [19:19<1:53:22, 12.57it/s]
epoch 14500  training loss: 0.5681353211402893




 15%|█▍        | 14619/100000 [19:27<1:53:20, 12.56it/s]
epoch 14600  training loss: 0.33319154381752014




 15%|█▍        | 14719/100000 [19:35<1:53:11, 12.56it/s]
epoch 14700  training loss: 0.3376676142215729




 15%|█▍        | 14821/100000 [19:43<1:53:03, 12.56it/s]
epoch 14800  training loss: 0.3324867784976959




 15%|█▍        | 14921/100000 [19:51<1:52:57, 12.55it/s]
epoch 14900  training loss: 0.3921957314014435




 15%|█▌        | 15021/100000 [19:59<1:53:40, 12.46it/s]
epoch 15000  training loss: 0.32984206080436707
epoch 15000  clean testing loss: 0.25593823194503784




 15%|█▌        | 15121/100000 [20:07<1:52:39, 12.56it/s]
epoch 15100  training loss: 0.32467347383499146




 15%|█▌        | 15223/100000 [20:15<1:52:25, 12.57it/s]
epoch 15200  training loss: 0.3205506205558777




 15%|█▌        | 15317/100000 [20:22<1:52:33, 12.54it/s]
epoch 15300  training loss: 0.3141477108001709




 15%|█▌        | 15417/100000 [20:30<1:52:34, 12.52it/s]
epoch 15400  training loss: 0.30799275636672974




 16%|█▌        | 15517/100000 [20:38<1:52:05, 12.56it/s]
epoch 15500  training loss: 0.3465801775455475




 16%|█▌        | 15617/100000 [20:46<1:52:11, 12.54it/s]
epoch 15600  training loss: 0.35524049401283264




 16%|█▌        | 15719/100000 [20:54<1:51:47, 12.57it/s]
epoch 15700  training loss: 0.3731953799724579




 16%|█▌        | 15819/100000 [21:02<1:51:44, 12.56it/s]
epoch 15800  training loss: 0.9036992192268372



 16%|█▌        | 15895/100000 [21:08<1:51:37, 12.56it/s]
epoch 15900  training loss: 0.2955799698829651




 16%|█▌        | 15995/100000 [21:16<1:51:32, 12.55it/s]
epoch 16000  training loss: 0.30149754881858826
epoch 16000  clean testing loss: 0.2512679994106293




 16%|█▌        | 16095/100000 [21:24<1:51:17, 12.56it/s]
epoch 16100  training loss: 0.3005843162536621




 16%|█▌        | 16195/100000 [21:32<1:51:26, 12.53it/s]
epoch 16200  training loss: 0.3164188265800476




 16%|█▋        | 16297/100000 [21:40<1:51:00, 12.57it/s]
epoch 16300  training loss: 0.2955569326877594




 16%|█▋        | 16397/100000 [21:48<1:51:04, 12.55it/s]
epoch 16400  training loss: 0.44820722937583923




 16%|█▋        | 16497/100000 [21:56<1:50:57, 12.54it/s]
epoch 16500  training loss: 0.285099595785141




 17%|█▋        | 16597/100000 [22:04<1:50:39, 12.56it/s]
epoch 16600  training loss: 0.3522172272205353




 17%|█▋        | 16699/100000 [22:12<1:50:32, 12.56it/s]
epoch 16700  training loss: 0.2781519889831543




 17%|█▋        | 16799/100000 [22:20<1:50:21, 12.57it/s]
epoch 16800  training loss: 0.2841523587703705




 17%|█▋        | 16899/100000 [22:28<1:56:38, 11.87it/s]
epoch 16900  training loss: 0.2827536463737488




 17%|█▋        | 16999/100000 [22:36<1:50:13, 12.55it/s]
epoch 17000  training loss: 0.27871957421302795
epoch 17000  clean testing loss: 0.20060712099075317




 17%|█▋        | 17101/100000 [22:45<1:50:02, 12.56it/s]
epoch 17100  training loss: 0.28062453866004944




 17%|█▋        | 17201/100000 [22:52<1:49:55, 12.55it/s]
epoch 17200  training loss: 0.2720700204372406




 17%|█▋        | 17301/100000 [23:00<1:49:53, 12.54it/s]
epoch 17300  training loss: 0.2697478234767914




 17%|█▋        | 17401/100000 [23:08<1:49:40, 12.55it/s]
epoch 17400  training loss: 0.29766830801963806




 18%|█▊        | 17503/100000 [23:17<1:49:47, 12.52it/s]
epoch 17500  training loss: 0.27564045786857605




 18%|█▊        | 17603/100000 [23:25<1:49:28, 12.55it/s]
epoch 17600  training loss: 0.8667884469032288




 18%|█▊        | 17703/100000 [23:33<1:49:30, 12.53it/s]
epoch 17700  training loss: 0.2492659091949463




 18%|█▊        | 17803/100000 [23:40<1:49:20, 12.53it/s]
epoch 17800  training loss: 0.2472640872001648




 18%|█▊        | 17905/100000 [23:49<1:49:12, 12.53it/s]
epoch 17900  training loss: 0.24900804460048676




 18%|█▊        | 18005/100000 [23:57<1:49:38, 12.46it/s]
epoch 18000  training loss: 0.24997182190418243
epoch 18000  clean testing loss: 0.17285087704658508




 18%|█▊        | 18105/100000 [24:05<1:48:53, 12.53it/s]
epoch 18100  training loss: 0.24911782145500183




 18%|█▊        | 18205/100000 [24:13<1:48:50, 12.53it/s]
epoch 18200  training loss: 0.2326720952987671




 18%|█▊        | 18307/100000 [24:21<1:48:30, 12.55it/s]
epoch 18300  training loss: 0.23288871347904205




 18%|█▊        | 18407/100000 [24:29<1:48:24, 12.54it/s]
epoch 18400  training loss: 0.22736811637878418




 19%|█▊        | 18507/100000 [24:37<1:48:15, 12.55it/s]
epoch 18500  training loss: 0.3004171550273895




 19%|█▊        | 18607/100000 [24:45<1:48:09, 12.54it/s]
epoch 18600  training loss: 0.2906777858734131




 19%|█▊        | 18709/100000 [24:53<1:48:01, 12.54it/s]
epoch 18700  training loss: 0.24839729070663452




 19%|█▉        | 18809/100000 [25:01<1:48:26, 12.48it/s]
epoch 18800  training loss: 0.2151414006948471




 19%|█▉        | 18909/100000 [25:09<1:47:40, 12.55it/s]
epoch 18900  training loss: 0.31535518169403076




 19%|█▉        | 19009/100000 [25:17<1:47:47, 12.52it/s]
epoch 19000  training loss: 0.2104473114013672
epoch 19000  clean testing loss: 0.13263407349586487




 19%|█▉        | 19111/100000 [25:25<1:47:21, 12.56it/s]
epoch 19100  training loss: 0.21647655963897705




 19%|█▉        | 19211/100000 [25:33<1:47:15, 12.55it/s]
epoch 19200  training loss: 0.20230059325695038




 19%|█▉        | 19311/100000 [25:41<1:47:04, 12.56it/s]
epoch 19300  training loss: 0.21397468447685242




 19%|█▉        | 19411/100000 [25:49<1:47:03, 12.55it/s]
epoch 19400  training loss: 0.21057060360908508




 20%|█▉        | 19513/100000 [25:57<1:46:50, 12.56it/s]
epoch 19500  training loss: 0.2174750119447708




 20%|█▉        | 19613/100000 [26:05<1:46:44, 12.55it/s]
epoch 19600  training loss: 0.20361432433128357




 20%|█▉        | 19713/100000 [26:13<1:46:38, 12.55it/s]
epoch 19700  training loss: 0.19124801456928253




 20%|█▉        | 19813/100000 [26:21<1:46:24, 12.56it/s]
epoch 19800  training loss: 0.8798456788063049




 20%|█▉        | 19915/100000 [26:29<1:46:16, 12.56it/s]
epoch 19900  training loss: 0.2125149369239807




 20%|██        | 20015/100000 [26:37<1:46:16, 12.54it/s]
epoch 20000  training loss: 0.19451355934143066
epoch 20000  clean testing loss: 0.13061977922916412




 20%|██        | 20115/100000 [26:45<1:46:00, 12.56it/s]
epoch 20100  training loss: 0.20229923725128174




 20%|██        | 20215/100000 [26:53<1:45:54, 12.56it/s]
epoch 20200  training loss: 1.8550463914871216




 20%|██        | 20315/100000 [27:01<1:47:42, 12.33it/s]
epoch 20300  training loss: 0.19407953321933746




 20%|██        | 20417/100000 [27:09<1:45:33, 12.57it/s]
epoch 20400  training loss: 0.19462701678276062




 21%|██        | 20517/100000 [27:17<1:45:28, 12.56it/s]
epoch 20500  training loss: 0.18411336839199066




 21%|██        | 20617/100000 [27:25<1:45:18, 12.56it/s]
epoch 20600  training loss: 0.17431840300559998




 21%|██        | 20717/100000 [27:33<1:45:16, 12.55it/s]
epoch 20700  training loss: 0.18331092596054077




 21%|██        | 20819/100000 [27:41<1:45:01, 12.56it/s]
epoch 20800  training loss: 0.1721895933151245




 21%|██        | 20919/100000 [27:49<1:44:58, 12.56it/s]
epoch 20900  training loss: 0.9531695246696472




 21%|██        | 21019/100000 [27:57<1:44:49, 12.56it/s]
epoch 21000  training loss: 0.18202123045921326
epoch 21000  clean testing loss: 0.1024647057056427




 21%|██        | 21119/100000 [28:05<1:44:39, 12.56it/s]
epoch 21100  training loss: 0.17778189480304718




 21%|██        | 21219/100000 [28:13<1:44:39, 12.55it/s]
epoch 21200  training loss: 0.17402642965316772




 21%|██▏       | 21321/100000 [28:21<1:44:20, 12.57it/s]
epoch 21300  training loss: 0.17280851304531097




 21%|██▏       | 21421/100000 [28:29<1:44:17, 12.56it/s]
epoch 21400  training loss: 0.16120296716690063




 22%|██▏       | 21521/100000 [28:37<1:44:10, 12.55it/s]
epoch 21500  training loss: 0.16218602657318115




 22%|██▏       | 21621/100000 [28:45<1:43:56, 12.57it/s]
epoch 21600  training loss: 0.15845146775245667




 22%|██▏       | 21723/100000 [28:53<1:43:51, 12.56it/s]
epoch 21700  training loss: 0.1658880114555359




 22%|██▏       | 21823/100000 [29:01<1:51:52, 11.65it/s]
epoch 21800  training loss: 0.16980409622192383




 22%|██▏       | 21923/100000 [29:09<1:43:34, 12.56it/s]
epoch 21900  training loss: 0.15518608689308167




 22%|██▏       | 22023/100000 [29:17<1:43:25, 12.57it/s]
epoch 22000  training loss: 0.16213317215442657
epoch 22000  clean testing loss: 0.07824747264385223




 22%|██▏       | 22123/100000 [29:25<1:43:19, 12.56it/s]
epoch 22100  training loss: 0.15372496843338013




 22%|██▏       | 22225/100000 [29:33<1:43:18, 12.55it/s]
epoch 22200  training loss: 0.18735727667808533




 22%|██▏       | 22325/100000 [29:41<1:43:04, 12.56it/s]
epoch 22300  training loss: 0.15951122343540192



 22%|██▏       | 22401/100000 [29:47<1:42:59, 12.56it/s]
epoch 22400  training loss: 0.1768868863582611




 23%|██▎       | 22501/100000 [29:55<1:42:52, 12.56it/s]
epoch 22500  training loss: 0.14483273029327393




 23%|██▎       | 22601/100000 [30:03<1:42:56, 12.53it/s]
epoch 22600  training loss: 0.2747063934803009




 23%|██▎       | 22701/100000 [30:11<1:42:35, 12.56it/s]
epoch 22700  training loss: 0.15749529004096985




 23%|██▎       | 22803/100000 [30:19<1:42:42, 12.53it/s]
epoch 22800  training loss: 0.1536024808883667




 23%|██▎       | 22897/100000 [30:27<1:42:21, 12.55it/s]
epoch 22900  training loss: 0.14232634007930756




 23%|██▎       | 22997/100000 [30:35<1:42:08, 12.57it/s]
epoch 23000  training loss: 0.14321647584438324
epoch 23000  clean testing loss: 0.0655117779970169




 23%|██▎       | 23097/100000 [30:43<1:42:06, 12.55it/s]
epoch 23100  training loss: 0.14562782645225525




 23%|██▎       | 23197/100000 [30:51<1:41:53, 12.56it/s]
epoch 23200  training loss: 0.14525799453258514




 23%|██▎       | 23299/100000 [30:59<1:41:41, 12.57it/s]
epoch 23300  training loss: 0.1446555107831955




 23%|██▎       | 23399/100000 [31:07<1:41:34, 12.57it/s]
epoch 23400  training loss: 0.1494775414466858




 23%|██▎       | 23499/100000 [31:15<1:41:28, 12.56it/s]
epoch 23500  training loss: 0.1602889597415924




 24%|██▎       | 23599/100000 [31:23<1:41:26, 12.55it/s]
epoch 23600  training loss: 0.14679381251335144




 24%|██▎       | 23701/100000 [31:31<1:41:19, 12.55it/s]
epoch 23700  training loss: 0.13838154077529907




 24%|██▍       | 23801/100000 [31:39<1:41:06, 12.56it/s]
epoch 23800  training loss: 0.13341084122657776




 24%|██▍       | 23901/100000 [31:47<1:40:59, 12.56it/s]
epoch 23900  training loss: 0.1374516636133194




 24%|██▍       | 24001/100000 [31:55<1:42:15, 12.39it/s]
epoch 24000  training loss: 0.13303087651729584
epoch 24000  clean testing loss: 0.05621523782610893




 24%|██▍       | 24101/100000 [32:03<1:42:06, 12.39it/s]
epoch 24100  training loss: 0.12881508469581604




 24%|██▍       | 24203/100000 [32:11<1:40:52, 12.52it/s]
epoch 24200  training loss: 0.12770064175128937




 24%|██▍       | 24303/100000 [32:19<1:40:42, 12.53it/s]
epoch 24300  training loss: 0.1299099326133728




 24%|██▍       | 24403/100000 [32:27<1:40:27, 12.54it/s]
epoch 24400  training loss: 0.13204072415828705




 25%|██▍       | 24503/100000 [32:35<1:40:31, 12.52it/s]
epoch 24500  training loss: 0.12514646351337433




 25%|██▍       | 24605/100000 [32:43<1:40:16, 12.53it/s]
epoch 24600  training loss: 0.14566855132579803




 25%|██▍       | 24705/100000 [32:51<1:40:05, 12.54it/s]
epoch 24700  training loss: 0.12765271961688995




 25%|██▍       | 24805/100000 [32:59<1:39:57, 12.54it/s]
epoch 24800  training loss: 0.13791479170322418




 25%|██▍       | 24905/100000 [33:07<1:39:48, 12.54it/s]
epoch 24900  training loss: 0.12210763990879059




 25%|██▌       | 25007/100000 [33:15<1:40:03, 12.49it/s]
epoch 25000  training loss: 0.12327465415000916
epoch 25000  clean testing loss: 0.04700467362999916




 25%|██▌       | 25107/100000 [33:23<1:39:31, 12.54it/s]
epoch 25100  training loss: 0.12518179416656494




 25%|██▌       | 25207/100000 [33:31<1:39:17, 12.55it/s]
epoch 25200  training loss: 0.23416322469711304




 25%|██▌       | 25307/100000 [33:39<1:39:11, 12.55it/s]
epoch 25300  training loss: 0.12224793434143066




 25%|██▌       | 25409/100000 [33:47<1:39:01, 12.55it/s]
epoch 25400  training loss: 0.15763866901397705




 26%|██▌       | 25509/100000 [33:55<1:38:53, 12.55it/s]
epoch 25500  training loss: 0.12532809376716614




 26%|██▌       | 25609/100000 [34:03<1:42:04, 12.15it/s]
epoch 25600  training loss: 0.12102238833904266




 26%|██▌       | 25709/100000 [34:11<1:38:39, 12.55it/s]
epoch 25700  training loss: 0.12249875068664551




 26%|██▌       | 25811/100000 [34:19<1:38:26, 12.56it/s]
epoch 25800  training loss: 0.12983225286006927




 26%|██▌       | 25911/100000 [34:27<1:38:17, 12.56it/s]
epoch 25900  training loss: 0.11944250017404556




 26%|██▌       | 26011/100000 [34:35<1:38:26, 12.53it/s]
epoch 26000  training loss: 0.5647154450416565
epoch 26000  clean testing loss: 0.520357608795166




 26%|██▌       | 26111/100000 [34:43<1:38:03, 12.56it/s]
epoch 26100  training loss: 0.12037654966115952




 26%|██▌       | 26213/100000 [34:51<1:37:56, 12.56it/s]
epoch 26200  training loss: 0.13028793036937714




 26%|██▋       | 26313/100000 [34:59<1:37:49, 12.55it/s]
epoch 26300  training loss: 0.1186763271689415




 26%|██▋       | 26413/100000 [35:07<1:37:38, 12.56it/s]
epoch 26400  training loss: 0.1193074956536293




 27%|██▋       | 26513/100000 [35:15<1:37:30, 12.56it/s]
epoch 26500  training loss: 0.12871721386909485




 27%|██▋       | 26615/100000 [35:23<1:37:31, 12.54it/s]
epoch 26600  training loss: 0.14567327499389648




 27%|██▋       | 26715/100000 [35:31<1:37:23, 12.54it/s]
epoch 26700  training loss: 0.1183282658457756




 27%|██▋       | 26815/100000 [35:39<1:37:05, 12.56it/s]
epoch 26800  training loss: 0.11603967100381851




 27%|██▋       | 26915/100000 [35:47<1:36:56, 12.57it/s]
epoch 26900  training loss: 0.11334074288606644




 27%|██▋       | 27017/100000 [35:55<1:36:55, 12.55it/s]
epoch 27000  training loss: 0.11743680387735367
epoch 27000  clean testing loss: 0.039425354450941086




 27%|██▋       | 27117/100000 [36:04<1:41:57, 11.91it/s]
epoch 27100  training loss: 0.1131725087761879




 27%|██▋       | 27217/100000 [36:11<1:36:44, 12.54it/s]
epoch 27200  training loss: 0.11496350169181824




 27%|██▋       | 27317/100000 [36:19<1:36:31, 12.55it/s]
epoch 27300  training loss: 0.1138671338558197




 27%|██▋       | 27419/100000 [36:28<1:36:23, 12.55it/s]
epoch 27400  training loss: 0.11291540414094925




 28%|██▊       | 27519/100000 [36:36<1:36:30, 12.52it/s]
epoch 27500  training loss: 0.11492285132408142




 28%|██▊       | 27619/100000 [36:44<1:36:13, 12.54it/s]
epoch 27600  training loss: 0.11708910763263702




 28%|██▊       | 27719/100000 [36:52<1:35:53, 12.56it/s]
epoch 27700  training loss: 0.2669200003147125




 28%|██▊       | 27821/100000 [37:00<1:35:52, 12.55it/s]
epoch 27800  training loss: 0.11825473606586456




 28%|██▊       | 27921/100000 [37:08<1:35:38, 12.56it/s]
epoch 27900  training loss: 0.11608566343784332




 28%|██▊       | 28021/100000 [37:16<1:35:29, 12.56it/s]
epoch 28000  training loss: 0.11353793740272522
epoch 28000  clean testing loss: 0.03411344438791275




 28%|██▊       | 28121/100000 [37:24<1:35:26, 12.55it/s]
epoch 28100  training loss: 0.11109186708927155




 28%|██▊       | 28221/100000 [37:32<1:35:18, 12.55it/s]
epoch 28200  training loss: 0.11065265536308289




 28%|██▊       | 28321/100000 [37:40<1:35:05, 12.56it/s]
epoch 28300  training loss: 0.10905365645885468




 28%|██▊       | 28423/100000 [37:48<1:35:04, 12.55it/s]
epoch 28400  training loss: 0.11850698292255402




 29%|██▊       | 28523/100000 [37:56<1:34:49, 12.56it/s]
epoch 28500  training loss: 0.11713062226772308




 29%|██▊       | 28623/100000 [38:04<1:34:40, 12.56it/s]
epoch 28600  training loss: 0.1237931102514267




 29%|██▊       | 28725/100000 [38:12<1:34:30, 12.57it/s]
epoch 28700  training loss: 0.11906281113624573




 29%|██▉       | 28825/100000 [38:20<1:34:27, 12.56it/s]
epoch 28800  training loss: 0.11553085595369339



 29%|██▉       | 28899/100000 [38:26<1:34:46, 12.50it/s]
epoch 28900  training loss: 0.1904037594795227




 29%|██▉       | 29001/100000 [38:34<1:35:30, 12.39it/s]
epoch 29000  training loss: 0.11014050245285034
epoch 29000  clean testing loss: 0.031196199357509613




 29%|██▉       | 29101/100000 [38:42<1:34:08, 12.55it/s]
epoch 29100  training loss: 0.1159970760345459




 29%|██▉       | 29201/100000 [38:50<1:34:01, 12.55it/s]
epoch 29200  training loss: 0.11011410504579544




 29%|██▉       | 29301/100000 [38:58<1:33:50, 12.56it/s]
epoch 29300  training loss: 0.149680957198143




 29%|██▉       | 29401/100000 [39:06<1:34:01, 12.51it/s]
epoch 29400  training loss: 0.10586729645729065




 30%|██▉       | 29503/100000 [39:14<1:33:47, 12.53it/s]
epoch 29500  training loss: 0.11057629436254501




 30%|██▉       | 29603/100000 [39:22<1:33:52, 12.50it/s]
epoch 29600  training loss: 0.10597240924835205




 30%|██▉       | 29703/100000 [39:30<1:33:34, 12.52it/s]
epoch 29700  training loss: 0.11401325464248657




 30%|██▉       | 29803/100000 [39:38<1:33:20, 12.53it/s]
epoch 29800  training loss: 0.11078286170959473




 30%|██▉       | 29905/100000 [39:46<1:33:11, 12.54it/s]
epoch 29900  training loss: 0.1357542872428894




 30%|███       | 30005/100000 [39:54<1:33:29, 12.48it/s]
epoch 30000  training loss: 0.11181901395320892
epoch 30000  clean testing loss: 0.03175072371959686




 30%|███       | 30105/100000 [40:02<1:32:57, 12.53it/s]
epoch 30100  training loss: 0.10856061428785324




 30%|███       | 30207/100000 [40:10<1:32:43, 12.54it/s]
epoch 30200  training loss: 0.10580922663211823




 30%|███       | 30301/100000 [40:17<1:32:30, 12.56it/s]
epoch 30300  training loss: 0.10538049042224884




 30%|███       | 30401/100000 [40:25<1:32:51, 12.49it/s]
epoch 30400  training loss: 0.10567785054445267




 31%|███       | 30501/100000 [40:33<1:32:14, 12.56it/s]
epoch 30500  training loss: 0.10589534789323807




 31%|███       | 30601/100000 [40:41<1:32:02, 12.57it/s]
epoch 30600  training loss: 0.10532637685537338




 31%|███       | 30703/100000 [40:50<1:32:16, 12.52it/s]
epoch 30700  training loss: 0.10408470034599304




 31%|███       | 30803/100000 [40:58<1:32:03, 12.53it/s]
epoch 30800  training loss: 0.24564726650714874




 31%|███       | 30903/100000 [41:06<1:33:43, 12.29it/s]
epoch 30900  training loss: 0.10804955661296844




 31%|███       | 31003/100000 [41:13<1:32:29, 12.43it/s]
epoch 31000  training loss: 0.10527362674474716
epoch 31000  clean testing loss: 0.026113400235772133




 31%|███       | 31105/100000 [41:22<1:31:39, 12.53it/s]
epoch 31100  training loss: 0.13001330196857452




 31%|███       | 31205/100000 [41:30<1:31:26, 12.54it/s]
epoch 31200  training loss: 0.10781335085630417




 31%|███▏      | 31305/100000 [41:38<1:31:21, 12.53it/s]
epoch 31300  training loss: 0.27623504400253296




 31%|███▏      | 31405/100000 [41:46<1:31:09, 12.54it/s]
epoch 31400  training loss: 0.10402092337608337




 32%|███▏      | 31507/100000 [41:54<1:31:07, 12.53it/s]
epoch 31500  training loss: 0.10439994931221008




 32%|███▏      | 31607/100000 [42:02<1:30:51, 12.55it/s]
epoch 31600  training loss: 0.10204368829727173




 32%|███▏      | 31707/100000 [42:10<1:30:44, 12.54it/s]
epoch 31700  training loss: 0.10546606034040451




 32%|███▏      | 31807/100000 [42:18<1:30:38, 12.54it/s]
epoch 31800  training loss: 0.10257204622030258




 32%|███▏      | 31909/100000 [42:26<1:30:24, 12.55it/s]
epoch 31900  training loss: 0.29187434911727905




 32%|███▏      | 32009/100000 [42:34<1:30:31, 12.52it/s]
epoch 32000  training loss: 0.10346048325300217
epoch 32000  clean testing loss: 0.02349460870027542




 32%|███▏      | 32109/100000 [42:42<1:30:10, 12.55it/s]
epoch 32100  training loss: 0.10541041940450668




 32%|███▏      | 32209/100000 [42:50<1:30:05, 12.54it/s]
epoch 32200  training loss: 0.10379994660615921




 32%|███▏      | 32309/100000 [42:58<1:29:54, 12.55it/s]
epoch 32300  training loss: 0.11164616048336029




 32%|███▏      | 32411/100000 [43:06<1:32:57, 12.12it/s]
epoch 32400  training loss: 0.1038389652967453




 33%|███▎      | 32511/100000 [43:14<1:29:40, 12.54it/s]
epoch 32500  training loss: 0.25270503759384155




 33%|███▎      | 32611/100000 [43:22<1:29:36, 12.54it/s]
epoch 32600  training loss: 0.10570457577705383




 33%|███▎      | 32713/100000 [43:30<1:29:24, 12.54it/s]
epoch 32700  training loss: 0.1199953481554985




 33%|███▎      | 32813/100000 [43:38<1:29:12, 12.55it/s]
epoch 32800  training loss: 0.10458154231309891




 33%|███▎      | 32913/100000 [43:46<1:29:05, 12.55it/s]
epoch 32900  training loss: 0.11063958704471588




 33%|███▎      | 33013/100000 [43:54<1:29:07, 12.53it/s]
epoch 33000  training loss: 0.10061245411634445
epoch 33000  clean testing loss: 0.02209760621190071




 33%|███▎      | 33115/100000 [44:02<1:28:50, 12.55it/s]
epoch 33100  training loss: 0.10018862038850784




 33%|███▎      | 33215/100000 [44:10<1:28:37, 12.56it/s]
epoch 33200  training loss: 0.10093583911657333




 33%|███▎      | 33315/100000 [44:18<1:28:33, 12.55it/s]
epoch 33300  training loss: 0.1037135124206543




 33%|███▎      | 33415/100000 [44:26<1:28:30, 12.54it/s]
epoch 33400  training loss: 0.10036846995353699




 34%|███▎      | 33517/100000 [44:34<1:28:15, 12.55it/s]
epoch 33500  training loss: 0.10294967889785767




 34%|███▎      | 33617/100000 [44:42<1:28:04, 12.56it/s]
epoch 33600  training loss: 0.10177085548639297




 34%|███▎      | 33717/100000 [44:50<1:28:10, 12.53it/s]
epoch 33700  training loss: 0.10797244310379028




 34%|███▍      | 33817/100000 [44:58<1:27:49, 12.56it/s]
epoch 33800  training loss: 0.10049836337566376




 34%|███▍      | 33917/100000 [45:06<1:27:39, 12.56it/s]
epoch 33900  training loss: 0.10276582092046738




 34%|███▍      | 34019/100000 [45:14<1:27:34, 12.56it/s]
epoch 34000  training loss: 0.12546120584011078
epoch 34000  clean testing loss: 0.026691453531384468




 34%|███▍      | 34119/100000 [45:22<1:27:24, 12.56it/s]
epoch 34100  training loss: 0.10142046958208084




 34%|███▍      | 34219/100000 [45:30<1:27:17, 12.56it/s]
epoch 34200  training loss: 0.10037440061569214




 34%|███▍      | 34319/100000 [45:38<1:27:17, 12.54it/s]
epoch 34300  training loss: 0.12079594284296036




 34%|███▍      | 34421/100000 [45:46<1:27:00, 12.56it/s]
epoch 34400  training loss: 0.09963003545999527




 35%|███▍      | 34521/100000 [45:54<1:26:51, 12.56it/s]
epoch 34500  training loss: 0.10166258364915848




 35%|███▍      | 34621/100000 [46:02<1:26:44, 12.56it/s]
epoch 34600  training loss: 0.1877560019493103




 35%|███▍      | 34721/100000 [46:10<1:26:34, 12.57it/s]
epoch 34700  training loss: 0.09927306324243546




 35%|███▍      | 34823/100000 [46:18<1:26:28, 12.56it/s]
epoch 34800  training loss: 0.0992044135928154




 35%|███▍      | 34923/100000 [46:26<1:26:28, 12.54it/s]
epoch 34900  training loss: 0.104072704911232




 35%|███▌      | 35023/100000 [46:34<1:26:15, 12.55it/s]
epoch 35000  training loss: 0.09784119576215744
epoch 35000  clean testing loss: 0.019737841561436653




 35%|███▌      | 35123/100000 [46:42<1:26:03, 12.57it/s]
epoch 35100  training loss: 0.10350927710533142




 35%|███▌      | 35225/100000 [46:50<1:25:57, 12.56it/s]
epoch 35200  training loss: 0.09776511788368225




 35%|███▌      | 35325/100000 [46:58<1:25:47, 12.56it/s]
epoch 35300  training loss: 0.10139815509319305



 35%|███▌      | 35401/100000 [47:04<1:25:44, 12.56it/s]
epoch 35400  training loss: 0.0978550910949707




 36%|███▌      | 35501/100000 [47:12<1:25:36, 12.56it/s]
epoch 35500  training loss: 0.09786197543144226




 36%|███▌      | 35601/100000 [47:20<1:25:31, 12.55it/s]
epoch 35600  training loss: 0.10167110711336136




 36%|███▌      | 35701/100000 [47:28<1:25:21, 12.55it/s]
epoch 35700  training loss: 0.0986185297369957




 36%|███▌      | 35803/100000 [47:36<1:25:26, 12.52it/s]
epoch 35800  training loss: 0.09937015920877457




 36%|███▌      | 35903/100000 [47:44<1:25:17, 12.52it/s]
epoch 35900  training loss: 0.09901956468820572




 36%|███▌      | 36003/100000 [47:52<1:25:47, 12.43it/s]
epoch 36000  training loss: 0.10576565563678741
epoch 36000  clean testing loss: 0.0218541007488966




 36%|███▌      | 36103/100000 [48:00<1:25:01, 12.53it/s]
epoch 36100  training loss: 0.09831741452217102




 36%|███▌      | 36203/100000 [48:08<1:25:23, 12.45it/s]
epoch 36200  training loss: 0.09654958546161652




 36%|███▋      | 36305/100000 [48:16<1:24:40, 12.54it/s]
epoch 36300  training loss: 0.09788162261247635




 36%|███▋      | 36405/100000 [48:24<1:24:39, 12.52it/s]
epoch 36400  training loss: 0.09883377701044083




 37%|███▋      | 36505/100000 [48:32<1:24:27, 12.53it/s]
epoch 36500  training loss: 0.09875383228063583




 37%|███▋      | 36605/100000 [48:40<1:24:18, 12.53it/s]
epoch 36600  training loss: 0.0979890450835228




 37%|███▋      | 36707/100000 [48:48<1:24:05, 12.54it/s]
epoch 36700  training loss: 0.09668032824993134




 37%|███▋      | 36807/100000 [48:56<1:23:57, 12.54it/s]
epoch 36800  training loss: 0.09646718204021454




 37%|███▋      | 36901/100000 [49:04<1:23:45, 12.56it/s]
epoch 36900  training loss: 0.10186917334794998




 37%|███▋      | 37001/100000 [49:12<1:24:47, 12.38it/s]
epoch 37000  training loss: 0.10112863779067993
epoch 37000  clean testing loss: 0.019329022616147995




 37%|███▋      | 37101/100000 [49:20<1:23:28, 12.56it/s]
epoch 37100  training loss: 0.09798482060432434




 37%|███▋      | 37203/100000 [49:28<1:23:35, 12.52it/s]
epoch 37200  training loss: 0.0983586311340332




 37%|███▋      | 37303/100000 [49:36<1:23:28, 12.52it/s]
epoch 37300  training loss: 0.09969798475503922




 37%|███▋      | 37403/100000 [49:44<1:23:21, 12.52it/s]
epoch 37400  training loss: 0.09969164431095123




 38%|███▊      | 37505/100000 [49:52<1:23:07, 12.53it/s]
epoch 37500  training loss: 0.09732011705636978




 38%|███▊      | 37605/100000 [50:00<1:22:58, 12.53it/s]
epoch 37600  training loss: 0.1739635318517685




 38%|███▊      | 37705/100000 [50:08<1:24:56, 12.22it/s]
epoch 37700  training loss: 0.09817203134298325




 38%|███▊      | 37805/100000 [50:16<1:22:35, 12.55it/s]
epoch 37800  training loss: 0.09759107232093811




 38%|███▊      | 37907/100000 [50:24<1:22:37, 12.52it/s]
epoch 37900  training loss: 0.10410768538713455




 38%|███▊      | 38007/100000 [50:32<1:22:43, 12.49it/s]
epoch 38000  training loss: 0.09707999229431152
epoch 38000  clean testing loss: 0.017987264320254326




 38%|███▊      | 38107/100000 [50:40<1:22:20, 12.53it/s]
epoch 38100  training loss: 0.09844407439231873




 38%|███▊      | 38207/100000 [50:48<1:22:11, 12.53it/s]
epoch 38200  training loss: 0.09635704010725021




 38%|███▊      | 38309/100000 [50:56<1:21:56, 12.55it/s]
epoch 38300  training loss: 0.09710003435611725




 38%|███▊      | 38409/100000 [51:04<1:21:50, 12.54it/s]
epoch 38400  training loss: 0.0994054451584816




 39%|███▊      | 38509/100000 [51:12<1:21:39, 12.55it/s]
epoch 38500  training loss: 0.09874457865953445




 39%|███▊      | 38609/100000 [51:20<1:21:38, 12.53it/s]
epoch 38600  training loss: 0.0960720032453537




 39%|███▊      | 38711/100000 [51:28<1:21:25, 12.54it/s]
epoch 38700  training loss: 0.12452328950166702




 39%|███▉      | 38811/100000 [51:36<1:21:21, 12.54it/s]
epoch 38800  training loss: 0.09637417644262314




 39%|███▉      | 38911/100000 [51:44<1:21:09, 12.55it/s]
epoch 38900  training loss: 0.09882348030805588




 39%|███▉      | 39011/100000 [51:52<1:21:06, 12.53it/s]
epoch 39000  training loss: 0.09625256806612015
epoch 39000  clean testing loss: 0.017773065716028214




 39%|███▉      | 39113/100000 [52:00<1:20:48, 12.56it/s]
epoch 39100  training loss: 0.09746285527944565




 39%|███▉      | 39213/100000 [52:08<1:25:15, 11.88it/s]
epoch 39200  training loss: 0.09629713743925095




 39%|███▉      | 39313/100000 [52:16<1:20:35, 12.55it/s]
epoch 39300  training loss: 0.09851033985614777




 39%|███▉      | 39413/100000 [52:24<1:20:35, 12.53it/s]
epoch 39400  training loss: 0.09744967520236969




 40%|███▉      | 39515/100000 [52:32<1:20:17, 12.55it/s]
epoch 39500  training loss: 0.09570488333702087




 40%|███▉      | 39615/100000 [52:40<1:20:14, 12.54it/s]
epoch 39600  training loss: 0.09529831260442734




 40%|███▉      | 39715/100000 [52:48<1:19:58, 12.56it/s]
epoch 39700  training loss: 0.10976413637399673




 40%|███▉      | 39815/100000 [52:56<1:19:54, 12.55it/s]
epoch 39800  training loss: 0.09507621079683304




 40%|███▉      | 39917/100000 [53:04<1:19:43, 12.56it/s]
epoch 39900  training loss: 0.09499125927686691




 40%|████      | 40017/100000 [53:12<1:19:39, 12.55it/s]
epoch 40000  training loss: 0.09470833837985992
epoch 40000  clean testing loss: 0.017364773899316788




 40%|████      | 40117/100000 [53:20<1:19:27, 12.56it/s]
epoch 40100  training loss: 0.0944930762052536




 40%|████      | 40217/100000 [53:28<1:19:21, 12.56it/s]
epoch 40200  training loss: 0.09512315690517426




 40%|████      | 40319/100000 [53:37<1:19:11, 12.56it/s]
epoch 40300  training loss: 0.09533955156803131




 40%|████      | 40419/100000 [53:45<1:19:04, 12.56it/s]
epoch 40400  training loss: 0.09670625627040863




 41%|████      | 40519/100000 [53:53<1:18:58, 12.55it/s]
epoch 40500  training loss: 0.09526754170656204




 41%|████      | 40619/100000 [54:00<1:18:49, 12.56it/s]
epoch 40600  training loss: 0.0945977196097374




 41%|████      | 40721/100000 [54:09<1:18:40, 12.56it/s]
epoch 40700  training loss: 0.09477145969867706




 41%|████      | 40821/100000 [54:17<1:18:30, 12.56it/s]
epoch 40800  training loss: 0.0966014638543129




 41%|████      | 40921/100000 [54:25<1:18:28, 12.55it/s]
epoch 40900  training loss: 0.09753286093473434




 41%|████      | 41021/100000 [54:33<1:18:13, 12.56it/s]
epoch 41000  training loss: 0.09583798795938492
epoch 41000  clean testing loss: 0.01729852519929409



 41%|████      | 41097/100000 [54:39<1:18:07, 12.56it/s]
epoch 41100  training loss: 0.11941905319690704




 41%|████      | 41197/100000 [54:47<1:18:03, 12.56it/s]
epoch 41200  training loss: 0.09514445811510086




 41%|████▏     | 41297/100000 [54:55<1:17:53, 12.56it/s]
epoch 41300  training loss: 0.09682305157184601




 41%|████▏     | 41399/100000 [55:03<1:17:46, 12.56it/s]
epoch 41400  training loss: 0.09810155630111694




 41%|████▏     | 41499/100000 [55:11<1:18:05, 12.48it/s]
epoch 41500  training loss: 0.09791014343500137




 42%|████▏     | 41599/100000 [55:19<1:17:29, 12.56it/s]
epoch 41600  training loss: 0.1131780818104744




 42%|████▏     | 41699/100000 [55:27<1:17:23, 12.55it/s]
epoch 41700  training loss: 0.09809476137161255




 42%|████▏     | 41801/100000 [55:35<1:17:15, 12.56it/s]
epoch 41800  training loss: 0.09518849849700928




 42%|████▏     | 41901/100000 [55:43<1:17:10, 12.55it/s]
epoch 41900  training loss: 0.09791886061429977




 42%|████▏     | 42001/100000 [55:51<1:18:04, 12.38it/s]
epoch 42000  training loss: 0.09857629239559174
epoch 42000  clean testing loss: 0.01899293251335621




 42%|████▏     | 42101/100000 [55:59<1:16:53, 12.55it/s]
epoch 42100  training loss: 0.09623540937900543




 42%|████▏     | 42203/100000 [56:07<1:16:51, 12.53it/s]
epoch 42200  training loss: 0.09415774792432785




 42%|████▏     | 42303/100000 [56:15<1:16:46, 12.52it/s]
epoch 42300  training loss: 0.09418699890375137




 42%|████▏     | 42403/100000 [56:23<1:16:40, 12.52it/s]
epoch 42400  training loss: 0.0963364690542221




 43%|████▎     | 42505/100000 [56:31<1:16:26, 12.54it/s]
epoch 42500  training loss: 0.0979519784450531




 43%|████▎     | 42605/100000 [56:39<1:16:20, 12.53it/s]
epoch 42600  training loss: 0.09717552363872528




 43%|████▎     | 42705/100000 [56:47<1:16:11, 12.53it/s]
epoch 42700  training loss: 0.09548822045326233




 43%|████▎     | 42805/100000 [56:55<1:16:01, 12.54it/s]
epoch 42800  training loss: 0.09523126482963562




 43%|████▎     | 42907/100000 [57:03<1:15:52, 12.54it/s]
epoch 42900  training loss: 0.09532375633716583




 43%|████▎     | 43007/100000 [57:11<1:17:13, 12.30it/s]
epoch 43000  training loss: 0.09585955739021301
epoch 43000  clean testing loss: 0.01697693206369877




 43%|████▎     | 43107/100000 [57:19<1:15:34, 12.55it/s]
epoch 43100  training loss: 0.10109176486730576




 43%|████▎     | 43207/100000 [57:27<1:15:31, 12.53it/s]
epoch 43200  training loss: 0.09752246737480164




 43%|████▎     | 43309/100000 [57:35<1:15:18, 12.55it/s]
epoch 43300  training loss: 0.09728482365608215




 43%|████▎     | 43409/100000 [57:43<1:15:23, 12.51it/s]
epoch 43400  training loss: 0.09683620184659958




 44%|████▎     | 43509/100000 [57:51<1:15:03, 12.54it/s]
epoch 43500  training loss: 0.117738276720047




 44%|████▎     | 43609/100000 [57:59<1:14:54, 12.55it/s]
epoch 43600  training loss: 0.09514689445495605




 44%|████▎     | 43711/100000 [58:07<1:14:46, 12.55it/s]
epoch 43700  training loss: 0.09524905681610107




 44%|████▍     | 43811/100000 [58:15<1:14:36, 12.55it/s]
epoch 43800  training loss: 0.09426583349704742




 44%|████▍     | 43911/100000 [58:23<1:14:31, 12.54it/s]
epoch 43900  training loss: 0.09398560225963593




 44%|████▍     | 44011/100000 [58:31<1:14:33, 12.52it/s]
epoch 44000  training loss: 0.09390783309936523
epoch 44000  clean testing loss: 0.016623757779598236




 44%|████▍     | 44111/100000 [58:39<1:14:20, 12.53it/s]
epoch 44100  training loss: 0.0946781113743782




 44%|████▍     | 44211/100000 [58:47<1:14:03, 12.55it/s]
epoch 44200  training loss: 0.09521108865737915




 44%|████▍     | 44313/100000 [58:55<1:13:56, 12.55it/s]
epoch 44300  training loss: 0.09621193259954453




 44%|████▍     | 44407/100000 [59:03<1:13:53, 12.54it/s]
epoch 44400  training loss: 0.09395141154527664





 45%|████▍     | 44511/100000 [59:13<1:13:51, 12.52it/s]
epoch 44500  training loss: 0.09472040086984634




 45%|████▍     | 44611/100000 [59:21<1:13:30, 12.56it/s]
epoch 44600  training loss: 0.12518595159053802




 45%|████▍     | 44713/100000 [59:29<1:13:22, 12.56it/s]
epoch 44700  training loss: 0.09384140372276306




 45%|████▍     | 44813/100000 [59:37<1:13:13, 12.56it/s]
epoch 44800  training loss: 0.09468060731887817




 45%|████▍     | 44913/100000 [59:45<1:13:07, 12.56it/s]
epoch 44900  training loss: 0.09642467647790909




 45%|████▌     | 45013/100000 [59:53<1:13:03, 12.54it/s]
epoch 45000  training loss: 0.09379823505878448
epoch 45000  clean testing loss: 0.01720789074897766




 45%|████▌     | 45115/100000 [1:00:01<1:12:48, 12.56it/s]
epoch 45100  training loss: 0.09555304050445557




 45%|████▌     | 45215/100000 [1:00:09<1:12:41, 12.56it/s]
epoch 45200  training loss: 0.09593302756547928




 45%|████▌     | 45315/100000 [1:00:17<1:12:33, 12.56it/s]
epoch 45300  training loss: 0.09520605206489563




 45%|████▌     | 45415/100000 [1:00:25<1:12:32, 12.54it/s]
epoch 45400  training loss: 0.09558718651533127




 46%|████▌     | 45517/100000 [1:00:33<1:12:15, 12.57it/s]
epoch 45500  training loss: 0.09669084846973419




 46%|████▌     | 45617/100000 [1:00:41<1:12:07, 12.57it/s]
epoch 45600  training loss: 0.09533655643463135




 46%|████▌     | 45717/100000 [1:00:49<1:12:00, 12.56it/s]
epoch 45700  training loss: 0.09363502264022827




 46%|████▌     | 45817/100000 [1:00:57<1:11:55, 12.56it/s]
epoch 45800  training loss: 0.09638125449419022




 46%|████▌     | 45919/100000 [1:01:05<1:11:45, 12.56it/s]
epoch 45900  training loss: 0.09560560435056686




 46%|████▌     | 46019/100000 [1:01:13<1:12:32, 12.40it/s]
epoch 46000  training loss: 0.09527972340583801
epoch 46000  clean testing loss: 0.019213279709219933




 46%|████▌     | 46119/100000 [1:01:21<1:11:28, 12.57it/s]
epoch 46100  training loss: 0.09376965463161469




 46%|████▌     | 46219/100000 [1:01:29<1:11:22, 12.56it/s]
epoch 46200  training loss: 0.09949272871017456



 46%|████▋     | 46295/100000 [1:01:35<1:11:15, 12.56it/s]
epoch 46300  training loss: 0.09459459781646729




 46%|████▋     | 46395/100000 [1:01:43<1:12:16, 12.36it/s]
epoch 46400  training loss: 0.09325004369020462




 46%|████▋     | 46495/100000 [1:01:51<1:10:58, 12.56it/s]
epoch 46500  training loss: 0.09270615875720978




 47%|████▋     | 46597/100000 [1:01:59<1:10:53, 12.55it/s]
epoch 46600  training loss: 0.09364618360996246




 47%|████▋     | 46697/100000 [1:02:07<1:10:41, 12.57it/s]
epoch 46700  training loss: 0.09351347386837006




 47%|████▋     | 46797/100000 [1:02:15<1:10:32, 12.57it/s]
epoch 46800  training loss: 0.09508635103702545





 47%|████▋     | 46923/100000 [1:02:25<1:10:28, 12.55it/s]
epoch 46900  training loss: 0.09452597051858902




 47%|████▋     | 47023/100000 [1:02:33<1:10:16, 12.56it/s]
epoch 47000  training loss: 0.09286713600158691
epoch 47000  clean testing loss: 0.0172138512134552




 47%|████▋     | 47125/100000 [1:02:41<1:10:08, 12.56it/s]
epoch 47100  training loss: 0.09256812185049057




 47%|████▋     | 47225/100000 [1:02:49<1:10:02, 12.56it/s]
epoch 47200  training loss: 0.09408795088529587




 47%|████▋     | 47325/100000 [1:02:57<1:09:53, 12.56it/s]
epoch 47300  training loss: 0.10925065726041794




 47%|████▋     | 47411/100000 [1:03:05<1:18:37, 11.15it/s]
epoch 47400  training loss: 0.09458094090223312




 48%|████▊     | 47501/100000 [1:03:13<1:11:54, 12.17it/s]
epoch 47500  training loss: 0.09323933720588684




 48%|████▊     | 47601/100000 [1:03:21<1:09:36, 12.54it/s]
epoch 47600  training loss: 0.09514126926660538




 48%|████▊     | 47703/100000 [1:03:29<1:09:38, 12.52it/s]
epoch 47700  training loss: 0.09393160045146942




 48%|████▊     | 47803/100000 [1:03:37<1:09:27, 12.52it/s]
epoch 47800  training loss: 0.09652750939130783




 48%|████▊     | 47903/100000 [1:03:45<1:09:24, 12.51it/s]
epoch 47900  training loss: 0.09316954016685486




 48%|████▊     | 48003/100000 [1:03:53<1:09:52, 12.40it/s]
epoch 48000  training loss: 0.10841784626245499
epoch 48000  clean testing loss: 0.021724026650190353




 48%|████▊     | 48105/100000 [1:04:01<1:09:04, 12.52it/s]
epoch 48100  training loss: 0.09383007138967514




 48%|████▊     | 48205/100000 [1:04:09<1:08:53, 12.53it/s]
epoch 48200  training loss: 0.09435483813285828




 48%|████▊     | 48305/100000 [1:04:17<1:08:49, 12.52it/s]
epoch 48300  training loss: 0.09444915503263474




 48%|████▊     | 48405/100000 [1:04:25<1:08:42, 12.52it/s]
epoch 48400  training loss: 0.09437138587236404




 49%|████▊     | 48507/100000 [1:04:33<1:08:32, 12.52it/s]
epoch 48500  training loss: 0.09341326355934143




 49%|████▊     | 48607/100000 [1:04:41<1:08:22, 12.53it/s]
epoch 48600  training loss: 0.0945701152086258




 49%|████▊     | 48707/100000 [1:04:49<1:08:10, 12.54it/s]
epoch 48700  training loss: 0.0923350527882576




 49%|████▉     | 48807/100000 [1:04:57<1:08:08, 12.52it/s]
epoch 48800  training loss: 0.09361586719751358




 49%|████▉     | 48907/100000 [1:05:05<1:07:56, 12.53it/s]
epoch 48900  training loss: 0.09392649680376053




 49%|████▉     | 49007/100000 [1:05:13<1:12:51, 11.66it/s]
epoch 49000  training loss: 0.09208609163761139
epoch 49000  clean testing loss: 0.01645008474588394




 49%|████▉     | 49109/100000 [1:05:21<1:07:38, 12.54it/s]
epoch 49100  training loss: 0.09438014775514603




 49%|████▉     | 49209/100000 [1:05:29<1:07:33, 12.53it/s]
epoch 49200  training loss: 0.09324055165052414




 49%|████▉     | 49309/100000 [1:05:37<1:07:25, 12.53it/s]
epoch 49300  training loss: 0.09460017830133438




 49%|████▉     | 49409/100000 [1:05:45<1:07:19, 12.52it/s]
epoch 49400  training loss: 0.09688492119312286




 50%|████▉     | 49511/100000 [1:05:53<1:07:07, 12.54it/s]
epoch 49500  training loss: 0.09446581453084946




 50%|████▉     | 49611/100000 [1:06:01<1:07:01, 12.53it/s]
epoch 49600  training loss: 0.09594697505235672




 50%|████▉     | 49711/100000 [1:06:09<1:06:43, 12.56it/s]
epoch 49700  training loss: 0.09392763674259186




 50%|████▉     | 49811/100000 [1:06:17<1:06:34, 12.56it/s]
epoch 49800  training loss: 0.09392699599266052




 50%|████▉     | 49913/100000 [1:06:25<1:06:57, 12.47it/s]
epoch 49900  training loss: 0.09459821879863739




 50%|█████     | 50013/100000 [1:06:33<1:06:26, 12.54it/s]
epoch 50000  training loss: 0.0927751362323761
epoch 50000  clean testing loss: 0.01641845889389515




 50%|█████     | 50113/100000 [1:06:41<1:06:09, 12.57it/s]
epoch 50100  training loss: 0.09488166123628616




 50%|█████     | 50215/100000 [1:06:50<1:06:06, 12.55it/s]
epoch 50200  training loss: 0.10083165019750595




 50%|█████     | 50315/100000 [1:06:58<1:05:52, 12.57it/s]
epoch 50300  training loss: 0.0943145751953125




 50%|█████     | 50415/100000 [1:07:05<1:05:44, 12.57it/s]
epoch 50400  training loss: 0.09275447577238083




 51%|█████     | 50517/100000 [1:07:14<1:05:40, 12.56it/s]
epoch 50500  training loss: 0.0942440778017044




 51%|█████     | 50617/100000 [1:07:22<1:05:30, 12.56it/s]
epoch 50600  training loss: 0.0933821052312851




 51%|█████     | 50717/100000 [1:07:30<1:05:20, 12.57it/s]
epoch 50700  training loss: 0.09466137737035751




 51%|█████     | 50817/100000 [1:07:38<1:05:15, 12.56it/s]
epoch 50800  training loss: 0.09455709904432297




 51%|█████     | 50919/100000 [1:07:46<1:05:11, 12.55it/s]
epoch 50900  training loss: 0.09267733991146088




 51%|█████     | 51019/100000 [1:07:54<1:05:05, 12.54it/s]
epoch 51000  training loss: 0.09420978277921677
epoch 51000  clean testing loss: 0.01612747460603714




 51%|█████     | 51119/100000 [1:08:02<1:04:53, 12.55it/s]
epoch 51100  training loss: 0.09444202482700348




 51%|█████     | 51221/100000 [1:08:10<1:04:40, 12.57it/s]
epoch 51200  training loss: 0.09474584460258484




 51%|█████▏    | 51315/100000 [1:08:17<1:04:34, 12.56it/s]
epoch 51300  training loss: 0.09453833103179932




 51%|█████▏    | 51415/100000 [1:08:25<1:04:30, 12.55it/s]
epoch 51400  training loss: 0.09461149573326111




 52%|█████▏    | 51515/100000 [1:08:33<1:04:20, 12.56it/s]
epoch 51500  training loss: 0.09393291920423508




 52%|█████▏    | 51617/100000 [1:08:41<1:04:14, 12.55it/s]
epoch 51600  training loss: 0.09341540187597275




 52%|█████▏    | 51717/100000 [1:08:49<1:04:03, 12.56it/s]
epoch 51700  training loss: 0.09338876605033875




 52%|█████▏    | 51817/100000 [1:08:57<1:03:59, 12.55it/s]
epoch 51800  training loss: 0.0930846557021141




 52%|█████▏    | 51917/100000 [1:09:05<1:03:50, 12.55it/s]
epoch 51900  training loss: 0.09245482087135315




 52%|█████▏    | 52019/100000 [1:09:13<1:03:40, 12.56it/s]
epoch 52000  training loss: 0.09242897480726242
epoch 52000  clean testing loss: 0.016146179288625717




 52%|█████▏    | 52119/100000 [1:09:21<1:03:29, 12.57it/s]
epoch 52100  training loss: 0.09148658066987991




 52%|█████▏    | 52219/100000 [1:09:29<1:03:23, 12.56it/s]
epoch 52200  training loss: 0.09153805673122406




 52%|█████▏    | 52319/100000 [1:09:37<1:03:16, 12.56it/s]
epoch 52300  training loss: 0.0917307436466217




 52%|█████▏    | 52419/100000 [1:09:45<1:04:06, 12.37it/s]
epoch 52400  training loss: 0.0918789803981781




 53%|█████▎    | 52521/100000 [1:09:53<1:03:00, 12.56it/s]
epoch 52500  training loss: 0.0917501226067543




 53%|█████▎    | 52621/100000 [1:10:01<1:02:50, 12.56it/s]
epoch 52600  training loss: 0.09193133562803268




 53%|█████▎    | 52721/100000 [1:10:09<1:02:43, 12.56it/s]
epoch 52700  training loss: 0.09257374703884125




 53%|█████▎    | 52823/100000 [1:10:17<1:02:36, 12.56it/s]
epoch 52800  training loss: 0.09350937604904175




 53%|█████▎    | 52923/100000 [1:10:25<1:02:45, 12.50it/s]
epoch 52900  training loss: 0.09290440380573273




 53%|█████▎    | 53023/100000 [1:10:33<1:02:24, 12.55it/s]
epoch 53000  training loss: 0.092809297144413
epoch 53000  clean testing loss: 0.015694376081228256



 53%|█████▎    | 53099/100000 [1:10:39<1:02:14, 12.56it/s]
epoch 53100  training loss: 0.09264745563268661




 53%|█████▎    | 53199/100000 [1:10:47<1:02:05, 12.56it/s]
epoch 53200  training loss: 0.09572242945432663




 53%|█████▎    | 53299/100000 [1:10:55<1:01:56, 12.57it/s]
epoch 53300  training loss: 0.09344618022441864




 53%|█████▎    | 53401/100000 [1:11:04<1:01:53, 12.55it/s]
epoch 53400  training loss: 0.09438081830739975




 54%|█████▎    | 53501/100000 [1:11:12<1:01:49, 12.53it/s]
epoch 53500  training loss: 0.09277971088886261




 54%|█████▎    | 53601/100000 [1:11:20<1:01:34, 12.56it/s]
epoch 53600  training loss: 0.09250631183385849




 54%|█████▎    | 53701/100000 [1:11:27<1:01:26, 12.56it/s]
epoch 53700  training loss: 0.09409748017787933




 54%|█████▍    | 53803/100000 [1:11:36<1:01:28, 12.53it/s]
epoch 53800  training loss: 0.09242849797010422




 54%|█████▍    | 53903/100000 [1:11:44<1:01:22, 12.52it/s]
epoch 53900  training loss: 0.0920700654387474




 54%|█████▍    | 54003/100000 [1:11:52<1:01:41, 12.43it/s]
epoch 54000  training loss: 0.09360448271036148
epoch 54000  clean testing loss: 0.015886612236499786




 54%|█████▍    | 54103/100000 [1:12:00<1:01:07, 12.51it/s]
epoch 54100  training loss: 0.09207231551408768




 54%|█████▍    | 54205/100000 [1:12:08<1:00:53, 12.53it/s]
epoch 54200  training loss: 0.09358543157577515




 54%|█████▍    | 54305/100000 [1:12:16<1:03:21, 12.02it/s]
epoch 54300  training loss: 0.09331486374139786




 54%|█████▍    | 54405/100000 [1:12:24<1:00:44, 12.51it/s]
epoch 54400  training loss: 0.09213941544294357




 55%|█████▍    | 54505/100000 [1:12:32<1:00:31, 12.53it/s]
epoch 54500  training loss: 0.09383587539196014




 55%|█████▍    | 54607/100000 [1:12:40<1:00:18, 12.54it/s]
epoch 54600  training loss: 0.09396257996559143




 55%|█████▍    | 54707/100000 [1:12:48<1:00:16, 12.52it/s]
epoch 54700  training loss: 0.09224569797515869




 55%|█████▍    | 54807/100000 [1:12:56<1:00:05, 12.54it/s]
epoch 54800  training loss: 0.09341016411781311




 55%|█████▍    | 54907/100000 [1:13:04<59:55, 12.54it/s]
epoch 54900  training loss: 0.09231167286634445




 55%|█████▌    | 55009/100000 [1:13:12<59:52, 12.52it/s]
epoch 55000  training loss: 0.09436944127082825
epoch 55000  clean testing loss: 0.01692809723317623




 55%|█████▌    | 55109/100000 [1:13:20<59:36, 12.55it/s]
epoch 55100  training loss: 0.09324363619089127




 55%|█████▌    | 55209/100000 [1:13:28<59:31, 12.54it/s]
epoch 55200  training loss: 0.0944768637418747




 55%|█████▌    | 55311/100000 [1:13:36<59:21, 12.55it/s]
epoch 55300  training loss: 0.09348953515291214




 55%|█████▌    | 55411/100000 [1:13:44<59:10, 12.56it/s]
epoch 55400  training loss: 0.09262844920158386




 56%|█████▌    | 55511/100000 [1:13:52<59:06, 12.54it/s]
epoch 55500  training loss: 0.09486069530248642




 56%|█████▌    | 55611/100000 [1:14:00<58:54, 12.56it/s]
epoch 55600  training loss: 0.09356436878442764




 56%|█████▌    | 55713/100000 [1:14:08<58:47, 12.56it/s]
epoch 55700  training loss: 0.09230807423591614




 56%|█████▌    | 55813/100000 [1:14:16<1:02:03, 11.87it/s]
epoch 55800  training loss: 0.09232065081596375




 56%|█████▌    | 55913/100000 [1:14:24<58:30, 12.56it/s]
epoch 55900  training loss: 0.09246353805065155




 56%|█████▌    | 56013/100000 [1:14:32<58:24, 12.55it/s]
epoch 56000  training loss: 0.09287478029727936
epoch 56000  clean testing loss: 0.01585959456861019




 56%|█████▌    | 56115/100000 [1:14:40<58:12, 12.56it/s]
epoch 56100  training loss: 0.09380945563316345




 56%|█████▌    | 56215/100000 [1:14:48<58:08, 12.55it/s]
epoch 56200  training loss: 0.09345073252916336




 56%|█████▋    | 56315/100000 [1:14:56<58:04, 12.54it/s]
epoch 56300  training loss: 0.09285386651754379




 56%|█████▋    | 56415/100000 [1:15:04<57:50, 12.56it/s]
epoch 56400  training loss: 0.09188659489154816



 56%|█████▋    | 56483/100000 [1:15:12<57:56, 12.52it/s]
epoch 56500  training loss: 0.09358628839254379




 57%|█████▋    | 56583/100000 [1:15:20<57:40, 12.55it/s]
epoch 56600  training loss: 0.09437307715415955




 57%|█████▋    | 56685/100000 [1:15:29<57:25, 12.57it/s]
epoch 56700  training loss: 0.09311489015817642




 57%|█████▋    | 56785/100000 [1:15:37<57:21, 12.56it/s]
epoch 56800  training loss: 0.09265840798616409




 57%|█████▋    | 56885/100000 [1:15:44<57:10, 12.57it/s]
epoch 56900  training loss: 0.09322713315486908




 57%|█████▋    | 56985/100000 [1:15:52<57:04, 12.56it/s]
epoch 57000  training loss: 0.09418350458145142
epoch 57000  clean testing loss: 0.015903323888778687




 57%|█████▋    | 57087/100000 [1:16:01<56:54, 12.57it/s]
epoch 57100  training loss: 0.0926436111330986




 57%|█████▋    | 57187/100000 [1:16:09<56:48, 12.56it/s]
epoch 57200  training loss: 0.09155017882585526




 57%|█████▋    | 57287/100000 [1:16:17<1:01:37, 11.55it/s]
epoch 57300  training loss: 0.09246894717216492




 57%|█████▋    | 57387/100000 [1:16:25<56:30, 12.57it/s]
epoch 57400  training loss: 0.09393128752708435




 57%|█████▋    | 57489/100000 [1:16:33<56:23, 12.56it/s]
epoch 57500  training loss: 0.09330101311206818




 58%|█████▊    | 57589/100000 [1:16:41<56:15, 12.56it/s]
epoch 57600  training loss: 0.09216538816690445




 58%|█████▊    | 57689/100000 [1:16:49<56:12, 12.55it/s]
epoch 57700  training loss: 0.09267071634531021




 58%|█████▊    | 57789/100000 [1:16:57<56:00, 12.56it/s]
epoch 57800  training loss: 0.09360059350728989




 58%|█████▊    | 57891/100000 [1:17:05<55:51, 12.57it/s]
epoch 57900  training loss: 0.0925072431564331




 58%|█████▊    | 57991/100000 [1:17:13<55:42, 12.57it/s]
epoch 58000  training loss: 0.09208644926548004
epoch 58000  clean testing loss: 0.01608206517994404




 58%|█████▊    | 58091/100000 [1:17:21<55:33, 12.57it/s]
epoch 58100  training loss: 0.09268266707658768




 58%|█████▊    | 58191/100000 [1:17:29<55:27, 12.56it/s]
epoch 58200  training loss: 0.09350336343050003




 58%|█████▊    | 58293/100000 [1:17:37<55:17, 12.57it/s]
epoch 58300  training loss: 0.09234308451414108




 58%|█████▊    | 58393/100000 [1:17:45<55:11, 12.57it/s]
epoch 58400  training loss: 0.09319080412387848




 58%|█████▊    | 58493/100000 [1:17:53<55:03, 12.56it/s]
epoch 58500  training loss: 0.09344605356454849




 59%|█████▊    | 58593/100000 [1:18:01<54:54, 12.57it/s]
epoch 58600  training loss: 0.09221066534519196




 59%|█████▊    | 58695/100000 [1:18:09<54:44, 12.57it/s]
epoch 58700  training loss: 0.09393148124217987




 59%|█████▉    | 58795/100000 [1:18:17<54:37, 12.57it/s]
epoch 58800  training loss: 0.09372192621231079




 59%|█████▉    | 58895/100000 [1:18:25<54:30, 12.57it/s]
epoch 58900  training loss: 0.09218305349349976




 59%|█████▉    | 58997/100000 [1:18:33<54:25, 12.56it/s]
epoch 59000  training loss: 0.09409382939338684
epoch 59000  clean testing loss: 0.0161103717982769




 59%|█████▉    | 59097/100000 [1:18:41<54:12, 12.58it/s]
epoch 59100  training loss: 0.09183014929294586




 59%|█████▉    | 59197/100000 [1:18:49<54:17, 12.53it/s]
epoch 59200  training loss: 0.09380707889795303




 59%|█████▉    | 59297/100000 [1:18:57<54:00, 12.56it/s]
epoch 59300  training loss: 0.09187084436416626




 59%|█████▉    | 59399/100000 [1:19:05<53:53, 12.56it/s]
epoch 59400  training loss: 0.09414947032928467




 59%|█████▉    | 59499/100000 [1:19:13<53:42, 12.57it/s]
epoch 59500  training loss: 0.09235431253910065




 60%|█████▉    | 59599/100000 [1:19:21<53:39, 12.55it/s]
epoch 59600  training loss: 0.09347150474786758




 60%|█████▉    | 59699/100000 [1:19:29<53:25, 12.57it/s]
epoch 59700  training loss: 0.09184357523918152




 60%|█████▉    | 59801/100000 [1:19:37<53:21, 12.55it/s]
epoch 59800  training loss: 0.09333710372447968




 60%|█████▉    | 59901/100000 [1:19:45<53:12, 12.56it/s]
epoch 59900  training loss: 0.09242300689220428




 60%|██████    | 60001/100000 [1:19:53<53:50, 12.38it/s]
epoch 60000  training loss: 0.09245329350233078
epoch 60000  clean testing loss: 0.016035594046115875




 60%|██████    | 60101/100000 [1:20:01<52:58, 12.55it/s]
epoch 60100  training loss: 0.09273925423622131




 60%|██████    | 60195/100000 [1:20:08<52:45, 12.57it/s]
epoch 60200  training loss: 0.09263458102941513




 60%|██████    | 60297/100000 [1:20:17<52:37, 12.58it/s]
epoch 60300  training loss: 0.09214594215154648




 60%|██████    | 60397/100000 [1:20:25<52:31, 12.57it/s]
epoch 60400  training loss: 0.09197717159986496




 60%|██████    | 60497/100000 [1:20:33<52:22, 12.57it/s]
epoch 60500  training loss: 0.09174524992704391




 61%|██████    | 60599/100000 [1:20:41<52:15, 12.57it/s]
epoch 60600  training loss: 0.09205484390258789




 61%|██████    | 60699/100000 [1:20:49<53:05, 12.34it/s]
epoch 60700  training loss: 0.092673659324646




 61%|██████    | 60799/100000 [1:20:57<52:00, 12.56it/s]
epoch 60800  training loss: 0.0932568907737732




 61%|██████    | 60899/100000 [1:21:05<51:52, 12.56it/s]
epoch 60900  training loss: 0.09289757162332535



 61%|██████    | 60975/100000 [1:21:11<51:48, 12.56it/s]
epoch 61000  training loss: 0.09167896211147308
epoch 61000  clean testing loss: 0.016140395775437355





 61%|██████    | 61101/100000 [1:21:21<51:41, 12.54it/s]
epoch 61100  training loss: 0.09093456715345383




 61%|██████    | 61201/100000 [1:21:29<51:30, 12.56it/s]
epoch 61200  training loss: 0.09214552491903305




 61%|██████▏   | 61301/100000 [1:21:37<51:25, 12.54it/s]
epoch 61300  training loss: 0.09243935346603394




 61%|██████▏   | 61403/100000 [1:21:45<51:21, 12.53it/s]
epoch 61400  training loss: 0.09106654673814774




 62%|██████▏   | 61503/100000 [1:21:53<51:14, 12.52it/s]
epoch 61500  training loss: 0.09198468178510666




 62%|██████▏   | 61603/100000 [1:22:01<51:03, 12.53it/s]
epoch 61600  training loss: 0.09304971992969513




 62%|██████▏   | 61703/100000 [1:22:09<51:00, 12.51it/s]
epoch 61700  training loss: 0.09107673168182373




 62%|██████▏   | 61805/100000 [1:22:17<50:45, 12.54it/s]
epoch 61800  training loss: 0.09225183725357056




 62%|██████▏   | 61905/100000 [1:22:25<50:39, 12.53it/s]
epoch 61900  training loss: 0.09328165650367737




 62%|██████▏   | 62005/100000 [1:22:33<50:45, 12.48it/s]
epoch 62000  training loss: 0.09170155972242355
epoch 62000  clean testing loss: 0.016116628423333168




 62%|██████▏   | 62105/100000 [1:22:41<50:21, 12.54it/s]
epoch 62100  training loss: 0.09262464195489883



 62%|██████▏   | 62181/100000 [1:22:47<50:11, 12.56it/s]
epoch 62200  training loss: 0.09358705580234528




 62%|██████▏   | 62281/100000 [1:22:55<50:02, 12.56it/s]
epoch 62300  training loss: 0.09335275739431381




 62%|██████▏   | 62383/100000 [1:23:03<49:57, 12.55it/s]
epoch 62400  training loss: 0.09314007312059402




 62%|██████▏   | 62483/100000 [1:23:11<49:46, 12.56it/s]
epoch 62500  training loss: 0.09293488413095474




 63%|██████▎   | 62583/100000 [1:23:19<51:21, 12.14it/s]
epoch 62600  training loss: 0.0925455391407013




 63%|██████▎   | 62683/100000 [1:23:27<49:36, 12.54it/s]
epoch 62700  training loss: 0.09177873283624649




 63%|██████▎   | 62785/100000 [1:23:35<49:58, 12.41it/s]
epoch 62800  training loss: 0.09144867956638336




 63%|██████▎   | 62885/100000 [1:23:43<49:13, 12.56it/s]
epoch 62900  training loss: 0.09275107085704803




 63%|██████▎   | 62985/100000 [1:23:51<49:13, 12.53it/s]
epoch 63000  training loss: 0.09280169755220413
epoch 63000  clean testing loss: 0.01633422262966633




 63%|██████▎   | 63085/100000 [1:23:59<48:57, 12.56it/s]
epoch 63100  training loss: 0.09295191615819931




 63%|██████▎   | 63187/100000 [1:24:07<48:49, 12.57it/s]
epoch 63200  training loss: 0.09276683628559113




 63%|██████▎   | 63287/100000 [1:24:15<48:42, 12.56it/s]
epoch 63300  training loss: 0.09247612953186035




 63%|██████▎   | 63387/100000 [1:24:23<48:34, 12.56it/s]
epoch 63400  training loss: 0.09257844090461731




 63%|██████▎   | 63487/100000 [1:24:31<48:25, 12.57it/s]
epoch 63500  training loss: 0.09271838515996933




 64%|██████▎   | 63589/100000 [1:24:39<48:16, 12.57it/s]
epoch 63600  training loss: 0.09216032177209854




 64%|██████▎   | 63689/100000 [1:24:47<48:10, 12.56it/s]
epoch 63700  training loss: 0.09132272750139236




 64%|██████▍   | 63789/100000 [1:24:55<48:01, 12.57it/s]
epoch 63800  training loss: 0.09170617163181305




 64%|██████▍   | 63889/100000 [1:25:03<47:53, 12.57it/s]
epoch 63900  training loss: 0.09270259737968445




 64%|██████▍   | 63991/100000 [1:25:11<47:46, 12.56it/s]
epoch 64000  training loss: 0.09263407438993454
epoch 64000  clean testing loss: 0.01639111153781414




 64%|██████▍   | 64091/100000 [1:25:19<47:36, 12.57it/s]
epoch 64100  training loss: 0.09243583679199219




 64%|██████▍   | 64191/100000 [1:25:27<47:29, 12.57it/s]
epoch 64200  training loss: 0.09114084392786026




 64%|██████▍   | 64291/100000 [1:25:35<47:22, 12.56it/s]
epoch 64300  training loss: 0.09141851216554642




 64%|██████▍   | 64393/100000 [1:25:43<47:15, 12.56it/s]
epoch 64400  training loss: 0.092359259724617




 64%|██████▍   | 64493/100000 [1:25:51<47:16, 12.52it/s]
epoch 64500  training loss: 0.09223618358373642




 65%|██████▍   | 64593/100000 [1:25:59<46:58, 12.56it/s]
epoch 64600  training loss: 0.09175978600978851




 65%|██████▍   | 64693/100000 [1:26:07<46:50, 12.56it/s]
epoch 64700  training loss: 0.090833380818367




 65%|██████▍   | 64795/100000 [1:26:15<46:42, 12.56it/s]
epoch 64800  training loss: 0.09121475368738174




 65%|██████▍   | 64895/100000 [1:26:23<46:36, 12.55it/s]
epoch 64900  training loss: 0.09068956971168518




 65%|██████▍   | 64995/100000 [1:26:31<46:25, 12.57it/s]
epoch 65000  training loss: 0.09080003201961517
epoch 65000  clean testing loss: 0.01655481569468975




 65%|██████▌   | 65095/100000 [1:26:39<46:18, 12.56it/s]
epoch 65100  training loss: 0.09124910831451416




 65%|██████▌   | 65197/100000 [1:26:47<46:10, 12.56it/s]
epoch 65200  training loss: 0.09236174821853638




 65%|██████▌   | 65297/100000 [1:26:55<46:02, 12.56it/s]
epoch 65300  training loss: 0.09252450615167618




 65%|██████▌   | 65397/100000 [1:27:03<45:55, 12.56it/s]
epoch 65400  training loss: 0.09174421429634094




 65%|██████▌   | 65497/100000 [1:27:11<45:45, 12.57it/s]
epoch 65500  training loss: 0.09141726791858673




 66%|██████▌   | 65599/100000 [1:27:19<45:37, 12.57it/s]
epoch 65600  training loss: 0.09051664918661118




 66%|██████▌   | 65699/100000 [1:27:27<45:30, 12.56it/s]
epoch 65700  training loss: 0.09100131690502167




 66%|██████▌   | 65799/100000 [1:27:35<45:22, 12.56it/s]
epoch 65800  training loss: 0.09147889167070389




 66%|██████▌   | 65899/100000 [1:27:43<45:13, 12.57it/s]
epoch 65900  training loss: 0.09272337704896927




 66%|██████▌   | 65999/100000 [1:27:51<45:33, 12.44it/s]
epoch 66000  training loss: 0.09287919849157333
epoch 66000  clean testing loss: 0.01592007651925087




 66%|██████▌   | 66101/100000 [1:27:59<44:59, 12.56it/s]
epoch 66100  training loss: 0.09289923310279846




 66%|██████▌   | 66201/100000 [1:28:07<44:51, 12.56it/s]
epoch 66200  training loss: 0.09107641130685806




 66%|██████▋   | 66301/100000 [1:28:15<44:48, 12.53it/s]
epoch 66300  training loss: 0.09232083708047867




 66%|██████▋   | 66401/100000 [1:28:23<44:40, 12.54it/s]
epoch 66400  training loss: 0.09143198281526566




 67%|██████▋   | 66503/100000 [1:28:31<44:35, 12.52it/s]
epoch 66500  training loss: 0.09232797473669052




 67%|██████▋   | 66603/100000 [1:28:39<44:24, 12.53it/s]
epoch 66600  training loss: 0.09180910140275955




 67%|██████▋   | 66703/100000 [1:28:47<44:20, 12.51it/s]
epoch 66700  training loss: 0.09186159074306488




 67%|██████▋   | 66803/100000 [1:28:55<44:15, 12.50it/s]
epoch 66800  training loss: 0.09207765758037567




 67%|██████▋   | 66905/100000 [1:29:04<43:59, 12.54it/s]
epoch 66900  training loss: 0.0921178087592125




 67%|██████▋   | 67005/100000 [1:29:12<44:04, 12.48it/s]
epoch 67000  training loss: 0.09160993993282318
epoch 67000  clean testing loss: 0.01603006385266781




 67%|██████▋   | 67105/100000 [1:29:19<43:44, 12.53it/s]
epoch 67100  training loss: 0.09244436770677567




 67%|██████▋   | 67205/100000 [1:29:27<43:36, 12.53it/s]
epoch 67200  training loss: 0.09158067405223846



 67%|██████▋   | 67281/100000 [1:29:34<43:21, 12.58it/s]
epoch 67300  training loss: 0.09270802140235901




 67%|██████▋   | 67381/100000 [1:29:41<43:20, 12.54it/s]
epoch 67400  training loss: 0.09243623167276382




 67%|██████▋   | 67483/100000 [1:29:50<43:08, 12.56it/s]
epoch 67500  training loss: 0.09187935292720795




 68%|██████▊   | 67577/100000 [1:29:57<42:58, 12.57it/s]
epoch 67600  training loss: 0.09147584438323975




 68%|██████▊   | 67677/100000 [1:30:05<42:52, 12.56it/s]
epoch 67700  training loss: 0.09172232449054718




 68%|██████▊   | 67777/100000 [1:30:13<42:44, 12.57it/s]
epoch 67800  training loss: 0.0916559174656868




 68%|██████▊   | 67879/100000 [1:30:21<42:34, 12.57it/s]
epoch 67900  training loss: 0.09154274314641953




 68%|██████▊   | 67979/100000 [1:30:29<42:27, 12.57it/s]
epoch 68000  training loss: 0.09158316254615784
epoch 68000  clean testing loss: 0.015587951056659222




 68%|██████▊   | 68079/100000 [1:30:37<42:19, 12.57it/s]
epoch 68100  training loss: 0.09167074412107468




 68%|██████▊   | 68179/100000 [1:30:45<42:11, 12.57it/s]
epoch 68200  training loss: 0.09157285839319229




 68%|██████▊   | 68279/100000 [1:30:53<42:15, 12.51it/s]
epoch 68300  training loss: 0.09145919233560562




 68%|██████▊   | 68381/100000 [1:31:01<41:55, 12.57it/s]
epoch 68400  training loss: 0.09129371494054794




 68%|██████▊   | 68481/100000 [1:31:09<41:46, 12.58it/s]
epoch 68500  training loss: 0.09130794554948807




 69%|██████▊   | 68581/100000 [1:31:17<41:39, 12.57it/s]
epoch 68600  training loss: 0.09192810952663422




 69%|██████▊   | 68683/100000 [1:31:25<41:31, 12.57it/s]
epoch 68700  training loss: 0.09262534976005554




 69%|██████▉   | 68783/100000 [1:31:33<41:23, 12.57it/s]
epoch 68800  training loss: 0.09283646196126938




 69%|██████▉   | 68883/100000 [1:31:41<41:14, 12.57it/s]
epoch 68900  training loss: 0.09264102578163147




 69%|██████▉   | 68985/100000 [1:31:49<41:06, 12.58it/s]
epoch 69000  training loss: 0.09181281179189682
epoch 69000  clean testing loss: 0.015824656933546066




 69%|██████▉   | 69085/100000 [1:31:57<40:59, 12.57it/s]
epoch 69100  training loss: 0.09223944693803787




 69%|██████▉   | 69185/100000 [1:32:05<40:51, 12.57it/s]
epoch 69200  training loss: 0.0911112055182457




 69%|██████▉   | 69285/100000 [1:32:13<40:42, 12.57it/s]
epoch 69300  training loss: 0.09152152389287949




 69%|██████▉   | 69387/100000 [1:32:21<40:36, 12.57it/s]
epoch 69400  training loss: 0.09274578839540482




 69%|██████▉   | 69487/100000 [1:32:29<40:27, 12.57it/s]
epoch 69500  training loss: 0.09115389734506607




 70%|██████▉   | 69587/100000 [1:32:37<40:20, 12.57it/s]
epoch 69600  training loss: 0.09175022691488266




 70%|██████▉   | 69687/100000 [1:32:45<40:12, 12.57it/s]
epoch 69700  training loss: 0.09198717027902603




 70%|██████▉   | 69787/100000 [1:32:53<40:27, 12.45it/s]
epoch 69800  training loss: 0.09038792550563812




 70%|██████▉   | 69889/100000 [1:33:01<39:55, 12.57it/s]
epoch 69900  training loss: 0.0918830931186676




 70%|██████▉   | 69989/100000 [1:33:09<39:49, 12.56it/s]
epoch 70000  training loss: 0.09159219264984131
epoch 70000  clean testing loss: 0.01658010482788086




 70%|███████   | 70089/100000 [1:33:17<39:40, 12.57it/s]
epoch 70100  training loss: 0.09026673436164856




 70%|███████   | 70191/100000 [1:33:26<39:34, 12.55it/s]
epoch 70200  training loss: 0.09207918494939804




 70%|███████   | 70291/100000 [1:33:34<39:22, 12.58it/s]
epoch 70300  training loss: 0.09118993580341339




 70%|███████   | 70391/100000 [1:33:41<39:15, 12.57it/s]
epoch 70400  training loss: 0.0913507267832756




 70%|███████   | 70491/100000 [1:33:49<39:06, 12.57it/s]
epoch 70500  training loss: 0.09139431267976761




 71%|███████   | 70593/100000 [1:33:58<39:02, 12.56it/s]
epoch 70600  training loss: 0.09117865562438965




 71%|███████   | 70693/100000 [1:34:06<38:52, 12.56it/s]
epoch 70700  training loss: 0.09125535935163498




 71%|███████   | 70793/100000 [1:34:14<38:43, 12.57it/s]
epoch 70800  training loss: 0.09162606298923492




 71%|███████   | 70895/100000 [1:34:22<38:34, 12.57it/s]
epoch 70900  training loss: 0.09148155152797699




 71%|███████   | 70995/100000 [1:34:30<38:29, 12.56it/s]
epoch 71000  training loss: 0.09091746807098389
epoch 71000  clean testing loss: 0.015579286031425




 71%|███████   | 71095/100000 [1:34:38<38:21, 12.56it/s]
epoch 71100  training loss: 0.0906454399228096




 71%|███████   | 71195/100000 [1:34:46<38:13, 12.56it/s]
epoch 71200  training loss: 0.09108707308769226




 71%|███████▏  | 71295/100000 [1:34:54<40:01, 11.95it/s]
epoch 71300  training loss: 0.09172844141721725




 71%|███████▏  | 71397/100000 [1:35:02<37:54, 12.57it/s]
epoch 71400  training loss: 0.09178570657968521




 71%|███████▏  | 71497/100000 [1:35:10<37:48, 12.56it/s]
epoch 71500  training loss: 0.09129621088504791




 72%|███████▏  | 71599/100000 [1:35:18<37:39, 12.57it/s]
epoch 71600  training loss: 0.09076309949159622




 72%|███████▏  | 71699/100000 [1:35:26<37:38, 12.53it/s]
epoch 71700  training loss: 0.09044334292411804




 72%|███████▏  | 71799/100000 [1:35:34<37:24, 12.57it/s]
epoch 71800  training loss: 0.09134151041507721




 72%|███████▏  | 71899/100000 [1:35:42<37:15, 12.57it/s]
epoch 71900  training loss: 0.09217105060815811




 72%|███████▏  | 72001/100000 [1:35:50<37:44, 12.36it/s]
epoch 72000  training loss: 0.0924597755074501
epoch 72000  clean testing loss: 0.01594211719930172




 72%|███████▏  | 72101/100000 [1:35:58<37:06, 12.53it/s]
epoch 72100  training loss: 0.09203125536441803




 72%|███████▏  | 72201/100000 [1:36:06<36:53, 12.56it/s]
epoch 72200  training loss: 0.09088083356618881




 72%|███████▏  | 72301/100000 [1:36:14<36:45, 12.56it/s]
epoch 72300  training loss: 0.09220721572637558




 72%|███████▏  | 72403/100000 [1:36:22<36:43, 12.52it/s]
epoch 72400  training loss: 0.09084674715995789




 73%|███████▎  | 72503/100000 [1:36:30<36:35, 12.52it/s]
epoch 72500  training loss: 0.09209063649177551




 73%|███████▎  | 72603/100000 [1:36:38<36:26, 12.53it/s]
epoch 72600  training loss: 0.09146174043416977




 73%|███████▎  | 72703/100000 [1:36:46<36:18, 12.53it/s]
epoch 72700  training loss: 0.09156303107738495




 73%|███████▎  | 72805/100000 [1:36:54<37:38, 12.04it/s]
epoch 72800  training loss: 0.09227695316076279




 73%|███████▎  | 72905/100000 [1:37:02<35:59, 12.54it/s]
epoch 72900  training loss: 0.09167876094579697




 73%|███████▎  | 73005/100000 [1:37:10<36:03, 12.48it/s]
epoch 73000  training loss: 0.09185373038053513
epoch 73000  clean testing loss: 0.01627545990049839




 73%|███████▎  | 73107/100000 [1:37:18<35:43, 12.55it/s]
epoch 73100  training loss: 0.09232819825410843



 73%|███████▎  | 73181/100000 [1:37:24<35:32, 12.57it/s]
epoch 73200  training loss: 0.09278694540262222




 73%|███████▎  | 73283/100000 [1:37:32<35:24, 12.58it/s]
epoch 73300  training loss: 0.09212237596511841




 73%|███████▎  | 73383/100000 [1:37:40<35:17, 12.57it/s]
epoch 73400  training loss: 0.09230097383260727




 73%|███████▎  | 73483/100000 [1:37:48<35:09, 12.57it/s]
epoch 73500  training loss: 0.09251518547534943




 74%|███████▎  | 73583/100000 [1:37:56<35:10, 12.52it/s]
epoch 73600  training loss: 0.09265352785587311




 74%|███████▎  | 73685/100000 [1:38:04<34:53, 12.57it/s]
epoch 73700  training loss: 0.09291531890630722




 74%|███████▍  | 73785/100000 [1:38:12<34:45, 12.57it/s]
epoch 73800  training loss: 0.09308642894029617




 74%|███████▍  | 73885/100000 [1:38:20<34:39, 12.56it/s]
epoch 73900  training loss: 0.09310764819383621




 74%|███████▍  | 73987/100000 [1:38:28<34:29, 12.57it/s]
epoch 74000  training loss: 0.09285018593072891
epoch 74000  clean testing loss: 0.017073580995202065




 74%|███████▍  | 74087/100000 [1:38:36<34:23, 12.56it/s]
epoch 74100  training loss: 0.09275025129318237




 74%|███████▍  | 74187/100000 [1:38:44<34:12, 12.58it/s]
epoch 74200  training loss: 0.09263727813959122




 74%|███████▍  | 74289/100000 [1:38:52<34:05, 12.57it/s]
epoch 74300  training loss: 0.09310693293809891




 74%|███████▍  | 74389/100000 [1:39:00<33:58, 12.57it/s]
epoch 74400  training loss: 0.09304541349411011




 74%|███████▍  | 74489/100000 [1:39:08<33:49, 12.57it/s]
epoch 74500  training loss: 0.09337655454874039




 75%|███████▍  | 74589/100000 [1:39:16<33:41, 12.57it/s]
epoch 74600  training loss: 0.09284095466136932




 75%|███████▍  | 74691/100000 [1:39:24<33:33, 12.57it/s]
epoch 74700  training loss: 0.09307953715324402




 75%|███████▍  | 74791/100000 [1:39:32<33:25, 12.57it/s]
epoch 74800  training loss: 0.09327114373445511




 75%|███████▍  | 74885/100000 [1:39:40<33:19, 12.56it/s]
epoch 74900  training loss: 0.09282985329627991




 75%|███████▍  | 74985/100000 [1:39:48<33:10, 12.57it/s]
epoch 75000  training loss: 0.09265962988138199
epoch 75000  clean testing loss: 0.01703997515141964




 75%|███████▌  | 75085/100000 [1:39:56<33:31, 12.38it/s]
epoch 75100  training loss: 0.09297356009483337




 75%|███████▌  | 75187/100000 [1:40:04<32:53, 12.57it/s]
epoch 75200  training loss: 0.09252767264842987




 75%|███████▌  | 75287/100000 [1:40:12<32:47, 12.56it/s]
epoch 75300  training loss: 0.09377098083496094




 75%|███████▌  | 75387/100000 [1:40:20<32:37, 12.57it/s]
epoch 75400  training loss: 0.09279649704694748




 75%|███████▌  | 75489/100000 [1:40:28<32:32, 12.55it/s]
epoch 75500  training loss: 0.09329552203416824




 76%|███████▌  | 75589/100000 [1:40:36<32:23, 12.56it/s]
epoch 75600  training loss: 0.09362366795539856




 76%|███████▌  | 75689/100000 [1:40:44<32:14, 12.57it/s]
epoch 75700  training loss: 0.09207671880722046




 76%|███████▌  | 75791/100000 [1:40:52<32:05, 12.57it/s]
epoch 75800  training loss: 0.09290247410535812




 76%|███████▌  | 75891/100000 [1:41:00<31:58, 12.56it/s]
epoch 75900  training loss: 0.0927799642086029




 76%|███████▌  | 75991/100000 [1:41:08<31:51, 12.56it/s]
epoch 76000  training loss: 0.09292386472225189
epoch 76000  clean testing loss: 0.017315074801445007




 76%|███████▌  | 76091/100000 [1:41:16<31:42, 12.57it/s]
epoch 76100  training loss: 0.09326064586639404




 76%|███████▌  | 76193/100000 [1:41:24<31:34, 12.56it/s]
epoch 76200  training loss: 0.09246330708265305




 76%|███████▋  | 76293/100000 [1:41:32<31:26, 12.56it/s]
epoch 76300  training loss: 0.09355289489030838




 76%|███████▋  | 76393/100000 [1:41:40<31:18, 12.57it/s]
epoch 76400  training loss: 0.09209692478179932




 76%|███████▋  | 76495/100000 [1:41:48<31:09, 12.57it/s]
epoch 76500  training loss: 0.09325326979160309




 77%|███████▋  | 76595/100000 [1:41:56<31:58, 12.20it/s]
epoch 76600  training loss: 0.09228355437517166




 77%|███████▋  | 76695/100000 [1:42:04<30:53, 12.57it/s]
epoch 76700  training loss: 0.09344185143709183




 77%|███████▋  | 76795/100000 [1:42:12<30:49, 12.55it/s]
epoch 76800  training loss: 0.09228339791297913




 77%|███████▋  | 76897/100000 [1:42:20<30:38, 12.57it/s]
epoch 76900  training loss: 0.09342651069164276




 77%|███████▋  | 76997/100000 [1:42:28<30:31, 12.56it/s]
epoch 77000  training loss: 0.09275690466165543
epoch 77000  clean testing loss: 0.017000870779156685




 77%|███████▋  | 77097/100000 [1:42:36<30:24, 12.56it/s]
epoch 77100  training loss: 0.0931561142206192




 77%|███████▋  | 77197/100000 [1:42:44<30:16, 12.55it/s]
epoch 77200  training loss: 0.09375419467687607




 77%|███████▋  | 77299/100000 [1:42:52<30:07, 12.56it/s]
epoch 77300  training loss: 0.09232701361179352




 77%|███████▋  | 77399/100000 [1:43:00<29:57, 12.57it/s]
epoch 77400  training loss: 0.09419557452201843




 77%|███████▋  | 77499/100000 [1:43:08<29:53, 12.54it/s]
epoch 77500  training loss: 0.09343124181032181




 78%|███████▊  | 77599/100000 [1:43:16<29:43, 12.56it/s]
epoch 77600  training loss: 0.09280114620923996




 78%|███████▊  | 77701/100000 [1:43:24<29:35, 12.56it/s]
epoch 77700  training loss: 0.09367187321186066




 78%|███████▊  | 77801/100000 [1:43:32<29:32, 12.53it/s]
epoch 77800  training loss: 0.09299720078706741




 78%|███████▊  | 77901/100000 [1:43:40<29:20, 12.55it/s]
epoch 77900  training loss: 0.0928114578127861




 78%|███████▊  | 78001/100000 [1:43:48<29:36, 12.39it/s]
epoch 78000  training loss: 0.09399095922708511
epoch 78000  clean testing loss: 0.016975805163383484




 78%|███████▊  | 78103/100000 [1:43:56<30:45, 11.86it/s]
epoch 78100  training loss: 0.09394600242376328




 78%|███████▊  | 78203/100000 [1:44:04<29:01, 12.52it/s]
epoch 78200  training loss: 0.09397115558385849




 78%|███████▊  | 78303/100000 [1:44:12<28:53, 12.52it/s]
epoch 78300  training loss: 0.0937301516532898




 78%|███████▊  | 78405/100000 [1:44:20<28:41, 12.55it/s]
epoch 78400  training loss: 0.09385306388139725




 79%|███████▊  | 78505/100000 [1:44:28<28:36, 12.53it/s]
epoch 78500  training loss: 0.09400860965251923




 79%|███████▊  | 78605/100000 [1:44:36<28:28, 12.52it/s]
epoch 78600  training loss: 0.09368444234132767




 79%|███████▊  | 78705/100000 [1:44:44<28:19, 12.53it/s]
epoch 78700  training loss: 0.09374592453241348




 79%|███████▉  | 78807/100000 [1:44:52<28:10, 12.54it/s]
epoch 78800  training loss: 0.09395386278629303




 79%|███████▉  | 78907/100000 [1:45:00<28:02, 12.54it/s]
epoch 78900  training loss: 0.09432148188352585



 79%|███████▉  | 78981/100000 [1:45:06<27:52, 12.56it/s]
epoch 79000  training loss: 0.0939146876335144
epoch 79000  clean testing loss: 0.01702062413096428




 79%|███████▉  | 79083/100000 [1:45:14<27:45, 12.56it/s]
epoch 79100  training loss: 0.0936306044459343




 79%|███████▉  | 79183/100000 [1:45:22<27:37, 12.56it/s]
epoch 79200  training loss: 0.09406030923128128




 79%|███████▉  | 79283/100000 [1:45:30<27:28, 12.57it/s]
epoch 79300  training loss: 0.09356915950775146




 79%|███████▉  | 79383/100000 [1:45:38<27:20, 12.57it/s]
epoch 79400  training loss: 0.093540258705616




 79%|███████▉  | 79485/100000 [1:45:46<27:12, 12.57it/s]
epoch 79500  training loss: 0.09404835104942322




 80%|███████▉  | 79585/100000 [1:45:54<27:04, 12.57it/s]
epoch 79600  training loss: 0.09339803457260132




 80%|███████▉  | 79685/100000 [1:46:02<26:56, 12.57it/s]
epoch 79700  training loss: 0.09452324360609055




 80%|███████▉  | 79787/100000 [1:46:11<26:48, 12.56it/s]
epoch 79800  training loss: 0.09417945146560669




 80%|███████▉  | 79887/100000 [1:46:18<26:41, 12.56it/s]
epoch 79900  training loss: 0.09501579403877258




 80%|███████▉  | 79987/100000 [1:46:26<26:34, 12.55it/s]
epoch 80000  training loss: 0.09480859339237213
epoch 80000  clean testing loss: 0.018628612160682678




 80%|████████  | 80087/100000 [1:46:34<26:24, 12.57it/s]
epoch 80100  training loss: 0.09431383013725281




 80%|████████  | 80189/100000 [1:46:43<26:17, 12.56it/s]
epoch 80200  training loss: 0.09474920481443405




 80%|████████  | 80289/100000 [1:46:51<26:07, 12.57it/s]
epoch 80300  training loss: 0.094744011759758




 80%|████████  | 80389/100000 [1:46:58<26:03, 12.54it/s]
epoch 80400  training loss: 0.0943777859210968




 80%|████████  | 80489/100000 [1:47:06<25:52, 12.57it/s]
epoch 80500  training loss: 0.09414293617010117




 81%|████████  | 80591/100000 [1:47:15<25:44, 12.57it/s]
epoch 80600  training loss: 0.09439459443092346




 81%|████████  | 80691/100000 [1:47:23<25:36, 12.56it/s]
epoch 80700  training loss: 0.09426282346248627




 81%|████████  | 80791/100000 [1:47:31<25:29, 12.56it/s]
epoch 80800  training loss: 0.09384580701589584




 81%|████████  | 80893/100000 [1:47:39<25:21, 12.56it/s]
epoch 80900  training loss: 0.09394428133964539




 81%|████████  | 80993/100000 [1:47:47<25:14, 12.55it/s]
epoch 81000  training loss: 0.09421148151159286
epoch 81000  clean testing loss: 0.018158135935664177




 81%|████████  | 81093/100000 [1:47:55<25:04, 12.57it/s]
epoch 81100  training loss: 0.09461887180805206




 81%|████████  | 81193/100000 [1:48:03<24:57, 12.56it/s]
epoch 81200  training loss: 0.09556839615106583




 81%|████████▏ | 81295/100000 [1:48:11<24:48, 12.56it/s]
epoch 81300  training loss: 0.09549763053655624




 81%|████████▏ | 81395/100000 [1:48:19<24:40, 12.57it/s]
epoch 81400  training loss: 0.09500214457511902




 81%|████████▏ | 81495/100000 [1:48:27<24:34, 12.55it/s]
epoch 81500  training loss: 0.0951342061161995




 82%|████████▏ | 81595/100000 [1:48:35<24:24, 12.57it/s]
epoch 81600  training loss: 0.095560222864151




 82%|████████▏ | 81697/100000 [1:48:43<24:17, 12.55it/s]
epoch 81700  training loss: 0.0953228622674942




 82%|████████▏ | 81797/100000 [1:48:51<24:08, 12.56it/s]
epoch 81800  training loss: 0.09526531398296356




 82%|████████▏ | 81897/100000 [1:48:59<24:10, 12.48it/s]
epoch 81900  training loss: 0.09503332525491714




 82%|████████▏ | 81997/100000 [1:49:07<23:51, 12.57it/s]
epoch 82000  training loss: 0.094746895134449
epoch 82000  clean testing loss: 0.01846822164952755




 82%|████████▏ | 82099/100000 [1:49:15<23:44, 12.57it/s]
epoch 82100  training loss: 0.0955076664686203




 82%|████████▏ | 82199/100000 [1:49:23<23:35, 12.58it/s]
epoch 82200  training loss: 0.09518145769834518




 82%|████████▏ | 82293/100000 [1:49:30<23:30, 12.56it/s]
epoch 82300  training loss: 0.09433813393115997




 82%|████████▏ | 82393/100000 [1:49:38<23:21, 12.56it/s]
epoch 82400  training loss: 0.09430486708879471




 82%|████████▏ | 82495/100000 [1:49:46<23:12, 12.57it/s]
epoch 82500  training loss: 0.09422380477190018




 83%|████████▎ | 82595/100000 [1:49:54<23:05, 12.57it/s]
epoch 82600  training loss: 0.09429637342691422




 83%|████████▎ | 82695/100000 [1:50:02<23:00, 12.54it/s]
epoch 82700  training loss: 0.09386617690324783




 83%|████████▎ | 82795/100000 [1:50:10<22:48, 12.57it/s]
epoch 82800  training loss: 0.09380290657281876




 83%|████████▎ | 82897/100000 [1:50:18<22:39, 12.58it/s]
epoch 82900  training loss: 0.09374935925006866




 83%|████████▎ | 82997/100000 [1:50:26<22:34, 12.55it/s]
epoch 83000  training loss: 0.09354838728904724
epoch 83000  clean testing loss: 0.01742013730108738




 83%|████████▎ | 83097/100000 [1:50:34<22:25, 12.57it/s]
epoch 83100  training loss: 0.09292707592248917




 83%|████████▎ | 83199/100000 [1:50:43<22:20, 12.53it/s]
epoch 83200  training loss: 0.09280739724636078




 83%|████████▎ | 83299/100000 [1:50:50<22:08, 12.57it/s]
epoch 83300  training loss: 0.09326508641242981




 83%|████████▎ | 83399/100000 [1:50:58<23:28, 11.79it/s]
epoch 83400  training loss: 0.0934586450457573




 83%|████████▎ | 83499/100000 [1:51:06<21:52, 12.57it/s]
epoch 83500  training loss: 0.09368863701820374




 84%|████████▎ | 83601/100000 [1:51:15<21:45, 12.56it/s]
epoch 83600  training loss: 0.09370031952857971




 84%|████████▎ | 83701/100000 [1:51:23<21:37, 12.56it/s]
epoch 83700  training loss: 0.09333688765764236




 84%|████████▍ | 83801/100000 [1:51:31<21:30, 12.56it/s]
epoch 83800  training loss: 0.09335777163505554




 84%|████████▍ | 83901/100000 [1:51:38<21:22, 12.56it/s]
epoch 83900  training loss: 0.0931568443775177




 84%|████████▍ | 84003/100000 [1:51:47<21:25, 12.44it/s]
epoch 84000  training loss: 0.09292930364608765
epoch 84000  clean testing loss: 0.017491329461336136




 84%|████████▍ | 84103/100000 [1:51:55<21:09, 12.52it/s]
epoch 84100  training loss: 0.09387994557619095




 84%|████████▍ | 84203/100000 [1:52:03<21:03, 12.51it/s]
epoch 84200  training loss: 0.09328033775091171




 84%|████████▍ | 84303/100000 [1:52:11<20:53, 12.52it/s]
epoch 84300  training loss: 0.09324051439762115




 84%|████████▍ | 84405/100000 [1:52:19<20:46, 12.51it/s]
epoch 84400  training loss: 0.0931176096200943




 85%|████████▍ | 84505/100000 [1:52:27<20:38, 12.51it/s]
epoch 84500  training loss: 0.09305134415626526




 85%|████████▍ | 84605/100000 [1:52:35<20:28, 12.54it/s]
epoch 84600  training loss: 0.09350240230560303




 85%|████████▍ | 84707/100000 [1:52:43<20:19, 12.54it/s]
epoch 84700  training loss: 0.09395401924848557



 85%|████████▍ | 84781/100000 [1:52:49<20:10, 12.57it/s]
epoch 84800  training loss: 0.09395197778940201




 85%|████████▍ | 84883/100000 [1:52:57<20:02, 12.57it/s]
epoch 84900  training loss: 0.09378400444984436




 85%|████████▍ | 84983/100000 [1:53:05<19:55, 12.57it/s]
epoch 85000  training loss: 0.09379997849464417
epoch 85000  clean testing loss: 0.017297586426138878




 85%|████████▌ | 85083/100000 [1:53:13<19:46, 12.57it/s]
epoch 85100  training loss: 0.09350454807281494




 85%|████████▌ | 85183/100000 [1:53:21<19:38, 12.57it/s]
epoch 85200  training loss: 0.09318961948156357




 85%|████████▌ | 85285/100000 [1:53:29<19:32, 12.55it/s]
epoch 85300  training loss: 0.09425755590200424




 85%|████████▌ | 85385/100000 [1:53:37<19:23, 12.56it/s]
epoch 85400  training loss: 0.09389034658670425




 85%|████████▌ | 85485/100000 [1:53:45<19:15, 12.57it/s]
epoch 85500  training loss: 0.09412211924791336




 86%|████████▌ | 85585/100000 [1:53:53<19:07, 12.56it/s]
epoch 85600  training loss: 0.09369406849145889




 86%|████████▌ | 85685/100000 [1:54:01<19:03, 12.52it/s]
epoch 85700  training loss: 0.09332394599914551




 86%|████████▌ | 85787/100000 [1:54:09<18:50, 12.57it/s]
epoch 85800  training loss: 0.09338953346014023




 86%|████████▌ | 85887/100000 [1:54:17<18:44, 12.55it/s]
epoch 85900  training loss: 0.09329277276992798




 86%|████████▌ | 85987/100000 [1:54:25<18:34, 12.57it/s]
epoch 86000  training loss: 0.09316597878932953
epoch 86000  clean testing loss: 0.017482135444879532




 86%|████████▌ | 86087/100000 [1:54:33<18:28, 12.56it/s]
epoch 86100  training loss: 0.09319392591714859




 86%|████████▌ | 86189/100000 [1:54:41<18:18, 12.57it/s]
epoch 86200  training loss: 0.09332006424665451




 86%|████████▋ | 86289/100000 [1:54:49<18:12, 12.55it/s]
epoch 86300  training loss: 0.09335070848464966




 86%|████████▋ | 86389/100000 [1:54:57<18:03, 12.57it/s]
epoch 86400  training loss: 0.09350767731666565




 86%|████████▋ | 86489/100000 [1:55:05<17:55, 12.56it/s]
epoch 86500  training loss: 0.0933820977807045




 87%|████████▋ | 86591/100000 [1:55:13<17:46, 12.57it/s]
epoch 86600  training loss: 0.0933515876531601




 87%|████████▋ | 86691/100000 [1:55:21<17:38, 12.57it/s]
epoch 86700  training loss: 0.09365805983543396




 87%|████████▋ | 86791/100000 [1:55:29<17:30, 12.57it/s]
epoch 86800  training loss: 0.09409119933843613




 87%|████████▋ | 86893/100000 [1:55:37<17:23, 12.56it/s]
epoch 86900  training loss: 0.09398563951253891




 87%|████████▋ | 86993/100000 [1:55:45<17:14, 12.57it/s]
epoch 87000  training loss: 0.0940420851111412
epoch 87000  clean testing loss: 0.017549727112054825




 87%|████████▋ | 87093/100000 [1:55:53<17:07, 12.56it/s]
epoch 87100  training loss: 0.09325126558542252




 87%|████████▋ | 87193/100000 [1:56:01<17:03, 12.51it/s]
epoch 87200  training loss: 0.09410679340362549




 87%|████████▋ | 87295/100000 [1:56:09<16:50, 12.57it/s]
epoch 87300  training loss: 0.0939718559384346




 87%|████████▋ | 87395/100000 [1:56:17<16:42, 12.57it/s]
epoch 87400  training loss: 0.09332500398159027




 87%|████████▋ | 87495/100000 [1:56:25<16:34, 12.57it/s]
epoch 87500  training loss: 0.09386613219976425




 88%|████████▊ | 87595/100000 [1:56:33<16:27, 12.57it/s]
epoch 87600  training loss: 0.09375358372926712




 88%|████████▊ | 87697/100000 [1:56:41<16:18, 12.57it/s]
epoch 87700  training loss: 0.09332161396741867




 88%|████████▊ | 87797/100000 [1:56:49<16:10, 12.57it/s]
epoch 87800  training loss: 0.09310462325811386




 88%|████████▊ | 87897/100000 [1:56:57<16:03, 12.57it/s]
epoch 87900  training loss: 0.09340760111808777




 88%|████████▊ | 87997/100000 [1:57:05<15:55, 12.57it/s]
epoch 88000  training loss: 0.093491330742836
epoch 88000  clean testing loss: 0.017986664548516273




 88%|████████▊ | 88099/100000 [1:57:13<15:46, 12.58it/s]
epoch 88100  training loss: 0.09400434046983719




 88%|████████▊ | 88199/100000 [1:57:21<15:38, 12.57it/s]
epoch 88200  training loss: 0.09371816366910934




 88%|████████▊ | 88299/100000 [1:57:29<15:31, 12.56it/s]
epoch 88300  training loss: 0.09326953440904617




 88%|████████▊ | 88399/100000 [1:57:37<15:22, 12.57it/s]
epoch 88400  training loss: 0.09292218834161758




 89%|████████▊ | 88501/100000 [1:57:45<15:15, 12.56it/s]
epoch 88500  training loss: 0.0939226746559143




 89%|████████▊ | 88601/100000 [1:57:53<15:08, 12.55it/s]
epoch 88600  training loss: 0.09366270154714584




 89%|████████▊ | 88701/100000 [1:58:01<15:12, 12.38it/s]
epoch 88700  training loss: 0.09299055486917496




 89%|████████▉ | 88801/100000 [1:58:09<14:51, 12.56it/s]
epoch 88800  training loss: 0.09305073320865631




 89%|████████▉ | 88903/100000 [1:58:17<14:45, 12.53it/s]
epoch 88900  training loss: 0.09348767250776291




 89%|████████▉ | 89003/100000 [1:58:25<14:44, 12.44it/s]
epoch 89000  training loss: 0.09352337568998337
epoch 89000  clean testing loss: 0.017149530351161957




 89%|████████▉ | 89103/100000 [1:58:33<14:30, 12.52it/s]
epoch 89100  training loss: 0.09330742806196213




 89%|████████▉ | 89203/100000 [1:58:41<14:22, 12.52it/s]
epoch 89200  training loss: 0.09292541444301605




 89%|████████▉ | 89305/100000 [1:58:49<14:13, 12.54it/s]
epoch 89300  training loss: 0.0926850289106369




 89%|████████▉ | 89405/100000 [1:58:57<14:04, 12.54it/s]
epoch 89400  training loss: 0.0931139811873436




 90%|████████▉ | 89505/100000 [1:59:05<13:56, 12.54it/s]
epoch 89500  training loss: 0.09335432946681976




 90%|████████▉ | 89599/100000 [1:59:13<13:47, 12.57it/s]
epoch 89600  training loss: 0.09315928816795349



 90%|████████▉ | 89675/100000 [1:59:19<13:41, 12.57it/s]
epoch 89700  training loss: 0.09230700880289078




 90%|████████▉ | 89775/100000 [1:59:27<13:33, 12.56it/s]
epoch 89800  training loss: 0.09245773404836655




 90%|████████▉ | 89877/100000 [1:59:35<13:25, 12.57it/s]
epoch 89900  training loss: 0.09293641149997711




 90%|████████▉ | 89977/100000 [1:59:43<13:17, 12.57it/s]
epoch 90000  training loss: 0.0925159901380539
epoch 90000  clean testing loss: 0.017320256680250168




 90%|█████████ | 90077/100000 [1:59:51<13:09, 12.57it/s]
epoch 90100  training loss: 0.09301968663930893




 90%|█████████ | 90179/100000 [1:59:59<13:01, 12.57it/s]
epoch 90200  training loss: 0.09292355924844742




 90%|█████████ | 90279/100000 [2:00:07<12:53, 12.56it/s]
epoch 90300  training loss: 0.09242796897888184




 90%|█████████ | 90379/100000 [2:00:15<12:45, 12.56it/s]
epoch 90400  training loss: 0.09224535524845123




 90%|█████████ | 90479/100000 [2:00:23<12:37, 12.57it/s]
epoch 90500  training loss: 0.09320782870054245




 91%|█████████ | 90579/100000 [2:00:31<12:30, 12.55it/s]
epoch 90600  training loss: 0.09244655817747116





 91%|█████████ | 90705/100000 [2:00:41<12:21, 12.54it/s]
epoch 90700  training loss: 0.09294011443853378



 91%|█████████ | 90781/100000 [2:00:47<12:13, 12.56it/s]
epoch 90800  training loss: 0.09218719601631165




 91%|█████████ | 90881/100000 [2:00:55<12:05, 12.57it/s]
epoch 90900  training loss: 0.09281695634126663




 91%|█████████ | 90981/100000 [2:01:03<11:58, 12.55it/s]
epoch 91000  training loss: 0.09273041784763336
epoch 91000  clean testing loss: 0.01762377843260765




 91%|█████████ | 91083/100000 [2:01:11<11:49, 12.57it/s]
epoch 91100  training loss: 0.0930703803896904




 91%|█████████ | 91183/100000 [2:01:19<11:41, 12.56it/s]
epoch 91200  training loss: 0.09289772808551788




 91%|█████████▏| 91283/100000 [2:01:27<11:34, 12.56it/s]
epoch 91300  training loss: 0.09250279515981674




 91%|█████████▏| 91385/100000 [2:01:35<11:26, 12.55it/s]
epoch 91400  training loss: 0.09303773939609528




 91%|█████████▏| 91485/100000 [2:01:43<11:17, 12.57it/s]
epoch 91500  training loss: 0.09337203949689865




 92%|█████████▏| 91585/100000 [2:01:51<11:09, 12.57it/s]
epoch 91600  training loss: 0.09297318756580353




 92%|█████████▏| 91687/100000 [2:01:59<11:01, 12.57it/s]
epoch 91700  training loss: 0.09317141771316528




 92%|█████████▏| 91787/100000 [2:02:07<10:53, 12.58it/s]
epoch 91800  training loss: 0.09273499250411987




 92%|█████████▏| 91887/100000 [2:02:15<10:45, 12.58it/s]
epoch 91900  training loss: 0.09373535215854645




 92%|█████████▏| 91987/100000 [2:02:23<10:37, 12.57it/s]
epoch 92000  training loss: 0.09327416121959686
epoch 92000  clean testing loss: 0.017634930089116096




 92%|█████████▏| 92089/100000 [2:02:31<10:29, 12.57it/s]
epoch 92100  training loss: 0.09338033199310303




 92%|█████████▏| 92189/100000 [2:02:39<10:21, 12.57it/s]
epoch 92200  training loss: 0.09362023323774338




 92%|█████████▏| 92289/100000 [2:02:47<10:13, 12.57it/s]
epoch 92300  training loss: 0.09313484281301498




 92%|█████████▏| 92389/100000 [2:02:55<10:05, 12.57it/s]
epoch 92400  training loss: 0.09366092085838318




 92%|█████████▏| 92489/100000 [2:03:03<09:59, 12.53it/s]
epoch 92500  training loss: 0.0934484452009201




 93%|█████████▎| 92591/100000 [2:03:11<09:49, 12.57it/s]
epoch 92600  training loss: 0.0934186726808548




 93%|█████████▎| 92691/100000 [2:03:19<09:41, 12.57it/s]
epoch 92700  training loss: 0.09391998499631882




 93%|█████████▎| 92793/100000 [2:03:27<09:33, 12.56it/s]
epoch 92800  training loss: 0.09393108636140823




 93%|█████████▎| 92893/100000 [2:03:35<09:25, 12.56it/s]
epoch 92900  training loss: 0.09368549287319183




 93%|█████████▎| 92993/100000 [2:03:43<09:17, 12.57it/s]
epoch 93000  training loss: 0.09358539432287216
epoch 93000  clean testing loss: 0.01753428392112255




 93%|█████████▎| 93093/100000 [2:03:51<09:09, 12.57it/s]
epoch 93100  training loss: 0.09369155019521713




 93%|█████████▎| 93195/100000 [2:04:00<09:01, 12.57it/s]
epoch 93200  training loss: 0.09358981996774673




 93%|█████████▎| 93295/100000 [2:04:08<08:53, 12.57it/s]
epoch 93300  training loss: 0.09325426816940308




 93%|█████████▎| 93395/100000 [2:04:15<08:45, 12.57it/s]
epoch 93400  training loss: 0.09358860552310944




 93%|█████████▎| 93495/100000 [2:04:23<08:38, 12.54it/s]
epoch 93500  training loss: 0.0932915136218071




 94%|█████████▎| 93597/100000 [2:04:32<08:29, 12.57it/s]
epoch 93600  training loss: 0.09295937418937683




 94%|█████████▎| 93697/100000 [2:04:40<08:21, 12.57it/s]
epoch 93700  training loss: 0.09340065717697144




 94%|█████████▍| 93797/100000 [2:04:48<08:13, 12.57it/s]
epoch 93800  training loss: 0.09384828060865402




 94%|█████████▍| 93897/100000 [2:04:55<08:05, 12.56it/s]
epoch 93900  training loss: 0.09329915791749954




 94%|█████████▍| 93999/100000 [2:05:04<07:59, 12.52it/s]
epoch 94000  training loss: 0.09324294328689575
epoch 94000  clean testing loss: 0.017772119492292404




 94%|█████████▍| 94099/100000 [2:05:12<07:49, 12.56it/s]
epoch 94100  training loss: 0.09367723017930984




 94%|█████████▍| 94199/100000 [2:05:20<07:41, 12.56it/s]
epoch 94200  training loss: 0.09417380392551422




 94%|█████████▍| 94299/100000 [2:05:28<07:34, 12.54it/s]
epoch 94300  training loss: 0.09509400278329849




 94%|█████████▍| 94401/100000 [2:05:36<07:26, 12.55it/s]
epoch 94400  training loss: 0.09454178065061569




 95%|█████████▍| 94501/100000 [2:05:44<07:17, 12.56it/s]
epoch 94500  training loss: 0.09483180940151215




 95%|█████████▍| 94601/100000 [2:05:52<07:09, 12.56it/s]
epoch 94600  training loss: 0.0944826602935791




 95%|█████████▍| 94703/100000 [2:06:00<07:02, 12.53it/s]
epoch 94700  training loss: 0.09463991224765778




 95%|█████████▍| 94803/100000 [2:06:08<06:55, 12.52it/s]
epoch 94800  training loss: 0.09416598826646805




 95%|█████████▍| 94903/100000 [2:06:16<06:46, 12.53it/s]
epoch 94900  training loss: 0.09446490556001663




 95%|█████████▌| 95003/100000 [2:06:24<06:42, 12.43it/s]
epoch 95000  training loss: 0.09430696070194244
epoch 95000  clean testing loss: 0.018826326355338097




 95%|█████████▌| 95105/100000 [2:06:32<06:30, 12.54it/s]
epoch 95100  training loss: 0.0946623757481575




 95%|█████████▌| 95205/100000 [2:06:40<06:22, 12.54it/s]
epoch 95200  training loss: 0.09473741054534912




 95%|█████████▌| 95305/100000 [2:06:48<06:14, 12.54it/s]
epoch 95300  training loss: 0.09446203708648682




 95%|█████████▌| 95405/100000 [2:06:56<06:06, 12.54it/s]
epoch 95400  training loss: 0.09512703865766525




 96%|█████████▌| 95505/100000 [2:07:04<06:05, 12.28it/s]
epoch 95500  training loss: 0.09515266865491867



 96%|█████████▌| 95581/100000 [2:07:10<05:51, 12.56it/s]
epoch 95600  training loss: 0.09528259187936783




 96%|█████████▌| 95681/100000 [2:07:18<05:44, 12.56it/s]
epoch 95700  training loss: 0.09508321434259415




 96%|█████████▌| 95783/100000 [2:07:26<05:35, 12.57it/s]
epoch 95800  training loss: 0.09534970670938492




 96%|█████████▌| 95883/100000 [2:07:34<05:35, 12.29it/s]
epoch 95900  training loss: 0.09466646611690521




 96%|█████████▌| 95983/100000 [2:07:42<05:19, 12.57it/s]
epoch 96000  training loss: 0.0951717346906662
epoch 96000  clean testing loss: 0.01851174794137478




 96%|█████████▌| 96083/100000 [2:07:50<05:12, 12.55it/s]
epoch 96100  training loss: 0.09521906822919846




 96%|█████████▌| 96185/100000 [2:07:58<05:03, 12.56it/s]
epoch 96200  training loss: 0.09502681344747543




 96%|█████████▋| 96285/100000 [2:08:06<04:55, 12.57it/s]
epoch 96300  training loss: 0.09488286077976227




 96%|█████████▋| 96385/100000 [2:08:14<04:47, 12.57it/s]
epoch 96400  training loss: 0.09471860527992249




 96%|█████████▋| 96487/100000 [2:08:22<04:39, 12.57it/s]
epoch 96500  training loss: 0.09486504644155502




 97%|█████████▋| 96587/100000 [2:08:30<04:31, 12.56it/s]
epoch 96600  training loss: 0.09497715532779694




 97%|█████████▋| 96687/100000 [2:08:38<04:23, 12.55it/s]
epoch 96700  training loss: 0.09496312588453293




 97%|█████████▋| 96787/100000 [2:08:46<04:15, 12.56it/s]
epoch 96800  training loss: 0.09456583857536316




 97%|█████████▋| 96887/100000 [2:08:54<04:08, 12.54it/s]
epoch 96900  training loss: 0.0943962037563324




 97%|█████████▋| 96989/100000 [2:09:02<03:59, 12.57it/s]
epoch 97000  training loss: 0.09438800811767578
epoch 97000  clean testing loss: 0.017974499613046646




 97%|█████████▋| 97083/100000 [2:09:10<03:52, 12.57it/s]
epoch 97100  training loss: 0.09474698454141617




 97%|█████████▋| 97183/100000 [2:09:18<03:44, 12.57it/s]
epoch 97200  training loss: 0.09513960778713226




 97%|█████████▋| 97283/100000 [2:09:25<03:36, 12.57it/s]
epoch 97300  training loss: 0.09498973190784454




 97%|█████████▋| 97385/100000 [2:09:34<03:28, 12.57it/s]
epoch 97400  training loss: 0.09534414112567902




 97%|█████████▋| 97485/100000 [2:09:42<03:20, 12.57it/s]
epoch 97500  training loss: 0.09497019648551941




 98%|█████████▊| 97585/100000 [2:09:50<03:12, 12.56it/s]
epoch 97600  training loss: 0.09479041397571564




 98%|█████████▊| 97687/100000 [2:09:58<03:04, 12.57it/s]
epoch 97700  training loss: 0.09442351758480072




 98%|█████████▊| 97787/100000 [2:10:06<02:57, 12.50it/s]
epoch 97800  training loss: 0.0944366529583931




 98%|█████████▊| 97887/100000 [2:10:14<02:48, 12.57it/s]
epoch 97900  training loss: 0.09492044150829315




 98%|█████████▊| 97987/100000 [2:10:22<02:40, 12.56it/s]
epoch 98000  training loss: 0.09477148205041885
epoch 98000  clean testing loss: 0.01756664365530014




 98%|█████████▊| 98089/100000 [2:10:30<02:32, 12.57it/s]
epoch 98100  training loss: 0.09452028572559357




 98%|█████████▊| 98189/100000 [2:10:38<02:24, 12.57it/s]
epoch 98200  training loss: 0.0948031023144722




 98%|█████████▊| 98289/100000 [2:10:46<02:16, 12.57it/s]
epoch 98300  training loss: 0.09493722766637802




 98%|█████████▊| 98389/100000 [2:10:54<02:08, 12.57it/s]
epoch 98400  training loss: 0.0946248471736908




 98%|█████████▊| 98491/100000 [2:11:02<02:00, 12.57it/s]
epoch 98500  training loss: 0.0947222113609314




 99%|█████████▊| 98591/100000 [2:11:10<01:52, 12.57it/s]
epoch 98600  training loss: 0.095137819647789




 99%|█████████▊| 98691/100000 [2:11:18<01:44, 12.56it/s]
epoch 98700  training loss: 0.09468269348144531




 99%|█████████▉| 98791/100000 [2:11:26<01:36, 12.56it/s]
epoch 98800  training loss: 0.09515264630317688




 99%|█████████▉| 98893/100000 [2:11:34<01:28, 12.57it/s]
epoch 98900  training loss: 0.09535852074623108




 99%|█████████▉| 98993/100000 [2:11:42<01:20, 12.57it/s]
epoch 99000  training loss: 0.09483010321855545
epoch 99000  clean testing loss: 0.017955446615815163




 99%|█████████▉| 99093/100000 [2:11:50<01:12, 12.57it/s]
epoch 99100  training loss: 0.0949726328253746




 99%|█████████▉| 99195/100000 [2:11:58<01:04, 12.57it/s]
epoch 99200  training loss: 0.09503224492073059




 99%|█████████▉| 99295/100000 [2:12:06<00:56, 12.40it/s]
epoch 99300  training loss: 0.09517144411802292




 99%|█████████▉| 99395/100000 [2:12:14<00:48, 12.57it/s]
epoch 99400  training loss: 0.09500470012426376




 99%|█████████▉| 99495/100000 [2:12:22<00:40, 12.57it/s]
epoch 99500  training loss: 0.0950966626405716




100%|█████████▉| 99597/100000 [2:12:30<00:32, 12.57it/s]
epoch 99600  training loss: 0.09487251937389374




100%|█████████▉| 99697/100000 [2:12:38<00:24, 12.57it/s]
epoch 99700  training loss: 0.09452701359987259




100%|█████████▉| 99797/100000 [2:12:46<00:16, 12.57it/s]
epoch 99800  training loss: 0.0944455936551094




100%|█████████▉| 99897/100000 [2:12:54<00:08, 12.57it/s]
epoch 99900  training loss: 0.09470093250274658




100%|█████████▉| 99999/100000 [2:13:02<00:00, 12.57it/s]

100%|██████████| 100000/100000 [2:13:02<00:00, 12.53it/s]