
  0%|‚ñè                                                                                 | 263/100000 [00:01<07:44, 214.56it/s]
epoch 0  training loss: 0.5926247835159302
epoch 0  clean testing loss: 4.850313663482666
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 100  training loss: 0.14182008802890778
epoch 100  clean testing loss: 0.04861924797296524
epoch 200  training loss: 0.11657355725765228
epoch 200  clean testing loss: 0.03345170244574547
epoch 300  training loss: 0.1374032348394394

  1%|‚ñå                                                                                 | 710/100000 [00:03<07:48, 212.14it/s]
epoch 400  training loss: 0.12088146060705185
epoch 400  clean testing loss: 0.06422815471887589
epoch 500  training loss: 0.17492090165615082
epoch 500  clean testing loss: 0.20675010979175568
epoch 600  training loss: 0.11182078719139099
epoch 600  clean testing loss: 0.030754031613469124
epoch 700  training loss: 0.18188001215457916

  1%|‚ñâ                                                                                | 1137/100000 [00:05<07:51, 209.81it/s]
epoch 800  training loss: 0.11847188323736191
epoch 800  clean testing loss: 0.03354889899492264
epoch 900  training loss: 0.11852191388607025
epoch 900  clean testing loss: 0.03649384528398514
epoch 1000  training loss: 0.10257375240325928
epoch 1000  clean testing loss: 0.02660578489303589
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 1100  training loss: 0.12498723715543747

  2%|‚ñà‚ñé                                                                               | 1567/100000 [00:07<07:32, 217.59it/s]
epoch 1200  training loss: 0.10610797256231308
epoch 1200  clean testing loss: 0.02657109498977661
epoch 1300  training loss: 0.1779727190732956
epoch 1300  clean testing loss: 0.0995360016822815
epoch 1400  training loss: 0.10799086838960648
epoch 1400  clean testing loss: 0.02855827286839485
epoch 1500  training loss: 0.10616103559732437
epoch 1500  clean testing loss: 0.028231225907802582
epoch 1600  training loss: 0.09900090843439102

  2%|‚ñà‚ñå                                                                               | 1960/100000 [00:09<08:53, 183.65it/s]
epoch 1700  training loss: 0.09792602062225342
epoch 1700  clean testing loss: 0.02624170482158661
epoch 1800  training loss: 0.12107155472040176
epoch 1800  clean testing loss: 0.03496710956096649
epoch 1900  training loss: 0.10550326108932495
epoch 1900  clean testing loss: 0.027770381420850754
epoch 2000  training loss: 0.11770543456077576
epoch 2000  clean testing loss: 0.042675841599702835

  2%|‚ñà‚ñâ                                                                               | 2317/100000 [00:11<09:04, 179.55it/s]
epoch 2100  training loss: 0.10071533173322678
epoch 2100  clean testing loss: 0.032151367515325546
epoch 2200  training loss: 0.10659854859113693
epoch 2200  clean testing loss: 0.029873736202716827
epoch 2300  training loss: 0.09693989157676697

  3%|‚ñà‚ñà‚ñè                                                                              | 2670/100000 [00:13<09:17, 174.54it/s]
epoch 2400  training loss: 0.1348864585161209
epoch 2400  clean testing loss: 0.050427522510290146
epoch 2500  training loss: 0.09954597055912018
epoch 2500  clean testing loss: 0.028596166521310806
epoch 2600  training loss: 0.11160356551408768
epoch 2600  clean testing loss: 0.03265877068042755
epoch 2700  training loss: 0.1104525625705719

  3%|‚ñà‚ñà‚ñç                                                                              | 3045/100000 [00:15<09:04, 177.95it/s]
epoch 2800  training loss: 0.09951439499855042
epoch 2800  clean testing loss: 0.026641475036740303
epoch 2900  training loss: 0.0966019481420517
epoch 2900  clean testing loss: 0.028087209910154343
epoch 3000  training loss: 0.11958150565624237
epoch 3000  clean testing loss: 0.03957263007760048

  3%|‚ñà‚ñà‚ñä                                                                              | 3404/100000 [00:17<09:07, 176.46it/s]
epoch 3100  training loss: 0.097342349588871
epoch 3100  clean testing loss: 0.02761206403374672
epoch 3200  training loss: 0.09937332570552826
epoch 3200  clean testing loss: 0.028554841876029968
epoch 3300  training loss: 0.09050629287958145
epoch 3300  clean testing loss: 0.025952951982617378
epoch 3400  training loss: 0.09131823480129242

  4%|‚ñà‚ñà‚ñà                                                                              | 3758/100000 [00:19<09:06, 176.25it/s]
epoch 3500  training loss: 0.11569235473871231
epoch 3500  clean testing loss: 0.03910599648952484
epoch 3600  training loss: 0.10082794725894928
epoch 3600  clean testing loss: 0.030523397028446198
epoch 3700  training loss: 0.10139767825603485

  4%|‚ñà‚ñà‚ñà‚ñé                                                                             | 4111/100000 [00:21<08:59, 177.65it/s]
epoch 3800  training loss: 0.09265223145484924
epoch 3800  clean testing loss: 0.02965579740703106
epoch 3900  training loss: 0.1025434136390686
epoch 3900  clean testing loss: 0.0362367145717144
epoch 4000  training loss: 0.09223943203687668
epoch 4000  clean testing loss: 0.02839796245098114
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 4100  training loss: 0.09292950481176376

  4%|‚ñà‚ñà‚ñà‚ñå                                                                             | 4464/100000 [00:23<09:01, 176.45it/s]
epoch 4200  training loss: 0.099932000041008
epoch 4200  clean testing loss: 0.03366487845778465
epoch 4300  training loss: 0.1086515411734581
epoch 4300  clean testing loss: 0.03287086263298988
epoch 4400  training loss: 0.10126479715108871

  5%|‚ñà‚ñà‚ñà‚ñâ                                                                             | 4817/100000 [00:25<08:59, 176.47it/s]
epoch 4500  training loss: 0.1124144047498703
epoch 4500  clean testing loss: 0.03591741621494293
epoch 4600  training loss: 0.0882379561662674
epoch 4600  clean testing loss: 0.028920354321599007
epoch 4700  training loss: 0.08562319725751877
epoch 4700  clean testing loss: 0.030973736196756363
epoch 4800  training loss: 0.10049951821565628

  5%|‚ñà‚ñà‚ñà‚ñà‚ñè                                                                            | 5170/100000 [00:27<08:51, 178.51it/s]
epoch 4900  training loss: 0.08502357453107834
epoch 4900  clean testing loss: 0.028063548728823662
epoch 5000  training loss: 0.08238934725522995
epoch 5000  clean testing loss: 0.027733854949474335
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 5100  training loss: 0.08145075291395187
  5%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                            | 5410/100000 [00:28<09:04, 173.78it/s][34m[1mwandb[39m[22m: 429 encountered (Filestream rate limit exceeded, retrying in 2.0 seconds.), retrying request
  6%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                            | 5522/100000 [00:29<09:01, 174.35it/s]
epoch 5200  training loss: 0.08075544238090515
epoch 5200  clean testing loss: 0.028357530012726784
epoch 5300  training loss: 0.08055539429187775
epoch 5300  clean testing loss: 0.0282670259475708
epoch 5400  training loss: 0.11893608421087265
epoch 5400  clean testing loss: 0.06064634397625923
epoch 5500  training loss: 0.08453360199928284

  6%|‚ñà‚ñà‚ñà‚ñà‚ñä                                                                            | 5875/100000 [00:31<08:53, 176.58it/s]
epoch 5600  training loss: 0.0829562246799469
epoch 5600  clean testing loss: 0.027393067255616188
epoch 5700  training loss: 0.08386636525392532
epoch 5700  clean testing loss: 0.02899278700351715
epoch 5800  training loss: 0.0953655019402504
epoch 5800  clean testing loss: 0.030418412759900093
epoch 5900  training loss: 0.08758959919214249

  6%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                            | 6227/100000 [00:33<08:44, 178.67it/s]
epoch 6000  training loss: 0.07967644184827805
epoch 6000  clean testing loss: 0.027711037546396255
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 6100  training loss: 0.07896716147661209
epoch 6100  clean testing loss: 0.027786916121840477
epoch 6200  training loss: 0.07826922833919525

  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                           | 6578/100000 [00:35<08:57, 173.72it/s]
epoch 6300  training loss: 0.07723162323236465
epoch 6300  clean testing loss: 0.028407135978341103
epoch 6400  training loss: 0.07644864916801453
epoch 6400  clean testing loss: 0.028768261894583702
epoch 6500  training loss: 0.07581868022680283
epoch 6500  clean testing loss: 0.029132826253771782
epoch 6600  training loss: 0.13374438881874084

  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                           | 6949/100000 [00:37<08:55, 173.80it/s]
epoch 6700  training loss: 0.07778501510620117
epoch 6700  clean testing loss: 0.029623406007885933
epoch 6800  training loss: 0.07613343000411987
epoch 6800  clean testing loss: 0.02895437553524971
epoch 6900  training loss: 0.07523965835571289

  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                           | 7303/100000 [00:39<08:45, 176.37it/s]
epoch 7000  training loss: 0.07814900577068329
epoch 7000  clean testing loss: 0.04105844721198082
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 7100  training loss: 0.07540503144264221
epoch 7100  clean testing loss: 0.029126955196261406
epoch 7200  training loss: 0.07390902936458588
epoch 7200  clean testing loss: 0.029500912874937057
epoch 7300  training loss: 0.08134062588214874

  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                          | 7657/100000 [00:41<08:37, 178.48it/s]
epoch 7400  training loss: 0.07398709654808044
epoch 7400  clean testing loss: 0.02934911847114563
epoch 7500  training loss: 0.07394030690193176
epoch 7500  clean testing loss: 0.03107120841741562
epoch 7600  training loss: 0.07870371639728546

  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                          | 8008/100000 [00:43<08:48, 174.04it/s]
epoch 7700  training loss: 0.07188752293586731
epoch 7700  clean testing loss: 0.03214242681860924
epoch 7800  training loss: 0.07228501886129379
epoch 7800  clean testing loss: 0.03548690676689148
epoch 7900  training loss: 0.07106143981218338
epoch 7900  clean testing loss: 0.030909469351172447
epoch 8000  training loss: 0.07150885462760925
epoch 8000  clean testing loss: 0.03407792001962662

  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                          | 8361/100000 [00:45<08:39, 176.47it/s]
epoch 8100  training loss: 0.07202867418527603
epoch 8100  clean testing loss: 0.035009920597076416
epoch 8200  training loss: 0.0697961300611496
epoch 8200  clean testing loss: 0.03195766359567642
epoch 8300  training loss: 0.0827828124165535

  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                          | 8714/100000 [00:47<08:31, 178.57it/s]
epoch 8400  training loss: 0.06882581114768982
epoch 8400  clean testing loss: 0.03289397805929184
epoch 8500  training loss: 0.07176391035318375
epoch 8500  clean testing loss: 0.032457612454891205
epoch 8600  training loss: 0.06797481328248978
epoch 8600  clean testing loss: 0.033126138150691986
epoch 8700  training loss: 0.06765743345022202

  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                         | 9064/100000 [00:49<08:50, 171.35it/s]
epoch 8800  training loss: 0.07424341142177582
epoch 8800  clean testing loss: 0.036046020686626434
epoch 8900  training loss: 0.06809704005718231
epoch 8900  clean testing loss: 0.038502998650074005
epoch 9000  training loss: 0.07024622708559036
epoch 9000  clean testing loss: 0.03337209299206734

  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                         | 9417/100000 [00:51<08:33, 176.39it/s]
epoch 9100  training loss: 0.06737925112247467
epoch 9100  clean testing loss: 0.03382701426744461
epoch 9200  training loss: 0.06553156673908234
epoch 9200  clean testing loss: 0.0346369594335556
epoch 9300  training loss: 0.06507730484008789
epoch 9300  clean testing loss: 0.03450837358832359
epoch 9400  training loss: 0.06964210420846939

 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                         | 9770/100000 [00:53<08:25, 178.43it/s]
epoch 9500  training loss: 0.06711705774068832
epoch 9500  clean testing loss: 0.035325583070516586
epoch 9600  training loss: 0.06402195245027542
epoch 9600  clean testing loss: 0.03607841208577156
epoch 9700  training loss: 0.06975920498371124

 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                        | 10121/100000 [00:55<08:37, 173.62it/s]
epoch 9800  training loss: 0.06509432941675186
epoch 9800  clean testing loss: 0.03759327903389931
epoch 9900  training loss: 0.06304002553224564
epoch 9900  clean testing loss: 0.03553501516580582
epoch 10000  training loss: 0.06284657120704651
epoch 10000  clean testing loss: 0.036091532558202744
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 10100  training loss: 0.06238638982176781

 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 10492/100000 [00:57<08:35, 173.66it/s]
epoch 10200  training loss: 0.0629986971616745
epoch 10200  clean testing loss: 0.03707773983478546
epoch 10300  training loss: 0.06726163625717163
epoch 10300  clean testing loss: 0.04160800948739052
epoch 10400  training loss: 0.0640707015991211
 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 10696/100000 [00:58<08:28, 175.74it/s][34m[1mwandb[39m[22m: 429 encountered (Filestream rate limit exceeded, retrying in 2.4 seconds.), retrying request
 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                       | 10845/100000 [00:59<08:25, 176.51it/s]
epoch 10500  training loss: 0.06835804879665375
epoch 10500  clean testing loss: 0.03634650632739067
epoch 10600  training loss: 0.06175277382135391
epoch 10600  clean testing loss: 0.0378398634493351
epoch 10700  training loss: 0.06112958863377571
epoch 10700  clean testing loss: 0.03668373450636864
epoch 10800  training loss: 0.06077372655272484

 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 11200/100000 [01:01<08:17, 178.62it/s]
epoch 10900  training loss: 0.06208660453557968
epoch 10900  clean testing loss: 0.043427493423223495
epoch 11000  training loss: 0.06065412610769272
epoch 11000  clean testing loss: 0.03762802481651306
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 11100  training loss: 0.06946250051259995
epoch 11100  clean testing loss: 0.042606573551893234
epoch 11200  training loss: 0.06107770651578903

 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 11552/100000 [01:03<08:28, 173.86it/s]
epoch 11300  training loss: 0.05985746905207634
epoch 11300  clean testing loss: 0.0391881987452507
epoch 11400  training loss: 0.059158794581890106
epoch 11400  clean testing loss: 0.038055744022130966
epoch 11500  training loss: 0.06097572669386864

 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 11905/100000 [01:05<08:18, 176.76it/s]
epoch 11600  training loss: 0.06168685480952263
epoch 11600  clean testing loss: 0.03923133760690689
epoch 11700  training loss: 0.058201633393764496
epoch 11700  clean testing loss: 0.03999538719654083
epoch 11800  training loss: 0.05940477177500725
epoch 11800  clean testing loss: 0.04061022028326988
epoch 11900  training loss: 0.06403942406177521

 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 12259/100000 [01:07<08:11, 178.50it/s]
epoch 12000  training loss: 0.05774294584989548
epoch 12000  clean testing loss: 0.04001979902386665
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 12100  training loss: 0.05627673119306564
epoch 12100  clean testing loss: 0.04028764367103577
epoch 12200  training loss: 0.05601506680250168

 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 12611/100000 [01:09<08:23, 173.69it/s]
epoch 12300  training loss: 0.05621419474482536
epoch 12300  clean testing loss: 0.041166484355926514
epoch 12400  training loss: 0.058958642184734344
epoch 12400  clean testing loss: 0.04151485115289688
epoch 12500  training loss: 0.05501636117696762
epoch 12500  clean testing loss: 0.04101938009262085
epoch 12600  training loss: 0.05533866584300995

 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 12964/100000 [01:11<08:12, 176.71it/s]
epoch 12700  training loss: 0.05418253690004349
epoch 12700  clean testing loss: 0.0420612171292305
epoch 12800  training loss: 0.05355514958500862
epoch 12800  clean testing loss: 0.0420873761177063
epoch 12900  training loss: 0.05352912098169327

 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 13314/100000 [01:13<08:10, 176.59it/s]
epoch 13000  training loss: 0.05323934555053711
epoch 13000  clean testing loss: 0.04290374740958214
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 13100  training loss: 0.052978526800870895
epoch 13100  clean testing loss: 0.042349398136138916
epoch 13200  training loss: 0.0542009137570858
epoch 13200  clean testing loss: 0.04425075650215149
epoch 13300  training loss: 0.053419895470142365

 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                     | 13674/100000 [01:15<08:01, 179.39it/s]
epoch 13400  training loss: 0.05214591324329376
epoch 13400  clean testing loss: 0.043896447867155075
epoch 13500  training loss: 0.05319646745920181
epoch 13500  clean testing loss: 0.042634159326553345
epoch 13600  training loss: 0.05501030012965202

 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                    | 14025/100000 [01:17<08:12, 174.62it/s]
epoch 13700  training loss: 0.052793849259614944
epoch 13700  clean testing loss: 0.04500859975814819
epoch 13800  training loss: 0.05285444110631943
epoch 13800  clean testing loss: 0.04659758880734444
epoch 13900  training loss: 0.05180451273918152
epoch 13900  clean testing loss: 0.04494757950305939
epoch 14000  training loss: 0.05306142941117287
epoch 14000  clean testing loss: 0.04365430027246475

 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 14396/100000 [01:19<08:09, 174.73it/s]
epoch 14100  training loss: 0.05105103179812431
epoch 14100  clean testing loss: 0.04760664701461792
epoch 14200  training loss: 0.05066695809364319
epoch 14200  clean testing loss: 0.04528624191880226
epoch 14300  training loss: 0.05041755735874176

 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 14749/100000 [01:21<07:57, 178.50it/s]
epoch 14400  training loss: 0.049982018768787384
epoch 14400  clean testing loss: 0.04539923369884491
epoch 14500  training loss: 0.052313677966594696
epoch 14500  clean testing loss: 0.04503743350505829
epoch 14600  training loss: 0.04943343624472618
epoch 14600  clean testing loss: 0.04592461511492729
epoch 14700  training loss: 0.050943415611982346

 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                    | 15103/100000 [01:23<07:53, 179.22it/s]
epoch 14800  training loss: 0.05011602118611336
epoch 14800  clean testing loss: 0.04730316996574402
epoch 14900  training loss: 0.053487762808799744
epoch 14900  clean testing loss: 0.04737656190991402
epoch 15000  training loss: 0.04909665882587433
epoch 15000  clean testing loss: 0.04646282270550728
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 15100  training loss: 0.04873089864850044

 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                   | 15455/100000 [01:25<08:03, 174.81it/s]
epoch 15200  training loss: 0.04850490763783455
epoch 15200  clean testing loss: 0.04677765443921089
epoch 15300  training loss: 0.04848260059952736
epoch 15300  clean testing loss: 0.047828309237957
epoch 15400  training loss: 0.04829299449920654

 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 15808/100000 [01:27<07:52, 178.08it/s]
epoch 15500  training loss: 0.04785348102450371
epoch 15500  clean testing loss: 0.048057179898023605
epoch 15600  training loss: 0.04899229109287262
epoch 15600  clean testing loss: 0.04788238927721977
epoch 15700  training loss: 0.05001521110534668
epoch 15700  clean testing loss: 0.04940781369805336
epoch 15800  training loss: 0.047861792147159576

 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 16160/100000 [01:29<07:47, 179.17it/s]
epoch 15900  training loss: 0.04747666418552399
epoch 15900  clean testing loss: 0.04868430644273758
epoch 16000  training loss: 0.05139155313372612
epoch 16000  clean testing loss: 0.05255626142024994
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 16100  training loss: 0.05003480613231659

 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 16512/100000 [01:31<07:54, 176.06it/s]
epoch 16200  training loss: 0.04760867357254028
epoch 16200  clean testing loss: 0.04912387952208519
epoch 16300  training loss: 0.04794952645897865
epoch 16300  clean testing loss: 0.05113612487912178
epoch 16400  training loss: 0.04683288559317589
epoch 16400  clean testing loss: 0.049540404230356216
epoch 16500  training loss: 0.05102691426873207

 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 16865/100000 [01:33<07:45, 178.72it/s]
epoch 16600  training loss: 0.05012745037674904
epoch 16600  clean testing loss: 0.05218372866511345
epoch 16700  training loss: 0.04670679569244385
epoch 16700  clean testing loss: 0.04991736635565758
epoch 16800  training loss: 0.04791562631726265

 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 17236/100000 [01:35<07:45, 177.95it/s]
epoch 16900  training loss: 0.06153903156518936
epoch 16900  clean testing loss: 0.05461433529853821
epoch 17000  training loss: 0.0470285564661026
epoch 17000  clean testing loss: 0.051644571125507355
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 17100  training loss: 0.04619770124554634
epoch 17100  clean testing loss: 0.05083621293306351
epoch 17200  training loss: 0.04772863909602165

 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                  | 17588/100000 [01:37<07:46, 176.65it/s]
epoch 17300  training loss: 0.04680265486240387
epoch 17300  clean testing loss: 0.05053091049194336
epoch 17400  training loss: 0.05147242173552513
epoch 17400  clean testing loss: 0.049837734550237656
epoch 17500  training loss: 0.05840437486767769

 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                 | 17941/100000 [01:39<07:44, 176.68it/s]
epoch 17600  training loss: 0.04598504304885864
epoch 17600  clean testing loss: 0.051459964364767075
epoch 17700  training loss: 0.04601062089204788
epoch 17700  clean testing loss: 0.053133513778448105
epoch 17800  training loss: 0.04621237888932228
epoch 17800  clean testing loss: 0.0544961541891098
epoch 17900  training loss: 0.048787716776132584

 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                 | 18294/100000 [01:41<07:37, 178.46it/s]
epoch 18000  training loss: 0.04661757871508598
epoch 18000  clean testing loss: 0.05251145362854004
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 18100  training loss: 0.045371055603027344
epoch 18100  clean testing loss: 0.05205174535512924
epoch 18200  training loss: 0.04527268186211586

 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 18628/100000 [01:43<07:40, 176.63it/s]
epoch 18300  training loss: 0.045480865985155106
epoch 18300  clean testing loss: 0.05270185321569443
epoch 18400  training loss: 0.04506092146039009
epoch 18400  clean testing loss: 0.05324353650212288
epoch 18500  training loss: 0.0458858385682106
epoch 18500  clean testing loss: 0.053478121757507324
epoch 18600  training loss: 0.04610826075077057

 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 18998/100000 [01:45<07:37, 177.03it/s]
epoch 18700  training loss: 0.047723885625600815
epoch 18700  clean testing loss: 0.05451266095042229
epoch 18800  training loss: 0.0451335571706295
epoch 18800  clean testing loss: 0.05396959185600281
epoch 18900  training loss: 0.04499610513448715

 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                | 19352/100000 [01:47<07:31, 178.81it/s]
epoch 19000  training loss: 0.0461810864508152
epoch 19000  clean testing loss: 0.05515410751104355
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 19100  training loss: 0.04458584636449814
epoch 19100  clean testing loss: 0.05444116145372391
epoch 19200  training loss: 0.044707994908094406
epoch 19200  clean testing loss: 0.05385168641805649
epoch 19300  training loss: 0.04539820924401283

 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                | 19704/100000 [01:49<07:39, 174.56it/s]
epoch 19400  training loss: 0.04637999087572098
epoch 19400  clean testing loss: 0.053922947496175766
epoch 19500  training loss: 0.04428672417998314
epoch 19500  clean testing loss: 0.055107489228248596
epoch 19600  training loss: 0.04559462144970894
epoch 19600  clean testing loss: 0.05718645453453064
epoch 19700  training loss: 0.044297270476818085

 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 20058/100000 [01:51<07:34, 175.94it/s]
epoch 19800  training loss: 0.04429461434483528
epoch 19800  clean testing loss: 0.0564798079431057
epoch 19900  training loss: 0.046059802174568176
epoch 19900  clean testing loss: 0.05666377767920494
epoch 20000  training loss: 0.04407792165875435
epoch 20000  clean testing loss: 0.05504162982106209

 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 20429/100000 [01:53<07:30, 176.47it/s]
epoch 20100  training loss: 0.04391319304704666
epoch 20100  clean testing loss: 0.055204737931489944
epoch 20200  training loss: 0.04398147761821747
epoch 20200  clean testing loss: 0.055438652634620667
epoch 20300  training loss: 0.04468030855059624
epoch 20300  clean testing loss: 0.0556245781481266
epoch 20400  training loss: 0.04448713734745979

 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 20782/100000 [01:55<07:23, 178.77it/s]
epoch 20500  training loss: 0.04391656443476677
epoch 20500  clean testing loss: 0.05525759235024452
epoch 20600  training loss: 0.04404982179403305
epoch 20600  clean testing loss: 0.05510466918349266
epoch 20700  training loss: 0.043541330844163895

 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 21134/100000 [01:57<07:29, 175.54it/s]
epoch 20800  training loss: 0.04392049089074135
epoch 20800  clean testing loss: 0.05870428681373596
epoch 20900  training loss: 0.05253607779741287
epoch 20900  clean testing loss: 0.05564304441213608
epoch 21000  training loss: 0.04408884793519974
epoch 21000  clean testing loss: 0.055858317762613297
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 21100  training loss: 0.043390221893787384

 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 21488/100000 [01:59<07:24, 176.66it/s]
epoch 21200  training loss: 0.04365343600511551
epoch 21200  clean testing loss: 0.05592354014515877
epoch 21300  training loss: 0.04324004426598549
epoch 21300  clean testing loss: 0.05620967969298363
epoch 21400  training loss: 0.04319026321172714

 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 21841/100000 [02:01<07:17, 178.84it/s]
epoch 21500  training loss: 0.04343347251415253
epoch 21500  clean testing loss: 0.05625239014625549
epoch 21600  training loss: 0.04337098449468613
epoch 21600  clean testing loss: 0.05734819918870926
epoch 21700  training loss: 0.042997948825359344
epoch 21700  clean testing loss: 0.057308491319417953
epoch 21800  training loss: 0.04307127371430397

 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                              | 22194/100000 [02:03<07:15, 178.60it/s]
epoch 21900  training loss: 0.04356676712632179
epoch 21900  clean testing loss: 0.0567794069647789
epoch 22000  training loss: 0.04316697269678116
epoch 22000  clean testing loss: 0.05753065645694733
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 22100  training loss: 0.04300916567444801

 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                              | 22547/100000 [02:05<07:19, 176.18it/s]
epoch 22200  training loss: 0.04299609735608101
epoch 22200  clean testing loss: 0.0578080378472805
epoch 22300  training loss: 0.04491334408521652
epoch 22300  clean testing loss: 0.0574081689119339
epoch 22400  training loss: 0.043279435485601425
epoch 22400  clean testing loss: 0.05812967196106911
epoch 22500  training loss: 0.042942143976688385

 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                             | 22900/100000 [02:07<07:11, 178.76it/s]
epoch 22600  training loss: 0.042613428086042404
epoch 22600  clean testing loss: 0.057994015514850616
epoch 22700  training loss: 0.042611196637153625
epoch 22700  clean testing loss: 0.057953666895627975
epoch 22800  training loss: 0.04298994317650795

 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 23254/100000 [02:09<07:00, 182.49it/s]
epoch 22900  training loss: 0.042768288403749466
epoch 22900  clean testing loss: 0.058626748621463776
epoch 23000  training loss: 0.0425463430583477
epoch 23000  clean testing loss: 0.05786289647221565
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 23100  training loss: 0.04313516244292259
epoch 23100  clean testing loss: 0.05874697491526604
epoch 23200  training loss: 0.04230739176273346

 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 23616/100000 [02:11<07:03, 180.32it/s]
epoch 23300  training loss: 0.04301100969314575
epoch 23300  clean testing loss: 0.05955556407570839
epoch 23400  training loss: 0.04340248182415962
epoch 23400  clean testing loss: 0.058564286679029465
epoch 23500  training loss: 0.04234553128480911
epoch 23500  clean testing loss: 0.05863667652010918
epoch 23600  training loss: 0.04268727824091911

 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                            | 23969/100000 [02:13<07:13, 175.34it/s]
epoch 23700  training loss: 0.04300713911652565
epoch 23700  clean testing loss: 0.05869646742939949
epoch 23800  training loss: 0.043466005474328995
epoch 23800  clean testing loss: 0.05864657834172249
epoch 23900  training loss: 0.04215347394347191

 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                            | 24322/100000 [02:15<07:04, 178.41it/s]
epoch 24000  training loss: 0.04204120114445686
epoch 24000  clean testing loss: 0.0593017153441906
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 24100  training loss: 0.04196199029684067
epoch 24100  clean testing loss: 0.05930640920996666
epoch 24200  training loss: 0.042116545140743256
epoch 24200  clean testing loss: 0.05895150452852249
epoch 24300  training loss: 0.04194151237607002

 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                            | 24693/100000 [02:17<07:01, 178.54it/s]
epoch 24400  training loss: 0.04222754389047623
epoch 24400  clean testing loss: 0.05896678939461708
epoch 24500  training loss: 0.04192235693335533
epoch 24500  clean testing loss: 0.06118784472346306
epoch 24600  training loss: 0.04196000471711159

 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 25058/100000 [02:19<06:14, 199.95it/s]
epoch 24700  training loss: 0.04198743402957916
epoch 24700  clean testing loss: 0.059909190982580185
epoch 24800  training loss: 0.04193233326077461
epoch 24800  clean testing loss: 0.06018771976232529
epoch 24900  training loss: 0.04182950779795647
epoch 24900  clean testing loss: 0.060292087495326996
epoch 25000  training loss: 0.04171314463019371
epoch 25000  clean testing loss: 0.05986233055591583

 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                           | 25471/100000 [02:21<05:55, 209.86it/s]
epoch 25100  training loss: 0.041874874383211136
epoch 25100  clean testing loss: 0.05966530367732048
epoch 25200  training loss: 0.04314272105693817
epoch 25200  clean testing loss: 0.06423128396272659
epoch 25300  training loss: 0.04167144373059273
epoch 25300  clean testing loss: 0.0599486343562603
epoch 25400  training loss: 0.0416424386203289

 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                           | 25882/100000 [02:23<06:04, 203.27it/s]
epoch 25500  training loss: 0.04184803366661072
epoch 25500  clean testing loss: 0.06163989380002022
epoch 25600  training loss: 0.041271086782217026
epoch 25600  clean testing loss: 0.060871850699186325
epoch 25700  training loss: 0.04129019379615784
epoch 25700  clean testing loss: 0.06177275627851486
epoch 25800  training loss: 0.04152506962418556

 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                           | 26295/100000 [02:25<06:04, 202.06it/s]
epoch 25900  training loss: 0.041258130222558975
epoch 25900  clean testing loss: 0.06101864203810692
epoch 26000  training loss: 0.04227270558476448
epoch 26000  clean testing loss: 0.06321962922811508
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 26100  training loss: 0.04096643626689911
epoch 26100  clean testing loss: 0.06130227819085121
epoch 26200  training loss: 0.0409441702067852

 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 26708/100000 [02:27<05:55, 206.22it/s]
epoch 26300  training loss: 0.04100034385919571
epoch 26300  clean testing loss: 0.061702776700258255
epoch 26400  training loss: 0.04167556017637253
epoch 26400  clean testing loss: 0.06173863634467125
epoch 26500  training loss: 0.04102843627333641
epoch 26500  clean testing loss: 0.06269557774066925
epoch 26600  training loss: 0.04078824073076248

 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                          | 27119/100000 [02:29<05:51, 207.12it/s]
epoch 26700  training loss: 0.041436538100242615
epoch 26700  clean testing loss: 0.06051347032189369
epoch 26800  training loss: 0.04083795100450516
epoch 26800  clean testing loss: 0.06189418211579323
epoch 26900  training loss: 0.04094665125012398
epoch 26900  clean testing loss: 0.06247013062238693
epoch 27000  training loss: 0.04107893258333206
epoch 27000  clean testing loss: 0.06111433729529381

 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                          | 27533/100000 [02:31<05:45, 209.68it/s]
epoch 27100  training loss: 0.04054935276508331
epoch 27100  clean testing loss: 0.062256477773189545
epoch 27200  training loss: 0.04058101773262024
epoch 27200  clean testing loss: 0.061905328184366226
epoch 27300  training loss: 0.04045045003294945
epoch 27300  clean testing loss: 0.06256425380706787
epoch 27400  training loss: 0.04062753915786743
epoch 27400  clean testing loss: 0.062075261026620865
epoch 27500  training loss: 0.04042201489210129

 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                         | 27944/100000 [02:33<05:54, 203.04it/s]
epoch 27600  training loss: 0.04053522273898125
epoch 27600  clean testing loss: 0.06334150582551956
epoch 27700  training loss: 0.04041913151741028
epoch 27700  clean testing loss: 0.06231193244457245
epoch 27800  training loss: 0.04033633694052696
epoch 27800  clean testing loss: 0.06290426850318909
epoch 27900  training loss: 0.04023093357682228

 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                         | 28357/100000 [02:35<05:48, 205.31it/s]
epoch 28000  training loss: 0.04014960676431656
epoch 28000  clean testing loss: 0.06298349797725677
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 28100  training loss: 0.0402713306248188
epoch 28100  clean testing loss: 0.06361965835094452
epoch 28200  training loss: 0.04029494524002075
epoch 28200  clean testing loss: 0.06352409720420837
epoch 28300  training loss: 0.04015956073999405

 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                         | 28772/100000 [02:37<05:43, 207.43it/s]
epoch 28400  training loss: 0.04010755196213722
epoch 28400  clean testing loss: 0.06371772289276123
epoch 28500  training loss: 0.04072866216301918
epoch 28500  clean testing loss: 0.06275162845849991
epoch 28600  training loss: 0.03990200161933899
epoch 28600  clean testing loss: 0.0633322075009346
epoch 28700  training loss: 0.040009140968322754

 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 29186/100000 [02:39<05:41, 207.62it/s]
epoch 28800  training loss: 0.039970919489860535
epoch 28800  clean testing loss: 0.06347659975290298
epoch 28900  training loss: 0.03999209776520729
epoch 28900  clean testing loss: 0.06385825574398041
epoch 29000  training loss: 0.040123350918293
epoch 29000  clean testing loss: 0.06355517357587814
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 29100  training loss: 0.04022836312651634

 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                        | 29599/100000 [02:41<05:35, 209.73it/s]
epoch 29200  training loss: 0.03971558436751366
epoch 29200  clean testing loss: 0.0640595331788063
epoch 29300  training loss: 0.03965095058083534
epoch 29300  clean testing loss: 0.06396154314279556
epoch 29400  training loss: 0.040709588676691055
epoch 29400  clean testing loss: 0.06370380520820618
epoch 29500  training loss: 0.03976871073246002

 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                        | 30012/100000 [02:44<05:49, 199.99it/s]
epoch 29600  training loss: 0.03955359756946564
epoch 29600  clean testing loss: 0.0644589439034462
epoch 29700  training loss: 0.039690352976322174
epoch 29700  clean testing loss: 0.06458617001771927
epoch 29800  training loss: 0.039528217166662216
epoch 29800  clean testing loss: 0.0646756961941719
epoch 29900  training loss: 0.04011005535721779

 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 30425/100000 [02:46<05:39, 204.91it/s]
epoch 30000  training loss: 0.039391715079545975
epoch 30000  clean testing loss: 0.06458110362291336
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 30100  training loss: 0.03933791443705559
epoch 30100  clean testing loss: 0.06478302925825119
epoch 30200  training loss: 0.03922843188047409
epoch 30200  clean testing loss: 0.0648789256811142
epoch 30300  training loss: 0.03925369679927826
epoch 30300  clean testing loss: 0.0649641901254654
epoch 30400  training loss: 0.03920254856348038

 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 30839/100000 [02:48<05:35, 206.42it/s]
epoch 30500  training loss: 0.03938676416873932
epoch 30500  clean testing loss: 0.06537837535142899
epoch 30600  training loss: 0.03922576457262039
epoch 30600  clean testing loss: 0.06531795114278793
epoch 30700  training loss: 0.039089370518922806
epoch 30700  clean testing loss: 0.06472849100828171
epoch 30800  training loss: 0.03941139578819275

 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                       | 31252/100000 [02:50<05:28, 209.32it/s]
epoch 30900  training loss: 0.03941095620393753
epoch 30900  clean testing loss: 0.06589095294475555
epoch 31000  training loss: 0.03901515528559685
epoch 31000  clean testing loss: 0.06586136668920517
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 31100  training loss: 0.03971589729189873
epoch 31100  clean testing loss: 0.0658452957868576
epoch 31200  training loss: 0.03894278407096863

 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                      | 31686/100000 [02:52<05:31, 206.36it/s]
epoch 31300  training loss: 0.038974322378635406
epoch 31300  clean testing loss: 0.0658840760588646
epoch 31400  training loss: 0.039235878735780716
epoch 31400  clean testing loss: 0.06699669361114502
epoch 31500  training loss: 0.03927549719810486
epoch 31500  clean testing loss: 0.0663413554430008
epoch 31600  training loss: 0.03943939507007599

 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                      | 32100/100000 [02:54<05:26, 208.10it/s]
epoch 31700  training loss: 0.03916347771883011
epoch 31700  clean testing loss: 0.06589271873235703
epoch 31800  training loss: 0.03895141929388046
epoch 31800  clean testing loss: 0.06614071875810623
epoch 31900  training loss: 0.03870198875665665
epoch 31900  clean testing loss: 0.06602755934000015
epoch 32000  training loss: 0.03873694688081741
epoch 32000  clean testing loss: 0.06673019379377365

 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 32514/100000 [02:56<05:22, 209.01it/s]
epoch 32100  training loss: 0.03860672935843468
epoch 32100  clean testing loss: 0.06656333059072495
epoch 32200  training loss: 0.03855381906032562
epoch 32200  clean testing loss: 0.06677818298339844
epoch 32300  training loss: 0.03994685038924217
epoch 32300  clean testing loss: 0.06652878224849701
epoch 32400  training loss: 0.03878702595829964

 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                     | 32927/100000 [02:58<05:26, 205.68it/s]
epoch 32500  training loss: 0.03947629779577255
epoch 32500  clean testing loss: 0.06951596587896347
epoch 32600  training loss: 0.03871351107954979
epoch 32600  clean testing loss: 0.06825245171785355
epoch 32700  training loss: 0.03877018392086029
epoch 32700  clean testing loss: 0.0672951489686966
epoch 32800  training loss: 0.03850303590297699

 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 33340/100000 [03:00<05:27, 203.64it/s]
epoch 32900  training loss: 0.03877422586083412
epoch 32900  clean testing loss: 0.06821977347135544
epoch 33000  training loss: 0.038272127509117126
epoch 33000  clean testing loss: 0.06774947047233582
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 33100  training loss: 0.03826475888490677
epoch 33100  clean testing loss: 0.06790687143802643
epoch 33200  training loss: 0.03823293745517731

 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                     | 33756/100000 [03:02<05:25, 203.67it/s]
epoch 33300  training loss: 0.03815092518925667
epoch 33300  clean testing loss: 0.06814001500606537
epoch 33400  training loss: 0.03829493746161461
epoch 33400  clean testing loss: 0.06786967813968658
epoch 33500  training loss: 0.03810213506221771
epoch 33500  clean testing loss: 0.06865587085485458
epoch 33600  training loss: 0.03833385929465294
epoch 33600  clean testing loss: 0.06824348866939545
epoch 33700  training loss: 0.038025230169296265

 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 34170/100000 [03:04<05:21, 204.75it/s]
epoch 33800  training loss: 0.03803935647010803
epoch 33800  clean testing loss: 0.06839767843484879
epoch 33900  training loss: 0.038196053355932236
epoch 33900  clean testing loss: 0.06857175379991531
epoch 34000  training loss: 0.037869371473789215
epoch 34000  clean testing loss: 0.06878390908241272
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 34100  training loss: 0.0380881130695343

 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 34584/100000 [03:06<05:17, 206.13it/s]
epoch 34200  training loss: 0.03830353543162346
epoch 34200  clean testing loss: 0.06872987002134323
epoch 34300  training loss: 0.03786362707614899
epoch 34300  clean testing loss: 0.06953518837690353
epoch 34400  training loss: 0.03799845278263092
epoch 34400  clean testing loss: 0.06907618790864944
epoch 34500  training loss: 0.038261305540800095

 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                    | 34997/100000 [03:08<05:13, 207.55it/s]
epoch 34600  training loss: 0.03764616698026657
epoch 34600  clean testing loss: 0.06936708092689514
epoch 34700  training loss: 0.03771122172474861
epoch 34700  clean testing loss: 0.07020723074674606
epoch 34800  training loss: 0.037874724715948105
epoch 34800  clean testing loss: 0.07048139721155167
epoch 34900  training loss: 0.037787456065416336

 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 35410/100000 [03:10<05:08, 209.42it/s]
epoch 35000  training loss: 0.03781326487660408
epoch 35000  clean testing loss: 0.07056228816509247
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 35100  training loss: 0.03791729733347893
epoch 35100  clean testing loss: 0.06922022253274918
epoch 35200  training loss: 0.03747721016407013
epoch 35200  clean testing loss: 0.06971307843923569
epoch 35300  training loss: 0.037552617490291595

 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                   | 35821/100000 [03:12<05:16, 202.74it/s]
epoch 35400  training loss: 0.037856850773096085
epoch 35400  clean testing loss: 0.07229643315076828
epoch 35500  training loss: 0.037474896758794785
epoch 35500  clean testing loss: 0.07020658999681473
epoch 35600  training loss: 0.03743007779121399
epoch 35600  clean testing loss: 0.07067816704511642
epoch 35700  training loss: 0.03737713769078255

 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                   | 36234/100000 [03:14<05:10, 205.06it/s]
epoch 35800  training loss: 0.03729861602187157
epoch 35800  clean testing loss: 0.0708671286702156
epoch 35900  training loss: 0.03729206323623657
epoch 35900  clean testing loss: 0.0710548534989357
epoch 36000  training loss: 0.03739219158887863
epoch 36000  clean testing loss: 0.07066035270690918
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 36100  training loss: 0.037248678505420685

 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                  | 36647/100000 [03:16<05:07, 206.20it/s]
epoch 36200  training loss: 0.03718676045536995
epoch 36200  clean testing loss: 0.07066845893859863
epoch 36300  training loss: 0.03714798018336296
epoch 36300  clean testing loss: 0.07141054421663284
epoch 36400  training loss: 0.03713904693722725
epoch 36400  clean testing loss: 0.07149234414100647
epoch 36500  training loss: 0.037143927067518234
epoch 36500  clean testing loss: 0.07117518782615662
epoch 36600  training loss: 0.037135254591703415

 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                  | 37060/100000 [03:18<05:04, 206.46it/s]
epoch 36700  training loss: 0.03704829514026642
epoch 36700  clean testing loss: 0.07116883993148804
epoch 36800  training loss: 0.037089791148900986
epoch 36800  clean testing loss: 0.07159111648797989
epoch 36900  training loss: 0.03720710799098015
epoch 36900  clean testing loss: 0.07125116884708405
epoch 37000  training loss: 0.0371391661465168
epoch 37000  clean testing loss: 0.07198643684387207

 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 37473/100000 [03:20<05:00, 208.21it/s]
epoch 37100  training loss: 0.03696278855204582
epoch 37100  clean testing loss: 0.07202568650245667
epoch 37200  training loss: 0.03706679120659828
epoch 37200  clean testing loss: 0.07257025688886642
epoch 37300  training loss: 0.03713245689868927
epoch 37300  clean testing loss: 0.07163131982088089
epoch 37400  training loss: 0.036938056349754333

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 37885/100000 [03:22<05:05, 203.04it/s]
epoch 37500  training loss: 0.03685963898897171
epoch 37500  clean testing loss: 0.0714665949344635
epoch 37600  training loss: 0.036829154938459396
epoch 37600  clean testing loss: 0.07196784764528275
epoch 37700  training loss: 0.036908648908138275
epoch 37700  clean testing loss: 0.07232383638620377
epoch 37800  training loss: 0.036933060735464096

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 38297/100000 [03:24<05:01, 204.74it/s]
epoch 37900  training loss: 0.03681115806102753
epoch 37900  clean testing loss: 0.07193250209093094
epoch 38000  training loss: 0.036805957555770874
epoch 38000  clean testing loss: 0.07236554473638535
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 38100  training loss: 0.03682072460651398
epoch 38100  clean testing loss: 0.0722506120800972
epoch 38200  training loss: 0.03670171648263931

 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                 | 38709/100000 [03:26<04:55, 207.15it/s]
epoch 38300  training loss: 0.036727357655763626
epoch 38300  clean testing loss: 0.07244208455085754
epoch 38400  training loss: 0.03673749789595604
epoch 38400  clean testing loss: 0.07263142615556717
epoch 38500  training loss: 0.03681008890271187
epoch 38500  clean testing loss: 0.072211354970932
epoch 38600  training loss: 0.03664734959602356

 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                | 39013/100000 [03:27<04:55, 206.37it/s]
epoch 38700  training loss: 0.03678051754832268
epoch 38700  clean testing loss: 0.07345074415206909
epoch 38800  training loss: 0.036697953939437866
epoch 38800  clean testing loss: 0.07251562178134918
epoch 38900  training loss: 0.036554090678691864
epoch 38900  clean testing loss: 0.07293669879436493
epoch 39000  training loss: 0.03656844049692154
epoch 39000  clean testing loss: 0.07302214205265045

 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 39425/100000 [03:29<05:00, 201.58it/s]
epoch 39100  training loss: 0.03649916127324104
epoch 39100  clean testing loss: 0.07349973917007446
epoch 39200  training loss: 0.03654571622610092
epoch 39200  clean testing loss: 0.07330819219350815
epoch 39300  training loss: 0.036465104669332504
epoch 39300  clean testing loss: 0.07337592542171478
epoch 39400  training loss: 0.0364563874900341

 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                | 39839/100000 [03:31<04:55, 203.80it/s]
epoch 39500  training loss: 0.03642282262444496
epoch 39500  clean testing loss: 0.07318540662527084
epoch 39600  training loss: 0.03642020747065544
epoch 39600  clean testing loss: 0.07356025278568268
epoch 39700  training loss: 0.036407601088285446
epoch 39700  clean testing loss: 0.0736207440495491
epoch 39800  training loss: 0.03640983998775482

 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 40251/100000 [03:33<04:50, 205.50it/s]
epoch 39900  training loss: 0.03648751229047775
epoch 39900  clean testing loss: 0.07326337695121765
epoch 40000  training loss: 0.03634055331349373
epoch 40000  clean testing loss: 0.07380542159080505
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 40100  training loss: 0.03630909323692322
epoch 40100  clean testing loss: 0.07396675646305084
epoch 40200  training loss: 0.03633618727326393
epoch 40200  clean testing loss: 0.07391029596328735
epoch 40300  training loss: 0.036502622067928314

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 40665/100000 [03:35<04:44, 208.56it/s]
epoch 40400  training loss: 0.03628316894173622
epoch 40400  clean testing loss: 0.07427023351192474
epoch 40500  training loss: 0.036212146282196045
epoch 40500  clean testing loss: 0.0748036578297615
epoch 40600  training loss: 0.036178428679704666
epoch 40600  clean testing loss: 0.0747496709227562
epoch 40700  training loss: 0.036226123571395874

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 41078/100000 [03:37<04:43, 207.97it/s]
epoch 40800  training loss: 0.03611680865287781
epoch 40800  clean testing loss: 0.07465963810682297
epoch 40900  training loss: 0.036142800003290176
epoch 40900  clean testing loss: 0.07474896311759949
epoch 41000  training loss: 0.036094117909669876
epoch 41000  clean testing loss: 0.07463418692350388
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 41100  training loss: 0.036259669810533524

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                              | 41489/100000 [03:39<04:50, 201.69it/s]
epoch 41200  training loss: 0.036233872175216675
epoch 41200  clean testing loss: 0.07455062121152878
epoch 41300  training loss: 0.0360819473862648
epoch 41300  clean testing loss: 0.0751187726855278
epoch 41400  training loss: 0.03604143112897873
epoch 41400  clean testing loss: 0.07484230399131775
epoch 41500  training loss: 0.03599434345960617

 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 41901/100000 [03:41<04:44, 204.39it/s]
epoch 41600  training loss: 0.036297839134931564
epoch 41600  clean testing loss: 0.07625870406627655
epoch 41700  training loss: 0.03599514812231064
epoch 41700  clean testing loss: 0.0748990848660469
epoch 41800  training loss: 0.0359485000371933
epoch 41800  clean testing loss: 0.07531087100505829
epoch 41900  training loss: 0.03603264316916466

 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 42315/100000 [03:43<04:40, 205.54it/s]
epoch 42000  training loss: 0.03608928248286247
epoch 42000  clean testing loss: 0.07517015188932419
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 42100  training loss: 0.03583916649222374
epoch 42100  clean testing loss: 0.07570689916610718
epoch 42200  training loss: 0.035825274884700775
epoch 42200  clean testing loss: 0.07545873522758484
epoch 42300  training loss: 0.03586428239941597

 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 42728/100000 [03:45<04:36, 207.23it/s]
epoch 42400  training loss: 0.035808347165584564
epoch 42400  clean testing loss: 0.07595422118902206
epoch 42500  training loss: 0.03585038334131241
epoch 42500  clean testing loss: 0.07581774145364761
epoch 42600  training loss: 0.03581059351563454
epoch 42600  clean testing loss: 0.07619743794202805
epoch 42700  training loss: 0.035872384905815125

 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 43142/100000 [03:47<04:32, 208.75it/s]
epoch 42800  training loss: 0.03576551377773285
epoch 42800  clean testing loss: 0.0763864815235138
epoch 42900  training loss: 0.03572094812989235
epoch 42900  clean testing loss: 0.0763118788599968
epoch 43000  training loss: 0.0356719084084034
epoch 43000  clean testing loss: 0.076510488986969
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 43100  training loss: 0.03576920926570892

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 43554/100000 [03:49<04:39, 202.05it/s]
epoch 43200  training loss: 0.03566359356045723
epoch 43200  clean testing loss: 0.07688352465629578
epoch 43300  training loss: 0.035862602293491364
epoch 43300  clean testing loss: 0.07741095125675201
epoch 43400  training loss: 0.035783812403678894
epoch 43400  clean testing loss: 0.07714571058750153
epoch 43500  training loss: 0.03559008985757828
epoch 43500  clean testing loss: 0.07634247094392776
epoch 43600  training loss: 0.03561067208647728

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 43973/100000 [03:51<04:31, 206.57it/s]
epoch 43700  training loss: 0.03552745282649994
epoch 43700  clean testing loss: 0.07600519061088562
epoch 43800  training loss: 0.03559136390686035
epoch 43800  clean testing loss: 0.07739189267158508
epoch 43900  training loss: 0.03561757132411003
epoch 43900  clean testing loss: 0.07669352740049362
epoch 44000  training loss: 0.0355997271835804
epoch 44000  clean testing loss: 0.07643518596887589

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 44386/100000 [03:53<04:33, 203.15it/s]
epoch 44100  training loss: 0.03555928170681
epoch 44100  clean testing loss: 0.07614032924175262
epoch 44200  training loss: 0.03546157106757164
epoch 44200  clean testing loss: 0.0769905298948288
epoch 44300  training loss: 0.03560955077409744
epoch 44300  clean testing loss: 0.07664749771356583
epoch 44400  training loss: 0.03559618070721626

 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                            | 44800/100000 [03:55<04:28, 205.65it/s]
epoch 44500  training loss: 0.0354284942150116
epoch 44500  clean testing loss: 0.07763423770666122
epoch 44600  training loss: 0.03557870537042618
epoch 44600  clean testing loss: 0.07748549431562424
epoch 44700  training loss: 0.03538532927632332
epoch 44700  clean testing loss: 0.0767737403512001
epoch 44800  training loss: 0.03538426384329796

 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                           | 45212/100000 [03:57<04:23, 207.58it/s]
epoch 44900  training loss: 0.03532220795750618
epoch 44900  clean testing loss: 0.07754399627447128
epoch 45000  training loss: 0.035300031304359436
epoch 45000  clean testing loss: 0.07703815400600433
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 45100  training loss: 0.035257622599601746
epoch 45100  clean testing loss: 0.07758502662181854
epoch 45200  training loss: 0.03524533286690712

 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                           | 45626/100000 [03:59<04:20, 208.53it/s]
epoch 45300  training loss: 0.035253845155239105
epoch 45300  clean testing loss: 0.07727836817502975
epoch 45400  training loss: 0.03525197133421898
epoch 45400  clean testing loss: 0.07735280692577362
epoch 45500  training loss: 0.03527417778968811
epoch 45500  clean testing loss: 0.07810366898775101
epoch 45600  training loss: 0.03519711643457413

 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 46039/100000 [04:01<04:20, 207.18it/s]
epoch 45700  training loss: 0.03519757091999054
epoch 45700  clean testing loss: 0.0775836706161499
epoch 45800  training loss: 0.035216279327869415
epoch 45800  clean testing loss: 0.07769320905208588
epoch 45900  training loss: 0.035219889134168625
epoch 45900  clean testing loss: 0.07744360715150833
epoch 46000  training loss: 0.03513355553150177
epoch 46000  clean testing loss: 0.07765402644872665

 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 46451/100000 [04:03<04:23, 203.32it/s]
epoch 46100  training loss: 0.03514949232339859
epoch 46100  clean testing loss: 0.07783066481351852
epoch 46200  training loss: 0.03515390679240227
epoch 46200  clean testing loss: 0.07760880142450333
epoch 46300  training loss: 0.03513091430068016
epoch 46300  clean testing loss: 0.07823675870895386
epoch 46400  training loss: 0.035158511251211166

 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                          | 46863/100000 [04:05<04:18, 205.57it/s]
epoch 46500  training loss: 0.03529583290219307
epoch 46500  clean testing loss: 0.07766000181436539
epoch 46600  training loss: 0.035060781985521317
epoch 46600  clean testing loss: 0.07843471318483353
epoch 46700  training loss: 0.0351080447435379
epoch 46700  clean testing loss: 0.07898857444524765
epoch 46800  training loss: 0.035104840993881226
epoch 46800  clean testing loss: 0.07831422239542007
epoch 46900  training loss: 0.03500048816204071

 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 47279/100000 [04:07<04:16, 205.84it/s]
epoch 47000  training loss: 0.034986864775419235
epoch 47000  clean testing loss: 0.07819058001041412
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 47100  training loss: 0.03501996770501137
epoch 47100  clean testing loss: 0.07788945734500885
epoch 47200  training loss: 0.03496529906988144
epoch 47200  clean testing loss: 0.07818567752838135
epoch 47300  training loss: 0.03494750335812569

 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 47692/100000 [04:09<04:10, 209.04it/s]
epoch 47400  training loss: 0.03495350107550621
epoch 47400  clean testing loss: 0.07855083048343658
epoch 47500  training loss: 0.03494291007518768
epoch 47500  clean testing loss: 0.07854170352220535
epoch 47600  training loss: 0.034981921315193176
epoch 47600  clean testing loss: 0.07945652306079865
epoch 47700  training loss: 0.03492957353591919

 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 48106/100000 [04:11<04:09, 208.32it/s]
epoch 47800  training loss: 0.034973498433828354
epoch 47800  clean testing loss: 0.07830771058797836
epoch 47900  training loss: 0.03486974537372589
epoch 47900  clean testing loss: 0.07878264039754868
epoch 48000  training loss: 0.03487745672464371
epoch 48000  clean testing loss: 0.07859805971384048
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 48100  training loss: 0.034880511462688446

 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 48497/100000 [04:13<04:09, 206.03it/s]
epoch 48200  training loss: 0.03483904153108597
epoch 48200  clean testing loss: 0.07848060876131058
epoch 48300  training loss: 0.03485376015305519
epoch 48300  clean testing loss: 0.07885396480560303
epoch 48400  training loss: 0.03480739891529083
epoch 48400  clean testing loss: 0.0786791443824768
epoch 48500  training loss: 0.03484732285141945

 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 48954/100000 [04:15<04:04, 209.15it/s]
epoch 48600  training loss: 0.03478017449378967
epoch 48600  clean testing loss: 0.07891330122947693
epoch 48700  training loss: 0.0347885824739933
epoch 48700  clean testing loss: 0.07928553223609924
epoch 48800  training loss: 0.034760668873786926
epoch 48800  clean testing loss: 0.07915569841861725
epoch 48900  training loss: 0.03473273664712906

 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                        | 49365/100000 [04:17<04:06, 205.47it/s]
epoch 49000  training loss: 0.03473827242851257
epoch 49000  clean testing loss: 0.07933119684457779
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 49100  training loss: 0.034803587943315506
epoch 49100  clean testing loss: 0.07921020686626434
epoch 49200  training loss: 0.03476545587182045
epoch 49200  clean testing loss: 0.0788714662194252
epoch 49300  training loss: 0.03471294790506363

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                        | 49778/100000 [04:19<04:05, 204.60it/s]
epoch 49400  training loss: 0.03472764045000076
epoch 49400  clean testing loss: 0.07975656539201736
epoch 49500  training loss: 0.03475603088736534
epoch 49500  clean testing loss: 0.0792052373290062
epoch 49600  training loss: 0.03469116985797882
epoch 49600  clean testing loss: 0.08016905933618546
epoch 49700  training loss: 0.034769341349601746
epoch 49700  clean testing loss: 0.08007628470659256
epoch 49800  training loss: 0.03470228239893913

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                       | 50191/100000 [04:21<04:02, 205.71it/s]
epoch 49900  training loss: 0.03461926430463791
epoch 49900  clean testing loss: 0.08013425022363663
epoch 50000  training loss: 0.03464030474424362
epoch 50000  clean testing loss: 0.07965853065252304
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 50100  training loss: 0.03464667499065399
epoch 50100  clean testing loss: 0.0796465128660202
epoch 50200  training loss: 0.034605447202920914

 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 50605/100000 [04:23<03:57, 208.02it/s]
epoch 50300  training loss: 0.03457292169332504
epoch 50300  clean testing loss: 0.08030768483877182
epoch 50400  training loss: 0.03454368934035301
epoch 50400  clean testing loss: 0.07961267232894897
epoch 50500  training loss: 0.03469882532954216
epoch 50500  clean testing loss: 0.07953289151191711
epoch 50600  training loss: 0.034565381705760956

 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 51020/100000 [04:25<03:57, 206.00it/s]
epoch 50700  training loss: 0.034531015902757645
epoch 50700  clean testing loss: 0.07988026738166809
epoch 50800  training loss: 0.03456263244152069
epoch 50800  clean testing loss: 0.07984404265880585
epoch 50900  training loss: 0.03449280187487602
epoch 50900  clean testing loss: 0.08008483052253723
epoch 51000  training loss: 0.03448941931128502
epoch 51000  clean testing loss: 0.08013789355754852

 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 51434/100000 [04:27<03:51, 210.01it/s]
epoch 51100  training loss: 0.03446774184703827
epoch 51100  clean testing loss: 0.08037928491830826
epoch 51200  training loss: 0.03446541726589203
epoch 51200  clean testing loss: 0.08023996651172638
epoch 51300  training loss: 0.034453704953193665
epoch 51300  clean testing loss: 0.08035635948181152
epoch 51400  training loss: 0.03445059433579445

 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 51848/100000 [04:29<03:57, 202.63it/s]
epoch 51500  training loss: 0.03445778787136078
epoch 51500  clean testing loss: 0.08045762777328491
epoch 51600  training loss: 0.034443750977516174
epoch 51600  clean testing loss: 0.08053172379732132
epoch 51700  training loss: 0.0344010591506958
epoch 51700  clean testing loss: 0.08045313507318497
epoch 51800  training loss: 0.03440595418214798

 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 52262/100000 [04:31<03:52, 204.94it/s]
epoch 51900  training loss: 0.03442106395959854
epoch 51900  clean testing loss: 0.08023270964622498
epoch 52000  training loss: 0.03441709280014038
epoch 52000  clean testing loss: 0.08086183667182922
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 52100  training loss: 0.03436737135052681
epoch 52100  clean testing loss: 0.08097195625305176
epoch 52200  training loss: 0.034345339983701706

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 52677/100000 [04:33<03:49, 206.32it/s]
epoch 52300  training loss: 0.03433331474661827
epoch 52300  clean testing loss: 0.08065637946128845
epoch 52400  training loss: 0.03436281904578209
epoch 52400  clean testing loss: 0.08108833432197571
epoch 52500  training loss: 0.03431693837046623
epoch 52500  clean testing loss: 0.08020200580358505
epoch 52600  training loss: 0.03429905325174332

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 53089/100000 [04:35<03:44, 208.56it/s]
epoch 52700  training loss: 0.0342850387096405
epoch 52700  clean testing loss: 0.08063529431819916
epoch 52800  training loss: 0.03430334851145744
epoch 52800  clean testing loss: 0.08079793304204941
epoch 52900  training loss: 0.03434449061751366
epoch 52900  clean testing loss: 0.08129847049713135
epoch 53000  training loss: 0.03438225015997887
epoch 53000  clean testing loss: 0.08062533289194107
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 53100  training loss: 0.034239280968904495

 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 53504/100000 [04:37<03:42, 209.00it/s]
epoch 53200  training loss: 0.03425867110490799
epoch 53200  clean testing loss: 0.08102129399776459
epoch 53300  training loss: 0.03424526005983353
epoch 53300  clean testing loss: 0.08092804998159409
epoch 53400  training loss: 0.03421393409371376
epoch 53400  clean testing loss: 0.08082164078950882
epoch 53500  training loss: 0.03422281891107559

 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 53924/100000 [04:39<03:39, 209.46it/s]
epoch 53600  training loss: 0.03418255224823952
epoch 53600  clean testing loss: 0.08118454366922379
epoch 53700  training loss: 0.034176889806985855
epoch 53700  clean testing loss: 0.08127875626087189
epoch 53800  training loss: 0.03416416049003601
epoch 53800  clean testing loss: 0.08119192719459534
epoch 53900  training loss: 0.03416662663221359

 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 54339/100000 [04:41<03:37, 209.68it/s]
epoch 54000  training loss: 0.034153200685977936
epoch 54000  clean testing loss: 0.08145175874233246
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 54100  training loss: 0.0341326929628849
epoch 54100  clean testing loss: 0.08152326941490173
epoch 54200  training loss: 0.034120019525289536
epoch 54200  clean testing loss: 0.08135327696800232
epoch 54300  training loss: 0.0341428741812706

 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 54752/100000 [04:44<03:42, 203.80it/s]
epoch 54400  training loss: 0.034119341522455215
epoch 54400  clean testing loss: 0.0814688578248024
epoch 54500  training loss: 0.03412843868136406
epoch 54500  clean testing loss: 0.08153241127729416
epoch 54600  training loss: 0.0340844988822937
epoch 54600  clean testing loss: 0.08168452978134155
epoch 54700  training loss: 0.03410561755299568

 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 55164/100000 [04:46<03:39, 204.02it/s]
epoch 54800  training loss: 0.03412122651934624
epoch 54800  clean testing loss: 0.08141880482435226
epoch 54900  training loss: 0.03406231850385666
epoch 54900  clean testing loss: 0.08187063038349152
epoch 55000  training loss: 0.034061938524246216
epoch 55000  clean testing loss: 0.08176451176404953
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 55100  training loss: 0.03409223631024361

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 55579/100000 [04:48<03:35, 206.14it/s]
epoch 55200  training loss: 0.0340702123939991
epoch 55200  clean testing loss: 0.08146544545888901
epoch 55300  training loss: 0.03403768688440323
epoch 55300  clean testing loss: 0.08192198723554611
epoch 55400  training loss: 0.03405272960662842
epoch 55400  clean testing loss: 0.08173670619726181
epoch 55500  training loss: 0.034011490643024445

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 55993/100000 [04:50<03:31, 208.23it/s]
epoch 55600  training loss: 0.03401130065321922
epoch 55600  clean testing loss: 0.08222867548465729
epoch 55700  training loss: 0.03403294086456299
epoch 55700  clean testing loss: 0.08230945467948914
epoch 55800  training loss: 0.034035585820674896
epoch 55800  clean testing loss: 0.08237016946077347
epoch 55900  training loss: 0.03401069715619087
epoch 55900  clean testing loss: 0.08197092264890671
epoch 56000  training loss: 0.03398025780916214
epoch 56000  clean testing loss: 0.08208934962749481

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 56407/100000 [04:52<03:28, 208.64it/s]
epoch 56100  training loss: 0.033985305577516556
epoch 56100  clean testing loss: 0.08205322176218033
epoch 56200  training loss: 0.03398076817393303
epoch 56200  clean testing loss: 0.08249889314174652
epoch 56300  training loss: 0.033955879509449005
epoch 56300  clean testing loss: 0.08228041231632233
epoch 56400  training loss: 0.03396124392747879

 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 56822/100000 [04:54<03:25, 210.26it/s]
epoch 56500  training loss: 0.03393065929412842
epoch 56500  clean testing loss: 0.08242711424827576
epoch 56600  training loss: 0.033948954194784164
epoch 56600  clean testing loss: 0.08246082812547684
epoch 56700  training loss: 0.03392006829380989
epoch 56700  clean testing loss: 0.08269508928060532
epoch 56800  training loss: 0.03391420096158981

 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 57235/100000 [04:56<03:31, 202.39it/s]
epoch 56900  training loss: 0.03391474857926369
epoch 56900  clean testing loss: 0.08252018690109253
epoch 57000  training loss: 0.0338994562625885
epoch 57000  clean testing loss: 0.08253921568393707
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 57100  training loss: 0.033860575407743454
epoch 57100  clean testing loss: 0.08255405724048615
epoch 57200  training loss: 0.03384941443800926

 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 57650/100000 [04:58<03:26, 205.17it/s]
epoch 57300  training loss: 0.033856041729450226
epoch 57300  clean testing loss: 0.08273061364889145
epoch 57400  training loss: 0.03387334197759628
epoch 57400  clean testing loss: 0.08233632147312164
epoch 57500  training loss: 0.03386408090591431
epoch 57500  clean testing loss: 0.0826270654797554
epoch 57600  training loss: 0.033832985907793045

 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 58064/100000 [05:00<03:24, 205.26it/s]
epoch 57700  training loss: 0.03381815552711487
epoch 57700  clean testing loss: 0.08270062506198883
epoch 57800  training loss: 0.033815719187259674
epoch 57800  clean testing loss: 0.08267667144536972
epoch 57900  training loss: 0.03383633494377136
epoch 57900  clean testing loss: 0.08299607783555984
epoch 58000  training loss: 0.03379834070801735
epoch 58000  clean testing loss: 0.0829114094376564

 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 58478/100000 [05:02<03:18, 209.02it/s]
epoch 58100  training loss: 0.03381813317537308
epoch 58100  clean testing loss: 0.08261049538850784
epoch 58200  training loss: 0.033785380423069
epoch 58200  clean testing loss: 0.08300919085741043
epoch 58300  training loss: 0.03379084914922714
epoch 58300  clean testing loss: 0.08277914673089981
epoch 58400  training loss: 0.0337873175740242

 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 58893/100000 [05:04<03:16, 209.51it/s]
epoch 58500  training loss: 0.03376356512308121
epoch 58500  clean testing loss: 0.08306851238012314
epoch 58600  training loss: 0.03375714272260666
epoch 58600  clean testing loss: 0.08277741074562073
epoch 58700  training loss: 0.03377519175410271
epoch 58700  clean testing loss: 0.08285671472549438
epoch 58800  training loss: 0.03374677896499634
epoch 58800  clean testing loss: 0.08294150233268738
epoch 58900  training loss: 0.03376658633351326

 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 59305/100000 [05:06<03:16, 206.77it/s]
epoch 59000  training loss: 0.03374503552913666
epoch 59000  clean testing loss: 0.08291400969028473
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 59100  training loss: 0.033722907304763794
epoch 59100  clean testing loss: 0.08317235857248306
epoch 59200  training loss: 0.03375513106584549
epoch 59200  clean testing loss: 0.08333760499954224
epoch 59300  training loss: 0.03373413905501366

 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 59719/100000 [05:08<03:17, 203.53it/s]
epoch 59400  training loss: 0.03371265530586243
epoch 59400  clean testing loss: 0.08329194784164429
epoch 59500  training loss: 0.03369253873825073
epoch 59500  clean testing loss: 0.08299215883016586
epoch 59600  training loss: 0.033697839826345444
epoch 59600  clean testing loss: 0.0832858756184578
epoch 59700  training loss: 0.03367675095796585

 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 60133/100000 [05:10<03:13, 205.52it/s]
epoch 59800  training loss: 0.033674005419015884
epoch 59800  clean testing loss: 0.08335402607917786
epoch 59900  training loss: 0.03364996984601021
epoch 59900  clean testing loss: 0.08343812823295593
epoch 60000  training loss: 0.03365961089730263
epoch 60000  clean testing loss: 0.08318264037370682
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 60100  training loss: 0.033635567873716354

 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 60549/100000 [05:12<03:10, 206.62it/s]
epoch 60200  training loss: 0.03363104909658432
epoch 60200  clean testing loss: 0.0834176167845726
epoch 60300  training loss: 0.03365543484687805
epoch 60300  clean testing loss: 0.08330643177032471
epoch 60400  training loss: 0.03361565247178078
epoch 60400  clean testing loss: 0.08359111100435257
epoch 60500  training loss: 0.03360752388834953

 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 60965/100000 [05:14<03:07, 208.47it/s]
epoch 60600  training loss: 0.03360316902399063
epoch 60600  clean testing loss: 0.08367729187011719
epoch 60700  training loss: 0.03359779343008995
epoch 60700  clean testing loss: 0.0837348997592926
epoch 60800  training loss: 0.03358379378914833
epoch 60800  clean testing loss: 0.08373464643955231
epoch 60900  training loss: 0.033586516976356506

 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 61377/100000 [05:16<03:04, 209.72it/s]
epoch 61000  training loss: 0.03357664868235588
epoch 61000  clean testing loss: 0.08388075977563858
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 61100  training loss: 0.03357526659965515
epoch 61100  clean testing loss: 0.08382288366556168
epoch 61200  training loss: 0.03356189653277397
epoch 61200  clean testing loss: 0.08402477204799652
epoch 61300  training loss: 0.03354332968592644

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 61791/100000 [05:18<03:06, 205.33it/s]
epoch 61400  training loss: 0.033534806221723557
epoch 61400  clean testing loss: 0.0839851126074791
epoch 61500  training loss: 0.03354872390627861
epoch 61500  clean testing loss: 0.08403703570365906
epoch 61600  training loss: 0.033546578139066696
epoch 61600  clean testing loss: 0.08412398397922516
epoch 61700  training loss: 0.033525627106428146
epoch 61700  clean testing loss: 0.084165059030056
epoch 61800  training loss: 0.03351972624659538

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 62203/100000 [05:20<03:04, 204.45it/s]
epoch 61900  training loss: 0.03350302204489708
epoch 61900  clean testing loss: 0.0841510146856308
epoch 62000  training loss: 0.03349413350224495
epoch 62000  clean testing loss: 0.08430778235197067
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 62100  training loss: 0.033491749316453934
epoch 62100  clean testing loss: 0.08440330624580383
epoch 62200  training loss: 0.033480241894721985

 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 62617/100000 [05:22<03:01, 206.44it/s]
epoch 62300  training loss: 0.033484525978565216
epoch 62300  clean testing loss: 0.08441449701786041
epoch 62400  training loss: 0.033480074256658554
epoch 62400  clean testing loss: 0.08410154283046722
epoch 62500  training loss: 0.03346535190939903
epoch 62500  clean testing loss: 0.08423810452222824
epoch 62600  training loss: 0.03346198424696922

 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 63032/100000 [05:24<02:59, 206.31it/s]
epoch 62700  training loss: 0.03346145153045654
epoch 62700  clean testing loss: 0.08441142737865448
epoch 62800  training loss: 0.033444758504629135
epoch 62800  clean testing loss: 0.08444839715957642
epoch 62900  training loss: 0.03344358131289482
epoch 62900  clean testing loss: 0.0845661386847496
epoch 63000  training loss: 0.03342873975634575
epoch 63000  clean testing loss: 0.08449899405241013

 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 63467/100000 [05:26<02:57, 206.00it/s]
epoch 63100  training loss: 0.033420007675886154
epoch 63100  clean testing loss: 0.08473661541938782
epoch 63200  training loss: 0.03341898322105408
epoch 63200  clean testing loss: 0.08450964838266373
epoch 63300  training loss: 0.033415306359529495
epoch 63300  clean testing loss: 0.08464588969945908
epoch 63400  training loss: 0.03342016041278839

 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 63882/100000 [05:28<02:45, 217.95it/s]
epoch 63500  training loss: 0.03339506685733795
epoch 63500  clean testing loss: 0.08456776291131973
epoch 63600  training loss: 0.03339695185422897
epoch 63600  clean testing loss: 0.08475357294082642
epoch 63700  training loss: 0.033392272889614105
epoch 63700  clean testing loss: 0.08464385569095612
epoch 63800  training loss: 0.03337947279214859

 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 64298/100000 [05:30<02:52, 206.63it/s]
epoch 63900  training loss: 0.03339793160557747
epoch 63900  clean testing loss: 0.08487987518310547
epoch 64000  training loss: 0.0333702452480793
epoch 64000  clean testing loss: 0.08466654270887375
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 64100  training loss: 0.03335767611861229
epoch 64100  clean testing loss: 0.08469928056001663
epoch 64200  training loss: 0.033360134810209274
epoch 64200  clean testing loss: 0.08475346863269806
epoch 64300  training loss: 0.03335985541343689

 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 64713/100000 [05:32<02:49, 208.35it/s]
epoch 64400  training loss: 0.03334381431341171
epoch 64400  clean testing loss: 0.08471623808145523
epoch 64500  training loss: 0.03333932161331177
epoch 64500  clean testing loss: 0.08477021008729935
epoch 64600  training loss: 0.033337950706481934
epoch 64600  clean testing loss: 0.08497221767902374
epoch 64700  training loss: 0.033326614648103714

 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 65126/100000 [05:34<02:46, 209.56it/s]
epoch 64800  training loss: 0.03332647308707237
epoch 64800  clean testing loss: 0.08467265963554382
epoch 64900  training loss: 0.033327873796224594
epoch 64900  clean testing loss: 0.08503779768943787
epoch 65000  training loss: 0.033306218683719635
epoch 65000  clean testing loss: 0.08497261255979538
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 65100  training loss: 0.03331636264920235

 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 65540/100000 [05:36<02:48, 204.66it/s]
epoch 65200  training loss: 0.033300790935754776
epoch 65200  clean testing loss: 0.08502798527479172
epoch 65300  training loss: 0.03329868242144585
epoch 65300  clean testing loss: 0.08524373173713684
epoch 65400  training loss: 0.03328743204474449
epoch 65400  clean testing loss: 0.08525548130273819
epoch 65500  training loss: 0.03330523520708084

 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 65955/100000 [05:38<02:46, 204.48it/s]
epoch 65600  training loss: 0.033288463950157166
epoch 65600  clean testing loss: 0.08514467626810074
epoch 65700  training loss: 0.03327029570937157
epoch 65700  clean testing loss: 0.08519890159368515
epoch 65800  training loss: 0.03327126055955887
epoch 65800  clean testing loss: 0.08514373004436493
epoch 65900  training loss: 0.03326516970992088

 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 66368/100000 [05:40<02:43, 206.30it/s]
epoch 66000  training loss: 0.03325590491294861
epoch 66000  clean testing loss: 0.0852573812007904
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 66100  training loss: 0.03325141593813896
epoch 66100  clean testing loss: 0.08536581695079803
epoch 66200  training loss: 0.03324120119214058
epoch 66200  clean testing loss: 0.08513372391462326
epoch 66300  training loss: 0.033248141407966614

 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 66782/100000 [05:42<02:39, 208.23it/s]
epoch 66400  training loss: 0.03323110193014145
epoch 66400  clean testing loss: 0.0853191614151001
epoch 66500  training loss: 0.033229485154151917
epoch 66500  clean testing loss: 0.08542861044406891
epoch 66600  training loss: 0.03322489932179451
epoch 66600  clean testing loss: 0.0853722095489502
epoch 66700  training loss: 0.03322010114789009

 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 67197/100000 [05:44<02:37, 208.26it/s]
epoch 66800  training loss: 0.03321899101138115
epoch 66800  clean testing loss: 0.08542975038290024
epoch 66900  training loss: 0.033226896077394485
epoch 66900  clean testing loss: 0.08555885404348373
epoch 67000  training loss: 0.03320479020476341
epoch 67000  clean testing loss: 0.08548182994127274
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 67100  training loss: 0.033201634883880615
epoch 67100  clean testing loss: 0.0853312537074089
epoch 67200  training loss: 0.0332021564245224

 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 67611/100000 [05:46<02:34, 210.12it/s]
epoch 67300  training loss: 0.03319205343723297
epoch 67300  clean testing loss: 0.08543306589126587
epoch 67400  training loss: 0.033195916563272476
epoch 67400  clean testing loss: 0.08546686172485352
epoch 67500  training loss: 0.03318021073937416
epoch 67500  clean testing loss: 0.08556389063596725
epoch 67600  training loss: 0.03317946940660477

 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 68027/100000 [05:48<02:38, 202.11it/s]
epoch 67700  training loss: 0.03316321596503258
epoch 67700  clean testing loss: 0.0854995995759964
epoch 67800  training loss: 0.03316415473818779
epoch 67800  clean testing loss: 0.08558709919452667
epoch 67900  training loss: 0.033165864646434784
epoch 67900  clean testing loss: 0.08558327704668045
epoch 68000  training loss: 0.03315261751413345
epoch 68000  clean testing loss: 0.08562561869621277

 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 68443/100000 [05:50<02:34, 204.27it/s]
epoch 68100  training loss: 0.033145930618047714
epoch 68100  clean testing loss: 0.08587133884429932
epoch 68200  training loss: 0.03314954414963722
epoch 68200  clean testing loss: 0.08566392958164215
epoch 68300  training loss: 0.03313857316970825
epoch 68300  clean testing loss: 0.08563663065433502
epoch 68400  training loss: 0.033133286982774734

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 68858/100000 [05:52<02:30, 206.28it/s]
epoch 68500  training loss: 0.033127233386039734
epoch 68500  clean testing loss: 0.0858059898018837
epoch 68600  training loss: 0.03312024101614952
epoch 68600  clean testing loss: 0.08560387045145035
epoch 68700  training loss: 0.03312424570322037
epoch 68700  clean testing loss: 0.08556868135929108
epoch 68800  training loss: 0.03311071917414665

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 69274/100000 [05:54<02:28, 206.69it/s]
epoch 68900  training loss: 0.03310207650065422
epoch 68900  clean testing loss: 0.08573783934116364
epoch 69000  training loss: 0.033103279769420624
epoch 69000  clean testing loss: 0.08585619181394577
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 69100  training loss: 0.033091481775045395
epoch 69100  clean testing loss: 0.08587120473384857
epoch 69200  training loss: 0.03308594599366188

 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 69689/100000 [05:56<02:25, 208.04it/s]
epoch 69300  training loss: 0.033083055168390274
epoch 69300  clean testing loss: 0.08585463464260101
epoch 69400  training loss: 0.03307943791151047
epoch 69400  clean testing loss: 0.08590003848075867
epoch 69500  training loss: 0.03308141604065895
epoch 69500  clean testing loss: 0.08586502820253372
epoch 69600  training loss: 0.033074576407670975

 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 70105/100000 [05:58<02:23, 208.78it/s]
epoch 69700  training loss: 0.03306557610630989
epoch 69700  clean testing loss: 0.08601834625005722
epoch 69800  training loss: 0.03307066112756729
epoch 69800  clean testing loss: 0.08595440536737442
epoch 69900  training loss: 0.033065710216760635
epoch 69900  clean testing loss: 0.08611451089382172
epoch 70000  training loss: 0.033055901527404785
epoch 70000  clean testing loss: 0.08619945496320724
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 70100  training loss: 0.03305652365088463

 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 70517/100000 [06:00<02:23, 204.76it/s]
epoch 70200  training loss: 0.03304566442966461
epoch 70200  clean testing loss: 0.08607520163059235
epoch 70300  training loss: 0.033039920032024384
epoch 70300  clean testing loss: 0.08616409450769424
epoch 70400  training loss: 0.03303457796573639
epoch 70400  clean testing loss: 0.08601581305265427
epoch 70500  training loss: 0.03303171694278717

 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 70932/100000 [06:02<02:22, 204.29it/s]
epoch 70600  training loss: 0.033024001866579056
epoch 70600  clean testing loss: 0.08614891022443771
epoch 70700  training loss: 0.03302174434065819
epoch 70700  clean testing loss: 0.08627243340015411
epoch 70800  training loss: 0.03301437944173813
epoch 70800  clean testing loss: 0.08627521991729736
epoch 70900  training loss: 0.033017247915267944

 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 71346/100000 [06:04<02:18, 206.35it/s]
epoch 71000  training loss: 0.0330066941678524
epoch 71000  clean testing loss: 0.08634811639785767
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 71100  training loss: 0.033011700958013535
epoch 71100  clean testing loss: 0.08627267926931381
epoch 71200  training loss: 0.03300962224602699
epoch 71200  clean testing loss: 0.08622308820486069
epoch 71300  training loss: 0.03299648314714432

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 71760/100000 [06:06<02:15, 207.96it/s]
epoch 71400  training loss: 0.03299112990498543
epoch 71400  clean testing loss: 0.0864238440990448
epoch 71500  training loss: 0.032988663762807846
epoch 71500  clean testing loss: 0.08653169870376587
epoch 71600  training loss: 0.03298299014568329
epoch 71600  clean testing loss: 0.08639521896839142
epoch 71700  training loss: 0.03297903761267662

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 72175/100000 [06:08<02:13, 207.75it/s]
epoch 71800  training loss: 0.03297670558094978
epoch 71800  clean testing loss: 0.08660435676574707
epoch 71900  training loss: 0.03297407552599907
epoch 71900  clean testing loss: 0.08641444891691208
epoch 72000  training loss: 0.03297107294201851
epoch 72000  clean testing loss: 0.08662158250808716
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 72100  training loss: 0.03296862170100212

 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 72591/100000 [06:10<02:10, 210.12it/s]
epoch 72200  training loss: 0.032955851405858994
epoch 72200  clean testing loss: 0.08656513690948486
epoch 72300  training loss: 0.03295157104730606
epoch 72300  clean testing loss: 0.08667319267988205
epoch 72400  training loss: 0.03294805809855461
epoch 72400  clean testing loss: 0.08660272508859634
epoch 72500  training loss: 0.0329485647380352

 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 73005/100000 [06:12<02:12, 203.51it/s]
epoch 72600  training loss: 0.03294196352362633
epoch 72600  clean testing loss: 0.086676225066185
epoch 72700  training loss: 0.03293678164482117
epoch 72700  clean testing loss: 0.08671848475933075
epoch 72800  training loss: 0.032933712005615234
epoch 72800  clean testing loss: 0.08658745139837265
epoch 72900  training loss: 0.03293051943182945
epoch 72900  clean testing loss: 0.08658137172460556
epoch 73000  training loss: 0.03293254226446152
epoch 73000  clean testing loss: 0.08659406751394272

 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 73419/100000 [06:14<02:10, 204.17it/s]
epoch 73100  training loss: 0.03292406350374222
epoch 73100  clean testing loss: 0.08674408495426178
epoch 73200  training loss: 0.0329260379076004
epoch 73200  clean testing loss: 0.08678336441516876
epoch 73300  training loss: 0.0329214371740818
epoch 73300  clean testing loss: 0.08677324652671814
epoch 73400  training loss: 0.032908305525779724

 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 73833/100000 [06:16<02:07, 205.29it/s]
epoch 73500  training loss: 0.03290655463933945
epoch 73500  clean testing loss: 0.0868414044380188
epoch 73600  training loss: 0.03290377929806709
epoch 73600  clean testing loss: 0.08688061684370041
epoch 73700  training loss: 0.03290463611483574
epoch 73700  clean testing loss: 0.08684031665325165
epoch 73800  training loss: 0.03289775922894478

 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 74252/100000 [06:18<02:05, 204.63it/s]
epoch 73900  training loss: 0.03289325535297394
epoch 73900  clean testing loss: 0.0868365541100502
epoch 74000  training loss: 0.032893747091293335
epoch 74000  clean testing loss: 0.08701460808515549
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 74100  training loss: 0.03288602456450462
epoch 74100  clean testing loss: 0.08705868571996689
epoch 74200  training loss: 0.0328805036842823

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 74667/100000 [06:20<02:02, 206.46it/s]
epoch 74300  training loss: 0.03287717327475548
epoch 74300  clean testing loss: 0.08700057864189148
epoch 74400  training loss: 0.03288025036454201
epoch 74400  clean testing loss: 0.08688921481370926
epoch 74500  training loss: 0.032869018614292145
epoch 74500  clean testing loss: 0.08705616742372513
epoch 74600  training loss: 0.032864972949028015

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 75081/100000 [06:22<02:00, 206.88it/s]
epoch 74700  training loss: 0.032862383872270584
epoch 74700  clean testing loss: 0.08711761981248856
epoch 74800  training loss: 0.03285962715744972
epoch 74800  clean testing loss: 0.08702407777309418
epoch 74900  training loss: 0.032853882759809494
epoch 74900  clean testing loss: 0.0871785581111908
epoch 75000  training loss: 0.0328514389693737
epoch 75000  clean testing loss: 0.08714266121387482

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 75496/100000 [06:24<01:57, 208.62it/s]
epoch 75100  training loss: 0.032845865935087204
epoch 75100  clean testing loss: 0.08711874485015869
epoch 75200  training loss: 0.032842185348272324
epoch 75200  clean testing loss: 0.08713005483150482
epoch 75300  training loss: 0.032839708030223846
epoch 75300  clean testing loss: 0.08722218871116638
epoch 75400  training loss: 0.0328381285071373

 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 75914/100000 [06:26<01:54, 210.23it/s]
epoch 75500  training loss: 0.03283318504691124
epoch 75500  clean testing loss: 0.08725441247224808
epoch 75600  training loss: 0.032832711935043335
epoch 75600  clean testing loss: 0.0872446820139885
epoch 75700  training loss: 0.03282560408115387
epoch 75700  clean testing loss: 0.08724810928106308
epoch 75800  training loss: 0.0328226201236248
epoch 75800  clean testing loss: 0.08723099529743195
epoch 75900  training loss: 0.03282397240400314

 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 76327/100000 [06:28<01:54, 206.01it/s]
epoch 76000  training loss: 0.0328211635351181
epoch 76000  clean testing loss: 0.08728525787591934
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 76100  training loss: 0.0328136570751667
epoch 76100  clean testing loss: 0.08734691143035889
epoch 76200  training loss: 0.03281102329492569
epoch 76200  clean testing loss: 0.08726582676172256
epoch 76300  training loss: 0.03280986472964287

 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 76741/100000 [06:30<01:53, 204.39it/s]
epoch 76400  training loss: 0.032810624688863754
epoch 76400  clean testing loss: 0.08726207166910172
epoch 76500  training loss: 0.03280201181769371
epoch 76500  clean testing loss: 0.08754318952560425
epoch 76600  training loss: 0.03279639407992363
epoch 76600  clean testing loss: 0.0874265804886818
epoch 76700  training loss: 0.032793063670396805

 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 77159/100000 [06:32<01:51, 205.16it/s]
epoch 76800  training loss: 0.03278954327106476
epoch 76800  clean testing loss: 0.08745643496513367
epoch 76900  training loss: 0.032789453864097595
epoch 76900  clean testing loss: 0.08750327676534653
epoch 77000  training loss: 0.03278419002890587
epoch 77000  clean testing loss: 0.08754109591245651
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 77100  training loss: 0.03278208523988724

 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 77576/100000 [06:34<01:48, 206.63it/s]
epoch 77200  training loss: 0.03277824446558952
epoch 77200  clean testing loss: 0.08745568990707397
epoch 77300  training loss: 0.032775770872831345
epoch 77300  clean testing loss: 0.08758241683244705
epoch 77400  training loss: 0.03277377411723137
epoch 77400  clean testing loss: 0.08753755688667297
epoch 77500  training loss: 0.03277146816253662

 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 77991/100000 [06:36<01:45, 208.93it/s]
epoch 77600  training loss: 0.032764554023742676
epoch 77600  clean testing loss: 0.08765052258968353
epoch 77700  training loss: 0.03276372700929642
epoch 77700  clean testing loss: 0.08768954873085022
epoch 77800  training loss: 0.032759279012680054
epoch 77800  clean testing loss: 0.08751603960990906
epoch 77900  training loss: 0.03275651857256889

 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 78405/100000 [06:38<01:43, 209.11it/s]
epoch 78000  training loss: 0.03275289759039879
epoch 78000  clean testing loss: 0.0876348614692688
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 78100  training loss: 0.03274861350655556
epoch 78100  clean testing loss: 0.08765434473752975
epoch 78200  training loss: 0.032745350152254105
epoch 78200  clean testing loss: 0.08771687746047974
epoch 78300  training loss: 0.032743752002716064

 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 78819/100000 [06:40<01:41, 209.60it/s]
epoch 78400  training loss: 0.03274158015847206
epoch 78400  clean testing loss: 0.08771202713251114
epoch 78500  training loss: 0.03274083882570267
epoch 78500  clean testing loss: 0.08767478913068771
epoch 78600  training loss: 0.032733429223299026
epoch 78600  clean testing loss: 0.08775313198566437
epoch 78700  training loss: 0.032734986394643784
epoch 78700  clean testing loss: 0.08778645098209381
epoch 78800  training loss: 0.03273014351725578

 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 79231/100000 [06:42<01:42, 203.43it/s]
epoch 78900  training loss: 0.03272605314850807
epoch 78900  clean testing loss: 0.08773360401391983
epoch 79000  training loss: 0.03272285684943199
epoch 79000  clean testing loss: 0.0878383219242096
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 79100  training loss: 0.032723162323236465
epoch 79100  clean testing loss: 0.0878320187330246
epoch 79200  training loss: 0.0327170267701149

 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 79645/100000 [06:44<01:38, 206.12it/s]
epoch 79300  training loss: 0.03271464630961418
epoch 79300  clean testing loss: 0.08795144408941269
epoch 79400  training loss: 0.032712671905756
epoch 79400  clean testing loss: 0.08780822902917862
epoch 79500  training loss: 0.032714229077100754
epoch 79500  clean testing loss: 0.08794602006673813
epoch 79600  training loss: 0.03271186724305153

 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 80061/100000 [06:46<01:36, 205.84it/s]
epoch 79700  training loss: 0.03270387277007103
epoch 79700  clean testing loss: 0.08804082125425339
epoch 79800  training loss: 0.03270159289240837
epoch 79800  clean testing loss: 0.08802013844251633
epoch 79900  training loss: 0.032700300216674805
epoch 79900  clean testing loss: 0.0880492627620697
epoch 80000  training loss: 0.03269534558057785
epoch 80000  clean testing loss: 0.08806277811527252

 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 80386/100000 [06:47<01:35, 205.94it/s]
epoch 80100  training loss: 0.032690953463315964
epoch 80100  clean testing loss: 0.08794236928224564
epoch 80200  training loss: 0.03268644958734512
epoch 80200  clean testing loss: 0.0880211815237999
epoch 80300  training loss: 0.03268801048398018
epoch 80300  clean testing loss: 0.08792972564697266
epoch 80400  training loss: 0.032682664692401886

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 80802/100000 [06:49<01:32, 206.97it/s]
epoch 80500  training loss: 0.03267942741513252
epoch 80500  clean testing loss: 0.08805657178163528
epoch 80600  training loss: 0.03268014267086983
epoch 80600  clean testing loss: 0.08807048201560974
epoch 80700  training loss: 0.03267733380198479
epoch 80700  clean testing loss: 0.0881183072924614
epoch 80800  training loss: 0.03267023712396622

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 81218/100000 [06:51<01:29, 209.71it/s]
epoch 80900  training loss: 0.03267093002796173
epoch 80900  clean testing loss: 0.0880974605679512
epoch 81000  training loss: 0.0326635017991066
epoch 81000  clean testing loss: 0.08815433084964752
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 81100  training loss: 0.03266393393278122
epoch 81100  clean testing loss: 0.08819963783025742
epoch 81200  training loss: 0.03265893831849098

 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 81634/100000 [06:53<01:27, 209.19it/s]
epoch 81300  training loss: 0.03266020491719246
epoch 81300  clean testing loss: 0.08821195363998413
epoch 81400  training loss: 0.03265592083334923
epoch 81400  clean testing loss: 0.08825358748435974
epoch 81500  training loss: 0.03265206888318062
epoch 81500  clean testing loss: 0.0882561057806015
epoch 81600  training loss: 0.03265035152435303
epoch 81600  clean testing loss: 0.08821706473827362
epoch 81700  training loss: 0.03264487534761429

 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 82048/100000 [06:55<01:26, 208.32it/s]
epoch 81800  training loss: 0.032643601298332214
epoch 81800  clean testing loss: 0.08825042843818665
epoch 81900  training loss: 0.03264189884066582
epoch 81900  clean testing loss: 0.0883159190416336
epoch 82000  training loss: 0.03263860568404198
epoch 82000  clean testing loss: 0.08843238651752472
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 82100  training loss: 0.03263421356678009

 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 82460/100000 [06:57<01:26, 203.73it/s]
epoch 82200  training loss: 0.0326324924826622
epoch 82200  clean testing loss: 0.08832914382219315
epoch 82300  training loss: 0.03263038024306297
epoch 82300  clean testing loss: 0.0883721187710762
epoch 82400  training loss: 0.03262712433934212
epoch 82400  clean testing loss: 0.08829360455274582
epoch 82500  training loss: 0.032625604420900345

 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 82875/100000 [06:59<01:22, 206.52it/s]
epoch 82600  training loss: 0.032620567828416824
epoch 82600  clean testing loss: 0.0883682370185852
epoch 82700  training loss: 0.03261604532599449
epoch 82700  clean testing loss: 0.088449627161026
epoch 82800  training loss: 0.0326145701110363
epoch 82800  clean testing loss: 0.08846141397953033
epoch 82900  training loss: 0.03261604532599449

 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 83289/100000 [07:01<01:20, 206.63it/s]
epoch 83000  training loss: 0.03261200711131096
epoch 83000  clean testing loss: 0.08848367631435394
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 83100  training loss: 0.03260739892721176
epoch 83100  clean testing loss: 0.08852548897266388
epoch 83200  training loss: 0.03260501101613045
epoch 83200  clean testing loss: 0.08846444636583328
epoch 83300  training loss: 0.032601989805698395

 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 83705/100000 [07:04<01:18, 208.30it/s]
epoch 83400  training loss: 0.03259890899062157
epoch 83400  clean testing loss: 0.08853811770677567
epoch 83500  training loss: 0.03259677067399025
epoch 83500  clean testing loss: 0.0886048898100853
epoch 83600  training loss: 0.03260071948170662
epoch 83600  clean testing loss: 0.0885569229722023
epoch 83700  training loss: 0.032590609043836594

 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 84120/100000 [07:05<01:13, 215.91it/s]
epoch 83800  training loss: 0.03259023278951645
epoch 83800  clean testing loss: 0.0885699987411499
epoch 83900  training loss: 0.03258730098605156
epoch 83900  clean testing loss: 0.088663749396801
epoch 84000  training loss: 0.03258482366800308
epoch 84000  clean testing loss: 0.08872230350971222
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 84100  training loss: 0.03258311748504639

 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 84537/100000 [07:08<01:14, 208.90it/s]
epoch 84200  training loss: 0.032578516751527786
epoch 84200  clean testing loss: 0.08866565674543381
epoch 84300  training loss: 0.03257942199707031
epoch 84300  clean testing loss: 0.0887744203209877
epoch 84400  training loss: 0.032573502510786057
epoch 84400  clean testing loss: 0.08871655911207199
epoch 84500  training loss: 0.032572053372859955
epoch 84500  clean testing loss: 0.08874911069869995
epoch 84600  training loss: 0.032568298280239105

 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 84953/100000 [07:10<01:11, 210.36it/s]
epoch 84700  training loss: 0.03256630897521973
epoch 84700  clean testing loss: 0.08880976587533951
epoch 84800  training loss: 0.032566070556640625
epoch 84800  clean testing loss: 0.08882424980401993
epoch 84900  training loss: 0.032562967389822006
epoch 84900  clean testing loss: 0.0887933149933815
epoch 85000  training loss: 0.03256194293498993
epoch 85000  clean testing loss: 0.08882245421409607

 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 85365/100000 [07:12<01:12, 202.81it/s]
epoch 85100  training loss: 0.03255851939320564
epoch 85100  clean testing loss: 0.08886029571294785
epoch 85200  training loss: 0.03255516290664673
epoch 85200  clean testing loss: 0.0888013020157814
epoch 85300  training loss: 0.032555460929870605
epoch 85300  clean testing loss: 0.08883658796548843
epoch 85400  training loss: 0.032549675554037094

 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 85780/100000 [07:14<01:09, 205.48it/s]
epoch 85500  training loss: 0.03255024924874306
epoch 85500  clean testing loss: 0.08889948576688766
epoch 85600  training loss: 0.03254644572734833
epoch 85600  clean testing loss: 0.08896645903587341
epoch 85700  training loss: 0.03254258260130882
epoch 85700  clean testing loss: 0.08893809467554092
epoch 85800  training loss: 0.032540686428546906

 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 86193/100000 [07:16<01:06, 206.58it/s]
epoch 85900  training loss: 0.03253752365708351
epoch 85900  clean testing loss: 0.08897612988948822
epoch 86000  training loss: 0.03253530338406563
epoch 86000  clean testing loss: 0.08904104679822922
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 86100  training loss: 0.03253132104873657
epoch 86100  clean testing loss: 0.08901102095842361
epoch 86200  training loss: 0.03252943605184555

 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 86609/100000 [07:18<01:04, 208.94it/s]
epoch 86300  training loss: 0.032527703791856766
epoch 86300  clean testing loss: 0.0890708863735199
epoch 86400  training loss: 0.03252523019909859
epoch 86400  clean testing loss: 0.08902935683727264
epoch 86500  training loss: 0.03252287581562996
epoch 86500  clean testing loss: 0.08906294405460358
epoch 86600  training loss: 0.0325201116502285

 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 87026/100000 [07:20<01:02, 206.81it/s]
epoch 86700  training loss: 0.032518621534109116
epoch 86700  clean testing loss: 0.0890631303191185
epoch 86800  training loss: 0.032514698803424835
epoch 86800  clean testing loss: 0.0890527218580246
epoch 86900  training loss: 0.03251497074961662
epoch 86900  clean testing loss: 0.08907144516706467
epoch 87000  training loss: 0.032508645206689835
epoch 87000  clean testing loss: 0.08913075178861618

 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 87440/100000 [07:22<00:59, 210.16it/s]
epoch 87100  training loss: 0.03250674530863762
epoch 87100  clean testing loss: 0.08919603377580643
epoch 87200  training loss: 0.03250477835536003
epoch 87200  clean testing loss: 0.08912982791662216
epoch 87300  training loss: 0.032502107322216034
epoch 87300  clean testing loss: 0.08918057382106781
epoch 87400  training loss: 0.03250155970454216
epoch 87400  clean testing loss: 0.08916783332824707
epoch 87500  training loss: 0.03249703347682953

 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 87854/100000 [07:24<00:59, 203.08it/s]
epoch 87600  training loss: 0.03249822556972504
epoch 87600  clean testing loss: 0.08924823254346848
epoch 87700  training loss: 0.03249368816614151
epoch 87700  clean testing loss: 0.08920872956514359
epoch 87800  training loss: 0.03249137103557587
epoch 87800  clean testing loss: 0.0892634466290474
epoch 87900  training loss: 0.032489240169525146

 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 88270/100000 [07:26<00:57, 204.72it/s]
epoch 88000  training loss: 0.03248891234397888
epoch 88000  clean testing loss: 0.08925972133874893
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 88100  training loss: 0.032484885305166245
epoch 88100  clean testing loss: 0.08931148052215576
epoch 88200  training loss: 0.0324833020567894
epoch 88200  clean testing loss: 0.08927813172340393
epoch 88300  training loss: 0.032481107860803604

 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 88686/100000 [07:28<00:54, 206.19it/s]
epoch 88400  training loss: 0.03247779235243797
epoch 88400  clean testing loss: 0.08932739496231079
epoch 88500  training loss: 0.03247739002108574
epoch 88500  clean testing loss: 0.08930229395627975
epoch 88600  training loss: 0.03247348591685295
epoch 88600  clean testing loss: 0.08940999209880829
epoch 88700  training loss: 0.032473161816596985

 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 89103/100000 [07:30<00:52, 206.34it/s]
epoch 88800  training loss: 0.032468538731336594
epoch 88800  clean testing loss: 0.0893612653017044
epoch 88900  training loss: 0.032469797879457474
epoch 88900  clean testing loss: 0.08940112590789795
epoch 89000  training loss: 0.03246496617794037
epoch 89000  clean testing loss: 0.08939730376005173
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 89100  training loss: 0.03246317058801651

 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 89518/100000 [07:32<00:50, 208.74it/s]
epoch 89200  training loss: 0.032461978495121
epoch 89200  clean testing loss: 0.08940939605236053
epoch 89300  training loss: 0.032458651810884476
epoch 89300  clean testing loss: 0.08945027738809586
epoch 89400  training loss: 0.03246094286441803
epoch 89400  clean testing loss: 0.0894467905163765
epoch 89500  training loss: 0.03245522454380989

 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 89933/100000 [07:34<00:47, 210.20it/s]
epoch 89600  training loss: 0.032454486936330795
epoch 89600  clean testing loss: 0.08947622776031494
epoch 89700  training loss: 0.032449692487716675
epoch 89700  clean testing loss: 0.08948537707328796
epoch 89800  training loss: 0.032448869198560715
epoch 89800  clean testing loss: 0.08950232714414597
epoch 89900  training loss: 0.032446958124637604
epoch 89900  clean testing loss: 0.08949536085128784
epoch 90000  training loss: 0.032444439828395844

 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 90349/100000 [07:36<00:46, 209.77it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 90100  training loss: 0.032441459596157074
epoch 90100  clean testing loss: 0.08950653672218323
epoch 90200  training loss: 0.032441653311252594
epoch 90200  clean testing loss: 0.08950264751911163
epoch 90300  training loss: 0.03243990242481232
epoch 90300  clean testing loss: 0.08955828845500946
epoch 90400  training loss: 0.0324384905397892

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 90762/100000 [07:38<00:45, 204.12it/s]
epoch 90500  training loss: 0.03243444114923477
epoch 90500  clean testing loss: 0.08955130726099014
epoch 90600  training loss: 0.03243337571620941
epoch 90600  clean testing loss: 0.0895729809999466
epoch 90700  training loss: 0.03243302181363106
epoch 90700  clean testing loss: 0.08961716294288635
epoch 90800  training loss: 0.03242882713675499

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 91176/100000 [07:40<00:42, 205.89it/s]
epoch 90900  training loss: 0.03242727741599083
epoch 90900  clean testing loss: 0.08963003754615784
epoch 91000  training loss: 0.0324268639087677
epoch 91000  clean testing loss: 0.08965606987476349
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 91100  training loss: 0.032424286007881165
epoch 91100  clean testing loss: 0.08959393203258514
epoch 91200  training loss: 0.032422907650470734

 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 91592/100000 [07:42<00:40, 207.01it/s]
epoch 91300  training loss: 0.03242067992687225
epoch 91300  clean testing loss: 0.08965214341878891
epoch 91400  training loss: 0.032418299466371536
epoch 91400  clean testing loss: 0.08963929861783981
epoch 91500  training loss: 0.032416727393865585
epoch 91500  clean testing loss: 0.0897073745727539
epoch 91600  training loss: 0.032414671033620834

 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 92009/100000 [07:44<00:38, 207.02it/s]
epoch 91700  training loss: 0.03241177648305893
epoch 91700  clean testing loss: 0.0896938219666481
epoch 91800  training loss: 0.03241073712706566
epoch 91800  clean testing loss: 0.0897131934762001
epoch 91900  training loss: 0.0324086993932724
epoch 91900  clean testing loss: 0.08971240371465683
epoch 92000  training loss: 0.032406654208898544
epoch 92000  clean testing loss: 0.08973540365695953

 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 92424/100000 [07:46<00:36, 209.45it/s]
epoch 92100  training loss: 0.03240529075264931
epoch 92100  clean testing loss: 0.0897478386759758
epoch 92200  training loss: 0.03240307793021202
epoch 92200  clean testing loss: 0.08978907763957977
epoch 92300  training loss: 0.03240116685628891
epoch 92300  clean testing loss: 0.0897873118519783
epoch 92400  training loss: 0.03239937871694565

 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 92838/100000 [07:48<00:34, 209.79it/s]
epoch 92500  training loss: 0.0323982797563076
epoch 92500  clean testing loss: 0.08984215557575226
epoch 92600  training loss: 0.03239525854587555
epoch 92600  clean testing loss: 0.0898071900010109
epoch 92700  training loss: 0.03239288553595543
epoch 92700  clean testing loss: 0.08982229977846146
epoch 92800  training loss: 0.03239179402589798
epoch 92800  clean testing loss: 0.08980239927768707
epoch 92900  training loss: 0.03239056468009949

 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 93249/100000 [07:50<00:33, 203.96it/s]
epoch 93000  training loss: 0.032388169318437576
epoch 93000  clean testing loss: 0.08984753489494324
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 93100  training loss: 0.03238563612103462
epoch 93100  clean testing loss: 0.08983633667230606
epoch 93200  training loss: 0.03238629922270775
epoch 93200  clean testing loss: 0.08986576646566391
epoch 93300  training loss: 0.03238415718078613

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 93665/100000 [07:52<00:30, 205.83it/s]
epoch 93400  training loss: 0.03238191455602646
epoch 93400  clean testing loss: 0.08990375697612762
epoch 93500  training loss: 0.03238087147474289
epoch 93500  clean testing loss: 0.08991103619337082
epoch 93600  training loss: 0.03237856552004814
epoch 93600  clean testing loss: 0.08988025039434433
epoch 93700  training loss: 0.03237638995051384

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 94099/100000 [07:54<00:29, 202.06it/s]
epoch 93800  training loss: 0.03237437084317207
epoch 93800  clean testing loss: 0.0899071991443634
epoch 93900  training loss: 0.032373711466789246
epoch 93900  clean testing loss: 0.08991280198097229
epoch 94000  training loss: 0.03237234055995941
epoch 94000  clean testing loss: 0.08994569629430771
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 94100  training loss: 0.03237052261829376

 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 94521/100000 [07:56<00:26, 209.74it/s]
epoch 94200  training loss: 0.03236841410398483
epoch 94200  clean testing loss: 0.08997251838445663
epoch 94300  training loss: 0.032367538660764694
epoch 94300  clean testing loss: 0.08996733278036118
epoch 94400  training loss: 0.03236478939652443
epoch 94400  clean testing loss: 0.09000065922737122
epoch 94500  training loss: 0.032363422214984894

 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 94918/100000 [07:58<00:24, 207.09it/s]
epoch 94600  training loss: 0.032363180071115494
epoch 94600  clean testing loss: 0.08999232947826385
epoch 94700  training loss: 0.03236033022403717
epoch 94700  clean testing loss: 0.08998674154281616
epoch 94800  training loss: 0.03235943242907524
epoch 94800  clean testing loss: 0.09002751857042313
epoch 94900  training loss: 0.03235657513141632

 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 95334/100000 [08:00<00:22, 209.21it/s]
epoch 95000  training loss: 0.03235563635826111
epoch 95000  clean testing loss: 0.09003286808729172
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 95100  training loss: 0.032354068011045456
epoch 95100  clean testing loss: 0.09002939611673355
epoch 95200  training loss: 0.0323520191013813
epoch 95200  clean testing loss: 0.09006432443857193
epoch 95300  training loss: 0.03234987333416939

 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 95749/100000 [08:02<00:20, 209.24it/s]
epoch 95400  training loss: 0.03234851732850075
epoch 95400  clean testing loss: 0.09008804708719254
epoch 95500  training loss: 0.03234769031405449
epoch 95500  clean testing loss: 0.09007559716701508
epoch 95600  training loss: 0.03234585374593735
epoch 95600  clean testing loss: 0.09010371565818787
epoch 95700  training loss: 0.03234393894672394
epoch 95700  clean testing loss: 0.0901154950261116
epoch 95800  training loss: 0.03234235569834709

 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 96163/100000 [08:04<00:18, 210.44it/s]
epoch 95900  training loss: 0.03234049677848816
epoch 95900  clean testing loss: 0.09011642634868622
epoch 96000  training loss: 0.03233909234404564
epoch 96000  clean testing loss: 0.09012807160615921
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 96100  training loss: 0.032337985932826996
epoch 96100  clean testing loss: 0.09014351665973663
epoch 96200  training loss: 0.03233582526445389

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 96578/100000 [08:06<00:16, 203.19it/s]
epoch 96300  training loss: 0.032334666699171066
epoch 96300  clean testing loss: 0.09013699740171432
epoch 96400  training loss: 0.03233354166150093
epoch 96400  clean testing loss: 0.09016072005033493
epoch 96500  training loss: 0.03233209252357483
epoch 96500  clean testing loss: 0.09016557037830353
epoch 96600  training loss: 0.032332129776477814

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 96996/100000 [08:08<00:14, 204.64it/s]
epoch 96700  training loss: 0.032329630106687546
epoch 96700  clean testing loss: 0.09018600732088089
epoch 96800  training loss: 0.032328199595212936
epoch 96800  clean testing loss: 0.09022458642721176
epoch 96900  training loss: 0.03232642635703087
epoch 96900  clean testing loss: 0.09019064903259277
epoch 97000  training loss: 0.0323244109749794
epoch 97000  clean testing loss: 0.09022717922925949

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 97406/100000 [08:10<00:12, 206.07it/s]
epoch 97100  training loss: 0.03232315182685852
epoch 97100  clean testing loss: 0.09024075418710709
epoch 97200  training loss: 0.03232182562351227
epoch 97200  clean testing loss: 0.09020887315273285
epoch 97300  training loss: 0.03232136741280556
epoch 97300  clean testing loss: 0.09026007354259491
epoch 97400  training loss: 0.03232015669345856

 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 97865/100000 [08:12<00:08, 251.61it/s]
epoch 97500  training loss: 0.032318077981472015
epoch 97500  clean testing loss: 0.09025599807500839
epoch 97600  training loss: 0.03231668099761009
epoch 97600  clean testing loss: 0.09024826437234879
epoch 97700  training loss: 0.03231518343091011
epoch 97700  clean testing loss: 0.0902630165219307
epoch 97800  training loss: 0.03231429308652878
epoch 97800  clean testing loss: 0.09027524292469025
epoch 97900  training loss: 0.03231190890073776

 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 98369/100000 [08:14<00:06, 254.67it/s]
epoch 98000  training loss: 0.03231019154191017
epoch 98000  clean testing loss: 0.09027991443872452
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 98100  training loss: 0.032309141010046005
epoch 98100  clean testing loss: 0.09029968827962875
epoch 98200  training loss: 0.032307837158441544
epoch 98200  clean testing loss: 0.09031049907207489
epoch 98300  training loss: 0.03230644389986992
epoch 98300  clean testing loss: 0.09032411873340607
epoch 98400  training loss: 0.03230558708310127

 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 98884/100000 [08:16<00:04, 261.56it/s]
epoch 98500  training loss: 0.03230386599898338
epoch 98500  clean testing loss: 0.09033055603504181
epoch 98600  training loss: 0.03230229392647743
epoch 98600  clean testing loss: 0.0903375968337059
epoch 98700  training loss: 0.03230077400803566
epoch 98700  clean testing loss: 0.09035656601190567
epoch 98800  training loss: 0.03229983523488045
epoch 98800  clean testing loss: 0.09036053717136383
epoch 98900  training loss: 0.03229840472340584

 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 99398/100000 [08:18<00:02, 258.31it/s]
epoch 99000  training loss: 0.03229673579335213
epoch 99000  clean testing loss: 0.09038807451725006
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 99100  training loss: 0.032295335084199905
epoch 99100  clean testing loss: 0.09039609134197235
epoch 99200  training loss: 0.032294075936079025
epoch 99200  clean testing loss: 0.09038586914539337
epoch 99300  training loss: 0.03229288384318352
epoch 99300  clean testing loss: 0.09041421860456467
epoch 99400  training loss: 0.03229156881570816

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99909/100000 [08:20<00:00, 251.13it/s]
epoch 99500  training loss: 0.03229036182165146
epoch 99500  clean testing loss: 0.09042709320783615
epoch 99600  training loss: 0.03228907287120819
epoch 99600  clean testing loss: 0.09043574333190918
epoch 99700  training loss: 0.03228757157921791
epoch 99700  clean testing loss: 0.09044588357210159
epoch 99800  training loss: 0.032286420464515686
epoch 99800  clean testing loss: 0.09044191986322403
epoch 99900  training loss: 0.03228484466671944

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [08:20<00:00, 199.75it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...