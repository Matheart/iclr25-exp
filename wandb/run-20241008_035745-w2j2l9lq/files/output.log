
  0%|▏                                                                                 | 198/100000 [00:00<05:35, 297.67it/s]
epoch 0  training loss: 111.33840942382812
epoch 0  clean testing loss: 92.0411605834961
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 100  training loss: 0.4461634159088135
epoch 100  clean testing loss: 0.31624481081962585
epoch 200  training loss: 0.4380854070186615

  0%|▏                                                                                 | 296/100000 [00:01<05:17, 314.24it/s]
epoch 300  training loss: 0.43426886200904846

  0%|▍                                                                                 | 494/100000 [00:01<05:09, 321.24it/s]
epoch 400  training loss: 0.43037617206573486
epoch 400  clean testing loss: 0.3065597116947174
epoch 500  training loss: 0.42576608061790466
epoch 500  clean testing loss: 0.30291643738746643
epoch 600  training loss: 0.42090409994125366

  1%|▋                                                                                 | 891/100000 [00:02<05:05, 324.36it/s]
epoch 700  training loss: 0.4162793755531311
epoch 700  clean testing loss: 0.29468175768852234
epoch 800  training loss: 0.4105716943740845
epoch 800  clean testing loss: 0.2892763912677765
epoch 900  training loss: 0.40417787432670593

  1%|▉                                                                                | 1188/100000 [00:03<05:08, 320.52it/s]
epoch 1000  training loss: 0.4005764424800873
epoch 1000  clean testing loss: 0.28342777490615845
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 1100  training loss: 0.39626258611679077
epoch 1100  clean testing loss: 0.27907323837280273
epoch 1200  training loss: 0.39389535784721375

  2%|█▎                                                                               | 1586/100000 [00:05<05:02, 324.83it/s]
epoch 1300  training loss: 0.3932076096534729
epoch 1300  clean testing loss: 0.2765136957168579
epoch 1400  training loss: 0.3910399377346039
epoch 1400  clean testing loss: 0.27555519342422485
epoch 1500  training loss: 0.38995879888534546
epoch 1500  clean testing loss: 0.27348387241363525
epoch 1600  training loss: 0.39153411984443665
epoch 1600  clean testing loss: 0.27321022748947144
epoch 1700  training loss: 0.3884865343570709

  2%|█▌                                                                               | 1980/100000 [00:06<05:05, 320.46it/s]
epoch 1800  training loss: 0.5753922462463379
epoch 1800  clean testing loss: 0.6559445858001709
epoch 1900  training loss: 0.38714075088500977
epoch 1900  clean testing loss: 0.2708210349082947
epoch 2000  training loss: 0.38866183161735535
epoch 2000  clean testing loss: 0.27404022216796875
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 2100  training loss: 0.38584432005882263

  2%|█▉                                                                               | 2376/100000 [00:07<05:02, 322.67it/s]
epoch 2200  training loss: 0.38489067554473877
epoch 2200  clean testing loss: 0.26869887113571167
epoch 2300  training loss: 0.43523499369621277
epoch 2300  clean testing loss: 0.3627295196056366
epoch 2400  training loss: 0.3842480182647705

  3%|██                                                                               | 2574/100000 [00:08<05:03, 321.49it/s]
epoch 2500  training loss: 0.38309088349342346
epoch 2500  clean testing loss: 0.266481876373291
epoch 2600  training loss: 0.3827100396156311

  3%|██▍                                                                              | 2970/100000 [00:09<05:00, 323.12it/s]
epoch 2700  training loss: 0.38060981035232544
epoch 2700  clean testing loss: 0.26430293917655945
epoch 2800  training loss: 0.3884614408016205
epoch 2800  clean testing loss: 0.27083051204681396
epoch 2900  training loss: 0.42870989441871643
epoch 2900  clean testing loss: 0.310294508934021
epoch 3000  training loss: 0.7377608418464661

  4%|██▉                                                                              | 3595/100000 [00:11<04:58, 322.90it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 3100  training loss: 0.3753470778465271
epoch 3100  clean testing loss: 0.2595185339450836
epoch 3200  training loss: 0.3739153742790222
epoch 3200  clean testing loss: 0.2584346830844879
epoch 3300  training loss: 0.3722839653491974
epoch 3300  clean testing loss: 0.25717177987098694
epoch 3400  training loss: 0.3707719147205353
epoch 3400  clean testing loss: 0.2564360499382019
epoch 3500  training loss: 0.37471798062324524
epoch 3500  clean testing loss: 0.2596066892147064
epoch 3600  training loss: 0.36828383803367615

  5%|████▎                                                                            | 5378/100000 [00:16<04:54, 321.12it/s]
epoch 3700  training loss: 0.3687775433063507
epoch 3700  clean testing loss: 0.25233882665634155
epoch 3800  training loss: 0.3616749942302704
epoch 3800  clean testing loss: 0.2483322024345398
epoch 3900  training loss: 0.36319899559020996
epoch 3900  clean testing loss: 0.25044649839401245
epoch 4000  training loss: 0.353895902633667
epoch 4000  clean testing loss: 0.2417866438627243
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 4100  training loss: 0.3553343117237091
epoch 4100  clean testing loss: 0.24636253714561462
epoch 4200  training loss: 0.3452543616294861
epoch 4200  clean testing loss: 0.23578453063964844
epoch 4300  training loss: 0.3392709493637085
epoch 4300  clean testing loss: 0.230298712849617
epoch 4400  training loss: 0.3435863256454468
epoch 4400  clean testing loss: 0.23640018701553345
epoch 4500  training loss: 0.33969855308532715
epoch 4500  clean testing loss: 0.23530466854572296
epoch 4600  training loss: 0.3226141631603241
epoch 4600  clean testing loss: 0.2205975502729416
epoch 4700  training loss: 0.31022584438323975
epoch 4700  clean testing loss: 0.20917679369449615
epoch 4800  training loss: 0.2923257648944855
epoch 4800  clean testing loss: 0.19099274277687073
epoch 4900  training loss: 0.27888455986976624
epoch 4900  clean testing loss: 0.1870640516281128
epoch 5000  training loss: 0.24149124324321747
epoch 5000  clean testing loss: 0.14618420600891113
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 5100  training loss: 0.21444377303123474
epoch 5100  clean testing loss: 0.12900610268115997
epoch 5200  training loss: 0.18839775025844574
epoch 5200  clean testing loss: 0.11114761233329773
epoch 5300  training loss: 0.17502373456954956
epoch 5300  clean testing loss: 0.100941501557827
epoch 5400  training loss: 0.16167432069778442

  9%|███████▏                                                                         | 8805/100000 [00:27<04:43, 321.86it/s]
epoch 5500  training loss: 0.15682107210159302
epoch 5500  clean testing loss: 0.09820409119129181
epoch 5600  training loss: 0.1455860733985901
epoch 5600  clean testing loss: 0.0768163725733757
epoch 5700  training loss: 0.14794358611106873
epoch 5700  clean testing loss: 0.07614617794752121
epoch 5800  training loss: 0.1363290250301361
epoch 5800  clean testing loss: 0.06995668262243271
epoch 5900  training loss: 0.19114163517951965
epoch 5900  clean testing loss: 0.13822756707668304
epoch 6000  training loss: 0.37385091185569763
epoch 6000  clean testing loss: 0.09209053218364716
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 6100  training loss: 0.1285625398159027
epoch 6100  clean testing loss: 0.06378481537103653
epoch 6200  training loss: 0.1265210509300232
epoch 6200  clean testing loss: 0.06247013062238693
epoch 6300  training loss: 0.12472660094499588
epoch 6300  clean testing loss: 0.061344027519226074
epoch 6400  training loss: 0.12308890372514725
epoch 6400  clean testing loss: 0.06036399304866791
epoch 6500  training loss: 0.13003332912921906
epoch 6500  clean testing loss: 0.07093086838722229
epoch 6600  training loss: 0.1250627338886261
epoch 6600  clean testing loss: 0.061040811240673065
epoch 6700  training loss: 0.11887690424919128
epoch 6700  clean testing loss: 0.05769404023885727
epoch 6800  training loss: 0.1184082105755806
epoch 6800  clean testing loss: 0.056705575436353683
epoch 6900  training loss: 0.11714398860931396
epoch 6900  clean testing loss: 0.056067414581775665
epoch 7000  training loss: 0.11606311798095703
epoch 7000  clean testing loss: 0.055672165006399155
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 7100  training loss: 0.1153939887881279
epoch 7100  clean testing loss: 0.054749660193920135
epoch 7200  training loss: 0.12353718280792236
epoch 7200  clean testing loss: 0.05750089883804321
epoch 7300  training loss: 0.11383379250764847
epoch 7300  clean testing loss: 0.0533904992043972
epoch 7400  training loss: 0.11316269636154175
epoch 7400  clean testing loss: 0.05331723764538765
epoch 7500  training loss: 0.11245881021022797
epoch 7500  clean testing loss: 0.05218712240457535
epoch 7600  training loss: 0.17157986760139465
epoch 7600  clean testing loss: 0.15346936881542206
epoch 7700  training loss: 0.1114468052983284
epoch 7700  clean testing loss: 0.0509161502122879
epoch 7800  training loss: 0.11056973785161972
epoch 7800  clean testing loss: 0.05058851093053818
epoch 7900  training loss: 0.11226361244916916
epoch 7900  clean testing loss: 0.05354117602109909
epoch 8000  training loss: 0.10943388938903809
epoch 8000  clean testing loss: 0.05037904903292656
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 8100  training loss: 0.1087440550327301
epoch 8100  clean testing loss: 0.04884650558233261
epoch 8200  training loss: 0.10790182650089264
epoch 8200  clean testing loss: 0.04846607521176338
epoch 8300  training loss: 0.11010237038135529
epoch 8300  clean testing loss: 0.047445148229599
epoch 8400  training loss: 0.1072298213839531
epoch 8400  clean testing loss: 0.04706122726202011
epoch 8500  training loss: 0.10641809552907944
epoch 8500  clean testing loss: 0.04665828496217728
epoch 8600  training loss: 0.1055917739868164
epoch 8600  clean testing loss: 0.0461488701403141
epoch 8700  training loss: 0.11073264479637146
epoch 8700  clean testing loss: 0.04645495116710663
epoch 8800  training loss: 0.10482271015644073

  9%|███████▋                                                                         | 9465/100000 [00:29<04:40, 322.53it/s]
epoch 8900  training loss: 0.10398384928703308
epoch 8900  clean testing loss: 0.04434898495674133
epoch 9000  training loss: 0.10318246483802795
epoch 9000  clean testing loss: 0.0439833402633667
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 9100  training loss: 0.10257703065872192
epoch 9100  clean testing loss: 0.043729715049266815
epoch 9200  training loss: 0.10200879722833633
epoch 9200  clean testing loss: 0.043522220104932785
epoch 9300  training loss: 0.10143563151359558
epoch 9300  clean testing loss: 0.04332631826400757
epoch 9400  training loss: 0.10259968787431717

 10%|████████                                                                        | 10091/100000 [00:31<04:40, 320.67it/s]
epoch 9500  training loss: 0.10086117684841156
epoch 9500  clean testing loss: 0.042435113340616226
epoch 9600  training loss: 0.10036302357912064
epoch 9600  clean testing loss: 0.04231636971235275
epoch 9700  training loss: 0.1043839231133461
epoch 9700  clean testing loss: 0.05112433806061745
epoch 9800  training loss: 0.09990434348583221
epoch 9800  clean testing loss: 0.04120346158742905
epoch 9900  training loss: 0.09942936152219772
epoch 9900  clean testing loss: 0.04121650010347366
epoch 10000  training loss: 0.09900829195976257
epoch 10000  clean testing loss: 0.041146378964185715
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 10100  training loss: 0.2261890321969986

 11%|████████▌                                                                       | 10752/100000 [00:33<04:38, 320.13it/s]
epoch 10200  training loss: 0.09871738404035568
epoch 10200  clean testing loss: 0.04011235386133194
epoch 10300  training loss: 0.09830550104379654
epoch 10300  clean testing loss: 0.040387801826000214
epoch 10400  training loss: 0.09792562574148178
epoch 10400  clean testing loss: 0.04054722189903259
epoch 10500  training loss: 0.09755363315343857
epoch 10500  clean testing loss: 0.04067189246416092
epoch 10600  training loss: 0.1007249504327774
epoch 10600  clean testing loss: 0.038990311324596405
epoch 10700  training loss: 0.09729702025651932

 11%|█████████                                                                       | 11378/100000 [00:35<04:35, 321.47it/s]
epoch 10800  training loss: 0.09686099737882614
epoch 10800  clean testing loss: 0.040067095309495926
epoch 10900  training loss: 0.09647978842258453
epoch 10900  clean testing loss: 0.040295109152793884
epoch 11000  training loss: 0.09613118320703506
epoch 11000  clean testing loss: 0.040491100400686264
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 11100  training loss: 0.1149485856294632
epoch 11100  clean testing loss: 0.06198430806398392
epoch 11200  training loss: 0.09583920240402222
epoch 11200  clean testing loss: 0.03988843783736229
epoch 11300  training loss: 0.09548893570899963
epoch 11300  clean testing loss: 0.04031382128596306
epoch 11400  training loss: 0.095146045088768

 12%|█████████▋                                                                      | 12037/100000 [00:37<04:36, 318.38it/s]
epoch 11500  training loss: 0.10091281682252884
epoch 11500  clean testing loss: 0.07117470353841782
epoch 11600  training loss: 0.09453483670949936
epoch 11600  clean testing loss: 0.040198881179094315
epoch 11700  training loss: 0.09412471950054169
epoch 11700  clean testing loss: 0.04056733101606369
epoch 11800  training loss: 0.09378648549318314
epoch 11800  clean testing loss: 0.04080133140087128
epoch 11900  training loss: 0.09347426146268845
epoch 11900  clean testing loss: 0.041026096791028976
epoch 12000  training loss: 0.09350348263978958
epoch 12000  clean testing loss: 0.04013994708657265

 13%|██████████▏                                                                     | 12664/100000 [00:39<04:30, 322.95it/s]
epoch 12100  training loss: 0.0932389423251152
epoch 12100  clean testing loss: 0.04051763191819191
epoch 12200  training loss: 0.0930025652050972
epoch 12200  clean testing loss: 0.040766917169094086
epoch 12300  training loss: 0.0927695631980896
epoch 12300  clean testing loss: 0.04095340520143509
epoch 12400  training loss: 0.09253348410129547
epoch 12400  clean testing loss: 0.04109850525856018
epoch 12500  training loss: 0.0922943651676178
epoch 12500  clean testing loss: 0.04121854156255722
epoch 12600  training loss: 0.09326231479644775
epoch 12600  clean testing loss: 0.04406657814979553
epoch 12700  training loss: 0.09212599694728851

 13%|██████████▋                                                                     | 13324/100000 [00:41<04:29, 321.15it/s]
epoch 12800  training loss: 0.09186524897813797
epoch 12800  clean testing loss: 0.040807027369737625
epoch 12900  training loss: 0.09163737297058105
epoch 12900  clean testing loss: 0.04106593504548073
epoch 13000  training loss: 0.09141521155834198
epoch 13000  clean testing loss: 0.041265346109867096
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 13100  training loss: 0.0914544016122818
epoch 13100  clean testing loss: 0.040563568472862244
epoch 13200  training loss: 0.09116383641958237
epoch 13200  clean testing loss: 0.041012316942214966
epoch 13300  training loss: 0.09094446897506714

 14%|███████████▏                                                                    | 13951/100000 [00:43<04:29, 319.62it/s]
epoch 13400  training loss: 0.09186215698719025
epoch 13400  clean testing loss: 0.040312159806489944
epoch 13500  training loss: 0.09078644961118698
epoch 13500  clean testing loss: 0.04071930795907974
epoch 13600  training loss: 0.09056093543767929
epoch 13600  clean testing loss: 0.04106234759092331
epoch 13700  training loss: 0.09034986793994904
epoch 13700  clean testing loss: 0.041300952434539795
epoch 13800  training loss: 0.09114240109920502
epoch 13800  clean testing loss: 0.04156942293047905
epoch 13900  training loss: 0.09013344347476959

 15%|███████████▋                                                                    | 14612/100000 [00:45<04:25, 322.13it/s]
epoch 14000  training loss: 0.08991920202970505
epoch 14000  clean testing loss: 0.04127475991845131
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 14100  training loss: 0.12197823077440262
epoch 14100  clean testing loss: 0.07540593296289444
epoch 14200  training loss: 0.08976730704307556
epoch 14200  clean testing loss: 0.040692273527383804
epoch 14300  training loss: 0.08953455090522766
epoch 14300  clean testing loss: 0.04112919792532921
epoch 14400  training loss: 0.0893213078379631
epoch 14400  clean testing loss: 0.041384585201740265
epoch 14500  training loss: 0.09091730415821075
epoch 14500  clean testing loss: 0.0422811433672905
epoch 14600  training loss: 0.08908290416002274

 15%|████████████▏                                                                   | 15272/100000 [00:47<04:21, 323.90it/s]
epoch 14700  training loss: 0.08884312212467194
epoch 14700  clean testing loss: 0.041481029242277145
epoch 14800  training loss: 0.08954135328531265
epoch 14800  clean testing loss: 0.043843913823366165
epoch 14900  training loss: 0.08863671869039536
epoch 14900  clean testing loss: 0.041145920753479004
epoch 15000  training loss: 0.08841435611248016
epoch 15000  clean testing loss: 0.04154152050614357
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 15100  training loss: 0.08824874460697174
epoch 15100  clean testing loss: 0.041757527738809586
epoch 15200  training loss: 0.08808387815952301

 16%|████████████▋                                                                   | 15901/100000 [00:49<04:21, 321.85it/s]
epoch 15300  training loss: 0.0879114419221878
epoch 15300  clean testing loss: 0.04216078296303749
epoch 15400  training loss: 0.08931280672550201
epoch 15400  clean testing loss: 0.045089006423950195
epoch 15500  training loss: 0.0876946896314621
epoch 15500  clean testing loss: 0.041863519698381424
epoch 15600  training loss: 0.08750203251838684
epoch 15600  clean testing loss: 0.04225416108965874
epoch 15700  training loss: 0.0874691978096962
epoch 15700  clean testing loss: 0.04270617291331291
epoch 15800  training loss: 0.08727844059467316
epoch 15800  clean testing loss: 0.04213060066103935
epoch 15900  training loss: 0.08709384500980377

 17%|█████████████▏                                                                  | 16561/100000 [00:51<04:17, 324.00it/s]
epoch 16000  training loss: 0.09254047274589539
epoch 16000  clean testing loss: 0.04360136762261391
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 16100  training loss: 0.0868796706199646
epoch 16100  clean testing loss: 0.04253192991018295
epoch 16200  training loss: 0.08670563250780106
epoch 16200  clean testing loss: 0.04291141778230667
epoch 16300  training loss: 0.08732564747333527
epoch 16300  clean testing loss: 0.042603105306625366
epoch 16400  training loss: 0.08657210320234299
epoch 16400  clean testing loss: 0.042572565376758575
epoch 16500  training loss: 0.08639666438102722

 17%|█████████████▊                                                                  | 17188/100000 [00:53<04:19, 319.37it/s]
epoch 16600  training loss: 0.08623632043600082
epoch 16600  clean testing loss: 0.04330776259303093
epoch 16700  training loss: 0.08634839206933975
epoch 16700  clean testing loss: 0.042556822299957275
epoch 16800  training loss: 0.0860741138458252
epoch 16800  clean testing loss: 0.043129511177539825
epoch 16900  training loss: 0.08591261506080627
epoch 16900  clean testing loss: 0.043505460023880005
epoch 17000  training loss: 0.08765494078397751
epoch 17000  clean testing loss: 0.052946627140045166
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 17100  training loss: 0.08574680984020233
epoch 17100  clean testing loss: 0.043322350829839706
epoch 17200  training loss: 0.08558156341314316

 18%|██████████████▎                                                                 | 17848/100000 [00:55<04:14, 323.24it/s]
epoch 17300  training loss: 0.11050443351268768
epoch 17300  clean testing loss: 0.07365375012159348
epoch 17400  training loss: 0.08540813624858856
epoch 17400  clean testing loss: 0.04359087720513344
epoch 17500  training loss: 0.0852409079670906
epoch 17500  clean testing loss: 0.044036272913217545
epoch 17600  training loss: 0.16327007114887238
epoch 17600  clean testing loss: 0.15798218548297882
epoch 17700  training loss: 0.08513562381267548
epoch 17700  clean testing loss: 0.043506160378456116
epoch 17800  training loss: 0.08495014160871506

 19%|██████████████▊                                                                 | 18508/100000 [00:57<04:12, 323.36it/s]
epoch 17900  training loss: 0.08479645848274231
epoch 17900  clean testing loss: 0.0444103367626667
epoch 18000  training loss: 0.16183972358703613
epoch 18000  clean testing loss: 0.07726073265075684
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 18100  training loss: 0.08464507013559341
epoch 18100  clean testing loss: 0.04416099935770035
epoch 18200  training loss: 0.0845145434141159
epoch 18200  clean testing loss: 0.044559914618730545
epoch 18300  training loss: 0.08439407497644424
epoch 18300  clean testing loss: 0.04481453821063042
epoch 18400  training loss: 0.08427446335554123
epoch 18400  clean testing loss: 0.04503876715898514
epoch 18500  training loss: 0.08415327966213226

 19%|███████████████▎                                                                | 19135/100000 [00:59<04:11, 321.10it/s]
epoch 18600  training loss: 0.08403012156486511
epoch 18600  clean testing loss: 0.04544927179813385
epoch 18700  training loss: 0.08410057425498962
epoch 18700  clean testing loss: 0.04472973197698593
epoch 18800  training loss: 0.08389117568731308
epoch 18800  clean testing loss: 0.04519837722182274
epoch 18900  training loss: 0.0837666392326355
epoch 18900  clean testing loss: 0.04550196975469589
epoch 19000  training loss: 0.08364395797252655
epoch 19000  clean testing loss: 0.04575072601437569
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 19100  training loss: 0.08362063020467758

 20%|███████████████▊                                                                | 19797/100000 [01:01<04:07, 323.81it/s]
epoch 19200  training loss: 0.08348169922828674
epoch 19200  clean testing loss: 0.04570658132433891
epoch 19300  training loss: 0.08336059749126434
epoch 19300  clean testing loss: 0.04599396139383316
epoch 19400  training loss: 0.08335961401462555
epoch 19400  clean testing loss: 0.0454738512635231
epoch 19500  training loss: 0.08320024609565735
epoch 19500  clean testing loss: 0.04596946761012077
epoch 19600  training loss: 0.08308106660842896
epoch 19600  clean testing loss: 0.046265069395303726
epoch 19700  training loss: 0.08315122127532959
epoch 19700  clean testing loss: 0.0455486960709095
epoch 19800  training loss: 0.08297334611415863

 20%|████████████████▎                                                               | 20424/100000 [01:03<04:07, 322.11it/s]
epoch 19900  training loss: 0.08285242319107056
epoch 19900  clean testing loss: 0.046293750405311584
epoch 20000  training loss: 0.08273739367723465
epoch 20000  clean testing loss: 0.046574193984270096
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 20100  training loss: 0.09748822450637817
epoch 20100  clean testing loss: 0.04719279706478119
epoch 20200  training loss: 0.08261698484420776
epoch 20200  clean testing loss: 0.04623048007488251
epoch 20300  training loss: 0.08249345421791077
epoch 20300  clean testing loss: 0.04662873595952988
epoch 20400  training loss: 0.08237890154123306

 21%|████████████████▊                                                               | 21083/100000 [01:05<04:07, 319.21it/s]
epoch 20500  training loss: 0.08275806158781052
epoch 20500  clean testing loss: 0.04655071347951889
epoch 20600  training loss: 0.08223702758550644
epoch 20600  clean testing loss: 0.046716079115867615
epoch 20700  training loss: 0.08212079852819443
epoch 20700  clean testing loss: 0.047064296901226044
epoch 20800  training loss: 0.08202394098043442
epoch 20800  clean testing loss: 0.0473807193338871
epoch 20900  training loss: 0.08200979977846146
epoch 20900  clean testing loss: 0.04665787145495415
epoch 21000  training loss: 0.08188427239656448
epoch 21000  clean testing loss: 0.04713953658938408

 22%|█████████████████▎                                                              | 21677/100000 [01:07<04:02, 322.56it/s]
epoch 21100  training loss: 0.08179493248462677
epoch 21100  clean testing loss: 0.04738428443670273
epoch 21200  training loss: 0.08170655369758606
epoch 21200  clean testing loss: 0.047589778900146484
epoch 21300  training loss: 0.08161776512861252
epoch 21300  clean testing loss: 0.04777665063738823
epoch 21400  training loss: 0.08152718096971512
epoch 21400  clean testing loss: 0.04795363172888756
epoch 21500  training loss: 0.08143435418605804
epoch 21500  clean testing loss: 0.04812363535165787
epoch 21600  training loss: 0.08183697611093521
epoch 21600  clean testing loss: 0.04806980490684509
epoch 21700  training loss: 0.08131600171327591

 22%|█████████████████▋                                                              | 22073/100000 [01:08<04:00, 324.29it/s]
epoch 21800  training loss: 0.08122211694717407
epoch 21800  clean testing loss: 0.04811059683561325
epoch 21900  training loss: 0.08112994581460953
epoch 21900  clean testing loss: 0.04832087829709053
epoch 22000  training loss: 0.0811474397778511
epoch 22000  clean testing loss: 0.048818472772836685
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 22100  training loss: 0.08101250231266022

 22%|█████████████████▉                                                              | 22370/100000 [01:09<03:59, 323.91it/s]
epoch 22200  training loss: 0.08091303706169128
epoch 22200  clean testing loss: 0.04838336259126663
epoch 22300  training loss: 0.08082175999879837
epoch 22300  clean testing loss: 0.04861615225672722
epoch 22400  training loss: 0.08072963356971741

 23%|██████████████████▏                                                             | 22800/100000 [01:11<03:59, 322.99it/s]
epoch 22500  training loss: 0.08072963356971741
epoch 22500  clean testing loss: 0.048132333904504776
epoch 22600  training loss: 0.0806209146976471
epoch 22600  clean testing loss: 0.04857850447297096
epoch 22700  training loss: 0.08053017407655716
epoch 22700  clean testing loss: 0.04884972795844078
epoch 22800  training loss: 0.08044049888849258

 23%|██████████████████▍                                                             | 23097/100000 [01:11<03:58, 321.78it/s]
epoch 22900  training loss: 0.08034880459308624
epoch 22900  clean testing loss: 0.04926992952823639
epoch 23000  training loss: 0.08039765059947968
epoch 23000  clean testing loss: 0.04836054891347885
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 23100  training loss: 0.08025816828012466

 23%|██████████████████▋                                                             | 23295/100000 [01:12<03:55, 325.16it/s]
epoch 23200  training loss: 0.0801677405834198
epoch 23200  clean testing loss: 0.04920577257871628
epoch 23300  training loss: 0.08007954061031342

 24%|██████████████████▊                                                             | 23592/100000 [01:13<03:55, 323.83it/s]
epoch 23400  training loss: 0.0799897164106369
epoch 23400  clean testing loss: 0.04965763911604881
epoch 23500  training loss: 0.08074669539928436
epoch 23500  clean testing loss: 0.05666074529290199
epoch 23600  training loss: 0.07987724989652634

 24%|███████████████████                                                             | 23790/100000 [01:14<03:55, 323.44it/s]
epoch 23700  training loss: 0.07978269457817078
epoch 23700  clean testing loss: 0.049745168536901474
epoch 23800  training loss: 0.0796927958726883

 24%|███████████████████▏                                                            | 23988/100000 [01:14<03:55, 322.47it/s]
epoch 23900  training loss: 0.07960174232721329
epoch 23900  clean testing loss: 0.05024225637316704
epoch 24000  training loss: 0.08013969659805298

 24%|███████████████████▌                                                            | 24384/100000 [01:15<03:54, 322.08it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 24100  training loss: 0.0795409306883812
epoch 24100  clean testing loss: 0.04964866116642952
epoch 24200  training loss: 0.07946036010980606
epoch 24200  clean testing loss: 0.0500376895070076
epoch 24300  training loss: 0.07938769459724426
epoch 24300  clean testing loss: 0.05030123516917229
epoch 24400  training loss: 0.07931654900312424

 25%|███████████████████▋                                                            | 24581/100000 [01:16<03:55, 320.11it/s]
epoch 24500  training loss: 0.07924464344978333
epoch 24500  clean testing loss: 0.050720080733299255
epoch 24600  training loss: 0.07917173951864243

 25%|███████████████████▉                                                            | 24878/100000 [01:17<03:51, 324.54it/s]
epoch 24700  training loss: 0.07909740507602692
epoch 24700  clean testing loss: 0.051098719239234924
epoch 24800  training loss: 0.07902153581380844
epoch 24800  clean testing loss: 0.05128154531121254
epoch 24900  training loss: 0.07972145825624466

 25%|████████████████████▏                                                           | 25274/100000 [01:18<03:51, 322.70it/s]
epoch 25000  training loss: 0.08070378750562668
epoch 25000  clean testing loss: 0.05164019390940666
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 25100  training loss: 0.07880043238401413
epoch 25100  clean testing loss: 0.05161554366350174
epoch 25200  training loss: 0.07876849174499512
epoch 25200  clean testing loss: 0.05200006440281868
epoch 25300  training loss: 0.07870574295520782

 26%|████████████████████▍                                                           | 25571/100000 [01:19<03:51, 321.74it/s]
epoch 25400  training loss: 0.07862216234207153
epoch 25400  clean testing loss: 0.05168761685490608
epoch 25500  training loss: 0.07854649424552917
epoch 25500  clean testing loss: 0.05193091183900833
epoch 25600  training loss: 0.07847070693969727

 26%|████████████████████▋                                                           | 25868/100000 [01:20<03:50, 321.80it/s]
epoch 25700  training loss: 0.07839301228523254
epoch 25700  clean testing loss: 0.05231769382953644
epoch 25800  training loss: 0.07831870764493942
epoch 25800  clean testing loss: 0.052501048892736435
epoch 25900  training loss: 0.07830392569303513

 26%|████████████████████▉                                                           | 26198/100000 [01:21<03:49, 322.22it/s]
epoch 26000  training loss: 0.07822052389383316
epoch 26000  clean testing loss: 0.052276045083999634
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 26100  training loss: 0.07814674824476242
epoch 26100  clean testing loss: 0.052504267543554306
epoch 26200  training loss: 0.07807230204343796

 27%|█████████████████████▌                                                          | 26891/100000 [01:23<03:45, 324.86it/s]
epoch 26300  training loss: 0.07799676805734634
epoch 26300  clean testing loss: 0.052851397544145584
epoch 26400  training loss: 0.07821983844041824
epoch 26400  clean testing loss: 0.06080435961484909
epoch 26500  training loss: 0.07788243144750595
epoch 26500  clean testing loss: 0.05268694460391998
epoch 26600  training loss: 0.07780727744102478
epoch 26600  clean testing loss: 0.05293497443199158
epoch 26700  training loss: 0.07773218303918839
epoch 26700  clean testing loss: 0.05310264229774475
epoch 26800  training loss: 0.07765558362007141

 27%|█████████████████████▉                                                          | 27387/100000 [01:25<03:45, 322.31it/s]
epoch 26900  training loss: 0.07766997069120407
epoch 26900  clean testing loss: 0.05266565829515457
epoch 27000  training loss: 0.0775594413280487
epoch 27000  clean testing loss: 0.05301773548126221
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 27100  training loss: 0.0775022879242897
epoch 27100  clean testing loss: 0.05319700762629509
epoch 27200  training loss: 0.07744444906711578
epoch 27200  clean testing loss: 0.053344301879405975
epoch 27300  training loss: 0.07738574594259262
epoch 27300  clean testing loss: 0.05347538739442825
epoch 27400  training loss: 0.07732602208852768

 28%|██████████████████████▍                                                         | 27981/100000 [01:27<03:43, 322.12it/s]
epoch 27500  training loss: 0.07726449519395828
epoch 27500  clean testing loss: 0.05371375381946564
epoch 27600  training loss: 0.07720151543617249
epoch 27600  clean testing loss: 0.05383720621466637
epoch 27700  training loss: 0.07713664323091507
epoch 27700  clean testing loss: 0.05396229773759842
epoch 27800  training loss: 0.07836092263460159
epoch 27800  clean testing loss: 0.05466984212398529
epoch 27900  training loss: 0.07703489810228348
epoch 27900  clean testing loss: 0.053893350064754486
epoch 28000  training loss: 0.076973557472229

 28%|██████████████████████▊                                                         | 28476/100000 [01:28<03:41, 323.51it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 28100  training loss: 0.07691127061843872
epoch 28100  clean testing loss: 0.05422266572713852
epoch 28200  training loss: 0.07684773951768875
epoch 28200  clean testing loss: 0.05435455963015556
epoch 28300  training loss: 0.07688191533088684
epoch 28300  clean testing loss: 0.0540483221411705
epoch 28400  training loss: 0.07675113528966904
epoch 28400  clean testing loss: 0.05428335815668106
epoch 28500  training loss: 0.0766909122467041

 29%|███████████████████████▏                                                        | 28971/100000 [01:30<03:40, 321.53it/s]
epoch 28600  training loss: 0.07663065195083618
epoch 28600  clean testing loss: 0.054596491158008575
epoch 28700  training loss: 0.07656862586736679
epoch 28700  clean testing loss: 0.05472758784890175
epoch 28800  training loss: 0.07658279687166214
epoch 28800  clean testing loss: 0.05444488301873207
epoch 28900  training loss: 0.07646860182285309

 29%|███████████████████████▌                                                        | 29499/100000 [01:31<03:36, 324.94it/s]
epoch 29000  training loss: 0.07640869170427322
epoch 29000  clean testing loss: 0.05485662445425987
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 29100  training loss: 0.07634787261486053
epoch 29100  clean testing loss: 0.05497933551669121
epoch 29200  training loss: 0.07669605314731598
epoch 29200  clean testing loss: 0.05522840842604637
epoch 29300  training loss: 0.07625307142734528
epoch 29300  clean testing loss: 0.054871395230293274
epoch 29400  training loss: 0.0761946588754654
epoch 29400  clean testing loss: 0.05504491925239563
epoch 29500  training loss: 0.07613541185855865

 30%|████████████████████████▏                                                       | 30190/100000 [01:33<03:36, 322.62it/s]
epoch 29600  training loss: 0.07607436925172806
epoch 29600  clean testing loss: 0.05529874563217163
epoch 29700  training loss: 0.07680356502532959
epoch 29700  clean testing loss: 0.0548848994076252
epoch 29800  training loss: 0.0759829431772232
epoch 29800  clean testing loss: 0.05519009009003639
epoch 29900  training loss: 0.07592621445655823
epoch 29900  clean testing loss: 0.05536491796374321
epoch 30000  training loss: 0.07586868852376938
epoch 30000  clean testing loss: 0.05549997836351395
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 30100  training loss: 0.07582204043865204
epoch 30100  clean testing loss: 0.05559864640235901
epoch 30200  training loss: 0.0757741704583168

 31%|████████████████████████▋                                                       | 30883/100000 [01:36<03:33, 323.01it/s]
epoch 30300  training loss: 0.0757242739200592
epoch 30300  clean testing loss: 0.0557856447994709
epoch 30400  training loss: 0.07567265629768372
epoch 30400  clean testing loss: 0.055876120924949646
epoch 30500  training loss: 0.07561883330345154
epoch 30500  clean testing loss: 0.0559663288295269
epoch 30600  training loss: 0.07570210844278336
epoch 30600  clean testing loss: 0.055700600147247314
epoch 30700  training loss: 0.07552995532751083
epoch 30700  clean testing loss: 0.055950287729501724
epoch 30800  training loss: 0.07547999918460846
epoch 30800  clean testing loss: 0.05606326460838318
epoch 30900  training loss: 0.07542923092842102

 31%|█████████████████████████▏                                                      | 31477/100000 [01:37<03:32, 322.19it/s]
epoch 31000  training loss: 0.07537563890218735
epoch 31000  clean testing loss: 0.056256070733070374
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 31100  training loss: 0.07535598427057266
epoch 31100  clean testing loss: 0.05599893629550934
epoch 31200  training loss: 0.07529615610837936
epoch 31200  clean testing loss: 0.05618927255272865
epoch 31300  training loss: 0.07524756342172623
epoch 31300  clean testing loss: 0.056302644312381744
epoch 31400  training loss: 0.07519856095314026
epoch 31400  clean testing loss: 0.05640149116516113
epoch 31500  training loss: 0.0751466378569603

 32%|█████████████████████████▋                                                      | 32071/100000 [01:39<03:30, 323.12it/s]
epoch 31600  training loss: 0.08852486312389374
epoch 31600  clean testing loss: 0.058452483266592026
epoch 31700  training loss: 0.0750596821308136
epoch 31700  clean testing loss: 0.05642899498343468
epoch 31800  training loss: 0.07501048594713211
epoch 31800  clean testing loss: 0.05656284838914871
epoch 31900  training loss: 0.07496216148138046
epoch 31900  clean testing loss: 0.05666483938694
epoch 32000  training loss: 0.07491133362054825
epoch 32000  clean testing loss: 0.05675872787833214
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 32100  training loss: 0.08188243210315704

 33%|██████████████████████████                                                      | 32599/100000 [01:41<03:29, 321.25it/s]
epoch 32200  training loss: 0.07482921332120895
epoch 32200  clean testing loss: 0.056672465056180954
epoch 32300  training loss: 0.07478180527687073
epoch 32300  clean testing loss: 0.056806907057762146
epoch 32400  training loss: 0.07473304867744446
epoch 32400  clean testing loss: 0.05690791457891464
epoch 32500  training loss: 0.07468308508396149
epoch 32500  clean testing loss: 0.05700196698307991
epoch 32600  training loss: 0.0746355801820755

 33%|██████████████████████████▍                                                     | 33094/100000 [01:42<03:28, 320.85it/s]
epoch 32700  training loss: 0.07459506392478943
epoch 32700  clean testing loss: 0.056932952255010605
epoch 32800  training loss: 0.0745457336306572
epoch 32800  clean testing loss: 0.05707915127277374
epoch 32900  training loss: 0.0744948536157608
epoch 32900  clean testing loss: 0.05718138441443443
epoch 33000  training loss: 0.07444269210100174
epoch 33000  clean testing loss: 0.057274941354990005
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 33100  training loss: 0.07439883053302765

 33%|██████████████████████████▊                                                     | 33490/100000 [01:44<03:26, 322.56it/s]
epoch 33200  training loss: 0.07435307651758194
epoch 33200  clean testing loss: 0.05741489306092262
epoch 33300  training loss: 0.07430500537157059
epoch 33300  clean testing loss: 0.05748734623193741
epoch 33400  training loss: 0.0742548406124115
epoch 33400  clean testing loss: 0.057563066482543945
epoch 33500  training loss: 0.07435376197099686

 34%|███████████████████████████▎                                                    | 34083/100000 [01:46<03:26, 319.01it/s]
epoch 33600  training loss: 0.07416918128728867
epoch 33600  clean testing loss: 0.057579491287469864
epoch 33700  training loss: 0.07412505894899368
epoch 33700  clean testing loss: 0.05766376107931137
epoch 33800  training loss: 0.07407907396554947
epoch 33800  clean testing loss: 0.05773729085922241
epoch 33900  training loss: 0.07608960568904877
epoch 33900  clean testing loss: 0.06219816580414772
epoch 34000  training loss: 0.07399716228246689
epoch 34000  clean testing loss: 0.057730261236429214
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 34100  training loss: 0.07395461201667786

 34%|███████████████████████████▌                                                    | 34479/100000 [01:47<03:23, 321.35it/s]
epoch 34200  training loss: 0.07391013950109482
epoch 34200  clean testing loss: 0.057909417897462845
epoch 34300  training loss: 0.07386460155248642
epoch 34300  clean testing loss: 0.0579831600189209
epoch 34400  training loss: 0.07391006499528885
epoch 34400  clean testing loss: 0.05793587118387222
epoch 34500  training loss: 0.07378480583429337

 35%|███████████████████████████▉                                                    | 34974/100000 [01:48<03:21, 323.51it/s]
epoch 34600  training loss: 0.07374180853366852
epoch 34600  clean testing loss: 0.05808320641517639
epoch 34700  training loss: 0.07369610667228699
epoch 34700  clean testing loss: 0.05816011503338814
epoch 34800  training loss: 0.07477985322475433
epoch 34800  clean testing loss: 0.06040045619010925
epoch 34900  training loss: 0.07361631840467453
epoch 34900  clean testing loss: 0.058155909180641174
epoch 35000  training loss: 0.07357317209243774

 35%|████████████████████████████▍                                                   | 35469/100000 [01:50<03:20, 321.21it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 35100  training loss: 0.07352983206510544
epoch 35100  clean testing loss: 0.05835220590233803
epoch 35200  training loss: 0.07348514348268509
epoch 35200  clean testing loss: 0.05844217911362648
epoch 35300  training loss: 0.07392579317092896
epoch 35300  clean testing loss: 0.05869932845234871
epoch 35400  training loss: 0.07341043651103973
epoch 35400  clean testing loss: 0.058471180498600006
epoch 35500  training loss: 0.07336944341659546

 36%|████████████████████████████▉                                                   | 36096/100000 [01:52<03:18, 321.73it/s]
epoch 35600  training loss: 0.07332800328731537
epoch 35600  clean testing loss: 0.05867547541856766
epoch 35700  training loss: 0.07328523695468903
epoch 35700  clean testing loss: 0.05877300724387169
epoch 35800  training loss: 0.07341435551643372
epoch 35800  clean testing loss: 0.05944052338600159
epoch 35900  training loss: 0.0732126235961914
epoch 35900  clean testing loss: 0.05880364403128624
epoch 36000  training loss: 0.07317299395799637

 37%|█████████████████████████████▌                                                  | 36888/100000 [01:54<03:15, 322.54it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 36100  training loss: 0.07314050942659378
epoch 36100  clean testing loss: 0.05898662284016609
epoch 36200  training loss: 0.07310651242733002
epoch 36200  clean testing loss: 0.05906238406896591
epoch 36300  training loss: 0.0730716735124588
epoch 36300  clean testing loss: 0.05914056673645973
epoch 36400  training loss: 0.07303587347269058
epoch 36400  clean testing loss: 0.05921857804059982
epoch 36500  training loss: 0.07299813628196716
epoch 36500  clean testing loss: 0.0592975839972496
epoch 36600  training loss: 0.07295965403318405
epoch 36600  clean testing loss: 0.05937984585762024
epoch 36700  training loss: 0.07327856868505478
epoch 36700  clean testing loss: 0.05962112545967102
epoch 36800  training loss: 0.07288987934589386

 37%|█████████████████████████████▉                                                  | 37484/100000 [01:56<03:13, 322.49it/s]
epoch 36900  training loss: 0.0728541910648346
epoch 36900  clean testing loss: 0.05953522026538849
epoch 37000  training loss: 0.07281608879566193
epoch 37000  clean testing loss: 0.05961617827415466
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 37100  training loss: 0.07278572767972946
epoch 37100  clean testing loss: 0.059698864817619324
epoch 37200  training loss: 0.07274781912565231
epoch 37200  clean testing loss: 0.059661321341991425
epoch 37300  training loss: 0.07271218299865723
epoch 37300  clean testing loss: 0.059757452458143234
epoch 37400  training loss: 0.07267606258392334
epoch 37400  clean testing loss: 0.059840213507413864
epoch 37500  training loss: 0.07263835519552231

 38%|██████████████████████████████▍                                                 | 37979/100000 [01:58<03:12, 322.55it/s]
epoch 37600  training loss: 0.0747402086853981
epoch 37600  clean testing loss: 0.0622449666261673
epoch 37700  training loss: 0.07257084548473358
epoch 37700  clean testing loss: 0.059973858296871185
epoch 37800  training loss: 0.07253550738096237
epoch 37800  clean testing loss: 0.060062311589717865
epoch 37900  training loss: 0.07250010967254639
epoch 37900  clean testing loss: 0.06014405936002731
epoch 38000  training loss: 0.07246219366788864

 38%|██████████████████████████████▋                                                 | 38374/100000 [01:59<03:11, 322.16it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 38100  training loss: 0.0724540650844574
epoch 38100  clean testing loss: 0.060163743793964386
epoch 38200  training loss: 0.07239764928817749
epoch 38200  clean testing loss: 0.06028280034661293
epoch 38300  training loss: 0.0723620131611824

 39%|███████████████████████████████▏                                                | 38968/100000 [02:01<03:10, 321.02it/s]
epoch 38400  training loss: 0.07232480496168137
epoch 38400  clean testing loss: 0.0604485422372818
epoch 38500  training loss: 0.07230935990810394
epoch 38500  clean testing loss: 0.06054031103849411
epoch 38600  training loss: 0.07225775718688965
epoch 38600  clean testing loss: 0.06047816574573517
epoch 38700  training loss: 0.07222256064414978
epoch 38700  clean testing loss: 0.060577936470508575
epoch 38800  training loss: 0.0721864253282547
epoch 38800  clean testing loss: 0.06065812706947327
epoch 38900  training loss: 0.0721491202712059
epoch 38900  clean testing loss: 0.060732197016477585
epoch 39000  training loss: 0.078825943171978

 40%|███████████████████████████████▋                                                | 39593/100000 [02:03<03:07, 323.03it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 39100  training loss: 0.0720890462398529
epoch 39100  clean testing loss: 0.06074404716491699
epoch 39200  training loss: 0.0720629170536995
epoch 39200  clean testing loss: 0.06080959737300873
epoch 39300  training loss: 0.07203514128923416
epoch 39300  clean testing loss: 0.06086407229304314
epoch 39400  training loss: 0.07200710475444794
epoch 39400  clean testing loss: 0.06091548502445221
epoch 39500  training loss: 0.07197818905115128
epoch 39500  clean testing loss: 0.06096525117754936
epoch 39600  training loss: 0.07194703817367554

 40%|████████████████████████████████▏                                               | 40284/100000 [02:05<03:05, 321.30it/s]
epoch 39700  training loss: 0.07191551476716995
epoch 39700  clean testing loss: 0.06106981635093689
epoch 39800  training loss: 0.0718834400177002
epoch 39800  clean testing loss: 0.06112745776772499
epoch 39900  training loss: 0.0719853863120079
epoch 39900  clean testing loss: 0.06148144230246544
epoch 40000  training loss: 0.07182398438453674
epoch 40000  clean testing loss: 0.061193566769361496
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 40100  training loss: 0.07179373502731323
epoch 40100  clean testing loss: 0.06125587224960327
epoch 40200  training loss: 0.07176260650157928
epoch 40200  clean testing loss: 0.06131674721837044
epoch 40300  training loss: 0.07174791395664215

 41%|████████████████████████████████▌                                               | 40779/100000 [02:06<03:03, 322.10it/s]
epoch 40400  training loss: 0.07171057164669037
epoch 40400  clean testing loss: 0.06133798137307167
epoch 40500  training loss: 0.0716836005449295
epoch 40500  clean testing loss: 0.06140463426709175
epoch 40600  training loss: 0.07165583968162537
epoch 40600  clean testing loss: 0.06146632134914398
epoch 40700  training loss: 0.07162728905677795
epoch 40700  clean testing loss: 0.06152835488319397
epoch 40800  training loss: 0.0715976282954216

 41%|█████████████████████████████████                                               | 41272/100000 [02:08<03:01, 322.89it/s]
epoch 40900  training loss: 0.0716821700334549
epoch 40900  clean testing loss: 0.06175873428583145
epoch 41000  training loss: 0.07154503464698792
epoch 41000  clean testing loss: 0.061642490327358246
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 41100  training loss: 0.07151713967323303
epoch 41100  clean testing loss: 0.061701495200395584
epoch 41200  training loss: 0.07148919999599457
epoch 41200  clean testing loss: 0.06175840273499489
epoch 41300  training loss: 0.07146266847848892

 42%|█████████████████████████████████▌                                              | 41899/100000 [02:10<03:00, 321.25it/s]
epoch 41400  training loss: 0.07143845409154892
epoch 41400  clean testing loss: 0.06177155673503876
epoch 41500  training loss: 0.0714128315448761
epoch 41500  clean testing loss: 0.061837129294872284
epoch 41600  training loss: 0.07138720154762268
epoch 41600  clean testing loss: 0.061894290149211884
epoch 41700  training loss: 0.0713600218296051
epoch 41700  clean testing loss: 0.061949823051691055
epoch 41800  training loss: 0.0713324025273323

 42%|█████████████████████████████████▉                                              | 42394/100000 [02:11<02:57, 323.71it/s]
epoch 41900  training loss: 0.07152015715837479
epoch 41900  clean testing loss: 0.06225023791193962
epoch 42000  training loss: 0.07128160446882248
epoch 42000  clean testing loss: 0.0620415098965168
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 42100  training loss: 0.07126082479953766
epoch 42100  clean testing loss: 0.062087323516607285
epoch 42200  training loss: 0.07123912125825882
epoch 42200  clean testing loss: 0.062131382524967194
epoch 42300  training loss: 0.07121643424034119
epoch 42300  clean testing loss: 0.06217324733734131
epoch 42400  training loss: 0.07119371742010117

 43%|██████████████████████████████████▍                                             | 42988/100000 [02:13<02:56, 322.13it/s]
epoch 42500  training loss: 0.07116992771625519
epoch 42500  clean testing loss: 0.06226026266813278
epoch 42600  training loss: 0.07114508748054504
epoch 42600  clean testing loss: 0.0623055137693882
epoch 42700  training loss: 0.07111947983503342
epoch 42700  clean testing loss: 0.06235184893012047
epoch 42800  training loss: 0.07110212743282318
epoch 42800  clean testing loss: 0.06235412880778313
epoch 42900  training loss: 0.07107402384281158

 43%|██████████████████████████████████▋                                             | 43285/100000 [02:14<02:55, 322.98it/s]
epoch 43000  training loss: 0.07105080783367157
epoch 43000  clean testing loss: 0.06244005635380745
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 43100  training loss: 0.07102632522583008
epoch 43100  clean testing loss: 0.0624854750931263
epoch 43200  training loss: 0.07644616812467575
epoch 43200  clean testing loss: 0.06652995944023132
epoch 43300  training loss: 0.0709795281291008

 44%|███████████████████████████████████                                             | 43879/100000 [02:16<02:53, 323.31it/s]
epoch 43400  training loss: 0.07095582783222198
epoch 43400  clean testing loss: 0.06257521361112595
epoch 43500  training loss: 0.07093129307031631
epoch 43500  clean testing loss: 0.06262040138244629
epoch 43600  training loss: 0.07090403884649277
epoch 43600  clean testing loss: 0.06266505271196365
epoch 43700  training loss: 0.07089468091726303
epoch 43700  clean testing loss: 0.06266649067401886
epoch 43800  training loss: 0.07085953652858734
epoch 43800  clean testing loss: 0.06269277632236481
epoch 43900  training loss: 0.07083668559789658

 45%|███████████████████████████████████▋                                            | 44570/100000 [02:18<02:51, 323.13it/s]
epoch 44000  training loss: 0.07081333547830582
epoch 44000  clean testing loss: 0.06277275085449219
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 44100  training loss: 0.07078836113214493
epoch 44100  clean testing loss: 0.06281062960624695
epoch 44200  training loss: 0.07104324549436569
epoch 44200  clean testing loss: 0.06332254409790039
epoch 44300  training loss: 0.07074667513370514
epoch 44300  clean testing loss: 0.06281494349241257
epoch 44400  training loss: 0.07072559744119644
epoch 44400  clean testing loss: 0.06285935640335083
epoch 44500  training loss: 0.07070380449295044

 45%|███████████████████████████████████▉                                            | 44900/100000 [02:19<02:50, 323.10it/s]
epoch 44600  training loss: 0.0706808865070343
epoch 44600  clean testing loss: 0.06293269246816635
epoch 44700  training loss: 0.0706573873758316
epoch 44700  clean testing loss: 0.06296753883361816
epoch 44800  training loss: 0.07197803258895874
epoch 44800  clean testing loss: 0.06327339261770248
epoch 44900  training loss: 0.07061323523521423

 45%|████████████████████████████████████▍                                           | 45494/100000 [02:21<02:49, 321.82it/s]
epoch 45000  training loss: 0.07059093564748764
epoch 45000  clean testing loss: 0.06302046775817871
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 45100  training loss: 0.07057270407676697
epoch 45100  clean testing loss: 0.06304981559515
epoch 45200  training loss: 0.07055400311946869
epoch 45200  clean testing loss: 0.06308125704526901
epoch 45300  training loss: 0.07053449004888535
epoch 45300  clean testing loss: 0.06311347335577011
epoch 45400  training loss: 0.07051408290863037
epoch 45400  clean testing loss: 0.06314787268638611
epoch 45500  training loss: 0.0704926922917366

 46%|████████████████████████████████████▊                                           | 46088/100000 [02:23<02:48, 320.84it/s]
epoch 45600  training loss: 0.07047073543071747
epoch 45600  clean testing loss: 0.06321792304515839
epoch 45700  training loss: 0.07046116888523102
epoch 45700  clean testing loss: 0.06320109218358994
epoch 45800  training loss: 0.07043185085058212
epoch 45800  clean testing loss: 0.06324917078018188
epoch 45900  training loss: 0.07041200995445251
epoch 45900  clean testing loss: 0.06328390538692474
epoch 46000  training loss: 0.07039105892181396
epoch 46000  clean testing loss: 0.06331878155469894
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 46100  training loss: 0.07036963850259781

 47%|█████████████████████████████████████▎                                          | 46585/100000 [02:24<02:45, 323.53it/s]
epoch 46200  training loss: 0.07038679718971252
epoch 46200  clean testing loss: 0.06331799179315567
epoch 46300  training loss: 0.07032982259988785
epoch 46300  clean testing loss: 0.06338660418987274
epoch 46400  training loss: 0.07030899822711945
epoch 46400  clean testing loss: 0.06341994553804398
epoch 46500  training loss: 0.0702870637178421
epoch 46500  clean testing loss: 0.0634545236825943
epoch 46600  training loss: 0.07026591897010803

 47%|█████████████████████████████████████▋                                          | 47080/100000 [02:26<02:45, 320.32it/s]
epoch 46700  training loss: 0.07024820894002914
epoch 46700  clean testing loss: 0.06346116214990616
epoch 46800  training loss: 0.07022891938686371
epoch 46800  clean testing loss: 0.0635080486536026
epoch 46900  training loss: 0.07020933926105499
epoch 46900  clean testing loss: 0.06353927403688431
epoch 47000  training loss: 0.07018916308879852
epoch 47000  clean testing loss: 0.06357009708881378
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 47100  training loss: 0.070168137550354

 48%|██████████████████████████████████████                                          | 47575/100000 [02:28<02:49, 310.16it/s]
epoch 47200  training loss: 0.07398149371147156
epoch 47200  clean testing loss: 0.06483077257871628
epoch 47300  training loss: 0.0701284185051918
epoch 47300  clean testing loss: 0.06361759454011917
epoch 47400  training loss: 0.07010967284440994
epoch 47400  clean testing loss: 0.06365038454532623
epoch 47500  training loss: 0.07009009271860123

 48%|██████████████████████████████████████▍                                         | 47970/100000 [02:29<02:40, 323.47it/s]
epoch 47600  training loss: 0.07006997615098953
epoch 47600  clean testing loss: 0.06370636820793152
epoch 47700  training loss: 0.07004942744970322
epoch 47700  clean testing loss: 0.06373659521341324
epoch 47800  training loss: 0.07003264129161835
epoch 47800  clean testing loss: 0.06371976435184479
epoch 47900  training loss: 0.07001281529664993
epoch 47900  clean testing loss: 0.0637538731098175
epoch 48000  training loss: 0.06999316066503525

 48%|██████████████████████████████████████▋                                         | 48399/100000 [02:30<02:39, 323.63it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 48100  training loss: 0.06997763365507126
epoch 48100  clean testing loss: 0.06380405277013779
epoch 48200  training loss: 0.06996133923530579
epoch 48200  clean testing loss: 0.0638260617852211
epoch 48300  training loss: 0.06994442641735077
epoch 48300  clean testing loss: 0.06385022401809692
epoch 48400  training loss: 0.06992746889591217

 49%|███████████████████████████████████████▌                                        | 49488/100000 [02:33<02:37, 321.33it/s]
epoch 48500  training loss: 0.06990998983383179
epoch 48500  clean testing loss: 0.06389879435300827
epoch 48600  training loss: 0.06989101320505142
epoch 48600  clean testing loss: 0.06392543017864227
epoch 48700  training loss: 0.07166773825883865
epoch 48700  clean testing loss: 0.06755255162715912
epoch 48800  training loss: 0.06985553354024887
epoch 48800  clean testing loss: 0.06394974142313004
epoch 48900  training loss: 0.06983911246061325
epoch 48900  clean testing loss: 0.0639798492193222
epoch 49000  training loss: 0.06982135027647018
epoch 49000  clean testing loss: 0.06400485336780548
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 49100  training loss: 0.06980317831039429
epoch 49100  clean testing loss: 0.06403060257434845
epoch 49200  training loss: 0.06978431344032288
epoch 49200  clean testing loss: 0.06405778229236603
epoch 49300  training loss: 0.069771409034729
epoch 49300  clean testing loss: 0.06407710909843445
epoch 49400  training loss: 0.06975133717060089
epoch 49400  clean testing loss: 0.06407900899648666
epoch 49500  training loss: 0.06973449885845184

 50%|████████████████████████████████████████                                        | 50081/100000 [02:35<02:36, 319.22it/s]
epoch 49600  training loss: 0.069717638194561
epoch 49600  clean testing loss: 0.06412463635206223
epoch 49700  training loss: 0.06969916075468063
epoch 49700  clean testing loss: 0.0641493871808052
epoch 49800  training loss: 0.0698147788643837
epoch 49800  clean testing loss: 0.06511019170284271
epoch 49900  training loss: 0.0696667805314064
epoch 49900  clean testing loss: 0.06416215747594833
epoch 50000  training loss: 0.06965166330337524

 51%|████████████████████████████████████████▌                                       | 50674/100000 [02:37<02:33, 321.60it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 50100  training loss: 0.06963600963354111
epoch 50100  clean testing loss: 0.06421081721782684
epoch 50200  training loss: 0.06961944699287415
epoch 50200  clean testing loss: 0.06423435360193253
epoch 50300  training loss: 0.06960205733776093
epoch 50300  clean testing loss: 0.06425823271274567
epoch 50400  training loss: 0.06958473473787308
epoch 50400  clean testing loss: 0.06428319215774536
epoch 50500  training loss: 0.06969553232192993
epoch 50500  clean testing loss: 0.06436285376548767
epoch 50600  training loss: 0.06955208629369736

 51%|█████████████████████████████████████████                                       | 51299/100000 [02:39<02:32, 319.92it/s]
epoch 50700  training loss: 0.06953656673431396
epoch 50700  clean testing loss: 0.06432230025529861
epoch 50800  training loss: 0.06951987743377686
epoch 50800  clean testing loss: 0.06434223055839539
epoch 50900  training loss: 0.06950218975543976
epoch 50900  clean testing loss: 0.06436081975698471
epoch 51000  training loss: 0.06948421895503998
epoch 51000  clean testing loss: 0.06438051164150238
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 51100  training loss: 0.06946904957294464
epoch 51100  clean testing loss: 0.06439779698848724
epoch 51200  training loss: 0.06945313513278961
epoch 51200  clean testing loss: 0.06441595405340195
epoch 51300  training loss: 0.06943683326244354

 51%|█████████████████████████████████████████▏                                      | 51497/100000 [02:40<02:31, 320.94it/s]
epoch 51400  training loss: 0.06942018121480942
epoch 51400  clean testing loss: 0.0644555315375328
epoch 51500  training loss: 0.06940712034702301

 52%|█████████████████████████████████████████▌                                      | 51992/100000 [02:41<02:29, 321.29it/s]
epoch 51600  training loss: 0.06939253211021423
epoch 51600  clean testing loss: 0.06446893513202667
epoch 51700  training loss: 0.06937891244888306
epoch 51700  clean testing loss: 0.06448724120855331
epoch 51800  training loss: 0.06936460733413696
epoch 51800  clean testing loss: 0.06450535356998444
epoch 51900  training loss: 0.06935059279203415

 53%|██████████████████████████████████████████                                      | 52585/100000 [02:43<02:27, 321.29it/s]
epoch 52000  training loss: 0.06933572143316269
epoch 52000  clean testing loss: 0.06454376131296158
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 52100  training loss: 0.06931991130113602
epoch 52100  clean testing loss: 0.06456326693296432
epoch 52200  training loss: 0.06930330395698547
epoch 52200  clean testing loss: 0.06458280235528946
epoch 52300  training loss: 0.06928933411836624
epoch 52300  clean testing loss: 0.06458337604999542
epoch 52400  training loss: 0.06927464157342911
epoch 52400  clean testing loss: 0.06459978222846985
epoch 52500  training loss: 0.06926006078720093
epoch 52500  clean testing loss: 0.06461489945650101
epoch 52600  training loss: 0.06924412399530411

 53%|██████████████████████████████████████████▍                                     | 53079/100000 [02:45<02:26, 321.13it/s]
epoch 52700  training loss: 0.06922861933708191
epoch 52700  clean testing loss: 0.06464692205190659
epoch 52800  training loss: 0.06934820860624313
epoch 52800  clean testing loss: 0.06482885032892227
epoch 52900  training loss: 0.06919950991868973
epoch 52900  clean testing loss: 0.0646553561091423
epoch 53000  training loss: 0.06918539106845856

 54%|███████████████████████████████████████████                                     | 53772/100000 [02:47<02:23, 321.46it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 53100  training loss: 0.06917138397693634
epoch 53100  clean testing loss: 0.06468866020441055
epoch 53200  training loss: 0.06915626674890518
epoch 53200  clean testing loss: 0.06470423936843872
epoch 53300  training loss: 0.06914031505584717
epoch 53300  clean testing loss: 0.06472119688987732
epoch 53400  training loss: 0.06912355124950409
epoch 53400  clean testing loss: 0.06474050879478455
epoch 53500  training loss: 0.06911031901836395
epoch 53500  clean testing loss: 0.06477906554937363
epoch 53600  training loss: 0.06909164786338806
epoch 53600  clean testing loss: 0.06476946920156479
epoch 53700  training loss: 0.06907656788825989

 54%|███████████████████████████████████████████▌                                    | 54397/100000 [02:49<02:22, 320.90it/s]
epoch 53800  training loss: 0.06906146556138992
epoch 53800  clean testing loss: 0.06480348110198975
epoch 53900  training loss: 0.06904543936252594
epoch 53900  clean testing loss: 0.06482262164354324
epoch 54000  training loss: 0.06908910721540451
epoch 54000  clean testing loss: 0.0648154765367508
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 54100  training loss: 0.06901468336582184
epoch 54100  clean testing loss: 0.06485901027917862
epoch 54200  training loss: 0.06900037080049515
epoch 54200  clean testing loss: 0.06487547606229782
epoch 54300  training loss: 0.06898590922355652

 55%|███████████████████████████████████████████▉                                    | 54990/100000 [02:51<02:19, 321.86it/s]
epoch 54400  training loss: 0.06897071748971939
epoch 54400  clean testing loss: 0.0649130567908287
epoch 54500  training loss: 0.06896477192640305
epoch 54500  clean testing loss: 0.06494542211294174
epoch 54600  training loss: 0.0689452663064003
epoch 54600  clean testing loss: 0.06492988765239716
epoch 54700  training loss: 0.06893264502286911
epoch 54700  clean testing loss: 0.06494380533695221
epoch 54800  training loss: 0.0689195767045021
epoch 54800  clean testing loss: 0.06496032327413559
epoch 54900  training loss: 0.06890567392110825

 55%|████████████████████████████████████████████▎                                   | 55387/100000 [02:52<02:18, 322.09it/s]
epoch 55000  training loss: 0.06889206171035767
epoch 55000  clean testing loss: 0.06499326229095459
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 55100  training loss: 0.0688776820898056
epoch 55100  clean testing loss: 0.06501106917858124
epoch 55200  training loss: 0.06886287033557892
epoch 55200  clean testing loss: 0.0650300607085228
epoch 55300  training loss: 0.06885120272636414
epoch 55300  clean testing loss: 0.06502965092658997
epoch 55400  training loss: 0.06883606314659119

 56%|████████████████████████████████████████████▋                                   | 55783/100000 [02:53<02:17, 320.94it/s]
epoch 55500  training loss: 0.06882301717996597
epoch 55500  clean testing loss: 0.0650596022605896
epoch 55600  training loss: 0.06880932301282883
epoch 55600  clean testing loss: 0.06507311016321182
epoch 55700  training loss: 0.06879547983407974
epoch 55700  clean testing loss: 0.06508723646402359
epoch 55800  training loss: 0.06878059357404709

 56%|████████████████████████████████████████████▋                                   | 55882/100000 [02:53<02:17, 320.42it/s]
epoch 55900  training loss: 0.06879354268312454

 56%|█████████████████████████████████████████████                                   | 56278/100000 [02:55<02:15, 322.32it/s]
epoch 56000  training loss: 0.06875734776258469
epoch 56000  clean testing loss: 0.06511073559522629
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 56100  training loss: 0.0687466710805893
epoch 56100  clean testing loss: 0.06512510031461716
epoch 56200  training loss: 0.06873565912246704
epoch 56200  clean testing loss: 0.06513694673776627
epoch 56300  training loss: 0.06872417032718658

 57%|█████████████████████████████████████████████▍                                  | 56773/100000 [02:56<02:14, 321.96it/s]
epoch 56400  training loss: 0.06871204823255539
epoch 56400  clean testing loss: 0.0651652067899704
epoch 56500  training loss: 0.06869899481534958
epoch 56500  clean testing loss: 0.06518124043941498
epoch 56600  training loss: 0.06868599355220795

 69%|██████████████████████████████████████████████████████▉                         | 68714/100000 [03:33<01:37, 319.86it/s]
epoch 56700  training loss: 0.06867321580648422
epoch 56700  clean testing loss: 0.06521639972925186
epoch 56800  training loss: 0.06865879893302917
epoch 56800  clean testing loss: 0.06523429602384567
epoch 56900  training loss: 0.06864628940820694
epoch 56900  clean testing loss: 0.06524784862995148
epoch 57000  training loss: 0.06863471120595932
epoch 57000  clean testing loss: 0.06525467336177826
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 57100  training loss: 0.06862402707338333
epoch 57100  clean testing loss: 0.06526661664247513
epoch 57200  training loss: 0.06861360371112823
epoch 57200  clean testing loss: 0.0652783140540123
epoch 57300  training loss: 0.06860346347093582
epoch 57300  clean testing loss: 0.06529203057289124
epoch 57400  training loss: 0.0685923621058464
epoch 57400  clean testing loss: 0.06530507653951645
epoch 57500  training loss: 0.06858094036579132
epoch 57500  clean testing loss: 0.06532157957553864
epoch 57600  training loss: 0.06856928020715714
epoch 57600  clean testing loss: 0.06533835828304291
epoch 57700  training loss: 0.06855600327253342
epoch 57700  clean testing loss: 0.06535638123750687
epoch 57800  training loss: 0.06854335218667984
epoch 57800  clean testing loss: 0.06537603586912155
epoch 57900  training loss: 0.06854498386383057
epoch 57900  clean testing loss: 0.06535544246435165
epoch 58000  training loss: 0.06852063536643982
epoch 58000  clean testing loss: 0.06540089845657349
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 58100  training loss: 0.0685097798705101
epoch 58100  clean testing loss: 0.06541598588228226
epoch 58200  training loss: 0.06849882751703262
epoch 58200  clean testing loss: 0.06543201208114624
epoch 58300  training loss: 0.06848679482936859
epoch 58300  clean testing loss: 0.06544893234968185
epoch 58400  training loss: 0.06847463548183441
epoch 58400  clean testing loss: 0.06546783447265625
epoch 58500  training loss: 0.0684618428349495
epoch 58500  clean testing loss: 0.06548720598220825
epoch 58600  training loss: 0.0684826523065567
epoch 58600  clean testing loss: 0.0655769407749176
epoch 58700  training loss: 0.06843888014554977
epoch 58700  clean testing loss: 0.06551411002874374
epoch 58800  training loss: 0.06842732429504395
epoch 58800  clean testing loss: 0.06552929431200027
epoch 58900  training loss: 0.06841618567705154
epoch 58900  clean testing loss: 0.06554573774337769
epoch 59000  training loss: 0.06840400397777557
epoch 59000  clean testing loss: 0.06556417793035507
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 59100  training loss: 0.06839092075824738
epoch 59100  clean testing loss: 0.06558270752429962
epoch 59200  training loss: 0.0683971494436264
epoch 59200  clean testing loss: 0.06564212590456009
epoch 59300  training loss: 0.06836970150470734
epoch 59300  clean testing loss: 0.06560532003641129
epoch 59400  training loss: 0.06835807114839554
epoch 59400  clean testing loss: 0.06562080979347229
epoch 59500  training loss: 0.06834699213504791
epoch 59500  clean testing loss: 0.06563655287027359
epoch 59600  training loss: 0.06833605468273163
epoch 59600  clean testing loss: 0.06565245985984802
epoch 59700  training loss: 0.06832405179738998
epoch 59700  clean testing loss: 0.06567089259624481
epoch 59800  training loss: 0.06831153482198715
epoch 59800  clean testing loss: 0.06569045037031174
epoch 59900  training loss: 0.06829987466335297
epoch 59900  clean testing loss: 0.06570518761873245
epoch 60000  training loss: 0.06828849017620087
epoch 60000  clean testing loss: 0.06571892648935318
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 60100  training loss: 0.06827974319458008
epoch 60100  clean testing loss: 0.06573004275560379
epoch 60200  training loss: 0.0682712271809578
epoch 60200  clean testing loss: 0.065742127597332
epoch 60300  training loss: 0.06826123595237732
epoch 60300  clean testing loss: 0.06575494259595871
epoch 60400  training loss: 0.06825198978185654
epoch 60400  clean testing loss: 0.06576865166425705
epoch 60500  training loss: 0.06824183464050293
epoch 60500  clean testing loss: 0.06578446924686432
epoch 60600  training loss: 0.06823191791772842
epoch 60600  clean testing loss: 0.06579986959695816
epoch 60700  training loss: 0.06822113692760468
epoch 60700  clean testing loss: 0.06581886857748032
epoch 60800  training loss: 0.0682099238038063
epoch 60800  clean testing loss: 0.06583823263645172
epoch 60900  training loss: 0.06819751858711243
epoch 60900  clean testing loss: 0.06585797667503357
epoch 61000  training loss: 0.06820064038038254
epoch 61000  clean testing loss: 0.06696402281522751
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 61100  training loss: 0.06817746162414551
epoch 61100  clean testing loss: 0.0658823698759079
epoch 61200  training loss: 0.06816887110471725
epoch 61200  clean testing loss: 0.06589369475841522
epoch 61300  training loss: 0.06815943866968155
epoch 61300  clean testing loss: 0.06590434908866882
epoch 61400  training loss: 0.0681486651301384
epoch 61400  clean testing loss: 0.06591591238975525
epoch 61500  training loss: 0.06813904643058777
epoch 61500  clean testing loss: 0.06592904776334763
epoch 61600  training loss: 0.06812774389982224
epoch 61600  clean testing loss: 0.06594601273536682
epoch 61700  training loss: 0.06811705976724625
epoch 61700  clean testing loss: 0.06596440076828003
epoch 61800  training loss: 0.06810646504163742
epoch 61800  clean testing loss: 0.06598567217588425
epoch 61900  training loss: 0.06809478998184204
epoch 61900  clean testing loss: 0.06600663810968399
epoch 62000  training loss: 0.06811387836933136
epoch 62000  clean testing loss: 0.06605178117752075
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 62100  training loss: 0.06807504594326019
epoch 62100  clean testing loss: 0.06603466719388962
epoch 62200  training loss: 0.06806667894124985
epoch 62200  clean testing loss: 0.06605057418346405
epoch 62300  training loss: 0.06805738061666489
epoch 62300  clean testing loss: 0.06606529653072357
epoch 62400  training loss: 0.06804708391427994
epoch 62400  clean testing loss: 0.06608299911022186
epoch 62500  training loss: 0.06803689897060394
epoch 62500  clean testing loss: 0.06610032171010971
epoch 62600  training loss: 0.06802649796009064
epoch 62600  clean testing loss: 0.0661185160279274
epoch 62700  training loss: 0.06801590323448181
epoch 62700  clean testing loss: 0.06613948941230774
epoch 62800  training loss: 0.06800438463687897
epoch 62800  clean testing loss: 0.06616038084030151
epoch 62900  training loss: 0.06834761053323746
epoch 62900  clean testing loss: 0.067417211830616
epoch 63000  training loss: 0.0679841861128807
epoch 63000  clean testing loss: 0.06619033962488174
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 63100  training loss: 0.06797701865434647
epoch 63100  clean testing loss: 0.06620156764984131
epoch 63200  training loss: 0.06796965003013611
epoch 63200  clean testing loss: 0.06621261686086655
epoch 63300  training loss: 0.06796176731586456
epoch 63300  clean testing loss: 0.0662253126502037
epoch 63400  training loss: 0.06795355677604675
epoch 63400  clean testing loss: 0.06623837351799011
epoch 63500  training loss: 0.0679454505443573
epoch 63500  clean testing loss: 0.06625320762395859
epoch 63600  training loss: 0.06793657690286636
epoch 63600  clean testing loss: 0.06626778841018677
epoch 63700  training loss: 0.06792745739221573
epoch 63700  clean testing loss: 0.06628352403640747
epoch 63800  training loss: 0.06791795790195465
epoch 63800  clean testing loss: 0.06629985570907593
epoch 63900  training loss: 0.0679076537489891
epoch 63900  clean testing loss: 0.0663171112537384
epoch 64000  training loss: 0.06789825856685638
epoch 64000  clean testing loss: 0.06633587181568146
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 64100  training loss: 0.06788742542266846
epoch 64100  clean testing loss: 0.06635544449090958
epoch 64200  training loss: 0.06795000284910202
epoch 64200  clean testing loss: 0.06683563441038132
epoch 64300  training loss: 0.06786833703517914
epoch 64300  clean testing loss: 0.06637934595346451
epoch 64400  training loss: 0.06786086410284042
epoch 64400  clean testing loss: 0.0663919672369957
epoch 64500  training loss: 0.06785255670547485
epoch 64500  clean testing loss: 0.0664050281047821
epoch 64600  training loss: 0.06784399598836899
epoch 64600  clean testing loss: 0.06641887873411179
epoch 64700  training loss: 0.06783457845449448
epoch 64700  clean testing loss: 0.06643293052911758
epoch 64800  training loss: 0.06782568991184235
epoch 64800  clean testing loss: 0.06644818186759949
epoch 64900  training loss: 0.0678156167268753
epoch 64900  clean testing loss: 0.06646686047315598
epoch 65000  training loss: 0.06780584901571274
epoch 65000  clean testing loss: 0.06648264080286026
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 65100  training loss: 0.06779574602842331
epoch 65100  clean testing loss: 0.06650238484144211
epoch 65200  training loss: 0.06778527051210403
epoch 65200  clean testing loss: 0.06652334332466125
epoch 65300  training loss: 0.06777741014957428
epoch 65300  clean testing loss: 0.06653014570474625
epoch 65400  training loss: 0.06776820868253708
epoch 65400  clean testing loss: 0.06654409319162369
epoch 65500  training loss: 0.06776051968336105
epoch 65500  clean testing loss: 0.06655588001012802
epoch 65600  training loss: 0.0677511990070343
epoch 65600  clean testing loss: 0.06656792759895325
epoch 65700  training loss: 0.0677427276968956
epoch 65700  clean testing loss: 0.06658052653074265
epoch 65800  training loss: 0.06773440539836884
epoch 65800  clean testing loss: 0.0665939524769783
epoch 65900  training loss: 0.06772442907094955
epoch 65900  clean testing loss: 0.06660951673984528
epoch 66000  training loss: 0.06771500408649445
epoch 66000  clean testing loss: 0.0666261836886406
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 66100  training loss: 0.06770658493041992
epoch 66100  clean testing loss: 0.0666406899690628
epoch 66200  training loss: 0.06769835948944092
epoch 66200  clean testing loss: 0.06665448099374771
epoch 66300  training loss: 0.0676899254322052
epoch 66300  clean testing loss: 0.06667323410511017
epoch 66400  training loss: 0.06768099963665009
epoch 66400  clean testing loss: 0.06669057160615921
epoch 66500  training loss: 0.0676717683672905
epoch 66500  clean testing loss: 0.06671075522899628
epoch 66600  training loss: 0.06766191124916077
epoch 66600  clean testing loss: 0.06673111021518707
epoch 66700  training loss: 0.06802588701248169
epoch 66700  clean testing loss: 0.06713942438364029
epoch 66800  training loss: 0.0676460936665535
epoch 66800  clean testing loss: 0.06675691902637482
epoch 66900  training loss: 0.0676397755742073
epoch 66900  clean testing loss: 0.06676869094371796
epoch 67000  training loss: 0.06763269007205963
epoch 67000  clean testing loss: 0.06677886843681335
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 67100  training loss: 0.06762608885765076
epoch 67100  clean testing loss: 0.06679105013608932
epoch 67200  training loss: 0.06761863827705383
epoch 67200  clean testing loss: 0.06680204719305038
epoch 67300  training loss: 0.06761065870523453
epoch 67300  clean testing loss: 0.06681497395038605
epoch 67400  training loss: 0.06760275363922119
epoch 67400  clean testing loss: 0.06683018803596497
epoch 67500  training loss: 0.067594975233078
epoch 67500  clean testing loss: 0.06684575229883194
epoch 67600  training loss: 0.06758653372526169
epoch 67600  clean testing loss: 0.06686205416917801
epoch 67700  training loss: 0.0675773024559021
epoch 67700  clean testing loss: 0.06688044220209122
epoch 67800  training loss: 0.06756871193647385
epoch 67800  clean testing loss: 0.06689976900815964
epoch 67900  training loss: 0.06755848973989487
epoch 67900  clean testing loss: 0.06692037731409073
epoch 68000  training loss: 0.06764847040176392
epoch 68000  clean testing loss: 0.06688131392002106
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 68100  training loss: 0.06754335761070251
epoch 68100  clean testing loss: 0.0669451504945755
epoch 68200  training loss: 0.06753738969564438
epoch 68200  clean testing loss: 0.066954106092453
epoch 68300  training loss: 0.06753018498420715
epoch 68300  clean testing loss: 0.06696377694606781
epoch 68400  training loss: 0.06752319633960724
epoch 68400  clean testing loss: 0.06697341054677963
epoch 68500  training loss: 0.06751590222120285
epoch 68500  clean testing loss: 0.06698644161224365
epoch 68600  training loss: 0.0675082877278328
epoch 68600  clean testing loss: 0.06699743121862411
epoch 68700  training loss: 0.06750032305717468
epoch 68700  clean testing loss: 0.06701155751943588
epoch 68800  training loss: 0.06749273091554642

 69%|███████████████████████████████████████████████████████▍                        | 69373/100000 [03:35<01:34, 322.62it/s]
epoch 68900  training loss: 0.06748371571302414
epoch 68900  clean testing loss: 0.06704244017601013
epoch 69000  training loss: 0.06747424602508545
epoch 69000  clean testing loss: 0.06705956161022186
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 69100  training loss: 0.06746756285429001
epoch 69100  clean testing loss: 0.06707441806793213
epoch 69200  training loss: 0.0674600899219513
epoch 69200  clean testing loss: 0.06708985567092896
epoch 69300  training loss: 0.06745290011167526
epoch 69300  clean testing loss: 0.067106693983078
epoch 69400  training loss: 0.06744461506605148

 70%|████████████████████████████████████████████████████████                        | 70000/100000 [03:37<01:33, 322.23it/s]
epoch 69500  training loss: 0.06743542850017548
epoch 69500  clean testing loss: 0.06714405864477158
epoch 69600  training loss: 0.06742698699235916
epoch 69600  clean testing loss: 0.0671638622879982
epoch 69700  training loss: 0.06759988516569138
epoch 69700  clean testing loss: 0.06828974187374115
epoch 69800  training loss: 0.06741313636302948
epoch 69800  clean testing loss: 0.06719037890434265
epoch 69900  training loss: 0.06740736961364746
epoch 69900  clean testing loss: 0.06719983369112015
epoch 70000  training loss: 0.0674017071723938
epoch 70000  clean testing loss: 0.06721074134111404

 71%|████████████████████████████████████████████████████████▌                       | 70659/100000 [03:39<01:30, 322.99it/s]
epoch 70100  training loss: 0.0673956647515297
epoch 70100  clean testing loss: 0.06721892207860947
epoch 70200  training loss: 0.06739015877246857
epoch 70200  clean testing loss: 0.06722856312990189
epoch 70300  training loss: 0.06738407164812088
epoch 70300  clean testing loss: 0.06723915785551071
epoch 70400  training loss: 0.06737776845693588
epoch 70400  clean testing loss: 0.06725048273801804
epoch 70500  training loss: 0.06737083196640015
epoch 70500  clean testing loss: 0.06726381182670593
epoch 70600  training loss: 0.06736351549625397
epoch 70600  clean testing loss: 0.06727585196495056
epoch 70700  training loss: 0.06735704094171524

 71%|█████████████████████████████████████████████████████████                       | 71286/100000 [03:41<01:29, 321.67it/s]
epoch 70800  training loss: 0.06734941899776459
epoch 70800  clean testing loss: 0.06730581820011139
epoch 70900  training loss: 0.06734141707420349
epoch 70900  clean testing loss: 0.06732119619846344
epoch 71000  training loss: 0.0673334077000618
epoch 71000  clean testing loss: 0.06733947992324829
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 71100  training loss: 0.06732548773288727
epoch 71100  clean testing loss: 0.06735855340957642
epoch 71200  training loss: 0.06731727719306946
epoch 71200  clean testing loss: 0.06737745553255081
epoch 71300  training loss: 0.06736335158348083

 72%|█████████████████████████████████████████████████████████▌                      | 71946/100000 [03:43<01:27, 321.32it/s]
epoch 71400  training loss: 0.06730416417121887
epoch 71400  clean testing loss: 0.0673992708325386
epoch 71500  training loss: 0.06729831546545029
epoch 71500  clean testing loss: 0.06740551441907883
epoch 71600  training loss: 0.06729336827993393
epoch 71600  clean testing loss: 0.06741290539503098
epoch 71700  training loss: 0.06728772073984146
epoch 71700  clean testing loss: 0.06742127239704132
epoch 71800  training loss: 0.0672817975282669
epoch 71800  clean testing loss: 0.06742999702692032
epoch 71900  training loss: 0.06727566570043564
epoch 71900  clean testing loss: 0.06743784993886948
epoch 72000  training loss: 0.06726932525634766
epoch 72000  clean testing loss: 0.06744841486215591

 73%|██████████████████████████████████████████████████████████                      | 72573/100000 [03:45<01:25, 322.54it/s]
epoch 72100  training loss: 0.06726443767547607
epoch 72100  clean testing loss: 0.06745816767215729
epoch 72200  training loss: 0.06725846976041794
epoch 72200  clean testing loss: 0.06746728718280792
epoch 72300  training loss: 0.06725285947322845
epoch 72300  clean testing loss: 0.06747760623693466
epoch 72400  training loss: 0.0672471895813942
epoch 72400  clean testing loss: 0.0674881786108017
epoch 72500  training loss: 0.0672411322593689
epoch 72500  clean testing loss: 0.06750097870826721
epoch 72600  training loss: 0.0672348365187645

 73%|██████████████████████████████████████████████████████████▌                     | 73234/100000 [03:47<01:22, 322.94it/s]
epoch 72700  training loss: 0.0672277957201004
epoch 72700  clean testing loss: 0.06752736866474152
epoch 72800  training loss: 0.06722090393304825
epoch 72800  clean testing loss: 0.06754396110773087
epoch 72900  training loss: 0.0672147199511528
epoch 72900  clean testing loss: 0.06755927205085754
epoch 73000  training loss: 0.06720662862062454
epoch 73000  clean testing loss: 0.06757624447345734
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 73100  training loss: 0.06719996780157089
epoch 73100  clean testing loss: 0.06759528070688248
epoch 73200  training loss: 0.06719250977039337
epoch 73200  clean testing loss: 0.0676136389374733
epoch 73300  training loss: 0.06744872033596039

 74%|███████████████████████████████████████████████████████████                     | 73894/100000 [03:49<01:21, 320.37it/s]
epoch 73400  training loss: 0.06717898696660995
epoch 73400  clean testing loss: 0.06763814389705658
epoch 73500  training loss: 0.06717515736818314
epoch 73500  clean testing loss: 0.0676451176404953
epoch 73600  training loss: 0.06717047840356827
epoch 73600  clean testing loss: 0.06765144318342209
epoch 73700  training loss: 0.0671655535697937
epoch 73700  clean testing loss: 0.0676574781537056
epoch 73800  training loss: 0.06716035306453705
epoch 73800  clean testing loss: 0.0676659345626831
epoch 73900  training loss: 0.06715478748083115

 75%|███████████████████████████████████████████████████████████▌                    | 74521/100000 [03:51<01:18, 322.55it/s]
epoch 74000  training loss: 0.0671498030424118
epoch 74000  clean testing loss: 0.06768206506967545
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 74100  training loss: 0.06714385002851486
epoch 74100  clean testing loss: 0.06769294291734695
epoch 74200  training loss: 0.06713800132274628
epoch 74200  clean testing loss: 0.0677032619714737
epoch 74300  training loss: 0.06713218986988068
epoch 74300  clean testing loss: 0.06771539151668549
epoch 74400  training loss: 0.06712594628334045
epoch 74400  clean testing loss: 0.0677279457449913
epoch 74500  training loss: 0.06711950153112411
epoch 74500  clean testing loss: 0.06774187088012695
epoch 74600  training loss: 0.06711269170045853

 75%|████████████████████████████████████████████████████████████▏                   | 75181/100000 [03:53<01:17, 321.82it/s]
epoch 74700  training loss: 0.06710632890462875
epoch 74700  clean testing loss: 0.06777133047580719
epoch 74800  training loss: 0.06709849089384079
epoch 74800  clean testing loss: 0.0677875280380249
epoch 74900  training loss: 0.06709142029285431
epoch 74900  clean testing loss: 0.0678040012717247
epoch 75000  training loss: 0.0670824944972992
epoch 75000  clean testing loss: 0.06782177090644836
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 75100  training loss: 0.06707664579153061
epoch 75100  clean testing loss: 0.06783752143383026
epoch 75200  training loss: 0.0670696422457695

 76%|████████████████████████████████████████████████████████████▋                   | 75808/100000 [03:55<01:15, 321.95it/s]
epoch 75300  training loss: 0.06706290692090988
epoch 75300  clean testing loss: 0.06787213683128357
epoch 75400  training loss: 0.06705620139837265
epoch 75400  clean testing loss: 0.06788931041955948
epoch 75500  training loss: 0.06704811751842499
epoch 75500  clean testing loss: 0.06790436059236526
epoch 75600  training loss: 0.06704424321651459
epoch 75600  clean testing loss: 0.06792537122964859
epoch 75700  training loss: 0.06704014539718628
epoch 75700  clean testing loss: 0.06792902946472168
epoch 75800  training loss: 0.06703533232212067

 76%|█████████████████████████████████████████████████████████████▏                  | 76467/100000 [03:57<01:13, 320.74it/s]
epoch 75900  training loss: 0.06703038513660431
epoch 75900  clean testing loss: 0.06793984025716782
epoch 76000  training loss: 0.06702663004398346
epoch 76000  clean testing loss: 0.0679447203874588
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 76100  training loss: 0.06702185422182083
epoch 76100  clean testing loss: 0.06794679164886475
epoch 76200  training loss: 0.06701697409152985
epoch 76200  clean testing loss: 0.06795483082532883
epoch 76300  training loss: 0.06701230257749557
epoch 76300  clean testing loss: 0.0679616928100586
epoch 76400  training loss: 0.0670071616768837
epoch 76400  clean testing loss: 0.0679708942770958
epoch 76500  training loss: 0.06700173020362854

 77%|█████████████████████████████████████████████████████████████▌                  | 76896/100000 [03:59<01:11, 323.10it/s]
epoch 76600  training loss: 0.06699639558792114
epoch 76600  clean testing loss: 0.06799279153347015
epoch 76700  training loss: 0.066989965736866
epoch 76700  clean testing loss: 0.06800480931997299
epoch 76800  training loss: 0.06698442250490189
epoch 76800  clean testing loss: 0.0680166631937027
epoch 76900  training loss: 0.06697863340377808
epoch 76900  clean testing loss: 0.06802861392498016
epoch 77000  training loss: 0.06697114557027817

 77%|█████████████████████████████████████████████████████████████▊                  | 77193/100000 [04:00<01:10, 321.92it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 77100  training loss: 0.06696488708257675
epoch 77100  clean testing loss: 0.06805983930826187
epoch 77200  training loss: 0.06695783883333206
epoch 77200  clean testing loss: 0.06807521730661392
epoch 77300  training loss: 0.06695074588060379

 78%|██████████████████████████████████████████████████████████████                  | 77589/100000 [04:01<01:09, 322.06it/s]
epoch 77400  training loss: 0.06694614887237549
epoch 77400  clean testing loss: 0.06810060143470764
epoch 77500  training loss: 0.06694180518388748
epoch 77500  clean testing loss: 0.06810768693685532
epoch 77600  training loss: 0.06693767011165619
epoch 77600  clean testing loss: 0.06811199337244034
epoch 77700  training loss: 0.06693330407142639

 78%|██████████████████████████████████████████████████████████████▍                 | 78084/100000 [04:02<01:08, 321.28it/s]
epoch 77800  training loss: 0.06692943722009659
epoch 77800  clean testing loss: 0.0681225135922432
epoch 77900  training loss: 0.06692451983690262
epoch 77900  clean testing loss: 0.06812745332717896
epoch 78000  training loss: 0.06691937893629074
epoch 78000  clean testing loss: 0.06813331693410873
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 78100  training loss: 0.06691548973321915
epoch 78100  clean testing loss: 0.06814026832580566
epoch 78200  training loss: 0.06691185384988785

 78%|██████████████████████████████████████████████████████████████▊                 | 78480/100000 [04:04<01:07, 320.72it/s]
epoch 78300  training loss: 0.06690818816423416
epoch 78300  clean testing loss: 0.06815090775489807
epoch 78400  training loss: 0.06690400838851929
epoch 78400  clean testing loss: 0.06815996766090393
epoch 78500  training loss: 0.06689926981925964
epoch 78500  clean testing loss: 0.06816806644201279
epoch 78600  training loss: 0.06689473241567612

 79%|███████████████████████████████████████████████████████████████                 | 78776/100000 [04:05<01:06, 320.14it/s]
epoch 78700  training loss: 0.06689007580280304
epoch 78700  clean testing loss: 0.06818899512290955
epoch 78800  training loss: 0.06688448786735535
epoch 78800  clean testing loss: 0.06820098310709
epoch 78900  training loss: 0.06687947362661362

 79%|███████████████████████████████████████████████████████████████▏                | 78974/100000 [04:05<01:05, 322.83it/s]
epoch 79000  training loss: 0.06687445938587189
epoch 79000  clean testing loss: 0.06822682172060013
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 79100  training loss: 0.06686816364526749

 80%|███████████████████████████████████████████████████████████████▋                | 79600/100000 [04:07<01:03, 320.60it/s]
epoch 79200  training loss: 0.06686233729124069
epoch 79200  clean testing loss: 0.06826058775186539
epoch 79300  training loss: 0.0668567568063736
epoch 79300  clean testing loss: 0.06827786564826965
epoch 79400  training loss: 0.06684954464435577
epoch 79400  clean testing loss: 0.06829644739627838
epoch 79500  training loss: 0.06684276461601257
epoch 79500  clean testing loss: 0.06831709295511246
epoch 79600  training loss: 0.06683555990457535
epoch 79600  clean testing loss: 0.068337082862854
epoch 79700  training loss: 0.06683184206485748
epoch 79700  clean testing loss: 0.06835968047380447
epoch 79800  training loss: 0.06682734191417694

 80%|████████████████████████████████████████████████████████████████▏               | 80194/100000 [04:09<01:01, 321.74it/s]
epoch 79900  training loss: 0.06682315468788147
epoch 79900  clean testing loss: 0.06837138533592224
epoch 80000  training loss: 0.0668184757232666
epoch 80000  clean testing loss: 0.06838026642799377
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 80100  training loss: 0.0668138936161995
epoch 80100  clean testing loss: 0.06838835775852203
epoch 80200  training loss: 0.06680971384048462
epoch 80200  clean testing loss: 0.06839731335639954
epoch 80300  training loss: 0.0668046623468399

 81%|████████████████████████████████████████████████████████████████▌               | 80689/100000 [04:11<01:00, 320.82it/s]
epoch 80400  training loss: 0.06680002063512802
epoch 80400  clean testing loss: 0.0684167668223381
epoch 80500  training loss: 0.06679443269968033
epoch 80500  clean testing loss: 0.06842772662639618
epoch 80600  training loss: 0.06679017841815948
epoch 80600  clean testing loss: 0.06843873858451843
epoch 80700  training loss: 0.06678460538387299

 81%|████████████████████████████████████████████████████████████████▋               | 80886/100000 [04:11<00:59, 321.03it/s]
epoch 80800  training loss: 0.06677855551242828
epoch 80800  clean testing loss: 0.06846248358488083
epoch 80900  training loss: 0.0667729452252388

 81%|████████████████████████████████████████████████████████████████▉               | 81183/100000 [04:12<00:58, 321.34it/s]
epoch 81000  training loss: 0.06676694005727768
epoch 81000  clean testing loss: 0.0684909075498581
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 81100  training loss: 0.06676138192415237
epoch 81100  clean testing loss: 0.06850294023752213
epoch 81200  training loss: 0.06675674021244049

 82%|█████████████████████████████████████████████████████████████████▎              | 81678/100000 [04:14<00:56, 323.32it/s]
epoch 81300  training loss: 0.06675147265195847
epoch 81300  clean testing loss: 0.06852813810110092
epoch 81400  training loss: 0.06674621999263763
epoch 81400  clean testing loss: 0.06853961199522018
epoch 81500  training loss: 0.06674009561538696
epoch 81500  clean testing loss: 0.06855326890945435
epoch 81600  training loss: 0.06673503667116165
epoch 81600  clean testing loss: 0.06856660544872284
epoch 81700  training loss: 0.06672962009906769

 82%|█████████████████████████████████████████████████████████████████▋              | 82075/100000 [04:15<00:55, 320.09it/s]
epoch 81800  training loss: 0.06672322750091553
epoch 81800  clean testing loss: 0.06859757006168365
epoch 81900  training loss: 0.06671679019927979
epoch 81900  clean testing loss: 0.06861553341150284
epoch 82000  training loss: 0.06671319156885147
epoch 82000  clean testing loss: 0.06861506402492523
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 82100  training loss: 0.06670936197042465

 83%|██████████████████████████████████████████████████████████████████              | 82570/100000 [04:16<00:54, 322.14it/s]
epoch 82200  training loss: 0.06670515984296799
epoch 82200  clean testing loss: 0.06863594055175781
epoch 82300  training loss: 0.06670146435499191
epoch 82300  clean testing loss: 0.06864354014396667
epoch 82400  training loss: 0.0666983351111412
epoch 82400  clean testing loss: 0.06865210086107254
epoch 82500  training loss: 0.06669432669878006
epoch 82500  clean testing loss: 0.06866191327571869
epoch 82600  training loss: 0.06669057160615921
epoch 82600  clean testing loss: 0.0686725378036499
epoch 82700  training loss: 0.06668559461832047

 83%|██████████████████████████████████████████████████████████████████▍             | 82999/100000 [04:18<00:52, 321.84it/s]
epoch 82800  training loss: 0.06668294221162796
epoch 82800  clean testing loss: 0.06869027018547058
epoch 82900  training loss: 0.06667798012495041
epoch 82900  clean testing loss: 0.06870125234127045
epoch 83000  training loss: 0.06667422503232956

 83%|██████████████████████████████████████████████████████████████████▋             | 83395/100000 [04:19<00:51, 322.75it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 83100  training loss: 0.06666939705610275
epoch 83100  clean testing loss: 0.068720243871212
epoch 83200  training loss: 0.06666487455368042
epoch 83200  clean testing loss: 0.06873156875371933
epoch 83300  training loss: 0.06666016578674316
epoch 83300  clean testing loss: 0.06874382495880127
epoch 83400  training loss: 0.06665563583374023
epoch 83400  clean testing loss: 0.06875728815793991
epoch 83500  training loss: 0.06665044277906418

 84%|███████████████████████████████████████████████████████████████████             | 83890/100000 [04:20<00:50, 322.00it/s]
epoch 83600  training loss: 0.06664542108774185
epoch 83600  clean testing loss: 0.06878502666950226
epoch 83700  training loss: 0.0666399896144867
epoch 83700  clean testing loss: 0.06880100071430206
epoch 83800  training loss: 0.06663442403078079
epoch 83800  clean testing loss: 0.06881669163703918
epoch 83900  training loss: 0.06663978099822998

 84%|███████████████████████████████████████████████████████████████████▍            | 84285/100000 [04:22<00:48, 322.44it/s]
epoch 84000  training loss: 0.06662636250257492
epoch 84000  clean testing loss: 0.068837009370327
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 84100  training loss: 0.06662294268608093
epoch 84100  clean testing loss: 0.06884099543094635
epoch 84200  training loss: 0.06662055104970932
epoch 84200  clean testing loss: 0.06884553283452988
epoch 84300  training loss: 0.06661761552095413

 85%|███████████████████████████████████████████████████████████████████▋            | 84681/100000 [04:23<00:47, 323.45it/s]
epoch 84400  training loss: 0.06661569327116013
epoch 84400  clean testing loss: 0.06885488331317902
epoch 84500  training loss: 0.06661215424537659
epoch 84500  clean testing loss: 0.06885947287082672
epoch 84600  training loss: 0.06660915166139603
epoch 84600  clean testing loss: 0.06886535882949829
epoch 84700  training loss: 0.06660587340593338

 85%|███████████████████████████████████████████████████████████████████▉            | 84978/100000 [04:24<00:46, 323.30it/s]
epoch 84800  training loss: 0.0666026845574379
epoch 84800  clean testing loss: 0.06887863576412201
epoch 84900  training loss: 0.06659876555204391
epoch 84900  clean testing loss: 0.06888698041439056
epoch 85000  training loss: 0.06659527868032455

 90%|████████████████████████████████████████████████████████████████████████▏       | 90287/100000 [04:40<00:30, 322.37it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 85100  training loss: 0.06659200042486191
epoch 85100  clean testing loss: 0.06890420615673065
epoch 85200  training loss: 0.06658845394849777
epoch 85200  clean testing loss: 0.06891322135925293
epoch 85300  training loss: 0.06658392399549484
epoch 85300  clean testing loss: 0.0689227506518364
epoch 85400  training loss: 0.06657969951629639
epoch 85400  clean testing loss: 0.06893351674079895
epoch 85500  training loss: 0.06657587736845016
epoch 85500  clean testing loss: 0.06894334405660629
epoch 85600  training loss: 0.06657195836305618
epoch 85600  clean testing loss: 0.06895668059587479
epoch 85700  training loss: 0.06656715273857117
epoch 85700  clean testing loss: 0.0689687505364418
epoch 85800  training loss: 0.0665627270936966
epoch 85800  clean testing loss: 0.06898418813943863
epoch 85900  training loss: 0.06655819714069366
epoch 85900  clean testing loss: 0.06899616122245789
epoch 86000  training loss: 0.06655333191156387
epoch 86000  clean testing loss: 0.06901155412197113
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 86100  training loss: 0.06654804199934006
epoch 86100  clean testing loss: 0.06902796775102615
epoch 86200  training loss: 0.06654427945613861
epoch 86200  clean testing loss: 0.06903556734323502
epoch 86300  training loss: 0.0665414035320282
epoch 86300  clean testing loss: 0.0690389946103096
epoch 86400  training loss: 0.06653840839862823
epoch 86400  clean testing loss: 0.06904289871454239
epoch 86500  training loss: 0.06653613597154617
epoch 86500  clean testing loss: 0.06904710084199905
epoch 86600  training loss: 0.06653255224227905
epoch 86600  clean testing loss: 0.06905141472816467
epoch 86700  training loss: 0.06652974337339401
epoch 86700  clean testing loss: 0.06905671954154968
epoch 86800  training loss: 0.06652653962373734
epoch 86800  clean testing loss: 0.06906192004680634
epoch 86900  training loss: 0.06652295589447021
epoch 86900  clean testing loss: 0.06906969845294952
epoch 87000  training loss: 0.06651979684829712
epoch 87000  clean testing loss: 0.06907715648412704
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 87100  training loss: 0.06651610136032104
epoch 87100  clean testing loss: 0.06908142566680908
epoch 87200  training loss: 0.06651347875595093
epoch 87200  clean testing loss: 0.0690883919596672
epoch 87300  training loss: 0.06651046872138977
epoch 87300  clean testing loss: 0.0690949484705925
epoch 87400  training loss: 0.06650713831186295
epoch 87400  clean testing loss: 0.06910225003957748
epoch 87500  training loss: 0.06650342792272568
epoch 87500  clean testing loss: 0.06911079585552216
epoch 87600  training loss: 0.06650031358003616
epoch 87600  clean testing loss: 0.06912103295326233
epoch 87700  training loss: 0.06649652123451233
epoch 87700  clean testing loss: 0.06912919133901596
epoch 87800  training loss: 0.06649346649646759
epoch 87800  clean testing loss: 0.06914033740758896
epoch 87900  training loss: 0.06648974120616913
epoch 87900  clean testing loss: 0.06915047019720078
epoch 88000  training loss: 0.06648548692464828
epoch 88000  clean testing loss: 0.06916304677724838
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 88100  training loss: 0.06648122519254684
epoch 88100  clean testing loss: 0.0691748782992363
epoch 88200  training loss: 0.06647735834121704
epoch 88200  clean testing loss: 0.06918904185295105
epoch 88300  training loss: 0.06647249311208725
epoch 88300  clean testing loss: 0.06920243799686432
epoch 88400  training loss: 0.0664689764380455
epoch 88400  clean testing loss: 0.06921597570180893
epoch 88500  training loss: 0.06647288799285889
epoch 88500  clean testing loss: 0.06918295472860336
epoch 88600  training loss: 0.06646154075860977
epoch 88600  clean testing loss: 0.06923464685678482
epoch 88700  training loss: 0.06645999103784561
epoch 88700  clean testing loss: 0.06923823058605194
epoch 88800  training loss: 0.06645683199167252
epoch 88800  clean testing loss: 0.06924126297235489
epoch 88900  training loss: 0.06645479053258896
epoch 88900  clean testing loss: 0.06924571841955185
epoch 89000  training loss: 0.0664520338177681
epoch 89000  clean testing loss: 0.06924945116043091
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 89100  training loss: 0.06644927710294724
epoch 89100  clean testing loss: 0.0692538246512413
epoch 89200  training loss: 0.06644638627767563
epoch 89200  clean testing loss: 0.06925898045301437
epoch 89300  training loss: 0.06644366681575775
epoch 89300  clean testing loss: 0.0692649558186531
epoch 89400  training loss: 0.06644145399332047
epoch 89400  clean testing loss: 0.06927122920751572
epoch 89500  training loss: 0.06643751263618469
epoch 89500  clean testing loss: 0.06927740573883057
epoch 89600  training loss: 0.06643425673246384
epoch 89600  clean testing loss: 0.06928613781929016
epoch 89700  training loss: 0.0664311870932579
epoch 89700  clean testing loss: 0.06929337978363037
epoch 89800  training loss: 0.06642734259366989
epoch 89800  clean testing loss: 0.06930264830589294
epoch 89900  training loss: 0.06642404198646545
epoch 89900  clean testing loss: 0.06931392848491669
epoch 90000  training loss: 0.06642109900712967
epoch 90000  clean testing loss: 0.06932385265827179
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 90100  training loss: 0.06641791015863419
epoch 90100  clean testing loss: 0.06933233886957169
epoch 90200  training loss: 0.06641470640897751
epoch 90200  clean testing loss: 0.06934152543544769
epoch 90300  training loss: 0.06641141325235367
epoch 90300  clean testing loss: 0.06935139000415802
epoch 90400  training loss: 0.06640774756669998
epoch 90400  clean testing loss: 0.06936313211917877
epoch 90500  training loss: 0.06640443950891495

 91%|█████████████████████████████████████████████████████████████████████████       | 91307/100000 [04:44<00:27, 320.59it/s]
epoch 90600  training loss: 0.06640065461397171
epoch 90600  clean testing loss: 0.06938556581735611
epoch 90700  training loss: 0.06639702618122101
epoch 90700  clean testing loss: 0.06939724832773209
epoch 90800  training loss: 0.06639362871646881
epoch 90800  clean testing loss: 0.06941104680299759
epoch 90900  training loss: 0.06638988852500916
epoch 90900  clean testing loss: 0.06942395865917206
epoch 91000  training loss: 0.06638558954000473
epoch 91000  clean testing loss: 0.06943774968385696
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 91100  training loss: 0.06638266146183014
epoch 91100  clean testing loss: 0.06944412738084793
epoch 91200  training loss: 0.06638087332248688
epoch 91200  clean testing loss: 0.06945022940635681
epoch 91300  training loss: 0.06637876480817795

 92%|█████████████████████████████████████████████████████████████████████████▌      | 91933/100000 [04:46<00:25, 319.95it/s]
epoch 91400  training loss: 0.06637706607580185
epoch 91400  clean testing loss: 0.06945585459470749
epoch 91500  training loss: 0.06637494266033173
epoch 91500  clean testing loss: 0.06945959478616714
epoch 91600  training loss: 0.06637198477983475
epoch 91600  clean testing loss: 0.06946326792240143
epoch 91700  training loss: 0.06636938452720642
epoch 91700  clean testing loss: 0.06946826726198196
epoch 91800  training loss: 0.06636714935302734
epoch 91800  clean testing loss: 0.06947262585163116
epoch 91900  training loss: 0.06636400520801544

 93%|██████████████████████████████████████████████████████████████████████████      | 92594/100000 [04:48<00:22, 323.02it/s]
epoch 92000  training loss: 0.06636162102222443
epoch 92000  clean testing loss: 0.06948453187942505
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 92100  training loss: 0.06635867804288864
epoch 92100  clean testing loss: 0.06949219852685928
epoch 92200  training loss: 0.06635609269142151
epoch 92200  clean testing loss: 0.06949914246797562
epoch 92300  training loss: 0.06635275483131409
epoch 92300  clean testing loss: 0.06950785964727402
epoch 92400  training loss: 0.0663498118519783
epoch 92400  clean testing loss: 0.06951770186424255
epoch 92500  training loss: 0.06634629517793655
epoch 92500  clean testing loss: 0.06952668726444244
epoch 92600  training loss: 0.0663435161113739

 93%|██████████████████████████████████████████████████████████████████████████▌     | 93221/100000 [04:50<00:21, 321.89it/s]
epoch 92700  training loss: 0.06633950024843216
epoch 92700  clean testing loss: 0.069548100233078
epoch 92800  training loss: 0.06633608043193817
epoch 92800  clean testing loss: 0.06956015527248383
epoch 92900  training loss: 0.06633241474628448
epoch 92900  clean testing loss: 0.0695715993642807
epoch 93000  training loss: 0.06632878631353378
epoch 93000  clean testing loss: 0.06958390772342682
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 93100  training loss: 0.06632580608129501
epoch 93100  clean testing loss: 0.06959468126296997
epoch 93200  training loss: 0.06632234156131744

 94%|███████████████████████████████████████████████████████████████████████████     | 93881/100000 [04:52<00:18, 322.23it/s]
epoch 93300  training loss: 0.06631912291049957
epoch 93300  clean testing loss: 0.06961682438850403
epoch 93400  training loss: 0.06631585955619812
epoch 93400  clean testing loss: 0.06962727755308151
epoch 93500  training loss: 0.0663125067949295
epoch 93500  clean testing loss: 0.06964152306318283
epoch 93600  training loss: 0.06630929559469223
epoch 93600  clean testing loss: 0.06970750540494919
epoch 93700  training loss: 0.06630631536245346
epoch 93700  clean testing loss: 0.06965654343366623
epoch 93800  training loss: 0.06630489230155945
epoch 93800  clean testing loss: 0.06966027617454529
epoch 93900  training loss: 0.06630276888608932

 94%|███████████████████████████████████████████████████████████████████████████▌    | 94440/100000 [04:54<00:20, 277.08it/s]
epoch 94000  training loss: 0.06630056351423264
epoch 94000  clean testing loss: 0.06966638565063477
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 94100  training loss: 0.066298708319664
epoch 94100  clean testing loss: 0.0696706473827362
epoch 94200  training loss: 0.06629623472690582
epoch 94200  clean testing loss: 0.06967480480670929
epoch 94300  training loss: 0.06629429757595062
epoch 94300  clean testing loss: 0.06967933475971222
epoch 94400  training loss: 0.06629175692796707

 95%|███████████████████████████████████████████████████████████████████████████▉    | 94982/100000 [04:56<00:17, 281.24it/s]
epoch 94500  training loss: 0.06628947705030441
epoch 94500  clean testing loss: 0.06969071924686432
epoch 94600  training loss: 0.06628678739070892
epoch 94600  clean testing loss: 0.06969740986824036
epoch 94700  training loss: 0.06628470122814178
epoch 94700  clean testing loss: 0.06970438361167908
epoch 94800  training loss: 0.06628149002790451
epoch 94800  clean testing loss: 0.06971244513988495
epoch 94900  training loss: 0.06627820432186127
epoch 94900  clean testing loss: 0.069720059633255
epoch 95000  training loss: 0.06627600640058517
epoch 95000  clean testing loss: 0.06972891092300415

 96%|████████████████████████████████████████████████████████████████████████████▍   | 95554/100000 [04:58<00:15, 278.59it/s]
epoch 95100  training loss: 0.06627330929040909
epoch 95100  clean testing loss: 0.06973845511674881
epoch 95200  training loss: 0.06627029180526733
epoch 95200  clean testing loss: 0.06974798440933228
epoch 95300  training loss: 0.06626689434051514
epoch 95300  clean testing loss: 0.06975853443145752
epoch 95400  training loss: 0.06626284867525101
epoch 95400  clean testing loss: 0.06976989656686783
epoch 95500  training loss: 0.06626063585281372

 96%|████████████████████████████████████████████████████████████████████████████▊   | 96091/100000 [05:00<00:14, 273.04it/s]
epoch 95600  training loss: 0.0662565678358078
epoch 95600  clean testing loss: 0.06979408860206604
epoch 95700  training loss: 0.06626271456480026
epoch 95700  clean testing loss: 0.06975643336772919
epoch 95800  training loss: 0.06625095009803772
epoch 95800  clean testing loss: 0.06980863213539124
epoch 95900  training loss: 0.06624927371740341
epoch 95900  clean testing loss: 0.06981179118156433
epoch 96000  training loss: 0.06624702364206314
epoch 96000  clean testing loss: 0.0698152706027031
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 96100  training loss: 0.06624594330787659

 97%|█████████████████████████████████████████████████████████████████████████████▎  | 96658/100000 [05:02<00:12, 273.19it/s]
epoch 96200  training loss: 0.06624475121498108
epoch 96200  clean testing loss: 0.06981965154409409
epoch 96300  training loss: 0.06624266505241394
epoch 96300  clean testing loss: 0.06982257217168808
epoch 96400  training loss: 0.06624074280261993
epoch 96400  clean testing loss: 0.06982586532831192
epoch 96500  training loss: 0.06623916327953339
epoch 96500  clean testing loss: 0.06982826441526413
epoch 96600  training loss: 0.06623756140470505

 97%|█████████████████████████████████████████████████████████████████████████████▊  | 97198/100000 [05:04<00:10, 278.24it/s]
epoch 96700  training loss: 0.0662359669804573
epoch 96700  clean testing loss: 0.06983744353055954
epoch 96800  training loss: 0.06623358279466629
epoch 96800  clean testing loss: 0.06984248757362366
epoch 96900  training loss: 0.06623110920190811
epoch 96900  clean testing loss: 0.06984642148017883
epoch 97000  training loss: 0.06622958928346634
epoch 97000  clean testing loss: 0.06985155493021011
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 97100  training loss: 0.06622691452503204
epoch 97100  clean testing loss: 0.06985778361558914
epoch 97200  training loss: 0.06622479110956192

 98%|██████████████████████████████████████████████████████████████████████████████  | 97594/100000 [05:05<00:08, 274.64it/s]
epoch 97300  training loss: 0.06622183322906494
epoch 97300  clean testing loss: 0.06987149268388748
epoch 97400  training loss: 0.06621883064508438
epoch 97400  clean testing loss: 0.06987929344177246
epoch 97500  training loss: 0.06621699035167694
epoch 97500  clean testing loss: 0.06988714635372162
epoch 97600  training loss: 0.06621458381414413

 98%|██████████████████████████████████████████████████████████████████████████████▎ | 97878/100000 [05:06<00:07, 276.54it/s]
epoch 97700  training loss: 0.0662117674946785
epoch 97700  clean testing loss: 0.0699067935347557
epoch 97800  training loss: 0.06620915979146957
epoch 97800  clean testing loss: 0.06991571187973022
epoch 97900  training loss: 0.06620626896619797

 98%|██████████████████████████████████████████████████████████████████████████████▍ | 97990/100000 [05:06<00:07, 275.30it/s]
epoch 98000  training loss: 0.06620335578918457

 98%|██████████████████████████████████████████████████████████████████████████████▍ | 98074/100000 [05:07<00:07, 270.12it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 98100  training loss: 0.06620071828365326
epoch 98100  clean testing loss: 0.06994681060314178
epoch 98200  training loss: 0.06619711965322495

 98%|██████████████████████████████████████████████████████████████████████████████▌ | 98273/100000 [05:08<00:06, 273.45it/s]
epoch 98300  training loss: 0.06619464606046677
epoch 98300  clean testing loss: 0.06997080147266388
epoch 98400  training loss: 0.06619332730770111

 99%|██████████████████████████████████████████████████████████████████████████████▉ | 98699/100000 [05:09<00:04, 274.70it/s]
epoch 98500  training loss: 0.0661916509270668
epoch 98500  clean testing loss: 0.06997231394052505
epoch 98600  training loss: 0.06618990749120712
epoch 98600  clean testing loss: 0.06997423619031906
epoch 98700  training loss: 0.06618864834308624

100%|███████████████████████████████████████████████████████████████████████████████▊| 99690/100000 [05:13<00:01, 277.07it/s]
epoch 98800  training loss: 0.06618611514568329
epoch 98800  clean testing loss: 0.06998152285814285
epoch 98900  training loss: 0.06618469208478928
epoch 98900  clean testing loss: 0.06998410820960999
epoch 99000  training loss: 0.0661827027797699
epoch 99000  clean testing loss: 0.06998807191848755
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...
epoch 99100  training loss: 0.06618080288171768
epoch 99100  clean testing loss: 0.06999184191226959
epoch 99200  training loss: 0.0661793127655983
epoch 99200  clean testing loss: 0.06999514997005463
epoch 99300  training loss: 0.06617864966392517
epoch 99300  clean testing loss: 0.069999098777771
epoch 99400  training loss: 0.06617625057697296
epoch 99400  clean testing loss: 0.07000337541103363
epoch 99500  training loss: 0.06617438793182373
epoch 99500  clean testing loss: 0.07000792771577835
epoch 99600  training loss: 0.06617269665002823
epoch 99600  clean testing loss: 0.07001381367444992
epoch 99700  training loss: 0.06617094576358795

100%|███████████████████████████████████████████████████████████████████████████████▊| 99774/100000 [05:13<00:00, 276.21it/s]
epoch 99800  training loss: 0.06616856902837753

100%|███████████████████████████████████████████████████████████████████████████████| 100000/100000 [05:14<00:00, 317.93it/s]
epoch 99900  training loss: 0.06616662442684174
epoch 99900  clean testing loss: 0.07003037631511688
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu2_size500_noise1.00e-01_invop0 ...