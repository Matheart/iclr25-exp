
  0%|                                                                                | 79/100000 [00:01<28:25, 58.59it/s]
epoch 0  training loss: 42.660789489746094
epoch 0  clean testing loss: 40.770721435546875
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop1 ...
epoch 100  training loss: 0.12573763728141785

  0%|▏                                                                              | 197/100000 [00:03<27:51, 59.70it/s]
epoch 200  training loss: 0.10231992602348328

  0%|▏                                                                              | 315/100000 [00:05<27:53, 59.55it/s]
epoch 300  training loss: 0.09768400341272354

  0%|▎                                                                              | 434/100000 [00:07<27:49, 59.62it/s]
epoch 400  training loss: 0.0949665755033493

  1%|▍                                                                              | 554/100000 [00:09<28:06, 58.98it/s]
epoch 500  training loss: 0.09305360168218613

  1%|▌                                                                              | 663/100000 [00:11<33:36, 49.26it/s]
epoch 600  training loss: 0.09165039658546448

  1%|▌                                                                              | 761/100000 [00:13<33:47, 48.96it/s]
epoch 700  training loss: 0.09059964120388031

  1%|▋                                                                              | 861/100000 [00:15<33:19, 49.59it/s]
epoch 800  training loss: 0.08979608863592148

  1%|▊                                                                              | 959/100000 [00:17<33:13, 49.68it/s]
epoch 900  training loss: 0.08916860073804855

  1%|▊                                                                             | 1059/100000 [00:19<33:26, 49.31it/s]
epoch 1000  training loss: 0.08866945654153824
epoch 1000  clean testing loss: 0.010124065913259983

  1%|▉                                                                             | 1155/100000 [00:21<33:15, 49.54it/s]
epoch 1100  training loss: 0.0882657989859581

  1%|▉                                                                             | 1254/100000 [00:23<32:49, 50.15it/s]
epoch 1200  training loss: 0.08793365210294724

  1%|█                                                                             | 1355/100000 [00:25<33:08, 49.61it/s]
epoch 1300  training loss: 0.08765270560979843

  1%|█▏                                                                            | 1456/100000 [00:27<33:10, 49.51it/s]
epoch 1400  training loss: 0.08740616589784622

  2%|█▏                                                                            | 1552/100000 [00:29<34:28, 47.59it/s]
epoch 1500  training loss: 0.08718142658472061

  2%|█▎                                                                            | 1653/100000 [00:31<34:00, 48.20it/s]
epoch 1600  training loss: 0.08697085827589035


  2%|█▌                                                                            | 1928/100000 [00:37<32:54, 49.66it/s]
epoch 1700  training loss: 0.0867701843380928
epoch 1700  clean testing loss: 0.012327548116445541
epoch 1800  training loss: 0.08657756447792053
epoch 1800  clean testing loss: 0.012499663047492504
epoch 1900  training loss: 0.08639249205589294

  2%|█▌                                                                            | 2025/100000 [00:39<33:24, 48.89it/s]
epoch 2000  training loss: 0.08621542155742645
epoch 2000  clean testing loss: 0.012788550928235054

  2%|█▋                                                                            | 2126/100000 [00:41<32:52, 49.62it/s]
epoch 2100  training loss: 0.08604660630226135

  2%|█▋                                                                            | 2227/100000 [00:43<32:53, 49.53it/s]
epoch 2200  training loss: 0.08588515222072601

  2%|█▊                                                                            | 2323/100000 [00:45<32:51, 49.55it/s]
epoch 2300  training loss: 0.08573119342327118

  2%|█▉                                                                            | 2426/100000 [00:47<32:48, 49.57it/s]
epoch 2400  training loss: 0.08558400720357895

  3%|█▉                                                                            | 2526/100000 [00:49<32:43, 49.63it/s]
epoch 2500  training loss: 0.08544238656759262

  3%|██                                                                            | 2623/100000 [00:51<32:40, 49.66it/s]
epoch 2600  training loss: 0.08530591428279877

  3%|██                                                                            | 2723/100000 [00:53<32:45, 49.49it/s]
epoch 2700  training loss: 0.0851733535528183

  3%|██▏                                                                           | 2820/100000 [00:55<32:21, 50.04it/s]
epoch 2800  training loss: 0.08504378795623779

  3%|██▎                                                                           | 2921/100000 [00:57<32:37, 49.59it/s]
epoch 2900  training loss: 0.08491624891757965

  3%|██▎                                                                           | 3023/100000 [00:59<33:02, 48.91it/s]
epoch 3000  training loss: 0.08478965610265732
epoch 3000  clean testing loss: 0.01386888325214386

  3%|██▍                                                                           | 3118/100000 [01:01<33:19, 48.45it/s]
epoch 3100  training loss: 0.08468736708164215

  3%|██▌                                                                           | 3218/100000 [01:03<33:29, 48.16it/s]
epoch 3200  training loss: 0.08458328247070312

  3%|██▌                                                                           | 3320/100000 [01:05<32:31, 49.55it/s]
epoch 3300  training loss: 0.08447585999965668

  3%|██▋                                                                           | 3415/100000 [01:07<32:38, 49.32it/s]
epoch 3400  training loss: 0.0843646302819252

  4%|██▋                                                                           | 3516/100000 [01:09<32:28, 49.52it/s]
epoch 3500  training loss: 0.08424800634384155

  4%|██▊                                                                           | 3612/100000 [01:11<32:19, 49.71it/s]
epoch 3600  training loss: 0.08412478864192963
epoch 3600  clean testing loss: 0.014429678209125996
epoch 3700  training loss: 0.08399232476949692

  4%|██▉                                                                           | 3712/100000 [01:13<32:43, 49.03it/s]
epoch 3800  training loss: 0.08384842425584793

  4%|██▉                                                                           | 3812/100000 [01:15<32:19, 49.60it/s]
epoch 3900  training loss: 0.08368959277868271

  4%|███                                                                           | 3912/100000 [01:17<32:19, 49.54it/s]
epoch 4000  training loss: 0.08351178467273712
epoch 4000  clean testing loss: 0.01503064390271902

  4%|███▏                                                                          | 4012/100000 [01:19<33:12, 48.19it/s]
epoch 4100  training loss: 0.0833095908164978

  4%|███▏                                                                          | 4108/100000 [01:21<32:14, 49.57it/s]
epoch 4200  training loss: 0.08307887613773346

  4%|███▎                                                                          | 4208/100000 [01:23<32:20, 49.37it/s]
epoch 4300  training loss: 0.08281759917736053

  4%|███▎                                                                          | 4309/100000 [01:25<32:17, 49.39it/s]
epoch 4400  training loss: 0.08253784477710724

  4%|███▍                                                                          | 4409/100000 [01:27<32:08, 49.58it/s]
epoch 4500  training loss: 0.08223976939916611

  5%|███▌                                                                          | 4505/100000 [01:29<32:06, 49.57it/s]
epoch 4600  training loss: 0.08200517296791077

  5%|███▌                                                                          | 4606/100000 [01:31<31:51, 49.91it/s]
epoch 4700  training loss: 0.08157232403755188

  5%|███▋                                                                          | 4706/100000 [01:33<32:11, 49.33it/s]
epoch 4800  training loss: 0.08114548027515411

  5%|███▋                                                                          | 4807/100000 [01:35<31:59, 49.58it/s]
epoch 4900  training loss: 0.08062253892421722

  5%|███▊                                                                          | 4902/100000 [01:37<32:08, 49.31it/s]
epoch 5000  training loss: 0.0800212100148201
epoch 5000  clean testing loss: 0.02030066028237343


  5%|███▉                                                                          | 5103/100000 [01:41<32:05, 49.28it/s]
epoch 5100  training loss: 0.07943260669708252

  5%|████                                                                          | 5203/100000 [01:43<31:57, 49.44it/s]
epoch 5200  training loss: 0.07881511002779007

  5%|████▏                                                                         | 5303/100000 [01:45<31:49, 49.59it/s]
epoch 5300  training loss: 0.07917143404483795

  5%|████▏                                                                         | 5398/100000 [01:47<31:45, 49.64it/s]
epoch 5400  training loss: 0.07756607979536057

  6%|████▎                                                                         | 5500/100000 [01:49<31:47, 49.55it/s]
epoch 5500  training loss: 0.07693536579608917

  6%|████▎                                                                         | 5601/100000 [01:51<31:49, 49.43it/s]
epoch 5600  training loss: 0.07629480957984924

  6%|████▍                                                                         | 5697/100000 [01:53<31:48, 49.40it/s]
epoch 5700  training loss: 0.07554756850004196

  6%|████▌                                                                         | 5797/100000 [01:55<31:42, 49.51it/s]
epoch 5800  training loss: 0.07459067553281784

  6%|████▌                                                                         | 5897/100000 [01:57<31:37, 49.58it/s]
epoch 5900  training loss: 0.07341747730970383

  6%|████▋                                                                         | 5997/100000 [01:59<31:40, 49.47it/s]
epoch 6000  training loss: 0.07257472723722458
epoch 6000  clean testing loss: 0.0370524562895298

  6%|████▊                                                                         | 6097/100000 [02:01<31:35, 49.53it/s]
epoch 6100  training loss: 0.07178816199302673

  6%|████▊                                                                         | 6197/100000 [02:03<31:35, 49.50it/s]
epoch 6200  training loss: 0.07137499749660492

  6%|████▉                                                                         | 6296/100000 [02:05<31:33, 49.48it/s]
epoch 6300  training loss: 0.07100734114646912

  6%|████▉                                                                         | 6392/100000 [02:07<31:28, 49.57it/s]
epoch 6400  training loss: 0.0706586167216301

  6%|█████                                                                         | 6492/100000 [02:09<31:30, 49.45it/s]
epoch 6500  training loss: 0.07032214105129242

  7%|█████▏                                                                        | 6592/100000 [02:11<31:28, 49.45it/s]
epoch 6600  training loss: 0.0699605867266655

  7%|█████▏                                                                        | 6693/100000 [02:13<31:27, 49.42it/s]
epoch 6700  training loss: 0.06958272308111191

  7%|█████▎                                                                        | 6789/100000 [02:15<31:21, 49.54it/s]
epoch 6800  training loss: 0.06916426122188568

  7%|█████▎                                                                        | 6889/100000 [02:17<31:18, 49.57it/s]
epoch 6900  training loss: 0.06872514635324478

  7%|█████▍                                                                        | 6990/100000 [02:19<31:18, 49.50it/s]
epoch 7000  training loss: 0.06825514882802963
epoch 7000  clean testing loss: 0.043235696852207184

  7%|█████▌                                                                        | 7091/100000 [02:21<31:13, 49.58it/s]
epoch 7100  training loss: 0.06776129454374313

  7%|█████▌                                                                        | 7189/100000 [02:23<31:00, 49.89it/s]
epoch 7200  training loss: 0.06722008436918259

  7%|█████▋                                                                        | 7289/100000 [02:25<31:12, 49.50it/s]
epoch 7300  training loss: 0.06668756157159805

  7%|█████▊                                                                        | 7389/100000 [02:27<31:06, 49.61it/s]
epoch 7400  training loss: 0.0661865696310997

  7%|█████▊                                                                        | 7489/100000 [02:29<31:07, 49.53it/s]
epoch 7500  training loss: 0.06610763818025589

  8%|█████▉                                                                        | 7589/100000 [02:31<31:04, 49.56it/s]
epoch 7600  training loss: 0.0653008297085762

  8%|██████                                                                        | 7701/100000 [02:33<28:58, 53.09it/s]
epoch 7700  training loss: 0.06495034694671631

  8%|██████                                                                        | 7797/100000 [02:35<31:02, 49.51it/s]
epoch 7800  training loss: 0.06464743614196777

  8%|██████▏                                                                       | 7897/100000 [02:37<30:57, 49.59it/s]
epoch 7900  training loss: 0.06439030915498734

  8%|██████▏                                                                       | 7998/100000 [02:39<30:56, 49.56it/s]
epoch 8000  training loss: 0.06412901729345322
epoch 8000  clean testing loss: 0.050726618617773056

  8%|██████▎                                                                       | 8099/100000 [02:41<30:50, 49.66it/s]
epoch 8100  training loss: 0.0638764351606369

  8%|██████▍                                                                       | 8195/100000 [02:43<30:46, 49.72it/s]
epoch 8200  training loss: 0.06371479481458664

  8%|██████▍                                                                       | 8296/100000 [02:45<30:48, 49.62it/s]
epoch 8300  training loss: 0.06343328207731247

  8%|██████▌                                                                       | 8396/100000 [02:47<30:44, 49.66it/s]
epoch 8400  training loss: 0.06322285532951355

  8%|██████▋                                                                       | 8496/100000 [02:49<30:43, 49.64it/s]
epoch 8500  training loss: 0.06409947574138641

  9%|██████▋                                                                       | 8596/100000 [02:51<30:43, 49.58it/s]
epoch 8600  training loss: 0.06278923153877258

  9%|██████▊                                                                       | 8693/100000 [02:53<30:31, 49.86it/s]
epoch 8700  training loss: 0.06255148351192474

  9%|██████▊                                                                       | 8795/100000 [02:55<30:37, 49.63it/s]
epoch 8800  training loss: 0.062308549880981445

  9%|██████▉                                                                       | 8890/100000 [02:57<30:37, 49.57it/s]
epoch 8900  training loss: 0.062029045075178146

  9%|███████                                                                       | 8990/100000 [02:59<30:38, 49.51it/s]
epoch 9000  training loss: 0.061733417212963104
epoch 9000  clean testing loss: 0.05627593770623207

  9%|███████                                                                       | 9091/100000 [03:01<30:34, 49.57it/s]
epoch 9100  training loss: 0.06144650653004646

  9%|███████▏                                                                      | 9191/100000 [03:03<30:42, 49.29it/s]
epoch 9200  training loss: 0.06113361567258835

  9%|███████▏                                                                      | 9288/100000 [03:05<30:30, 49.57it/s]
epoch 9300  training loss: 0.060792140662670135

  9%|███████▎                                                                      | 9388/100000 [03:07<30:24, 49.67it/s]
epoch 9400  training loss: 0.06078090891242027

  9%|███████▍                                                                      | 9485/100000 [03:09<30:29, 49.48it/s]
epoch 9500  training loss: 0.060104887932538986

 10%|███████▍                                                                      | 9586/100000 [03:11<30:26, 49.50it/s]
epoch 9600  training loss: 0.059756673872470856

 10%|███████▌                                                                      | 9686/100000 [03:13<30:19, 49.65it/s]
epoch 9700  training loss: 0.059424128383398056

 10%|███████▋                                                                      | 9786/100000 [03:15<30:16, 49.65it/s]
epoch 9800  training loss: 0.05909217521548271

 10%|███████▋                                                                      | 9887/100000 [03:17<30:20, 49.49it/s]
epoch 9900  training loss: 0.058725506067276

 10%|███████▊                                                                      | 9983/100000 [03:19<30:11, 49.68it/s]
epoch 10000  training loss: 0.058367762714624405
epoch 10000  clean testing loss: 0.06487914174795151

 10%|███████▊                                                                     | 10083/100000 [03:21<30:14, 49.56it/s]
epoch 10100  training loss: 0.05800989642739296


 10%|███████▉                                                                     | 10284/100000 [03:25<30:09, 49.57it/s]
epoch 10200  training loss: 0.057673998177051544

 10%|███████▉                                                                     | 10359/100000 [03:27<30:09, 49.55it/s]
epoch 10300  training loss: 0.05716441571712494

 10%|████████                                                                     | 10454/100000 [03:29<30:06, 49.58it/s]
epoch 10400  training loss: 0.05672885477542877

 11%|████████▏                                                                    | 10554/100000 [03:31<30:07, 49.47it/s]
epoch 10500  training loss: 0.05696113035082817

 11%|████████▏                                                                    | 10655/100000 [03:33<29:57, 49.72it/s]
epoch 10600  training loss: 0.055851761251688004
epoch 10600  clean testing loss: 0.07208837568759918
epoch 10700  training loss: 0.05538569763302803

 11%|████████▎                                                                    | 10757/100000 [03:35<29:58, 49.62it/s]
epoch 10800  training loss: 0.05496831610798836

 11%|████████▎                                                                    | 10852/100000 [03:37<30:40, 48.44it/s]
epoch 10900  training loss: 0.055254749953746796

 11%|████████▍                                                                    | 10952/100000 [03:39<29:56, 49.56it/s]
epoch 11000  training loss: 0.055426500737667084
epoch 11000  clean testing loss: 0.08307746797800064

 11%|████████▌                                                                    | 11053/100000 [03:41<30:01, 49.38it/s]
epoch 11100  training loss: 0.053782541304826736

 11%|████████▌                                                                    | 11149/100000 [03:43<29:49, 49.65it/s]
epoch 11200  training loss: 0.05341673642396927


 11%|████████▋                                                                    | 11349/100000 [03:47<29:47, 49.58it/s]
epoch 11300  training loss: 0.05304770544171333

 11%|████████▊                                                                    | 11449/100000 [03:49<29:48, 49.52it/s]
epoch 11400  training loss: 0.052695270627737045

 12%|████████▉                                                                    | 11550/100000 [03:51<29:45, 49.53it/s]
epoch 11500  training loss: 0.052436746656894684
epoch 11500  clean testing loss: 0.09552992880344391
epoch 11600  training loss: 0.052272919565439224

 12%|████████▉                                                                    | 11650/100000 [03:53<29:45, 49.47it/s]
epoch 11700  training loss: 0.05151566118001938

 12%|█████████                                                                    | 11750/100000 [03:55<29:38, 49.61it/s]
epoch 11800  training loss: 0.051124103367328644

 12%|█████████                                                                    | 11846/100000 [03:57<29:38, 49.56it/s]
epoch 11900  training loss: 0.053733959794044495

 12%|█████████▏                                                                   | 11947/100000 [03:59<29:39, 49.47it/s]
epoch 12000  training loss: 0.0521518811583519
epoch 12000  clean testing loss: 0.10806167870759964

 12%|█████████▎                                                                   | 12048/100000 [04:01<29:42, 49.35it/s]
epoch 12100  training loss: 0.049903057515621185

 12%|█████████▎                                                                   | 12148/100000 [04:03<29:35, 49.49it/s]
epoch 12200  training loss: 0.04950306937098503

 12%|█████████▍                                                                   | 12248/100000 [04:05<29:12, 50.06it/s]
epoch 12300  training loss: 0.04906477406620979

 12%|█████████▌                                                                   | 12345/100000 [04:07<29:16, 49.90it/s]
epoch 12400  training loss: 0.048629358410835266

 12%|█████████▌                                                                   | 12445/100000 [04:09<29:31, 49.44it/s]
epoch 12500  training loss: 0.0481453612446785

 13%|█████████▋                                                                   | 12545/100000 [04:11<29:57, 48.64it/s]
epoch 12600  training loss: 0.04768933355808258

 13%|█████████▋                                                                   | 12641/100000 [04:13<30:05, 48.39it/s]
epoch 12700  training loss: 0.04723706841468811

 13%|█████████▊                                                                   | 12742/100000 [04:15<29:22, 49.51it/s]
epoch 12800  training loss: 0.04683634266257286

 13%|█████████▉                                                                   | 12842/100000 [04:17<29:16, 49.62it/s]
epoch 12900  training loss: 0.04643424600362778

 13%|█████████▉                                                                   | 12942/100000 [04:19<29:18, 49.52it/s]
epoch 13000  training loss: 0.04611054062843323
epoch 13000  clean testing loss: 0.12931901216506958

 13%|██████████                                                                   | 13037/100000 [04:21<29:25, 49.26it/s]
epoch 13100  training loss: 0.045486148446798325

 13%|██████████                                                                   | 13137/100000 [04:23<29:12, 49.55it/s]
epoch 13200  training loss: 0.04508330672979355

 13%|██████████▏                                                                  | 13238/100000 [04:25<29:07, 49.66it/s]
epoch 13300  training loss: 0.04469641298055649

 13%|██████████▎                                                                  | 13335/100000 [04:27<29:06, 49.62it/s]
epoch 13400  training loss: 0.04453720152378082

 13%|██████████▎                                                                  | 13435/100000 [04:29<29:14, 49.33it/s]
epoch 13500  training loss: 0.043904222548007965

 14%|██████████▍                                                                  | 13535/100000 [04:31<29:05, 49.53it/s]
epoch 13600  training loss: 0.04352492466568947

 14%|██████████▍                                                                  | 13635/100000 [04:33<29:08, 49.38it/s]
epoch 13700  training loss: 0.04312650114297867

 14%|██████████▌                                                                  | 13732/100000 [04:35<29:01, 49.54it/s]
epoch 13800  training loss: 0.04271339997649193

 14%|██████████▋                                                                  | 13832/100000 [04:37<28:59, 49.53it/s]
epoch 13900  training loss: 0.04230974614620209

 14%|██████████▋                                                                  | 13934/100000 [04:39<28:59, 49.47it/s]
epoch 14000  training loss: 0.04190417006611824

 14%|██████████▊                                                                  | 13999/100000 [04:40<28:55, 49.57it/s]

 14%|██████████▊                                                                  | 14099/100000 [04:43<29:01, 49.33it/s]
epoch 14100  training loss: 0.04150879755616188

 14%|██████████▉                                                                  | 14197/100000 [04:45<28:22, 50.39it/s]
epoch 14200  training loss: 0.041095782071352005

 14%|███████████                                                                  | 14294/100000 [04:47<28:54, 49.41it/s]
epoch 14300  training loss: 0.04074600711464882

 14%|███████████                                                                  | 14394/100000 [04:49<28:46, 49.58it/s]
epoch 14400  training loss: 0.040254123508930206

 14%|███████████▏                                                                 | 14494/100000 [04:51<28:46, 49.52it/s]
epoch 14500  training loss: 0.03982633352279663

 15%|███████████▏                                                                 | 14595/100000 [04:53<29:04, 48.95it/s]
epoch 14600  training loss: 0.03939142823219299


 15%|███████████▍                                                                 | 14792/100000 [04:57<28:42, 49.46it/s]
epoch 14700  training loss: 0.039230894297361374

 15%|███████████▍                                                                 | 14892/100000 [04:59<28:41, 49.43it/s]
epoch 14800  training loss: 0.03850541636347771

 15%|███████████▌                                                                 | 14992/100000 [05:01<28:39, 49.45it/s]
epoch 14900  training loss: 0.0382673554122448

 15%|███████████▌                                                                 | 15087/100000 [05:03<28:35, 49.51it/s]
epoch 15000  training loss: 0.03764411434531212
epoch 15000  clean testing loss: 0.18491321802139282

 15%|███████████▋                                                                 | 15189/100000 [05:05<28:05, 50.31it/s]
epoch 15100  training loss: 0.03715243563055992

 15%|███████████▊                                                                 | 15288/100000 [05:07<28:31, 49.50it/s]
epoch 15200  training loss: 0.03672060742974281

 15%|███████████▊                                                                 | 15389/100000 [05:09<28:30, 49.48it/s]
epoch 15300  training loss: 0.03625447303056717

 15%|███████████▉                                                                 | 15489/100000 [05:11<28:26, 49.52it/s]
epoch 15400  training loss: 0.03578431159257889

 16%|████████████                                                                 | 15585/100000 [05:13<28:24, 49.54it/s]
epoch 15500  training loss: 0.03529126197099686

 16%|████████████                                                                 | 15687/100000 [05:15<28:18, 49.63it/s]
epoch 15600  training loss: 0.03480828180909157

 16%|████████████▏                                                                | 15785/100000 [05:17<28:11, 49.79it/s]
epoch 15700  training loss: 0.03432789072394371

 16%|████████████▏                                                                | 15882/100000 [05:19<28:15, 49.63it/s]
epoch 15800  training loss: 0.03429662436246872

 16%|████████████▎                                                                | 15982/100000 [05:21<28:13, 49.60it/s]
epoch 15900  training loss: 0.033471256494522095

 16%|████████████▍                                                                | 16082/100000 [05:23<28:29, 49.08it/s]
epoch 16000  training loss: 0.03289332613348961
epoch 16000  clean testing loss: 0.2161421924829483

 16%|████████████▍                                                                | 16183/100000 [05:25<27:53, 50.08it/s]
epoch 16100  training loss: 0.032447244971990585

 16%|████████████▌                                                                | 16280/100000 [05:27<28:00, 49.82it/s]
epoch 16200  training loss: 0.03201866149902344
epoch 16200  clean testing loss: 0.2221127301454544
epoch 16300  training loss: 0.03159044682979584

 16%|████████████▌                                                                | 16382/100000 [05:29<28:05, 49.61it/s]
epoch 16400  training loss: 0.03119823895394802

 16%|████████████▋                                                                | 16482/100000 [05:31<28:04, 49.58it/s]
epoch 16500  training loss: 0.030820179730653763

 17%|████████████▊                                                                | 16578/100000 [05:33<27:51, 49.91it/s]
epoch 16600  training loss: 0.030463602393865585

 17%|████████████▊                                                                | 16679/100000 [05:35<28:01, 49.56it/s]
epoch 16700  training loss: 0.030120473355054855

 17%|████████████▉                                                                | 16780/100000 [05:37<27:57, 49.60it/s]
epoch 16800  training loss: 0.029817063361406326

 17%|████████████▉                                                                | 16880/100000 [05:39<27:55, 49.60it/s]
epoch 16900  training loss: 0.029751259833574295

 17%|█████████████                                                                | 16977/100000 [05:41<28:39, 48.27it/s]
epoch 17000  training loss: 0.029466889798641205
epoch 17000  clean testing loss: 0.240167036652565

 17%|█████████████▏                                                               | 17052/100000 [05:43<28:59, 47.67it/s]
epoch 17100  training loss: 0.029164159670472145

 17%|█████████████▏                                                               | 17152/100000 [05:45<27:45, 49.74it/s]
epoch 17200  training loss: 0.028890695422887802

 17%|█████████████▎                                                               | 17253/100000 [05:47<27:36, 49.94it/s]
epoch 17300  training loss: 0.02837030030786991

 17%|█████████████▎                                                               | 17353/100000 [05:49<27:48, 49.53it/s]
epoch 17400  training loss: 0.028424454852938652

 17%|█████████████▍                                                               | 17453/100000 [05:51<27:46, 49.52it/s]
epoch 17500  training loss: 0.02782457508146763

 18%|█████████████▌                                                               | 17549/100000 [05:53<27:41, 49.62it/s]
epoch 17600  training loss: 0.027514195069670677

 18%|█████████████▌                                                               | 17651/100000 [05:55<27:37, 49.70it/s]
epoch 17700  training loss: 0.02743348479270935

 18%|█████████████▋                                                               | 17747/100000 [05:57<28:07, 48.73it/s]
epoch 17800  training loss: 0.02707396075129509

 18%|█████████████▋                                                               | 17848/100000 [05:59<27:27, 49.88it/s]
epoch 17900  training loss: 0.02680773288011551

 18%|█████████████▊                                                               | 17948/100000 [06:01<27:37, 49.51it/s]
epoch 18000  training loss: 0.02658352628350258
epoch 18000  clean testing loss: 0.2634815275669098

 18%|█████████████▉                                                               | 18049/100000 [06:03<27:36, 49.46it/s]
epoch 18100  training loss: 0.026334451511502266

 18%|█████████████▉                                                               | 18144/100000 [06:05<27:33, 49.49it/s]
epoch 18200  training loss: 0.026140935719013214

 18%|██████████████                                                               | 18244/100000 [06:07<27:31, 49.51it/s]
epoch 18300  training loss: 0.025937948375940323

 18%|██████████████▏                                                              | 18346/100000 [06:09<27:24, 49.65it/s]
epoch 18400  training loss: 0.025724811479449272

 18%|██████████████▏                                                              | 18443/100000 [06:11<27:21, 49.68it/s]
epoch 18500  training loss: 0.025515401735901833

 19%|██████████████▎                                                              | 18543/100000 [06:13<27:23, 49.57it/s]
epoch 18600  training loss: 0.025362243875861168

 19%|██████████████▎                                                              | 18644/100000 [06:15<27:20, 49.60it/s]
epoch 18700  training loss: 0.025074219331145287

 19%|██████████████▍                                                              | 18745/100000 [06:17<27:21, 49.51it/s]
epoch 18800  training loss: 0.024856824427843094

 19%|██████████████▌                                                              | 18845/100000 [06:19<27:18, 49.54it/s]
epoch 18900  training loss: 0.024640638381242752

 19%|██████████████▌                                                              | 18945/100000 [06:21<27:14, 49.60it/s]
epoch 19000  training loss: 0.024417482316493988
epoch 19000  clean testing loss: 0.2978843152523041

 19%|██████████████▋                                                              | 19043/100000 [06:23<27:14, 49.54it/s]
epoch 19100  training loss: 0.024235723540186882

 19%|██████████████▋                                                              | 19138/100000 [06:25<27:17, 49.38it/s]
epoch 19200  training loss: 0.024038605391979218

 19%|██████████████▊                                                              | 19238/100000 [06:27<27:06, 49.64it/s]
epoch 19300  training loss: 0.023758111521601677

 19%|██████████████▉                                                              | 19338/100000 [06:29<27:07, 49.57it/s]
epoch 19400  training loss: 0.023546621203422546

 19%|██████████████▉                                                              | 19438/100000 [06:31<27:03, 49.61it/s]
epoch 19500  training loss: 0.023324379697442055

 20%|███████████████                                                              | 19539/100000 [06:33<27:02, 49.58it/s]
epoch 19600  training loss: 0.023134302347898483

 20%|███████████████                                                              | 19636/100000 [06:35<27:00, 49.60it/s]
epoch 19700  training loss: 0.02290818840265274

 20%|███████████████▏                                                             | 19736/100000 [06:37<26:59, 49.57it/s]
epoch 19800  training loss: 0.023530641570687294

 20%|███████████████▎                                                             | 19838/100000 [06:39<26:57, 49.57it/s]
epoch 19900  training loss: 0.022551029920578003

 20%|███████████████▎                                                             | 19898/100000 [06:41<26:56, 49.56it/s]
epoch 20000  training loss: 0.02226618304848671
epoch 20000  clean testing loss: 0.3581647574901581

 20%|███████████████▍                                                             | 20033/100000 [06:43<27:03, 49.25it/s]
epoch 20100  training loss: 0.02207479625940323

 20%|███████████████▌                                                             | 20133/100000 [06:45<26:49, 49.63it/s]
epoch 20200  training loss: 0.021867725998163223

 20%|███████████████▌                                                             | 20234/100000 [06:47<26:49, 49.57it/s]
epoch 20300  training loss: 0.02185818739235401

 20%|███████████████▋                                                             | 20335/100000 [06:49<26:43, 49.69it/s]
epoch 20400  training loss: 0.021575920283794403

 20%|███████████████▋                                                             | 20435/100000 [06:51<26:44, 49.60it/s]
epoch 20500  training loss: 0.02174769714474678

 21%|███████████████▊                                                             | 20532/100000 [06:53<26:41, 49.61it/s]
epoch 20600  training loss: 0.021128617227077484

 21%|███████████████▉                                                             | 20633/100000 [06:55<26:32, 49.84it/s]
epoch 20700  training loss: 0.020935064181685448

 21%|███████████████▉                                                             | 20733/100000 [06:57<26:39, 49.57it/s]
epoch 20800  training loss: 0.02076737955212593

 21%|████████████████                                                             | 20808/100000 [06:59<26:41, 49.44it/s]
epoch 20900  training loss: 0.020590757951140404

 21%|████████████████                                                             | 20905/100000 [07:01<26:37, 49.52it/s]
epoch 21000  training loss: 0.020432300865650177
epoch 21000  clean testing loss: 0.4405512809753418

 21%|████████████████▏                                                            | 21005/100000 [07:03<27:59, 47.03it/s]
epoch 21100  training loss: 0.020290199667215347

 21%|████████████████▏                                                            | 21102/100000 [07:05<26:28, 49.68it/s]
epoch 21200  training loss: 0.020152494311332703

 21%|████████████████▎                                                            | 21202/100000 [07:07<26:26, 49.67it/s]
epoch 21300  training loss: 0.020010529085993767

 21%|████████████████▍                                                            | 21302/100000 [07:09<26:17, 49.89it/s]
epoch 21400  training loss: 0.019864525645971298

 21%|████████████████▍                                                            | 21404/100000 [07:11<26:19, 49.77it/s]
epoch 21500  training loss: 0.019734838977456093

 22%|████████████████▌                                                            | 21500/100000 [07:13<26:19, 49.69it/s]
epoch 21600  training loss: 0.01958089880645275

 22%|████████████████▋                                                            | 21600/100000 [07:15<26:42, 48.92it/s]
epoch 21700  training loss: 0.019436340779066086

 22%|████████████████▋                                                            | 21702/100000 [07:17<26:23, 49.46it/s]
epoch 21800  training loss: 0.019300034269690514

 22%|████████████████▊                                                            | 21798/100000 [07:19<26:19, 49.52it/s]
epoch 21900  training loss: 0.019168099388480186

 22%|████████████████▊                                                            | 21898/100000 [07:21<26:15, 49.58it/s]
epoch 22000  training loss: 0.019039591774344444
epoch 22000  clean testing loss: 0.5218551158905029

 22%|████████████████▉                                                            | 21998/100000 [07:23<26:14, 49.54it/s]
epoch 22100  training loss: 0.018912335857748985

 22%|█████████████████                                                            | 22098/100000 [07:25<26:11, 49.56it/s]
epoch 22200  training loss: 0.01879262365400791

 22%|█████████████████                                                            | 22199/100000 [07:27<26:04, 49.74it/s]
epoch 22300  training loss: 0.01866241917014122

 22%|█████████████████▏                                                           | 22299/100000 [07:29<26:05, 49.64it/s]
epoch 22400  training loss: 0.018597519025206566


 22%|█████████████████▎                                                           | 22498/100000 [07:33<25:58, 49.73it/s]
epoch 22500  training loss: 0.018428659066557884

 23%|█████████████████▍                                                           | 22594/100000 [07:35<25:52, 49.87it/s]
epoch 22600  training loss: 0.018317433074116707

 23%|█████████████████▍                                                           | 22693/100000 [07:37<26:01, 49.52it/s]
epoch 22700  training loss: 0.01820339262485504

 23%|█████████████████▌                                                           | 22794/100000 [07:39<26:07, 49.24it/s]
epoch 22800  training loss: 0.01808311976492405

 23%|█████████████████▋                                                           | 22895/100000 [07:41<25:53, 49.64it/s]
epoch 22900  training loss: 0.01798178069293499

 23%|█████████████████▋                                                           | 22990/100000 [07:43<26:14, 48.91it/s]
epoch 23000  training loss: 0.017950965091586113
epoch 23000  clean testing loss: 0.6049165725708008

 23%|█████████████████▊                                                           | 23090/100000 [07:45<25:54, 49.49it/s]
epoch 23100  training loss: 0.017787054181098938

 23%|█████████████████▊                                                           | 23191/100000 [07:47<25:42, 49.80it/s]
epoch 23200  training loss: 0.0176533255726099

 23%|█████████████████▉                                                           | 23290/100000 [07:49<25:49, 49.50it/s]
epoch 23300  training loss: 0.017551463097333908

 23%|██████████████████                                                           | 23390/100000 [07:51<25:45, 49.57it/s]
epoch 23400  training loss: 0.017454273998737335

 23%|██████████████████                                                           | 23491/100000 [07:53<25:43, 49.58it/s]
epoch 23500  training loss: 0.017352823168039322

 24%|██████████████████▏                                                          | 23586/100000 [07:55<25:40, 49.61it/s]
epoch 23600  training loss: 0.017254238948225975

 24%|██████████████████▏                                                          | 23687/100000 [07:57<25:40, 49.54it/s]
epoch 23700  training loss: 0.017157243564724922

 24%|██████████████████▎                                                          | 23785/100000 [07:59<25:37, 49.57it/s]
epoch 23800  training loss: 0.017064133659005165

 24%|██████████████████▍                                                          | 23885/100000 [08:01<25:36, 49.53it/s]
epoch 23900  training loss: 0.017783043906092644

 24%|██████████████████▍                                                          | 23985/100000 [08:03<25:49, 49.06it/s]
epoch 24000  training loss: 0.016954872757196426
epoch 24000  clean testing loss: 0.6868574619293213

 24%|██████████████████▌                                                          | 24085/100000 [08:05<25:30, 49.59it/s]
epoch 24100  training loss: 0.016803434118628502

 24%|██████████████████▌                                                          | 24185/100000 [08:07<25:14, 50.05it/s]
epoch 24200  training loss: 0.01672820746898651

 24%|██████████████████▋                                                          | 24281/100000 [08:09<25:30, 49.49it/s]
epoch 24300  training loss: 0.01664993166923523

 24%|██████████████████▊                                                          | 24382/100000 [08:11<25:26, 49.54it/s]
epoch 24400  training loss: 0.01656881347298622

 24%|██████████████████▊                                                          | 24483/100000 [08:13<25:23, 49.56it/s]
epoch 24500  training loss: 0.016484547406435013

 25%|██████████████████▉                                                          | 24583/100000 [08:15<25:22, 49.55it/s]
epoch 24600  training loss: 0.016401639208197594

 25%|███████████████████                                                          | 24680/100000 [08:17<25:17, 49.64it/s]
epoch 24700  training loss: 0.01636909507215023

 25%|███████████████████                                                          | 24781/100000 [08:19<25:20, 49.47it/s]
epoch 24800  training loss: 0.01623690500855446

 25%|███████████████████▏                                                         | 24881/100000 [08:21<25:17, 49.50it/s]
epoch 24900  training loss: 0.016259726136922836

 25%|███████████████████▏                                                         | 24981/100000 [08:23<25:15, 49.51it/s]
epoch 25000  training loss: 0.016076549887657166
epoch 25000  clean testing loss: 0.7702810168266296

 25%|███████████████████▎                                                         | 25076/100000 [08:25<25:13, 49.50it/s]
epoch 25100  training loss: 0.01599275879561901

 25%|███████████████████▍                                                         | 25180/100000 [08:27<24:42, 50.45it/s]
epoch 25200  training loss: 0.016003331169486046

 25%|███████████████████▍                                                         | 25277/100000 [08:29<25:10, 49.46it/s]
epoch 25300  training loss: 0.01596241444349289

 25%|███████████████████▌                                                         | 25377/100000 [08:31<25:04, 49.59it/s]
epoch 25400  training loss: 0.015781572088599205

 25%|███████████████████▌                                                         | 25477/100000 [08:33<25:04, 49.53it/s]
epoch 25500  training loss: 0.01567934639751911

 26%|███████████████████▋                                                         | 25574/100000 [08:35<25:01, 49.58it/s]
epoch 25600  training loss: 0.015606083907186985

 26%|███████████████████▊                                                         | 25672/100000 [08:37<24:54, 49.73it/s]
epoch 25700  training loss: 0.015527560375630856

 26%|███████████████████▊                                                         | 25773/100000 [08:39<24:59, 49.52it/s]
epoch 25800  training loss: 0.015456135384738445

 26%|███████████████████▉                                                         | 25873/100000 [08:41<24:54, 49.59it/s]
epoch 25900  training loss: 0.015399504452943802

 26%|███████████████████▉                                                         | 25973/100000 [08:43<24:57, 49.44it/s]
epoch 26000  training loss: 0.015307514928281307
epoch 26000  clean testing loss: 0.8704173564910889

 26%|████████████████████                                                         | 26073/100000 [08:45<24:55, 49.43it/s]
epoch 26100  training loss: 0.015234104357659817

 26%|████████████████████▏                                                        | 26171/100000 [08:47<24:32, 50.15it/s]
epoch 26200  training loss: 0.015191887505352497

 26%|████████████████████▏                                                        | 26270/100000 [08:49<24:48, 49.53it/s]
epoch 26300  training loss: 0.015215419232845306

 26%|████████████████████▎                                                        | 26371/100000 [08:51<24:43, 49.63it/s]
epoch 26400  training loss: 0.015023168176412582


 27%|████████████████████▍                                                        | 26617/100000 [08:56<24:39, 49.61it/s]
epoch 26500  training loss: 0.014951818622648716
epoch 26500  clean testing loss: 0.9266211986541748
epoch 26600  training loss: 0.014886013232171535

 27%|████████████████████▌                                                        | 26708/100000 [08:58<24:39, 49.55it/s]
epoch 26700  training loss: 0.014846842736005783
epoch 26700  clean testing loss: 0.950045645236969
epoch 26800  training loss: 0.014745030552148819
epoch 26800  clean testing loss: 0.9620962142944336
epoch 26900  training loss: 0.014664332382380962

 27%|████████████████████▊                                                        | 27002/100000 [09:06<25:57, 46.88it/s]
epoch 27000  training loss: 0.01459526177495718
epoch 27000  clean testing loss: 0.9866889119148254

 27%|████████████████████▊                                                        | 27097/100000 [09:08<24:30, 49.58it/s]
epoch 27100  training loss: 0.014536905102431774

 27%|████████████████████▉                                                        | 27199/100000 [09:10<24:03, 50.43it/s]
epoch 27200  training loss: 0.014476682059466839

 27%|█████████████████████                                                        | 27299/100000 [09:12<24:24, 49.64it/s]
epoch 27300  training loss: 0.014413650147616863

 27%|█████████████████████                                                        | 27400/100000 [09:14<24:24, 49.58it/s]
epoch 27400  training loss: 0.014347752556204796

 27%|█████████████████████▏                                                       | 27496/100000 [09:16<24:21, 49.62it/s]
epoch 27500  training loss: 0.014290881343185902

 28%|█████████████████████▏                                                       | 27597/100000 [09:18<24:16, 49.71it/s]
epoch 27600  training loss: 0.014289085753262043

 28%|█████████████████████▎                                                       | 27699/100000 [09:20<24:18, 49.58it/s]
epoch 27700  training loss: 0.01425892859697342

 28%|█████████████████████▍                                                       | 27799/100000 [09:22<24:15, 49.60it/s]
epoch 27800  training loss: 0.014093471691012383

 28%|█████████████████████▍                                                       | 27894/100000 [09:24<24:12, 49.63it/s]
epoch 27900  training loss: 0.014015979133546352


 28%|█████████████████████▋                                                       | 28095/100000 [09:28<24:10, 49.57it/s]
epoch 28000  training loss: 0.013966800644993782
epoch 28000  clean testing loss: 1.1143606901168823

 28%|█████████████████████▋                                                       | 28191/100000 [09:30<23:54, 50.07it/s]
epoch 28100  training loss: 0.013885981403291225

 28%|█████████████████████▊                                                       | 28293/100000 [09:32<23:51, 50.09it/s]
epoch 28200  training loss: 0.01381900254637003

 28%|█████████████████████▊                                                       | 28394/100000 [09:34<24:03, 49.59it/s]
epoch 28300  training loss: 0.013806316070258617

 28%|█████████████████████▉                                                       | 28494/100000 [09:36<24:02, 49.56it/s]
epoch 28400  training loss: 0.013691466301679611

 29%|██████████████████████                                                       | 28590/100000 [09:38<24:01, 49.53it/s]
epoch 28500  training loss: 0.013768055476248264

 29%|██████████████████████                                                       | 28690/100000 [09:40<23:58, 49.58it/s]
epoch 28600  training loss: 0.013556168414652348

 29%|██████████████████████▏                                                      | 28791/100000 [09:42<23:54, 49.63it/s]
epoch 28700  training loss: 0.01349265780299902

 29%|██████████████████████▏                                                      | 28892/100000 [09:44<23:49, 49.73it/s]
epoch 28800  training loss: 0.01343268807977438

 29%|██████████████████████▎                                                      | 28993/100000 [09:47<23:53, 49.52it/s]
epoch 28900  training loss: 0.013367165811359882

 29%|██████████████████████▍                                                      | 29089/100000 [09:48<23:52, 49.52it/s]
epoch 29000  training loss: 0.013313980773091316
epoch 29000  clean testing loss: 1.2600840330123901

 29%|██████████████████████▍                                                      | 29190/100000 [09:51<23:34, 50.05it/s]
epoch 29100  training loss: 0.013280410319566727

 29%|██████████████████████▌                                                      | 29289/100000 [09:53<23:39, 49.80it/s]
epoch 29200  training loss: 0.013182692229747772

 29%|██████████████████████▋                                                      | 29386/100000 [09:54<23:44, 49.57it/s]
epoch 29300  training loss: 0.013121753931045532

 29%|██████████████████████▋                                                      | 29486/100000 [09:56<23:40, 49.65it/s]
epoch 29400  training loss: 0.013111365027725697

 30%|██████████████████████▊                                                      | 29587/100000 [09:59<23:43, 49.45it/s]
epoch 29500  training loss: 0.013002853840589523

 30%|██████████████████████▊                                                      | 29688/100000 [10:01<23:39, 49.52it/s]
epoch 29600  training loss: 0.012952140532433987

 30%|██████████████████████▉                                                      | 29763/100000 [10:02<23:36, 49.57it/s]
epoch 29700  training loss: 0.012887348420917988

 30%|██████████████████████▉                                                      | 29863/100000 [10:04<23:36, 49.50it/s]
epoch 29800  training loss: 0.012887257151305676

 30%|███████████████████████                                                      | 29959/100000 [10:06<23:39, 49.33it/s]
epoch 29900  training loss: 0.012875623069703579

 30%|███████████████████████▏                                                     | 30059/100000 [10:08<23:33, 49.47it/s]
epoch 30000  training loss: 0.012707287445664406
epoch 30000  clean testing loss: 1.4168133735656738

 30%|███████████████████████▏                                                     | 30155/100000 [10:10<24:17, 47.93it/s]
epoch 30100  training loss: 0.012660160660743713

 30%|███████████████████████▎                                                     | 30254/100000 [10:12<23:18, 49.86it/s]
epoch 30200  training loss: 0.01261129230260849

 30%|███████████████████████▎                                                     | 30354/100000 [10:14<23:28, 49.46it/s]
epoch 30300  training loss: 0.01256058644503355

 30%|███████████████████████▍                                                     | 30455/100000 [10:16<23:16, 49.79it/s]
epoch 30400  training loss: 0.012507920153439045

 31%|███████████████████████▌                                                     | 30555/100000 [10:18<23:22, 49.50it/s]
epoch 30500  training loss: 0.012463079765439034

 31%|███████████████████████▌                                                     | 30652/100000 [10:20<23:16, 49.67it/s]
epoch 30600  training loss: 0.012483942322432995

 31%|███████████████████████▋                                                     | 30752/100000 [10:22<23:42, 48.70it/s]
epoch 30700  training loss: 0.012400459498167038

 31%|███████████████████████▊                                                     | 30852/100000 [10:24<23:14, 49.57it/s]
epoch 30800  training loss: 0.012300257571041584

 31%|███████████████████████▊                                                     | 30952/100000 [10:26<23:13, 49.56it/s]
epoch 30900  training loss: 0.012257710099220276

 31%|███████████████████████▉                                                     | 31062/100000 [10:28<19:32, 58.77it/s]
epoch 31000  training loss: 0.012246080674231052
epoch 31000  clean testing loss: 1.5728445053100586

 31%|████████████████████████                                                     | 31185/100000 [10:30<19:17, 59.46it/s]
epoch 31100  training loss: 0.01215098425745964

 31%|████████████████████████                                                     | 31300/100000 [10:32<19:24, 59.02it/s]
epoch 31200  training loss: 0.012105449102818966
epoch 31200  clean testing loss: 1.604562520980835
epoch 31300  training loss: 0.01204981841146946

 31%|████████████████████████▏                                                    | 31420/100000 [10:34<19:23, 58.96it/s]
epoch 31400  training loss: 0.012003479525446892

 32%|████████████████████████▎                                                    | 31536/100000 [10:36<19:16, 59.20it/s]
epoch 31500  training loss: 0.011975937522947788

 32%|████████████████████████▍                                                    | 31657/100000 [10:38<19:12, 59.32it/s]
epoch 31600  training loss: 0.011921758763492107

 32%|████████████████████████▍                                                    | 31777/100000 [10:40<19:20, 58.80it/s]
epoch 31700  training loss: 0.011903596110641956

 32%|████████████████████████▌                                                    | 31893/100000 [10:42<19:13, 59.04it/s]
epoch 31800  training loss: 0.011817886494100094
epoch 31800  clean testing loss: 1.7011631727218628
epoch 31900  training loss: 0.011774067766964436

 32%|████████████████████████▋                                                    | 32013/100000 [10:44<19:44, 57.42it/s]
epoch 32000  training loss: 0.011777509935200214
epoch 32000  clean testing loss: 1.733559489250183

 32%|████████████████████████▋                                                    | 32128/100000 [10:46<19:13, 58.84it/s]
epoch 32100  training loss: 0.011702545918524265

 32%|████████████████████████▊                                                    | 32251/100000 [10:48<19:07, 59.02it/s]
epoch 32200  training loss: 0.01169758290052414

 32%|████████████████████████▉                                                    | 32365/100000 [10:50<19:10, 58.79it/s]
epoch 32300  training loss: 0.011599243618547916

 32%|█████████████████████████                                                    | 32485/100000 [10:52<19:04, 58.97it/s]
epoch 32400  training loss: 0.011556566692888737

 33%|█████████████████████████                                                    | 32605/100000 [10:54<19:03, 58.95it/s]
epoch 32500  training loss: 0.011513904668390751
epoch 32500  clean testing loss: 1.8136951923370361
epoch 32600  training loss: 0.011560793034732342

 33%|█████████████████████████▏                                                   | 32720/100000 [10:56<19:05, 58.74it/s]
epoch 32700  training loss: 0.011461712419986725

 33%|█████████████████████████▎                                                   | 32834/100000 [10:58<19:00, 58.90it/s]
epoch 32800  training loss: 0.011437359265983105

 33%|█████████████████████████▍                                                   | 32960/100000 [11:00<19:00, 58.81it/s]
epoch 32900  training loss: 0.011353621259331703

 33%|█████████████████████████▍                                                   | 33075/100000 [11:02<18:56, 58.87it/s]
epoch 33000  training loss: 0.011314993724226952
epoch 33000  clean testing loss: 1.8925256729125977

 33%|█████████████████████████▌                                                   | 33196/100000 [11:04<18:52, 58.99it/s]
epoch 33100  training loss: 0.011275453492999077

 33%|█████████████████████████▋                                                   | 33311/100000 [11:06<18:49, 59.04it/s]
epoch 33200  training loss: 0.011241519823670387
epoch 33200  clean testing loss: 1.9189295768737793
epoch 33300  training loss: 0.011206184513866901

 33%|█████████████████████████▋                                                   | 33431/100000 [11:08<18:45, 59.17it/s]
epoch 33400  training loss: 0.01116918958723545

 34%|█████████████████████████▊                                                   | 33551/100000 [11:10<18:49, 58.81it/s]
epoch 33500  training loss: 0.01113753393292427

 34%|█████████████████████████▉                                                   | 33667/100000 [11:12<18:46, 58.87it/s]
epoch 33600  training loss: 0.011130760423839092

 34%|██████████████████████████                                                   | 33787/100000 [11:14<18:41, 59.01it/s]
epoch 33700  training loss: 0.011077587492763996

 34%|██████████████████████████                                                   | 33907/100000 [11:16<18:37, 59.12it/s]
epoch 33800  training loss: 0.011055801063776016
epoch 33800  clean testing loss: 2.009357213973999
epoch 33900  training loss: 0.010991099290549755

 34%|██████████████████████████▏                                                  | 34022/100000 [11:18<18:58, 57.95it/s]
epoch 34000  training loss: 0.010945207439363003
epoch 34000  clean testing loss: 2.03922438621521

 34%|██████████████████████████▎                                                  | 34142/100000 [11:20<18:39, 58.81it/s]
epoch 34100  training loss: 0.010909120552241802

 34%|██████████████████████████▍                                                  | 34259/100000 [11:22<18:39, 58.74it/s]
epoch 34200  training loss: 0.010892399586737156

 34%|██████████████████████████▍                                                  | 34380/100000 [11:24<18:33, 58.92it/s]
epoch 34300  training loss: 0.010874079540371895

 34%|██████████████████████████▌                                                  | 34495/100000 [11:26<18:32, 58.89it/s]
epoch 34400  training loss: 0.010891139507293701

 35%|██████████████████████████▋                                                  | 34615/100000 [11:28<18:31, 58.81it/s]
epoch 34500  training loss: 0.010767395608127117
epoch 34500  clean testing loss: 2.112483263015747
epoch 34600  training loss: 0.010735338553786278

 35%|██████████████████████████▋                                                  | 34737/100000 [11:30<18:12, 59.71it/s]
epoch 34700  training loss: 0.010701530613005161

 35%|██████████████████████████▊                                                  | 34851/100000 [11:32<18:25, 58.95it/s]
epoch 34800  training loss: 0.010666104033589363

 35%|██████████████████████████▉                                                  | 34971/100000 [11:34<18:23, 58.93it/s]
epoch 34900  training loss: 0.010630480945110321

 35%|███████████████████████████                                                  | 35092/100000 [11:36<18:19, 59.03it/s]
epoch 35000  training loss: 0.010602038353681564
epoch 35000  clean testing loss: 2.1839101314544678

 35%|███████████████████████████                                                  | 35208/100000 [11:38<18:15, 59.13it/s]
epoch 35100  training loss: 0.010566683486104012
epoch 35100  clean testing loss: 2.197690486907959
epoch 35200  training loss: 0.01052730344235897

 35%|███████████████████████████▏                                                 | 35329/100000 [11:40<18:19, 58.84it/s]
epoch 35300  training loss: 0.010494930669665337

 35%|███████████████████████████▎                                                 | 35443/100000 [11:42<18:18, 58.75it/s]
epoch 35400  training loss: 0.01046154834330082

 36%|███████████████████████████▍                                                 | 35564/100000 [11:44<18:14, 58.88it/s]
epoch 35500  training loss: 0.010428856126964092

 36%|███████████████████████████▍                                                 | 35679/100000 [11:46<18:07, 59.13it/s]
epoch 35600  training loss: 0.010402705520391464

 36%|███████████████████████████▌                                                 | 35799/100000 [11:48<18:10, 58.87it/s]
epoch 35700  training loss: 0.010375255718827248

 36%|███████████████████████████▋                                                 | 35919/100000 [11:50<18:07, 58.94it/s]
epoch 35800  training loss: 0.010340367443859577
epoch 35800  clean testing loss: 2.293212413787842
epoch 35900  training loss: 0.01029657106846571

 36%|███████████████████████████▋                                                 | 36033/100000 [11:52<18:11, 58.60it/s]
epoch 36000  training loss: 0.01026454009115696
epoch 36000  clean testing loss: 2.319228172302246

 36%|███████████████████████████▊                                                 | 36153/100000 [11:54<17:57, 59.24it/s]
epoch 36100  training loss: 0.010238164104521275

 36%|███████████████████████████▉                                                 | 36270/100000 [11:56<18:01, 58.95it/s]
epoch 36200  training loss: 0.010210630483925343

 36%|████████████████████████████                                                 | 36390/100000 [11:58<17:59, 58.94it/s]
epoch 36300  training loss: 0.010181810706853867

 37%|████████████████████████████                                                 | 36510/100000 [12:00<18:02, 58.67it/s]
epoch 36400  training loss: 0.010151826776564121
epoch 36400  clean testing loss: 2.3646721839904785
epoch 36500  training loss: 0.010129688307642937

 37%|████████████████████████████▏                                                | 36630/100000 [12:03<17:53, 59.02it/s]
epoch 36600  training loss: 0.010210919193923473

 37%|████████████████████████████▎                                                | 36744/100000 [12:04<17:51, 59.04it/s]
epoch 36700  training loss: 0.01010107807815075

 37%|████████████████████████████▍                                                | 36864/100000 [12:06<17:50, 58.96it/s]
epoch 36800  training loss: 0.01013024803251028

 37%|████████████████████████████▍                                                | 36984/100000 [12:09<17:49, 58.94it/s]
epoch 36900  training loss: 0.010000650770962238

 37%|████████████████████████████▌                                                | 37098/100000 [12:10<17:47, 58.93it/s]
epoch 37000  training loss: 0.009971965104341507
epoch 37000  clean testing loss: 2.435854196548462

 37%|████████████████████████████▋                                                | 37220/100000 [12:13<17:49, 58.72it/s]
epoch 37100  training loss: 0.009971041232347488
epoch 37100  clean testing loss: 2.4471242427825928
epoch 37200  training loss: 0.009912937879562378

 37%|████████████████████████████▋                                                | 37335/100000 [12:14<17:44, 58.89it/s]
epoch 37300  training loss: 0.0098844263702631

 37%|████████████████████████████▊                                                | 37455/100000 [12:17<17:43, 58.83it/s]
epoch 37400  training loss: 0.009855679236352444

 38%|████████████████████████████▉                                                | 37575/100000 [12:19<17:41, 58.79it/s]
epoch 37500  training loss: 0.009829351678490639

 38%|█████████████████████████████                                                | 37690/100000 [12:20<17:40, 58.76it/s]
epoch 37600  training loss: 0.00983023177832365

 38%|█████████████████████████████                                                | 37811/100000 [12:23<17:37, 58.79it/s]
epoch 37700  training loss: 0.009770604781806469
epoch 37700  clean testing loss: 2.510996103286743
epoch 37800  training loss: 0.009743076749145985

 38%|█████████████████████████████▏                                               | 37931/100000 [12:25<17:28, 59.17it/s]
epoch 37900  training loss: 0.009714667685329914

 38%|█████████████████████████████▎                                               | 38045/100000 [12:27<17:35, 58.68it/s]
epoch 38000  training loss: 0.009686792269349098
epoch 38000  clean testing loss: 2.5410470962524414

 38%|█████████████████████████████▍                                               | 38166/100000 [12:29<17:15, 59.70it/s]
epoch 38100  training loss: 0.009663857519626617

 38%|█████████████████████████████▍                                               | 38281/100000 [12:31<17:31, 58.70it/s]
epoch 38200  training loss: 0.009631771594285965

 38%|█████████████████████████████▌                                               | 38401/100000 [12:33<17:24, 58.95it/s]
epoch 38300  training loss: 0.00961253046989441

 39%|█████████████████████████████▋                                               | 38521/100000 [12:35<17:23, 58.91it/s]
epoch 38400  training loss: 0.009591004811227322
epoch 38400  clean testing loss: 2.579291582107544
epoch 38500  training loss: 0.009549763053655624

 39%|█████████████████████████████▋                                               | 38636/100000 [12:37<17:13, 59.37it/s]
epoch 38600  training loss: 0.009522850625216961

 39%|█████████████████████████████▊                                               | 38756/100000 [12:39<17:22, 58.75it/s]
epoch 38700  training loss: 0.009501595981419086

 39%|█████████████████████████████▉                                               | 38876/100000 [12:41<17:14, 59.09it/s]
epoch 38800  training loss: 0.009470196440815926

 39%|██████████████████████████████                                               | 38996/100000 [12:43<17:16, 58.87it/s]
epoch 38900  training loss: 0.009444529190659523

 39%|██████████████████████████████                                               | 39121/100000 [12:45<14:05, 72.02it/s]
epoch 39000  training loss: 0.009417260065674782
epoch 39000  clean testing loss: 2.63150954246521
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop1 ...
epoch 39100  training loss: 0.00939562451094389

 39%|██████████████████████████████▏                                              | 39273/100000 [12:47<13:51, 73.06it/s]
epoch 39200  training loss: 0.009373084641993046

 39%|██████████████████████████████▎                                              | 39417/100000 [12:49<13:52, 72.74it/s]
epoch 39300  training loss: 0.009349607862532139
epoch 39300  clean testing loss: 2.6528289318084717
epoch 39400  training loss: 0.009325082413852215

 40%|██████████████████████████████▍                                              | 39561/100000 [12:51<13:51, 72.65it/s]
epoch 39500  training loss: 0.009306245483458042

 40%|██████████████████████████████▌                                              | 39705/100000 [12:53<13:55, 72.21it/s]
epoch 39600  training loss: 0.009284457191824913

 40%|██████████████████████████████▋                                              | 39857/100000 [12:55<13:46, 72.77it/s]
epoch 39700  training loss: 0.009255600161850452
epoch 39700  clean testing loss: 2.6831705570220947
epoch 39800  training loss: 0.009233538992702961

 40%|██████████████████████████████▊                                              | 40001/100000 [12:57<13:53, 71.99it/s]
epoch 39900  training loss: 0.009201296605169773

 40%|██████████████████████████████▉                                              | 40145/100000 [12:59<13:40, 72.94it/s]
epoch 40000  training loss: 0.009175227023661137
epoch 40000  clean testing loss: 2.7048916816711426
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop1 ...
epoch 40100  training loss: 0.009150248020887375

 40%|███████████████████████████████                                              | 40289/100000 [13:01<13:39, 72.82it/s]
epoch 40200  training loss: 0.009126641787588596

 40%|███████████████████████████████▏                                             | 40433/100000 [13:03<13:41, 72.54it/s]
epoch 40300  training loss: 0.009246079251170158
epoch 40300  clean testing loss: 2.7252848148345947
epoch 40400  training loss: 0.009077341295778751

 41%|███████████████████████████████▎                                             | 40585/100000 [13:05<13:33, 73.00it/s]
epoch 40500  training loss: 0.009093870408833027

 41%|███████████████████████████████▎                                             | 40729/100000 [13:07<13:33, 72.89it/s]
epoch 40600  training loss: 0.009031546302139759
epoch 40600  clean testing loss: 2.7448666095733643
epoch 40700  training loss: 0.009005771018564701

 41%|███████████████████████████████▍                                             | 40873/100000 [13:09<13:30, 72.96it/s]
epoch 40800  training loss: 0.008981782011687756

 41%|███████████████████████████████▌                                             | 41000/100000 [13:10<18:58, 51.84it/s]
epoch 40900  training loss: 0.00896559190005064
epoch 40900  clean testing loss: 2.7637054920196533
epoch 41000  training loss: 0.00893316324800253
epoch 41000  clean testing loss: 2.769960641860962
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop1 ...