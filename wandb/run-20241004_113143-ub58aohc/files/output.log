
  0%|                                                                                                                             | 8/100000 [00:01<3:26:15,  8.08it/s]
epoch 0  training loss: 49.82851028442383


  0%|                                                                                                                            | 92/100000 [00:05<1:19:19, 20.99it/s]
epoch 100  training loss: 0.41237255930900574



  0%|▎                                                                                                                          | 218/100000 [00:11<1:20:02, 20.78it/s]
epoch 200  training loss: 0.41237255930900574


  0%|▎                                                                                                                          | 302/100000 [00:15<1:19:24, 20.92it/s]
epoch 300  training loss: 0.41237255930900574


  0%|▍                                                                                                                          | 386/100000 [00:19<1:19:22, 20.92it/s]
epoch 400  training loss: 0.41237255930900574



  1%|▋                                                                                                                          | 512/100000 [00:25<1:19:20, 20.90it/s]
epoch 500  training loss: 0.41237255930900574

  1%|▋                                                                                                                          | 556/100000 [00:27<1:22:27, 20.10it/s]
Traceback (most recent call last):
  File "/home/howon/aistats25-exp/nn_exp.py", line 273, in <module>
    optimizer.step(closure)
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/optim/lbfgs.py", line 319, in step
    orig_loss = closure()
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/howon/aistats25-exp/nn_exp.py", line 259, in closure
    losses.backward()
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt