
  1%|          | 1008/100000 [00:01<03:02, 543.61it/s]
epoch 0  training loss: 0.6431364417076111
epoch 0  clean testing loss: 0.9197818636894226
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 100  training loss: 0.14528487622737885
epoch 100  clean testing loss: 0.06277614831924438
epoch 200  training loss: 0.12549401819705963
epoch 200  clean testing loss: 0.06506744027137756
epoch 300  training loss: 0.13199836015701294
epoch 300  clean testing loss: 0.11109396070241928
epoch 400  training loss: 0.0784115120768547
epoch 400  clean testing loss: 0.08573968708515167
epoch 500  training loss: 0.0800008773803711
epoch 500  clean testing loss: 0.0683818832039833
epoch 600  training loss: 0.06064391881227493
epoch 600  clean testing loss: 0.07467322796583176
epoch 700  training loss: 0.055763646960258484
epoch 700  clean testing loss: 0.09025842696428299
epoch 800  training loss: 0.05037922412157059

  2%|▏         | 2144/100000 [00:04<02:56, 553.30it/s]
epoch 900  training loss: 0.04639070853590965
epoch 900  clean testing loss: 0.10203900933265686
epoch 1000  training loss: 0.23934108018875122
epoch 1000  clean testing loss: 0.13653090596199036
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 1100  training loss: 0.0747591182589531
epoch 1100  clean testing loss: 0.07148987799882889
epoch 1200  training loss: 0.06413593888282776
epoch 1200  clean testing loss: 0.07987874746322632
epoch 1300  training loss: 0.04864530637860298
epoch 1300  clean testing loss: 0.08470877259969711
epoch 1400  training loss: 0.04099619388580322
epoch 1400  clean testing loss: 0.08450846374034882
epoch 1500  training loss: 0.04115164652466774
epoch 1500  clean testing loss: 0.07728411257266998
epoch 1600  training loss: 0.06514529138803482
epoch 1600  clean testing loss: 0.08077577501535416
epoch 1700  training loss: 0.03828035295009613
epoch 1700  clean testing loss: 0.07937590777873993
epoch 1800  training loss: 0.03763287514448166
epoch 1800  clean testing loss: 0.09243649244308472
epoch 1900  training loss: 0.04742185026407242

  3%|▎         | 3280/100000 [00:06<02:52, 561.83it/s]
epoch 2000  training loss: 0.037459757179021835
epoch 2000  clean testing loss: 0.08708284795284271
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 2100  training loss: 0.04200484976172447
epoch 2100  clean testing loss: 0.07195944339036942
epoch 2200  training loss: 0.04847186058759689
epoch 2200  clean testing loss: 0.09733432531356812
epoch 2300  training loss: 0.03524351492524147
epoch 2300  clean testing loss: 0.0910530835390091
epoch 2400  training loss: 0.03781544417142868
epoch 2400  clean testing loss: 0.08965764194726944
epoch 2500  training loss: 0.04109838232398033
epoch 2500  clean testing loss: 0.0914771631360054
epoch 2600  training loss: 0.04052402079105377
epoch 2600  clean testing loss: 0.09013422578573227
epoch 2700  training loss: 0.03315035626292229
epoch 2700  clean testing loss: 0.08687736093997955
epoch 2800  training loss: 0.03615390136837959
epoch 2800  clean testing loss: 0.08698728680610657
epoch 2900  training loss: 0.03566555306315422
epoch 2900  clean testing loss: 0.12065961211919785
epoch 3000  training loss: 0.035920873284339905
epoch 3000  clean testing loss: 0.07590223103761673

  4%|▍         | 4078/100000 [00:07<02:52, 556.25it/s]
epoch 3100  training loss: 0.03227510303258896
epoch 3100  clean testing loss: 0.09570939838886261
epoch 3200  training loss: 0.031782228499650955
epoch 3200  clean testing loss: 0.09716719388961792
epoch 3300  training loss: 0.03238147497177124
epoch 3300  clean testing loss: 0.10179275274276733
epoch 3400  training loss: 0.031045598909258842
epoch 3400  clean testing loss: 0.10090624541044235
epoch 3500  training loss: 0.034465089440345764
epoch 3500  clean testing loss: 0.10017003864049911
epoch 3600  training loss: 0.046614889055490494
epoch 3600  clean testing loss: 0.0916299819946289
epoch 3700  training loss: 0.03599105775356293
epoch 3700  clean testing loss: 0.0927957147359848
epoch 3800  training loss: 0.030684126541018486
epoch 3800  clean testing loss: 0.10727117210626602
epoch 3900  training loss: 0.0312252976000309
epoch 3900  clean testing loss: 0.10246498137712479
epoch 4000  training loss: 0.03231761232018471
epoch 4000  clean testing loss: 0.11158885806798935
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 4100  training loss: 0.03155601769685745

  5%|▌         | 5215/100000 [00:09<02:50, 556.74it/s]
epoch 4200  training loss: 0.03135499730706215
epoch 4200  clean testing loss: 0.10302206873893738
epoch 4300  training loss: 0.03171854838728905
epoch 4300  clean testing loss: 0.10580357164144516
epoch 4400  training loss: 0.03226041421294212
epoch 4400  clean testing loss: 0.09793299436569214
epoch 4500  training loss: 0.03180709481239319
epoch 4500  clean testing loss: 0.08921913057565689
epoch 4600  training loss: 0.030156435444951057
epoch 4600  clean testing loss: 0.1106821820139885
epoch 4700  training loss: 0.030294310301542282
epoch 4700  clean testing loss: 0.10171288996934891
epoch 4800  training loss: 0.029937664046883583
epoch 4800  clean testing loss: 0.11253231018781662
epoch 4900  training loss: 0.05482378229498863
epoch 4900  clean testing loss: 0.10130180418491364
epoch 5000  training loss: 0.03365109860897064
epoch 5000  clean testing loss: 0.10018898546695709
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 5100  training loss: 0.031246520578861237
epoch 5100  clean testing loss: 0.10524255782365799
epoch 5200  training loss: 0.03136485442519188

  6%|▋         | 6353/100000 [00:11<02:47, 558.64it/s]
epoch 5300  training loss: 0.03469010815024376
epoch 5300  clean testing loss: 0.13549794256687164
epoch 5400  training loss: 0.031936075538396835
epoch 5400  clean testing loss: 0.11581090837717056
epoch 5500  training loss: 0.03397270292043686
epoch 5500  clean testing loss: 0.11151392757892609
epoch 5600  training loss: 0.03576570749282837
epoch 5600  clean testing loss: 0.09274922311306
epoch 5700  training loss: 0.054767265915870667
epoch 5700  clean testing loss: 0.1576920598745346
epoch 5800  training loss: 0.0323818102478981
epoch 5800  clean testing loss: 0.10068725049495697
epoch 5900  training loss: 0.03498498350381851
epoch 5900  clean testing loss: 0.10950904339551926
epoch 6000  training loss: 0.031361863017082214
epoch 6000  clean testing loss: 0.11347626149654388
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 6100  training loss: 0.03010455146431923
epoch 6100  clean testing loss: 0.11187482625246048
epoch 6200  training loss: 0.030859746038913727
epoch 6200  clean testing loss: 0.11094377934932709
epoch 6300  training loss: 0.029295140877366066

  7%|▋         | 7431/100000 [00:13<02:46, 556.43it/s]
epoch 6400  training loss: 0.030948298051953316
epoch 6400  clean testing loss: 0.11733590811491013
epoch 6500  training loss: 0.03152571618556976
epoch 6500  clean testing loss: 0.1058572456240654
epoch 6600  training loss: 0.02926216460764408
epoch 6600  clean testing loss: 0.11463690549135208
epoch 6700  training loss: 0.030254725366830826
epoch 6700  clean testing loss: 0.10958372056484222
epoch 6800  training loss: 0.029936999082565308
epoch 6800  clean testing loss: 0.11100418120622635
epoch 6900  training loss: 0.029293522238731384
epoch 6900  clean testing loss: 0.11510410159826279
epoch 7000  training loss: 0.03005692921578884
epoch 7000  clean testing loss: 0.1239834576845169
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 7100  training loss: 0.030908090993762016
epoch 7100  clean testing loss: 0.11715858429670334
epoch 7200  training loss: 0.03042890504002571
epoch 7200  clean testing loss: 0.12010165303945541
epoch 7300  training loss: 0.029056664556264877
epoch 7300  clean testing loss: 0.11591928452253342
epoch 7400  training loss: 0.04291604086756706
epoch 7400  clean testing loss: 0.10983788967132568
epoch 7500  training loss: 0.029147766530513763

  9%|▊         | 8564/100000 [00:15<02:43, 559.96it/s]
epoch 7600  training loss: 0.03046557866036892
epoch 7600  clean testing loss: 0.11733885854482651
epoch 7700  training loss: 0.0302138552069664
epoch 7700  clean testing loss: 0.11102286726236343
epoch 7800  training loss: 0.029273800551891327
epoch 7800  clean testing loss: 0.1157921701669693
epoch 7900  training loss: 0.030024489387869835
epoch 7900  clean testing loss: 0.11136727780103683
epoch 8000  training loss: 0.028879808261990547
epoch 8000  clean testing loss: 0.1159040778875351
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 8100  training loss: 0.02908230945467949
epoch 8100  clean testing loss: 0.11312919110059738
epoch 8200  training loss: 0.030435489490628242
epoch 8200  clean testing loss: 0.10561753064393997
epoch 8300  training loss: 0.030576828867197037
epoch 8300  clean testing loss: 0.1205231174826622
epoch 8400  training loss: 0.03221166878938675
epoch 8400  clean testing loss: 0.10341826826334
epoch 8500  training loss: 0.029642337933182716
epoch 8500  clean testing loss: 0.11523332446813583
epoch 8600  training loss: 0.03423802927136421

 10%|▉         | 9640/100000 [00:17<02:41, 558.79it/s]
epoch 8700  training loss: 0.03666367381811142
epoch 8700  clean testing loss: 0.09558876603841782
epoch 8800  training loss: 0.02909264527261257
epoch 8800  clean testing loss: 0.11877977848052979
epoch 8900  training loss: 0.029859572649002075
epoch 8900  clean testing loss: 0.11459138244390488
epoch 9000  training loss: 0.03272044286131859
epoch 9000  clean testing loss: 0.1050872951745987
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 9100  training loss: 0.028884755447506905
epoch 9100  clean testing loss: 0.11057524383068085
epoch 9200  training loss: 0.028845908120274544
epoch 9200  clean testing loss: 0.11280574649572372
epoch 9300  training loss: 0.02960975095629692
epoch 9300  clean testing loss: 0.10926370322704315
epoch 9400  training loss: 0.02853993885219097
epoch 9400  clean testing loss: 0.11605553328990936
epoch 9500  training loss: 0.02938941866159439
epoch 9500  clean testing loss: 0.1142413318157196
epoch 9600  training loss: 0.028842585161328316
epoch 9600  clean testing loss: 0.11661441624164581
epoch 9700  training loss: 0.0301638413220644

 11%|█         | 10776/100000 [00:19<02:38, 561.64it/s]
epoch 9800  training loss: 0.034693893045186996
epoch 9800  clean testing loss: 0.1019628494977951
epoch 9900  training loss: 0.03068334050476551
epoch 9900  clean testing loss: 0.11476602405309677
epoch 10000  training loss: 0.029468240216374397
epoch 10000  clean testing loss: 0.11507543921470642
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 10100  training loss: 0.029244031757116318
epoch 10100  clean testing loss: 0.11444500833749771
epoch 10200  training loss: 0.030677270144224167
epoch 10200  clean testing loss: 0.12324290722608566
epoch 10300  training loss: 0.030043087899684906
epoch 10300  clean testing loss: 0.12723611295223236
epoch 10400  training loss: 0.029494337737560272
epoch 10400  clean testing loss: 0.11668121069669724
epoch 10500  training loss: 0.028981341049075127
epoch 10500  clean testing loss: 0.12469737976789474
epoch 10600  training loss: 0.02913011983036995
epoch 10600  clean testing loss: 0.1255044937133789
epoch 10700  training loss: 0.030570799484848976
epoch 10700  clean testing loss: 0.11017081141471863
epoch 10800  training loss: 0.02907230332493782

 12%|█▏        | 11859/100000 [00:21<02:36, 562.22it/s]
epoch 10900  training loss: 0.02915787138044834
epoch 10900  clean testing loss: 0.10951483249664307
epoch 11000  training loss: 0.032953858375549316
epoch 11000  clean testing loss: 0.11998675763607025
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 11100  training loss: 0.029187951236963272
epoch 11100  clean testing loss: 0.11689132452011108
epoch 11200  training loss: 0.02878764271736145
epoch 11200  clean testing loss: 0.12129297107458115
epoch 11300  training loss: 0.03171386942267418
epoch 11300  clean testing loss: 0.11136981844902039
epoch 11400  training loss: 0.02945389226078987
epoch 11400  clean testing loss: 0.11304794996976852
epoch 11500  training loss: 0.02959350310266018
epoch 11500  clean testing loss: 0.11318988353013992
epoch 11600  training loss: 0.02862817607820034
epoch 11600  clean testing loss: 0.12562918663024902
epoch 11700  training loss: 0.028438901528716087
epoch 11700  clean testing loss: 0.11768150329589844
epoch 11800  training loss: 0.028512191027402878
epoch 11800  clean testing loss: 0.11288779228925705
epoch 11900  training loss: 0.03333320468664169

 13%|█▎        | 12882/100000 [00:23<02:35, 561.07it/s]
epoch 12000  training loss: 0.028489932417869568
epoch 12000  clean testing loss: 0.11484269052743912
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 12100  training loss: 0.028598854318261147
epoch 12100  clean testing loss: 0.11905582249164581
epoch 12200  training loss: 0.02825322560966015
epoch 12200  clean testing loss: 0.11598779261112213
epoch 12300  training loss: 0.028311319649219513
epoch 12300  clean testing loss: 0.11805505305528641
epoch 12400  training loss: 0.02841009944677353
epoch 12400  clean testing loss: 0.11442790925502777
epoch 12500  training loss: 0.02873988077044487
epoch 12500  clean testing loss: 0.11557900905609131
epoch 12600  training loss: 0.028530966490507126
epoch 12600  clean testing loss: 0.12036839872598648
epoch 12700  training loss: 0.028708450496196747
epoch 12700  clean testing loss: 0.12453543394804001
epoch 12800  training loss: 0.028455529361963272

 14%|█▍        | 14076/100000 [00:25<02:35, 553.01it/s]
epoch 12900  training loss: 0.028378533199429512
epoch 12900  clean testing loss: 0.11404985189437866
epoch 13000  training loss: 0.028320716693997383
epoch 13000  clean testing loss: 0.11700290441513062
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 13100  training loss: 0.02834010124206543
epoch 13100  clean testing loss: 0.11482036113739014
epoch 13200  training loss: 0.029270227998495102
epoch 13200  clean testing loss: 0.11685985326766968
epoch 13300  training loss: 0.028610890731215477
epoch 13300  clean testing loss: 0.11742473393678665
epoch 13400  training loss: 0.03003857098519802
epoch 13400  clean testing loss: 0.11495021730661392
epoch 13500  training loss: 0.028270550072193146
epoch 13500  clean testing loss: 0.12029363214969635
epoch 13600  training loss: 0.028578033670783043
epoch 13600  clean testing loss: 0.11978454142808914
epoch 13700  training loss: 0.02872895635664463
epoch 13700  clean testing loss: 0.11417032033205032
epoch 13800  training loss: 0.029692286625504494
epoch 13800  clean testing loss: 0.11160773038864136
epoch 13900  training loss: 0.029814252629876137
epoch 13900  clean testing loss: 0.10735580325126648
epoch 14000  training loss: 0.028757108375430107
epoch 14000  clean testing loss: 0.11912185698747635
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 14100  training loss: 0.03069392777979374

 15%|█▌        | 15149/100000 [00:27<02:33, 553.69it/s]
epoch 14200  training loss: 0.028246641159057617
epoch 14200  clean testing loss: 0.11620283126831055
epoch 14300  training loss: 0.02809137850999832
epoch 14300  clean testing loss: 0.11999975144863129
epoch 14400  training loss: 0.02985452674329281
epoch 14400  clean testing loss: 0.12046297639608383
epoch 14500  training loss: 0.029832711443305016
epoch 14500  clean testing loss: 0.11236691474914551
epoch 14600  training loss: 0.03359163552522659
epoch 14600  clean testing loss: 0.11585754156112671
epoch 14700  training loss: 0.029066303744912148
epoch 14700  clean testing loss: 0.11803848296403885
epoch 14800  training loss: 0.0283203087747097
epoch 14800  clean testing loss: 0.11819344013929367
epoch 14900  training loss: 0.02926606871187687
epoch 14900  clean testing loss: 0.11326339840888977
epoch 15000  training loss: 0.0288507342338562
epoch 15000  clean testing loss: 0.11502300202846527
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 15100  training loss: 0.02820068784058094
epoch 15100  clean testing loss: 0.11783143132925034
epoch 15200  training loss: 0.02874930575489998
 16%|█▌        | 15830/100000 [00:28<02:32, 552.85it/s]wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3 seconds.), retrying request
 16%|█▋        | 16286/100000 [00:29<02:29, 558.79it/s]
epoch 15300  training loss: 0.02819182723760605
epoch 15300  clean testing loss: 0.11887731403112411
epoch 15400  training loss: 0.02811466157436371
epoch 15400  clean testing loss: 0.11951039731502533
epoch 15500  training loss: 0.028077000752091408
epoch 15500  clean testing loss: 0.12083742022514343
epoch 15600  training loss: 0.028413571417331696
epoch 15600  clean testing loss: 0.11729907989501953
epoch 15700  training loss: 0.028748704120516777
epoch 15700  clean testing loss: 0.11801864206790924
epoch 15800  training loss: 0.028374671936035156
epoch 15800  clean testing loss: 0.11781015247106552
epoch 15900  training loss: 0.02815304510295391
epoch 15900  clean testing loss: 0.12160226702690125
epoch 16000  training loss: 0.028247561305761337
epoch 16000  clean testing loss: 0.11772160977125168
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 16100  training loss: 0.028095755726099014
epoch 16100  clean testing loss: 0.1167462095618248
epoch 16200  training loss: 0.028363699093461037
epoch 16200  clean testing loss: 0.11523281037807465
epoch 16300  training loss: 0.02883441187441349

 17%|█▋        | 17417/100000 [00:31<02:28, 557.23it/s]
epoch 16400  training loss: 0.028985384851694107
epoch 16400  clean testing loss: 0.1217140331864357
epoch 16500  training loss: 0.028427500277757645
epoch 16500  clean testing loss: 0.11826523393392563
epoch 16600  training loss: 0.028805701062083244
epoch 16600  clean testing loss: 0.11575168371200562
epoch 16700  training loss: 0.028186121955513954
epoch 16700  clean testing loss: 0.11843184381723404
epoch 16800  training loss: 0.029486555606126785
epoch 16800  clean testing loss: 0.1133638471364975
epoch 16900  training loss: 0.03237389028072357
epoch 16900  clean testing loss: 0.10905548185110092
epoch 17000  training loss: 0.028503678739070892
epoch 17000  clean testing loss: 0.11402160674333572
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 17100  training loss: 0.028825219720602036
epoch 17100  clean testing loss: 0.12252994626760483
epoch 17200  training loss: 0.028293145820498466
epoch 17200  clean testing loss: 0.11639294028282166
epoch 17300  training loss: 0.028639711439609528
epoch 17300  clean testing loss: 0.11447325348854065
epoch 17400  training loss: 0.028014229610562325

 18%|█▊        | 18495/100000 [00:33<02:24, 562.79it/s]
epoch 17500  training loss: 0.027960117906332016
epoch 17500  clean testing loss: 0.11718351393938065
epoch 17600  training loss: 0.02821844443678856
epoch 17600  clean testing loss: 0.11960645765066147
epoch 17700  training loss: 0.02802889607846737
epoch 17700  clean testing loss: 0.12094784528017044
epoch 17800  training loss: 0.028729146346449852
epoch 17800  clean testing loss: 0.12019578367471695
epoch 17900  training loss: 0.028139542788267136
epoch 17900  clean testing loss: 0.12412514537572861
epoch 18000  training loss: 0.02799481339752674
epoch 18000  clean testing loss: 0.11449668556451797
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 18100  training loss: 0.02794470451772213
epoch 18100  clean testing loss: 0.11853212863206863
epoch 18200  training loss: 0.02813437394797802
epoch 18200  clean testing loss: 0.11688007414340973
epoch 18300  training loss: 0.027993420138955116
epoch 18300  clean testing loss: 0.12009557336568832
epoch 18400  training loss: 0.02822706662118435
epoch 18400  clean testing loss: 0.11780763417482376
epoch 18500  training loss: 0.027875445783138275

 20%|█▉        | 19633/100000 [00:35<02:23, 559.20it/s]
epoch 18600  training loss: 0.02790588140487671
epoch 18600  clean testing loss: 0.1182384192943573
epoch 18700  training loss: 0.028235606849193573
epoch 18700  clean testing loss: 0.11467450857162476
epoch 18800  training loss: 0.027866220101714134
epoch 18800  clean testing loss: 0.11786056309938431
epoch 18900  training loss: 0.02805483341217041
epoch 18900  clean testing loss: 0.11682490259408951
epoch 19000  training loss: 0.02874821051955223
epoch 19000  clean testing loss: 0.12287570536136627
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 19100  training loss: 0.028552722185850143
epoch 19100  clean testing loss: 0.11804395169019699
epoch 19200  training loss: 0.0278855599462986
epoch 19200  clean testing loss: 0.1202315241098404
epoch 19300  training loss: 0.02784503623843193
epoch 19300  clean testing loss: 0.1209392324090004
epoch 19400  training loss: 0.028087876737117767
epoch 19400  clean testing loss: 0.11961814761161804
epoch 19500  training loss: 0.02804618515074253
epoch 19500  clean testing loss: 0.11741586774587631
epoch 19600  training loss: 0.028112763538956642

 21%|██        | 20714/100000 [00:37<02:22, 556.81it/s]
epoch 19700  training loss: 0.02785670757293701
epoch 19700  clean testing loss: 0.11751005053520203
epoch 19800  training loss: 0.028259605169296265
epoch 19800  clean testing loss: 0.1144651547074318
epoch 19900  training loss: 0.02808939851820469
epoch 19900  clean testing loss: 0.11946689337491989
epoch 20000  training loss: 0.02795443870127201
epoch 20000  clean testing loss: 0.12339941412210464
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 20100  training loss: 0.028580622747540474
epoch 20100  clean testing loss: 0.11808320134878159
epoch 20200  training loss: 0.027941234409809113
epoch 20200  clean testing loss: 0.11629656702280045
epoch 20300  training loss: 0.027904024347662926
epoch 20300  clean testing loss: 0.11791488528251648
epoch 20400  training loss: 0.028085937723517418
epoch 20400  clean testing loss: 0.11778464913368225
epoch 20500  training loss: 0.028276562690734863
epoch 20500  clean testing loss: 0.11932279169559479
epoch 20600  training loss: 0.027800504118204117
epoch 20600  clean testing loss: 0.11988596618175507
epoch 20700  training loss: 0.02820911630988121
epoch 20700  clean testing loss: 0.11574246734380722
epoch 20800  training loss: 0.02839609980583191

 22%|██▏       | 21848/100000 [00:39<02:20, 555.21it/s]
epoch 20900  training loss: 0.027968158945441246
epoch 20900  clean testing loss: 0.11589930951595306
epoch 21000  training loss: 0.028401069343090057
epoch 21000  clean testing loss: 0.11630582809448242
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 21100  training loss: 0.027901191264390945
epoch 21100  clean testing loss: 0.11602509021759033
epoch 21200  training loss: 0.027957169339060783
epoch 21200  clean testing loss: 0.11901631206274033
epoch 21300  training loss: 0.0278337225317955
epoch 21300  clean testing loss: 0.12079645693302155
epoch 21400  training loss: 0.02810823917388916
epoch 21400  clean testing loss: 0.1137830913066864
epoch 21500  training loss: 0.027778975665569305
epoch 21500  clean testing loss: 0.11668989807367325
epoch 21600  training loss: 0.027963008731603622
epoch 21600  clean testing loss: 0.11726430803537369
epoch 21700  training loss: 0.027772847563028336
epoch 21700  clean testing loss: 0.11875840276479721
epoch 21800  training loss: 0.028857383877038956
epoch 21800  clean testing loss: 0.11841770261526108
epoch 21900  training loss: 0.028081264346837997

 23%|██▎       | 22985/100000 [00:41<02:17, 558.18it/s]
epoch 22000  training loss: 0.028071431443095207
epoch 22000  clean testing loss: 0.1192711889743805
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 22100  training loss: 0.02781633287668228
epoch 22100  clean testing loss: 0.11994291841983795
epoch 22200  training loss: 0.028178218752145767
epoch 22200  clean testing loss: 0.11529232561588287
epoch 22300  training loss: 0.02796724997460842
epoch 22300  clean testing loss: 0.11902166903018951
epoch 22400  training loss: 0.027731534093618393
epoch 22400  clean testing loss: 0.11941640824079514
epoch 22500  training loss: 0.027873791754245758
epoch 22500  clean testing loss: 0.11848943680524826
epoch 22600  training loss: 0.028104685246944427
epoch 22600  clean testing loss: 0.1197725459933281
epoch 22700  training loss: 0.027935797348618507
epoch 22700  clean testing loss: 0.11770164221525192
epoch 22800  training loss: 0.028095725923776627
epoch 22800  clean testing loss: 0.11998426169157028
epoch 22900  training loss: 0.027848239988088608
epoch 22900  clean testing loss: 0.11958929896354675
epoch 23000  training loss: 0.02828129194676876
epoch 23000  clean testing loss: 0.12033521384000778

 24%|██▍       | 24061/100000 [00:43<02:17, 553.91it/s]
epoch 23100  training loss: 0.027949269860982895
epoch 23100  clean testing loss: 0.11699952930212021
epoch 23200  training loss: 0.027955085039138794
epoch 23200  clean testing loss: 0.11561374366283417
epoch 23300  training loss: 0.027990514412522316
epoch 23300  clean testing loss: 0.11876972764730453
epoch 23400  training loss: 0.027811050415039062
epoch 23400  clean testing loss: 0.1188458800315857
epoch 23500  training loss: 0.027855297550559044
epoch 23500  clean testing loss: 0.12266617268323898
epoch 23600  training loss: 0.027782507240772247
epoch 23600  clean testing loss: 0.12470988929271698
epoch 23700  training loss: 0.027928192168474197
epoch 23700  clean testing loss: 0.12095620483160019
epoch 23800  training loss: 0.027819799259305
epoch 23800  clean testing loss: 0.11742570251226425
epoch 23900  training loss: 0.027907060459256172
epoch 23900  clean testing loss: 0.11988814175128937
epoch 24000  training loss: 0.027863286435604095
epoch 24000  clean testing loss: 0.1206163689494133
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 24100  training loss: 0.027989907190203667

 25%|██▌       | 25191/100000 [00:45<02:13, 558.44it/s]
epoch 24200  training loss: 0.027667973190546036
epoch 24200  clean testing loss: 0.11842112988233566
epoch 24300  training loss: 0.027722317725419998
epoch 24300  clean testing loss: 0.12329667806625366
epoch 24400  training loss: 0.028107909485697746
epoch 24400  clean testing loss: 0.11799206584692001
epoch 24500  training loss: 0.027917103841900826
epoch 24500  clean testing loss: 0.11848024278879166
epoch 24600  training loss: 0.027805270627141
epoch 24600  clean testing loss: 0.12344337999820709
epoch 24700  training loss: 0.027745604515075684
epoch 24700  clean testing loss: 0.1158551350235939
epoch 24800  training loss: 0.028004087507724762
epoch 24800  clean testing loss: 0.1200326681137085
epoch 24900  training loss: 0.027716536074876785
epoch 24900  clean testing loss: 0.11939622461795807
epoch 25000  training loss: 0.02778262086212635
epoch 25000  clean testing loss: 0.1179017424583435
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 25100  training loss: 0.027859237045049667
epoch 25100  clean testing loss: 0.11971375346183777
epoch 25200  training loss: 0.027718104422092438

 26%|██▋       | 26266/100000 [00:47<02:11, 559.08it/s]
epoch 25300  training loss: 0.027702560648322105
epoch 25300  clean testing loss: 0.11691509187221527
epoch 25400  training loss: 0.028282659128308296
epoch 25400  clean testing loss: 0.1152866929769516
epoch 25500  training loss: 0.02768278308212757
epoch 25500  clean testing loss: 0.11989172548055649
epoch 25600  training loss: 0.027658728882670403
epoch 25600  clean testing loss: 0.11880256980657578
epoch 25700  training loss: 0.02784149907529354
epoch 25700  clean testing loss: 0.11661973595619202
epoch 25800  training loss: 0.027758372947573662
epoch 25800  clean testing loss: 0.11937621980905533
epoch 25900  training loss: 0.02803904190659523
epoch 25900  clean testing loss: 0.11810576915740967
epoch 26000  training loss: 0.027636002749204636
epoch 26000  clean testing loss: 0.11983699351549149
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 26100  training loss: 0.0276412982493639
epoch 26100  clean testing loss: 0.12088479846715927
epoch 26200  training loss: 0.027813410386443138
epoch 26200  clean testing loss: 0.11939294636249542
epoch 26300  training loss: 0.028304925188422203

 27%|██▋       | 27401/100000 [00:49<02:10, 557.97it/s]
epoch 26400  training loss: 0.027790497988462448
epoch 26400  clean testing loss: 0.12240525335073471
epoch 26500  training loss: 0.027766846120357513
epoch 26500  clean testing loss: 0.11937551200389862
epoch 26600  training loss: 0.02772609330713749
epoch 26600  clean testing loss: 0.12196023017168045
epoch 26700  training loss: 0.027899494394659996
epoch 26700  clean testing loss: 0.11766811460256577
epoch 26800  training loss: 0.02771763503551483
epoch 26800  clean testing loss: 0.12231091409921646
epoch 26900  training loss: 0.02770952321588993
epoch 26900  clean testing loss: 0.1222831979393959
epoch 27000  training loss: 0.028112879022955894
epoch 27000  clean testing loss: 0.11768447607755661
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 27100  training loss: 0.027651004493236542
epoch 27100  clean testing loss: 0.1179884523153305
epoch 27200  training loss: 0.027601908892393112
epoch 27200  clean testing loss: 0.11903230100870132
epoch 27300  training loss: 0.02770148776471615
epoch 27300  clean testing loss: 0.12066294997930527
epoch 27400  training loss: 0.027690138667821884

 29%|██▊       | 28533/100000 [00:51<02:08, 556.77it/s]
epoch 27500  training loss: 0.02786044217646122
epoch 27500  clean testing loss: 0.11801329255104065
epoch 27600  training loss: 0.02763323299586773
epoch 27600  clean testing loss: 0.12006543576717377
epoch 27700  training loss: 0.027660874649882317
epoch 27700  clean testing loss: 0.11824072897434235
epoch 27800  training loss: 0.02769370563328266
epoch 27800  clean testing loss: 0.1174299567937851
epoch 27900  training loss: 0.027855610474944115
epoch 27900  clean testing loss: 0.1177433654665947
epoch 28000  training loss: 0.027634071186184883
epoch 28000  clean testing loss: 0.11976161599159241
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 28100  training loss: 0.02764943614602089
epoch 28100  clean testing loss: 0.1202499270439148
epoch 28200  training loss: 0.02761659026145935
epoch 28200  clean testing loss: 0.11825817078351974
epoch 28300  training loss: 0.027890359982848167
epoch 28300  clean testing loss: 0.11767730116844177
epoch 28400  training loss: 0.027679523453116417
epoch 28400  clean testing loss: 0.12170692533254623
epoch 28500  training loss: 0.027569182217121124

 30%|██▉       | 29604/100000 [00:53<02:06, 556.12it/s]
epoch 28600  training loss: 0.027810951694846153
epoch 28600  clean testing loss: 0.11900680512189865
epoch 28700  training loss: 0.027781357988715172
epoch 28700  clean testing loss: 0.11840886622667313
epoch 28800  training loss: 0.027597470209002495
epoch 28800  clean testing loss: 0.12196715176105499
epoch 28900  training loss: 0.02778790332376957
epoch 28900  clean testing loss: 0.11955396085977554
epoch 29000  training loss: 0.027600429952144623
epoch 29000  clean testing loss: 0.12184705585241318
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 29100  training loss: 0.02758280746638775
epoch 29100  clean testing loss: 0.11818686872720718
epoch 29200  training loss: 0.027803855016827583
epoch 29200  clean testing loss: 0.11824377626180649
epoch 29300  training loss: 0.02774905227124691
epoch 29300  clean testing loss: 0.1215580403804779
epoch 29400  training loss: 0.02757362276315689
epoch 29400  clean testing loss: 0.12071303278207779
epoch 29500  training loss: 0.027655623853206635
epoch 29500  clean testing loss: 0.12163152545690536
epoch 29600  training loss: 0.02753826603293419

 31%|███       | 30675/100000 [00:55<02:04, 558.86it/s]
epoch 29700  training loss: 0.02764752134680748
epoch 29700  clean testing loss: 0.12019231170415878
epoch 29800  training loss: 0.02761443331837654
epoch 29800  clean testing loss: 0.1188221350312233
epoch 29900  training loss: 0.027884913608431816
epoch 29900  clean testing loss: 0.11780420690774918
epoch 30000  training loss: 0.02755207195878029
epoch 30000  clean testing loss: 0.1194879338145256
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 30100  training loss: 0.027550704777240753
epoch 30100  clean testing loss: 0.11944475024938583
epoch 30200  training loss: 0.02757704257965088
epoch 30200  clean testing loss: 0.12022244930267334
epoch 30300  training loss: 0.02755548804998398
epoch 30300  clean testing loss: 0.12062568217515945
epoch 30400  training loss: 0.027542976662516594
epoch 30400  clean testing loss: 0.11989638209342957
epoch 30500  training loss: 0.027730431407690048
epoch 30500  clean testing loss: 0.12029274553060532
epoch 30600  training loss: 0.027667595073580742
epoch 30600  clean testing loss: 0.12071391940116882
epoch 30700  training loss: 0.02753256820142269

 32%|███▏      | 31809/100000 [00:57<02:02, 557.23it/s]
epoch 30800  training loss: 0.02756250835955143
epoch 30800  clean testing loss: 0.11761727929115295
epoch 30900  training loss: 0.027657359838485718
epoch 30900  clean testing loss: 0.11979823559522629
epoch 31000  training loss: 0.027581986039876938
epoch 31000  clean testing loss: 0.11769285053014755
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 31100  training loss: 0.027522653341293335
epoch 31100  clean testing loss: 0.11847874522209167
epoch 31200  training loss: 0.027521569281816483
epoch 31200  clean testing loss: 0.11919037252664566
epoch 31300  training loss: 0.027564510703086853
epoch 31300  clean testing loss: 0.12095745652914047
epoch 31400  training loss: 0.027626194059848785
epoch 31400  clean testing loss: 0.11994241178035736
epoch 31500  training loss: 0.027510179206728935
epoch 31500  clean testing loss: 0.11900821328163147
epoch 31600  training loss: 0.027563337236642838
epoch 31600  clean testing loss: 0.11740582436323166
epoch 31700  training loss: 0.027568034827709198
epoch 31700  clean testing loss: 0.12095391005277634
epoch 31800  training loss: 0.02753850445151329

 33%|███▎      | 32942/100000 [00:59<02:00, 557.75it/s]
epoch 31900  training loss: 0.027617301791906357
epoch 31900  clean testing loss: 0.11963795125484467
epoch 32000  training loss: 0.027506522834300995
epoch 32000  clean testing loss: 0.11989597231149673
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 32100  training loss: 0.02755211852490902
epoch 32100  clean testing loss: 0.11946761608123779
epoch 32200  training loss: 0.027513369917869568
epoch 32200  clean testing loss: 0.12146572768688202
epoch 32300  training loss: 0.02762983925640583
epoch 32300  clean testing loss: 0.11838464438915253
epoch 32400  training loss: 0.027623258531093597
epoch 32400  clean testing loss: 0.11950601637363434
epoch 32500  training loss: 0.027593612670898438
epoch 32500  clean testing loss: 0.11941491812467575
epoch 32600  training loss: 0.027552494779229164
epoch 32600  clean testing loss: 0.12004686146974564
epoch 32700  training loss: 0.027546323835849762
epoch 32700  clean testing loss: 0.12001024186611176
epoch 32800  training loss: 0.027551641687750816
epoch 32800  clean testing loss: 0.11795618385076523
epoch 32900  training loss: 0.02757304534316063
epoch 32900  clean testing loss: 0.11938177049160004
epoch 33000  training loss: 0.027475247159600258

epoch 33000  clean testing loss: 0.12007097154855728
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 33100  training loss: 0.02752647176384926
epoch 33100  clean testing loss: 0.11918136477470398
epoch 33200  training loss: 0.027472905814647675
epoch 33200  clean testing loss: 0.11932960152626038
epoch 33300  training loss: 0.027500012889504433
epoch 33300  clean testing loss: 0.11837238073348999
epoch 33400  training loss: 0.027513591572642326
epoch 33400  clean testing loss: 0.12035026401281357
epoch 33500  training loss: 0.027514399960637093
epoch 33500  clean testing loss: 0.1201920360326767
epoch 33600  training loss: 0.027505865320563316
epoch 33600  clean testing loss: 0.12039516866207123
epoch 33700  training loss: 0.02752518653869629
epoch 33700  clean testing loss: 0.12075452506542206
epoch 33800  training loss: 0.02752532623708248
epoch 33800  clean testing loss: 0.11890984326601028
epoch 33900  training loss: 0.02758527174592018
epoch 33900  clean testing loss: 0.11886685341596603
epoch 34000  training loss: 0.027538582682609558
epoch 34000  clean testing loss: 0.11898402869701385
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 34100  training loss: 0.027556922286748886

 35%|███▌      | 35158/100000 [01:03<01:56, 556.42it/s]
epoch 34200  training loss: 0.027524983510375023
epoch 34200  clean testing loss: 0.1187838688492775
epoch 34300  training loss: 0.027468379586935043
epoch 34300  clean testing loss: 0.12047294527292252
epoch 34400  training loss: 0.027495360001921654
epoch 34400  clean testing loss: 0.11966189742088318
epoch 34500  training loss: 0.027520570904016495
epoch 34500  clean testing loss: 0.1204167827963829
epoch 34600  training loss: 0.027469458058476448
epoch 34600  clean testing loss: 0.1191289871931076
epoch 34700  training loss: 0.027452316135168076
epoch 34700  clean testing loss: 0.11967429518699646
epoch 34800  training loss: 0.027502642944455147
epoch 34800  clean testing loss: 0.11909700185060501
epoch 34900  training loss: 0.027467645704746246
epoch 34900  clean testing loss: 0.12080997228622437
epoch 35000  training loss: 0.02748267538845539
epoch 35000  clean testing loss: 0.11793071776628494
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 35100  training loss: 0.02747470885515213
epoch 35100  clean testing loss: 0.12153896689414978
epoch 35200  training loss: 0.02755081094801426

 36%|███▌      | 36233/100000 [01:05<01:55, 554.39it/s]
epoch 35300  training loss: 0.027543488889932632
epoch 35300  clean testing loss: 0.12043125182390213
epoch 35400  training loss: 0.027514394372701645
epoch 35400  clean testing loss: 0.11965452879667282
epoch 35500  training loss: 0.027482913807034492
epoch 35500  clean testing loss: 0.11844979971647263
epoch 35600  training loss: 0.027478376403450966
epoch 35600  clean testing loss: 0.12026550620794296
epoch 35700  training loss: 0.027518639340996742
epoch 35700  clean testing loss: 0.11812939494848251
epoch 35800  training loss: 0.02744111977517605
epoch 35800  clean testing loss: 0.12132774293422699
epoch 35900  training loss: 0.0274704210460186
epoch 35900  clean testing loss: 0.1218765452504158
epoch 36000  training loss: 0.027523459866642952
epoch 36000  clean testing loss: 0.12016357481479645
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 36100  training loss: 0.027427123859524727
epoch 36100  clean testing loss: 0.12020039558410645
epoch 36200  training loss: 0.027470353990793228
epoch 36200  clean testing loss: 0.11903989315032959
epoch 36300  training loss: 0.027439722791314125

 37%|███▋      | 37366/100000 [01:07<01:51, 559.30it/s]
epoch 36400  training loss: 0.02751719020307064
epoch 36400  clean testing loss: 0.11870574951171875
epoch 36500  training loss: 0.027487333863973618
epoch 36500  clean testing loss: 0.11891843378543854
epoch 36600  training loss: 0.027433566749095917
epoch 36600  clean testing loss: 0.11960997432470322
epoch 36700  training loss: 0.027421707287430763
epoch 36700  clean testing loss: 0.11990116536617279
epoch 36800  training loss: 0.027458472177386284
epoch 36800  clean testing loss: 0.11880981177091599
epoch 36900  training loss: 0.027455639094114304
epoch 36900  clean testing loss: 0.11925704032182693
epoch 37000  training loss: 0.02741974964737892
epoch 37000  clean testing loss: 0.12083736062049866
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 37100  training loss: 0.027483191341161728
epoch 37100  clean testing loss: 0.11941365897655487
epoch 37200  training loss: 0.02750411443412304
epoch 37200  clean testing loss: 0.1194479689002037
epoch 37300  training loss: 0.027451571077108383
epoch 37300  clean testing loss: 0.12103582173585892
epoch 37400  training loss: 0.027454392984509468

 38%|███▊      | 38499/100000 [01:09<01:49, 561.42it/s]
epoch 37500  training loss: 0.027453741058707237
epoch 37500  clean testing loss: 0.12024041265249252
epoch 37600  training loss: 0.027453619986772537
epoch 37600  clean testing loss: 0.12042781710624695
epoch 37700  training loss: 0.027419814839959145
epoch 37700  clean testing loss: 0.11943357437849045
epoch 37800  training loss: 0.027461165562272072
epoch 37800  clean testing loss: 0.12127536535263062
epoch 37900  training loss: 0.027418166399002075
epoch 37900  clean testing loss: 0.11976249516010284
epoch 38000  training loss: 0.027431050315499306
epoch 38000  clean testing loss: 0.11934193968772888
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 38100  training loss: 0.027433322742581367
epoch 38100  clean testing loss: 0.12121491134166718
epoch 38200  training loss: 0.027500076219439507
epoch 38200  clean testing loss: 0.1196867898106575
epoch 38300  training loss: 0.027393391355872154
epoch 38300  clean testing loss: 0.12005919963121414
epoch 38400  training loss: 0.027441438287496567
epoch 38400  clean testing loss: 0.11997408419847488
epoch 38500  training loss: 0.027407078072428703

 40%|███▉      | 39576/100000 [01:11<01:47, 562.26it/s]
epoch 38600  training loss: 0.027388930320739746
epoch 38600  clean testing loss: 0.12007845938205719
epoch 38700  training loss: 0.027402451261878014
epoch 38700  clean testing loss: 0.12097908556461334
epoch 38800  training loss: 0.02738901600241661
epoch 38800  clean testing loss: 0.12126985937356949
epoch 38900  training loss: 0.027463845908641815
epoch 38900  clean testing loss: 0.12120845168828964
epoch 39000  training loss: 0.027495769783854485
epoch 39000  clean testing loss: 0.12060429155826569
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 39100  training loss: 0.02741135098040104
epoch 39100  clean testing loss: 0.11955830454826355
epoch 39200  training loss: 0.027382344007492065
epoch 39200  clean testing loss: 0.12128568440675735
epoch 39300  training loss: 0.027383551001548767
epoch 39300  clean testing loss: 0.1214682012796402
epoch 39400  training loss: 0.027385815978050232
epoch 39400  clean testing loss: 0.12076829373836517
epoch 39500  training loss: 0.02739325538277626
epoch 39500  clean testing loss: 0.12143344432115555
epoch 39600  training loss: 0.02739819698035717

 41%|████      | 40654/100000 [01:13<01:46, 558.36it/s]
epoch 39700  training loss: 0.02739936113357544
epoch 39700  clean testing loss: 0.12108751386404037
epoch 39800  training loss: 0.02738594450056553
epoch 39800  clean testing loss: 0.12151849269866943
epoch 39900  training loss: 0.02741304039955139
epoch 39900  clean testing loss: 0.11960694938898087
epoch 40000  training loss: 0.027429994195699692
epoch 40000  clean testing loss: 0.12168633192777634
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 40100  training loss: 0.02739187702536583
epoch 40100  clean testing loss: 0.12010155618190765
epoch 40200  training loss: 0.027404235675930977
epoch 40200  clean testing loss: 0.12210699170827866
epoch 40300  training loss: 0.027372481301426888
epoch 40300  clean testing loss: 0.12088663130998611
epoch 40400  training loss: 0.027408752590417862
epoch 40400  clean testing loss: 0.11969421058893204
epoch 40500  training loss: 0.02741246484220028
epoch 40500  clean testing loss: 0.12096544355154037
epoch 40600  training loss: 0.02735430747270584
epoch 40600  clean testing loss: 0.12049184739589691
epoch 40700  training loss: 0.027373120188713074

 42%|████▏     | 41842/100000 [01:15<01:44, 558.38it/s]
epoch 40800  training loss: 0.02734549529850483
epoch 40800  clean testing loss: 0.12131698429584503
epoch 40900  training loss: 0.027425002306699753
epoch 40900  clean testing loss: 0.12108390778303146
epoch 41000  training loss: 0.027365421876311302
epoch 41000  clean testing loss: 0.12095697224140167
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 41100  training loss: 0.027379702776670456
epoch 41100  clean testing loss: 0.12102954834699631
epoch 41200  training loss: 0.02736780047416687
epoch 41200  clean testing loss: 0.12098349630832672
epoch 41300  training loss: 0.02740224078297615
epoch 41300  clean testing loss: 0.12112370878458023
epoch 41400  training loss: 0.027371499687433243
epoch 41400  clean testing loss: 0.12114032357931137
epoch 41500  training loss: 0.027331991121172905
epoch 41500  clean testing loss: 0.12090345472097397
epoch 41600  training loss: 0.02742597833275795
epoch 41600  clean testing loss: 0.12022025883197784
epoch 41700  training loss: 0.027368325740098953
epoch 41700  clean testing loss: 0.12219810485839844
epoch 41800  training loss: 0.027337757870554924
epoch 41800  clean testing loss: 0.12050452828407288
epoch 41900  training loss: 0.027368199080228806

 43%|████▎     | 42919/100000 [01:17<01:42, 557.44it/s]
epoch 42000  training loss: 0.027373692020773888
epoch 42000  clean testing loss: 0.12138525396585464
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 42100  training loss: 0.02731354348361492
epoch 42100  clean testing loss: 0.1212163120508194
epoch 42200  training loss: 0.027330290526151657
epoch 42200  clean testing loss: 0.12155457586050034
epoch 42300  training loss: 0.027317389845848083
epoch 42300  clean testing loss: 0.12195491790771484
epoch 42400  training loss: 0.02731882594525814
epoch 42400  clean testing loss: 0.12154748290777206
epoch 42500  training loss: 0.02731606736779213
epoch 42500  clean testing loss: 0.1209152415394783
epoch 42600  training loss: 0.027311405166983604
epoch 42600  clean testing loss: 0.12118922173976898
epoch 42700  training loss: 0.027316588908433914
epoch 42700  clean testing loss: 0.12203923612833023
epoch 42800  training loss: 0.027297599241137505
epoch 42800  clean testing loss: 0.12210510671138763
epoch 42900  training loss: 0.027304232120513916
epoch 42900  clean testing loss: 0.12150903791189194
epoch 43000  training loss: 0.02729344740509987
epoch 43000  clean testing loss: 0.12094684690237045

 44%|████▍     | 44053/100000 [01:19<01:42, 546.90it/s]
epoch 43100  training loss: 0.027324533089995384
epoch 43100  clean testing loss: 0.1216355487704277
epoch 43200  training loss: 0.027301928028464317
epoch 43200  clean testing loss: 0.12240516394376755
epoch 43300  training loss: 0.027299711480736732
epoch 43300  clean testing loss: 0.12145411968231201
epoch 43400  training loss: 0.027327517047524452
epoch 43400  clean testing loss: 0.1220298483967781
epoch 43500  training loss: 0.027301916852593422
epoch 43500  clean testing loss: 0.12084817886352539
epoch 43600  training loss: 0.027287619188427925
epoch 43600  clean testing loss: 0.1218806654214859
epoch 43700  training loss: 0.02736039087176323
epoch 43700  clean testing loss: 0.12087532132863998
epoch 43800  training loss: 0.02730829268693924
epoch 43800  clean testing loss: 0.12053854018449783
epoch 43900  training loss: 0.02730630338191986
epoch 43900  clean testing loss: 0.12163837254047394
epoch 44000  training loss: 0.027311749756336212
epoch 44000  clean testing loss: 0.12149440497159958
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 44100  training loss: 0.027279814705252647

 45%|████▌     | 45128/100000 [01:21<01:39, 552.51it/s]
epoch 44200  training loss: 0.027341365814208984
epoch 44200  clean testing loss: 0.12098738551139832
epoch 44300  training loss: 0.027293693274259567
epoch 44300  clean testing loss: 0.12085633724927902
epoch 44400  training loss: 0.027290133759379387
epoch 44400  clean testing loss: 0.12207616865634918
epoch 44500  training loss: 0.027278374880552292
epoch 44500  clean testing loss: 0.12106694281101227
epoch 44600  training loss: 0.027294030413031578
epoch 44600  clean testing loss: 0.12161733210086823
epoch 44700  training loss: 0.027271868661046028
epoch 44700  clean testing loss: 0.1214650571346283
epoch 44800  training loss: 0.027277380228042603
epoch 44800  clean testing loss: 0.12193084508180618
epoch 44900  training loss: 0.027295593172311783
epoch 44900  clean testing loss: 0.1217658743262291
epoch 45000  training loss: 0.027269938960671425
epoch 45000  clean testing loss: 0.12114962935447693
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 45100  training loss: 0.027270562946796417
epoch 45100  clean testing loss: 0.12128153443336487
epoch 45200  training loss: 0.027256198227405548

 46%|████▋     | 46262/100000 [01:23<01:36, 557.60it/s]
epoch 45300  training loss: 0.027270395308732986
epoch 45300  clean testing loss: 0.1218654066324234
epoch 45400  training loss: 0.02729847840964794
epoch 45400  clean testing loss: 0.12172961235046387
epoch 45500  training loss: 0.02725941129028797
epoch 45500  clean testing loss: 0.1214124858379364
epoch 45600  training loss: 0.0272565558552742
epoch 45600  clean testing loss: 0.12218350917100906
epoch 45700  training loss: 0.027264617383480072
epoch 45700  clean testing loss: 0.12119676172733307
epoch 45800  training loss: 0.027262462303042412
epoch 45800  clean testing loss: 0.12143292278051376
epoch 45900  training loss: 0.027270980179309845
epoch 45900  clean testing loss: 0.12091609835624695
epoch 46000  training loss: 0.027292413637042046
epoch 46000  clean testing loss: 0.12201835215091705
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 46100  training loss: 0.02725466713309288
epoch 46100  clean testing loss: 0.1219259649515152
epoch 46200  training loss: 0.027249107137322426
epoch 46200  clean testing loss: 0.12228837609291077
epoch 46300  training loss: 0.02725585363805294

 47%|████▋     | 47335/100000 [01:25<01:35, 552.50it/s]
epoch 46400  training loss: 0.02724955976009369
epoch 46400  clean testing loss: 0.12247355282306671
epoch 46500  training loss: 0.027242369949817657
epoch 46500  clean testing loss: 0.12186184525489807
epoch 46600  training loss: 0.027277326211333275
epoch 46600  clean testing loss: 0.12187883257865906
epoch 46700  training loss: 0.02724475786089897
epoch 46700  clean testing loss: 0.1227894052863121
epoch 46800  training loss: 0.02724462002515793
epoch 46800  clean testing loss: 0.12218095362186432
epoch 46900  training loss: 0.02724703960120678
epoch 46900  clean testing loss: 0.12205029278993607
epoch 47000  training loss: 0.02725071646273136
epoch 47000  clean testing loss: 0.12157054990530014
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 47100  training loss: 0.027234259992837906
epoch 47100  clean testing loss: 0.12227409332990646
epoch 47200  training loss: 0.02723659947514534
epoch 47200  clean testing loss: 0.12250155955553055
epoch 47300  training loss: 0.02726609632372856
epoch 47300  clean testing loss: 0.12234197556972504
epoch 47400  training loss: 0.02724180556833744

 48%|████▊     | 48468/100000 [01:27<01:32, 560.01it/s]
epoch 47500  training loss: 0.027244439348578453
epoch 47500  clean testing loss: 0.12160424143075943
epoch 47600  training loss: 0.02722773514688015
epoch 47600  clean testing loss: 0.12175559997558594
epoch 47700  training loss: 0.027228619903326035
epoch 47700  clean testing loss: 0.12190788984298706
epoch 47800  training loss: 0.027243580669164658
epoch 47800  clean testing loss: 0.12176141142845154
epoch 47900  training loss: 0.02722083032131195
epoch 47900  clean testing loss: 0.12241119146347046
epoch 48000  training loss: 0.02729974500834942
epoch 48000  clean testing loss: 0.12237659096717834
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 48100  training loss: 0.027218252420425415
epoch 48100  clean testing loss: 0.12222479283809662
epoch 48200  training loss: 0.027224864810705185
epoch 48200  clean testing loss: 0.122128427028656
epoch 48300  training loss: 0.0272222887724638
epoch 48300  clean testing loss: 0.12190403044223785
epoch 48400  training loss: 0.027227256447076797
epoch 48400  clean testing loss: 0.12264429032802582
epoch 48500  training loss: 0.027224795892834663

 50%|████▉     | 49549/100000 [01:29<01:30, 558.72it/s]
epoch 48600  training loss: 0.027211934328079224
epoch 48600  clean testing loss: 0.12220176309347153
epoch 48700  training loss: 0.027223384007811546
epoch 48700  clean testing loss: 0.12254580855369568
epoch 48800  training loss: 0.027213850989937782
epoch 48800  clean testing loss: 0.12257194519042969
epoch 48900  training loss: 0.027235521003603935
epoch 48900  clean testing loss: 0.1221451386809349
epoch 49000  training loss: 0.027217311784625053
epoch 49000  clean testing loss: 0.12303632497787476
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 49100  training loss: 0.027210811153054237
epoch 49100  clean testing loss: 0.12263946980237961
epoch 49200  training loss: 0.027215881273150444
epoch 49200  clean testing loss: 0.12261365354061127
epoch 49300  training loss: 0.027221759781241417
epoch 49300  clean testing loss: 0.12215966731309891
epoch 49400  training loss: 0.02721405029296875
epoch 49400  clean testing loss: 0.12228944152593613
epoch 49500  training loss: 0.027227060869336128
epoch 49500  clean testing loss: 0.12289121001958847
epoch 49600  training loss: 0.027212247252464294

 51%|█████     | 50682/100000 [01:31<01:28, 558.86it/s]
epoch 49700  training loss: 0.027212118729948997
epoch 49700  clean testing loss: 0.12250639498233795
epoch 49800  training loss: 0.027218885719776154
epoch 49800  clean testing loss: 0.12259948253631592
epoch 49900  training loss: 0.027214208617806435
epoch 49900  clean testing loss: 0.12259643524885178
epoch 50000  training loss: 0.02721145562827587
epoch 50000  clean testing loss: 0.1227051168680191
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 50100  training loss: 0.02723003551363945
epoch 50100  clean testing loss: 0.1226593405008316
epoch 50200  training loss: 0.02723884955048561
epoch 50200  clean testing loss: 0.12278138846158981
epoch 50300  training loss: 0.02721216157078743
epoch 50300  clean testing loss: 0.12260495871305466
epoch 50400  training loss: 0.027222396805882454
epoch 50400  clean testing loss: 0.12217788398265839
epoch 50500  training loss: 0.027195405215024948
epoch 50500  clean testing loss: 0.1230868324637413
epoch 50600  training loss: 0.027206996455788612
epoch 50600  clean testing loss: 0.1226336807012558
epoch 50700  training loss: 0.02719801291823387

 52%|█████▏    | 51756/100000 [01:33<01:26, 557.48it/s]
epoch 50800  training loss: 0.027197405695915222
epoch 50800  clean testing loss: 0.12294125556945801
epoch 50900  training loss: 0.02719399891793728
epoch 50900  clean testing loss: 0.12294137477874756
epoch 51000  training loss: 0.027194814756512642
epoch 51000  clean testing loss: 0.12288345396518707
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 51100  training loss: 0.02719150483608246
epoch 51100  clean testing loss: 0.1227540448307991
epoch 51200  training loss: 0.02718302607536316
epoch 51200  clean testing loss: 0.12297876924276352
epoch 51300  training loss: 0.027174048125743866
epoch 51300  clean testing loss: 0.12297932058572769
epoch 51400  training loss: 0.027180800214409828
epoch 51400  clean testing loss: 0.12311990559101105
epoch 51500  training loss: 0.027180170640349388
epoch 51500  clean testing loss: 0.12295053899288177
epoch 51600  training loss: 0.027172956615686417
epoch 51600  clean testing loss: 0.12312989681959152
epoch 51700  training loss: 0.027172885835170746
epoch 51700  clean testing loss: 0.12313366681337357
epoch 51800  training loss: 0.02719060517847538

 53%|█████▎    | 52889/100000 [01:35<01:23, 562.42it/s]
epoch 51900  training loss: 0.027168430387973785
epoch 51900  clean testing loss: 0.12328265607357025
epoch 52000  training loss: 0.02718420885503292
epoch 52000  clean testing loss: 0.12308665364980698
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 52100  training loss: 0.027185354381799698
epoch 52100  clean testing loss: 0.12279729545116425
epoch 52200  training loss: 0.027167800813913345
epoch 52200  clean testing loss: 0.12308390438556671
epoch 52300  training loss: 0.0271735992282629
epoch 52300  clean testing loss: 0.12311749905347824
epoch 52400  training loss: 0.027165355160832405
epoch 52400  clean testing loss: 0.12342628091573715
epoch 52500  training loss: 0.027186857536435127
epoch 52500  clean testing loss: 0.12328394502401352
epoch 52600  training loss: 0.02716764435172081
epoch 52600  clean testing loss: 0.12311555445194244
epoch 52700  training loss: 0.027165323495864868
epoch 52700  clean testing loss: 0.12330375611782074
epoch 52800  training loss: 0.027164410799741745
epoch 52800  clean testing loss: 0.12328965216875076
epoch 52900  training loss: 0.02716802805662155

 54%|█████▍    | 54023/100000 [01:37<01:23, 548.63it/s]
epoch 53000  training loss: 0.027161695063114166
epoch 53000  clean testing loss: 0.1229821965098381
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 53100  training loss: 0.027163829654455185
epoch 53100  clean testing loss: 0.12319184839725494
epoch 53200  training loss: 0.027158111333847046
epoch 53200  clean testing loss: 0.1235077828168869
epoch 53300  training loss: 0.02716132253408432
epoch 53300  clean testing loss: 0.1233629584312439
epoch 53400  training loss: 0.027153411880135536
epoch 53400  clean testing loss: 0.12360433489084244
epoch 53500  training loss: 0.02715259976685047
epoch 53500  clean testing loss: 0.12350345402956009
epoch 53600  training loss: 0.027153877541422844
epoch 53600  clean testing loss: 0.12345178425312042
epoch 53700  training loss: 0.027159418910741806
epoch 53700  clean testing loss: 0.12360072135925293
epoch 53800  training loss: 0.027152981609106064
epoch 53800  clean testing loss: 0.12332460284233093
epoch 53900  training loss: 0.0271487757563591
epoch 53900  clean testing loss: 0.12316159904003143
epoch 54000  training loss: 0.02715209126472473
epoch 54000  clean testing loss: 0.12346875667572021

 55%|█████▌    | 55101/100000 [01:39<01:21, 551.72it/s]
epoch 54100  training loss: 0.027152560651302338
epoch 54100  clean testing loss: 0.12334024906158447
epoch 54200  training loss: 0.02714269980788231
epoch 54200  clean testing loss: 0.12335068732500076
epoch 54300  training loss: 0.027149422094225883
epoch 54300  clean testing loss: 0.12372446060180664
epoch 54400  training loss: 0.027147315442562103
epoch 54400  clean testing loss: 0.1232789009809494
epoch 54500  training loss: 0.02714003250002861
epoch 54500  clean testing loss: 0.12319456785917282
epoch 54600  training loss: 0.027136296033859253
epoch 54600  clean testing loss: 0.12343677133321762
epoch 54700  training loss: 0.02715221978724003
epoch 54700  clean testing loss: 0.12350719422101974
epoch 54800  training loss: 0.027139540761709213
epoch 54800  clean testing loss: 0.12348628044128418
epoch 54900  training loss: 0.027135031297802925
epoch 54900  clean testing loss: 0.12369757145643234
epoch 55000  training loss: 0.027131518349051476
epoch 55000  clean testing loss: 0.12353026866912842
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 55100  training loss: 0.02713320404291153
epoch 55100  clean testing loss: 0.12335120886564255
epoch 55200  training loss: 0.027137042954564095

 56%|█████▌    | 56236/100000 [01:41<01:18, 556.34it/s]
epoch 55300  training loss: 0.027140196412801743
epoch 55300  clean testing loss: 0.12350158393383026
epoch 55400  training loss: 0.027133407071232796
epoch 55400  clean testing loss: 0.12373990565538406
epoch 55500  training loss: 0.02713477984070778
epoch 55500  clean testing loss: 0.12376540899276733
epoch 55600  training loss: 0.027131199836730957
epoch 55600  clean testing loss: 0.12372125685214996
epoch 55700  training loss: 0.027133123949170113
epoch 55700  clean testing loss: 0.12379556149244308
epoch 55800  training loss: 0.027134103700518608
epoch 55800  clean testing loss: 0.12362321466207504
epoch 55900  training loss: 0.027145003899931908
epoch 55900  clean testing loss: 0.12362375110387802
epoch 56000  training loss: 0.027147337794303894
epoch 56000  clean testing loss: 0.12343188375234604
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 56100  training loss: 0.02713692933320999
epoch 56100  clean testing loss: 0.12344498187303543
epoch 56200  training loss: 0.027121424674987793
epoch 56200  clean testing loss: 0.12377668172121048
epoch 56300  training loss: 0.02712511457502842

 57%|█████▋    | 57312/100000 [01:43<01:17, 549.42it/s]
epoch 56400  training loss: 0.02712099812924862
epoch 56400  clean testing loss: 0.12356507778167725
epoch 56500  training loss: 0.027131330221891403
epoch 56500  clean testing loss: 0.12368322908878326
epoch 56600  training loss: 0.02712065912783146
epoch 56600  clean testing loss: 0.12385108321905136
epoch 56700  training loss: 0.027123063802719116
epoch 56700  clean testing loss: 0.12399087846279144
epoch 56800  training loss: 0.02712155133485794
epoch 56800  clean testing loss: 0.12384609133005142
epoch 56900  training loss: 0.027124416083097458
epoch 56900  clean testing loss: 0.12355584651231766
epoch 57000  training loss: 0.02712012082338333
epoch 57000  clean testing loss: 0.12358667701482773
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 57100  training loss: 0.027114400640130043
epoch 57100  clean testing loss: 0.124106764793396
epoch 57200  training loss: 0.027119068428874016
epoch 57200  clean testing loss: 0.12391240894794464
epoch 57300  training loss: 0.027112936601042747
epoch 57300  clean testing loss: 0.12364436686038971
epoch 57400  training loss: 0.02710970863699913

 58%|█████▊    | 58444/100000 [01:45<01:14, 557.01it/s]
epoch 57500  training loss: 0.027120651677250862
epoch 57500  clean testing loss: 0.12372642010450363
epoch 57600  training loss: 0.027112169191241264
epoch 57600  clean testing loss: 0.12396224588155746
epoch 57700  training loss: 0.02710886485874653
epoch 57700  clean testing loss: 0.12401197850704193
epoch 57800  training loss: 0.027123888954520226
epoch 57800  clean testing loss: 0.1238870620727539
epoch 57900  training loss: 0.027109162881970406
epoch 57900  clean testing loss: 0.12409930676221848
epoch 58000  training loss: 0.027110686525702477
epoch 58000  clean testing loss: 0.12392143905162811
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 58100  training loss: 0.027107400819659233
epoch 58100  clean testing loss: 0.12380315363407135
epoch 58200  training loss: 0.027103442698717117
epoch 58200  clean testing loss: 0.12399350106716156
epoch 58300  training loss: 0.027107402682304382
epoch 58300  clean testing loss: 0.12408110499382019
epoch 58400  training loss: 0.02711029164493084
epoch 58400  clean testing loss: 0.12379909306764603
epoch 58500  training loss: 0.027108006179332733

 60%|█████▉    | 59576/100000 [01:47<01:12, 560.25it/s]
epoch 58600  training loss: 0.027106987312436104
epoch 58600  clean testing loss: 0.12392457574605942
epoch 58700  training loss: 0.02710728533565998
epoch 58700  clean testing loss: 0.12394038587808609
epoch 58800  training loss: 0.02710036002099514
epoch 58800  clean testing loss: 0.12403680384159088
epoch 58900  training loss: 0.027107128873467445
epoch 58900  clean testing loss: 0.12407636642456055
epoch 59000  training loss: 0.02709856629371643
epoch 59000  clean testing loss: 0.12413132190704346
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 59100  training loss: 0.02710535004734993
epoch 59100  clean testing loss: 0.12389661371707916
epoch 59200  training loss: 0.027102665975689888
epoch 59200  clean testing loss: 0.12416919320821762
epoch 59300  training loss: 0.027113785967230797
epoch 59300  clean testing loss: 0.12397081404924393
epoch 59400  training loss: 0.027095850557088852
epoch 59400  clean testing loss: 0.12407195568084717
epoch 59500  training loss: 0.027103571221232414
epoch 59500  clean testing loss: 0.12377246469259262
epoch 59600  training loss: 0.02710779756307602

 61%|██████    | 60654/100000 [01:49<01:10, 557.44it/s]
epoch 59700  training loss: 0.027096642181277275
epoch 59700  clean testing loss: 0.1239112839102745
epoch 59800  training loss: 0.027098068967461586
epoch 59800  clean testing loss: 0.12417762726545334
epoch 59900  training loss: 0.027094002813100815
epoch 59900  clean testing loss: 0.1243339329957962
epoch 60000  training loss: 0.027100352570414543
epoch 60000  clean testing loss: 0.12422855198383331
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 60100  training loss: 0.027093147858977318
epoch 60100  clean testing loss: 0.12415067106485367
epoch 60200  training loss: 0.027094028890132904
epoch 60200  clean testing loss: 0.12435979396104813
epoch 60300  training loss: 0.027093900367617607
epoch 60300  clean testing loss: 0.12417541444301605
epoch 60400  training loss: 0.027090050280094147
epoch 60400  clean testing loss: 0.12408516556024551
epoch 60500  training loss: 0.0270867720246315
epoch 60500  clean testing loss: 0.12430039793252945
epoch 60600  training loss: 0.027087731286883354
epoch 60600  clean testing loss: 0.12432464212179184
epoch 60700  training loss: 0.02708619087934494

 62%|██████▏   | 61788/100000 [01:51<01:07, 562.31it/s]
epoch 60800  training loss: 0.027086324989795685
epoch 60800  clean testing loss: 0.12427951395511627
epoch 60900  training loss: 0.027089722454547882
epoch 60900  clean testing loss: 0.12414136528968811
epoch 61000  training loss: 0.027088653296232224
epoch 61000  clean testing loss: 0.12411834299564362
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 61100  training loss: 0.02708778716623783
epoch 61100  clean testing loss: 0.12419606000185013
epoch 61200  training loss: 0.02708558551967144
epoch 61200  clean testing loss: 0.12434416264295578
epoch 61300  training loss: 0.027083858847618103
epoch 61300  clean testing loss: 0.12433239072561264
epoch 61400  training loss: 0.02709200233221054
epoch 61400  clean testing loss: 0.1242954209446907
epoch 61500  training loss: 0.027081985026597977
epoch 61500  clean testing loss: 0.12446248531341553
epoch 61600  training loss: 0.0270827766507864
epoch 61600  clean testing loss: 0.12427648901939392
epoch 61700  training loss: 0.027078265324234962
epoch 61700  clean testing loss: 0.12444249540567398
epoch 61800  training loss: 0.027083441615104675

 63%|██████▎   | 62865/100000 [01:53<01:06, 560.81it/s]
epoch 61900  training loss: 0.027078429237008095
epoch 61900  clean testing loss: 0.12441273778676987
epoch 62000  training loss: 0.02707873471081257
epoch 62000  clean testing loss: 0.12447204440832138
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 62100  training loss: 0.027078578248620033
epoch 62100  clean testing loss: 0.12445957213640213
epoch 62200  training loss: 0.027081970125436783
epoch 62200  clean testing loss: 0.12439203262329102
epoch 62300  training loss: 0.02707795612514019
epoch 62300  clean testing loss: 0.12436848133802414
epoch 62400  training loss: 0.02708733268082142
epoch 62400  clean testing loss: 0.12435237318277359
epoch 62500  training loss: 0.0270810816437006
epoch 62500  clean testing loss: 0.12437514215707779
epoch 62600  training loss: 0.027079960331320763
epoch 62600  clean testing loss: 0.12435533851385117
epoch 62700  training loss: 0.027075227349996567
epoch 62700  clean testing loss: 0.12467531114816666
epoch 62800  training loss: 0.027078818529844284
epoch 62800  clean testing loss: 0.12454061210155487
epoch 62900  training loss: 0.02707698754966259

 64%|██████▍   | 63937/100000 [01:55<01:05, 551.85it/s]
epoch 63000  training loss: 0.027075743302702904
epoch 63000  clean testing loss: 0.12452156096696854
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 63100  training loss: 0.027073107659816742
epoch 63100  clean testing loss: 0.12457007169723511
epoch 63200  training loss: 0.02707386389374733
epoch 63200  clean testing loss: 0.12449878454208374
epoch 63300  training loss: 0.027072062715888023
epoch 63300  clean testing loss: 0.12444093078374863
epoch 63400  training loss: 0.02707081288099289
epoch 63400  clean testing loss: 0.12447771430015564
epoch 63500  training loss: 0.027072571218013763
epoch 63500  clean testing loss: 0.12459821254014969
epoch 63600  training loss: 0.0270699393004179
epoch 63600  clean testing loss: 0.12458955496549606
epoch 63700  training loss: 0.02706901729106903
epoch 63700  clean testing loss: 0.12463812530040741
epoch 63800  training loss: 0.027071131393313408
epoch 63800  clean testing loss: 0.12456811964511871
epoch 63900  training loss: 0.02707098424434662
epoch 63900  clean testing loss: 0.12453651428222656
epoch 64000  training loss: 0.0270791407674551
epoch 64000  clean testing loss: 0.12429510056972504

 65%|██████▌   | 65069/100000 [01:57<01:03, 553.80it/s]
epoch 64100  training loss: 0.027068180963397026
epoch 64100  clean testing loss: 0.12470103800296783
epoch 64200  training loss: 0.027066124603152275
epoch 64200  clean testing loss: 0.12474329024553299
epoch 64300  training loss: 0.02706507220864296
epoch 64300  clean testing loss: 0.12457102537155151
epoch 64400  training loss: 0.027067407965660095
epoch 64400  clean testing loss: 0.12459834665060043
epoch 64500  training loss: 0.027066098526120186
epoch 64500  clean testing loss: 0.12467994540929794
epoch 64600  training loss: 0.027066223323345184
epoch 64600  clean testing loss: 0.12472856044769287
epoch 64700  training loss: 0.027065660804510117
epoch 64700  clean testing loss: 0.1246846541762352
epoch 64800  training loss: 0.027063004672527313
epoch 64800  clean testing loss: 0.12484139204025269
epoch 64900  training loss: 0.027065834030508995
epoch 64900  clean testing loss: 0.12463012337684631
epoch 65000  training loss: 0.027065446600317955
epoch 65000  clean testing loss: 0.12463899701833725
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 65100  training loss: 0.027061814442276955

 66%|██████▌   | 66199/100000 [01:59<01:00, 558.50it/s]
epoch 65200  training loss: 0.02706744149327278
epoch 65200  clean testing loss: 0.12471963465213776
epoch 65300  training loss: 0.027063429355621338
epoch 65300  clean testing loss: 0.12464919686317444
epoch 65400  training loss: 0.02706155739724636
epoch 65400  clean testing loss: 0.12495249509811401
epoch 65500  training loss: 0.027067240327596664
epoch 65500  clean testing loss: 0.12471488863229752
epoch 65600  training loss: 0.027065081521868706
epoch 65600  clean testing loss: 0.12459846585988998
epoch 65700  training loss: 0.027060184627771378
epoch 65700  clean testing loss: 0.124770887196064
epoch 65800  training loss: 0.027057604864239693
epoch 65800  clean testing loss: 0.12481411546468735
epoch 65900  training loss: 0.027060598134994507
epoch 65900  clean testing loss: 0.12475269287824631
epoch 66000  training loss: 0.027062315493822098
epoch 66000  clean testing loss: 0.12478258460760117
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 66100  training loss: 0.027055777609348297
epoch 66100  clean testing loss: 0.12485531717538834
epoch 66200  training loss: 0.027056869119405746

 67%|██████▋   | 67275/100000 [02:01<00:58, 559.65it/s]
epoch 66300  training loss: 0.027056798338890076
epoch 66300  clean testing loss: 0.12476682662963867
epoch 66400  training loss: 0.02705751173198223
epoch 66400  clean testing loss: 0.12488788366317749
epoch 66500  training loss: 0.027055734768509865
epoch 66500  clean testing loss: 0.1248285248875618
epoch 66600  training loss: 0.02705419436097145
epoch 66600  clean testing loss: 0.12492916733026505
epoch 66700  training loss: 0.02705433778464794
epoch 66700  clean testing loss: 0.12485785037279129
epoch 66800  training loss: 0.02705339901149273
epoch 66800  clean testing loss: 0.1250082403421402
epoch 66900  training loss: 0.027054889127612114
epoch 66900  clean testing loss: 0.12489735335111618
epoch 67000  training loss: 0.02705635502934456
epoch 67000  clean testing loss: 0.12491277605295181
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 67100  training loss: 0.02705424092710018
epoch 67100  clean testing loss: 0.12495064735412598
epoch 67200  training loss: 0.027054131031036377
epoch 67200  clean testing loss: 0.12489490211009979
epoch 67300  training loss: 0.027053257450461388

 68%|██████▊   | 68409/100000 [02:03<00:56, 556.40it/s]
epoch 67400  training loss: 0.027056381106376648
epoch 67400  clean testing loss: 0.12487361580133438
epoch 67500  training loss: 0.02705293335020542
epoch 67500  clean testing loss: 0.12500885128974915
epoch 67600  training loss: 0.02705291658639908
epoch 67600  clean testing loss: 0.12504518032073975
epoch 67700  training loss: 0.027051717042922974
epoch 67700  clean testing loss: 0.12491151690483093
epoch 67800  training loss: 0.02705039456486702
epoch 67800  clean testing loss: 0.12499448657035828
epoch 67900  training loss: 0.027048854157328606
epoch 67900  clean testing loss: 0.1251009702682495
epoch 68000  training loss: 0.027052659541368484
epoch 68000  clean testing loss: 0.12491957098245621
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 68100  training loss: 0.027051962912082672
epoch 68100  clean testing loss: 0.12496471405029297
epoch 68200  training loss: 0.027051176875829697
epoch 68200  clean testing loss: 0.12495402991771698
epoch 68300  training loss: 0.027048161253333092
epoch 68300  clean testing loss: 0.12499233335256577
epoch 68400  training loss: 0.02704811841249466
epoch 68400  clean testing loss: 0.12498725950717926
epoch 68500  training loss: 0.027049340307712555

 69%|██████▉   | 69490/100000 [02:05<00:54, 561.37it/s]
epoch 68600  training loss: 0.027045661583542824
epoch 68600  clean testing loss: 0.12508352100849152
epoch 68700  training loss: 0.027049992233514786
epoch 68700  clean testing loss: 0.12504369020462036
epoch 68800  training loss: 0.02704879269003868
epoch 68800  clean testing loss: 0.12507252395153046
epoch 68900  training loss: 0.0270465649664402
epoch 68900  clean testing loss: 0.12505316734313965
epoch 69000  training loss: 0.02704576402902603
epoch 69000  clean testing loss: 0.12514351308345795
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 69100  training loss: 0.027044136077165604
epoch 69100  clean testing loss: 0.1249709278345108
epoch 69200  training loss: 0.027043035253882408
epoch 69200  clean testing loss: 0.12510988116264343
epoch 69300  training loss: 0.0270443893969059
epoch 69300  clean testing loss: 0.12514762580394745
epoch 69400  training loss: 0.027047477662563324
epoch 69400  clean testing loss: 0.12512078881263733
epoch 69500  training loss: 0.027047397568821907
epoch 69500  clean testing loss: 0.12511886656284332
epoch 69600  training loss: 0.027042269706726074

 71%|███████   | 70625/100000 [02:07<00:52, 556.96it/s]
epoch 69700  training loss: 0.027044452726840973
epoch 69700  clean testing loss: 0.12509505450725555
epoch 69800  training loss: 0.027044054120779037
epoch 69800  clean testing loss: 0.12518300116062164
epoch 69900  training loss: 0.02704371139407158
epoch 69900  clean testing loss: 0.1251509040594101
epoch 70000  training loss: 0.027044298127293587
epoch 70000  clean testing loss: 0.12517796456813812
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 70100  training loss: 0.027041545137763023
epoch 70100  clean testing loss: 0.12516430020332336
epoch 70200  training loss: 0.027041234076023102
epoch 70200  clean testing loss: 0.12525592744350433
epoch 70300  training loss: 0.027038559317588806
epoch 70300  clean testing loss: 0.12530013918876648
epoch 70400  training loss: 0.027040114626288414
epoch 70400  clean testing loss: 0.12525911629199982
epoch 70500  training loss: 0.027041740715503693
epoch 70500  clean testing loss: 0.12528884410858154
epoch 70600  training loss: 0.027039775624871254
epoch 70600  clean testing loss: 0.12519009411334991
epoch 70700  training loss: 0.027040131390094757

 72%|███████▏  | 71758/100000 [02:09<00:50, 560.25it/s]
epoch 70800  training loss: 0.02703689970076084
epoch 70800  clean testing loss: 0.12531837821006775
epoch 70900  training loss: 0.027038292959332466
epoch 70900  clean testing loss: 0.12532220780849457
epoch 71000  training loss: 0.027037017047405243
epoch 71000  clean testing loss: 0.1253882199525833
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 71100  training loss: 0.02703845500946045
epoch 71100  clean testing loss: 0.12532585859298706
epoch 71200  training loss: 0.02703818306326866
epoch 71200  clean testing loss: 0.1252680867910385
epoch 71300  training loss: 0.02703443542122841
epoch 71300  clean testing loss: 0.1253403127193451
epoch 71400  training loss: 0.02703968621790409
epoch 71400  clean testing loss: 0.12536588311195374
epoch 71500  training loss: 0.027035802602767944
epoch 71500  clean testing loss: 0.12533633410930634
epoch 71600  training loss: 0.027037322521209717
epoch 71600  clean testing loss: 0.12543201446533203
epoch 71700  training loss: 0.027035623788833618
epoch 71700  clean testing loss: 0.1253984272480011
epoch 71800  training loss: 0.027033574879169464

 73%|███████▎  | 72833/100000 [02:11<00:48, 557.51it/s]
epoch 71900  training loss: 0.02703338861465454
epoch 71900  clean testing loss: 0.12551037967205048
epoch 72000  training loss: 0.027036184445023537
epoch 72000  clean testing loss: 0.12549182772636414
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 72100  training loss: 0.027032658457756042
epoch 72100  clean testing loss: 0.125523179769516
epoch 72200  training loss: 0.0270356647670269
epoch 72200  clean testing loss: 0.125448539853096
epoch 72300  training loss: 0.027032190933823586
epoch 72300  clean testing loss: 0.12547284364700317
epoch 72400  training loss: 0.027033189311623573
epoch 72400  clean testing loss: 0.12546315789222717
epoch 72500  training loss: 0.027032554149627686
epoch 72500  clean testing loss: 0.1254042685031891
epoch 72600  training loss: 0.027032354846596718
epoch 72600  clean testing loss: 0.12554195523262024
epoch 72700  training loss: 0.027030861005187035
epoch 72700  clean testing loss: 0.12554258108139038
epoch 72800  training loss: 0.027029380202293396
epoch 72800  clean testing loss: 0.12556210160255432
epoch 72900  training loss: 0.027029862627387047

 74%|███████▍  | 73964/100000 [02:13<00:46, 556.35it/s]
epoch 73000  training loss: 0.027029655873775482
epoch 73000  clean testing loss: 0.12556561827659607
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 73100  training loss: 0.027029287070035934
epoch 73100  clean testing loss: 0.12551195919513702
epoch 73200  training loss: 0.027029123157262802
epoch 73200  clean testing loss: 0.12565241754055023
epoch 73300  training loss: 0.02703162655234337
epoch 73300  clean testing loss: 0.12560439109802246
epoch 73400  training loss: 0.027028821408748627
epoch 73400  clean testing loss: 0.12559294700622559
epoch 73500  training loss: 0.02702822908759117
epoch 73500  clean testing loss: 0.12567298114299774
epoch 73600  training loss: 0.027029847726225853
epoch 73600  clean testing loss: 0.1256006360054016
epoch 73700  training loss: 0.027028948068618774
epoch 73700  clean testing loss: 0.12561406195163727
epoch 73800  training loss: 0.02703014761209488
epoch 73800  clean testing loss: 0.1255880743265152
epoch 73900  training loss: 0.027026720345020294
epoch 73900  clean testing loss: 0.12570355832576752
epoch 74000  training loss: 0.027027344331145287
epoch 74000  clean testing loss: 0.1256583333015442

 75%|███████▌  | 75098/100000 [02:15<00:44, 555.58it/s]
epoch 74100  training loss: 0.0270270723849535
epoch 74100  clean testing loss: 0.12569743394851685
epoch 74200  training loss: 0.02702607586979866
epoch 74200  clean testing loss: 0.12572577595710754
epoch 74300  training loss: 0.02702607959508896
epoch 74300  clean testing loss: 0.1257624477148056
epoch 74400  training loss: 0.027027081698179245
epoch 74400  clean testing loss: 0.1256774365901947
epoch 74500  training loss: 0.027026113122701645
epoch 74500  clean testing loss: 0.12579956650733948
epoch 74600  training loss: 0.027027243748307228
epoch 74600  clean testing loss: 0.12576037645339966
epoch 74700  training loss: 0.0270247720181942
epoch 74700  clean testing loss: 0.125815287232399
epoch 74800  training loss: 0.02702457457780838
epoch 74800  clean testing loss: 0.12582869827747345
epoch 74900  training loss: 0.027024993672966957
epoch 74900  clean testing loss: 0.12577350437641144
epoch 75000  training loss: 0.027024997398257256
epoch 75000  clean testing loss: 0.12577010691165924
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 75100  training loss: 0.027025528252124786

 76%|███████▌  | 76173/100000 [02:17<00:42, 558.60it/s]
epoch 75200  training loss: 0.027026524767279625
epoch 75200  clean testing loss: 0.12577468156814575
epoch 75300  training loss: 0.02702443115413189
epoch 75300  clean testing loss: 0.12573537230491638
epoch 75400  training loss: 0.02702290005981922
epoch 75400  clean testing loss: 0.12587440013885498
epoch 75500  training loss: 0.027022184804081917
epoch 75500  clean testing loss: 0.12583550810813904
epoch 75600  training loss: 0.027021631598472595
epoch 75600  clean testing loss: 0.12581805884838104
epoch 75700  training loss: 0.027021583169698715
epoch 75700  clean testing loss: 0.1259845346212387
epoch 75800  training loss: 0.027020668610930443
epoch 75800  clean testing loss: 0.12588582932949066
epoch 75900  training loss: 0.027021212503314018
epoch 75900  clean testing loss: 0.12591713666915894
epoch 76000  training loss: 0.02702091448009014
epoch 76000  clean testing loss: 0.12585118412971497
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 76100  training loss: 0.027020921930670738
epoch 76100  clean testing loss: 0.1258613020181656
epoch 76200  training loss: 0.027021702378988266

 77%|███████▋  | 77311/100000 [02:19<00:40, 555.24it/s]
epoch 76300  training loss: 0.027018871158361435
epoch 76300  clean testing loss: 0.1259884089231491
epoch 76400  training loss: 0.027019869536161423
epoch 76400  clean testing loss: 0.12597540020942688
epoch 76500  training loss: 0.0270185898989439
epoch 76500  clean testing loss: 0.12594367563724518
epoch 76600  training loss: 0.027020229026675224
epoch 76600  clean testing loss: 0.12597142159938812
epoch 76700  training loss: 0.027018770575523376
epoch 76700  clean testing loss: 0.1259295791387558
epoch 76800  training loss: 0.027019014582037926
epoch 76800  clean testing loss: 0.1260477751493454
epoch 76900  training loss: 0.027019774541258812
epoch 76900  clean testing loss: 0.12593470513820648
epoch 77000  training loss: 0.02701761946082115
epoch 77000  clean testing loss: 0.12601132690906525
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 77100  training loss: 0.027017392218112946
epoch 77100  clean testing loss: 0.12599442899227142
epoch 77200  training loss: 0.027017798274755478
epoch 77200  clean testing loss: 0.1260499805212021
epoch 77300  training loss: 0.027017459273338318
epoch 77300  clean testing loss: 0.12600012123584747
epoch 77400  training loss: 0.027018066495656967

 78%|███████▊  | 78386/100000 [02:21<00:38, 558.41it/s]
epoch 77500  training loss: 0.027016762644052505
epoch 77500  clean testing loss: 0.1260545551776886
epoch 77600  training loss: 0.027017740532755852
epoch 77600  clean testing loss: 0.12602275609970093
epoch 77700  training loss: 0.027016639709472656
epoch 77700  clean testing loss: 0.12604986131191254
epoch 77800  training loss: 0.027016591280698776
epoch 77800  clean testing loss: 0.12603797018527985
epoch 77900  training loss: 0.027015533298254013
epoch 77900  clean testing loss: 0.12611626088619232
epoch 78000  training loss: 0.02701580710709095
epoch 78000  clean testing loss: 0.1261145919561386
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 78100  training loss: 0.02701513282954693
epoch 78100  clean testing loss: 0.12603725492954254
epoch 78200  training loss: 0.027015678584575653
epoch 78200  clean testing loss: 0.12603555619716644
epoch 78300  training loss: 0.027014803141355515
epoch 78300  clean testing loss: 0.12611141800880432
epoch 78400  training loss: 0.027014898136258125
epoch 78400  clean testing loss: 0.12612950801849365
epoch 78500  training loss: 0.02701513282954693

 80%|███████▉  | 79514/100000 [02:23<00:36, 556.32it/s]
epoch 78600  training loss: 0.027015313506126404
epoch 78600  clean testing loss: 0.12612757086753845
epoch 78700  training loss: 0.027014922350645065
epoch 78700  clean testing loss: 0.1260976940393448
epoch 78800  training loss: 0.027014000341296196
epoch 78800  clean testing loss: 0.12612922489643097
epoch 78900  training loss: 0.027014464139938354
epoch 78900  clean testing loss: 0.12610894441604614
epoch 79000  training loss: 0.02701357752084732
epoch 79000  clean testing loss: 0.1261812001466751
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 79100  training loss: 0.027013100683689117
epoch 79100  clean testing loss: 0.12615707516670227
epoch 79200  training loss: 0.027014024555683136
epoch 79200  clean testing loss: 0.12610894441604614
epoch 79300  training loss: 0.027012674137949944
epoch 79300  clean testing loss: 0.1262095868587494
epoch 79400  training loss: 0.02701374888420105
epoch 79400  clean testing loss: 0.1261381357908249
epoch 79500  training loss: 0.027012653648853302
epoch 79500  clean testing loss: 0.12616398930549622
epoch 79600  training loss: 0.02701411582529545

 81%|████████  | 80587/100000 [02:25<00:35, 550.67it/s]
epoch 79700  training loss: 0.027012966573238373
epoch 79700  clean testing loss: 0.1262257695198059
epoch 79800  training loss: 0.02701445296406746
epoch 79800  clean testing loss: 0.12616994976997375
epoch 79900  training loss: 0.027012599632143974
epoch 79900  clean testing loss: 0.1261654794216156
epoch 80000  training loss: 0.027012476697564125
epoch 80000  clean testing loss: 0.12624695897102356
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 80100  training loss: 0.027011269703507423
epoch 80100  clean testing loss: 0.12623117864131927
epoch 80200  training loss: 0.027011249214410782
epoch 80200  clean testing loss: 0.12622785568237305
epoch 80300  training loss: 0.027011200785636902
epoch 80300  clean testing loss: 0.12621168792247772
epoch 80400  training loss: 0.027010682970285416
epoch 80400  clean testing loss: 0.12623223662376404
epoch 80500  training loss: 0.027011238038539886
epoch 80500  clean testing loss: 0.12623897194862366
epoch 80600  training loss: 0.027010425925254822

 82%|████████▏ | 81719/100000 [02:27<00:32, 558.01it/s]
epoch 80700  training loss: 0.027010884135961533
epoch 80700  clean testing loss: 0.12628306448459625
epoch 80800  training loss: 0.02701217122375965
epoch 80800  clean testing loss: 0.12631310522556305
epoch 80900  training loss: 0.027011189609766006
epoch 80900  clean testing loss: 0.12623533606529236
epoch 81000  training loss: 0.02701115980744362
epoch 81000  clean testing loss: 0.1262679100036621
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 81100  training loss: 0.02701033465564251
epoch 81100  clean testing loss: 0.12625710666179657
epoch 81200  training loss: 0.027010317891836166
epoch 81200  clean testing loss: 0.12623563408851624
epoch 81300  training loss: 0.027009334415197372
epoch 81300  clean testing loss: 0.12630049884319305
epoch 81400  training loss: 0.027008792385458946
epoch 81400  clean testing loss: 0.1263331174850464
epoch 81500  training loss: 0.027010543271899223
epoch 81500  clean testing loss: 0.12628918886184692
epoch 81600  training loss: 0.02700895443558693
epoch 81600  clean testing loss: 0.12630435824394226
epoch 81700  training loss: 0.027008719742298126
epoch 81700  clean testing loss: 0.12628552317619324
epoch 81800  training loss: 0.027008015662431717

 83%|████████▎ | 82795/100000 [02:29<00:30, 560.42it/s]
epoch 81900  training loss: 0.027009906247258186
epoch 81900  clean testing loss: 0.12629102170467377
epoch 82000  training loss: 0.0270083025097847
epoch 82000  clean testing loss: 0.12631119787693024
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 82100  training loss: 0.027008093893527985
epoch 82100  clean testing loss: 0.1263430118560791
epoch 82200  training loss: 0.02700858563184738
epoch 82200  clean testing loss: 0.12631916999816895
epoch 82300  training loss: 0.0270080529153347
epoch 82300  clean testing loss: 0.12631823122501373
epoch 82400  training loss: 0.027008555829524994
epoch 82400  clean testing loss: 0.12631313502788544
epoch 82500  training loss: 0.02700738050043583
epoch 82500  clean testing loss: 0.12636446952819824
epoch 82600  training loss: 0.027008090168237686
epoch 82600  clean testing loss: 0.12634669244289398
epoch 82700  training loss: 0.027007998898625374
epoch 82700  clean testing loss: 0.12634415924549103
epoch 82800  training loss: 0.027006983757019043
epoch 82800  clean testing loss: 0.1263241320848465
epoch 82900  training loss: 0.02700760029256344

 84%|████████▍ | 83930/100000 [02:31<00:28, 558.55it/s]
epoch 83000  training loss: 0.027006473392248154
epoch 83000  clean testing loss: 0.12639138102531433
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 83100  training loss: 0.02700689807534218
epoch 83100  clean testing loss: 0.12641361355781555
epoch 83200  training loss: 0.027008136734366417
epoch 83200  clean testing loss: 0.12631957232952118
epoch 83300  training loss: 0.02700643427670002
epoch 83300  clean testing loss: 0.12641452252864838
epoch 83400  training loss: 0.02700641378760338
epoch 83400  clean testing loss: 0.12640318274497986
epoch 83500  training loss: 0.02700699307024479
epoch 83500  clean testing loss: 0.12639541923999786
epoch 83600  training loss: 0.02700640633702278
epoch 83600  clean testing loss: 0.1263466328382492
epoch 83700  training loss: 0.027006514370441437
epoch 83700  clean testing loss: 0.12636809051036835
epoch 83800  training loss: 0.0270055141299963
epoch 83800  clean testing loss: 0.1263909488916397
epoch 83900  training loss: 0.027005385607481003
epoch 83900  clean testing loss: 0.12638479471206665
epoch 84000  training loss: 0.0270055141299963
epoch 84000  clean testing loss: 0.12642310559749603

 85%|████████▌ | 85062/100000 [02:33<00:26, 553.77it/s]
epoch 84100  training loss: 0.027004681527614594
epoch 84100  clean testing loss: 0.1264548897743225
epoch 84200  training loss: 0.0270049050450325
epoch 84200  clean testing loss: 0.12641428411006927
epoch 84300  training loss: 0.027004480361938477
epoch 84300  clean testing loss: 0.12644760310649872
epoch 84400  training loss: 0.027004607021808624
epoch 84400  clean testing loss: 0.12645505368709564
epoch 84500  training loss: 0.027005257084965706
epoch 84500  clean testing loss: 0.12642167508602142
epoch 84600  training loss: 0.02700468711555004
epoch 84600  clean testing loss: 0.12641488015651703
epoch 84700  training loss: 0.027004318311810493
epoch 84700  clean testing loss: 0.1264808177947998
epoch 84800  training loss: 0.027003871276974678
epoch 84800  clean testing loss: 0.1264267861843109
epoch 84900  training loss: 0.02700428105890751
epoch 84900  clean testing loss: 0.12644067406654358
epoch 85000  training loss: 0.02700338512659073
epoch 85000  clean testing loss: 0.12644726037979126
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 85100  training loss: 0.027003902941942215

 86%|████████▌ | 86135/100000 [02:35<00:25, 550.62it/s]
epoch 85200  training loss: 0.027003254741430283
epoch 85200  clean testing loss: 0.12644325196743011
epoch 85300  training loss: 0.027002649381756783
epoch 85300  clean testing loss: 0.1264917403459549
epoch 85400  training loss: 0.027003085240721703
epoch 85400  clean testing loss: 0.12646159529685974
epoch 85500  training loss: 0.027002999559044838
epoch 85500  clean testing loss: 0.12648466229438782
epoch 85600  training loss: 0.027003267779946327
epoch 85600  clean testing loss: 0.126492440700531
epoch 85700  training loss: 0.027002692222595215
epoch 85700  clean testing loss: 0.1264730840921402
epoch 85800  training loss: 0.02700212597846985
epoch 85800  clean testing loss: 0.12647823989391327
epoch 85900  training loss: 0.027002662420272827
epoch 85900  clean testing loss: 0.1264849454164505
epoch 86000  training loss: 0.027001747861504555
epoch 86000  clean testing loss: 0.12648022174835205
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 86100  training loss: 0.02700214274227619
epoch 86100  clean testing loss: 0.1264871507883072
epoch 86200  training loss: 0.027001939713954926

 87%|████████▋ | 87266/100000 [02:37<00:22, 557.60it/s]
epoch 86300  training loss: 0.02700166217982769
epoch 86300  clean testing loss: 0.12651501595973969
epoch 86400  training loss: 0.02700127474963665
epoch 86400  clean testing loss: 0.1264825016260147
epoch 86500  training loss: 0.027001680806279182
epoch 86500  clean testing loss: 0.12653078138828278
epoch 86600  training loss: 0.027002429589629173
epoch 86600  clean testing loss: 0.1264926642179489
epoch 86700  training loss: 0.027001487091183662
epoch 86700  clean testing loss: 0.1265084445476532
epoch 86800  training loss: 0.027001162990927696
epoch 86800  clean testing loss: 0.12655849754810333
epoch 86900  training loss: 0.027001118287444115
epoch 86900  clean testing loss: 0.12652093172073364
epoch 87000  training loss: 0.02700086496770382
epoch 87000  clean testing loss: 0.12654389441013336
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 87100  training loss: 0.02700021117925644
epoch 87100  clean testing loss: 0.12652240693569183
epoch 87200  training loss: 0.02700066938996315
epoch 87200  clean testing loss: 0.1265292465686798
epoch 87300  training loss: 0.027000131085515022

 88%|████████▊ | 88340/100000 [02:39<00:20, 555.63it/s]
epoch 87400  training loss: 0.02700035087764263
epoch 87400  clean testing loss: 0.12653279304504395
epoch 87500  training loss: 0.026999883353710175
epoch 87500  clean testing loss: 0.12654916942119598
epoch 87600  training loss: 0.026999659836292267
epoch 87600  clean testing loss: 0.12656310200691223
epoch 87700  training loss: 0.026999659836292267
epoch 87700  clean testing loss: 0.12657073140144348
epoch 87800  training loss: 0.026999562978744507
epoch 87800  clean testing loss: 0.12655490636825562
epoch 87900  training loss: 0.026999682188034058
epoch 87900  clean testing loss: 0.12654338777065277
epoch 88000  training loss: 0.02699938230216503
epoch 88000  clean testing loss: 0.12658047676086426
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 88100  training loss: 0.026999711990356445
epoch 88100  clean testing loss: 0.12656687200069427
epoch 88200  training loss: 0.02699901908636093
epoch 88200  clean testing loss: 0.1265781819820404
epoch 88300  training loss: 0.0269989762455225
epoch 88300  clean testing loss: 0.12660163640975952
epoch 88400  training loss: 0.026999015361070633

 89%|████████▉ | 89470/100000 [02:41<00:18, 560.66it/s]
epoch 88500  training loss: 0.02699856646358967
epoch 88500  clean testing loss: 0.12656402587890625
epoch 88600  training loss: 0.02699963189661503
epoch 88600  clean testing loss: 0.12656395137310028
epoch 88700  training loss: 0.026998810470104218
epoch 88700  clean testing loss: 0.12658214569091797
epoch 88800  training loss: 0.026998259127140045
epoch 88800  clean testing loss: 0.12661482393741608
epoch 88900  training loss: 0.026998743414878845
epoch 88900  clean testing loss: 0.12659481167793274
epoch 89000  training loss: 0.026998165994882584
epoch 89000  clean testing loss: 0.12660034000873566
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 89100  training loss: 0.026998121291399002
epoch 89100  clean testing loss: 0.1265823096036911
epoch 89200  training loss: 0.026997804641723633
epoch 89200  clean testing loss: 0.12655308842658997
epoch 89300  training loss: 0.026998266577720642
epoch 89300  clean testing loss: 0.12659256160259247
epoch 89400  training loss: 0.026997804641723633
epoch 89400  clean testing loss: 0.12659282982349396
epoch 89500  training loss: 0.026997584849596024

 91%|█████████ | 90548/100000 [02:43<00:16, 556.76it/s]
epoch 89600  training loss: 0.026998110115528107
epoch 89600  clean testing loss: 0.12659160792827606
epoch 89700  training loss: 0.026997271925210953
epoch 89700  clean testing loss: 0.12663322687149048
epoch 89800  training loss: 0.026998324319720268
epoch 89800  clean testing loss: 0.12659701704978943
epoch 89900  training loss: 0.026996778324246407
epoch 89900  clean testing loss: 0.12662771344184875
epoch 90000  training loss: 0.026996878907084465
epoch 90000  clean testing loss: 0.12661133706569672
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 90100  training loss: 0.026996754109859467
epoch 90100  clean testing loss: 0.12663236260414124
epoch 90200  training loss: 0.026996416971087456
epoch 90200  clean testing loss: 0.12663495540618896
epoch 90300  training loss: 0.026996202766895294
epoch 90300  clean testing loss: 0.1266302913427353
epoch 90400  training loss: 0.02699659764766693
epoch 90400  clean testing loss: 0.12662644684314728
epoch 90500  training loss: 0.026996437460184097
epoch 90500  clean testing loss: 0.12662509083747864
epoch 90600  training loss: 0.026995841413736343

 92%|█████████▏| 91679/100000 [02:45<00:14, 561.79it/s]
epoch 90700  training loss: 0.02699611522257328
epoch 90700  clean testing loss: 0.1266496777534485
epoch 90800  training loss: 0.02699613943696022
epoch 90800  clean testing loss: 0.1266300529241562
epoch 90900  training loss: 0.026996387168765068
epoch 90900  clean testing loss: 0.1266428828239441
epoch 91000  training loss: 0.026995781809091568
epoch 91000  clean testing loss: 0.12665483355522156
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 91100  training loss: 0.02699626423418522
epoch 91100  clean testing loss: 0.1266673505306244
epoch 91200  training loss: 0.026996169239282608
epoch 91200  clean testing loss: 0.12666411697864532
epoch 91300  training loss: 0.026995453983545303
epoch 91300  clean testing loss: 0.12665849924087524
epoch 91400  training loss: 0.026995748281478882
epoch 91400  clean testing loss: 0.12664911150932312
epoch 91500  training loss: 0.02699512615799904
epoch 91500  clean testing loss: 0.1266273856163025
epoch 91600  training loss: 0.026994837448000908
epoch 91600  clean testing loss: 0.1266554296016693
epoch 91700  training loss: 0.02699495665729046
epoch 91700  clean testing loss: 0.1266738474369049
epoch 91800  training loss: 0.026994675397872925

 93%|█████████▎| 92811/100000 [02:47<00:12, 554.24it/s]
epoch 91900  training loss: 0.02699454315006733
epoch 91900  clean testing loss: 0.1266983598470688
epoch 92000  training loss: 0.026994826272130013
epoch 92000  clean testing loss: 0.12668222188949585
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 92100  training loss: 0.026994751766324043
epoch 92100  clean testing loss: 0.12666797637939453
epoch 92200  training loss: 0.026995481923222542
epoch 92200  clean testing loss: 0.1266990751028061
epoch 92300  training loss: 0.026994317770004272
epoch 92300  clean testing loss: 0.1266826093196869
epoch 92400  training loss: 0.026994023472070694
epoch 92400  clean testing loss: 0.12667396664619446
epoch 92500  training loss: 0.026994578540325165
epoch 92500  clean testing loss: 0.12667861580848694
epoch 92600  training loss: 0.02699405699968338
epoch 92600  clean testing loss: 0.12669937312602997
epoch 92700  training loss: 0.02699371799826622
epoch 92700  clean testing loss: 0.12669777870178223
epoch 92800  training loss: 0.026993975043296814
epoch 92800  clean testing loss: 0.12669450044631958
epoch 92900  training loss: 0.026993373408913612

 94%|█████████▍| 93942/100000 [02:49<00:10, 558.62it/s]
epoch 93000  training loss: 0.0269934069365263
epoch 93000  clean testing loss: 0.12671273946762085
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 93100  training loss: 0.026993364095687866
epoch 93100  clean testing loss: 0.12671823799610138
epoch 93200  training loss: 0.026993438601493835
epoch 93200  clean testing loss: 0.1267005205154419
epoch 93300  training loss: 0.02699313312768936
epoch 93300  clean testing loss: 0.12672096490859985
epoch 93400  training loss: 0.026992980390787125
epoch 93400  clean testing loss: 0.12670856714248657
epoch 93500  training loss: 0.026993028819561005
epoch 93500  clean testing loss: 0.12670843303203583
epoch 93600  training loss: 0.026993010193109512
epoch 93600  clean testing loss: 0.12671348452568054
epoch 93700  training loss: 0.026992542669177055
epoch 93700  clean testing loss: 0.12671494483947754
epoch 93800  training loss: 0.02699240855872631
epoch 93800  clean testing loss: 0.12672270834445953
epoch 93900  training loss: 0.026992425322532654
epoch 93900  clean testing loss: 0.12672437727451324
epoch 94000  training loss: 0.02699252963066101
epoch 94000  clean testing loss: 0.12672224640846252

 95%|█████████▌| 95018/100000 [02:51<00:09, 546.43it/s]
epoch 94100  training loss: 0.02699264883995056
epoch 94100  clean testing loss: 0.1267392486333847
epoch 94200  training loss: 0.026992112398147583
epoch 94200  clean testing loss: 0.12671765685081482
epoch 94300  training loss: 0.026992354542016983
epoch 94300  clean testing loss: 0.12673190236091614
epoch 94400  training loss: 0.026991989463567734
epoch 94400  clean testing loss: 0.12671294808387756
epoch 94500  training loss: 0.026992006227374077
epoch 94500  clean testing loss: 0.1267208307981491
epoch 94600  training loss: 0.02699197083711624
epoch 94600  clean testing loss: 0.12673768401145935
epoch 94700  training loss: 0.02699180506169796
epoch 94700  clean testing loss: 0.12672604620456696
epoch 94800  training loss: 0.026991916820406914
epoch 94800  clean testing loss: 0.12673625349998474
epoch 94900  training loss: 0.02699194848537445
epoch 94900  clean testing loss: 0.1267465054988861
epoch 95000  training loss: 0.026991738006472588
epoch 95000  clean testing loss: 0.12675240635871887
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 95100  training loss: 0.026991508901119232

 96%|█████████▌| 96150/100000 [02:53<00:06, 552.96it/s]
epoch 95200  training loss: 0.02699173428118229
epoch 95200  clean testing loss: 0.12674614787101746
epoch 95300  training loss: 0.02699141763150692
epoch 95300  clean testing loss: 0.12675462663173676
epoch 95400  training loss: 0.0269914623349905
epoch 95400  clean testing loss: 0.12674842774868011
epoch 95500  training loss: 0.026991277933120728
epoch 95500  clean testing loss: 0.12673942744731903
epoch 95600  training loss: 0.026991600170731544
epoch 95600  clean testing loss: 0.12675224244594574
epoch 95700  training loss: 0.02699155919253826
epoch 95700  clean testing loss: 0.12675456702709198
epoch 95800  training loss: 0.02699117548763752
epoch 95800  clean testing loss: 0.1267692744731903
epoch 95900  training loss: 0.026991521939635277
epoch 95900  clean testing loss: 0.12676820158958435
epoch 96000  training loss: 0.026990842074155807
epoch 96000  clean testing loss: 0.12675265967845917
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 96100  training loss: 0.026990579441189766
epoch 96100  clean testing loss: 0.12678365409374237
epoch 96200  training loss: 0.02699088491499424

 97%|█████████▋| 97214/100000 [02:55<00:05, 537.90it/s]
epoch 96300  training loss: 0.02699039690196514
epoch 96300  clean testing loss: 0.12676261365413666
epoch 96400  training loss: 0.026990622282028198
epoch 96400  clean testing loss: 0.1267671138048172
epoch 96500  training loss: 0.026990242302417755
epoch 96500  clean testing loss: 0.1267707347869873
epoch 96600  training loss: 0.02699037455022335
epoch 96600  clean testing loss: 0.12678144872188568
epoch 96700  training loss: 0.026990218088030815
epoch 96700  clean testing loss: 0.1267697811126709
epoch 96800  training loss: 0.02699030376970768
epoch 96800  clean testing loss: 0.12678158283233643
epoch 96900  training loss: 0.026990346610546112
epoch 96900  clean testing loss: 0.12678299844264984
epoch 97000  training loss: 0.02698996476829052
epoch 97000  clean testing loss: 0.12678249180316925
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 97100  training loss: 0.026990041136741638
epoch 97100  clean testing loss: 0.1267785280942917
epoch 97200  training loss: 0.026989733800292015
epoch 97200  clean testing loss: 0.12679074704647064
epoch 97300  training loss: 0.026989685371518135

 98%|█████████▊| 98351/100000 [02:57<00:02, 558.82it/s]
epoch 97400  training loss: 0.026989907026290894
epoch 97400  clean testing loss: 0.12679101526737213
epoch 97500  training loss: 0.02698959782719612
epoch 97500  clean testing loss: 0.12678173184394836
epoch 97600  training loss: 0.026989564299583435
epoch 97600  clean testing loss: 0.1267833709716797
epoch 97700  training loss: 0.026989396661520004
epoch 97700  clean testing loss: 0.12679073214530945
epoch 97800  training loss: 0.026989592239260674
epoch 97800  clean testing loss: 0.12680315971374512
epoch 97900  training loss: 0.026989368721842766
epoch 97900  clean testing loss: 0.1267949938774109
epoch 98000  training loss: 0.02698935940861702
epoch 98000  clean testing loss: 0.12680621445178986
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 98100  training loss: 0.026989616453647614
epoch 98100  clean testing loss: 0.12680242955684662
epoch 98200  training loss: 0.02698948234319687
epoch 98200  clean testing loss: 0.1267901062965393
epoch 98300  training loss: 0.026989081874489784
epoch 98300  clean testing loss: 0.12681390345096588
epoch 98400  training loss: 0.026989001780748367

 99%|█████████▉| 99430/100000 [02:59<00:01, 556.34it/s]
epoch 98500  training loss: 0.026989087462425232
epoch 98500  clean testing loss: 0.12680399417877197
epoch 98600  training loss: 0.02698914147913456
epoch 98600  clean testing loss: 0.1268012374639511
epoch 98700  training loss: 0.026988953351974487
epoch 98700  clean testing loss: 0.12681721150875092
epoch 98800  training loss: 0.02698918804526329
epoch 98800  clean testing loss: 0.1268090456724167
epoch 98900  training loss: 0.026988817378878593
epoch 98900  clean testing loss: 0.1268148422241211
epoch 99000  training loss: 0.02698875218629837
epoch 99000  clean testing loss: 0.12682214379310608
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...
epoch 99100  training loss: 0.02698860503733158
epoch 99100  clean testing loss: 0.1268243044614792
epoch 99200  training loss: 0.026988312602043152
epoch 99200  clean testing loss: 0.1268281489610672
epoch 99300  training loss: 0.026988279074430466
epoch 99300  clean testing loss: 0.12682397663593292
epoch 99400  training loss: 0.02698880434036255
epoch 99400  clean testing loss: 0.12682215869426727
epoch 99500  training loss: 0.026988215744495392

100%|██████████| 100000/100000 [03:00<00:00, 552.80it/s]
epoch 99600  training loss: 0.02698812633752823
epoch 99600  clean testing loss: 0.1268232762813568
epoch 99700  training loss: 0.02698819525539875
epoch 99700  clean testing loss: 0.12682640552520752
epoch 99800  training loss: 0.026987986639142036
epoch 99800  clean testing loss: 0.12683910131454468
epoch 99900  training loss: 0.026988152414560318
epoch 99900  clean testing loss: 0.12683552503585815
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size100_noise1.00e-01_invop0_lr0.005 ...