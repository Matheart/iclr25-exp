
  0%|                                                                               | 106/100000 [00:01<21:21, 77.97it/s]
epoch 0  training loss: 47.35911560058594
epoch 0  clean testing loss: 43.778743743896484
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 100  training loss: 1.224440574645996

  0%|▏                                                                              | 194/100000 [00:02<21:09, 78.59it/s]
epoch 200  training loss: 0.6971407532691956

  1%|▍                                                                              | 578/100000 [00:07<21:00, 78.87it/s]
epoch 300  training loss: 0.6561274528503418
epoch 300  clean testing loss: 0.12087194621562958
epoch 400  training loss: 0.6239513158798218
epoch 400  clean testing loss: 0.1316288411617279
epoch 500  training loss: 0.5988069176673889

  1%|▌                                                                              | 738/100000 [00:09<20:54, 79.15it/s]
epoch 600  training loss: 0.5840853452682495
epoch 600  clean testing loss: 0.15605048835277557
epoch 700  training loss: 0.5613128542900085

  1%|▋                                                                              | 899/100000 [00:11<20:46, 79.50it/s]
epoch 800  training loss: 0.5464645028114319
epoch 800  clean testing loss: 0.17225907742977142
epoch 900  training loss: 0.5308542251586914

  1%|▊                                                                             | 1051/100000 [00:13<20:55, 78.82it/s]
epoch 1000  training loss: 0.5132663249969482
epoch 1000  clean testing loss: 0.18572400510311127

  1%|▉                                                                             | 1213/100000 [00:15<20:43, 79.43it/s]
epoch 1100  training loss: 0.4875180423259735
epoch 1100  clean testing loss: 0.19968250393867493
epoch 1200  training loss: 0.4773470163345337

  1%|█                                                                             | 1377/100000 [00:17<20:55, 78.53it/s]
epoch 1300  training loss: 0.4664957523345947

  2%|█▏                                                                            | 1529/100000 [00:19<20:45, 79.08it/s]
epoch 1400  training loss: 0.46779361367225647
epoch 1400  clean testing loss: 0.24558384716510773
epoch 1500  training loss: 0.45327338576316833

  2%|█▎                                                                            | 1689/100000 [00:21<20:37, 79.47it/s]
epoch 1600  training loss: 0.43733566999435425
epoch 1600  clean testing loss: 0.27059313654899597
epoch 1700  training loss: 0.4386363625526428

  2%|█▍                                                                            | 1795/100000 [00:22<20:33, 79.63it/s]
epoch 1800  training loss: 0.4306551516056061
epoch 1800  clean testing loss: 0.2603955864906311
epoch 1900  training loss: 0.3982774615287781
epoch 1900  clean testing loss: 0.28185945749282837
epoch 2000  training loss: 0.393390953540802
epoch 2000  clean testing loss: 0.3264186680316925
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 2100  training loss: 0.3947514593601227

  2%|█▋                                                                            | 2135/100000 [00:29<21:06, 77.28it/s]
epoch 2200  training loss: 0.3673914968967438
epoch 2200  clean testing loss: 0.3259902000427246
epoch 2300  training loss: 0.35480397939682007

  2%|█▊                                                                            | 2296/100000 [00:31<20:29, 79.47it/s]
epoch 2400  training loss: 0.3918919265270233

  2%|█▉                                                                            | 2459/100000 [00:33<20:28, 79.43it/s]
epoch 2500  training loss: 0.39460813999176025
epoch 2500  clean testing loss: 0.37961745262145996
epoch 2600  training loss: 0.3454171419143677

  3%|██                                                                            | 2619/100000 [00:35<20:30, 79.17it/s]
epoch 2700  training loss: 0.338990718126297

  3%|██▏                                                                           | 2773/100000 [00:37<20:28, 79.14it/s]
epoch 2800  training loss: 0.3594086468219757
epoch 2800  clean testing loss: 0.3892102837562561
epoch 2900  training loss: 0.35937029123306274

  3%|██▎                                                                           | 2935/100000 [00:39<20:24, 79.25it/s]
epoch 3000  training loss: 0.35238659381866455
epoch 3000  clean testing loss: 0.3941000998020172
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 3100  training loss: 0.32971668243408203

  3%|██▍                                                                           | 3095/100000 [00:41<20:23, 79.17it/s]
epoch 3200  training loss: 0.3254315257072449
epoch 3200  clean testing loss: 0.4176281988620758
epoch 3300  training loss: 0.428921639919281
epoch 3300  clean testing loss: 0.30897313356399536
epoch 3400  training loss: 0.3811347186565399
epoch 3400  clean testing loss: 0.35667067766189575
epoch 3500  training loss: 0.353838711977005

  4%|██▊                                                                           | 3572/100000 [00:47<20:17, 79.19it/s]
epoch 3600  training loss: 0.34796664118766785
epoch 3600  clean testing loss: 0.38163578510284424
epoch 3700  training loss: 0.34891754388809204

  4%|██▉                                                                           | 3692/100000 [00:49<20:12, 79.43it/s]
epoch 3800  training loss: 0.3291322588920593
epoch 3800  clean testing loss: 0.4401490092277527
epoch 3900  training loss: 0.3432653844356537
epoch 3900  clean testing loss: 0.41549885272979736
epoch 4000  training loss: 0.3368307948112488
epoch 4000  clean testing loss: 0.44025719165802

  4%|███▏                                                                          | 4097/100000 [00:55<21:53, 73.01it/s]
epoch 4100  training loss: 0.3355569839477539
epoch 4100  clean testing loss: 0.4644237756729126
epoch 4200  training loss: 0.3380032181739807

  4%|███▎                                                                          | 4249/100000 [00:57<20:09, 79.16it/s]
epoch 4300  training loss: 0.3292461633682251
epoch 4300  clean testing loss: 0.4579131007194519
epoch 4400  training loss: 0.3362581431865692

  4%|███▍                                                                          | 4409/100000 [00:59<20:14, 78.73it/s]
epoch 4500  training loss: 0.3272066116333008

  4%|███▌                                                                          | 4497/100000 [01:00<20:11, 78.86it/s]
epoch 4600  training loss: 0.3231257200241089
epoch 4600  clean testing loss: 0.5131811499595642
epoch 4700  training loss: 0.31552693247795105

  5%|███▋                                                                          | 4731/100000 [01:03<20:03, 79.14it/s]
epoch 4800  training loss: 0.3341565728187561

  5%|███▊                                                                          | 4883/100000 [01:05<19:55, 79.57it/s]
epoch 4900  training loss: 0.32591310143470764
epoch 4900  clean testing loss: 0.5407702326774597
epoch 5000  training loss: 0.3167387843132019
epoch 5000  clean testing loss: 0.5315101146697998

  5%|███▉                                                                          | 5043/100000 [01:07<20:03, 78.90it/s]
epoch 5100  training loss: 0.30827009677886963
epoch 5100  clean testing loss: 0.5579494833946228
epoch 5200  training loss: 0.32941171526908875

  5%|████                                                                          | 5203/100000 [01:09<20:03, 78.76it/s]
epoch 5300  training loss: 0.3151457905769348

  5%|████▏                                                                         | 5363/100000 [01:11<20:23, 77.36it/s]
epoch 5400  training loss: 0.2971403896808624
epoch 5400  clean testing loss: 0.5709880590438843
epoch 5500  training loss: 0.28388872742652893

  5%|████▎                                                                         | 5499/100000 [01:13<19:59, 78.75it/s]
epoch 5600  training loss: 0.38551098108291626
epoch 5600  clean testing loss: 0.614832878112793
epoch 5700  training loss: 0.41377443075180054
epoch 5700  clean testing loss: 0.38398298621177673
epoch 5800  training loss: 0.37102463841438293

  6%|████▌                                                                         | 5836/100000 [01:17<19:50, 79.10it/s]
epoch 5900  training loss: 0.35272204875946045

  6%|████▋                                                                         | 5980/100000 [01:19<21:41, 72.25it/s]
epoch 6000  training loss: 0.35117366909980774
epoch 6000  clean testing loss: 0.48445749282836914
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 6100  training loss: 0.34309738874435425

  6%|████▊                                                                         | 6124/100000 [01:21<21:48, 71.75it/s]
epoch 6200  training loss: 0.3338087797164917

  6%|████▉                                                                         | 6268/100000 [01:23<21:29, 72.71it/s]
epoch 6300  training loss: 0.3433827757835388
epoch 6300  clean testing loss: 0.5420264601707458
epoch 6400  training loss: 0.311087042093277

  6%|█████                                                                         | 6420/100000 [01:25<21:50, 71.42it/s]
epoch 6500  training loss: 0.3051101267337799

  6%|█████                                                                         | 6500/100000 [01:26<21:17, 73.16it/s]
epoch 6600  training loss: 0.3107079565525055
epoch 6600  clean testing loss: 0.5591099858283997
epoch 6700  training loss: 0.30683213472366333
epoch 6700  clean testing loss: 0.5678536891937256
epoch 6800  training loss: 0.2841537594795227
epoch 6800  clean testing loss: 0.5638411641120911
epoch 6900  training loss: 0.2714296281337738
epoch 6900  clean testing loss: 0.5800933241844177
epoch 7000  training loss: 0.29758039116859436
epoch 7000  clean testing loss: 0.5861150622367859
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 7100  training loss: 0.2881052494049072

  7%|█████▌                                                                        | 7136/100000 [01:38<21:52, 70.73it/s]
epoch 7200  training loss: 0.27485039830207825

  7%|█████▋                                                                        | 7280/100000 [01:40<21:10, 73.00it/s]
epoch 7300  training loss: 0.27764350175857544
epoch 7300  clean testing loss: 0.5932998061180115
epoch 7400  training loss: 0.2650800943374634

  7%|█████▊                                                                        | 7432/100000 [01:42<21:18, 72.39it/s]
epoch 7500  training loss: 0.2873572111129761

  8%|█████▉                                                                        | 7561/100000 [01:44<23:54, 64.45it/s]
epoch 7600  training loss: 0.28007078170776367

  8%|█████▉                                                                        | 7687/100000 [01:46<23:49, 64.56it/s]
epoch 7700  training loss: 0.27402088046073914
epoch 7700  clean testing loss: 0.6022750735282898
epoch 7800  training loss: 0.26812905073165894

  8%|██████                                                                        | 7820/100000 [01:48<23:56, 64.19it/s]
epoch 7900  training loss: 0.2888254225254059

  8%|██████▏                                                                       | 7946/100000 [01:50<23:48, 64.44it/s]
epoch 8000  training loss: 0.2847638726234436
epoch 8000  clean testing loss: 0.6186636090278625

  8%|██████▎                                                                       | 8079/100000 [01:52<24:00, 63.81it/s]
epoch 8100  training loss: 0.2805691659450531
epoch 8100  clean testing loss: 0.6112208366394043
epoch 8200  training loss: 0.28143608570098877

  8%|██████▍                                                                       | 8205/100000 [01:54<23:39, 64.67it/s]
epoch 8300  training loss: 0.27360817790031433

  8%|██████▌                                                                       | 8338/100000 [01:56<23:39, 64.58it/s]
epoch 8400  training loss: 0.26256316900253296

  8%|██████▌                                                                       | 8464/100000 [01:58<23:33, 64.77it/s]
epoch 8500  training loss: 0.27648767828941345

  9%|██████▋                                                                       | 8597/100000 [02:00<23:22, 65.17it/s]
epoch 8600  training loss: 0.2777754068374634
epoch 8600  clean testing loss: 0.629779577255249
epoch 8700  training loss: 0.27285242080688477

  9%|██████▊                                                                       | 8695/100000 [02:01<23:29, 64.76it/s]
epoch 8800  training loss: 0.2595534324645996
epoch 8800  clean testing loss: 0.70585036277771
epoch 8900  training loss: 0.29332035779953003
epoch 8900  clean testing loss: 0.6162768602371216
epoch 9000  training loss: 0.26766955852508545
epoch 9000  clean testing loss: 0.6206351518630981

  9%|███████                                                                       | 9073/100000 [02:11<31:15, 48.49it/s]
epoch 9100  training loss: 0.26897937059402466

  9%|███████                                                                       | 9094/100000 [02:12<26:02, 58.19it/s]
epoch 9200  training loss: 0.2715858221054077
epoch 9200  clean testing loss: 0.6376267671585083
epoch 9300  training loss: 0.25871899724006653


 10%|███████▍                                                                      | 9500/100000 [02:18<23:24, 64.45it/s]
epoch 9400  training loss: 0.2848230004310608
epoch 9400  clean testing loss: 0.6503803730010986
epoch 9500  training loss: 0.27101919054985046
epoch 9500  clean testing loss: 0.6309043169021606
epoch 9600  training loss: 0.27948620915412903
epoch 9600  clean testing loss: 0.6022219657897949
epoch 9700  training loss: 0.2783159911632538
epoch 9700  clean testing loss: 0.6182398796081543
epoch 9800  training loss: 0.2806631028652191
epoch 9800  clean testing loss: 0.644981861114502
epoch 9900  training loss: 0.29424506425857544
epoch 9900  clean testing loss: 0.5744520425796509
epoch 10000  training loss: 0.26267194747924805
epoch 10000  clean testing loss: 0.6105528473854065

 10%|███████▋                                                                     | 10039/100000 [02:26<23:33, 63.65it/s]
epoch 10100  training loss: 0.26187998056411743

 10%|███████▊                                                                     | 10151/100000 [02:28<23:16, 64.35it/s]
epoch 10200  training loss: 0.2497284710407257
epoch 10200  clean testing loss: 0.6237937211990356
epoch 10300  training loss: 0.2412964403629303
epoch 10300  clean testing loss: 0.6286830306053162
epoch 10400  training loss: 0.23762603104114532
epoch 10400  clean testing loss: 0.6522122025489807
epoch 10500  training loss: 0.2270869016647339

 11%|████████▏                                                                    | 10557/100000 [02:34<23:02, 64.69it/s]
epoch 10600  training loss: 0.23428374528884888


 11%|████████▌                                                                    | 11096/100000 [02:47<26:45, 55.39it/s]
epoch 10700  training loss: 0.25016024708747864
epoch 10700  clean testing loss: 0.6999396085739136
epoch 10800  training loss: 0.24374046921730042
epoch 10800  clean testing loss: 0.6969671249389648
epoch 10900  training loss: 0.24654154479503632
epoch 10900  clean testing loss: 0.6930662989616394
epoch 11000  training loss: 0.2688277065753937
epoch 11000  clean testing loss: 0.6666056513786316
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 11100  training loss: 0.2639840841293335

 11%|████████▋                                                                    | 11222/100000 [02:49<23:01, 64.24it/s]
epoch 11200  training loss: 0.2587168216705322

 11%|████████▋                                                                    | 11299/100000 [02:51<22:57, 64.40it/s]
epoch 11300  training loss: 0.23361589014530182
epoch 11300  clean testing loss: 0.7456979155540466
epoch 11400  training loss: 0.24375995993614197
epoch 11400  clean testing loss: 0.7010679244995117
epoch 11500  training loss: 0.2306409478187561
epoch 11500  clean testing loss: 0.6441264748573303
epoch 11600  training loss: 0.29479512572288513
epoch 11600  clean testing loss: 0.6689062714576721
epoch 11700  training loss: 0.2785511612892151

 12%|█████████                                                                    | 11747/100000 [02:58<22:48, 64.48it/s]
epoch 11800  training loss: 0.31667760014533997

 12%|█████████▏                                                                   | 11873/100000 [03:00<22:42, 64.68it/s]
epoch 11900  training loss: 0.35325154662132263
epoch 11900  clean testing loss: 0.6619848608970642
epoch 12000  training loss: 0.3543577492237091
epoch 12000  clean testing loss: 0.6478633880615234

 12%|█████████▏                                                                   | 11999/100000 [03:01<23:03, 63.62it/s]
epoch 12100  training loss: 0.3048383891582489

 12%|█████████▎                                                                   | 12125/100000 [03:03<22:34, 64.87it/s]
epoch 12200  training loss: 0.2989320158958435
epoch 12200  clean testing loss: 0.6712514758110046
epoch 12300  training loss: 0.31367480754852295
epoch 12300  clean testing loss: 0.6482651233673096
epoch 12400  training loss: 0.297112375497818
epoch 12400  clean testing loss: 0.6116775274276733
epoch 12500  training loss: 0.2846278250217438
epoch 12500  clean testing loss: 0.6443148851394653
epoch 12600  training loss: 0.28939321637153625

 13%|█████████▋                                                                   | 12650/100000 [03:12<22:33, 64.56it/s]
epoch 12700  training loss: 0.2929283678531647

 13%|█████████▊                                                                   | 12783/100000 [03:14<22:23, 64.90it/s]
epoch 12800  training loss: 0.28074967861175537
epoch 12800  clean testing loss: 0.6168452501296997
epoch 12900  training loss: 0.2823242247104645


 13%|██████████                                                                   | 13000/100000 [03:17<22:05, 65.64it/s]
epoch 13000  training loss: 0.27733051776885986
epoch 13000  clean testing loss: 0.6691381931304932

 13%|██████████                                                                   | 13084/100000 [03:20<23:58, 60.40it/s]
epoch 13100  training loss: 0.2853170931339264
epoch 13100  clean testing loss: 0.6692551970481873
epoch 13200  training loss: 0.26825520396232605

 13%|██████████▏                                                                  | 13210/100000 [03:22<22:16, 64.95it/s]
epoch 13300  training loss: 0.2761445939540863

 13%|██████████▏                                                                  | 13294/100000 [03:23<22:28, 64.28it/s]
epoch 13400  training loss: 0.25518545508384705
epoch 13400  clean testing loss: 0.6198541522026062
epoch 13500  training loss: 0.25723516941070557
epoch 13500  clean testing loss: 0.606432318687439
epoch 13600  training loss: 0.27778157591819763


 14%|██████████▌                                                                  | 13728/100000 [03:30<22:17, 64.51it/s]
epoch 13700  training loss: 0.27446839213371277

 14%|██████████▋                                                                  | 13861/100000 [03:32<22:20, 64.25it/s]
epoch 13800  training loss: 0.30517029762268066

 14%|██████████▋                                                                  | 13896/100000 [03:32<22:17, 64.39it/s]
epoch 13900  training loss: 0.3265863060951233
epoch 13900  clean testing loss: 0.6912282705307007
epoch 14000  training loss: 0.30916744470596313
epoch 14000  clean testing loss: 0.6458309292793274

 14%|██████████▌                                                                | 14007/100000 [03:36<1:38:37, 14.53it/s]
epoch 14100  training loss: 0.3237493932247162

 14%|██████████▉                                                                  | 14140/100000 [03:38<22:22, 63.97it/s]
epoch 14200  training loss: 0.3282899260520935

 14%|██████████▉                                                                  | 14266/100000 [03:40<22:05, 64.69it/s]
epoch 14300  training loss: 0.31542661786079407
epoch 14300  clean testing loss: 0.6675043702125549
epoch 14400  training loss: 0.3004164397716522

 14%|███████████                                                                  | 14399/100000 [03:42<22:13, 64.19it/s]
epoch 14500  training loss: 0.31340083479881287

 15%|███████████▏                                                                 | 14525/100000 [03:44<22:00, 64.72it/s]
epoch 14600  training loss: 0.29796358942985535

 15%|███████████▎                                                                 | 14658/100000 [03:46<21:56, 64.82it/s]
epoch 14700  training loss: 0.28649935126304626
epoch 14700  clean testing loss: 0.606342613697052
epoch 14800  training loss: 0.28662633895874023

 15%|███████████▍                                                                 | 14784/100000 [03:48<22:03, 64.40it/s]
epoch 14900  training loss: 0.2819254398345947

 15%|███████████▍                                                                 | 14917/100000 [03:50<21:58, 64.54it/s]
epoch 15000  training loss: 0.27511346340179443
epoch 15000  clean testing loss: 0.6988644003868103

 15%|███████████▌                                                                 | 15043/100000 [03:52<22:03, 64.21it/s]
epoch 15100  training loss: 0.26353156566619873

 15%|███████████▋                                                                 | 15176/100000 [03:54<21:44, 65.01it/s]
epoch 15200  training loss: 0.2624918222427368


 16%|███████████▉                                                                 | 15561/100000 [04:00<21:45, 64.68it/s]
epoch 15300  training loss: 0.27297791838645935
epoch 15300  clean testing loss: 0.6794929504394531
epoch 15400  training loss: 0.2636847198009491
epoch 15400  clean testing loss: 0.7075240612030029
epoch 15500  training loss: 0.2664937376976013

 16%|████████████                                                                 | 15694/100000 [04:02<21:45, 64.57it/s]
epoch 15600  training loss: 0.2447466254234314
epoch 15600  clean testing loss: 0.6912506222724915
epoch 15700  training loss: 0.2365153282880783
epoch 15700  clean testing loss: 0.7259427905082703
epoch 15800  training loss: 0.2503439784049988

 16%|████████████▎                                                                | 15953/100000 [04:06<21:41, 64.55it/s]
epoch 15900  training loss: 0.2368050068616867

 16%|████████████▍                                                                | 16079/100000 [04:08<21:41, 64.50it/s]
epoch 16000  training loss: 0.24927325546741486
epoch 16000  clean testing loss: 0.6759651899337769

 16%|████████████▍                                                                | 16212/100000 [04:10<21:48, 64.03it/s]
epoch 16100  training loss: 0.2503712773323059
epoch 16100  clean testing loss: 0.6803964972496033
epoch 16200  training loss: 0.23561249673366547

 16%|████████████▌                                                                | 16338/100000 [04:12<21:41, 64.29it/s]
epoch 16300  training loss: 0.24407775700092316

 16%|████████████▌                                                                | 16394/100000 [04:13<21:37, 64.43it/s]
epoch 16400  training loss: 0.2702654004096985

 17%|█████████████▏                                                               | 17073/100000 [04:24<22:35, 61.18it/s]
epoch 16500  training loss: 0.23837825655937195
epoch 16500  clean testing loss: 0.7145566940307617
epoch 16600  training loss: 0.22918283939361572
epoch 16600  clean testing loss: 0.7499502301216125
epoch 16700  training loss: 0.24872678518295288
epoch 16700  clean testing loss: 0.7222378253936768
epoch 16800  training loss: 0.25826629996299744
epoch 16800  clean testing loss: 0.6912181973457336
epoch 16900  training loss: 0.24941276013851166
epoch 16900  clean testing loss: 0.718511164188385
epoch 17000  training loss: 0.24403390288352966
epoch 17000  clean testing loss: 0.7012428641319275

 17%|█████████████▏                                                               | 17199/100000 [04:26<21:18, 64.79it/s]
epoch 17100  training loss: 0.25562477111816406
epoch 17100  clean testing loss: 0.705038845539093
epoch 17200  training loss: 0.24402287602424622

 17%|█████████████▎                                                               | 17297/100000 [04:27<21:22, 64.50it/s]
epoch 17300  training loss: 0.24447692930698395

 17%|█████████████▍                                                               | 17458/100000 [04:30<21:17, 64.62it/s]
epoch 17400  training loss: 0.24343159794807434

 18%|█████████████▌                                                               | 17591/100000 [04:32<21:25, 64.13it/s]
epoch 17500  training loss: 0.23765113949775696

 18%|█████████████▋                                                               | 17696/100000 [04:33<21:06, 65.01it/s]
epoch 17600  training loss: 0.2542075514793396
epoch 17600  clean testing loss: 0.7242214679718018
epoch 17700  training loss: 0.2481170892715454
epoch 17700  clean testing loss: 0.7337902188301086
epoch 17800  training loss: 0.25165021419525146
epoch 17800  clean testing loss: 0.7152882218360901
epoch 17900  training loss: 0.2469482719898224

 18%|█████████████▊                                                               | 17948/100000 [04:42<28:47, 47.50it/s]
epoch 18000  training loss: 0.23684653639793396
epoch 18000  clean testing loss: 0.7526963353157043

 18%|█████████████▉                                                               | 18074/100000 [04:44<21:09, 64.54it/s]
epoch 18100  training loss: 0.23478658497333527
epoch 18100  clean testing loss: 0.7848498225212097
epoch 18200  training loss: 0.24631249904632568

 18%|██████████████                                                               | 18207/100000 [04:46<21:10, 64.38it/s]
epoch 18300  training loss: 0.23187614977359772

 18%|██████████████                                                               | 18333/100000 [04:48<21:05, 64.52it/s]
epoch 18400  training loss: 0.2408440113067627

 18%|██████████████▏                                                              | 18466/100000 [04:50<21:00, 64.69it/s]
epoch 18500  training loss: 0.2443927675485611
epoch 18500  clean testing loss: 0.8127171993255615
epoch 18600  training loss: 0.25920698046684265


 19%|██████████████▎                                                              | 18634/100000 [04:52<21:02, 64.43it/s]
epoch 18700  training loss: 0.2320505976676941
epoch 18700  clean testing loss: 0.8213329315185547
epoch 18800  training loss: 0.2265254557132721
epoch 18800  clean testing loss: 0.8079335689544678
epoch 18900  training loss: 0.2152722030878067

 19%|██████████████▋                                                              | 19082/100000 [04:59<20:51, 64.66it/s]
epoch 19000  training loss: 0.2247380018234253
epoch 19000  clean testing loss: 0.8291919231414795
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 19100  training loss: 0.22323761880397797

 19%|██████████████▊                                                              | 19208/100000 [05:01<20:51, 64.56it/s]
epoch 19200  training loss: 0.2173132300376892

 19%|██████████████▉                                                              | 19341/100000 [05:03<20:48, 64.62it/s]
epoch 19300  training loss: 0.20281070470809937

 19%|██████████████▉                                                              | 19467/100000 [05:05<20:45, 64.64it/s]
epoch 19400  training loss: 0.21252267062664032
epoch 19400  clean testing loss: 0.7810548543930054
epoch 19500  training loss: 0.2162453830242157

 20%|███████████████                                                              | 19600/100000 [05:07<20:50, 64.29it/s]
epoch 19600  training loss: 0.21742238104343414

 20%|███████████████▏                                                             | 19726/100000 [05:09<20:40, 64.69it/s]
epoch 19700  training loss: 0.20284904539585114

 20%|███████████████▎                                                             | 19859/100000 [05:11<20:39, 64.68it/s]
epoch 19800  training loss: 0.2205742597579956

 20%|███████████████▍                                                             | 19985/100000 [05:13<20:38, 64.62it/s]
epoch 19900  training loss: 0.20873455703258514
epoch 19900  clean testing loss: 0.8296617269515991
epoch 20000  training loss: 0.18887366354465485
epoch 20000  clean testing loss: 0.8255413174629211

 20%|███████████████▍                                                             | 20118/100000 [05:15<20:37, 64.57it/s]
epoch 20100  training loss: 0.20406532287597656

 20%|███████████████▌                                                             | 20244/100000 [05:17<20:44, 64.08it/s]
epoch 20200  training loss: 0.19414713978767395

 20%|███████████████▋                                                             | 20377/100000 [05:19<20:27, 64.88it/s]
epoch 20300  training loss: 0.20491188764572144
epoch 20300  clean testing loss: 0.8532286286354065
epoch 20400  training loss: 0.22133423388004303

 21%|███████████████▊                                                             | 20503/100000 [05:21<20:32, 64.49it/s]
epoch 20500  training loss: 0.22189313173294067

 21%|███████████████▉                                                             | 20636/100000 [05:24<20:33, 64.36it/s]
epoch 20600  training loss: 0.22188016772270203

 21%|███████████████▉                                                             | 20762/100000 [05:25<20:27, 64.53it/s]
epoch 20700  training loss: 0.27336445450782776

 21%|████████████████                                                             | 20888/100000 [05:27<20:24, 64.63it/s]
epoch 20800  training loss: 0.24395209550857544
epoch 20800  clean testing loss: 0.8454993367195129
epoch 20900  training loss: 0.23866963386535645

 21%|████████████████▏                                                            | 21021/100000 [05:30<20:22, 64.61it/s]
epoch 21000  training loss: 0.23900297284126282
epoch 21000  clean testing loss: 0.7966428399085999

 21%|████████████████▏                                                            | 21098/100000 [05:31<20:14, 64.99it/s]
epoch 21100  training loss: 0.2264341413974762

 21%|████████████████▍                                                            | 21280/100000 [05:34<20:12, 64.95it/s]
epoch 21200  training loss: 0.21132831275463104
epoch 21200  clean testing loss: 0.8204317092895508
epoch 21300  training loss: 0.20901337265968323

 21%|████████████████▍                                                            | 21399/100000 [05:35<20:12, 64.81it/s]
epoch 21400  training loss: 0.21678650379180908
epoch 21400  clean testing loss: 0.8039364814758301
epoch 21500  training loss: 0.2144806832075119
epoch 21500  clean testing loss: 0.8299435377120972
epoch 21600  training loss: 0.20491090416908264
epoch 21600  clean testing loss: 0.8174362182617188
epoch 21700  training loss: 0.22882789373397827
epoch 21700  clean testing loss: 0.8441591262817383
epoch 21800  training loss: 0.20961008965969086
epoch 21800  clean testing loss: 0.8503607511520386
epoch 21900  training loss: 0.2078554630279541
epoch 21900  clean testing loss: 0.8404083847999573
epoch 22000  training loss: 0.21022409200668335
epoch 22000  clean testing loss: 0.791871964931488

 22%|████████████████▉                                                            | 22050/100000 [05:45<20:18, 63.95it/s]
epoch 22100  training loss: 0.19879943132400513

 22%|█████████████████                                                            | 22183/100000 [05:48<20:01, 64.75it/s]
epoch 22200  training loss: 0.1850416511297226
epoch 22200  clean testing loss: 0.8142845630645752
epoch 22300  training loss: 0.21846579015254974

 22%|█████████████████▏                                                           | 22309/100000 [05:50<20:02, 64.63it/s]
epoch 22400  training loss: 0.20204061269760132

 22%|█████████████████▎                                                           | 22442/100000 [05:52<20:00, 64.58it/s]
epoch 22500  training loss: 0.2169899344444275

 23%|█████████████████▍                                                           | 22568/100000 [05:54<19:55, 64.76it/s]
epoch 22600  training loss: 0.18726642429828644

 23%|█████████████████▍                                                           | 22694/100000 [05:55<20:27, 62.99it/s]
epoch 22700  training loss: 0.21339167654514313
epoch 22700  clean testing loss: 0.7958618998527527
epoch 22800  training loss: 0.20743726193904877
epoch 22800  clean testing loss: 0.8073479533195496
epoch 22900  training loss: 0.24295121431350708
epoch 22900  clean testing loss: 0.8370946049690247
epoch 23000  training loss: 0.23857730627059937
epoch 23000  clean testing loss: 0.8572185635566711


 23%|█████████████████▊                                                           | 23100/100000 [06:02<20:05, 63.78it/s]
epoch 23100  training loss: 0.2638746201992035

 23%|██████████████████                                                           | 23408/100000 [06:07<19:59, 63.83it/s]
epoch 23200  training loss: 0.30531933903694153
epoch 23200  clean testing loss: 0.8156802654266357
epoch 23300  training loss: 0.3254373073577881
epoch 23300  clean testing loss: 0.8321277499198914
epoch 23400  training loss: 0.2956590950489044
epoch 23400  clean testing loss: 0.7665423154830933
epoch 23500  training loss: 0.2639012634754181


 24%|██████████████████▏                                                          | 23667/100000 [06:11<19:45, 64.39it/s]
epoch 23600  training loss: 0.2925831377506256

 24%|██████████████████▎                                                          | 23793/100000 [06:13<19:40, 64.54it/s]
epoch 23700  training loss: 0.2641475200653076

 24%|██████████████████▍                                                          | 23926/100000 [06:15<19:35, 64.70it/s]
epoch 23800  training loss: 0.27086758613586426
epoch 23800  clean testing loss: 0.8015339374542236
epoch 23900  training loss: 0.24628791213035583

 24%|██████████████████▌                                                          | 24052/100000 [06:17<19:42, 64.21it/s]
epoch 24000  training loss: 0.2390739470720291
epoch 24000  clean testing loss: 0.8399498462677002

 24%|██████████████████▌                                                          | 24185/100000 [06:19<19:31, 64.73it/s]
epoch 24100  training loss: 0.24411408603191376

 24%|██████████████████▋                                                          | 24304/100000 [06:21<19:30, 64.67it/s]
epoch 24200  training loss: 0.22932074964046478
epoch 24200  clean testing loss: 0.8427937626838684
epoch 24300  training loss: 0.248480424284935
epoch 24300  clean testing loss: 0.825484037399292
epoch 24400  training loss: 0.23829558491706848
epoch 24400  clean testing loss: 0.7735645174980164
epoch 24500  training loss: 0.23523274064064026
epoch 24500  clean testing loss: 0.7761615514755249
epoch 24600  training loss: 0.24955889582633972

 25%|██████████████████▉                                                          | 24668/100000 [06:26<19:25, 64.62it/s]
epoch 24700  training loss: 0.2549048364162445
epoch 24700  clean testing loss: 0.7786416411399841
epoch 24800  training loss: 0.24605320394039154

 25%|███████████████████                                                          | 24794/100000 [06:28<19:27, 64.41it/s]
epoch 24900  training loss: 0.26556652784347534

 25%|███████████████████▏                                                         | 24927/100000 [06:30<19:25, 64.44it/s]
epoch 25000  training loss: 0.24215184152126312

 25%|███████████████████▏                                                         | 24998/100000 [06:31<18:28, 67.65it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 25100  training loss: 0.24606549739837646

 25%|███████████████████▎                                                         | 25110/100000 [06:35<19:50, 62.89it/s]
epoch 25200  training loss: 0.24518179893493652

 25%|███████████████████▍                                                         | 25243/100000 [06:37<19:19, 64.45it/s]
epoch 25300  training loss: 0.26894593238830566

 25%|███████████████████▌                                                         | 25369/100000 [06:39<19:09, 64.95it/s]
epoch 25400  training loss: 0.24023929238319397

 25%|███████████████████▋                                                         | 25495/100000 [06:41<19:18, 64.32it/s]
epoch 25500  training loss: 0.2339010238647461

 26%|████████████████████                                                         | 26097/100000 [06:51<19:20, 63.66it/s]
epoch 25600  training loss: 0.2451052963733673
epoch 25600  clean testing loss: 0.7634556293487549
epoch 25700  training loss: 0.22468486428260803
epoch 25700  clean testing loss: 0.8182508945465088
epoch 25800  training loss: 0.2336462140083313
epoch 25800  clean testing loss: 0.8397112488746643
epoch 25900  training loss: 0.23996131122112274
epoch 25900  clean testing loss: 0.8351626396179199
epoch 26000  training loss: 0.22537797689437866
epoch 26000  clean testing loss: 0.8702567219734192
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 26100  training loss: 0.25095921754837036

 26%|████████████████████▏                                                        | 26237/100000 [06:53<19:12, 64.00it/s]
epoch 26200  training loss: 0.22715751826763153

 26%|████████████████████▎                                                        | 26370/100000 [06:55<19:03, 64.42it/s]
epoch 26300  training loss: 0.21776556968688965

 26%|████████████████████▍                                                        | 26496/100000 [06:57<18:57, 64.59it/s]
epoch 26400  training loss: 0.23779729008674622

 27%|████████████████████▍                                                        | 26594/100000 [06:58<18:52, 64.83it/s]
epoch 26500  training loss: 0.25796929001808167
epoch 26500  clean testing loss: 0.820746123790741
epoch 26600  training loss: 0.23151125013828278

 27%|████████████████████▌                                                        | 26755/100000 [07:01<18:52, 64.67it/s]
epoch 26700  training loss: 0.2383689284324646


 27%|████████████████████▊                                                        | 27000/100000 [07:05<18:43, 64.99it/s]
epoch 26800  training loss: 0.2344595044851303
epoch 26800  clean testing loss: 0.8253659009933472
epoch 26900  training loss: 0.23467570543289185
epoch 26900  clean testing loss: 0.8375349044799805
epoch 27000  training loss: 0.24322417378425598

 27%|████████████████████▉                                                        | 27126/100000 [07:09<19:04, 63.69it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 27100  training loss: 0.2202063351869583

 27%|████████████████████▉                                                        | 27259/100000 [07:11<18:51, 64.31it/s]
epoch 27200  training loss: 0.23361796140670776

 27%|█████████████████████                                                        | 27385/100000 [07:13<18:41, 64.73it/s]
epoch 27300  training loss: 0.2288070172071457

 28%|█████████████████████▏                                                       | 27518/100000 [07:15<18:44, 64.47it/s]
epoch 27400  training loss: 0.2342056930065155
epoch 27400  clean testing loss: 0.8714699149131775
epoch 27500  training loss: 0.21544896066188812

 28%|█████████████████████▎                                                       | 27644/100000 [07:17<18:44, 64.36it/s]
epoch 27600  training loss: 0.22675660252571106

 28%|█████████████████████▍                                                       | 27777/100000 [07:19<18:29, 65.10it/s]
epoch 27700  training loss: 0.21786344051361084

 28%|█████████████████████▍                                                       | 27896/100000 [07:21<18:31, 64.86it/s]
epoch 27800  training loss: 0.22421802580356598
epoch 27800  clean testing loss: 0.8872241973876953
epoch 27900  training loss: 0.23139387369155884

 28%|█████████████████████▋                                                       | 28085/100000 [07:25<19:31, 61.38it/s]
epoch 28000  training loss: 0.2369023561477661
epoch 28000  clean testing loss: 0.8880369067192078
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 28100  training loss: 0.22936445474624634

 28%|█████████████████████▋                                                       | 28197/100000 [07:27<18:34, 64.43it/s]
epoch 28200  training loss: 0.23129120469093323

 28%|█████████████████████▊                                                       | 28344/100000 [07:29<18:24, 64.90it/s]
epoch 28300  training loss: 0.2152032107114792

 28%|█████████████████████▉                                                       | 28477/100000 [07:31<18:31, 64.36it/s]
epoch 28400  training loss: 0.22708573937416077

 29%|██████████████████████                                                       | 28603/100000 [07:33<18:28, 64.43it/s]
epoch 28500  training loss: 0.22874274849891663
epoch 28500  clean testing loss: 0.9232580065727234
epoch 28600  training loss: 0.22165964543819427

 29%|██████████████████████                                                       | 28694/100000 [07:34<18:25, 64.49it/s]
epoch 28700  training loss: 0.2261340171098709

 29%|██████████████████████▏                                                      | 28862/100000 [07:37<18:29, 64.12it/s]
epoch 28800  training loss: 0.23371580243110657
epoch 28800  clean testing loss: 0.9132142663002014
epoch 28900  training loss: 0.22180403769016266

 29%|██████████████████████▎                                                      | 28988/100000 [07:39<18:15, 64.81it/s]
epoch 29000  training loss: 0.2268465757369995

 29%|██████████████████████▎                                                      | 29023/100000 [07:41<43:54, 26.95it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 29100  training loss: 0.19948959350585938

 29%|██████████████████████▍                                                      | 29156/100000 [07:43<18:23, 64.21it/s]
epoch 29200  training loss: 0.22117915749549866

 29%|██████████████████████▌                                                      | 29282/100000 [07:45<18:18, 64.36it/s]
epoch 29300  training loss: 0.22563505172729492

 29%|██████████████████████▋                                                      | 29415/100000 [07:47<18:17, 64.32it/s]
epoch 29400  training loss: 0.22646665573120117

 29%|██████████████████████▋                                                      | 29499/100000 [07:48<18:04, 65.00it/s]
epoch 29500  training loss: 0.21286213397979736
epoch 29500  clean testing loss: 0.8947852253913879
epoch 29600  training loss: 0.1965760886669159

 30%|██████████████████████▊                                                      | 29674/100000 [07:51<18:15, 64.20it/s]
epoch 29700  training loss: 0.2089071273803711

 30%|██████████████████████▉                                                      | 29800/100000 [07:53<18:09, 64.45it/s]
epoch 29800  training loss: 0.20719614624977112

 30%|███████████████████████                                                      | 29933/100000 [07:55<18:08, 64.37it/s]
epoch 29900  training loss: 0.21210861206054688
epoch 29900  clean testing loss: 0.9524866342544556
epoch 30000  training loss: 0.2157413810491562
epoch 30000  clean testing loss: 0.9623733758926392

 30%|███████████████████████▏                                                     | 30059/100000 [07:57<18:05, 64.41it/s]
epoch 30100  training loss: 0.20740897953510284

 30%|███████████████████████▏                                                     | 30192/100000 [07:59<17:53, 65.04it/s]
epoch 30200  training loss: 0.2135949432849884

 30%|███████████████████████▎                                                     | 30318/100000 [08:01<17:58, 64.63it/s]
epoch 30300  training loss: 0.19848765432834625

 30%|███████████████████████▍                                                     | 30451/100000 [08:03<17:58, 64.51it/s]
epoch 30400  training loss: 0.2009853571653366
epoch 30400  clean testing loss: 0.9525101780891418
epoch 30500  training loss: 0.20488855242729187

 31%|███████████████████████▌                                                     | 30577/100000 [08:05<17:52, 64.75it/s]
epoch 30600  training loss: 0.20096634328365326

 31%|███████████████████████▋                                                     | 30696/100000 [08:07<18:02, 64.02it/s]
epoch 30700  training loss: 0.19226020574569702

 31%|███████████████████████▊                                                     | 30899/100000 [08:10<17:42, 65.04it/s]
epoch 30800  training loss: 0.20041514933109283
epoch 30800  clean testing loss: 0.9480542540550232
epoch 30900  training loss: 0.21295380592346191

 31%|███████████████████████▉                                                     | 31032/100000 [08:12<17:51, 64.35it/s]
epoch 31000  training loss: 0.20887090265750885
epoch 31000  clean testing loss: 0.981885552406311

 31%|███████████████████████▉                                                     | 31158/100000 [08:14<17:43, 64.73it/s]
epoch 31100  training loss: 0.2161579430103302

 31%|████████████████████████                                                     | 31200/100000 [08:15<17:37, 65.07it/s]
epoch 31200  training loss: 0.22909337282180786

 31%|████████████████████████▏                                                    | 31480/100000 [08:19<17:38, 64.73it/s]
epoch 31300  training loss: 0.20674481987953186
epoch 31300  clean testing loss: 0.9484078884124756
epoch 31400  training loss: 0.20482759177684784

 32%|████████████████████████▎                                                    | 31613/100000 [08:21<17:42, 64.36it/s]
epoch 31500  training loss: 0.19281065464019775
epoch 31500  clean testing loss: 0.943026065826416
epoch 31600  training loss: 0.19988666474819183

 32%|████████████████████████▍                                                    | 31739/100000 [08:23<17:31, 64.89it/s]
epoch 31700  training loss: 0.2123708575963974

 32%|████████████████████████▍                                                    | 31795/100000 [08:24<17:30, 64.90it/s]
epoch 31800  training loss: 0.2367405742406845

 32%|████████████████████████▋                                                    | 32061/100000 [08:31<26:03, 43.45it/s]
epoch 31900  training loss: 0.2000236064195633
epoch 31900  clean testing loss: 0.9114840626716614
epoch 32000  training loss: 0.2210134118795395
epoch 32000  clean testing loss: 0.9117297530174255
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 32100  training loss: 0.1981307566165924

 32%|████████████████████████▊                                                    | 32194/100000 [08:33<17:30, 64.57it/s]
epoch 32200  training loss: 0.19471809267997742

 32%|████████████████████████▊                                                    | 32299/100000 [08:35<17:33, 64.27it/s]
epoch 32300  training loss: 0.20011040568351746
epoch 32300  clean testing loss: 0.9069634079933167
epoch 32400  training loss: 0.17362353205680847
epoch 32400  clean testing loss: 0.93502277135849
epoch 32500  training loss: 0.2055881768465042

 32%|█████████████████████████                                                    | 32495/100000 [08:38<17:32, 64.12it/s]
epoch 32600  training loss: 0.1920369267463684

 33%|█████████████████████████▏                                                   | 32656/100000 [08:41<17:20, 64.70it/s]
epoch 32700  training loss: 0.200407013297081

 33%|█████████████████████████▏                                                   | 32782/100000 [08:43<17:19, 64.65it/s]
epoch 32800  training loss: 0.19418928027153015

 33%|█████████████████████████▎                                                   | 32915/100000 [08:45<17:16, 64.73it/s]
epoch 32900  training loss: 0.18982334434986115
epoch 32900  clean testing loss: 0.9228622317314148
epoch 33000  training loss: 0.21351230144500732
epoch 33000  clean testing loss: 0.9335173964500427

 33%|█████████████████████████▍                                                   | 33041/100000 [08:47<17:27, 63.93it/s]
epoch 33100  training loss: 0.1803690493106842

 33%|█████████████████████████▌                                                   | 33174/100000 [08:49<17:04, 65.25it/s]
epoch 33200  training loss: 0.2007785439491272

 33%|█████████████████████████▋                                                   | 33300/100000 [08:51<17:01, 65.28it/s]
epoch 33300  training loss: 0.19439278542995453
epoch 33300  clean testing loss: 0.9239273071289062
epoch 33400  training loss: 0.18990959227085114

 33%|█████████████████████████▋                                                   | 33433/100000 [08:53<17:09, 64.67it/s]
epoch 33500  training loss: 0.19246672093868256


epoch 33500  clean testing loss: 0.9247298836708069
epoch 33600  training loss: 0.2235262244939804
epoch 33600  clean testing loss: 0.9236829280853271
epoch 33700  training loss: 0.21932397782802582

 34%|██████████████████████████                                                   | 33909/100000 [09:00<17:06, 64.40it/s]
epoch 33800  training loss: 0.2064768522977829
epoch 33800  clean testing loss: 0.9310427904129028
epoch 33900  training loss: 0.2094825804233551

 34%|██████████████████████████▏                                                  | 34049/100000 [09:02<17:06, 64.26it/s]
epoch 34000  training loss: 0.19619086384773254
epoch 34000  clean testing loss: 0.9354819655418396

 34%|██████████████████████████▎                                                  | 34175/100000 [09:04<16:51, 65.11it/s]
epoch 34100  training loss: 0.20005497336387634

 34%|██████████████████████████▍                                                  | 34308/100000 [09:06<16:57, 64.56it/s]
epoch 34200  training loss: 0.19783666729927063
epoch 34200  clean testing loss: 0.9583909511566162
epoch 34300  training loss: 0.18909820914268494

 34%|██████████████████████████▍                                                  | 34399/100000 [09:08<16:53, 64.73it/s]
epoch 34400  training loss: 0.18994258344173431

 35%|██████████████████████████▋                                                  | 34630/100000 [09:11<16:56, 64.32it/s]
epoch 34500  training loss: 0.18995755910873413
epoch 34500  clean testing loss: 0.9640088081359863
epoch 34600  training loss: 0.18420806527137756

 35%|██████████████████████████▊                                                  | 34756/100000 [09:13<16:56, 64.17it/s]
epoch 34700  training loss: 0.17608237266540527

 35%|██████████████████████████▊                                                  | 34889/100000 [09:15<16:46, 64.69it/s]
epoch 34800  training loss: 0.1926499903202057

 35%|██████████████████████████▉                                                  | 34994/100000 [09:17<16:50, 64.32it/s]
epoch 34900  training loss: 0.19123496115207672
epoch 34900  clean testing loss: 1.017541527748108
epoch 35000  training loss: 0.17955675721168518

 35%|███████████████████████████                                                  | 35113/100000 [09:19<16:45, 64.52it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 35100  training loss: 0.21411478519439697

 35%|███████████████████████████▏                                                 | 35239/100000 [09:21<16:43, 64.53it/s]
epoch 35200  training loss: 0.20908211171627045

 35%|███████████████████████████▏                                                 | 35365/100000 [09:23<16:45, 64.27it/s]
epoch 35300  training loss: 0.18860825896263123

 35%|███████████████████████████▎                                                 | 35498/100000 [09:25<16:39, 64.55it/s]
epoch 35400  training loss: 0.2157057225704193
epoch 35400  clean testing loss: 1.0108033418655396
epoch 35500  training loss: 0.19857370853424072

 36%|███████████████████████████▍                                                 | 35596/100000 [09:27<16:42, 64.26it/s]
epoch 35600  training loss: 0.21116626262664795

 36%|███████████████████████████                                                | 36009/100000 [09:35<1:23:02, 12.84it/s]
epoch 35700  training loss: 0.2131505161523819
epoch 35700  clean testing loss: 0.9836418628692627
epoch 35800  training loss: 0.19776441156864166
epoch 35800  clean testing loss: 0.9614083766937256
epoch 35900  training loss: 0.1793590933084488
epoch 35900  clean testing loss: 0.9863231778144836
epoch 36000  training loss: 0.18333297967910767
epoch 36000  clean testing loss: 0.9986458420753479

 36%|███████████████████████████▊                                                 | 36142/100000 [09:37<16:34, 64.22it/s]
epoch 36100  training loss: 0.18874552845954895
epoch 36100  clean testing loss: 0.9987157583236694
epoch 36200  training loss: 0.17324842512607574

 36%|███████████████████████████▉                                                 | 36268/100000 [09:39<16:25, 64.70it/s]
epoch 36300  training loss: 0.1871386170387268
epoch 36300  clean testing loss: 1.0171304941177368
epoch 36400  training loss: 0.19243775308132172


 37%|████████████████████████████▎                                                | 36793/100000 [09:47<16:23, 64.24it/s]
epoch 36500  training loss: 0.20117893815040588
epoch 36500  clean testing loss: 1.0404328107833862
epoch 36600  training loss: 0.1895282119512558
epoch 36600  clean testing loss: 1.0239602327346802
epoch 36700  training loss: 0.19627881050109863
epoch 36700  clean testing loss: 1.0616084337234497
epoch 36800  training loss: 0.20370054244995117
epoch 36800  clean testing loss: 1.0461225509643555
epoch 36900  training loss: 0.18942052125930786


 37%|████████████████████████████▍                                                | 37000/100000 [09:50<13:41, 76.69it/s]
epoch 37000  training loss: 0.19785135984420776

 37%|████████████████████████████▌                                                | 37106/100000 [10:00<18:36, 56.34it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 37100  training loss: 0.2091405689716339

 37%|████████████████████████████▋                                                | 37232/100000 [10:02<16:07, 64.85it/s]
epoch 37200  training loss: 0.1900000423192978

 37%|████████████████████████████▋                                                | 37330/100000 [10:03<16:06, 64.87it/s]
epoch 37300  training loss: 0.18887238204479218

 37%|████████████████████████████▊                                                | 37491/100000 [10:06<16:05, 64.76it/s]
epoch 37400  training loss: 0.19894449412822723

 38%|████████████████████████████▉                                                | 37624/100000 [10:08<15:58, 65.06it/s]
epoch 37500  training loss: 0.1848648339509964
epoch 37500  clean testing loss: 1.0549644231796265
epoch 37600  training loss: 0.19754701852798462

 38%|█████████████████████████████                                                | 37757/100000 [10:10<16:07, 64.35it/s]
epoch 37700  training loss: 0.21062836050987244

 38%|█████████████████████████████▏                                               | 37883/100000 [10:12<15:57, 64.88it/s]
epoch 37800  training loss: 0.20279020071029663

 38%|█████████████████████████████▎                                               | 38016/100000 [10:14<15:58, 64.65it/s]
epoch 37900  training loss: 0.202092245221138
epoch 37900  clean testing loss: 1.0905346870422363
epoch 38000  training loss: 0.1877772957086563
epoch 38000  clean testing loss: 1.0816230773925781

 38%|█████████████████████████████▎                                               | 38142/100000 [10:16<15:54, 64.80it/s]
epoch 38100  training loss: 0.20370511710643768

 38%|█████████████████████████████▍                                               | 38198/100000 [10:17<15:49, 65.08it/s]
epoch 38200  training loss: 0.20946557819843292

 38%|█████████████████████████████▋                                               | 38499/100000 [10:21<15:46, 64.97it/s]
epoch 38300  training loss: 0.18996353447437286
epoch 38300  clean testing loss: 1.0819417238235474
epoch 38400  training loss: 0.1959531605243683

 39%|█████████████████████████████▋                                               | 38632/100000 [10:23<15:47, 64.74it/s]
epoch 38500  training loss: 0.17746518552303314
epoch 38500  clean testing loss: 1.0403461456298828
epoch 38600  training loss: 0.1995389461517334
epoch 38600  clean testing loss: 1.0795419216156006
epoch 38700  training loss: 0.18937711417675018

 39%|█████████████████████████████▊                                               | 38695/100000 [10:24<15:58, 63.97it/s]
epoch 38800  training loss: 0.1885339468717575
epoch 38800  clean testing loss: 1.0586097240447998
epoch 38900  training loss: 0.16765156388282776
epoch 38900  clean testing loss: 1.0713486671447754
epoch 39000  training loss: 0.1912091225385666
epoch 39000  clean testing loss: 1.0454427003860474

 39%|██████████████████████████████                                               | 38989/100000 [10:29<15:37, 65.07it/s]
epoch 39100  training loss: 0.18123777210712433

 39%|██████████████████████████████                                               | 39115/100000 [10:31<15:39, 64.82it/s]
epoch 39200  training loss: 0.18960948288440704

 39%|██████████████████████████████▏                                              | 39248/100000 [10:33<15:37, 64.80it/s]
epoch 39300  training loss: 0.1782558709383011
epoch 39300  clean testing loss: 1.0402278900146484
epoch 39400  training loss: 0.19987481832504272

 39%|██████████████████████████████▎                                              | 39374/100000 [10:35<15:37, 64.65it/s]
epoch 39500  training loss: 0.1807728111743927

 40%|██████████████████████████████▍                                              | 39507/100000 [10:37<15:40, 64.33it/s]
epoch 39600  training loss: 0.16773831844329834

 40%|██████████████████████████████▌                                              | 39633/100000 [10:39<15:31, 64.80it/s]
epoch 39700  training loss: 0.17339813709259033

 40%|██████████████████████████████▌                                              | 39766/100000 [10:41<15:27, 64.95it/s]
epoch 39800  training loss: 0.16969776153564453
epoch 39800  clean testing loss: 1.0236088037490845
epoch 39900  training loss: 0.18683496117591858

 40%|██████████████████████████████▋                                              | 39892/100000 [10:43<15:24, 65.04it/s]
epoch 40000  training loss: 0.18403948843479156
epoch 40000  clean testing loss: 1.0479766130447388

 40%|██████████████████████████████▊                                              | 40088/100000 [10:46<15:28, 64.54it/s]
epoch 40100  training loss: 0.17524176836013794

 40%|██████████████████████████████▉                                              | 40221/100000 [10:48<15:18, 65.07it/s]
epoch 40200  training loss: 0.16616351902484894

 40%|███████████████████████████████                                              | 40354/100000 [10:51<15:22, 64.69it/s]
epoch 40300  training loss: 0.17630954086780548
epoch 40300  clean testing loss: 1.0150521993637085
epoch 40400  training loss: 0.17370225489139557

 40%|███████████████████████████████▏                                             | 40480/100000 [10:52<15:19, 64.70it/s]
epoch 40500  training loss: 0.17716006934642792

 41%|███████████████████████████████▎                                             | 40613/100000 [10:55<15:38, 63.29it/s]
epoch 40600  training loss: 0.16798484325408936

 41%|███████████████████████████████▎                                             | 40739/100000 [10:57<15:12, 64.97it/s]
epoch 40700  training loss: 0.17879869043827057

 41%|███████████████████████████████▍                                             | 40795/100000 [10:57<15:15, 64.70it/s]
epoch 40800  training loss: 0.16222520172595978
epoch 40800  clean testing loss: 1.0212584733963013
epoch 40900  training loss: 0.1781611144542694
epoch 40900  clean testing loss: 0.998297393321991
epoch 41000  training loss: 0.19237741827964783
epoch 41000  clean testing loss: 1.0023598670959473
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 41100  training loss: 0.16147522628307343

 41%|███████████████████████████████▋                                             | 41124/100000 [11:09<15:41, 62.51it/s]
epoch 41200  training loss: 0.17574387788772583

 41%|███████████████████████████████▊                                             | 41257/100000 [11:11<15:09, 64.58it/s]
epoch 41300  training loss: 0.1736498475074768


 42%|████████████████████████████████▎                                            | 41894/100000 [11:20<14:58, 64.65it/s]
epoch 41400  training loss: 0.17181098461151123
epoch 41400  clean testing loss: 1.030753493309021
epoch 41500  training loss: 0.17051921784877777
epoch 41500  clean testing loss: 1.0509775876998901
epoch 41600  training loss: 0.18988974392414093
epoch 41600  clean testing loss: 1.0386627912521362
epoch 41700  training loss: 0.18031591176986694
epoch 41700  clean testing loss: 1.0493159294128418
epoch 41800  training loss: 0.1881054788827896
epoch 41800  clean testing loss: 1.0610162019729614
epoch 41900  training loss: 0.1973208338022232

 42%|████████████████████████████████▍                                            | 42090/100000 [11:27<16:47, 57.47it/s]
epoch 42000  training loss: 0.19107463955879211
epoch 42000  clean testing loss: 1.0713623762130737
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 42100  training loss: 0.17650696635246277

 42%|████████████████████████████████▍                                            | 42195/100000 [11:28<14:52, 64.76it/s]
epoch 42200  training loss: 0.18177154660224915
epoch 42200  clean testing loss: 1.0743680000305176
epoch 42300  training loss: 0.184885635972023
epoch 42300  clean testing loss: 1.0501395463943481
epoch 42400  training loss: 0.17067088186740875

 42%|████████████████████████████████▋                                            | 42482/100000 [11:33<14:46, 64.89it/s]
epoch 42500  training loss: 0.19448889791965485
epoch 42500  clean testing loss: 1.0430018901824951
epoch 42600  training loss: 0.1737336814403534

 43%|████████████████████████████████▊                                            | 42594/100000 [11:34<14:59, 63.85it/s]
epoch 42700  training loss: 0.18474644422531128
epoch 42700  clean testing loss: 1.0077552795410156
epoch 42800  training loss: 0.18761897087097168

 43%|█████████████████████████████████                                            | 42895/100000 [11:39<14:43, 64.60it/s]
epoch 42900  training loss: 0.17957141995429993
epoch 42900  clean testing loss: 1.0258064270019531
epoch 43000  training loss: 0.17798839509487152
epoch 43000  clean testing loss: 1.0443685054779053

 43%|█████████████████████████████████▏                                           | 43098/100000 [11:42<14:43, 64.43it/s]
epoch 43100  training loss: 0.17134515941143036

 44%|█████████████████████████████████▊                                           | 43903/100000 [11:55<14:43, 63.47it/s]
epoch 43200  training loss: 0.1778450459241867
epoch 43200  clean testing loss: 1.0165913105010986
epoch 43300  training loss: 0.18222001194953918
epoch 43300  clean testing loss: 1.0311797857284546
epoch 43400  training loss: 0.1889072209596634
epoch 43400  clean testing loss: 1.0316787958145142
epoch 43500  training loss: 0.17586472630500793
epoch 43500  clean testing loss: 1.0425268411636353
epoch 43600  training loss: 0.1855163872241974
epoch 43600  clean testing loss: 1.066487193107605
epoch 43700  training loss: 0.18268339335918427
epoch 43700  clean testing loss: 1.0656458139419556
epoch 43800  training loss: 0.1771259605884552
epoch 43800  clean testing loss: 1.0676963329315186
epoch 43900  training loss: 0.18607978522777557

 44%|█████████████████████████████████▉                                           | 44036/100000 [11:57<14:26, 64.58it/s]
epoch 44000  training loss: 0.18069054186344147
epoch 44000  clean testing loss: 1.0668740272521973
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 44100  training loss: 0.17323169112205505

 44%|██████████████████████████████████                                           | 44162/100000 [11:59<14:20, 64.86it/s]
epoch 44200  training loss: 0.20955803990364075

 45%|██████████████████████████████████▍                                          | 44778/100000 [12:08<14:14, 64.66it/s]
epoch 44300  training loss: 0.1732696294784546
epoch 44300  clean testing loss: 1.0646075010299683
epoch 44400  training loss: 0.188950777053833
epoch 44400  clean testing loss: 1.0708515644073486
epoch 44500  training loss: 0.17387887835502625
epoch 44500  clean testing loss: 1.073615550994873
epoch 44600  training loss: 0.16879087686538696
epoch 44600  clean testing loss: 1.0831084251403809
epoch 44700  training loss: 0.1711539924144745

 45%|██████████████████████████████████▌                                          | 44911/100000 [12:10<14:19, 64.09it/s]
epoch 44800  training loss: 0.17333616316318512

 45%|██████████████████████████████████▋                                          | 45037/100000 [12:12<14:09, 64.68it/s]
epoch 44900  training loss: 0.18394428491592407
epoch 44900  clean testing loss: 1.0677231550216675
epoch 45000  training loss: 0.18214774131774902
epoch 45000  clean testing loss: 1.0606402158737183

 45%|██████████████████████████████████▋                                          | 45100/100000 [12:13<14:07, 64.75it/s]
epoch 45100  training loss: 0.1855696439743042

 45%|██████████████████████████████████▉                                          | 45296/100000 [12:16<14:06, 64.60it/s]
epoch 45200  training loss: 0.18992267549037933

 45%|██████████████████████████████████▉                                          | 45394/100000 [12:18<13:58, 65.10it/s]
epoch 45300  training loss: 0.1785968393087387
epoch 45300  clean testing loss: 1.1135838031768799
epoch 45400  training loss: 0.18304429948329926

 46%|███████████████████████████████████▏                                         | 45688/100000 [12:22<14:00, 64.60it/s]
epoch 45500  training loss: 0.1772686094045639
epoch 45500  clean testing loss: 1.1289080381393433
epoch 45600  training loss: 0.18914249539375305

 46%|███████████████████████████████████▎                                         | 45793/100000 [12:24<13:56, 64.82it/s]
epoch 45700  training loss: 0.19105800986289978

 46%|███████████████████████████████████▍                                         | 46073/100000 [12:28<14:00, 64.13it/s]
epoch 45800  training loss: 0.21201542019844055
epoch 45800  clean testing loss: 1.0763938426971436
epoch 45900  training loss: 0.21234528720378876
epoch 45900  clean testing loss: 1.0971568822860718
epoch 46000  training loss: 0.2598133087158203
epoch 46000  clean testing loss: 1.0400495529174805

 46%|███████████████████████████████████▌                                         | 46199/100000 [12:30<13:53, 64.53it/s]
epoch 46100  training loss: 0.2652198374271393

 46%|███████████████████████████████████▋                                         | 46297/100000 [12:32<13:49, 64.75it/s]
epoch 46200  training loss: 0.31768763065338135
epoch 46200  clean testing loss: 1.0026459693908691
epoch 46300  training loss: 0.3177972435951233


 47%|████████████████████████████████████                                         | 46759/100000 [12:40<13:54, 63.83it/s]
epoch 46400  training loss: 0.3573909401893616
epoch 46400  clean testing loss: 1.07650887966156
epoch 46500  training loss: 0.3597783148288727
epoch 46500  clean testing loss: 1.0275012254714966
epoch 46600  training loss: 0.34829556941986084
epoch 46600  clean testing loss: 1.007368803024292
epoch 46700  training loss: 0.46028822660446167

 47%|████████████████████████████████████                                         | 46794/100000 [12:41<13:43, 64.64it/s]
epoch 46800  training loss: 0.5383182764053345

 47%|████████████████████████████████████▏                                        | 47049/100000 [12:46<20:00, 44.10it/s]
epoch 46900  training loss: 0.46229174733161926
epoch 46900  clean testing loss: 1.064047932624817
epoch 47000  training loss: 0.39663514494895935
epoch 47000  clean testing loss: 1.0072635412216187

 47%|████████████████████████████████████▎                                        | 47097/100000 [12:47<13:00, 67.80it/s]
epoch 47100  training loss: 0.539354681968689

 47%|████████████████████████████████████▍                                        | 47305/100000 [12:50<12:10, 72.09it/s]
epoch 47200  training loss: 0.5337718725204468
epoch 47200  clean testing loss: 0.9731374979019165
epoch 47300  training loss: 0.6028879880905151

 47%|████████████████████████████████████▌                                        | 47449/100000 [12:52<12:12, 71.75it/s]
epoch 47400  training loss: 0.5821177959442139

 48%|████████████████████████████████████▋                                        | 47593/100000 [12:54<12:01, 72.61it/s]
epoch 47500  training loss: 0.5460642576217651
epoch 47500  clean testing loss: 1.0354424715042114
epoch 47600  training loss: 0.49773281812667847

 48%|████████████████████████████████████▋                                        | 47697/100000 [12:55<12:03, 72.31it/s]
epoch 47700  training loss: 0.5085381865501404
epoch 47700  clean testing loss: 0.8901258111000061
epoch 47800  training loss: 0.4515051543712616

 48%|████████████████████████████████████▊                                        | 47889/100000 [12:58<11:52, 73.16it/s]
epoch 47900  training loss: 0.4419739842414856
epoch 47900  clean testing loss: 0.783957839012146
epoch 48000  training loss: 0.39224907755851746
epoch 48000  clean testing loss: 0.7765777111053467

 48%|████████████████████████████████████▉                                        | 48033/100000 [13:00<11:55, 72.67it/s]
epoch 48100  training loss: 0.38022249937057495

 48%|█████████████████████████████████████                                        | 48177/100000 [13:02<11:52, 72.77it/s]
epoch 48200  training loss: 0.3698904514312744
epoch 48200  clean testing loss: 0.7922782301902771
epoch 48300  training loss: 0.3698004484176636

 48%|█████████████████████████████████████▏                                       | 48329/100000 [13:04<11:46, 73.15it/s]
epoch 48400  training loss: 0.3694925010204315

 48%|█████████████████████████████████████▎                                       | 48473/100000 [13:06<11:57, 71.79it/s]
epoch 48500  training loss: 0.3756274878978729


 49%|█████████████████████████████████████▊                                       | 49049/100000 [13:14<11:39, 72.83it/s]
epoch 48600  training loss: 0.38000112771987915
epoch 48600  clean testing loss: 0.7425830364227295
epoch 48700  training loss: 0.3780478835105896
epoch 48700  clean testing loss: 0.7264780402183533
epoch 48800  training loss: 0.3599039912223816
epoch 48800  clean testing loss: 0.6993458867073059
epoch 48900  training loss: 0.3495747447013855
epoch 48900  clean testing loss: 0.7001522779464722
epoch 49000  training loss: 0.3380786180496216
epoch 49000  clean testing loss: 0.6920000314712524

 49%|█████████████████████████████████████▉                                       | 49201/100000 [13:16<11:35, 73.08it/s]
epoch 49100  training loss: 0.3381578028202057
epoch 49100  clean testing loss: 0.6869199275970459
epoch 49200  training loss: 0.35690900683403015

 49%|█████████████████████████████████████▉                                       | 49345/100000 [13:18<11:49, 71.45it/s]
epoch 49300  training loss: 0.33706751465797424

 49%|██████████████████████████████████████                                       | 49393/100000 [13:19<11:53, 70.90it/s]
epoch 49400  training loss: 0.33656468987464905

 50%|██████████████████████████████████████▏                                      | 49657/100000 [13:22<11:30, 72.92it/s]
epoch 49500  training loss: 0.32508331537246704
epoch 49500  clean testing loss: 0.698003351688385
epoch 49600  training loss: 0.3179979920387268

 50%|██████████████████████████████████████▍                                      | 49961/100000 [13:26<11:22, 73.33it/s]
epoch 49700  training loss: 0.32501959800720215
epoch 49700  clean testing loss: 0.7014598846435547
epoch 49800  training loss: 0.3364458680152893
epoch 49800  clean testing loss: 0.7102349400520325
epoch 49900  training loss: 0.3079948127269745

 50%|██████████████████████████████████████▌                                      | 50001/100000 [13:29<58:56, 14.14it/s]
epoch 50000  training loss: 0.30520740151405334
epoch 50000  clean testing loss: 0.7112199068069458

 50%|██████████████████████████████████████▌                                      | 50145/100000 [13:30<11:36, 71.57it/s]
epoch 50100  training loss: 0.2994794547557831

 50%|██████████████████████████████████████▋                                      | 50289/100000 [13:32<11:19, 73.19it/s]
epoch 50200  training loss: 0.3210155963897705

 50%|██████████████████████████████████████▊                                      | 50433/100000 [13:34<11:30, 71.82it/s]
epoch 50300  training loss: 0.3360520005226135
epoch 50300  clean testing loss: 0.7446057200431824
epoch 50400  training loss: 0.3391314744949341

 51%|██████████████████████████████████████▉                                      | 50577/100000 [13:36<11:17, 72.94it/s]
epoch 50500  training loss: 0.3211280405521393

 51%|███████████████████████████████████████                                      | 50729/100000 [13:39<11:31, 71.22it/s]
epoch 50600  training loss: 0.30812641978263855
epoch 50600  clean testing loss: 0.7666624784469604
epoch 50700  training loss: 0.3046184182167053

 51%|███████████████████████████████████████                                      | 50793/100000 [13:39<11:16, 72.74it/s]
epoch 50800  training loss: 0.31131961941719055
epoch 50800  clean testing loss: 0.7787612080574036
epoch 50900  training loss: 0.2998845875263214
epoch 50900  clean testing loss: 0.7721251845359802
epoch 51000  training loss: 0.30369144678115845
epoch 51000  clean testing loss: 0.7714762687683105

 51%|███████████████████████████████████████▎                                     | 51057/100000 [13:43<11:13, 72.64it/s]
epoch 51100  training loss: 0.3188535273075104
epoch 51100  clean testing loss: 0.7792621850967407
epoch 51200  training loss: 0.3013455867767334

 51%|███████████████████████████████████████▍                                     | 51193/100000 [13:45<11:07, 73.16it/s]
epoch 51300  training loss: 0.3108460307121277

 51%|███████████████████████████████████████▌                                     | 51345/100000 [13:47<11:17, 71.81it/s]
epoch 51400  training loss: 0.2909295856952667

 51%|███████████████████████████████████████▋                                     | 51489/100000 [13:49<11:04, 72.98it/s]
epoch 51500  training loss: 0.30308854579925537
epoch 51500  clean testing loss: 0.7570068836212158
epoch 51600  training loss: 0.28847232460975647

 52%|███████████████████████████████████████▊                                     | 51641/100000 [13:51<11:06, 72.52it/s]
epoch 51700  training loss: 0.2854008972644806

 52%|███████████████████████████████████████▊                                     | 51785/100000 [13:53<11:02, 72.74it/s]
epoch 51800  training loss: 0.2783070206642151
epoch 51800  clean testing loss: 0.7579195499420166
epoch 51900  training loss: 0.29334118962287903

 52%|███████████████████████████████████████▉                                     | 51929/100000 [13:55<11:08, 71.86it/s]
epoch 52000  training loss: 0.299376904964447
epoch 52000  clean testing loss: 0.7450903654098511

 52%|████████████████████████████████████████                                     | 52073/100000 [13:57<10:56, 73.04it/s]
epoch 52100  training loss: 0.2924858629703522
epoch 52100  clean testing loss: 0.7554336786270142
epoch 52200  training loss: 0.291990727186203

 52%|████████████████████████████████████████▏                                    | 52217/100000 [13:59<10:55, 72.95it/s]
epoch 52300  training loss: 0.2837752103805542

 52%|████████████████████████████████████████▎                                    | 52329/100000 [14:01<10:50, 73.34it/s]
epoch 52400  training loss: 0.2656354606151581
epoch 52400  clean testing loss: 0.7669858932495117
epoch 52500  training loss: 0.2857210338115692

 52%|████████████████████████████████████████▍                                    | 52481/100000 [14:03<10:47, 73.35it/s]
epoch 52600  training loss: 0.2736262083053589

 53%|████████████████████████████████████████▌                                    | 52625/100000 [14:05<10:48, 73.02it/s]
epoch 52700  training loss: 0.28778770565986633
epoch 52700  clean testing loss: 0.7616398334503174
epoch 52800  training loss: 0.2732979655265808

 53%|████████████████████████████████████████▋                                    | 52769/100000 [14:07<10:44, 73.29it/s]
epoch 52900  training loss: 0.2646467983722687

 53%|████████████████████████████████████████▋                                    | 52921/100000 [14:09<10:50, 72.42it/s]
epoch 53000  training loss: 0.27491065859794617
epoch 53000  clean testing loss: 0.7391019463539124

 53%|████████████████████████████████████████▊                                    | 53065/100000 [14:11<10:42, 73.08it/s]
epoch 53100  training loss: 0.2696123719215393
epoch 53100  clean testing loss: 0.7421620488166809
epoch 53200  training loss: 0.2663035988807678

 53%|████████████████████████████████████████▉                                    | 53209/100000 [14:13<10:40, 73.05it/s]
epoch 53300  training loss: 0.28851544857025146

 53%|█████████████████████████████████████████                                    | 53353/100000 [14:15<10:36, 73.23it/s]
epoch 53400  training loss: 0.27997538447380066
epoch 53400  clean testing loss: 0.7624377608299255
epoch 53500  training loss: 0.28024518489837646

 54%|█████████████████████████████████████████▏                                   | 53505/100000 [14:17<10:37, 72.91it/s]
epoch 53600  training loss: 0.2681101858615875

 54%|█████████████████████████████████████████▎                                   | 53649/100000 [14:19<10:31, 73.39it/s]
epoch 53700  training loss: 0.2757464647293091
epoch 53700  clean testing loss: 0.777363657951355
epoch 53800  training loss: 0.28557392954826355

 54%|█████████████████████████████████████████▍                                   | 53793/100000 [14:21<10:40, 72.10it/s]
epoch 53900  training loss: 0.3030798137187958

 54%|█████████████████████████████████████████▌                                   | 53945/100000 [14:23<10:28, 73.25it/s]
epoch 54000  training loss: 0.2819235324859619
epoch 54000  clean testing loss: 0.7574553489685059
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 54100  training loss: 0.2758343517780304

 54%|█████████████████████████████████████████▋                                   | 54089/100000 [14:25<10:27, 73.18it/s]
epoch 54200  training loss: 0.28466126322746277

 54%|█████████████████████████████████████████▊                                   | 54233/100000 [14:27<10:26, 73.06it/s]
epoch 54300  training loss: 0.27511751651763916
epoch 54300  clean testing loss: 0.7699281573295593
epoch 54400  training loss: 0.2673986852169037

 54%|█████████████████████████████████████████▉                                   | 54385/100000 [14:29<10:26, 72.77it/s]
epoch 54500  training loss: 0.29193076491355896

 55%|█████████████████████████████████████████▉                                   | 54529/100000 [14:31<10:22, 73.09it/s]
epoch 54600  training loss: 0.2994304299354553
epoch 54600  clean testing loss: 0.7773740887641907
epoch 54700  training loss: 0.3009316623210907

 55%|██████████████████████████████████████████                                   | 54673/100000 [14:33<10:21, 72.90it/s]
epoch 54800  training loss: 0.2960686683654785

 55%|██████████████████████████████████████████▏                                  | 54817/100000 [14:35<10:29, 71.74it/s]
epoch 54900  training loss: 0.2803291082382202

 55%|██████████████████████████████████████████▎                                  | 54961/100000 [14:37<10:26, 71.84it/s]
epoch 55000  training loss: 0.2920351028442383
epoch 55000  clean testing loss: 0.7779389023780823
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 55100  training loss: 0.277860164642334

 55%|██████████████████████████████████████████▍                                  | 55105/100000 [14:39<10:16, 72.82it/s]
epoch 55200  training loss: 0.27992960810661316

 55%|██████████████████████████████████████████▌                                  | 55257/100000 [14:41<10:24, 71.64it/s]
epoch 55300  training loss: 0.26339688897132874
epoch 55300  clean testing loss: 0.751456618309021
epoch 55400  training loss: 0.2732979655265808

 55%|██████████████████████████████████████████▋                                  | 55401/100000 [14:43<10:09, 73.13it/s]
epoch 55500  training loss: 0.268184632062912

 56%|██████████████████████████████████████████▊                                  | 55545/100000 [14:45<10:11, 72.65it/s]
epoch 55600  training loss: 0.26912733912467957
epoch 55600  clean testing loss: 0.7670212984085083
epoch 55700  training loss: 0.2803713083267212

 56%|██████████████████████████████████████████▉                                  | 55689/100000 [14:47<10:05, 73.23it/s]
epoch 55800  training loss: 0.2795390188694

 56%|██████████████████████████████████████████▉                                  | 55841/100000 [14:49<10:02, 73.32it/s]
epoch 55900  training loss: 0.27081620693206787
epoch 55900  clean testing loss: 0.7592718601226807
epoch 56000  training loss: 0.2609185576438904
epoch 56000  clean testing loss: 0.7665291428565979

 56%|███████████████████████████████████████████                                  | 55985/100000 [14:51<10:00, 73.26it/s]
epoch 56100  training loss: 0.27323293685913086

 56%|███████████████████████████████████████████▏                                 | 56129/100000 [14:53<10:08, 72.12it/s]
epoch 56200  training loss: 0.2827320992946625
epoch 56200  clean testing loss: 0.7720114588737488
epoch 56300  training loss: 0.27079689502716064

 56%|███████████████████████████████████████████▎                                 | 56273/100000 [14:55<09:59, 72.97it/s]
epoch 56400  training loss: 0.263357549905777

 56%|███████████████████████████████████████████▍                                 | 56417/100000 [14:57<10:06, 71.85it/s]
epoch 56500  training loss: 0.26426416635513306

 57%|███████████████████████████████████████████▌                                 | 56561/100000 [14:59<10:07, 71.56it/s]
epoch 56600  training loss: 0.2714906334877014
epoch 56600  clean testing loss: 0.7633688449859619
epoch 56700  training loss: 0.2625056803226471

 57%|███████████████████████████████████████████▋                                 | 56705/100000 [15:01<10:04, 71.65it/s]
epoch 56800  training loss: 0.26136356592178345

 57%|███████████████████████████████████████████▊                                 | 56849/100000 [15:03<09:48, 73.29it/s]
epoch 56900  training loss: 0.2755962312221527
epoch 56900  clean testing loss: 0.7512025833129883
epoch 57000  training loss: 0.266044944524765
epoch 57000  clean testing loss: 0.758180558681488

 57%|███████████████████████████████████████████▉                                 | 57001/100000 [15:05<10:10, 70.39it/s]
epoch 57100  training loss: 0.26950812339782715

 57%|████████████████████████████████████████████                                 | 57145/100000 [15:07<09:47, 72.93it/s]
epoch 57200  training loss: 0.2621833086013794
epoch 57200  clean testing loss: 0.7517029047012329
epoch 57300  training loss: 0.2735491693019867

 57%|████████████████████████████████████████████                                 | 57289/100000 [15:09<09:46, 72.77it/s]
epoch 57400  training loss: 0.26585403084754944

 57%|████████████████████████████████████████████▏                                | 57433/100000 [15:11<09:46, 72.54it/s]
epoch 57500  training loss: 0.2631079852581024
epoch 57500  clean testing loss: 0.7677243947982788
epoch 57600  training loss: 0.25906646251678467

 58%|████████████████████████████████████████████▎                                | 57577/100000 [15:13<09:38, 73.28it/s]
epoch 57700  training loss: 0.2615845501422882

 58%|████████████████████████████████████████████▍                                | 57729/100000 [15:15<09:34, 73.55it/s]
epoch 57800  training loss: 0.26299726963043213

 58%|████████████████████████████████████████████▌                                | 57873/100000 [15:17<09:41, 72.51it/s]
epoch 57900  training loss: 0.26694411039352417
epoch 57900  clean testing loss: 0.7625414133071899
epoch 58000  training loss: 0.2651662230491638
epoch 58000  clean testing loss: 0.7613714337348938

 58%|████████████████████████████████████████████▋                                | 58017/100000 [15:19<09:44, 71.86it/s]
epoch 58100  training loss: 0.25830551981925964

 58%|████████████████████████████████████████████▊                                | 58161/100000 [15:21<09:31, 73.25it/s]
epoch 58200  training loss: 0.26069995760917664
epoch 58200  clean testing loss: 0.783845841884613
epoch 58300  training loss: 0.27394357323646545

 58%|████████████████████████████████████████████▉                                | 58305/100000 [15:23<09:33, 72.76it/s]
epoch 58400  training loss: 0.2650453746318817


 59%|█████████████████████████████████████████████                                | 58601/100000 [15:27<09:25, 73.19it/s]
epoch 58500  training loss: 0.2707928717136383
epoch 58500  clean testing loss: 0.7806174755096436
epoch 58600  training loss: 0.2682068943977356

 59%|█████████████████████████████████████████████▏                               | 58745/100000 [15:29<09:25, 73.00it/s]
epoch 58700  training loss: 0.2581286132335663

 59%|█████████████████████████████████████████████▎                               | 58889/100000 [15:31<09:20, 73.40it/s]
epoch 58800  training loss: 0.24674008786678314
epoch 58800  clean testing loss: 0.7954941987991333
epoch 58900  training loss: 0.27638742327690125

 59%|█████████████████████████████████████████████▍                               | 59041/100000 [15:33<09:21, 72.97it/s]
epoch 59000  training loss: 0.2543928325176239
epoch 59000  clean testing loss: 0.7947125434875488

 59%|█████████████████████████████████████████████▌                               | 59185/100000 [15:35<09:26, 72.00it/s]
epoch 59100  training loss: 0.24839332699775696
epoch 59100  clean testing loss: 0.7788576483726501
epoch 59200  training loss: 0.26170477271080017

 59%|█████████████████████████████████████████████▋                               | 59329/100000 [15:37<09:23, 72.13it/s]
epoch 59300  training loss: 0.2694561779499054

 59%|█████████████████████████████████████████████▊                               | 59473/100000 [15:39<09:16, 72.81it/s]
epoch 59400  training loss: 0.25978001952171326

 60%|█████████████████████████████████████████████▉                               | 59617/100000 [15:41<09:11, 73.24it/s]
epoch 59500  training loss: 0.27637970447540283
epoch 59500  clean testing loss: 0.7924999594688416
epoch 59600  training loss: 0.26821932196617126

 60%|██████████████████████████████████████████████                               | 59769/100000 [15:43<09:10, 73.08it/s]
epoch 59700  training loss: 0.27826595306396484

 60%|██████████████████████████████████████████████▏                              | 59913/100000 [15:45<09:09, 72.93it/s]
epoch 59800  training loss: 0.2593858242034912
epoch 59800  clean testing loss: 0.789174497127533
epoch 59900  training loss: 0.27376773953437805

 60%|██████████████████████████████████████████████▏                              | 60057/100000 [15:47<09:13, 72.22it/s]
epoch 60000  training loss: 0.26748085021972656
epoch 60000  clean testing loss: 0.7921002507209778
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 60100  training loss: 0.2559112012386322
epoch 60100  clean testing loss: 0.7939851880073547
epoch 60200  training loss: 0.26206424832344055

 60%|██████████████████████████████████████████████▎                              | 60201/100000 [15:49<09:04, 73.13it/s]
epoch 60300  training loss: 0.26081836223602295

 60%|██████████████████████████████████████████████▍                              | 60353/100000 [15:51<09:05, 72.65it/s]
epoch 60400  training loss: 0.261429101228714
epoch 60400  clean testing loss: 0.79525226354599
epoch 60500  training loss: 0.25777125358581543

 60%|██████████████████████████████████████████████▌                              | 60497/100000 [15:53<08:59, 73.17it/s]
epoch 60600  training loss: 0.2574509382247925

 61%|██████████████████████████████████████████████▋                              | 60641/100000 [15:55<08:58, 73.08it/s]
epoch 60700  training loss: 0.2603764832019806
epoch 60700  clean testing loss: 0.8262877464294434
epoch 60800  training loss: 0.2604081332683563

 61%|██████████████████████████████████████████████▊                              | 60793/100000 [15:57<09:01, 72.45it/s]
epoch 60900  training loss: 0.2628556787967682

 61%|██████████████████████████████████████████████▉                              | 60937/100000 [15:59<08:53, 73.18it/s]
epoch 61000  training loss: 0.26247933506965637
epoch 61000  clean testing loss: 0.8051965832710266

 61%|██████████████████████████████████████████████▉                              | 61017/100000 [16:00<09:06, 71.36it/s]
epoch 61100  training loss: 0.2595275342464447
epoch 61100  clean testing loss: 0.80745929479599
epoch 61200  training loss: 0.25817036628723145
epoch 61200  clean testing loss: 0.8139249682426453
epoch 61300  training loss: 0.2616652846336365
epoch 61300  clean testing loss: 0.8080273866653442
epoch 61400  training loss: 0.24526222050189972
epoch 61400  clean testing loss: 0.8153016567230225
epoch 61500  training loss: 0.2555411756038666
epoch 61500  clean testing loss: 0.8114254474639893
epoch 61600  training loss: 0.24720633029937744
epoch 61600  clean testing loss: 0.8120445013046265
epoch 61700  training loss: 0.2509056329727173
epoch 61700  clean testing loss: 0.8090085983276367
epoch 61800  training loss: 0.24563126266002655

 62%|███████████████████████████████████████████████▌                             | 61809/100000 [16:11<08:40, 73.35it/s]
epoch 61900  training loss: 0.2437509298324585

 62%|███████████████████████████████████████████████▋                             | 61953/100000 [16:13<08:42, 72.83it/s]
epoch 62000  training loss: 0.2737185060977936
epoch 62000  clean testing loss: 0.8226835131645203
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 62100  training loss: 0.25264886021614075

 62%|███████████████████████████████████████████████▊                             | 62105/100000 [16:15<08:44, 72.20it/s]
epoch 62200  training loss: 0.25112199783325195

 62%|███████████████████████████████████████████████▉                             | 62249/100000 [16:17<08:35, 73.19it/s]
epoch 62300  training loss: 0.25645825266838074
epoch 62300  clean testing loss: 0.8125232458114624
epoch 62400  training loss: 0.2523503303527832

 62%|████████████████████████████████████████████████                             | 62393/100000 [16:19<08:41, 72.06it/s]
epoch 62500  training loss: 0.26680484414100647

 63%|████████████████████████████████████████████████▏                            | 62537/100000 [16:21<08:36, 72.53it/s]
epoch 62600  training loss: 0.26207199692726135

 63%|████████████████████████████████████████████████▎                            | 62681/100000 [16:23<08:33, 72.64it/s]
epoch 62700  training loss: 0.26042452454566956
epoch 62700  clean testing loss: 0.8219183683395386
epoch 62800  training loss: 0.24683232605457306

 63%|████████████████████████████████████████████████▍                            | 62833/100000 [16:25<08:28, 73.14it/s]
epoch 62900  training loss: 0.26285532116889954

 63%|████████████████████████████████████████████████▍                            | 62977/100000 [16:27<08:26, 73.11it/s]
epoch 63000  training loss: 0.2639281749725342
epoch 63000  clean testing loss: 0.8305377960205078
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 63100  training loss: 0.25968411564826965

 63%|████████████████████████████████████████████████▌                            | 63121/100000 [16:29<08:26, 72.87it/s]
epoch 63200  training loss: 0.24319204688072205

 63%|████████████████████████████████████████████████▋                            | 63273/100000 [16:31<08:18, 73.73it/s]
epoch 63300  training loss: 0.24301914870738983
epoch 63300  clean testing loss: 0.8427000641822815
epoch 63400  training loss: 0.2543550729751587

 63%|████████████████████████████████████████████████▊                            | 63417/100000 [16:33<08:24, 72.55it/s]
epoch 63500  training loss: 0.25545749068260193

 64%|████████████████████████████████████████████████▉                            | 63561/100000 [16:35<08:18, 73.05it/s]
epoch 63600  training loss: 0.24129022657871246
epoch 63600  clean testing loss: 0.844731867313385
epoch 63700  training loss: 0.24486331641674042

 64%|█████████████████████████████████████████████████                            | 63705/100000 [16:37<08:26, 71.69it/s]
epoch 63800  training loss: 0.24417303502559662

 64%|█████████████████████████████████████████████████▏                           | 63849/100000 [16:39<08:13, 73.19it/s]
epoch 63900  training loss: 0.2572568356990814
epoch 63900  clean testing loss: 0.8429180979728699
epoch 64000  training loss: 0.25944268703460693
epoch 64000  clean testing loss: 0.8484451174736023

 64%|█████████████████████████████████████████████████▎                           | 63993/100000 [16:41<08:14, 72.76it/s]
epoch 64100  training loss: 0.2468445748090744

 64%|█████████████████████████████████████████████████▍                           | 64145/100000 [16:43<08:13, 72.66it/s]
epoch 64200  training loss: 0.23879733681678772

 64%|█████████████████████████████████████████████████▍                           | 64281/100000 [16:45<08:08, 73.18it/s]
epoch 64300  training loss: 0.23257596790790558
epoch 64300  clean testing loss: 0.8528335690498352
epoch 64400  training loss: 0.25470638275146484

 64%|█████████████████████████████████████████████████▌                           | 64433/100000 [16:47<08:04, 73.38it/s]
epoch 64500  training loss: 0.2586893141269684

 65%|█████████████████████████████████████████████████▋                           | 64577/100000 [16:49<08:07, 72.70it/s]
epoch 64600  training loss: 0.2534480094909668
epoch 64600  clean testing loss: 0.8819965124130249
epoch 64700  training loss: 0.25006312131881714

 65%|█████████████████████████████████████████████████▊                           | 64729/100000 [16:51<08:04, 72.75it/s]
epoch 64800  training loss: 0.24673369526863098

 65%|█████████████████████████████████████████████████▉                           | 64873/100000 [16:53<07:57, 73.49it/s]
epoch 64900  training loss: 0.2372395247220993
epoch 64900  clean testing loss: 0.8840311169624329
epoch 65000  training loss: 0.25568896532058716
epoch 65000  clean testing loss: 0.8770455718040466

 65%|██████████████████████████████████████████████████                           | 65017/100000 [16:55<08:08, 71.56it/s]
epoch 65100  training loss: 0.23850685358047485

 65%|██████████████████████████████████████████████████▏                          | 65161/100000 [16:57<08:07, 71.48it/s]
epoch 65200  training loss: 0.2512429356575012
epoch 65200  clean testing loss: 0.8867924213409424
epoch 65300  training loss: 0.2437586933374405

 65%|██████████████████████████████████████████████████▎                          | 65305/100000 [16:59<07:55, 72.91it/s]
epoch 65400  training loss: 0.2527998089790344


 66%|██████████████████████████████████████████████████▌                          | 65601/100000 [17:03<07:49, 73.27it/s]
epoch 65500  training loss: 0.23408564925193787
epoch 65500  clean testing loss: 0.8883438110351562
epoch 65600  training loss: 0.24602621793746948

 66%|██████████████████████████████████████████████████▌                          | 65745/100000 [17:05<07:49, 72.91it/s]
epoch 65700  training loss: 0.24336738884449005

 66%|██████████████████████████████████████████████████▋                          | 65897/100000 [17:07<07:45, 73.28it/s]
epoch 65800  training loss: 0.24611970782279968
epoch 65800  clean testing loss: 0.8842973113059998
epoch 65900  training loss: 0.2382686585187912

 66%|██████████████████████████████████████████████████▊                          | 66033/100000 [17:09<07:55, 71.45it/s]
epoch 66000  training loss: 0.2479427009820938
epoch 66000  clean testing loss: 0.8910567164421082

 66%|██████████████████████████████████████████████████▉                          | 66185/100000 [17:11<07:47, 72.29it/s]
epoch 66100  training loss: 0.2518526017665863

 66%|███████████████████████████████████████████████████                          | 66329/100000 [17:13<07:38, 73.41it/s]
epoch 66200  training loss: 0.23491303622722626
epoch 66200  clean testing loss: 0.904373288154602
epoch 66300  training loss: 0.24821515381336212

 66%|███████████████████████████████████████████████████▏                         | 66473/100000 [17:15<07:43, 72.38it/s]
epoch 66400  training loss: 0.24411533772945404

 67%|███████████████████████████████████████████████████▎                         | 66617/100000 [17:17<07:36, 73.08it/s]
epoch 66500  training loss: 0.24329087138175964
epoch 66500  clean testing loss: 0.9099339842796326
epoch 66600  training loss: 0.236038938164711

 67%|███████████████████████████████████████████████████▍                         | 66761/100000 [17:19<07:34, 73.12it/s]
epoch 66700  training loss: 0.24065086245536804

 67%|███████████████████████████████████████████████████▌                         | 66913/100000 [17:21<07:33, 72.89it/s]
epoch 66800  training loss: 0.24185284972190857
epoch 66800  clean testing loss: 0.887111485004425
epoch 66900  training loss: 0.24509315192699432
epoch 66900  clean testing loss: 0.8797773718833923
epoch 67000  training loss: 0.2321244180202484
epoch 67000  clean testing loss: 0.8870639204978943

 67%|███████████████████████████████████████████████████▋                         | 67057/100000 [17:23<07:32, 72.81it/s]
epoch 67100  training loss: 0.24484749138355255
epoch 67100  clean testing loss: 0.8913225531578064
epoch 67200  training loss: 0.23106124997138977

 67%|███████████████████████████████████████████████████▋                         | 67201/100000 [17:25<07:29, 72.94it/s]
epoch 67300  training loss: 0.23490256071090698

 67%|███████████████████████████████████████████████████▊                         | 67345/100000 [17:27<07:30, 72.42it/s]
epoch 67400  training loss: 0.2347111999988556

 67%|███████████████████████████████████████████████████▉                         | 67497/100000 [17:29<07:28, 72.51it/s]
epoch 67500  training loss: 0.23239143192768097
epoch 67500  clean testing loss: 0.9021401405334473
epoch 67600  training loss: 0.23316019773483276

 68%|████████████████████████████████████████████████████                         | 67641/100000 [17:31<07:24, 72.87it/s]
epoch 67700  training loss: 0.241414412856102

 68%|████████████████████████████████████████████████████▏                        | 67785/100000 [17:33<07:21, 72.99it/s]
epoch 67800  training loss: 0.2408178150653839
epoch 67800  clean testing loss: 0.908333420753479
epoch 67900  training loss: 0.22920405864715576

 68%|████████████████████████████████████████████████████▎                        | 67929/100000 [17:35<07:18, 73.22it/s]
epoch 68000  training loss: 0.24265576899051666
epoch 68000  clean testing loss: 0.9191511869430542

 68%|████████████████████████████████████████████████████▍                        | 68081/100000 [17:37<07:17, 72.95it/s]
epoch 68100  training loss: 0.2473905384540558
epoch 68100  clean testing loss: 0.9172105193138123
epoch 68200  training loss: 0.24058952927589417

 68%|████████████████████████████████████████████████████▌                        | 68225/100000 [17:39<07:15, 73.02it/s]
epoch 68300  training loss: 0.2353743463754654

 68%|████████████████████████████████████████████████████▋                        | 68369/100000 [17:41<07:11, 73.38it/s]
epoch 68400  training loss: 0.24654492735862732
epoch 68400  clean testing loss: 0.92146235704422
epoch 68500  training loss: 0.24190875887870789

 69%|████████████████████████████████████████████████████▊                        | 68521/100000 [17:43<07:12, 72.80it/s]
epoch 68600  training loss: 0.23745417594909668

 69%|████████████████████████████████████████████████████▊                        | 68665/100000 [17:45<07:10, 72.76it/s]
epoch 68700  training loss: 0.23498576879501343
epoch 68700  clean testing loss: 0.9196574687957764
epoch 68800  training loss: 0.2322278916835785

 69%|████████████████████████████████████████████████████▉                        | 68809/100000 [17:47<07:10, 72.44it/s]
epoch 68900  training loss: 0.24368275701999664

 69%|█████████████████████████████████████████████████████                        | 68953/100000 [17:49<07:07, 72.67it/s]
epoch 69000  training loss: 0.233989879488945
epoch 69000  clean testing loss: 0.9154789447784424
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 69100  training loss: 0.24210511147975922

 69%|█████████████████████████████████████████████████████▏                       | 69105/100000 [17:51<07:07, 72.27it/s]
epoch 69200  training loss: 0.22382250428199768

 69%|█████████████████████████████████████████████████████▎                       | 69249/100000 [17:53<07:01, 72.92it/s]
epoch 69300  training loss: 0.23726405203342438

 69%|█████████████████████████████████████████████████████▍                       | 69361/100000 [17:55<06:58, 73.27it/s]
epoch 69400  training loss: 0.23698195815086365
epoch 69400  clean testing loss: 0.9153206944465637
epoch 69500  training loss: 0.23054958879947662

 70%|█████████████████████████████████████████████████████▌                       | 69505/100000 [17:57<07:01, 72.42it/s]
epoch 69600  training loss: 0.23963560163974762

 70%|█████████████████████████████████████████████████████▋                       | 69649/100000 [17:59<06:54, 73.29it/s]
epoch 69700  training loss: 0.2404731661081314
epoch 69700  clean testing loss: 0.9371857643127441
epoch 69800  training loss: 0.229729562997818

 70%|█████████████████████████████████████████████████████▋                       | 69793/100000 [18:01<06:54, 72.91it/s]
epoch 69900  training loss: 0.24742993712425232

 70%|█████████████████████████████████████████████████████▊                       | 69945/100000 [18:03<06:48, 73.51it/s]
epoch 70000  training loss: 0.2564677894115448
epoch 70000  clean testing loss: 0.9194428324699402
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 70100  training loss: 0.23583906888961792

 70%|█████████████████████████████████████████████████████▉                       | 70089/100000 [18:05<06:46, 73.62it/s]
epoch 70200  training loss: 0.23098525404930115

 70%|██████████████████████████████████████████████████████                       | 70233/100000 [18:07<06:52, 72.20it/s]
epoch 70300  training loss: 0.23838010430335999
epoch 70300  clean testing loss: 0.915042519569397
epoch 70400  training loss: 0.22937677800655365

 70%|██████████████████████████████████████████████████████▏                      | 70377/100000 [18:09<06:47, 72.62it/s]
epoch 70500  training loss: 0.22569169104099274

 71%|██████████████████████████████████████████████████████▎                      | 70529/100000 [18:11<06:44, 72.89it/s]
epoch 70600  training loss: 0.2369486391544342
epoch 70600  clean testing loss: 0.9396926164627075
epoch 70700  training loss: 0.23224487900733948

 71%|██████████████████████████████████████████████████████▍                      | 70673/100000 [18:13<06:42, 72.95it/s]
epoch 70800  training loss: 0.23634281754493713

 71%|██████████████████████████████████████████████████████▌                      | 70817/100000 [18:15<06:40, 72.83it/s]
epoch 70900  training loss: 0.22462734580039978

 71%|██████████████████████████████████████████████████████▋                      | 70969/100000 [18:17<06:37, 72.96it/s]
epoch 71000  training loss: 0.22826218605041504
epoch 71000  clean testing loss: 0.9325144290924072
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 71100  training loss: 0.22052624821662903

 71%|██████████████████████████████████████████████████████▊                      | 71113/100000 [18:19<06:36, 72.79it/s]
epoch 71200  training loss: 0.21576103568077087

 71%|██████████████████████████████████████████████████████▊                      | 71257/100000 [18:21<06:37, 72.30it/s]
epoch 71300  training loss: 0.22449851036071777
epoch 71300  clean testing loss: 0.9255901575088501
epoch 71400  training loss: 0.22514687478542328

 71%|██████████████████████████████████████████████████████▉                      | 71401/100000 [18:23<06:30, 73.22it/s]
epoch 71500  training loss: 0.22648575901985168

 72%|███████████████████████████████████████████████████████                      | 71553/100000 [18:25<06:27, 73.49it/s]
epoch 71600  training loss: 0.23464679718017578
epoch 71600  clean testing loss: 0.9419184923171997
epoch 71700  training loss: 0.23277540504932404

 72%|███████████████████████████████████████████████████████▏                     | 71697/100000 [18:27<06:28, 72.93it/s]
epoch 71800  training loss: 0.22803883254528046


 72%|███████████████████████████████████████████████████████▍                     | 71985/100000 [18:31<06:24, 72.83it/s]
epoch 71900  training loss: 0.22472748160362244
epoch 71900  clean testing loss: 0.9341447949409485
epoch 72000  training loss: 0.2178543210029602
epoch 72000  clean testing loss: 0.9318727254867554
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 72100  training loss: 0.21548527479171753

 72%|███████████████████████████████████████████████████████▌                     | 72137/100000 [18:33<06:20, 73.31it/s]
epoch 72200  training loss: 0.2298208475112915
epoch 72200  clean testing loss: 0.9354365468025208
epoch 72300  training loss: 0.23435117304325104


 72%|███████████████████████████████████████████████████████▊                     | 72425/100000 [18:37<06:18, 72.76it/s]
epoch 72400  training loss: 0.22222299873828888

 73%|███████████████████████████████████████████████████████▉                     | 72569/100000 [18:39<06:12, 73.59it/s]
epoch 72500  training loss: 0.22871901094913483
epoch 72500  clean testing loss: 0.9356657266616821
epoch 72600  training loss: 0.23486396670341492

 73%|███████████████████████████████████████████████████████▉                     | 72697/100000 [18:41<06:13, 73.05it/s]
epoch 72700  training loss: 0.2337077409029007
epoch 72700  clean testing loss: 0.9352841973304749
epoch 72800  training loss: 0.21664033830165863
epoch 72800  clean testing loss: 0.9348090291023254
epoch 72900  training loss: 0.2219419628381729
epoch 72900  clean testing loss: 0.9331901669502258
epoch 73000  training loss: 0.22740204632282257
epoch 73000  clean testing loss: 0.9387122392654419


 73%|████████████████████████████████████████████████████████▍                    | 73283/100000 [18:49<06:06, 72.88it/s]
epoch 73100  training loss: 0.2261812537908554
epoch 73100  clean testing loss: 0.9317409992218018
epoch 73200  training loss: 0.2194807380437851
epoch 73200  clean testing loss: 0.941672146320343
epoch 73300  training loss: 0.23336851596832275

 73%|████████████████████████████████████████████████████████▌                    | 73427/100000 [18:51<06:03, 73.04it/s]
epoch 73400  training loss: 0.23549915850162506

 74%|████████████████████████████████████████████████████████▋                    | 73571/100000 [18:53<06:07, 71.92it/s]
epoch 73500  training loss: 0.2214190512895584

 74%|████████████████████████████████████████████████████████▋                    | 73595/100000 [18:53<06:03, 72.63it/s]
epoch 73600  training loss: 0.23186494410037994

 74%|████████████████████████████████████████████████████████▉                    | 73931/100000 [18:58<05:57, 73.01it/s]
epoch 73700  training loss: 0.23283693194389343
epoch 73700  clean testing loss: 0.9395190477371216
epoch 73800  training loss: 0.22038786113262177
epoch 73800  clean testing loss: 0.9414353966712952
epoch 73900  training loss: 0.22479701042175293

 74%|█████████████████████████████████████████████████████████                    | 74075/100000 [19:00<05:56, 72.75it/s]
epoch 74000  training loss: 0.2312009185552597
epoch 74000  clean testing loss: 0.9470925331115723
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 74100  training loss: 0.24009516835212708

 74%|█████████████████████████████████████████████████████████▏                   | 74227/100000 [19:02<05:55, 72.58it/s]
epoch 74200  training loss: 0.23496012389659882

 74%|█████████████████████████████████████████████████████████▎                   | 74371/100000 [19:04<05:54, 72.34it/s]
epoch 74300  training loss: 0.2337590754032135

 75%|█████████████████████████████████████████████████████████▍                   | 74515/100000 [19:06<05:57, 71.28it/s]
epoch 74400  training loss: 0.2297086864709854
epoch 74400  clean testing loss: 0.9615623354911804
epoch 74500  training loss: 0.2296387404203415

 75%|█████████████████████████████████████████████████████████▍                   | 74659/100000 [19:08<05:44, 73.57it/s]
epoch 74600  training loss: 0.23083177208900452

 75%|█████████████████████████████████████████████████████████▌                   | 74803/100000 [19:10<05:47, 72.50it/s]
epoch 74700  training loss: 0.224979966878891
epoch 74700  clean testing loss: 0.9633386731147766
epoch 74800  training loss: 0.21831010282039642

 75%|█████████████████████████████████████████████████████████▋                   | 74955/100000 [19:12<05:40, 73.64it/s]
epoch 74900  training loss: 0.23352019488811493

 75%|█████████████████████████████████████████████████████████▊                   | 75099/100000 [19:14<05:40, 73.18it/s]
epoch 75000  training loss: 0.2386743724346161
epoch 75000  clean testing loss: 0.9276119470596313
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 75100  training loss: 0.2192344218492508

 75%|█████████████████████████████████████████████████████████▉                   | 75243/100000 [19:16<05:38, 73.12it/s]
epoch 75200  training loss: 0.22222080826759338

 75%|██████████████████████████████████████████████████████████                   | 75387/100000 [19:18<05:38, 72.72it/s]
epoch 75300  training loss: 0.22746552526950836
epoch 75300  clean testing loss: 0.9225162863731384
epoch 75400  training loss: 0.23663662374019623

 76%|██████████████████████████████████████████████████████████▏                  | 75539/100000 [19:20<05:35, 72.99it/s]
epoch 75500  training loss: 0.22284159064292908

 76%|██████████████████████████████████████████████████████████▎                  | 75683/100000 [19:22<05:33, 72.88it/s]
epoch 75600  training loss: 0.23422729969024658
epoch 75600  clean testing loss: 0.9067139029502869
epoch 75700  training loss: 0.22572870552539825

 76%|██████████████████████████████████████████████████████████▍                  | 75827/100000 [19:24<05:31, 73.03it/s]
epoch 75800  training loss: 0.23113314807415009

 76%|██████████████████████████████████████████████████████████▌                  | 75979/100000 [19:26<05:27, 73.43it/s]
epoch 75900  training loss: 0.22167906165122986

 76%|██████████████████████████████████████████████████████████▌                  | 76123/100000 [19:28<05:27, 72.95it/s]
epoch 76000  training loss: 0.2333020567893982
epoch 76000  clean testing loss: 0.908221423625946
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 76100  training loss: 0.2342754304409027

 76%|██████████████████████████████████████████████████████████▋                  | 76259/100000 [19:30<05:24, 73.21it/s]
epoch 76200  training loss: 0.2330199033021927

 76%|██████████████████████████████████████████████████████████▊                  | 76411/100000 [19:32<05:23, 73.01it/s]
epoch 76300  training loss: 0.2309499979019165
epoch 76300  clean testing loss: 0.9085037708282471
epoch 76400  training loss: 0.22509656846523285

 77%|██████████████████████████████████████████████████████████▉                  | 76563/100000 [19:34<05:20, 73.20it/s]
epoch 76500  training loss: 0.2266230285167694

 77%|███████████████████████████████████████████████████████████                  | 76707/100000 [19:36<05:29, 70.59it/s]
epoch 76600  training loss: 0.23523463308811188
epoch 76600  clean testing loss: 0.9011214971542358
epoch 76700  training loss: 0.22393232583999634

 77%|███████████████████████████████████████████████████████████▏                 | 76851/100000 [19:38<05:18, 72.57it/s]
epoch 76800  training loss: 0.2442724108695984

 77%|███████████████████████████████████████████████████████████▎                 | 76995/100000 [19:40<05:17, 72.39it/s]
epoch 76900  training loss: 0.2377895712852478
epoch 76900  clean testing loss: 0.918071448802948
epoch 77000  training loss: 0.23258689045906067
epoch 77000  clean testing loss: 0.9189249277114868

 77%|███████████████████████████████████████████████████████████▍                 | 77139/100000 [19:42<05:16, 72.13it/s]
epoch 77100  training loss: 0.22324571013450623

 77%|███████████████████████████████████████████████████████████▌                 | 77283/100000 [19:44<05:10, 73.14it/s]
epoch 77200  training loss: 0.22285352647304535
epoch 77200  clean testing loss: 0.9198928475379944
epoch 77300  training loss: 0.2329874187707901

 77%|███████████████████████████████████████████████████████████▌                 | 77435/100000 [19:46<05:13, 71.95it/s]
epoch 77400  training loss: 0.2256697565317154

 78%|███████████████████████████████████████████████████████████▋                 | 77579/100000 [19:48<05:06, 73.16it/s]
epoch 77500  training loss: 0.23215101659297943

 78%|███████████████████████████████████████████████████████████▊                 | 77723/100000 [19:50<05:05, 72.80it/s]
epoch 77600  training loss: 0.24336527287960052
epoch 77600  clean testing loss: 0.9345200061798096
epoch 77700  training loss: 0.23386545479297638

 78%|███████████████████████████████████████████████████████████▉                 | 77867/100000 [19:52<05:03, 72.88it/s]
epoch 77800  training loss: 0.227395698428154

 78%|████████████████████████████████████████████████████████████                 | 78019/100000 [19:54<05:05, 71.85it/s]
epoch 77900  training loss: 0.2378539890050888
epoch 77900  clean testing loss: 0.9265835285186768
epoch 78000  training loss: 0.2228892296552658
epoch 78000  clean testing loss: 0.929842472076416
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 78100  training loss: 0.21627448499202728

 78%|████████████████████████████████████████████████████████████▏                | 78155/100000 [19:56<05:06, 71.34it/s]
epoch 78200  training loss: 0.228119358420372
epoch 78200  clean testing loss: 0.9039732813835144
epoch 78300  training loss: 0.2223786860704422

 78%|████████████████████████████████████████████████████████████▎                | 78307/100000 [19:58<04:55, 73.36it/s]
epoch 78400  training loss: 0.22566697001457214

 78%|████████████████████████████████████████████████████████████▍                | 78451/100000 [20:00<04:57, 72.34it/s]
epoch 78500  training loss: 0.22740493714809418
epoch 78500  clean testing loss: 0.8918420076370239
epoch 78600  training loss: 0.22091755270957947


 79%|████████████████████████████████████████████████████████████▋                | 78747/100000 [20:04<04:52, 72.75it/s]
epoch 78700  training loss: 0.22311802208423615

 79%|████████████████████████████████████████████████████████████▋                | 78891/100000 [20:06<04:48, 73.17it/s]
epoch 78800  training loss: 0.22177675366401672
epoch 78800  clean testing loss: 0.8927903771400452
epoch 78900  training loss: 0.2211986482143402

 79%|████████████████████████████████████████████████████████████▊                | 79035/100000 [20:08<04:53, 71.49it/s]
epoch 79000  training loss: 0.2322251945734024
epoch 79000  clean testing loss: 0.8901141285896301

 79%|████████████████████████████████████████████████████████████▉                | 79179/100000 [20:10<04:46, 72.76it/s]
epoch 79100  training loss: 0.23469178378582

 79%|█████████████████████████████████████████████████████████████                | 79323/100000 [20:12<04:47, 72.02it/s]
epoch 79200  training loss: 0.2246164083480835
epoch 79200  clean testing loss: 0.8956224918365479
epoch 79300  training loss: 0.23337654769420624

 79%|█████████████████████████████████████████████████████████████▏               | 79475/100000 [20:14<04:42, 72.75it/s]
epoch 79400  training loss: 0.2259891778230667

 80%|█████████████████████████████████████████████████████████████▎               | 79619/100000 [20:16<04:39, 72.96it/s]
epoch 79500  training loss: 0.23958399891853333
epoch 79500  clean testing loss: 0.8996248245239258
epoch 79600  training loss: 0.23257219791412354
epoch 79600  clean testing loss: 0.8998587131500244
epoch 79700  training loss: 0.23881834745407104

 80%|█████████████████████████████████████████████████████████████▍               | 79763/100000 [20:18<04:41, 71.96it/s]
epoch 79800  training loss: 0.25493529438972473
epoch 79800  clean testing loss: 0.8971765041351318
epoch 79900  training loss: 0.23743510246276855

 80%|█████████████████████████████████████████████████████████████▌               | 79907/100000 [20:20<04:35, 73.01it/s]
epoch 80000  training loss: 0.2403617948293686
epoch 80000  clean testing loss: 0.901282012462616

 80%|█████████████████████████████████████████████████████████████▋               | 80051/100000 [20:22<04:34, 72.80it/s]
epoch 80100  training loss: 0.23316079378128052
epoch 80100  clean testing loss: 0.9041008949279785
epoch 80200  training loss: 0.2233155369758606

 80%|█████████████████████████████████████████████████████████████▊               | 80203/100000 [20:24<04:31, 72.80it/s]
epoch 80300  training loss: 0.23121826350688934

 80%|█████████████████████████████████████████████████████████████▊               | 80347/100000 [20:26<04:28, 73.16it/s]
epoch 80400  training loss: 0.2297458052635193
epoch 80400  clean testing loss: 0.8897016644477844
epoch 80500  training loss: 0.24056880176067352

 80%|█████████████████████████████████████████████████████████████▉               | 80491/100000 [20:28<04:25, 73.41it/s]
epoch 80600  training loss: 0.2413969486951828

 81%|██████████████████████████████████████████████████████████████               | 80643/100000 [20:30<04:24, 73.08it/s]
epoch 80700  training loss: 0.23342208564281464

 81%|██████████████████████████████████████████████████████████████▏              | 80787/100000 [20:32<04:24, 72.76it/s]
epoch 80800  training loss: 0.23331721127033234
epoch 80800  clean testing loss: 0.8960047364234924
epoch 80900  training loss: 0.2328219711780548

 81%|██████████████████████████████████████████████████████████████▎              | 80931/100000 [20:34<04:25, 71.91it/s]
epoch 81000  training loss: 0.238434299826622
epoch 81000  clean testing loss: 0.8963962197303772

 81%|██████████████████████████████████████████████████████████████▍              | 81075/100000 [20:36<04:21, 72.42it/s]
epoch 81100  training loss: 0.21442097425460815
epoch 81100  clean testing loss: 0.8924069404602051
epoch 81200  training loss: 0.21882711350917816

 81%|██████████████████████████████████████████████████████████████▌              | 81219/100000 [20:38<04:18, 72.66it/s]
epoch 81300  training loss: 0.23943284153938293


 82%|██████████████████████████████████████████████████████████████▊              | 81515/100000 [20:42<04:12, 73.22it/s]
epoch 81400  training loss: 0.2375289499759674
epoch 81400  clean testing loss: 0.8984481692314148
epoch 81500  training loss: 0.23578156530857086

 82%|██████████████████████████████████████████████████████████████▉              | 81659/100000 [20:44<04:10, 73.11it/s]
epoch 81600  training loss: 0.22842246294021606

 82%|██████████████████████████████████████████████████████████████▉              | 81811/100000 [20:46<04:09, 73.04it/s]
epoch 81700  training loss: 0.23576386272907257
epoch 81700  clean testing loss: 0.8982168436050415
epoch 81800  training loss: 0.23435010015964508

 82%|███████████████████████████████████████████████████████████████              | 81955/100000 [20:48<04:06, 73.28it/s]
epoch 81900  training loss: 0.22482435405254364

 82%|███████████████████████████████████████████████████████████████▏             | 82099/100000 [20:50<04:06, 72.65it/s]
epoch 82000  training loss: 0.22445368766784668
epoch 82000  clean testing loss: 0.8934745192527771
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 82100  training loss: 0.23020847141742706

 82%|███████████████████████████████████████████████████████████████▎             | 82251/100000 [20:52<04:01, 73.39it/s]
epoch 82200  training loss: 0.22862473130226135
epoch 82200  clean testing loss: 0.8986403942108154
epoch 82300  training loss: 0.23051100969314575
epoch 82300  clean testing loss: 0.8991394639015198
epoch 82400  training loss: 0.23689696192741394



 82%|███████████████████████████████████████████████████████████████▌             | 82483/100000 [21:01<22:07, 13.20it/s]
epoch 82500  training loss: 0.2432844340801239
epoch 82500  clean testing loss: 0.9033882021903992
epoch 82600  training loss: 0.23488765954971313

 83%|███████████████████████████████████████████████████████████████▌             | 82627/100000 [21:02<04:04, 71.08it/s]
epoch 82700  training loss: 0.2207542359828949

 83%|███████████████████████████████████████████████████████████████▋             | 82771/100000 [21:04<03:56, 72.75it/s]
epoch 82800  training loss: 0.23090574145317078
epoch 82800  clean testing loss: 0.8953655362129211
epoch 82900  training loss: 0.23204198479652405

 83%|███████████████████████████████████████████████████████████████▊             | 82915/100000 [21:06<03:56, 72.23it/s]
epoch 83000  training loss: 0.24132727086544037
epoch 83000  clean testing loss: 0.8962876200675964

 83%|███████████████████████████████████████████████████████████████▉             | 83059/100000 [21:08<03:50, 73.37it/s]
epoch 83100  training loss: 0.23700757324695587
epoch 83100  clean testing loss: 0.8965694904327393
epoch 83200  training loss: 0.2287125140428543

 83%|████████████████████████████████████████████████████████████████             | 83211/100000 [21:11<03:48, 73.57it/s]
epoch 83300  training loss: 0.23939956724643707

 83%|████████████████████████████████████████████████████████████████▏            | 83355/100000 [21:13<03:50, 72.17it/s]
epoch 83400  training loss: 0.22912262380123138
epoch 83400  clean testing loss: 0.8851820230484009
epoch 83500  training loss: 0.22725099325180054


 84%|████████████████████████████████████████████████████████████████▍            | 83643/100000 [21:16<03:49, 71.25it/s]
epoch 83600  training loss: 0.23264874517917633

 84%|████████████████████████████████████████████████████████████████▌            | 83787/100000 [21:18<03:45, 71.95it/s]
epoch 83700  training loss: 0.2291114777326584

 84%|████████████████████████████████████████████████████████████████▋            | 83931/100000 [21:21<03:41, 72.50it/s]
epoch 83800  training loss: 0.23677387833595276
epoch 83800  clean testing loss: 0.8774608373641968
epoch 83900  training loss: 0.24374233186244965

 84%|████████████████████████████████████████████████████████████████▋            | 84075/100000 [21:23<03:39, 72.59it/s]
epoch 84000  training loss: 0.2310725748538971
epoch 84000  clean testing loss: 0.8815747499465942

 84%|████████████████████████████████████████████████████████████████▊            | 84227/100000 [21:25<03:37, 72.46it/s]
epoch 84100  training loss: 0.23885959386825562
epoch 84100  clean testing loss: 0.88487309217453
epoch 84200  training loss: 0.2236219048500061

 84%|████████████████████████████████████████████████████████████████▉            | 84299/100000 [21:26<03:33, 73.39it/s]
epoch 84300  training loss: 0.2230617105960846

 85%|█████████████████████████████████████████████████████████████████            | 84515/100000 [21:29<03:32, 72.81it/s]
epoch 84400  training loss: 0.23022465407848358
epoch 84400  clean testing loss: 0.8820464015007019
epoch 84500  training loss: 0.2436988651752472

 85%|█████████████████████████████████████████████████████████████████▏           | 84667/100000 [21:31<03:30, 72.99it/s]
epoch 84600  training loss: 0.23332571983337402

 85%|█████████████████████████████████████████████████████████████████▏           | 84699/100000 [21:31<03:30, 72.58it/s]
epoch 84700  training loss: 0.2326255887746811

 85%|█████████████████████████████████████████████████████████████████▍           | 85027/100000 [21:36<03:30, 71.24it/s]
epoch 84800  training loss: 0.23215053975582123
epoch 84800  clean testing loss: 0.8947875499725342
epoch 84900  training loss: 0.23564039170742035
epoch 84900  clean testing loss: 0.8890929222106934
epoch 85000  training loss: 0.24224717915058136
epoch 85000  clean testing loss: 0.8914176225662231

 85%|█████████████████████████████████████████████████████████████████▌           | 85171/100000 [21:38<03:24, 72.60it/s]
epoch 85100  training loss: 0.2386728823184967

 85%|█████████████████████████████████████████████████████████████████▌           | 85195/100000 [21:38<03:23, 72.80it/s]
epoch 85200  training loss: 0.23107993602752686
epoch 85200  clean testing loss: 0.8928734064102173
epoch 85300  training loss: 0.22762435674667358
epoch 85300  clean testing loss: 0.8892121911048889
epoch 85400  training loss: 0.24557529389858246
epoch 85400  clean testing loss: 0.8949408531188965
epoch 85500  training loss: 0.241362065076828
epoch 85500  clean testing loss: 0.8926560878753662
epoch 85600  training loss: 0.24639585614204407
epoch 85600  clean testing loss: 0.8901315927505493
epoch 85700  training loss: 0.2261478155851364
epoch 85700  clean testing loss: 0.8921528458595276
epoch 85800  training loss: 0.24094173312187195
epoch 85800  clean testing loss: 0.8930104970932007
epoch 85900  training loss: 0.23479123413562775
epoch 85900  clean testing loss: 0.8929672241210938
epoch 86000  training loss: 0.2428855448961258
epoch 86000  clean testing loss: 0.8949902653694153
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 86100  training loss: 0.23690931499004364

 86%|██████████████████████████████████████████████████████████████████▎          | 86113/100000 [22:02<03:53, 59.38it/s]
epoch 86200  training loss: 0.2430589348077774

 86%|██████████████████████████████████████████████████████████████████▍          | 86257/100000 [22:04<03:07, 73.46it/s]
epoch 86300  training loss: 0.2431292086839676
epoch 86300  clean testing loss: 0.8990288376808167
epoch 86400  training loss: 0.23407001793384552

 86%|██████████████████████████████████████████████████████████████████▌          | 86401/100000 [22:06<03:05, 73.35it/s]
epoch 86500  training loss: 0.23575200140476227

 87%|██████████████████████████████████████████████████████████████████▋          | 86553/100000 [22:08<03:02, 73.60it/s]
epoch 86600  training loss: 0.23976711928844452

 87%|██████████████████████████████████████████████████████████████████▊          | 86697/100000 [22:10<03:02, 73.03it/s]
epoch 86700  training loss: 0.23626816272735596

 87%|██████████████████████████████████████████████████████████████████▉          | 86993/100000 [22:14<02:59, 72.65it/s]
epoch 86800  training loss: 0.2385042905807495
epoch 86800  clean testing loss: 0.8928499817848206
epoch 86900  training loss: 0.2254914939403534

 87%|███████████████████████████████████████████████████████████████████          | 87137/100000 [22:16<02:57, 72.52it/s]
epoch 87000  training loss: 0.2387390285730362
epoch 87000  clean testing loss: 0.8968349099159241
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 87100  training loss: 0.2420339435338974

 87%|███████████████████████████████████████████████████████████████████▏         | 87281/100000 [22:18<02:56, 72.08it/s]
epoch 87200  training loss: 0.2349618673324585

 87%|███████████████████████████████████████████████████████████████████▎         | 87433/100000 [22:20<02:51, 73.08it/s]
epoch 87300  training loss: 0.23425544798374176
epoch 87300  clean testing loss: 0.9062458872795105
epoch 87400  training loss: 0.23700670897960663

 88%|███████████████████████████████████████████████████████████████████▍         | 87577/100000 [22:22<02:50, 72.68it/s]
epoch 87500  training loss: 0.24205507338047028

 88%|███████████████████████████████████████████████████████████████████▌         | 87721/100000 [22:24<02:51, 71.56it/s]
epoch 87600  training loss: 0.23770320415496826
epoch 87600  clean testing loss: 0.9050799608230591
epoch 87700  training loss: 0.23880581557750702

 88%|███████████████████████████████████████████████████████████████████▋         | 87865/100000 [22:26<02:50, 71.33it/s]
epoch 87800  training loss: 0.24347548186779022

 88%|███████████████████████████████████████████████████████████████████▋         | 87985/100000 [22:27<02:43, 73.48it/s]
epoch 87900  training loss: 0.2532214820384979

 88%|███████████████████████████████████████████████████████████████████▊         | 88105/100000 [22:30<02:46, 71.39it/s]
epoch 88000  training loss: 0.24390879273414612
epoch 88000  clean testing loss: 0.9042743444442749
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 88100  training loss: 0.23933172225952148

 88%|███████████████████████████████████████████████████████████████████▉         | 88249/100000 [22:32<02:40, 73.05it/s]
epoch 88200  training loss: 0.2538435757160187

 88%|████████████████████████████████████████████████████████████████████         | 88393/100000 [22:34<02:40, 72.15it/s]
epoch 88300  training loss: 0.2517428398132324

 89%|████████████████████████████████████████████████████████████████████▏        | 88545/100000 [22:36<02:37, 72.70it/s]
epoch 88400  training loss: 0.24515195190906525
epoch 88400  clean testing loss: 0.9052997827529907
epoch 88500  training loss: 0.23564563691616058

 89%|████████████████████████████████████████████████████████████████████▎        | 88689/100000 [22:38<02:33, 73.59it/s]
epoch 88600  training loss: 0.23763619363307953

 89%|████████████████████████████████████████████████████████████████████▍        | 88841/100000 [22:40<02:32, 72.97it/s]
epoch 88700  training loss: 0.2370436191558838
epoch 88700  clean testing loss: 0.9054059386253357
epoch 88800  training loss: 0.24229559302330017

 89%|████████████████████████████████████████████████████████████████████▌        | 88985/100000 [22:42<02:30, 73.33it/s]
epoch 88900  training loss: 0.23761504888534546

 89%|████████████████████████████████████████████████████████████████████▋        | 89129/100000 [22:44<02:31, 71.85it/s]
epoch 89000  training loss: 0.23892652988433838
epoch 89000  clean testing loss: 0.9040107131004333
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...
epoch 89100  training loss: 0.23080036044120789

 89%|████████████████████████████████████████████████████████████████████▋        | 89241/100000 [22:45<02:20, 76.71it/s]
epoch 89200  training loss: 0.23396459221839905

 89%|████████████████████████████████████████████████████████████████████▊        | 89397/100000 [22:47<02:13, 79.32it/s]
epoch 89300  training loss: 0.2445129156112671
epoch 89300  clean testing loss: 0.9000030159950256
epoch 89400  training loss: 0.23920796811580658

 90%|████████████████████████████████████████████████████████████████████▉        | 89561/100000 [22:49<02:10, 79.76it/s]
epoch 89500  training loss: 0.24088993668556213

 90%|█████████████████████████████████████████████████████████████████████        | 89722/100000 [22:51<02:10, 78.50it/s]
epoch 89600  training loss: 0.23450501263141632
epoch 89600  clean testing loss: 0.904228925704956
epoch 89700  training loss: 0.23292887210845947

 90%|█████████████████████████████████████████████████████████████████████▏       | 89876/100000 [22:53<02:08, 78.98it/s]
epoch 89800  training loss: 0.24739384651184082
epoch 89800  clean testing loss: 0.9000682830810547
epoch 89900  training loss: 0.23093366622924805

 90%|█████████████████████████████████████████████████████████████████████▎       | 90036/100000 [22:55<02:06, 79.03it/s]
epoch 90000  training loss: 0.23931339383125305
epoch 90000  clean testing loss: 0.8960756063461304

 90%|█████████████████████████████████████████████████████████████████████▍       | 90197/100000 [22:57<02:03, 79.08it/s]
epoch 90100  training loss: 0.24467292428016663
epoch 90100  clean testing loss: 0.897462785243988
epoch 90200  training loss: 0.23674209415912628

 90%|█████████████████████████████████████████████████████████████████████▌       | 90358/100000 [22:59<02:01, 79.66it/s]
epoch 90300  training loss: 0.23942066729068756

 91%|█████████████████████████████████████████████████████████████████████▋       | 90518/100000 [23:01<01:59, 79.02it/s]
epoch 90400  training loss: 0.25047674775123596
epoch 90400  clean testing loss: 0.8958386778831482
epoch 90500  training loss: 0.24858994781970978

 91%|█████████████████████████████████████████████████████████████████████▊       | 90678/100000 [23:03<01:57, 79.29it/s]
epoch 90600  training loss: 0.23885749280452728
epoch 90600  clean testing loss: 0.8964093327522278
epoch 90700  training loss: 0.22929704189300537

 91%|█████████████████████████████████████████████████████████████████████▉       | 90833/100000 [23:05<01:54, 79.91it/s]
epoch 90800  training loss: 0.22588568925857544

 91%|██████████████████████████████████████████████████████████████████████       | 90993/100000 [23:07<01:53, 79.38it/s]
epoch 90900  training loss: 0.23816464841365814
epoch 90900  clean testing loss: 0.896497368812561
epoch 91000  training loss: 0.2472609132528305
epoch 91000  clean testing loss: 0.8986350297927856

 91%|██████████████████████████████████████████████████████████████████████▏      | 91164/100000 [23:09<01:41, 87.34it/s]
epoch 91100  training loss: 0.2409660965204239

 91%|██████████████████████████████████████████████████████████████████████▎      | 91344/100000 [23:11<01:39, 87.34it/s]
epoch 91200  training loss: 0.2437925636768341
epoch 91200  clean testing loss: 0.9014467000961304
epoch 91300  training loss: 0.23580463230609894

 92%|██████████████████████████████████████████████████████████████████████▍      | 91515/100000 [23:13<01:37, 87.07it/s]
epoch 91400  training loss: 0.23106126487255096
epoch 91400  clean testing loss: 0.8944324851036072
epoch 91500  training loss: 0.2259974330663681

 92%|██████████████████████████████████████████████████████████████████████▌      | 91695/100000 [23:15<01:34, 88.06it/s]
epoch 91600  training loss: 0.2265394628047943
epoch 91600  clean testing loss: 0.8928236365318298
epoch 91700  training loss: 0.2398885041475296

 92%|██████████████████████████████████████████████████████████████████████▋      | 91875/100000 [23:17<01:32, 87.37it/s]
epoch 91800  training loss: 0.24941937625408173

 92%|██████████████████████████████████████████████████████████████████████▉      | 92046/100000 [23:19<01:31, 87.27it/s]
epoch 91900  training loss: 0.22833387553691864
epoch 91900  clean testing loss: 0.8897697329521179
epoch 92000  training loss: 0.2342471480369568
epoch 92000  clean testing loss: 0.8871880173683167

 92%|███████████████████████████████████████████████████████████████████████      | 92217/100000 [23:21<01:29, 87.24it/s]
epoch 92100  training loss: 0.23788167536258698
epoch 92100  clean testing loss: 0.8867904543876648
epoch 92200  training loss: 0.23988640308380127

 92%|███████████████████████████████████████████████████████████████████████▏     | 92397/100000 [23:23<01:26, 87.43it/s]
epoch 92300  training loss: 0.24331071972846985
epoch 92300  clean testing loss: 0.8871197700500488
epoch 92400  training loss: 0.2363172024488449

 92%|███████████████████████████████████████████████████████████████████████▏     | 92500/100000 [23:25<01:53, 65.83it/s]
epoch 92500  training loss: 0.24058204889297485
epoch 92500  clean testing loss: 0.886023223400116
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop1 ...