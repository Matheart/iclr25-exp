
  1%|▌                                                                                | 690/100000 [00:01<03:11, 517.76it/s]
epoch 0  training loss: 0.5915643572807312
epoch 0  clean testing loss: 0.4934394061565399
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 100  training loss: 0.23536165058612823
epoch 100  clean testing loss: 0.14947596192359924
epoch 200  training loss: 0.20971761643886566
epoch 200  clean testing loss: 0.12420259416103363
epoch 300  training loss: 0.19404065608978271
epoch 300  clean testing loss: 0.10877455770969391
epoch 400  training loss: 0.18660162389278412
epoch 400  clean testing loss: 0.10153231024742126
epoch 500  training loss: 0.1815708428621292
epoch 500  clean testing loss: 0.09640907496213913
epoch 600  training loss: 0.17737708985805511
epoch 600  clean testing loss: 0.09203550219535828
epoch 700  training loss: 0.17364490032196045

  2%|█▏                                                                              | 1559/100000 [00:03<03:43, 441.01it/s]
epoch 800  training loss: 0.1701979786157608
epoch 800  clean testing loss: 0.08441778272390366
epoch 900  training loss: 0.16695091128349304
epoch 900  clean testing loss: 0.08102802187204361
epoch 1000  training loss: 0.16388961672782898
epoch 1000  clean testing loss: 0.07797180861234665
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 1100  training loss: 0.16102170944213867
epoch 1100  clean testing loss: 0.07530581951141357
epoch 1200  training loss: 0.1583307832479477
epoch 1200  clean testing loss: 0.07296150922775269
epoch 1300  training loss: 0.1557711809873581
epoch 1300  clean testing loss: 0.07080034166574478
epoch 1400  training loss: 0.15326975286006927
epoch 1400  clean testing loss: 0.06877881288528442
epoch 1500  training loss: 0.1507667601108551
epoch 1500  clean testing loss: 0.06699520349502563
epoch 1600  training loss: 0.14822348952293396

  2%|█▉                                                                              | 2391/100000 [00:05<04:05, 398.11it/s]
epoch 1700  training loss: 0.14561133086681366
epoch 1700  clean testing loss: 0.06442298740148544
epoch 1800  training loss: 0.14283138513565063
epoch 1800  clean testing loss: 0.06354846060276031
epoch 1900  training loss: 0.1397078037261963
epoch 1900  clean testing loss: 0.06355666369199753
epoch 2000  training loss: 0.13682395219802856
epoch 2000  clean testing loss: 0.06377094984054565
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 2100  training loss: 0.13433261215686798
epoch 2100  clean testing loss: 0.06360704451799393
epoch 2200  training loss: 0.1320791393518448
epoch 2200  clean testing loss: 0.06362520903348923
epoch 2300  training loss: 0.130015566945076
epoch 2300  clean testing loss: 0.06374859809875488
epoch 2400  training loss: 0.12812457978725433

  3%|██▌                                                                             | 3198/100000 [00:07<04:04, 395.17it/s]
epoch 2500  training loss: 0.12640437483787537
epoch 2500  clean testing loss: 0.06438779085874557
epoch 2600  training loss: 0.12482765316963196
epoch 2600  clean testing loss: 0.06485787034034729
epoch 2700  training loss: 0.12342117726802826
epoch 2700  clean testing loss: 0.06522313505411148
epoch 2800  training loss: 0.12183167785406113
epoch 2800  clean testing loss: 0.06612672656774521
epoch 2900  training loss: 0.1203295961022377
epoch 2900  clean testing loss: 0.0671265721321106
epoch 3000  training loss: 0.11883276700973511
epoch 3000  clean testing loss: 0.06847093254327774
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 3100  training loss: 0.11755175143480301
epoch 3100  clean testing loss: 0.0696854218840599
epoch 3200  training loss: 0.11623723804950714

  4%|███▏                                                                            | 4001/100000 [00:09<04:03, 393.46it/s]
epoch 3300  training loss: 0.11485540121793747
epoch 3300  clean testing loss: 0.07281310111284256
epoch 3400  training loss: 0.1134391650557518
epoch 3400  clean testing loss: 0.07468348741531372
epoch 3500  training loss: 0.11205226927995682
epoch 3500  clean testing loss: 0.07665644586086273
epoch 3600  training loss: 0.11065740883350372
epoch 3600  clean testing loss: 0.07853472232818604
epoch 3700  training loss: 0.10932308435440063
epoch 3700  clean testing loss: 0.08039282262325287
epoch 3800  training loss: 0.10803018510341644
epoch 3800  clean testing loss: 0.08219197392463684
epoch 3900  training loss: 0.1067604124546051
epoch 3900  clean testing loss: 0.08401688188314438
epoch 4000  training loss: 0.1055353507399559
epoch 4000  clean testing loss: 0.08596914261579514

  5%|███▊                                                                            | 4806/100000 [00:11<03:58, 399.08it/s]
epoch 4100  training loss: 0.104357048869133
epoch 4100  clean testing loss: 0.08792758733034134
epoch 4200  training loss: 0.10323209315538406
epoch 4200  clean testing loss: 0.08913666009902954
epoch 4300  training loss: 0.1021559089422226
epoch 4300  clean testing loss: 0.09013548493385315
epoch 4400  training loss: 0.10111180692911148
epoch 4400  clean testing loss: 0.09046445041894913
epoch 4500  training loss: 0.10006498545408249
epoch 4500  clean testing loss: 0.0904819518327713
epoch 4600  training loss: 0.09902291744947433
epoch 4600  clean testing loss: 0.09031230956315994
epoch 4700  training loss: 0.09794402122497559
epoch 4700  clean testing loss: 0.08998177945613861
epoch 4800  training loss: 0.09684234857559204

  6%|████▍                                                                           | 5606/100000 [00:13<03:57, 397.45it/s]
epoch 4900  training loss: 0.09565779566764832
epoch 4900  clean testing loss: 0.08950183540582657
epoch 5000  training loss: 0.09448894113302231
epoch 5000  clean testing loss: 0.089523084461689
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 5100  training loss: 0.09333272278308868
epoch 5100  clean testing loss: 0.08982637524604797
epoch 5200  training loss: 0.09217548370361328
epoch 5200  clean testing loss: 0.09036058187484741
epoch 5300  training loss: 0.09101230651140213
epoch 5300  clean testing loss: 0.09109020233154297
epoch 5400  training loss: 0.08983830362558365
epoch 5400  clean testing loss: 0.09195372462272644
epoch 5500  training loss: 0.08865535259246826
epoch 5500  clean testing loss: 0.0931902527809143
epoch 5600  training loss: 0.08746740967035294

  6%|█████                                                                           | 6373/100000 [00:15<03:54, 399.46it/s]
epoch 5700  training loss: 0.08628371357917786
epoch 5700  clean testing loss: 0.09629175066947937
epoch 5800  training loss: 0.08512041717767715
epoch 5800  clean testing loss: 0.09857850521802902
epoch 5900  training loss: 0.08399476110935211
epoch 5900  clean testing loss: 0.10179325938224792
epoch 6000  training loss: 0.08276968449354172
epoch 6000  clean testing loss: 0.1049850732088089
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 6100  training loss: 0.0818040519952774
epoch 6100  clean testing loss: 0.10818812251091003
epoch 6200  training loss: 0.08081255108118057
epoch 6200  clean testing loss: 0.11171069741249084
epoch 6300  training loss: 0.07980155199766159
epoch 6300  clean testing loss: 0.11544819176197052
epoch 6400  training loss: 0.07880198955535889

  7%|█████▋                                                                          | 7176/100000 [00:17<03:52, 398.44it/s]
epoch 6500  training loss: 0.07781633734703064
epoch 6500  clean testing loss: 0.12281481176614761
epoch 6600  training loss: 0.07684534043073654
epoch 6600  clean testing loss: 0.12619103491306305
epoch 6700  training loss: 0.07589127123355865
epoch 6700  clean testing loss: 0.12968066334724426
epoch 6800  training loss: 0.07495543360710144
epoch 6800  clean testing loss: 0.1329183727502823
epoch 6900  training loss: 0.07404494285583496
epoch 6900  clean testing loss: 0.13631735742092133
epoch 7000  training loss: 0.07315579056739807
epoch 7000  clean testing loss: 0.13978756964206696
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 7100  training loss: 0.07230838388204575
epoch 7100  clean testing loss: 0.14307165145874023
epoch 7200  training loss: 0.07148120552301407

  8%|██████▍                                                                         | 7978/100000 [00:19<03:51, 397.96it/s]
epoch 7300  training loss: 0.07068901509046555
epoch 7300  clean testing loss: 0.1500653624534607
epoch 7400  training loss: 0.06992606073617935
epoch 7400  clean testing loss: 0.1535356491804123
epoch 7500  training loss: 0.06919755786657333
epoch 7500  clean testing loss: 0.15753868222236633
epoch 7600  training loss: 0.06846682727336884
epoch 7600  clean testing loss: 0.16081605851650238
epoch 7700  training loss: 0.06776837259531021
epoch 7700  clean testing loss: 0.16438472270965576
epoch 7800  training loss: 0.06709081679582596
epoch 7800  clean testing loss: 0.16814331710338593
epoch 7900  training loss: 0.06642531603574753
epoch 7900  clean testing loss: 0.17200344800949097
epoch 8000  training loss: 0.0657845214009285
epoch 8000  clean testing loss: 0.1762526035308838

  9%|███████                                                                         | 8779/100000 [00:21<03:50, 396.22it/s]
epoch 8100  training loss: 0.06515906006097794
epoch 8100  clean testing loss: 0.1799309402704239
epoch 8200  training loss: 0.06455446779727936
epoch 8200  clean testing loss: 0.18417498469352722
epoch 8300  training loss: 0.06397620588541031
epoch 8300  clean testing loss: 0.18825262784957886
epoch 8400  training loss: 0.06341914087533951
epoch 8400  clean testing loss: 0.19239869713783264
epoch 8500  training loss: 0.06287435442209244
epoch 8500  clean testing loss: 0.19642868638038635
epoch 8600  training loss: 0.06234380230307579
epoch 8600  clean testing loss: 0.2005968987941742
epoch 8700  training loss: 0.061829693615436554
epoch 8700  clean testing loss: 0.2047012597322464
epoch 8800  training loss: 0.061324186623096466

 10%|███████▋                                                                        | 9583/100000 [00:23<03:47, 397.40it/s]
epoch 8900  training loss: 0.060828447341918945
epoch 8900  clean testing loss: 0.21294370293617249
epoch 9000  training loss: 0.060338206589221954
epoch 9000  clean testing loss: 0.21714991331100464
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 9100  training loss: 0.05994192883372307
epoch 9100  clean testing loss: 0.22063620388507843
epoch 9200  training loss: 0.05953986942768097
epoch 9200  clean testing loss: 0.22426611185073853
epoch 9300  training loss: 0.05913149565458298
epoch 9300  clean testing loss: 0.22805055975914001
epoch 9400  training loss: 0.058730434626340866
epoch 9400  clean testing loss: 0.23176328837871552
epoch 9500  training loss: 0.05838007107377052
epoch 9500  clean testing loss: 0.23574279248714447
epoch 9600  training loss: 0.057907357811927795

 10%|████████▏                                                                      | 10386/100000 [00:25<03:46, 396.42it/s]
epoch 9700  training loss: 0.05750613659620285
epoch 9700  clean testing loss: 0.2441016286611557
epoch 9800  training loss: 0.057168181985616684
epoch 9800  clean testing loss: 0.2480374574661255
epoch 9900  training loss: 0.05671894922852516
epoch 9900  clean testing loss: 0.25235775113105774
epoch 10000  training loss: 0.05633459612727165
epoch 10000  clean testing loss: 0.2565303444862366
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 10100  training loss: 0.05596105381846428
epoch 10100  clean testing loss: 0.26079249382019043
epoch 10200  training loss: 0.05558611825108528
epoch 10200  clean testing loss: 0.264887273311615
epoch 10300  training loss: 0.05522223934531212
epoch 10300  clean testing loss: 0.26909440755844116
epoch 10400  training loss: 0.05486832186579704

 11%|████████▊                                                                      | 11149/100000 [00:27<03:44, 396.43it/s]
epoch 10500  training loss: 0.0545203797519207
epoch 10500  clean testing loss: 0.27758699655532837
epoch 10600  training loss: 0.05416162312030792
epoch 10600  clean testing loss: 0.2818349599838257
epoch 10700  training loss: 0.05381885543465614
epoch 10700  clean testing loss: 0.28617390990257263
epoch 10800  training loss: 0.053540147840976715
epoch 10800  clean testing loss: 0.2909211814403534
epoch 10900  training loss: 0.053199343383312225
epoch 10900  clean testing loss: 0.29512014985084534
epoch 11000  training loss: 0.05282306298613548
epoch 11000  clean testing loss: 0.299182653427124
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 11100  training loss: 0.05250432714819908
epoch 11100  clean testing loss: 0.3035268187522888
epoch 11200  training loss: 0.0522051639854908

 12%|█████████▍                                                                     | 11951/100000 [00:29<03:41, 397.98it/s]
epoch 11300  training loss: 0.05189933255314827
epoch 11300  clean testing loss: 0.31210508942604065
epoch 11400  training loss: 0.05159028246998787
epoch 11400  clean testing loss: 0.3162825107574463
epoch 11500  training loss: 0.051300376653671265
epoch 11500  clean testing loss: 0.32045701146125793
epoch 11600  training loss: 0.05101931095123291
epoch 11600  clean testing loss: 0.3245238661766052
epoch 11700  training loss: 0.05074448511004448
epoch 11700  clean testing loss: 0.3286314010620117
epoch 11800  training loss: 0.05048032104969025
epoch 11800  clean testing loss: 0.332526296377182
epoch 11900  training loss: 0.05028611794114113
epoch 11900  clean testing loss: 0.3362318277359009
epoch 12000  training loss: 0.049974292516708374
epoch 12000  clean testing loss: 0.34010180830955505

 13%|██████████                                                                     | 12754/100000 [00:31<03:38, 398.44it/s]
epoch 12100  training loss: 0.049778446555137634
epoch 12100  clean testing loss: 0.3430388867855072
epoch 12200  training loss: 0.04958389699459076
epoch 12200  clean testing loss: 0.3459372818470001
epoch 12300  training loss: 0.04939069598913193
epoch 12300  clean testing loss: 0.3488125801086426
epoch 12400  training loss: 0.04919896647334099
epoch 12400  clean testing loss: 0.35166817903518677
epoch 12500  training loss: 0.04901277646422386
epoch 12500  clean testing loss: 0.3544859290122986
epoch 12600  training loss: 0.0488293431699276
epoch 12600  clean testing loss: 0.3572820723056793
epoch 12700  training loss: 0.04865214601159096
epoch 12700  clean testing loss: 0.3600194752216339
epoch 12800  training loss: 0.04847995564341545

 14%|██████████▋                                                                    | 13557/100000 [00:33<03:37, 397.36it/s]
epoch 12900  training loss: 0.04831060394644737
epoch 12900  clean testing loss: 0.36534640192985535
epoch 13000  training loss: 0.048144564032554626
epoch 13000  clean testing loss: 0.36794278025627136
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 13100  training loss: 0.04798330366611481
epoch 13100  clean testing loss: 0.3704342246055603
epoch 13200  training loss: 0.047824710607528687
epoch 13200  clean testing loss: 0.37294524908065796
epoch 13300  training loss: 0.04767058044672012
epoch 13300  clean testing loss: 0.3753584921360016
epoch 13400  training loss: 0.047523852437734604
epoch 13400  clean testing loss: 0.37803182005882263
epoch 13500  training loss: 0.04737028852105141
epoch 13500  clean testing loss: 0.3800654411315918
epoch 13600  training loss: 0.047229886054992676

 14%|███████████▎                                                                   | 14359/100000 [00:35<03:37, 394.52it/s]
epoch 13700  training loss: 0.04708046838641167
epoch 13700  clean testing loss: 0.3845825791358948
epoch 13800  training loss: 0.0469394326210022
epoch 13800  clean testing loss: 0.38675612211227417
epoch 13900  training loss: 0.046812135726213455
epoch 13900  clean testing loss: 0.38896751403808594
epoch 14000  training loss: 0.04666522145271301
epoch 14000  clean testing loss: 0.39101240038871765
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 14100  training loss: 0.04653201252222061
epoch 14100  clean testing loss: 0.393062949180603
epoch 14200  training loss: 0.04639948531985283
epoch 14200  clean testing loss: 0.39508911967277527
epoch 14300  training loss: 0.046269696205854416

 15%|███████████▉                                                                   | 15161/100000 [00:37<03:33, 396.71it/s]
epoch 14400  training loss: 0.04614533483982086
epoch 14400  clean testing loss: 0.3990159332752228
epoch 14500  training loss: 0.04601968079805374
epoch 14500  clean testing loss: 0.4006985127925873
epoch 14600  training loss: 0.045918095856904984
epoch 14600  clean testing loss: 0.4028762876987457
epoch 14700  training loss: 0.04577045515179634
epoch 14700  clean testing loss: 0.4047331213951111
epoch 14800  training loss: 0.04565038904547691
epoch 14800  clean testing loss: 0.406551718711853
epoch 14900  training loss: 0.045530498027801514
epoch 14900  clean testing loss: 0.40839722752571106
epoch 15000  training loss: 0.04541397467255592
epoch 15000  clean testing loss: 0.4101784825325012
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 15100  training loss: 0.04532010480761528

 16%|████████████▌                                                                  | 15964/100000 [00:39<03:33, 393.68it/s]
epoch 15200  training loss: 0.045226093381643295
epoch 15200  clean testing loss: 0.4130370616912842
epoch 15300  training loss: 0.04513098672032356
epoch 15300  clean testing loss: 0.41443899273872375
epoch 15400  training loss: 0.0450347475707531
epoch 15400  clean testing loss: 0.41583386063575745
epoch 15500  training loss: 0.04493740200996399
epoch 15500  clean testing loss: 0.41721683740615845
epoch 15600  training loss: 0.044841136783361435
epoch 15600  clean testing loss: 0.4186048209667206
epoch 15700  training loss: 0.04475019872188568
epoch 15700  clean testing loss: 0.4200427532196045
epoch 15800  training loss: 0.04465020075440407
epoch 15800  clean testing loss: 0.42139217257499695
epoch 15900  training loss: 0.044556695967912674

 16%|████████████▉                                                                  | 16400/100000 [00:40<03:27, 402.46it/s]
epoch 16000  training loss: 0.04446355998516083
epoch 16000  clean testing loss: 0.42408955097198486
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...
epoch 16100  training loss: 0.04437140002846718
epoch 16100  clean testing loss: 0.4253990054130554
epoch 16200  training loss: 0.044284265488386154
epoch 16200  clean testing loss: 0.4268477261066437
epoch 16300  training loss: 0.04418950155377388
epoch 16300  clean testing loss: 0.4278498589992523
epoch 16400  training loss: 0.044100284576416016
epoch 16400  clean testing loss: 0.4290004372596741
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise1.00e-01_invop0 ...