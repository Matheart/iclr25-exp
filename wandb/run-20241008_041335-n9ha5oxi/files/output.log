
  0%|‚ñè                                                                                 | 245/100000 [00:01<08:45, 189.73it/s]
epoch 0  training loss: 0.5899048447608948
epoch 0  clean testing loss: 0.6708981990814209
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 100  training loss: 0.12799564003944397
epoch 100  clean testing loss: 0.06067880243062973
epoch 200  training loss: 0.10697689652442932

  1%|‚ñå                                                                                 | 640/100000 [00:03<08:28, 195.24it/s]
epoch 300  training loss: 0.10002211481332779
epoch 300  clean testing loss: 0.03473561257123947
epoch 400  training loss: 0.09886950999498367
epoch 400  clean testing loss: 0.03700947389006615
epoch 500  training loss: 0.09201550483703613
epoch 500  clean testing loss: 0.031162254512310028
epoch 600  training loss: 0.09183953702449799
epoch 600  clean testing loss: 0.035210542380809784
epoch 700  training loss: 0.08690516650676727

  1%|‚ñä                                                                                | 1030/100000 [00:05<08:35, 192.00it/s]
epoch 800  training loss: 0.10511220991611481
epoch 800  clean testing loss: 0.05487583205103874
epoch 900  training loss: 0.10122687369585037
epoch 900  clean testing loss: 0.03472205623984337
epoch 1000  training loss: 0.08203570544719696
epoch 1000  clean testing loss: 0.030095161870121956
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 1100  training loss: 0.07952172309160233

  1%|‚ñà‚ñè                                                                               | 1414/100000 [00:07<08:38, 190.13it/s]
epoch 1200  training loss: 0.09682755917310715
epoch 1200  clean testing loss: 0.041329383850097656
epoch 1300  training loss: 0.08362342417240143
epoch 1300  clean testing loss: 0.030791597440838814
epoch 1400  training loss: 0.10648173838853836
epoch 1400  clean testing loss: 0.04220827296376228
epoch 1500  training loss: 0.07780496776103973

  2%|‚ñà‚ñç                                                                               | 1801/100000 [00:09<08:35, 190.50it/s]
epoch 1600  training loss: 0.0935896784067154
epoch 1600  clean testing loss: 0.04109185189008713
epoch 1700  training loss: 0.07584384828805923
epoch 1700  clean testing loss: 0.030153123661875725
epoch 1800  training loss: 0.09407409280538559
epoch 1800  clean testing loss: 0.037906795740127563
epoch 1900  training loss: 0.07736632227897644

  2%|‚ñà‚ñä                                                                               | 2190/100000 [00:11<08:34, 190.02it/s]
epoch 2000  training loss: 0.07795365154743195
epoch 2000  clean testing loss: 0.04516012966632843
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 2100  training loss: 0.07324656844139099
epoch 2100  clean testing loss: 0.03411002829670906
epoch 2200  training loss: 0.07097906619310379

  3%|‚ñà‚ñà                                                                               | 2577/100000 [00:13<08:40, 187.16it/s]
epoch 2300  training loss: 0.08927007764577866
epoch 2300  clean testing loss: 0.0413195937871933
epoch 2400  training loss: 0.07090285420417786
epoch 2400  clean testing loss: 0.03151879459619522
epoch 2500  training loss: 0.0697605088353157
epoch 2500  clean testing loss: 0.03150663524866104
epoch 2600  training loss: 0.06852952390909195

  3%|‚ñà‚ñà‚ñç                                                                              | 2966/100000 [00:15<08:15, 195.72it/s]
epoch 2700  training loss: 0.11501730233430862
epoch 2700  clean testing loss: 0.054608285427093506
epoch 2800  training loss: 0.07088793814182281
epoch 2800  clean testing loss: 0.03389924764633179
epoch 2900  training loss: 0.06641065329313278

  3%|‚ñà‚ñà‚ñã                                                                              | 3347/100000 [00:17<08:23, 191.79it/s]
epoch 3000  training loss: 0.06823694705963135
epoch 3000  clean testing loss: 0.0344877615571022
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 3100  training loss: 0.06488356739282608
epoch 3100  clean testing loss: 0.03521588444709778
epoch 3200  training loss: 0.06441456079483032
epoch 3200  clean testing loss: 0.0356033630669117
epoch 3300  training loss: 0.06319420784711838

  4%|‚ñà‚ñà‚ñà                                                                              | 3727/100000 [00:19<08:22, 191.66it/s]
epoch 3400  training loss: 0.11321152001619339
epoch 3400  clean testing loss: 0.05598219484090805
epoch 3500  training loss: 0.06855572015047073
epoch 3500  clean testing loss: 0.03684082254767418
epoch 3600  training loss: 0.06376529484987259
epoch 3600  clean testing loss: 0.03449013829231262
epoch 3700  training loss: 0.06292954087257385

  4%|‚ñà‚ñà‚ñà‚ñé                                                                             | 4116/100000 [00:21<08:16, 193.07it/s]
epoch 3800  training loss: 0.06224798038601875
epoch 3800  clean testing loss: 0.03791356086730957
epoch 3900  training loss: 0.06087842211127281
epoch 3900  clean testing loss: 0.03754955530166626
epoch 4000  training loss: 0.06962615996599197
epoch 4000  clean testing loss: 0.0436222180724144
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 4100  training loss: 0.07371644675731659

  5%|‚ñà‚ñà‚ñà‚ñã                                                                             | 4504/100000 [00:23<08:14, 193.18it/s]
epoch 4200  training loss: 0.064222551882267
epoch 4200  clean testing loss: 0.04272667318582535
epoch 4300  training loss: 0.05974701792001724
epoch 4300  clean testing loss: 0.03919114172458649
epoch 4400  training loss: 0.06055452302098274
epoch 4400  clean testing loss: 0.04105241969227791
epoch 4500  training loss: 0.06197331100702286

  5%|‚ñà‚ñà‚ñà‚ñâ                                                                             | 4895/100000 [00:25<08:25, 188.28it/s]
epoch 4600  training loss: 0.07141484320163727
epoch 4600  clean testing loss: 0.04206475242972374
epoch 4700  training loss: 0.05908016860485077
epoch 4700  clean testing loss: 0.03788537159562111
epoch 4800  training loss: 0.060167696326971054
epoch 4800  clean testing loss: 0.04479644075036049
epoch 4900  training loss: 0.06064552441239357

  5%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                            | 5284/100000 [00:27<08:06, 194.80it/s]
epoch 5000  training loss: 0.0652356818318367
epoch 5000  clean testing loss: 0.04135781526565552
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 5100  training loss: 0.05790521577000618
epoch 5100  clean testing loss: 0.039660923182964325
epoch 5200  training loss: 0.058927662670612335
epoch 5200  clean testing loss: 0.03977636620402336
epoch 5300  training loss: 0.06017565354704857
  5%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                            | 5406/100000 [00:28<08:04, 195.31it/s][34m[1mwandb[39m[22m: 429 encountered (Filestream rate limit exceeded, retrying in 2.2 seconds.), retrying request
  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                            | 5672/100000 [00:29<08:04, 194.63it/s]
epoch 5400  training loss: 0.05741200968623161
epoch 5400  clean testing loss: 0.04173809289932251
epoch 5500  training loss: 0.05910560116171837
epoch 5500  clean testing loss: 0.039473291486501694
epoch 5600  training loss: 0.06086670234799385
epoch 5600  clean testing loss: 0.040048036724328995
epoch 5700  training loss: 0.055885277688503265

  6%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                            | 6056/100000 [00:31<08:10, 191.64it/s]
epoch 5800  training loss: 0.06301961839199066
epoch 5800  clean testing loss: 0.043790653347969055
epoch 5900  training loss: 0.05756908282637596
epoch 5900  clean testing loss: 0.040713634341955185
epoch 6000  training loss: 0.054496586322784424
epoch 6000  clean testing loss: 0.04217378422617912

  6%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 6445/100000 [00:33<08:03, 193.65it/s]
epoch 6100  training loss: 0.05554533004760742
epoch 6100  clean testing loss: 0.04316171631217003
epoch 6200  training loss: 0.05310043692588806
epoch 6200  clean testing loss: 0.04417276009917259
epoch 6300  training loss: 0.05473775789141655
epoch 6300  clean testing loss: 0.04460957273840904
epoch 6400  training loss: 0.05283774808049202

  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                           | 6834/100000 [00:35<08:05, 191.86it/s]
epoch 6500  training loss: 0.05317704379558563
epoch 6500  clean testing loss: 0.045315563678741455
epoch 6600  training loss: 0.05195096880197525
epoch 6600  clean testing loss: 0.04526401311159134
epoch 6700  training loss: 0.051240473985672
epoch 6700  clean testing loss: 0.04544318467378616
epoch 6800  training loss: 0.05887983366847038

  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                           | 7221/100000 [00:37<08:05, 191.09it/s]
epoch 6900  training loss: 0.0513395331799984
epoch 6900  clean testing loss: 0.045006610453128815
epoch 7000  training loss: 0.051575709134340286
epoch 7000  clean testing loss: 0.047063183039426804
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 7100  training loss: 0.050306402146816254
epoch 7100  clean testing loss: 0.046791840344667435
epoch 7200  training loss: 0.07661579549312592

  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                          | 7604/100000 [00:39<08:08, 189.24it/s]
epoch 7300  training loss: 0.05062702298164368
epoch 7300  clean testing loss: 0.047075290232896805
epoch 7400  training loss: 0.05085564777255058
epoch 7400  clean testing loss: 0.047210942953825
epoch 7500  training loss: 0.05150255933403969
epoch 7500  clean testing loss: 0.045126788318157196
epoch 7600  training loss: 0.05234125629067421

  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                          | 7994/100000 [00:41<07:49, 196.04it/s]
epoch 7700  training loss: 0.05084370821714401
epoch 7700  clean testing loss: 0.0445343516767025
epoch 7800  training loss: 0.052202366292476654
epoch 7800  clean testing loss: 0.04462798684835434
epoch 7900  training loss: 0.05030675604939461
epoch 7900  clean testing loss: 0.04675532132387161
epoch 8000  training loss: 0.05048729106783867
epoch 8000  clean testing loss: 0.05112089961767197

  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                          | 8381/100000 [00:43<08:04, 189.13it/s]
epoch 8100  training loss: 0.04924413561820984
epoch 8100  clean testing loss: 0.047041554003953934
epoch 8200  training loss: 0.051299791783094406
epoch 8200  clean testing loss: 0.04886182025074959
epoch 8300  training loss: 0.04868316277861595
epoch 8300  clean testing loss: 0.04618869349360466
epoch 8400  training loss: 0.05260443314909935

  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                          | 8770/100000 [00:45<07:40, 198.13it/s]
epoch 8500  training loss: 0.04824800789356232
epoch 8500  clean testing loss: 0.04741988703608513
epoch 8600  training loss: 0.05094008892774582
epoch 8600  clean testing loss: 0.0463077574968338
epoch 8700  training loss: 0.04961340129375458

  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                         | 9160/100000 [00:47<07:54, 191.59it/s]
epoch 8800  training loss: 0.050480589270591736
epoch 8800  clean testing loss: 0.04892849177122116
epoch 8900  training loss: 0.04927084222435951
epoch 8900  clean testing loss: 0.04677959904074669
epoch 9000  training loss: 0.04929780960083008
epoch 9000  clean testing loss: 0.04652871564030647
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 9100  training loss: 0.046815142035484314

 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                         | 9529/100000 [00:49<07:58, 189.03it/s]
epoch 9200  training loss: 0.046292681246995926
epoch 9200  clean testing loss: 0.04822298884391785
epoch 9300  training loss: 0.045869745314121246
epoch 9300  clean testing loss: 0.048496704548597336
epoch 9400  training loss: 0.045501671731472015
epoch 9400  clean testing loss: 0.04856153950095177
epoch 9500  training loss: 0.04594118893146515

 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                         | 9917/100000 [00:51<07:45, 193.46it/s]
epoch 9600  training loss: 0.046984851360321045
epoch 9600  clean testing loss: 0.04995347186923027
epoch 9700  training loss: 0.04965544864535332
epoch 9700  clean testing loss: 0.05072062462568283
epoch 9800  training loss: 0.0447661466896534
epoch 9800  clean testing loss: 0.049305807799100876
epoch 9900  training loss: 0.04665415361523628

 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                       | 10304/100000 [00:53<07:39, 195.00it/s]
epoch 10000  training loss: 0.04706695303320885
epoch 10000  clean testing loss: 0.05376356095075607
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 10100  training loss: 0.04415519908070564
epoch 10100  clean testing loss: 0.04866796359419823
epoch 10200  training loss: 0.044001054018735886
epoch 10200  clean testing loss: 0.05031383037567139
epoch 10300  training loss: 0.04534870386123657

 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 10687/100000 [00:55<07:36, 195.86it/s]
epoch 10400  training loss: 0.04445275291800499
epoch 10400  clean testing loss: 0.050248630344867706
epoch 10500  training loss: 0.04454133287072182
epoch 10500  clean testing loss: 0.049619387835264206
epoch 10600  training loss: 0.0508476123213768
epoch 10600  clean testing loss: 0.06342561542987823
epoch 10700  training loss: 0.04460703581571579

 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                       | 11075/100000 [00:57<07:40, 193.16it/s]
epoch 10800  training loss: 0.044066596776247025
epoch 10800  clean testing loss: 0.049945443868637085
epoch 10900  training loss: 0.04322206974029541
epoch 10900  clean testing loss: 0.05010208487510681
epoch 11000  training loss: 0.04290164262056351
epoch 11000  clean testing loss: 0.05111788585782051
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 11100  training loss: 0.051729775965213776

 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 11483/100000 [00:59<07:29, 197.13it/s]
epoch 11200  training loss: 0.04685740917921066
epoch 11200  clean testing loss: 0.050637103617191315
epoch 11300  training loss: 0.04274309054017067
epoch 11300  clean testing loss: 0.05041169747710228
epoch 11400  training loss: 0.04374103620648384

 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 11873/100000 [01:01<07:44, 189.88it/s]
epoch 11500  training loss: 0.04315713793039322
epoch 11500  clean testing loss: 0.052173685282468796
epoch 11600  training loss: 0.04236786812543869
epoch 11600  clean testing loss: 0.05196384713053703
epoch 11700  training loss: 0.0486801415681839
epoch 11700  clean testing loss: 0.06221208721399307
epoch 11800  training loss: 0.04285219684243202

 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 12265/100000 [01:03<07:26, 196.55it/s]
epoch 11900  training loss: 0.045446984469890594
epoch 11900  clean testing loss: 0.052192140370607376
epoch 12000  training loss: 0.04199928417801857
epoch 12000  clean testing loss: 0.050777047872543335
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 12100  training loss: 0.04231775924563408
epoch 12100  clean testing loss: 0.05123402550816536
epoch 12200  training loss: 0.043719202280044556

 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 12649/100000 [01:05<07:39, 189.91it/s]
epoch 12300  training loss: 0.04185618460178375
epoch 12300  clean testing loss: 0.05220095440745354
epoch 12400  training loss: 0.04127805307507515
epoch 12400  clean testing loss: 0.05246877670288086
epoch 12500  training loss: 0.04127885028719902
epoch 12500  clean testing loss: 0.05367198958992958
epoch 12600  training loss: 0.04151032492518425

 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                     | 13020/100000 [01:07<07:40, 189.03it/s]
epoch 12700  training loss: 0.041745636612176895
epoch 12700  clean testing loss: 0.05317686125636101
epoch 12800  training loss: 0.04137745872139931
epoch 12800  clean testing loss: 0.05351715907454491
epoch 12900  training loss: 0.04931437224149704
epoch 12900  clean testing loss: 0.05479498580098152
epoch 13000  training loss: 0.04060424864292145
epoch 13000  clean testing loss: 0.053331226110458374

 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 13408/100000 [01:09<07:26, 193.93it/s]
epoch 13100  training loss: 0.048340726643800735
epoch 13100  clean testing loss: 0.05233359336853027
epoch 13200  training loss: 0.05075310915708542
epoch 13200  clean testing loss: 0.05991135537624359
epoch 13300  training loss: 0.041313495486974716
epoch 13300  clean testing loss: 0.05262477323412895
epoch 13400  training loss: 0.04072539880871773

 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 13798/100000 [01:11<07:37, 188.37it/s]
epoch 13500  training loss: 0.04101485013961792
epoch 13500  clean testing loss: 0.05318513885140419
epoch 13600  training loss: 0.04010720178484917
epoch 13600  clean testing loss: 0.053285468369722366
epoch 13700  training loss: 0.03998947516083717
epoch 13700  clean testing loss: 0.05357807129621506
epoch 13800  training loss: 0.04188188537955284

 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 14189/100000 [01:13<07:22, 193.87it/s]
epoch 13900  training loss: 0.040605198591947556
epoch 13900  clean testing loss: 0.05315818637609482
epoch 14000  training loss: 0.04060373827815056
epoch 14000  clean testing loss: 0.054525427520275116
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 14100  training loss: 0.03978058695793152
epoch 14100  clean testing loss: 0.05364370346069336
epoch 14200  training loss: 0.04526635259389877

 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                    | 14574/100000 [01:15<07:34, 187.86it/s]
epoch 14300  training loss: 0.039819274097681046
epoch 14300  clean testing loss: 0.053774118423461914
epoch 14400  training loss: 0.039937667548656464
epoch 14400  clean testing loss: 0.05401457101106644
epoch 14500  training loss: 0.040060099214315414

 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 14960/100000 [01:17<07:13, 196.07it/s]
epoch 14600  training loss: 0.04102620109915733
epoch 14600  clean testing loss: 0.05483521893620491
epoch 14700  training loss: 0.04100912809371948
epoch 14700  clean testing loss: 0.054104726761579514
epoch 14800  training loss: 0.05731112137436867
epoch 14800  clean testing loss: 0.06067794933915138
epoch 14900  training loss: 0.039783626794815063

 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                   | 15352/100000 [01:19<07:14, 194.74it/s]
epoch 15000  training loss: 0.039705920964479446
epoch 15000  clean testing loss: 0.05406441166996956
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 15100  training loss: 0.03928934037685394
epoch 15100  clean testing loss: 0.055070504546165466
epoch 15200  training loss: 0.03880017250776291
epoch 15200  clean testing loss: 0.05458207055926323
epoch 15300  training loss: 0.03922093287110329

 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                   | 15742/100000 [01:21<07:09, 195.98it/s]
epoch 15400  training loss: 0.03893967345356941
epoch 15400  clean testing loss: 0.05543266609311104
epoch 15500  training loss: 0.03920925408601761
epoch 15500  clean testing loss: 0.0554950051009655
epoch 15600  training loss: 0.038590773940086365
epoch 15600  clean testing loss: 0.055069901049137115
epoch 15700  training loss: 0.03856535255908966

 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 16131/100000 [01:23<07:21, 189.79it/s]
epoch 15800  training loss: 0.03904113173484802
epoch 15800  clean testing loss: 0.05616007745265961
epoch 15900  training loss: 0.039138853549957275
epoch 15900  clean testing loss: 0.055537015199661255
epoch 16000  training loss: 0.03898071497678757
epoch 16000  clean testing loss: 0.05562771111726761
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 16100  training loss: 0.04000995308160782

 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 16520/100000 [01:25<07:08, 194.97it/s]
epoch 16200  training loss: 0.03872256353497505
epoch 16200  clean testing loss: 0.055510301142930984
epoch 16300  training loss: 0.03920035809278488
epoch 16300  clean testing loss: 0.05654659867286682
epoch 16400  training loss: 0.039590321481227875
epoch 16400  clean testing loss: 0.05527164787054062
epoch 16500  training loss: 0.04023740440607071

 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                  | 16910/100000 [01:27<07:19, 189.17it/s]
epoch 16600  training loss: 0.03805547580122948
epoch 16600  clean testing loss: 0.05468733608722687
epoch 16700  training loss: 0.03808915987610817
epoch 16700  clean testing loss: 0.055618561804294586
epoch 16800  training loss: 0.03777441754937172
epoch 16800  clean testing loss: 0.05547652766108513
epoch 16900  training loss: 0.03858742117881775

 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 17279/100000 [01:29<07:23, 186.53it/s]
epoch 17000  training loss: 0.040860697627067566
epoch 17000  clean testing loss: 0.0667233020067215
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 17100  training loss: 0.037609413266181946
epoch 17100  clean testing loss: 0.05533256381750107
epoch 17200  training loss: 0.037815455347299576

 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 17671/100000 [01:31<07:00, 195.62it/s]
epoch 17300  training loss: 0.03771328181028366
epoch 17300  clean testing loss: 0.055628277361392975
epoch 17400  training loss: 0.03884094953536987
epoch 17400  clean testing loss: 0.057243213057518005
epoch 17500  training loss: 0.038379207253456116
epoch 17500  clean testing loss: 0.05646809563040733
epoch 17600  training loss: 0.04173040762543678

 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 18056/100000 [01:33<07:15, 188.02it/s]
epoch 17700  training loss: 0.03828025981783867
epoch 17700  clean testing loss: 0.05633175000548363
epoch 17800  training loss: 0.037603989243507385
epoch 17800  clean testing loss: 0.056125544011592865
epoch 17900  training loss: 0.05368996039032936
epoch 17900  clean testing loss: 0.0653577372431755
epoch 18000  training loss: 0.03825938329100609
epoch 18000  clean testing loss: 0.055339328944683075

 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 18446/100000 [01:35<06:54, 196.60it/s]
epoch 18100  training loss: 0.03714919090270996
epoch 18100  clean testing loss: 0.05583864450454712
epoch 18200  training loss: 0.03722141310572624
epoch 18200  clean testing loss: 0.055879946798086166
epoch 18300  training loss: 0.03736847639083862
epoch 18300  clean testing loss: 0.05605795606970787
epoch 18400  training loss: 0.036894287914037704

 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                 | 18835/100000 [01:37<07:03, 191.82it/s]
epoch 18500  training loss: 0.03766436129808426
epoch 18500  clean testing loss: 0.05841990187764168
epoch 18600  training loss: 0.03696926310658455
epoch 18600  clean testing loss: 0.05642438679933548
epoch 18700  training loss: 0.03754384070634842
epoch 18700  clean testing loss: 0.05730942636728287
epoch 18800  training loss: 0.0369734987616539

 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                | 19225/100000 [01:39<06:59, 192.76it/s]
epoch 18900  training loss: 0.038761965930461884
epoch 18900  clean testing loss: 0.05975501611828804
epoch 19000  training loss: 0.036983754485845566
epoch 19000  clean testing loss: 0.056858014315366745
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 19100  training loss: 0.036895547062158585
epoch 19100  clean testing loss: 0.05691065639257431
epoch 19200  training loss: 0.03683628514409065

 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                | 19614/100000 [01:41<06:58, 191.94it/s]
epoch 19300  training loss: 0.04242096096277237
epoch 19300  clean testing loss: 0.06129780784249306
epoch 19400  training loss: 0.03652624040842056
epoch 19400  clean testing loss: 0.05698564276099205
epoch 19500  training loss: 0.03845718502998352
epoch 19500  clean testing loss: 0.0577257014811039
epoch 19600  training loss: 0.036520544439554214

 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 20001/100000 [01:43<07:02, 189.17it/s]
epoch 19700  training loss: 0.03627832233905792
epoch 19700  clean testing loss: 0.057176828384399414
epoch 19800  training loss: 0.037345726042985916
epoch 19800  clean testing loss: 0.05837272107601166
epoch 19900  training loss: 0.038111839443445206
epoch 19900  clean testing loss: 0.05977717041969299
epoch 20000  training loss: 0.03625936433672905
epoch 20000  clean testing loss: 0.05722232535481453

 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 20387/100000 [01:45<07:04, 187.57it/s]
epoch 20100  training loss: 0.037228524684906006
epoch 20100  clean testing loss: 0.05757354199886322
epoch 20200  training loss: 0.03652836009860039
epoch 20200  clean testing loss: 0.05751501023769379
epoch 20300  training loss: 0.03647312521934509

 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 20773/100000 [01:47<06:58, 189.46it/s]
epoch 20400  training loss: 0.03700454905629158
epoch 20400  clean testing loss: 0.05710379034280777
epoch 20500  training loss: 0.036637112498283386
epoch 20500  clean testing loss: 0.056737128645181656
epoch 20600  training loss: 0.03652537241578102
epoch 20600  clean testing loss: 0.05749136209487915
epoch 20700  training loss: 0.03609726205468178

 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 21161/100000 [01:49<06:47, 193.27it/s]
epoch 20800  training loss: 0.0362294465303421
epoch 20800  clean testing loss: 0.05789785459637642
epoch 20900  training loss: 0.036148834973573685
epoch 20900  clean testing loss: 0.057587262243032455
epoch 21000  training loss: 0.03648717701435089
epoch 21000  clean testing loss: 0.058184072375297546
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 21100  training loss: 0.03564823418855667

 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 21548/100000 [01:51<06:48, 191.93it/s]
epoch 21200  training loss: 0.035596031695604324
epoch 21200  clean testing loss: 0.05796617269515991
epoch 21300  training loss: 0.03613581880927086
epoch 21300  clean testing loss: 0.05786503106355667
epoch 21400  training loss: 0.03544493392109871
epoch 21400  clean testing loss: 0.05821318179368973
epoch 21500  training loss: 0.035567689687013626

 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 21939/100000 [01:53<06:41, 194.51it/s]
epoch 21600  training loss: 0.03575139120221138
epoch 21600  clean testing loss: 0.05814854055643082
epoch 21700  training loss: 0.035539694130420685
epoch 21700  clean testing loss: 0.0577852725982666
epoch 21800  training loss: 0.03666592761874199
epoch 21800  clean testing loss: 0.06067052483558655
epoch 21900  training loss: 0.03530818596482277

 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                              | 22334/100000 [01:55<06:36, 195.83it/s]
epoch 22000  training loss: 0.03554415702819824
epoch 22000  clean testing loss: 0.05879490450024605
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 22100  training loss: 0.03521837666630745
epoch 22100  clean testing loss: 0.05845658853650093
epoch 22200  training loss: 0.035464297980070114
epoch 22200  clean testing loss: 0.05822063609957695
epoch 22300  training loss: 0.03571920841932297

 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 22718/100000 [01:57<06:45, 190.66it/s]
epoch 22400  training loss: 0.03533356636762619
epoch 22400  clean testing loss: 0.0588381290435791
epoch 22500  training loss: 0.035277415066957474
epoch 22500  clean testing loss: 0.058642759919166565
epoch 22600  training loss: 0.03495036065578461
epoch 22600  clean testing loss: 0.05820450931787491
epoch 22700  training loss: 0.034986481070518494

 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 23106/100000 [01:59<06:39, 192.41it/s]
epoch 22800  training loss: 0.0349678210914135
epoch 22800  clean testing loss: 0.05823269858956337
epoch 22900  training loss: 0.03565128520131111
epoch 22900  clean testing loss: 0.058366917073726654
epoch 23000  training loss: 0.035266630351543427
epoch 23000  clean testing loss: 0.0585879310965538

 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                             | 23491/100000 [02:01<06:38, 191.99it/s]
epoch 23100  training loss: 0.03481143340468407
epoch 23100  clean testing loss: 0.058183908462524414
epoch 23200  training loss: 0.03506498038768768
epoch 23200  clean testing loss: 0.05848915874958038
epoch 23300  training loss: 0.03501094877719879
epoch 23300  clean testing loss: 0.059234850108623505
epoch 23400  training loss: 0.03475560247898102

 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                             | 23880/100000 [02:03<06:33, 193.37it/s]
epoch 23500  training loss: 0.035783614963293076
epoch 23500  clean testing loss: 0.05804145336151123
epoch 23600  training loss: 0.03462822735309601
epoch 23600  clean testing loss: 0.058881983160972595
epoch 23700  training loss: 0.034587036818265915
epoch 23700  clean testing loss: 0.058734048157930374
epoch 23800  training loss: 0.03460610285401344

 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                            | 24271/100000 [02:05<06:29, 194.44it/s]
epoch 23900  training loss: 0.03468897566199303
epoch 23900  clean testing loss: 0.05900101363658905
epoch 24000  training loss: 0.03463032841682434
epoch 24000  clean testing loss: 0.05916125699877739
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 24100  training loss: 0.03435862809419632
epoch 24100  clean testing loss: 0.058995600789785385
epoch 24200  training loss: 0.034370094537734985

 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                            | 24664/100000 [02:07<06:17, 199.38it/s]
epoch 24300  training loss: 0.03439517691731453
epoch 24300  clean testing loss: 0.059174057096242905
epoch 24400  training loss: 0.034384872764348984
epoch 24400  clean testing loss: 0.05925799533724785
epoch 24500  training loss: 0.03420732542872429
epoch 24500  clean testing loss: 0.05931388959288597
epoch 24600  training loss: 0.03509858623147011

 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 25053/100000 [02:09<06:41, 186.82it/s]
epoch 24700  training loss: 0.03454499691724777
epoch 24700  clean testing loss: 0.06002490594983101
epoch 24800  training loss: 0.03482644259929657
epoch 24800  clean testing loss: 0.05945057049393654
epoch 24900  training loss: 0.03466831520199776
epoch 24900  clean testing loss: 0.05897088348865509
epoch 25000  training loss: 0.034077998250722885
epoch 25000  clean testing loss: 0.05936767905950546

 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 25422/100000 [02:11<06:21, 195.44it/s]
epoch 25100  training loss: 0.034150026738643646
epoch 25100  clean testing loss: 0.059940822422504425
epoch 25200  training loss: 0.034174125641584396
epoch 25200  clean testing loss: 0.059656184166669846
epoch 25300  training loss: 0.03438150882720947
epoch 25300  clean testing loss: 0.05990689992904663
epoch 25400  training loss: 0.034438204020261765

 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                           | 25809/100000 [02:13<06:21, 194.59it/s]
epoch 25500  training loss: 0.0341985858976841
epoch 25500  clean testing loss: 0.059878602623939514
epoch 25600  training loss: 0.033928364515304565
epoch 25600  clean testing loss: 0.059676870703697205
epoch 25700  training loss: 0.03398651257157326
epoch 25700  clean testing loss: 0.05979710444808006
epoch 25800  training loss: 0.03426568582653999

 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                           | 25893/100000 [02:14<06:17, 196.25it/s]
epoch 25900  training loss: 0.03402841463685036

 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                           | 26151/100000 [02:24<22:50, 53.90it/s]
epoch 26000  training loss: 0.03397120162844658
epoch 26000  clean testing loss: 0.060313984751701355
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 26100  training loss: 0.034147895872592926

 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 26582/100000 [02:26<05:43, 213.93it/s]
epoch 26200  training loss: 0.0343526154756546
epoch 26200  clean testing loss: 0.06132673844695091
epoch 26300  training loss: 0.03379228711128235
epoch 26300  clean testing loss: 0.06008865684270859
epoch 26400  training loss: 0.034644387662410736
epoch 26400  clean testing loss: 0.06106480583548546
epoch 26500  training loss: 0.03379987180233002

 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 27021/100000 [02:28<05:30, 221.02it/s]
epoch 26600  training loss: 0.033705249428749084
epoch 26600  clean testing loss: 0.06006469577550888
epoch 26700  training loss: 0.033811312168836594
epoch 26700  clean testing loss: 0.06034756824374199
epoch 26800  training loss: 0.03374055027961731
epoch 26800  clean testing loss: 0.06025185436010361
epoch 26900  training loss: 0.037055209279060364
epoch 26900  clean testing loss: 0.06104657053947449
epoch 27000  training loss: 0.033557161688804626
epoch 27000  clean testing loss: 0.060225557535886765
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 27100  training loss: 0.03346559777855873
epoch 27100  clean testing loss: 0.06043345108628273
epoch 27200  training loss: 0.03340793028473854
epoch 27200  clean testing loss: 0.060352422297000885
epoch 27300  training loss: 0.03338281065225601
epoch 27300  clean testing loss: 0.06077134236693382
epoch 27400  training loss: 0.03339776769280434

 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 27457/100000 [02:30<05:29, 220.38it/s]
epoch 27500  training loss: 0.03336583822965622
epoch 27500  clean testing loss: 0.06065533682703972
epoch 27600  training loss: 0.033560771495103836
epoch 27600  clean testing loss: 0.06079227849841118
epoch 27700  training loss: 0.03337648883461952
epoch 27700  clean testing loss: 0.06085200235247612
epoch 27800  training loss: 0.03360302373766899

 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                         | 27897/100000 [02:32<05:36, 214.41it/s]
epoch 27900  training loss: 0.03328454867005348
epoch 27900  clean testing loss: 0.06113571301102638
epoch 28000  training loss: 0.03361250460147858
epoch 28000  clean testing loss: 0.061113253235816956
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 28100  training loss: 0.03324213624000549
epoch 28100  clean testing loss: 0.06105548143386841
epoch 28200  training loss: 0.03331967815756798
epoch 28200  clean testing loss: 0.061177320778369904
epoch 28300  training loss: 0.03354351222515106

 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                         | 28351/100000 [02:34<05:31, 216.42it/s]
epoch 28400  training loss: 0.033102892339229584
epoch 28400  clean testing loss: 0.061254989355802536
epoch 28500  training loss: 0.033055827021598816
epoch 28500  clean testing loss: 0.06095016002655029
epoch 28600  training loss: 0.03383192420005798
epoch 28600  clean testing loss: 0.06182616204023361
epoch 28700  training loss: 0.033173639327287674

 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                         | 28770/100000 [02:36<05:25, 218.64it/s]
epoch 28800  training loss: 0.03307123854756355
epoch 28800  clean testing loss: 0.061287082731723785
epoch 28900  training loss: 0.03360980749130249
epoch 28900  clean testing loss: 0.06137990951538086
epoch 29000  training loss: 0.03317413106560707
epoch 29000  clean testing loss: 0.06119263172149658
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 29100  training loss: 0.033250343054533005
epoch 29100  clean testing loss: 0.061428796499967575
epoch 29200  training loss: 0.03321557492017746

 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 29208/100000 [02:38<05:28, 215.59it/s]
epoch 29300  training loss: 0.032914046198129654
epoch 29300  clean testing loss: 0.06145012751221657
epoch 29400  training loss: 0.03290458768606186
epoch 29400  clean testing loss: 0.06149416044354439
epoch 29500  training loss: 0.03297640383243561
epoch 29500  clean testing loss: 0.061420999467372894
epoch 29600  training loss: 0.03285009413957596

 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                        | 29648/100000 [02:40<05:22, 218.24it/s]
epoch 29700  training loss: 0.03283742070198059
epoch 29700  clean testing loss: 0.06188569962978363
epoch 29800  training loss: 0.03275980427861214
epoch 29800  clean testing loss: 0.06185058504343033
epoch 29900  training loss: 0.033073607832193375
epoch 29900  clean testing loss: 0.06166812404990196
epoch 30000  training loss: 0.03339549899101257
epoch 30000  clean testing loss: 0.06231316551566124

 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                        | 30089/100000 [02:42<05:27, 213.72it/s]
epoch 30100  training loss: 0.032635755836963654
epoch 30100  clean testing loss: 0.06186724454164505
epoch 30200  training loss: 0.03260429948568344
epoch 30200  clean testing loss: 0.06189101189374924
epoch 30300  training loss: 0.03257044404745102
epoch 30300  clean testing loss: 0.062231432646512985
epoch 30400  training loss: 0.0325750969350338
epoch 30400  clean testing loss: 0.06205424666404724
epoch 30500  training loss: 0.032693397253751755

 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                       | 30526/100000 [02:44<05:18, 218.08it/s]
epoch 30600  training loss: 0.032634537667036057
epoch 30600  clean testing loss: 0.06227099895477295
epoch 30700  training loss: 0.0326385460793972
epoch 30700  clean testing loss: 0.06208948791027069
epoch 30800  training loss: 0.03260380029678345
epoch 30800  clean testing loss: 0.06209266185760498
epoch 30900  training loss: 0.03254237771034241

 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                       | 30969/100000 [02:46<05:07, 224.64it/s]
epoch 31000  training loss: 0.032643936574459076
epoch 31000  clean testing loss: 0.062127359211444855
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 31100  training loss: 0.032506655901670456
epoch 31100  clean testing loss: 0.06225686892867088
epoch 31200  training loss: 0.03262845054268837
epoch 31200  clean testing loss: 0.06202133372426033
epoch 31300  training loss: 0.03244820609688759

 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                      | 31415/100000 [02:48<05:08, 222.63it/s]
epoch 31400  training loss: 0.03238300234079361
epoch 31400  clean testing loss: 0.062212590128183365
epoch 31500  training loss: 0.03235581889748573
epoch 31500  clean testing loss: 0.06246848776936531
epoch 31600  training loss: 0.032367363572120667
epoch 31600  clean testing loss: 0.06235967576503754
epoch 31700  training loss: 0.03251144289970398
epoch 31700  clean testing loss: 0.0626649260520935
epoch 31800  training loss: 0.03233785182237625

 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 31851/100000 [02:50<05:15, 215.81it/s]
epoch 31900  training loss: 0.032301101833581924
epoch 31900  clean testing loss: 0.06277408450841904
epoch 32000  training loss: 0.03227710723876953
epoch 32000  clean testing loss: 0.06270558387041092
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 32100  training loss: 0.03218233585357666
epoch 32100  clean testing loss: 0.06248950585722923
epoch 32200  training loss: 0.03252238780260086

 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                      | 32289/100000 [02:52<05:07, 220.03it/s]
epoch 32300  training loss: 0.03216704726219177
epoch 32300  clean testing loss: 0.06299224495887756
epoch 32400  training loss: 0.0323769710958004
epoch 32400  clean testing loss: 0.0625620111823082
epoch 32500  training loss: 0.03228117525577545
epoch 32500  clean testing loss: 0.06346194446086884
epoch 32600  training loss: 0.03244980052113533
epoch 32600  clean testing loss: 0.0629466325044632
epoch 32700  training loss: 0.03213711827993393

 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                     | 32732/100000 [02:54<04:51, 230.74it/s]
epoch 32800  training loss: 0.03279177099466324
epoch 32800  clean testing loss: 0.06345312297344208
epoch 32900  training loss: 0.0320802666246891
epoch 32900  clean testing loss: 0.06289737671613693
epoch 33000  training loss: 0.032391395419836044
epoch 33000  clean testing loss: 0.0629650205373764
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 33100  training loss: 0.031958840787410736

 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                     | 33171/100000 [02:56<05:01, 221.97it/s]
epoch 33200  training loss: 0.031924858689308167
epoch 33200  clean testing loss: 0.06305968016386032
epoch 33300  training loss: 0.031981874257326126
epoch 33300  clean testing loss: 0.0631214901804924
epoch 33400  training loss: 0.031970687210559845

 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 33396/100000 [02:57<05:11, 213.83it/s]
epoch 33500  training loss: 0.03196726739406586
epoch 33500  clean testing loss: 0.06324918568134308
epoch 33600  training loss: 0.03206819295883179
epoch 33600  clean testing loss: 0.0631193295121193
epoch 33700  training loss: 0.03200894221663475
epoch 33700  clean testing loss: 0.06385812908411026
epoch 33800  training loss: 0.031906843185424805
epoch 33800  clean testing loss: 0.06321443617343903
epoch 33900  training loss: 0.03204189985990524
epoch 33900  clean testing loss: 0.06342267245054245
epoch 34000  training loss: 0.03181508928537369
epoch 34000  clean testing loss: 0.06323667615652084
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 34100  training loss: 0.03183763101696968
epoch 34100  clean testing loss: 0.06326884776353836
epoch 34200  training loss: 0.031939174979925156
epoch 34200  clean testing loss: 0.06386620551347733
epoch 34300  training loss: 0.03191090375185013

 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 34353/100000 [03:02<05:42, 191.93it/s]
epoch 34400  training loss: 0.031809985637664795
epoch 34400  clean testing loss: 0.06358224898576736
epoch 34500  training loss: 0.0320112369954586
epoch 34500  clean testing loss: 0.06407646834850311
epoch 34600  training loss: 0.03199118375778198
epoch 34600  clean testing loss: 0.06357105821371078
epoch 34700  training loss: 0.03191531449556351

 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 34741/100000 [03:04<05:26, 199.77it/s]
epoch 34800  training loss: 0.031731016933918
epoch 34800  clean testing loss: 0.06353233009576797
epoch 34900  training loss: 0.031686823815107346
epoch 34900  clean testing loss: 0.06365695595741272
epoch 35000  training loss: 0.03201424703001976
epoch 35000  clean testing loss: 0.06421951204538345


 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 35500/100000 [03:08<05:37, 191.37it/s]
epoch 35100  training loss: 0.03169086202979088
epoch 35100  clean testing loss: 0.06365502625703812
epoch 35200  training loss: 0.03170163929462433
epoch 35200  clean testing loss: 0.06402182579040527
epoch 35300  training loss: 0.03197524696588516
epoch 35300  clean testing loss: 0.06383651494979858
epoch 35400  training loss: 0.0315840020775795

 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                   | 35889/100000 [03:10<05:22, 199.05it/s]
epoch 35500  training loss: 0.03155812993645668
epoch 35500  clean testing loss: 0.06378422677516937
epoch 35600  training loss: 0.03196397051215172
epoch 35600  clean testing loss: 0.06385070085525513
epoch 35700  training loss: 0.0317394882440567
epoch 35700  clean testing loss: 0.0640418529510498
epoch 35800  training loss: 0.03166290745139122

 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 36280/100000 [03:12<05:43, 185.43it/s]
epoch 35900  training loss: 0.03153490647673607
epoch 35900  clean testing loss: 0.06385964900255203
epoch 36000  training loss: 0.03174238279461861
epoch 36000  clean testing loss: 0.0639452338218689
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 36100  training loss: 0.031451515853405
epoch 36100  clean testing loss: 0.06401603668928146
epoch 36200  training loss: 0.03142497316002846

 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                  | 36669/100000 [03:14<05:27, 193.26it/s]
epoch 36300  training loss: 0.03139787167310715
epoch 36300  clean testing loss: 0.0640970766544342
epoch 36400  training loss: 0.031447283923625946
epoch 36400  clean testing loss: 0.06430547684431076
epoch 36500  training loss: 0.031368061900138855
epoch 36500  clean testing loss: 0.06406589597463608
epoch 36600  training loss: 0.03139825537800789

 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                  | 37056/100000 [03:16<05:26, 192.54it/s]
epoch 36700  training loss: 0.031452786177396774
epoch 36700  clean testing loss: 0.06418335437774658
epoch 36800  training loss: 0.031435418874025345
epoch 36800  clean testing loss: 0.06447423249483109
epoch 36900  training loss: 0.03132731094956398
epoch 36900  clean testing loss: 0.06455004960298538
epoch 37000  training loss: 0.03137843310832977
epoch 37000  clean testing loss: 0.06463174521923065

 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 37445/100000 [03:18<05:21, 194.55it/s]
epoch 37100  training loss: 0.03138888627290726
epoch 37100  clean testing loss: 0.06431729346513748
epoch 37200  training loss: 0.031475309282541275
epoch 37200  clean testing loss: 0.06453703343868256
epoch 37300  training loss: 0.03131601959466934
epoch 37300  clean testing loss: 0.06468623876571655
epoch 37400  training loss: 0.03134662285447121

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 37831/100000 [03:20<05:23, 192.46it/s]
epoch 37500  training loss: 0.0313260518014431
epoch 37500  clean testing loss: 0.06456048786640167
epoch 37600  training loss: 0.031291648745536804
epoch 37600  clean testing loss: 0.06489168852567673
epoch 37700  training loss: 0.03132690116763115
epoch 37700  clean testing loss: 0.06436815112829208
epoch 37800  training loss: 0.031193522736430168

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 38221/100000 [03:22<05:15, 195.99it/s]
epoch 37900  training loss: 0.03132406622171402
epoch 37900  clean testing loss: 0.06460809707641602
epoch 38000  training loss: 0.031181763857603073
epoch 38000  clean testing loss: 0.06465735286474228
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 38100  training loss: 0.031164254993200302

 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                 | 38608/100000 [03:24<05:19, 191.94it/s]
epoch 38200  training loss: 0.031332388520240784
epoch 38200  clean testing loss: 0.06538885086774826
epoch 38300  training loss: 0.031162085011601448
epoch 38300  clean testing loss: 0.0648132786154747
epoch 38400  training loss: 0.031171612441539764
epoch 38400  clean testing loss: 0.06473793089389801
epoch 38500  training loss: 0.031280070543289185

 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                | 39000/100000 [03:26<05:07, 198.54it/s]
epoch 38600  training loss: 0.031200582161545753
epoch 38600  clean testing loss: 0.0648578628897667
epoch 38700  training loss: 0.03113359771668911
epoch 38700  clean testing loss: 0.06504124402999878
epoch 38800  training loss: 0.03118688054382801
epoch 38800  clean testing loss: 0.06510984897613525
epoch 38900  training loss: 0.031059522181749344

 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 39391/100000 [03:28<05:16, 191.62it/s]
epoch 39000  training loss: 0.031123148277401924
epoch 39000  clean testing loss: 0.0651572123169899
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 39100  training loss: 0.030993420630693436
epoch 39100  clean testing loss: 0.06499957293272018
epoch 39200  training loss: 0.031005967408418655
epoch 39200  clean testing loss: 0.06523306667804718
epoch 39300  training loss: 0.03102317824959755

 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                | 39778/100000 [03:30<05:05, 197.26it/s]
epoch 39400  training loss: 0.030977969989180565
epoch 39400  clean testing loss: 0.06515710800886154
epoch 39500  training loss: 0.031015656888484955
epoch 39500  clean testing loss: 0.06514344364404678
epoch 39600  training loss: 0.031130973249673843
epoch 39600  clean testing loss: 0.0651930719614029
epoch 39700  training loss: 0.031003594398498535

 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 40169/100000 [03:32<05:12, 191.71it/s]
epoch 39800  training loss: 0.030965687707066536
epoch 39800  clean testing loss: 0.06533580273389816
epoch 39900  training loss: 0.030908996239304543
epoch 39900  clean testing loss: 0.06535591185092926
epoch 40000  training loss: 0.0311273243278265
epoch 40000  clean testing loss: 0.06531528383493423
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 40100  training loss: 0.030988408252596855

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 40540/100000 [03:34<05:14, 188.95it/s]
epoch 40200  training loss: 0.03088218718767166
epoch 40200  clean testing loss: 0.06557390838861465
epoch 40300  training loss: 0.030868228524923325
epoch 40300  clean testing loss: 0.06569677591323853
epoch 40400  training loss: 0.03093087486922741
epoch 40400  clean testing loss: 0.06556346267461777
epoch 40500  training loss: 0.030999230220913887

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 40950/100000 [03:36<05:07, 192.01it/s]
epoch 40600  training loss: 0.030820360407233238
epoch 40600  clean testing loss: 0.06580189615488052
epoch 40700  training loss: 0.03108401596546173
epoch 40700  clean testing loss: 0.06626566499471664
epoch 40800  training loss: 0.030873911455273628
epoch 40800  clean testing loss: 0.06571725755929947
epoch 40900  training loss: 0.030839985236525536

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 41318/100000 [03:38<05:06, 191.29it/s]
epoch 41000  training loss: 0.03084050677716732
epoch 41000  clean testing loss: 0.06600723415613174
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 41100  training loss: 0.030773689970374107
epoch 41100  clean testing loss: 0.06605947017669678
epoch 41200  training loss: 0.031129347160458565

 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                              | 41722/100000 [03:40<05:08, 188.66it/s]
epoch 41300  training loss: 0.030816005542874336
epoch 41300  clean testing loss: 0.065901979804039
epoch 41400  training loss: 0.03076505847275257
epoch 41400  clean testing loss: 0.06602729856967926
epoch 41500  training loss: 0.030784040689468384
epoch 41500  clean testing loss: 0.0657905638217926
epoch 41600  training loss: 0.030792975798249245

 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 42011/100000 [03:42<04:53, 197.47it/s]
epoch 41700  training loss: 0.03075774759054184
epoch 41700  clean testing loss: 0.06595221161842346
epoch 41800  training loss: 0.03074745275080204
epoch 41800  clean testing loss: 0.06595904380083084
epoch 41900  training loss: 0.03068489208817482
epoch 41900  clean testing loss: 0.06599494069814682
epoch 42000  training loss: 0.030693242326378822
epoch 42000  clean testing loss: 0.06602483987808228

 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                              | 42399/100000 [03:44<05:07, 187.35it/s]
epoch 42100  training loss: 0.03065904974937439
epoch 42100  clean testing loss: 0.06608738750219345
epoch 42200  training loss: 0.030658166855573654
epoch 42200  clean testing loss: 0.06608013063669205
epoch 42300  training loss: 0.03061595931649208
epoch 42300  clean testing loss: 0.06609907746315002
epoch 42400  training loss: 0.030645150691270828

 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 42786/100000 [03:46<04:57, 192.24it/s]
epoch 42500  training loss: 0.0306857880204916
epoch 42500  clean testing loss: 0.06613446027040482
epoch 42600  training loss: 0.030648384243249893
epoch 42600  clean testing loss: 0.06607452780008316
epoch 42700  training loss: 0.030637448653578758
epoch 42700  clean testing loss: 0.06610235571861267
epoch 42800  training loss: 0.030603593215346336

 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 43177/100000 [03:48<04:59, 189.66it/s]
epoch 42900  training loss: 0.03055795468389988
epoch 42900  clean testing loss: 0.06628650426864624
epoch 43000  training loss: 0.030669771134853363
epoch 43000  clean testing loss: 0.06613409519195557
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 43100  training loss: 0.03061385452747345
epoch 43100  clean testing loss: 0.06632509082555771
epoch 43200  training loss: 0.030598947778344154

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 43566/100000 [03:50<04:46, 196.68it/s]
epoch 43300  training loss: 0.030607961118221283
epoch 43300  clean testing loss: 0.06662523001432419
epoch 43400  training loss: 0.030524061992764473
epoch 43400  clean testing loss: 0.06641389429569244
epoch 43500  training loss: 0.03062145598232746
epoch 43500  clean testing loss: 0.06667918711900711
epoch 43600  training loss: 0.030527852475643158

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 43939/100000 [03:52<04:47, 195.10it/s]
epoch 43700  training loss: 0.03052402101457119
epoch 43700  clean testing loss: 0.06653335690498352
epoch 43800  training loss: 0.030543284490704536
epoch 43800  clean testing loss: 0.06672410666942596
epoch 43900  training loss: 0.030477723106741905
epoch 43900  clean testing loss: 0.06671200692653656
epoch 44000  training loss: 0.030451321974396706
epoch 44000  clean testing loss: 0.06643303483724594

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                            | 44323/100000 [03:54<04:51, 191.23it/s]
epoch 44100  training loss: 0.03050788678228855
epoch 44100  clean testing loss: 0.06658782809972763
epoch 44200  training loss: 0.030453091487288475
epoch 44200  clean testing loss: 0.06668227165937424
epoch 44300  training loss: 0.030431542545557022

 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                            | 44713/100000 [03:56<04:49, 190.95it/s]
epoch 44400  training loss: 0.03047068789601326
epoch 44400  clean testing loss: 0.06678386777639389
epoch 44500  training loss: 0.03042987361550331
epoch 44500  clean testing loss: 0.06692720949649811
epoch 44600  training loss: 0.03042079694569111
epoch 44600  clean testing loss: 0.0666436031460762
epoch 44700  training loss: 0.030367860570549965

 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                            | 45099/100000 [03:58<04:38, 197.24it/s]
epoch 44800  training loss: 0.03046654909849167
epoch 44800  clean testing loss: 0.06661675125360489
epoch 44900  training loss: 0.030505696311593056
epoch 44900  clean testing loss: 0.0671531930565834
epoch 45000  training loss: 0.030388278886675835
epoch 45000  clean testing loss: 0.06689031422138214
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 45100  training loss: 0.03031441569328308

 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                           | 45488/100000 [04:00<04:43, 192.11it/s]
epoch 45200  training loss: 0.0303177572786808
epoch 45200  clean testing loss: 0.06703308969736099
epoch 45300  training loss: 0.030311090871691704
epoch 45300  clean testing loss: 0.06678735464811325
epoch 45400  training loss: 0.03033076412975788
epoch 45400  clean testing loss: 0.06680421531200409
epoch 45500  training loss: 0.03027382120490074

 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 45879/100000 [04:02<04:31, 199.40it/s]
epoch 45600  training loss: 0.030317358672618866
epoch 45600  clean testing loss: 0.06696970015764236
epoch 45700  training loss: 0.03027997352182865
epoch 45700  clean testing loss: 0.06707122176885605
epoch 45800  training loss: 0.030298752710223198
epoch 45800  clean testing loss: 0.06703709810972214
epoch 45900  training loss: 0.030303403735160828

 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           | 46263/100000 [04:04<04:43, 189.86it/s]
epoch 46000  training loss: 0.03028983809053898
epoch 46000  clean testing loss: 0.06714076548814774
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 46100  training loss: 0.030215883627533913
epoch 46100  clean testing loss: 0.06700116395950317
epoch 46200  training loss: 0.030247358605265617
epoch 46200  clean testing loss: 0.06701135635375977
epoch 46300  training loss: 0.03024458885192871

 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                          | 46655/100000 [04:06<04:27, 199.38it/s]
epoch 46400  training loss: 0.030206838622689247
epoch 46400  clean testing loss: 0.06725555658340454
epoch 46500  training loss: 0.0302241463214159
epoch 46500  clean testing loss: 0.06710319966077805
epoch 46600  training loss: 0.030192337930202484

 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 47044/100000 [04:08<04:38, 190.42it/s]
epoch 46700  training loss: 0.03021479956805706
epoch 46700  clean testing loss: 0.06742478907108307
epoch 46800  training loss: 0.03019069880247116
epoch 46800  clean testing loss: 0.06714290380477905
epoch 46900  training loss: 0.030255770310759544
epoch 46900  clean testing loss: 0.0675959587097168
epoch 47000  training loss: 0.03015664592385292
epoch 47000  clean testing loss: 0.06721759587526321

 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                          | 47407/100000 [04:10<04:37, 189.82it/s]
epoch 47100  training loss: 0.030169416218996048
epoch 47100  clean testing loss: 0.06745301932096481
epoch 47200  training loss: 0.03014989010989666
epoch 47200  clean testing loss: 0.06723298877477646
epoch 47300  training loss: 0.030115365982055664
epoch 47300  clean testing loss: 0.06752938032150269
epoch 47400  training loss: 0.030126962810754776

 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 47800/100000 [04:12<04:23, 198.11it/s]
epoch 47500  training loss: 0.030110493302345276
epoch 47500  clean testing loss: 0.06777294725179672
epoch 47600  training loss: 0.030093278735876083
epoch 47600  clean testing loss: 0.06751750409603119
epoch 47700  training loss: 0.03010953590273857
epoch 47700  clean testing loss: 0.06748275458812714
epoch 47800  training loss: 0.030031278729438782

 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 48186/100000 [04:14<04:36, 187.13it/s]
epoch 47900  training loss: 0.03006226196885109
epoch 47900  clean testing loss: 0.06762098520994186
epoch 48000  training loss: 0.030159223824739456
epoch 48000  clean testing loss: 0.0677010640501976
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 48100  training loss: 0.029991639778017998
epoch 48100  clean testing loss: 0.06760483235120773
epoch 48200  training loss: 0.029992777854204178

 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 48568/100000 [04:16<04:28, 191.56it/s]
epoch 48300  training loss: 0.03000355325639248
epoch 48300  clean testing loss: 0.06763505935668945
epoch 48400  training loss: 0.029985575005412102
epoch 48400  clean testing loss: 0.06771478056907654
epoch 48500  training loss: 0.029974203556776047
epoch 48500  clean testing loss: 0.0676928162574768
epoch 48600  training loss: 0.02995278313755989

 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 48975/100000 [04:18<03:50, 221.68it/s]
epoch 48700  training loss: 0.02998674474656582
epoch 48700  clean testing loss: 0.06767607480287552
epoch 48800  training loss: 0.029938355088233948
epoch 48800  clean testing loss: 0.0679033175110817
epoch 48900  training loss: 0.029930904507637024
epoch 48900  clean testing loss: 0.06777016073465347
epoch 49000  training loss: 0.029932502657175064
epoch 49000  clean testing loss: 0.06775260716676712
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 49100  training loss: 0.029943231493234634
epoch 49100  clean testing loss: 0.06798989325761795
epoch 49200  training loss: 0.029900621622800827
epoch 49200  clean testing loss: 0.06787773221731186
epoch 49300  training loss: 0.029915062710642815
epoch 49300  clean testing loss: 0.0679413229227066
epoch 49400  training loss: 0.02987797185778618


 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                        | 49847/100000 [04:22<03:54, 213.70it/s]
epoch 49500  training loss: 0.029945477843284607
epoch 49500  clean testing loss: 0.06784525513648987
epoch 49600  training loss: 0.029917683452367783
epoch 49600  clean testing loss: 0.0680789053440094
epoch 49700  training loss: 0.02987842634320259
epoch 49700  clean testing loss: 0.06785416603088379
epoch 49800  training loss: 0.029872002080082893
epoch 49800  clean testing loss: 0.06797008216381073
epoch 49900  training loss: 0.02983788028359413

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                       | 50287/100000 [04:24<03:44, 221.20it/s]
epoch 50000  training loss: 0.029854794964194298
epoch 50000  clean testing loss: 0.06796137988567352
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 50100  training loss: 0.02982879802584648
epoch 50100  clean testing loss: 0.06819137930870056
epoch 50200  training loss: 0.0297933891415596
epoch 50200  clean testing loss: 0.06811080127954483
epoch 50300  training loss: 0.02979116700589657

 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                       | 50728/100000 [04:26<03:43, 220.00it/s]
epoch 50400  training loss: 0.029849760234355927
epoch 50400  clean testing loss: 0.06808058172464371
epoch 50500  training loss: 0.029803790152072906
epoch 50500  clean testing loss: 0.06828317046165466
epoch 50600  training loss: 0.02975921891629696
epoch 50600  clean testing loss: 0.06812198460102081
epoch 50700  training loss: 0.02979901246726513

 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                       | 51168/100000 [04:28<03:42, 219.04it/s]
epoch 50800  training loss: 0.029746323823928833
epoch 50800  clean testing loss: 0.06819002330303192
epoch 50900  training loss: 0.02976335398852825
epoch 50900  clean testing loss: 0.06829167902469635
epoch 51000  training loss: 0.029728880152106285
epoch 51000  clean testing loss: 0.0683286041021347
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 51100  training loss: 0.029709745198488235
epoch 51100  clean testing loss: 0.06830644607543945
epoch 51200  training loss: 0.029713120311498642

 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 51606/100000 [04:30<03:42, 217.40it/s]
epoch 51300  training loss: 0.029703225940465927
epoch 51300  clean testing loss: 0.0683344379067421
epoch 51400  training loss: 0.029693223536014557
epoch 51400  clean testing loss: 0.06845124810934067
epoch 51500  training loss: 0.029689263552427292
epoch 51500  clean testing loss: 0.06835254281759262
epoch 51600  training loss: 0.029669908806681633

 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 52041/100000 [04:32<03:45, 213.02it/s]
epoch 51700  training loss: 0.02967912144958973
epoch 51700  clean testing loss: 0.06830868124961853
epoch 51800  training loss: 0.029651310294866562
epoch 51800  clean testing loss: 0.06836000084877014
epoch 51900  training loss: 0.029637880623340607
epoch 51900  clean testing loss: 0.06846138089895248
epoch 52000  training loss: 0.029627855867147446
epoch 52000  clean testing loss: 0.06853726506233215

 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 52472/100000 [04:34<03:38, 217.75it/s]
epoch 52100  training loss: 0.02962634153664112
epoch 52100  clean testing loss: 0.06855230778455734
epoch 52200  training loss: 0.029614727944135666
epoch 52200  clean testing loss: 0.06853162497282028
epoch 52300  training loss: 0.029641591012477875
epoch 52300  clean testing loss: 0.06875765323638916
epoch 52400  training loss: 0.029634632170200348
epoch 52400  clean testing loss: 0.06856101006269455
epoch 52500  training loss: 0.029623761773109436

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 52909/100000 [04:36<03:38, 216.01it/s]
epoch 52600  training loss: 0.029631974175572395
epoch 52600  clean testing loss: 0.06876139342784882
epoch 52700  training loss: 0.029569951817393303
epoch 52700  clean testing loss: 0.06867500394582748
epoch 52800  training loss: 0.029620550572872162
epoch 52800  clean testing loss: 0.06865331530570984
epoch 52900  training loss: 0.029555490240454674

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 53352/100000 [04:38<03:28, 223.37it/s]
epoch 53000  training loss: 0.029575888067483902
epoch 53000  clean testing loss: 0.06872894614934921
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 53100  training loss: 0.029565172269940376
epoch 53100  clean testing loss: 0.06861114501953125
epoch 53200  training loss: 0.02950049750506878
epoch 53200  clean testing loss: 0.0688738152384758
epoch 53300  training loss: 0.029502009972929955
epoch 53300  clean testing loss: 0.06887014210224152
epoch 53400  training loss: 0.029492391273379326

 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 53793/100000 [04:40<03:31, 218.84it/s]
epoch 53500  training loss: 0.029491491615772247
epoch 53500  clean testing loss: 0.06884264945983887
epoch 53600  training loss: 0.029465116560459137
epoch 53600  clean testing loss: 0.06885754317045212
epoch 53700  training loss: 0.02948254533112049
epoch 53700  clean testing loss: 0.06888949871063232
epoch 53800  training loss: 0.02948240377008915

 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 54234/100000 [04:42<03:34, 213.72it/s]
epoch 53900  training loss: 0.029436811804771423
epoch 53900  clean testing loss: 0.06912514567375183
epoch 54000  training loss: 0.02949199452996254
epoch 54000  clean testing loss: 0.06885737180709839
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 54100  training loss: 0.02942424826323986
epoch 54100  clean testing loss: 0.06906121969223022
epoch 54200  training loss: 0.029396221041679382

 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 54679/100000 [04:44<03:25, 220.16it/s]
epoch 54300  training loss: 0.029414929449558258
epoch 54300  clean testing loss: 0.06915642321109772
epoch 54400  training loss: 0.02938678488135338
epoch 54400  clean testing loss: 0.06912864744663239
epoch 54500  training loss: 0.029385408386588097
epoch 54500  clean testing loss: 0.06913481652736664
epoch 54600  training loss: 0.02937263622879982
epoch 54600  clean testing loss: 0.06910865008831024
epoch 54700  training loss: 0.029378628358244896

 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 55114/100000 [04:46<03:27, 216.82it/s]
epoch 54800  training loss: 0.029364820569753647
epoch 54800  clean testing loss: 0.06932729482650757
epoch 54900  training loss: 0.0293650571256876
epoch 54900  clean testing loss: 0.06913738697767258
epoch 55000  training loss: 0.029365884140133858
epoch 55000  clean testing loss: 0.06912861764431
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 55100  training loss: 0.029322965070605278

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 55547/100000 [04:48<03:21, 220.94it/s]
epoch 55200  training loss: 0.029348228126764297
epoch 55200  clean testing loss: 0.06924794614315033
epoch 55300  training loss: 0.029340771958231926
epoch 55300  clean testing loss: 0.06920620799064636
epoch 55400  training loss: 0.029324738308787346
epoch 55400  clean testing loss: 0.06927884370088577
epoch 55500  training loss: 0.029315076768398285

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 55987/100000 [04:50<03:17, 222.48it/s]
epoch 55600  training loss: 0.029302390292286873
epoch 55600  clean testing loss: 0.06943672150373459
epoch 55700  training loss: 0.02929062582552433
epoch 55700  clean testing loss: 0.06947486847639084
epoch 55800  training loss: 0.029272548854351044
epoch 55800  clean testing loss: 0.06946542859077454
epoch 55900  training loss: 0.02928605116903782
epoch 55900  clean testing loss: 0.06942223757505417
epoch 56000  training loss: 0.029263831675052643
epoch 56000  clean testing loss: 0.06943367421627045

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 56457/100000 [04:52<03:02, 239.13it/s]
epoch 56100  training loss: 0.029249202460050583
epoch 56100  clean testing loss: 0.06943738460540771
epoch 56200  training loss: 0.029254570603370667
epoch 56200  clean testing loss: 0.0694674700498581
epoch 56300  training loss: 0.029235754162073135
epoch 56300  clean testing loss: 0.06947486102581024
epoch 56400  training loss: 0.0292355976998806
epoch 56400  clean testing loss: 0.06945764273405075
epoch 56500  training loss: 0.02922995202243328

 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 56961/100000 [04:54<02:55, 244.61it/s]
epoch 56600  training loss: 0.02920297533273697
epoch 56600  clean testing loss: 0.06958609819412231
epoch 56700  training loss: 0.029227543622255325
epoch 56700  clean testing loss: 0.06946112960577011
epoch 56800  training loss: 0.02921191230416298
epoch 56800  clean testing loss: 0.06962244212627411
epoch 56900  training loss: 0.029214223846793175

 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 57440/100000 [04:56<02:54, 244.19it/s]
epoch 57000  training loss: 0.029196232557296753
epoch 57000  clean testing loss: 0.06970042735338211
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 57100  training loss: 0.029175134375691414
epoch 57100  clean testing loss: 0.06970421224832535
epoch 57200  training loss: 0.029169617220759392
epoch 57200  clean testing loss: 0.06968890875577927
epoch 57300  training loss: 0.029161587357521057
epoch 57300  clean testing loss: 0.0697070062160492
epoch 57400  training loss: 0.029155833646655083

 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 57920/100000 [04:58<02:56, 237.82it/s]
epoch 57500  training loss: 0.029156342148780823
epoch 57500  clean testing loss: 0.06971373409032822
epoch 57600  training loss: 0.02913803607225418
epoch 57600  clean testing loss: 0.06975476443767548
epoch 57700  training loss: 0.029131395742297173
epoch 57700  clean testing loss: 0.06971275806427002
epoch 57800  training loss: 0.029129689559340477
epoch 57800  clean testing loss: 0.06973768770694733
epoch 57900  training loss: 0.029130596667528152

 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 58395/100000 [05:00<02:53, 240.12it/s]
epoch 58000  training loss: 0.029108520597219467
epoch 58000  clean testing loss: 0.06979431211948395
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 58100  training loss: 0.02910802513360977
epoch 58100  clean testing loss: 0.06998802721500397
epoch 58200  training loss: 0.029096024110913277
epoch 58200  clean testing loss: 0.06985572725534439
epoch 58300  training loss: 0.02909107133746147
epoch 58300  clean testing loss: 0.06982815265655518
epoch 58400  training loss: 0.029080480337142944

 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 58900/100000 [05:02<02:49, 242.10it/s]
epoch 58500  training loss: 0.02907404489815235
epoch 58500  clean testing loss: 0.0699247270822525
epoch 58600  training loss: 0.029067447409033775
epoch 58600  clean testing loss: 0.06995898485183716
epoch 58700  training loss: 0.02906208671629429
epoch 58700  clean testing loss: 0.07004459202289581
epoch 58800  training loss: 0.029053376987576485
epoch 58800  clean testing loss: 0.07001665234565735
epoch 58900  training loss: 0.02906155213713646

 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 59380/100000 [05:04<02:47, 243.07it/s]
epoch 59000  training loss: 0.0290484968572855
epoch 59000  clean testing loss: 0.07001197338104248
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 59100  training loss: 0.02903202921152115
epoch 59100  clean testing loss: 0.0700782909989357
epoch 59200  training loss: 0.029027586802840233
epoch 59200  clean testing loss: 0.07005264610052109
epoch 59300  training loss: 0.02901751920580864
epoch 59300  clean testing loss: 0.07014654576778412
epoch 59400  training loss: 0.029019270092248917

 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 59857/100000 [05:06<02:45, 242.58it/s]
epoch 59500  training loss: 0.029012855142354965
epoch 59500  clean testing loss: 0.07014602422714233
epoch 59600  training loss: 0.028998693451285362
epoch 59600  clean testing loss: 0.07014548778533936
epoch 59700  training loss: 0.029003819450736046
epoch 59700  clean testing loss: 0.07008595764636993
epoch 59800  training loss: 0.02900850586593151

 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 60338/100000 [05:08<02:44, 240.61it/s]
epoch 59900  training loss: 0.028994524851441383
epoch 59900  clean testing loss: 0.07013098150491714
epoch 60000  training loss: 0.02898297645151615
epoch 60000  clean testing loss: 0.07018553465604782
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 60100  training loss: 0.028965512290596962
epoch 60100  clean testing loss: 0.07022304832935333
epoch 60200  training loss: 0.02895374782383442
epoch 60200  clean testing loss: 0.07025888562202454
epoch 60300  training loss: 0.028950437903404236

 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 60821/100000 [05:10<02:42, 240.39it/s]
epoch 60400  training loss: 0.028969883918762207
epoch 60400  clean testing loss: 0.07025311887264252
epoch 60500  training loss: 0.028946684673428535
epoch 60500  clean testing loss: 0.07030556350946426
epoch 60600  training loss: 0.02893914468586445
epoch 60600  clean testing loss: 0.07025124877691269
epoch 60700  training loss: 0.02893281728029251
epoch 60700  clean testing loss: 0.0703103244304657
epoch 60800  training loss: 0.028943201526999474

 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 61302/100000 [05:12<02:39, 242.72it/s]
epoch 60900  training loss: 0.028931915760040283
epoch 60900  clean testing loss: 0.07027626782655716
epoch 61000  training loss: 0.028912294656038284
epoch 61000  clean testing loss: 0.07037489861249924
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 61100  training loss: 0.028907375410199165
epoch 61100  clean testing loss: 0.07036411762237549
epoch 61200  training loss: 0.02890186384320259
epoch 61200  clean testing loss: 0.07044278830289841
epoch 61300  training loss: 0.028889937326312065

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 61809/100000 [05:14<02:37, 243.10it/s]
epoch 61400  training loss: 0.028885873034596443
epoch 61400  clean testing loss: 0.07045729458332062
epoch 61500  training loss: 0.028882760554552078
epoch 61500  clean testing loss: 0.07045787572860718
epoch 61600  training loss: 0.028870945796370506
epoch 61600  clean testing loss: 0.07041670382022858
epoch 61700  training loss: 0.02887362614274025
epoch 61700  clean testing loss: 0.07050132006406784
epoch 61800  training loss: 0.028857702389359474

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 62289/100000 [05:16<02:37, 240.04it/s]
epoch 61900  training loss: 0.02885591983795166
epoch 61900  clean testing loss: 0.07050711661577225
epoch 62000  training loss: 0.02885046787559986
epoch 62000  clean testing loss: 0.07046366482973099
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 62100  training loss: 0.028844892978668213
epoch 62100  clean testing loss: 0.07047773152589798
epoch 62200  training loss: 0.02883964218199253
epoch 62200  clean testing loss: 0.07053676247596741
epoch 62300  training loss: 0.028829336166381836

 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 62765/100000 [05:18<02:32, 244.03it/s]
epoch 62400  training loss: 0.028816914185881615
epoch 62400  clean testing loss: 0.07057572901248932
epoch 62500  training loss: 0.028815165162086487
epoch 62500  clean testing loss: 0.07059958577156067
epoch 62600  training loss: 0.028807690367102623
epoch 62600  clean testing loss: 0.07054561376571655
epoch 62700  training loss: 0.0288042351603508

 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 63243/100000 [05:20<02:32, 241.77it/s]
epoch 62800  training loss: 0.028801007196307182
epoch 62800  clean testing loss: 0.07068237662315369
epoch 62900  training loss: 0.028794147074222565
epoch 62900  clean testing loss: 0.07061919569969177
epoch 63000  training loss: 0.028785550966858864
epoch 63000  clean testing loss: 0.0706440731883049
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 63100  training loss: 0.028783520683646202
epoch 63100  clean testing loss: 0.07067502290010452
epoch 63200  training loss: 0.028768762946128845

 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 63747/100000 [05:22<02:29, 242.20it/s]
epoch 63300  training loss: 0.028759565204381943
epoch 63300  clean testing loss: 0.07074809819459915
epoch 63400  training loss: 0.028761114925146103
epoch 63400  clean testing loss: 0.07065179944038391
epoch 63500  training loss: 0.028749773278832436
epoch 63500  clean testing loss: 0.07077186554670334
epoch 63600  training loss: 0.028754116967320442
epoch 63600  clean testing loss: 0.07073144614696503
epoch 63700  training loss: 0.02874155528843403

 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 64227/100000 [05:24<02:26, 244.93it/s]
epoch 63800  training loss: 0.02874353714287281
epoch 63800  clean testing loss: 0.07080265879631042
epoch 63900  training loss: 0.02872573211789131
epoch 63900  clean testing loss: 0.07078787684440613
epoch 64000  training loss: 0.028727715834975243
epoch 64000  clean testing loss: 0.070790134370327
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 64100  training loss: 0.028719883412122726
epoch 64100  clean testing loss: 0.07083907723426819
epoch 64200  training loss: 0.02870703861117363

 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 64786/100000 [05:26<02:08, 274.02it/s]
epoch 64300  training loss: 0.028706789016723633
epoch 64300  clean testing loss: 0.07090747356414795
epoch 64400  training loss: 0.028697729110717773
epoch 64400  clean testing loss: 0.07086401432752609
epoch 64500  training loss: 0.028697729110717773
epoch 64500  clean testing loss: 0.07099513709545135
epoch 64600  training loss: 0.0286872461438179
epoch 64600  clean testing loss: 0.07091739773750305
epoch 64700  training loss: 0.0286933034658432
epoch 64700  clean testing loss: 0.07094842940568924
epoch 64800  training loss: 0.028679845854640007

 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 65323/100000 [05:28<02:05, 276.16it/s]
epoch 64900  training loss: 0.028668230399489403
epoch 64900  clean testing loss: 0.07096823304891586
epoch 65000  training loss: 0.028665825724601746
epoch 65000  clean testing loss: 0.07090138643980026
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 65100  training loss: 0.02865668758749962
epoch 65100  clean testing loss: 0.07100453972816467
epoch 65200  training loss: 0.028675563633441925
epoch 65200  clean testing loss: 0.07093005627393723
epoch 65300  training loss: 0.028648342937231064

 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 65856/100000 [05:30<02:07, 267.57it/s]
epoch 65400  training loss: 0.028644884005188942
epoch 65400  clean testing loss: 0.07100529968738556
epoch 65500  training loss: 0.028644567355513573
epoch 65500  clean testing loss: 0.07102839648723602
epoch 65600  training loss: 0.028641950339078903
epoch 65600  clean testing loss: 0.07106609642505646
epoch 65700  training loss: 0.028630293905735016
epoch 65700  clean testing loss: 0.07105084508657455
epoch 65800  training loss: 0.02863314002752304

 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 66420/100000 [05:32<02:01, 275.59it/s]
epoch 65900  training loss: 0.02861758880317211
epoch 65900  clean testing loss: 0.07107395678758621
epoch 66000  training loss: 0.02861296758055687
epoch 66000  clean testing loss: 0.07117367535829544
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 66100  training loss: 0.028605084866285324
epoch 66100  clean testing loss: 0.07120794802904129
epoch 66200  training loss: 0.028600385412573814
epoch 66200  clean testing loss: 0.07117959856987
epoch 66300  training loss: 0.028596192598342896
epoch 66300  clean testing loss: 0.07117781043052673
epoch 66400  training loss: 0.02859080582857132

 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 66956/100000 [05:34<02:01, 271.32it/s]
epoch 66500  training loss: 0.028592413291335106
epoch 66500  clean testing loss: 0.07125161588191986
epoch 66600  training loss: 0.028582870960235596
epoch 66600  clean testing loss: 0.07123293727636337
epoch 66700  training loss: 0.028586840257048607
epoch 66700  clean testing loss: 0.07122081518173218
epoch 66800  training loss: 0.02857796661555767
epoch 66800  clean testing loss: 0.0712241381406784
epoch 66900  training loss: 0.02857031114399433

 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 67516/100000 [05:36<01:58, 272.98it/s]
epoch 67000  training loss: 0.02857077866792679
epoch 67000  clean testing loss: 0.07127851992845535
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 67100  training loss: 0.028563128784298897
epoch 67100  clean testing loss: 0.07129635661840439
epoch 67200  training loss: 0.02855689823627472
epoch 67200  clean testing loss: 0.07132378220558167
epoch 67300  training loss: 0.028556188568472862
epoch 67300  clean testing loss: 0.07136654108762741
epoch 67400  training loss: 0.028553372249007225
epoch 67400  clean testing loss: 0.07133142650127411
epoch 67500  training loss: 0.028546536341309547

 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 68051/100000 [05:38<01:58, 269.33it/s]
epoch 67600  training loss: 0.028544850647449493
epoch 67600  clean testing loss: 0.0713961198925972
epoch 67700  training loss: 0.02854103222489357
epoch 67700  clean testing loss: 0.0714360699057579
epoch 67800  training loss: 0.028537534177303314
epoch 67800  clean testing loss: 0.07137569040060043
epoch 67900  training loss: 0.028530677780508995
epoch 67900  clean testing loss: 0.07143356651067734
epoch 68000  training loss: 0.02852282114326954
epoch 68000  clean testing loss: 0.07143881916999817

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 68612/100000 [05:40<01:55, 271.98it/s]
epoch 68100  training loss: 0.02851766347885132
epoch 68100  clean testing loss: 0.07149088382720947
epoch 68200  training loss: 0.02851446159183979
epoch 68200  clean testing loss: 0.07149713486433029
epoch 68300  training loss: 0.028510011732578278
epoch 68300  clean testing loss: 0.07149908691644669
epoch 68400  training loss: 0.028503013774752617
epoch 68400  clean testing loss: 0.07152505964040756
epoch 68500  training loss: 0.028495466336607933
epoch 68500  clean testing loss: 0.07149311900138855
epoch 68600  training loss: 0.02849443629384041

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 69148/100000 [05:42<01:53, 271.76it/s]
epoch 68700  training loss: 0.02849414572119713
epoch 68700  clean testing loss: 0.0715111717581749
epoch 68800  training loss: 0.028488168492913246
epoch 68800  clean testing loss: 0.07156036794185638
epoch 68900  training loss: 0.028488416224718094
epoch 68900  clean testing loss: 0.07155773043632507
epoch 69000  training loss: 0.028471747413277626
epoch 69000  clean testing loss: 0.07156268507242203
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 69100  training loss: 0.028467249125242233

 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 69711/100000 [05:44<01:49, 275.77it/s]
epoch 69200  training loss: 0.028464283794164658
epoch 69200  clean testing loss: 0.07157626748085022
epoch 69300  training loss: 0.02846243791282177
epoch 69300  clean testing loss: 0.07161935418844223
epoch 69400  training loss: 0.028454579412937164
epoch 69400  clean testing loss: 0.07161939889192581
epoch 69500  training loss: 0.02845095843076706
epoch 69500  clean testing loss: 0.07166966050863266
epoch 69600  training loss: 0.028446216136217117
epoch 69600  clean testing loss: 0.07167571038007736
epoch 69700  training loss: 0.028442850336432457

 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 70246/100000 [05:46<01:48, 275.00it/s]
epoch 69800  training loss: 0.028440820053219795
epoch 69800  clean testing loss: 0.07165222615003586
epoch 69900  training loss: 0.028438584879040718
epoch 69900  clean testing loss: 0.07162254303693771
epoch 70000  training loss: 0.028432827442884445
epoch 70000  clean testing loss: 0.07165510952472687
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 70100  training loss: 0.02843114733695984
epoch 70100  clean testing loss: 0.07170413434505463
epoch 70200  training loss: 0.028421208262443542

 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 70810/100000 [05:48<01:46, 274.44it/s]
epoch 70300  training loss: 0.028417788445949554
epoch 70300  clean testing loss: 0.07170398533344269
epoch 70400  training loss: 0.028413623571395874
epoch 70400  clean testing loss: 0.07176149636507034
epoch 70500  training loss: 0.02841191180050373
epoch 70500  clean testing loss: 0.07166339457035065
epoch 70600  training loss: 0.02840559557080269
epoch 70600  clean testing loss: 0.07173207402229309
epoch 70700  training loss: 0.02840559184551239
epoch 70700  clean testing loss: 0.07175043225288391
epoch 70800  training loss: 0.028401752933859825

 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 71347/100000 [05:50<01:45, 272.81it/s]
epoch 70900  training loss: 0.028395432978868484
epoch 70900  clean testing loss: 0.07179724425077438
epoch 71000  training loss: 0.02839569002389908
epoch 71000  clean testing loss: 0.07181096822023392
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 71100  training loss: 0.02838929556310177
epoch 71100  clean testing loss: 0.07178907841444016
epoch 71200  training loss: 0.0283831637352705
epoch 71200  clean testing loss: 0.07179959863424301
epoch 71300  training loss: 0.028379911556839943

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 71911/100000 [05:52<01:42, 275.35it/s]
epoch 71400  training loss: 0.028374556452035904
epoch 71400  clean testing loss: 0.07188853621482849
epoch 71500  training loss: 0.0283689945936203
epoch 71500  clean testing loss: 0.07185527682304382
epoch 71600  training loss: 0.0283706896007061
epoch 71600  clean testing loss: 0.07183463126420975
epoch 71700  training loss: 0.028373071923851967
epoch 71700  clean testing loss: 0.07185469567775726
epoch 71800  training loss: 0.028357641771435738
epoch 71800  clean testing loss: 0.07187244296073914
epoch 71900  training loss: 0.02835555374622345

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 72446/100000 [05:54<01:40, 272.96it/s]
epoch 72000  training loss: 0.028350312262773514
epoch 72000  clean testing loss: 0.0719468891620636
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 72100  training loss: 0.02834441512823105
epoch 72100  clean testing loss: 0.0719340592622757
epoch 72200  training loss: 0.028342220932245255
epoch 72200  clean testing loss: 0.07194284349679947
epoch 72300  training loss: 0.02833770588040352
epoch 72300  clean testing loss: 0.07195303589105606
epoch 72400  training loss: 0.028332872316241264

 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 73012/100000 [05:56<01:39, 272.60it/s]
epoch 72500  training loss: 0.028332902118563652
epoch 72500  clean testing loss: 0.07195670157670975
epoch 72600  training loss: 0.02832973003387451
epoch 72600  clean testing loss: 0.07200847566127777
epoch 72700  training loss: 0.028323296457529068
epoch 72700  clean testing loss: 0.07200894504785538
epoch 72800  training loss: 0.028320930898189545
epoch 72800  clean testing loss: 0.07203874737024307
epoch 72900  training loss: 0.0283169224858284
epoch 72900  clean testing loss: 0.07206329703330994
epoch 73000  training loss: 0.028317155316472054
epoch 73000  clean testing loss: 0.0720948800444603

 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 73549/100000 [05:58<01:36, 273.52it/s]
epoch 73100  training loss: 0.028314687311649323
epoch 73100  clean testing loss: 0.07209989428520203
epoch 73200  training loss: 0.028308453038334846
epoch 73200  clean testing loss: 0.07212300598621368
epoch 73300  training loss: 0.028310414403676987
epoch 73300  clean testing loss: 0.07217077910900116
epoch 73400  training loss: 0.028300771489739418
epoch 73400  clean testing loss: 0.07214141637086868
epoch 73500  training loss: 0.028296975418925285

 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 74113/100000 [06:00<01:34, 272.52it/s]
epoch 73600  training loss: 0.028296001255512238
epoch 73600  clean testing loss: 0.07217791676521301
epoch 73700  training loss: 0.028288399800658226
epoch 73700  clean testing loss: 0.07219921052455902
epoch 73800  training loss: 0.0282880999147892
epoch 73800  clean testing loss: 0.07221388816833496
epoch 73900  training loss: 0.028281906619668007
epoch 73900  clean testing loss: 0.0722067728638649
epoch 74000  training loss: 0.02827569656074047
epoch 74000  clean testing loss: 0.0722380131483078
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 74100  training loss: 0.028277544304728508

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 74649/100000 [06:02<01:32, 274.10it/s]
epoch 74200  training loss: 0.028270794078707695
epoch 74200  clean testing loss: 0.07225891947746277
epoch 74300  training loss: 0.028266603127121925
epoch 74300  clean testing loss: 0.07226741313934326
epoch 74400  training loss: 0.028262104839086533
epoch 74400  clean testing loss: 0.07230337709188461
epoch 74500  training loss: 0.028262943029403687
epoch 74500  clean testing loss: 0.07228346168994904
epoch 74600  training loss: 0.02825758419930935

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 75212/100000 [06:04<01:30, 274.53it/s]
epoch 74700  training loss: 0.028255533427000046
epoch 74700  clean testing loss: 0.0723152831196785
epoch 74800  training loss: 0.028251348063349724
epoch 74800  clean testing loss: 0.07231017202138901
epoch 74900  training loss: 0.02824600413441658
epoch 74900  clean testing loss: 0.07234552502632141
epoch 75000  training loss: 0.028241906315088272
epoch 75000  clean testing loss: 0.0723496600985527
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 75100  training loss: 0.028239477425813675
epoch 75100  clean testing loss: 0.07232451438903809
epoch 75200  training loss: 0.02823709137737751

 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 75749/100000 [06:06<01:28, 274.06it/s]
epoch 75300  training loss: 0.028233442455530167
epoch 75300  clean testing loss: 0.0724044069647789
epoch 75400  training loss: 0.028231874108314514
epoch 75400  clean testing loss: 0.07238348573446274
epoch 75500  training loss: 0.028229599818587303
epoch 75500  clean testing loss: 0.07238627970218658
epoch 75600  training loss: 0.02822411246597767
epoch 75600  clean testing loss: 0.07241696864366531
epoch 75700  training loss: 0.028226720169186592

 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 76314/100000 [06:08<01:25, 277.16it/s]
epoch 75800  training loss: 0.02821720950305462
epoch 75800  clean testing loss: 0.07241110503673553
epoch 75900  training loss: 0.02821536734700203
epoch 75900  clean testing loss: 0.07242295891046524
epoch 76000  training loss: 0.02821170538663864
epoch 76000  clean testing loss: 0.0724099799990654
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 76100  training loss: 0.02821037918329239
epoch 76100  clean testing loss: 0.07239793986082077
epoch 76200  training loss: 0.028210410848259926
epoch 76200  clean testing loss: 0.07243193686008453
epoch 76300  training loss: 0.028206510469317436

 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 76850/100000 [06:10<01:25, 271.25it/s]
epoch 76400  training loss: 0.02820102870464325
epoch 76400  clean testing loss: 0.07246286422014236
epoch 76500  training loss: 0.028198271989822388
epoch 76500  clean testing loss: 0.07242365926504135
epoch 76600  training loss: 0.028196878731250763
epoch 76600  clean testing loss: 0.07246637344360352
epoch 76700  training loss: 0.02819402515888214
epoch 76700  clean testing loss: 0.07245564460754395
epoch 76800  training loss: 0.028188759461045265

 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 77414/100000 [06:12<01:23, 271.48it/s]
epoch 76900  training loss: 0.0281845536082983
epoch 76900  clean testing loss: 0.07248744368553162
epoch 77000  training loss: 0.028182389214634895
epoch 77000  clean testing loss: 0.07250216603279114
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 77100  training loss: 0.028177129104733467
epoch 77100  clean testing loss: 0.0725189819931984
epoch 77200  training loss: 0.028175022453069687
epoch 77200  clean testing loss: 0.07253334671258926
epoch 77300  training loss: 0.028175340965390205
epoch 77300  clean testing loss: 0.07252972573041916
epoch 77400  training loss: 0.028169935569167137

 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 77948/100000 [06:14<01:21, 271.49it/s]
epoch 77500  training loss: 0.02816774882376194
epoch 77500  clean testing loss: 0.07256601750850677
epoch 77600  training loss: 0.0281640887260437
epoch 77600  clean testing loss: 0.07256215065717697
epoch 77700  training loss: 0.028160247951745987
epoch 77700  clean testing loss: 0.07254204154014587
epoch 77800  training loss: 0.02815973572432995
epoch 77800  clean testing loss: 0.07256481051445007
epoch 77900  training loss: 0.02815198339521885

 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 78517/100000 [06:16<01:17, 277.42it/s]
epoch 78000  training loss: 0.02815493568778038
epoch 78000  clean testing loss: 0.07255120575428009
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 78100  training loss: 0.028147095814347267
epoch 78100  clean testing loss: 0.07257174700498581
epoch 78200  training loss: 0.02814425714313984
epoch 78200  clean testing loss: 0.0726155936717987
epoch 78300  training loss: 0.028143106028437614
epoch 78300  clean testing loss: 0.07258523255586624
epoch 78400  training loss: 0.028140094131231308
epoch 78400  clean testing loss: 0.07258974015712738
epoch 78500  training loss: 0.02813873067498207

 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 79052/100000 [06:18<01:17, 270.77it/s]
epoch 78600  training loss: 0.028133070096373558
epoch 78600  clean testing loss: 0.07261421531438828
epoch 78700  training loss: 0.028132328763604164
epoch 78700  clean testing loss: 0.07259944081306458
epoch 78800  training loss: 0.02812863141298294
epoch 78800  clean testing loss: 0.07263015955686569
epoch 78900  training loss: 0.028126681223511696
epoch 78900  clean testing loss: 0.07263914495706558
epoch 79000  training loss: 0.028122831135988235
epoch 79000  clean testing loss: 0.07264503836631775

 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 79615/100000 [06:20<01:15, 271.31it/s]
epoch 79100  training loss: 0.02812366932630539
epoch 79100  clean testing loss: 0.07262440770864487
epoch 79200  training loss: 0.028118794783949852
epoch 79200  clean testing loss: 0.07264695316553116
epoch 79300  training loss: 0.02811514586210251
epoch 79300  clean testing loss: 0.07264135032892227
epoch 79400  training loss: 0.02811506763100624
epoch 79400  clean testing loss: 0.0726511999964714
epoch 79500  training loss: 0.02811550721526146
epoch 79500  clean testing loss: 0.07264979928731918
epoch 79600  training loss: 0.028106942772865295

 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 80151/100000 [06:22<01:12, 272.66it/s]
epoch 79700  training loss: 0.028107887133955956
epoch 79700  clean testing loss: 0.07268878817558289
epoch 79800  training loss: 0.02810269221663475
epoch 79800  clean testing loss: 0.07270361483097076
epoch 79900  training loss: 0.028100356459617615
epoch 79900  clean testing loss: 0.0726931169629097
epoch 80000  training loss: 0.02809719741344452
epoch 80000  clean testing loss: 0.07271359860897064
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 80100  training loss: 0.028093792498111725

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 80716/100000 [06:24<01:10, 271.91it/s]
epoch 80200  training loss: 0.028091229498386383
epoch 80200  clean testing loss: 0.07275304198265076
epoch 80300  training loss: 0.028089135885238647
epoch 80300  clean testing loss: 0.07274429500102997
epoch 80400  training loss: 0.028089184314012527
epoch 80400  clean testing loss: 0.07271824777126312
epoch 80500  training loss: 0.028084630146622658
epoch 80500  clean testing loss: 0.07274466753005981
epoch 80600  training loss: 0.02808116376399994
epoch 80600  clean testing loss: 0.07272423803806305
epoch 80700  training loss: 0.02807883732020855

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 81252/100000 [06:26<01:07, 276.32it/s]
epoch 80800  training loss: 0.02807578444480896
epoch 80800  clean testing loss: 0.07273735851049423
epoch 80900  training loss: 0.028073567897081375
epoch 80900  clean testing loss: 0.07273926585912704
epoch 81000  training loss: 0.028071286156773567
epoch 81000  clean testing loss: 0.07276034355163574
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 81100  training loss: 0.028067713603377342
epoch 81100  clean testing loss: 0.0727609246969223
epoch 81200  training loss: 0.02806665189564228

 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 81792/100000 [06:28<01:05, 278.29it/s]
epoch 81300  training loss: 0.02806340903043747
epoch 81300  clean testing loss: 0.07276715338230133
epoch 81400  training loss: 0.02806052379310131
epoch 81400  clean testing loss: 0.07276410609483719
epoch 81500  training loss: 0.02805866114795208
epoch 81500  clean testing loss: 0.07277911901473999
epoch 81600  training loss: 0.02805790863931179
epoch 81600  clean testing loss: 0.07279101014137268
epoch 81700  training loss: 0.028053859248757362
epoch 81700  clean testing loss: 0.07279123365879059
epoch 81800  training loss: 0.028051229193806648

 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 82358/100000 [06:30<01:04, 275.63it/s]
epoch 81900  training loss: 0.02804894745349884
epoch 81900  clean testing loss: 0.07282142341136932
epoch 82000  training loss: 0.02804631181061268
epoch 82000  clean testing loss: 0.07281123846769333
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 82100  training loss: 0.02804672159254551
epoch 82100  clean testing loss: 0.07282689958810806
epoch 82200  training loss: 0.028041748329997063
epoch 82200  clean testing loss: 0.0728272870182991
epoch 82300  training loss: 0.0280421432107687

 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 82922/100000 [06:32<01:02, 273.81it/s]
epoch 82400  training loss: 0.028037549927830696
epoch 82400  clean testing loss: 0.07282248884439468
epoch 82500  training loss: 0.028035011142492294
epoch 82500  clean testing loss: 0.07286743074655533
epoch 82600  training loss: 0.028034070506691933
epoch 82600  clean testing loss: 0.07285547256469727
epoch 82700  training loss: 0.02803034521639347
epoch 82700  clean testing loss: 0.07284504920244217
epoch 82800  training loss: 0.02802889235317707
epoch 82800  clean testing loss: 0.07285688072443008
epoch 82900  training loss: 0.028028244152665138

 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 83459/100000 [06:34<01:00, 274.59it/s]
epoch 83000  training loss: 0.028025846928358078
epoch 83000  clean testing loss: 0.07287964224815369
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 83100  training loss: 0.028020242229104042
epoch 83100  clean testing loss: 0.072884701192379
epoch 83200  training loss: 0.028018895536661148
epoch 83200  clean testing loss: 0.07287859916687012
epoch 83300  training loss: 0.02801663428544998
epoch 83300  clean testing loss: 0.07288502901792526
epoch 83400  training loss: 0.028014160692691803

 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 84026/100000 [06:36<00:59, 269.41it/s]
epoch 83500  training loss: 0.028011176735162735
epoch 83500  clean testing loss: 0.07291920483112335
epoch 83600  training loss: 0.028009003028273582
epoch 83600  clean testing loss: 0.0729246586561203
epoch 83700  training loss: 0.02800666354596615
epoch 83700  clean testing loss: 0.07290533930063248
epoch 83800  training loss: 0.02800358459353447
epoch 83800  clean testing loss: 0.07291577756404877
epoch 83900  training loss: 0.0280012059956789
epoch 83900  clean testing loss: 0.07290622591972351
epoch 84000  training loss: 0.027999065816402435
epoch 84000  clean testing loss: 0.0729372426867485

 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 84561/100000 [06:38<00:55, 277.70it/s]
epoch 84100  training loss: 0.027996154502034187
epoch 84100  clean testing loss: 0.07294342666864395
epoch 84200  training loss: 0.027994433417916298
epoch 84200  clean testing loss: 0.07294659316539764
epoch 84300  training loss: 0.02799372375011444
epoch 84300  clean testing loss: 0.0729307308793068
epoch 84400  training loss: 0.027990171685814857
epoch 84400  clean testing loss: 0.07295789569616318
epoch 84500  training loss: 0.027988962829113007

 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 85071/100000 [06:40<01:01, 242.18it/s]
epoch 84600  training loss: 0.02798648364841938
epoch 84600  clean testing loss: 0.07296481728553772
epoch 84700  training loss: 0.0279845017939806
epoch 84700  clean testing loss: 0.07296515256166458
epoch 84800  training loss: 0.027983566746115685
epoch 84800  clean testing loss: 0.07296235859394073
epoch 84900  training loss: 0.0279824361205101
epoch 84900  clean testing loss: 0.07297636568546295
epoch 85000  training loss: 0.02797836810350418
epoch 85000  clean testing loss: 0.0729786828160286

 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 85553/100000 [06:42<00:59, 243.78it/s]
epoch 85100  training loss: 0.027978165075182915
epoch 85100  clean testing loss: 0.07297670841217041
epoch 85200  training loss: 0.027973731979727745
epoch 85200  clean testing loss: 0.07297026365995407
epoch 85300  training loss: 0.027972279116511345
epoch 85300  clean testing loss: 0.07300609350204468
epoch 85400  training loss: 0.027970898896455765
epoch 85400  clean testing loss: 0.07299830764532089
epoch 85500  training loss: 0.027968376874923706

 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 86062/100000 [06:44<00:57, 240.87it/s]
epoch 85600  training loss: 0.02796698734164238
epoch 85600  clean testing loss: 0.07300718873739243
epoch 85700  training loss: 0.02796364016830921
epoch 85700  clean testing loss: 0.07302780449390411
epoch 85800  training loss: 0.027961812913417816
epoch 85800  clean testing loss: 0.07300819456577301
epoch 85900  training loss: 0.027960345149040222
epoch 85900  clean testing loss: 0.07302892208099365
epoch 86000  training loss: 0.027958553284406662
epoch 86000  clean testing loss: 0.07302844524383545

 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 86536/100000 [06:46<00:56, 239.14it/s]
epoch 86100  training loss: 0.027954621240496635
epoch 86100  clean testing loss: 0.07304268330335617
epoch 86200  training loss: 0.02795323170721531
epoch 86200  clean testing loss: 0.07305363565683365
epoch 86300  training loss: 0.027952108532190323
epoch 86300  clean testing loss: 0.07305559515953064
epoch 86400  training loss: 0.027949102222919464
epoch 86400  clean testing loss: 0.07305651158094406
epoch 86500  training loss: 0.027947356924414635

 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 87011/100000 [06:48<00:54, 239.85it/s]
epoch 86600  training loss: 0.02794531360268593
epoch 86600  clean testing loss: 0.07307951897382736
epoch 86700  training loss: 0.02794390730559826
epoch 86700  clean testing loss: 0.0730738490819931
epoch 86800  training loss: 0.02794238179922104
epoch 86800  clean testing loss: 0.07307714968919754
epoch 86900  training loss: 0.027939753606915474
epoch 86900  clean testing loss: 0.07307860255241394
epoch 87000  training loss: 0.027938062325119972
epoch 87000  clean testing loss: 0.0730922743678093

 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 87493/100000 [06:50<00:51, 243.21it/s]
epoch 87100  training loss: 0.027935154736042023
epoch 87100  clean testing loss: 0.07308180630207062
epoch 87200  training loss: 0.027933891862630844
epoch 87200  clean testing loss: 0.073085255920887
epoch 87300  training loss: 0.02793247066438198
epoch 87300  clean testing loss: 0.07310215383768082
epoch 87400  training loss: 0.027931680902838707
epoch 87400  clean testing loss: 0.07309198379516602
epoch 87500  training loss: 0.02792847529053688

 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 87999/100000 [06:52<00:49, 242.68it/s]
epoch 87600  training loss: 0.027928011491894722
epoch 87600  clean testing loss: 0.07311564683914185
epoch 87700  training loss: 0.027925970032811165
epoch 87700  clean testing loss: 0.07311947643756866
epoch 87800  training loss: 0.027923759073019028
epoch 87800  clean testing loss: 0.07311639934778214
epoch 87900  training loss: 0.027924053370952606

 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 88482/100000 [06:54<00:47, 241.83it/s]
epoch 88000  training loss: 0.027920277789235115
epoch 88000  clean testing loss: 0.07314299792051315
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 88100  training loss: 0.02791948989033699
epoch 88100  clean testing loss: 0.07312684506177902
epoch 88200  training loss: 0.02791757695376873
epoch 88200  clean testing loss: 0.0731361135840416
epoch 88300  training loss: 0.02791495807468891
epoch 88300  clean testing loss: 0.0731486827135086
epoch 88400  training loss: 0.027913445606827736

 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 88965/100000 [06:56<00:46, 237.58it/s]
epoch 88500  training loss: 0.027911880984902382
epoch 88500  clean testing loss: 0.07317312806844711
epoch 88600  training loss: 0.027911052107810974
epoch 88600  clean testing loss: 0.07314611971378326
epoch 88700  training loss: 0.02790810912847519
epoch 88700  clean testing loss: 0.07315236330032349
epoch 88800  training loss: 0.027908286079764366
epoch 88800  clean testing loss: 0.07317081838846207
epoch 88900  training loss: 0.027904635295271873

 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 89442/100000 [06:58<00:44, 237.98it/s]
epoch 89000  training loss: 0.027902791276574135
epoch 89000  clean testing loss: 0.07318083196878433
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 89100  training loss: 0.02790210396051407
epoch 89100  clean testing loss: 0.07317496091127396
epoch 89200  training loss: 0.02789938449859619
epoch 89200  clean testing loss: 0.07317468523979187
epoch 89300  training loss: 0.02789720706641674
epoch 89300  clean testing loss: 0.07318280637264252
epoch 89400  training loss: 0.0278960932046175

 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 89923/100000 [07:00<00:40, 247.65it/s]
epoch 89500  training loss: 0.027894549071788788
epoch 89500  clean testing loss: 0.0732068419456482
epoch 89600  training loss: 0.027893362566828728
epoch 89600  clean testing loss: 0.07321254163980484
epoch 89700  training loss: 0.0278917383402586
epoch 89700  clean testing loss: 0.07319620996713638
epoch 89800  training loss: 0.027888493612408638
epoch 89800  clean testing loss: 0.0732230395078659
epoch 89900  training loss: 0.027887597680091858

 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 90430/100000 [07:02<00:39, 244.61it/s]
epoch 90000  training loss: 0.027885904535651207
epoch 90000  clean testing loss: 0.07322276383638382
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 90100  training loss: 0.027884064242243767
epoch 90100  clean testing loss: 0.07322180271148682
epoch 90200  training loss: 0.027882281690835953
epoch 90200  clean testing loss: 0.07323484122753143
epoch 90300  training loss: 0.02788073569536209
epoch 90300  clean testing loss: 0.07323715090751648
epoch 90400  training loss: 0.0278795026242733

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 90910/100000 [07:04<00:37, 241.50it/s]
epoch 90500  training loss: 0.0278778113424778
epoch 90500  clean testing loss: 0.07323790341615677
epoch 90600  training loss: 0.027876947075128555
epoch 90600  clean testing loss: 0.07324273884296417
epoch 90700  training loss: 0.02787669003009796
epoch 90700  clean testing loss: 0.0732446163892746
epoch 90800  training loss: 0.02787470817565918
epoch 90800  clean testing loss: 0.07325129956007004
epoch 90900  training loss: 0.027873747050762177

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 91391/100000 [07:06<00:35, 244.25it/s]
epoch 91000  training loss: 0.027870867401361465
epoch 91000  clean testing loss: 0.07325094938278198
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 91100  training loss: 0.027870653197169304
epoch 91100  clean testing loss: 0.07326547801494598
epoch 91200  training loss: 0.02786853164434433
epoch 91200  clean testing loss: 0.07325808703899384
epoch 91300  training loss: 0.0278669074177742

 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 91773/100000 [07:08<00:33, 244.26it/s]
epoch 91400  training loss: 0.02786511741578579
epoch 91400  clean testing loss: 0.07327605783939362
epoch 91500  training loss: 0.027863850817084312
epoch 91500  clean testing loss: 0.07328782975673676
epoch 91600  training loss: 0.027862226590514183
epoch 91600  clean testing loss: 0.07327194511890411
epoch 91700  training loss: 0.027862656861543655
epoch 91700  clean testing loss: 0.07328116148710251
epoch 91800  training loss: 0.027859875932335854

 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 92250/100000 [07:10<00:32, 238.85it/s]
epoch 91900  training loss: 0.027857458218932152
epoch 91900  clean testing loss: 0.07329213619232178
epoch 92000  training loss: 0.027856633067131042
epoch 92000  clean testing loss: 0.07329040765762329
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 92100  training loss: 0.02785474620759487
epoch 92100  clean testing loss: 0.07330095767974854
epoch 92200  training loss: 0.027853243052959442
epoch 92200  clean testing loss: 0.07330407947301865
epoch 92300  training loss: 0.027851637452840805

 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 92730/100000 [07:12<00:29, 244.14it/s]
epoch 92400  training loss: 0.027849948033690453
epoch 92400  clean testing loss: 0.07331676036119461
epoch 92500  training loss: 0.02784842997789383
epoch 92500  clean testing loss: 0.073325015604496
epoch 92600  training loss: 0.02784750610589981
epoch 92600  clean testing loss: 0.07332689315080643
epoch 92700  training loss: 0.02784588374197483
epoch 92700  clean testing loss: 0.0733242779970169
epoch 92800  training loss: 0.02784447930753231

 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 93211/100000 [07:14<00:28, 241.53it/s]
epoch 92900  training loss: 0.027843086048960686
epoch 92900  clean testing loss: 0.07333659380674362
epoch 93000  training loss: 0.02784145437180996
epoch 93000  clean testing loss: 0.07333442568778992
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 93100  training loss: 0.027839738875627518
epoch 93100  clean testing loss: 0.07334177196025848
epoch 93200  training loss: 0.027838800102472305
epoch 93200  clean testing loss: 0.07335028052330017
epoch 93300  training loss: 0.027837224304676056

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 93715/100000 [07:16<00:26, 238.15it/s]
epoch 93400  training loss: 0.027835873886942863
epoch 93400  clean testing loss: 0.07334969192743301
epoch 93500  training loss: 0.027835190296173096
epoch 93500  clean testing loss: 0.07335998862981796
epoch 93600  training loss: 0.02783353626728058
epoch 93600  clean testing loss: 0.07335629314184189
epoch 93700  training loss: 0.02783236652612686
epoch 93700  clean testing loss: 0.0733608677983284
epoch 93800  training loss: 0.027831323444843292

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 94190/100000 [07:18<00:24, 241.24it/s]
epoch 93900  training loss: 0.027830006554722786
epoch 93900  clean testing loss: 0.07336974889039993
epoch 94000  training loss: 0.027828874066472054
epoch 94000  clean testing loss: 0.07337352633476257
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 94100  training loss: 0.027827177196741104
epoch 94100  clean testing loss: 0.07337089627981186
epoch 94200  training loss: 0.027827393263578415

 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 94673/100000 [07:20<00:21, 245.82it/s]
epoch 94300  training loss: 0.02782434970140457
epoch 94300  clean testing loss: 0.07338713109493256
epoch 94400  training loss: 0.027823258191347122
epoch 94400  clean testing loss: 0.07338299602270126
epoch 94500  training loss: 0.027822410687804222
epoch 94500  clean testing loss: 0.07338469475507736
epoch 94600  training loss: 0.027820955961942673
epoch 94600  clean testing loss: 0.07338307797908783
epoch 94700  training loss: 0.027821321040391922

 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 95154/100000 [07:22<00:20, 241.18it/s]
epoch 94800  training loss: 0.02781820297241211
epoch 94800  clean testing loss: 0.0733962208032608
epoch 94900  training loss: 0.02781793661415577
epoch 94900  clean testing loss: 0.0734022706747055
epoch 95000  training loss: 0.02781648002564907
epoch 95000  clean testing loss: 0.07341301441192627
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 95100  training loss: 0.02781539224088192
epoch 95100  clean testing loss: 0.07341420650482178
epoch 95200  training loss: 0.027813881635665894

 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 95659/100000 [07:24<00:18, 239.62it/s]
epoch 95300  training loss: 0.027812160551548004
epoch 95300  clean testing loss: 0.07340866327285767
epoch 95400  training loss: 0.02781098708510399
epoch 95400  clean testing loss: 0.07340826094150543
epoch 95500  training loss: 0.02781013585627079
epoch 95500  clean testing loss: 0.07342664152383804
epoch 95600  training loss: 0.027808887884020805
epoch 95600  clean testing loss: 0.07342523336410522
epoch 95700  training loss: 0.027807019650936127

 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 96137/100000 [07:26<00:16, 241.21it/s]
epoch 95800  training loss: 0.02780606970191002
epoch 95800  clean testing loss: 0.07342788577079773
epoch 95900  training loss: 0.027805330231785774
epoch 95900  clean testing loss: 0.07344187796115875
epoch 96000  training loss: 0.027804410085082054
epoch 96000  clean testing loss: 0.0734383836388588
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 96100  training loss: 0.027802467346191406
epoch 96100  clean testing loss: 0.07344226539134979
epoch 96200  training loss: 0.027801435440778732

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 96616/100000 [07:28<00:13, 244.51it/s]
epoch 96300  training loss: 0.027800342068076134
epoch 96300  clean testing loss: 0.07344256341457367
epoch 96400  training loss: 0.027799073606729507
epoch 96400  clean testing loss: 0.07344509661197662
epoch 96500  training loss: 0.027798520401120186
epoch 96500  clean testing loss: 0.07345007359981537
epoch 96600  training loss: 0.027796991169452667
epoch 96600  clean testing loss: 0.07345698773860931
epoch 96700  training loss: 0.027796147391200066

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 97103/100000 [07:30<00:12, 239.05it/s]
epoch 96800  training loss: 0.02779584564268589
epoch 96800  clean testing loss: 0.07346068322658539
epoch 96900  training loss: 0.02779371477663517
epoch 96900  clean testing loss: 0.0734572485089302
epoch 97000  training loss: 0.027792854234576225
epoch 97000  clean testing loss: 0.07345970720052719
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 97100  training loss: 0.0277920663356781
epoch 97100  clean testing loss: 0.07345844060182571
epoch 97200  training loss: 0.02779104933142662

 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 97613/100000 [07:32<00:09, 250.21it/s]
epoch 97300  training loss: 0.027789682149887085
epoch 97300  clean testing loss: 0.07347065955400467
epoch 97400  training loss: 0.02778851054608822
epoch 97400  clean testing loss: 0.07347201555967331
epoch 97500  training loss: 0.027787718921899796
epoch 97500  clean testing loss: 0.07348142564296722
epoch 97600  training loss: 0.027786405757069588
epoch 97600  clean testing loss: 0.07348207384347916
epoch 97700  training loss: 0.027784917503595352

 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 98097/100000 [07:34<00:07, 242.66it/s]
epoch 97800  training loss: 0.02778233028948307
epoch 97800  clean testing loss: 0.07351694256067276
epoch 97900  training loss: 0.027780331671237946
epoch 97900  clean testing loss: 0.07353810220956802
epoch 98000  training loss: 0.02777937799692154
epoch 98000  clean testing loss: 0.07353188097476959
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 98100  training loss: 0.027777383103966713

 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 98579/100000 [07:36<00:05, 238.46it/s]
epoch 98200  training loss: 0.027775995433330536
epoch 98200  clean testing loss: 0.07352683693170547
epoch 98300  training loss: 0.027775555849075317
epoch 98300  clean testing loss: 0.07353633642196655
epoch 98400  training loss: 0.027773626148700714
epoch 98400  clean testing loss: 0.07353422045707703
epoch 98500  training loss: 0.027772465720772743
epoch 98500  clean testing loss: 0.07353486865758896
epoch 98600  training loss: 0.027771299704909325

 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 99058/100000 [07:38<00:03, 242.77it/s]
epoch 98700  training loss: 0.02777095139026642
epoch 98700  clean testing loss: 0.07355348765850067
epoch 98800  training loss: 0.027769094333052635
epoch 98800  clean testing loss: 0.07354701310396194
epoch 98900  training loss: 0.027767663821578026
epoch 98900  clean testing loss: 0.0735558420419693
epoch 99000  training loss: 0.027766678482294083
epoch 99000  clean testing loss: 0.07355038821697235
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 99100  training loss: 0.027765871956944466

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 99542/100000 [07:40<00:01, 241.17it/s]
epoch 99200  training loss: 0.027764882892370224
epoch 99200  clean testing loss: 0.07356241345405579
epoch 99300  training loss: 0.02776406519114971
epoch 99300  clean testing loss: 0.07355533540248871
epoch 99400  training loss: 0.02776407077908516
epoch 99400  clean testing loss: 0.07355724275112152
epoch 99500  training loss: 0.02776230312883854
epoch 99500  clean testing loss: 0.07355895638465881
epoch 99600  training loss: 0.027761321514844894
epoch 99600  clean testing loss: 0.07355905324220657
epoch 99700  training loss: 0.027760611847043037
epoch 99700  clean testing loss: 0.07356369495391846
epoch 99800  training loss: 0.027759552001953125
epoch 99800  clean testing loss: 0.07356592267751694
epoch 99900  training loss: 0.027758480980992317
epoch 99900  clean testing loss: 0.0735665038228035

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [07:42<00:00, 216.28it/s]