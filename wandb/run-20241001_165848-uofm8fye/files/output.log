
  1%|          | 678/100000 [00:01<03:11, 518.50it/s]
epoch 0  training loss: 0.5688302516937256
epoch 0  clean testing loss: 0.5450456738471985
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 100  training loss: 0.27331510186195374
epoch 100  clean testing loss: 0.34294387698173523
epoch 200  training loss: 0.07451749593019485
epoch 200  clean testing loss: 0.1562635600566864
epoch 300  training loss: 0.049104515463113785
epoch 300  clean testing loss: 0.15481500327587128
epoch 400  training loss: 0.029454750940203667
epoch 400  clean testing loss: 0.15650571882724762
epoch 500  training loss: 0.012216387316584587
epoch 500  clean testing loss: 0.17121413350105286
epoch 600  training loss: 0.002885121153667569
epoch 600  clean testing loss: 0.19341735541820526
epoch 700  training loss: 0.0008030841127038002

  2%|▏         | 1681/100000 [00:03<03:34, 457.77it/s]
epoch 800  training loss: 0.0005505327135324478
epoch 800  clean testing loss: 0.21281452476978302
epoch 900  training loss: 0.000501086178701371
epoch 900  clean testing loss: 0.21366380155086517
epoch 1000  training loss: 0.0004817760200239718
epoch 1000  clean testing loss: 0.21403451263904572
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 1100  training loss: 0.0004653721989598125
epoch 1100  clean testing loss: 0.21442990005016327
epoch 1200  training loss: 0.00044726961641572416
epoch 1200  clean testing loss: 0.21470136940479279
epoch 1300  training loss: 0.0004312732780817896
epoch 1300  clean testing loss: 0.21494393050670624
epoch 1400  training loss: 0.0004115512128919363
epoch 1400  clean testing loss: 0.21540232002735138
epoch 1500  training loss: 0.00039648363599553704
epoch 1500  clean testing loss: 0.21565376222133636
epoch 1600  training loss: 0.0003792266361415386
epoch 1600  clean testing loss: 0.21573959290981293
epoch 1700  training loss: 0.00036167126381769776

  3%|▎         | 2732/100000 [00:05<03:07, 519.04it/s]
epoch 1800  training loss: 0.00034880367456935346
epoch 1800  clean testing loss: 0.21639953553676605
epoch 1900  training loss: 0.0003371808852534741
epoch 1900  clean testing loss: 0.21649174392223358
epoch 2000  training loss: 0.0003204908571206033
epoch 2000  clean testing loss: 0.2171029895544052
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 2100  training loss: 0.0003138961910735816
epoch 2100  clean testing loss: 0.21728451550006866
epoch 2200  training loss: 0.00030071064247749746
epoch 2200  clean testing loss: 0.2174208164215088
epoch 2300  training loss: 0.0002883979759644717
epoch 2300  clean testing loss: 0.21760593354701996
epoch 2400  training loss: 0.0002756076864898205
epoch 2400  clean testing loss: 0.21784400939941406
epoch 2500  training loss: 0.00026703800540417433
epoch 2500  clean testing loss: 0.2180738002061844
epoch 2600  training loss: 0.0002613972465042025
epoch 2600  clean testing loss: 0.21827368438243866
epoch 2700  training loss: 0.00025430062669329345
epoch 2700  clean testing loss: 0.21849751472473145
epoch 2800  training loss: 0.0002480941766407341

  3%|▎         | 2891/100000 [00:05<03:06, 520.37it/s]
epoch 2900  training loss: 0.00024399634276051074
epoch 2900  clean testing loss: 0.21878860890865326
epoch 3000  training loss: 0.00023607791808899492
epoch 3000  clean testing loss: 0.21905238926410675
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 3100  training loss: 0.00023076699289958924
epoch 3100  clean testing loss: 0.21926473081111908
epoch 3200  training loss: 0.00022558528871741146
epoch 3200  clean testing loss: 0.21953915059566498
epoch 3300  training loss: 0.00021924186148680747
epoch 3300  clean testing loss: 0.21990075707435608
epoch 3400  training loss: 0.00021656132594216615
epoch 3400  clean testing loss: 0.22028283774852753
epoch 3500  training loss: 0.00020796878379769623
epoch 3500  clean testing loss: 0.2203383892774582
epoch 3600  training loss: 0.00020720926113426685
epoch 3600  clean testing loss: 0.22061510384082794
epoch 3700  training loss: 0.00020519073586910963

  4%|▍         | 3944/100000 [00:09<03:07, 513.13it/s]
epoch 3800  training loss: 0.00020648077770601958
epoch 3800  clean testing loss: 0.2210816591978073
epoch 3900  training loss: 0.0001941736991284415
epoch 3900  clean testing loss: 0.22166447341442108
epoch 4000  training loss: 0.0001931687438627705
epoch 4000  clean testing loss: 0.22190570831298828
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 4100  training loss: 0.00019239878747612238
epoch 4100  clean testing loss: 0.22218100726604462
epoch 4200  training loss: 0.00018546405772212893
epoch 4200  clean testing loss: 0.2226666510105133
epoch 4300  training loss: 0.000182277406565845
epoch 4300  clean testing loss: 0.22289668023586273
epoch 4400  training loss: 0.00018056127009913325
epoch 4400  clean testing loss: 0.22308802604675293
epoch 4500  training loss: 0.00017826189287006855
epoch 4500  clean testing loss: 0.22331778705120087
epoch 4600  training loss: 0.00017318048048764467
epoch 4600  clean testing loss: 0.22386407852172852
epoch 4700  training loss: 0.00017652285168878734
epoch 4700  clean testing loss: 0.22432434558868408
epoch 4800  training loss: 0.00017743100761435926


  5%|▍         | 4895/100000 [00:11<03:02, 521.59it/s]
epoch 4900  training loss: 0.00017195162945427
epoch 4900  clean testing loss: 0.22523866593837738
epoch 5000  training loss: 0.0001643216673983261
epoch 5000  clean testing loss: 0.22503986954689026
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 5100  training loss: 0.00016064185183495283
epoch 5100  clean testing loss: 0.2255788892507553
epoch 5200  training loss: 0.00016752869123592973
epoch 5200  clean testing loss: 0.22596533596515656
epoch 5300  training loss: 0.00016238981334026903
epoch 5300  clean testing loss: 0.2262679636478424
epoch 5400  training loss: 0.00015589187387377024
epoch 5400  clean testing loss: 0.2265830785036087
epoch 5500  training loss: 0.00016059423796832561
epoch 5500  clean testing loss: 0.22618722915649414
epoch 5600  training loss: 0.0001553736365167424
epoch 5600  clean testing loss: 0.2264038622379303
epoch 5700  training loss: 0.00014787497639190406

  6%|▌         | 5948/100000 [00:21<03:07, 502.69it/s]
epoch 5800  training loss: 0.00014595799439121038
epoch 5800  clean testing loss: 0.22695671021938324
epoch 5900  training loss: 0.00014386011753231287
epoch 5900  clean testing loss: 0.22749173641204834
epoch 6000  training loss: 0.00014521623961627483
epoch 6000  clean testing loss: 0.22748947143554688
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 6100  training loss: 0.00014044747513253242
epoch 6100  clean testing loss: 0.2276332825422287
epoch 6200  training loss: 0.00013917763135395944
epoch 6200  clean testing loss: 0.22760026156902313
epoch 6300  training loss: 0.00013650556502398103
epoch 6300  clean testing loss: 0.22794535756111145
epoch 6400  training loss: 0.00013671029591932893
epoch 6400  clean testing loss: 0.2280711978673935
epoch 6500  training loss: 0.0001311294035986066
epoch 6500  clean testing loss: 0.22826437652111053
epoch 6600  training loss: 0.00012860851711593568
epoch 6600  clean testing loss: 0.22847715020179749
epoch 6700  training loss: 0.00012529442028608173

  7%|▋         | 6952/100000 [00:23<02:59, 518.12it/s]
epoch 6800  training loss: 0.00012744611012749374
epoch 6800  clean testing loss: 0.2284875214099884
epoch 6900  training loss: 0.00012267428974155337
epoch 6900  clean testing loss: 0.22867588698863983
epoch 7000  training loss: 0.00012673321180045605
epoch 7000  clean testing loss: 0.22917966544628143
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 7100  training loss: 0.00012162670464022085
epoch 7100  clean testing loss: 0.22943560779094696
epoch 7200  training loss: 0.00012202427024021745
epoch 7200  clean testing loss: 0.22912584245204926
epoch 7300  training loss: 0.00012228164996486157
epoch 7300  clean testing loss: 0.22952468693256378
epoch 7400  training loss: 0.00011718348105205223
epoch 7400  clean testing loss: 0.22977624833583832
epoch 7500  training loss: 0.00011740349145838991
epoch 7500  clean testing loss: 0.22956204414367676
epoch 7600  training loss: 0.00011778229236369953
epoch 7600  clean testing loss: 0.2299477905035019
epoch 7700  training loss: 0.00011953940702369437

  8%|▊         | 7939/100000 [00:25<02:59, 513.35it/s]
epoch 7800  training loss: 0.00011595904652494937
epoch 7800  clean testing loss: 0.23031572997570038
epoch 7900  training loss: 0.00011814754543593153
epoch 7900  clean testing loss: 0.2300765961408615
epoch 8000  training loss: 0.0001201999475597404
epoch 8000  clean testing loss: 0.23058198392391205
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 8100  training loss: 0.00011302600614726543
epoch 8100  clean testing loss: 0.23035717010498047
epoch 8200  training loss: 0.00011274062853772193
epoch 8200  clean testing loss: 0.23049259185791016
epoch 8300  training loss: 0.00011188913049409166
epoch 8300  clean testing loss: 0.23065629601478577
epoch 8400  training loss: 0.00010904038936132565
epoch 8400  clean testing loss: 0.23057310283184052
epoch 8500  training loss: 0.00010776017006719485
epoch 8500  clean testing loss: 0.23091550171375275
epoch 8600  training loss: 0.00010755292896647006
epoch 8600  clean testing loss: 0.23107777535915375
epoch 8700  training loss: 0.00011209144577151164
epoch 8700  clean testing loss: 0.23103876411914825

epoch 8800  training loss: 0.0001057930858223699
epoch 8800  clean testing loss: 0.23109249770641327
epoch 8900  training loss: 0.00010651012416929007
epoch 8900  clean testing loss: 0.23108266294002533
epoch 9000  training loss: 0.0001049490092555061
epoch 9000  clean testing loss: 0.2310987263917923
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 9100  training loss: 0.00010485785605851561
epoch 9100  clean testing loss: 0.23108983039855957
epoch 9200  training loss: 0.00010425928485346958
epoch 9200  clean testing loss: 0.23117323219776154
epoch 9300  training loss: 0.00010361622844357044
epoch 9300  clean testing loss: 0.23135316371917725
epoch 9400  training loss: 0.00010570804442977533
epoch 9400  clean testing loss: 0.23117689788341522
epoch 9500  training loss: 0.00010274395026499406
epoch 9500  clean testing loss: 0.23128078877925873
epoch 9600  training loss: 0.00010229317558696494
epoch 9600  clean testing loss: 0.23134921491146088
epoch 9700  training loss: 0.00010196677612839267
epoch 9700  clean testing loss: 0.23126254975795746
epoch 9800  training loss: 0.00010194720380241051

 10%|▉         | 9991/100000 [00:29<02:52, 521.94it/s]
epoch 9900  training loss: 0.00010091250442201272
epoch 9900  clean testing loss: 0.23141930997371674
epoch 10000  training loss: 0.00010033931903308257
epoch 10000  clean testing loss: 0.23149745166301727
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 10100  training loss: 0.00010506354738026857
epoch 10100  clean testing loss: 0.23159673810005188
epoch 10200  training loss: 9.933323599398136e-05
epoch 10200  clean testing loss: 0.23144178092479706
epoch 10300  training loss: 0.00010181638936046511
epoch 10300  clean testing loss: 0.2312745898962021
epoch 10400  training loss: 9.874859097180888e-05
epoch 10400  clean testing loss: 0.2315252274274826
epoch 10500  training loss: 9.852812218014151e-05
epoch 10500  clean testing loss: 0.23153458535671234
epoch 10600  training loss: 9.873353701550514e-05
epoch 10600  clean testing loss: 0.231700137257576
epoch 10700  training loss: 0.00010030715930042788

 11%|█         | 10675/100000 [00:30<02:51, 519.37it/s]
epoch 10800  training loss: 0.0001013733126455918
epoch 10800  clean testing loss: 0.23137132823467255
epoch 10900  training loss: 9.597550524631515e-05
epoch 10900  clean testing loss: 0.2316061556339264
epoch 11000  training loss: 9.544655767967924e-05
epoch 11000  clean testing loss: 0.23174472153186798
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 11100  training loss: 9.896055416902527e-05
epoch 11100  clean testing loss: 0.23142743110656738
epoch 11200  training loss: 9.545157081447542e-05
epoch 11200  clean testing loss: 0.23165655136108398
epoch 11300  training loss: 9.511587995802984e-05
epoch 11300  clean testing loss: 0.23187175393104553
epoch 11400  training loss: 9.699025395093486e-05
epoch 11400  clean testing loss: 0.2318476289510727
epoch 11500  training loss: 9.625001985114068e-05
epoch 11500  clean testing loss: 0.23173895478248596
epoch 11600  training loss: 9.301059617428109e-05

 12%|█▏        | 11837/100000 [00:37<03:00, 489.65it/s]
epoch 11700  training loss: 9.531993418931961e-05
epoch 11700  clean testing loss: 0.23169313371181488
epoch 11800  training loss: 9.407258039573207e-05
epoch 11800  clean testing loss: 0.23173613846302032
epoch 11900  training loss: 9.319328819401562e-05

 13%|█▎        | 12789/100000 [00:42<02:56, 495.43it/s]
epoch 12000  training loss: 9.192515426548198e-05
epoch 12000  clean testing loss: 0.2318878173828125
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 12100  training loss: 9.140819747699425e-05
epoch 12100  clean testing loss: 0.23181310296058655
epoch 12200  training loss: 9.196771861752495e-05
epoch 12200  clean testing loss: 0.23184216022491455
epoch 12300  training loss: 9.218903869623318e-05
epoch 12300  clean testing loss: 0.23188374936580658
epoch 12400  training loss: 9.043158206623048e-05
epoch 12400  clean testing loss: 0.23197272419929504
epoch 12500  training loss: 8.977772813523188e-05
epoch 12500  clean testing loss: 0.2320057451725006
epoch 12600  training loss: 8.932765194913372e-05
epoch 12600  clean testing loss: 0.2319948971271515
epoch 12700  training loss: 9.019219578476623e-05
epoch 12700  clean testing loss: 0.23199021816253662
epoch 12800  training loss: 8.902666013455018e-05

 14%|█▍        | 13793/100000 [00:44<02:44, 522.81it/s]
epoch 12900  training loss: 8.875584899215028e-05
epoch 12900  clean testing loss: 0.23228564858436584
epoch 13000  training loss: 8.881104440661147e-05
epoch 13000  clean testing loss: 0.2320929616689682
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 13100  training loss: 9.072294778889045e-05
epoch 13100  clean testing loss: 0.23232637345790863
epoch 13200  training loss: 8.735516166780144e-05
epoch 13200  clean testing loss: 0.2322433441877365
epoch 13300  training loss: 8.71306547196582e-05
epoch 13300  clean testing loss: 0.2322772592306137
epoch 13400  training loss: 8.71903685037978e-05
epoch 13400  clean testing loss: 0.23236651718616486
epoch 13500  training loss: 8.721325866645202e-05
epoch 13500  clean testing loss: 0.2325078248977661
epoch 13600  training loss: 8.898401574697345e-05
epoch 13600  clean testing loss: 0.23250353336334229
epoch 13700  training loss: 8.661190076963976e-05
epoch 13700  clean testing loss: 0.23238597810268402
epoch 13800  training loss: 8.574520325055346e-05

 15%|█▍        | 14584/100000 [00:45<02:44, 520.13it/s]
epoch 13900  training loss: 8.727639215067029e-05
epoch 13900  clean testing loss: 0.23235534131526947
epoch 14000  training loss: 8.832124149193987e-05
epoch 14000  clean testing loss: 0.23233698308467865
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 14100  training loss: 8.83226384758018e-05
epoch 14100  clean testing loss: 0.23238305747509003
epoch 14200  training loss: 8.604850881965831e-05
epoch 14200  clean testing loss: 0.23247483372688293
epoch 14300  training loss: 8.725497173145413e-05
epoch 14300  clean testing loss: 0.23257894814014435
epoch 14400  training loss: 8.470498869428411e-05
epoch 14400  clean testing loss: 0.2325655072927475
epoch 14500  training loss: 8.674821583554149e-05
epoch 14500  clean testing loss: 0.2325325310230255
epoch 14600  training loss: 8.549234189558774e-05

 15%|█▌        | 15100/100000 [00:46<04:22, 323.53it/s]
epoch 14700  training loss: 8.652588439872488e-05
epoch 14700  clean testing loss: 0.23277448117733002
epoch 14800  training loss: 8.506257290719077e-05
epoch 14800  clean testing loss: 0.23269212245941162
epoch 14900  training loss: 8.461825927952304e-05
epoch 14900  clean testing loss: 0.23271456360816956
epoch 15000  training loss: 8.348386472789571e-05
epoch 15000  clean testing loss: 0.23272235691547394
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...
epoch 15100  training loss: 8.350052667083219e-05
epoch 15100  clean testing loss: 0.23272311687469482
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size10_noise1.00e-01_invop0 ...