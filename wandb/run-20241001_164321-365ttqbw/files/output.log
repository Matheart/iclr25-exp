
  0%|          | 660/300000 [00:01<09:53, 504.36it/s]
epoch 0  training loss: 0.6041462421417236
epoch 0  clean testing loss: 0.48389357328414917
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 100  training loss: 0.24782602488994598
epoch 100  clean testing loss: 0.1357685923576355
epoch 200  training loss: 0.19569355249404907
epoch 200  clean testing loss: 0.09240736067295074
epoch 300  training loss: 0.18135035037994385
epoch 300  clean testing loss: 0.07816819846630096
epoch 400  training loss: 0.16650943458080292
epoch 400  clean testing loss: 0.06491663306951523
epoch 500  training loss: 0.15410012006759644
epoch 500  clean testing loss: 0.05631611868739128
epoch 600  training loss: 0.1457236111164093
epoch 600  clean testing loss: 0.05135456845164299
epoch 700  training loss: 0.1394653022289276

  0%|          | 1176/300000 [00:02<09:50, 505.78it/s]
epoch 800  training loss: 0.13413797318935394
epoch 800  clean testing loss: 0.045302968472242355
epoch 900  training loss: 0.12923534214496613
epoch 900  clean testing loss: 0.04227863997220993
epoch 1000  training loss: 0.12500862777233124
epoch 1000  clean testing loss: 0.040344323962926865
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 1100  training loss: 0.12153355777263641
epoch 1100  clean testing loss: 0.03928131237626076
epoch 1200  training loss: 0.11859317868947983

  0%|          | 1280/300000 [00:17<6:26:39, 12.88it/s]
epoch 1300  training loss: 0.11575539410114288

  1%|          | 2247/300000 [00:19<10:29, 472.83it/s]
epoch 1400  training loss: 0.11328854411840439
epoch 1400  clean testing loss: 0.035173699259757996
epoch 1500  training loss: 0.11118989437818527
epoch 1500  clean testing loss: 0.035321492701768875
epoch 1600  training loss: 0.10931805521249771
epoch 1600  clean testing loss: 0.03477391228079796
epoch 1700  training loss: 0.10774068534374237
epoch 1700  clean testing loss: 0.03380383551120758
epoch 1800  training loss: 0.10624609887599945
epoch 1800  clean testing loss: 0.03383605182170868
epoch 1900  training loss: 0.10495749861001968
epoch 1900  clean testing loss: 0.03354940935969353
epoch 2000  training loss: 0.10405808687210083
epoch 2000  clean testing loss: 0.0323740653693676
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 2100  training loss: 0.10286935418844223
epoch 2100  clean testing loss: 0.03283414617180824
epoch 2200  training loss: 0.10197721421718597
epoch 2200  clean testing loss: 0.03274034708738327
epoch 2300  training loss: 0.10126616060733795

  1%|          | 3224/300000 [00:21<09:51, 502.12it/s]
epoch 2400  training loss: 0.10044682770967484
epoch 2400  clean testing loss: 0.033299654722213745
epoch 2500  training loss: 0.0998869389295578
epoch 2500  clean testing loss: 0.032289810478687286
epoch 2600  training loss: 0.09904904663562775
epoch 2600  clean testing loss: 0.03262786194682121
epoch 2700  training loss: 0.09835582226514816
epoch 2700  clean testing loss: 0.033340997993946075
epoch 2800  training loss: 0.09776050597429276
epoch 2800  clean testing loss: 0.03203784301877022
epoch 2900  training loss: 0.0970969945192337
epoch 2900  clean testing loss: 0.03321358561515808
epoch 3000  training loss: 0.0965457335114479
epoch 3000  clean testing loss: 0.03233500197529793
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 3100  training loss: 0.09589354693889618
epoch 3100  clean testing loss: 0.032796017825603485
epoch 3200  training loss: 0.09532559663057327
epoch 3200  clean testing loss: 0.032888054847717285
epoch 3300  training loss: 0.09487834572792053

  1%|▏         | 4250/300000 [00:23<09:47, 503.66it/s]
epoch 3400  training loss: 0.09434898942708969
epoch 3400  clean testing loss: 0.03239136561751366
epoch 3500  training loss: 0.09384019672870636
epoch 3500  clean testing loss: 0.033409859985113144
epoch 3600  training loss: 0.0935526117682457
epoch 3600  clean testing loss: 0.03442541882395744
epoch 3700  training loss: 0.09296432882547379
epoch 3700  clean testing loss: 0.033642467111349106
epoch 3800  training loss: 0.0926089882850647
epoch 3800  clean testing loss: 0.03423169627785683
epoch 3900  training loss: 0.09226127713918686
epoch 3900  clean testing loss: 0.03271067142486572
epoch 4000  training loss: 0.0917997881770134
epoch 4000  clean testing loss: 0.03460335358977318
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 4100  training loss: 0.09127000719308853
epoch 4100  clean testing loss: 0.034347355365753174
epoch 4200  training loss: 0.09083903580904007
epoch 4200  clean testing loss: 0.03481685742735863
epoch 4300  training loss: 0.0904187485575676

  2%|▏         | 5278/300000 [00:25<09:40, 507.51it/s]
epoch 4400  training loss: 0.08984654396772385
epoch 4400  clean testing loss: 0.03430384770035744
epoch 4500  training loss: 0.08938416838645935
epoch 4500  clean testing loss: 0.034249577671289444
epoch 4600  training loss: 0.08901958912611008
epoch 4600  clean testing loss: 0.03360887989401817
epoch 4700  training loss: 0.0885869711637497
epoch 4700  clean testing loss: 0.03339589759707451
epoch 4800  training loss: 0.08798004686832428
epoch 4800  clean testing loss: 0.03385498374700546
epoch 4900  training loss: 0.08752548694610596
epoch 4900  clean testing loss: 0.03392493352293968
epoch 5000  training loss: 0.08705262094736099
epoch 5000  clean testing loss: 0.034093812108039856
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 5100  training loss: 0.08656901866197586
epoch 5100  clean testing loss: 0.03435434401035309
epoch 5200  training loss: 0.08619986474514008
epoch 5200  clean testing loss: 0.03422052785754204
epoch 5300  training loss: 0.08585337549448013

  2%|▏         | 6255/300000 [00:27<09:42, 504.29it/s]
epoch 5400  training loss: 0.08534630388021469
epoch 5400  clean testing loss: 0.03440036252140999
epoch 5500  training loss: 0.08470213413238525
epoch 5500  clean testing loss: 0.0353793203830719
epoch 5600  training loss: 0.08449957519769669
epoch 5600  clean testing loss: 0.03469257801771164
epoch 5700  training loss: 0.08391020447015762
epoch 5700  clean testing loss: 0.03528563678264618
epoch 5800  training loss: 0.0835919976234436
epoch 5800  clean testing loss: 0.034993093460798264
epoch 5900  training loss: 0.08316740393638611
epoch 5900  clean testing loss: 0.03516290336847305
epoch 6000  training loss: 0.08266441524028778
epoch 6000  clean testing loss: 0.03588259965181351
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 6100  training loss: 0.08218061923980713
epoch 6100  clean testing loss: 0.03649856895208359
epoch 6200  training loss: 0.08182220906019211
epoch 6200  clean testing loss: 0.03671211376786232
epoch 6300  training loss: 0.08151225745677948

  2%|▏         | 7284/300000 [00:29<09:39, 505.52it/s]
epoch 6400  training loss: 0.08121594786643982
epoch 6400  clean testing loss: 0.036233484745025635
epoch 6500  training loss: 0.08073003590106964
epoch 6500  clean testing loss: 0.037577927112579346
epoch 6600  training loss: 0.08048505336046219
epoch 6600  clean testing loss: 0.03808470442891121
epoch 6700  training loss: 0.080023393034935
epoch 6700  clean testing loss: 0.03724448010325432
epoch 6800  training loss: 0.07982204109430313
epoch 6800  clean testing loss: 0.03676677122712135
epoch 6900  training loss: 0.07954467087984085
epoch 6900  clean testing loss: 0.036902979016304016
epoch 7000  training loss: 0.07913405448198318
epoch 7000  clean testing loss: 0.03739846870303154
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 7100  training loss: 0.07887321710586548
epoch 7100  clean testing loss: 0.037337180227041245
epoch 7200  training loss: 0.0785178691148758
epoch 7200  clean testing loss: 0.03761627525091171
epoch 7300  training loss: 0.07812736928462982

  3%|▎         | 8262/300000 [00:31<09:36, 506.20it/s]
epoch 7400  training loss: 0.07777227461338043
epoch 7400  clean testing loss: 0.03897632658481598
epoch 7500  training loss: 0.07752880454063416
epoch 7500  clean testing loss: 0.03961465135216713
epoch 7600  training loss: 0.07717395573854446
epoch 7600  clean testing loss: 0.03942806273698807
epoch 7700  training loss: 0.07696884125471115
epoch 7700  clean testing loss: 0.040100354701280594
epoch 7800  training loss: 0.07657063752412796
epoch 7800  clean testing loss: 0.039583347737789154
epoch 7900  training loss: 0.07627875357866287
epoch 7900  clean testing loss: 0.040061142295598984
epoch 8000  training loss: 0.07591389864683151
epoch 8000  clean testing loss: 0.03940250352025032
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 8100  training loss: 0.07571671158075333
epoch 8100  clean testing loss: 0.03940112888813019
epoch 8200  training loss: 0.07544173300266266
epoch 8200  clean testing loss: 0.03958601504564285
epoch 8300  training loss: 0.07506140321493149

  3%|▎         | 9291/300000 [00:33<09:34, 505.83it/s]
epoch 8400  training loss: 0.07485968619585037
epoch 8400  clean testing loss: 0.04002800211310387
epoch 8500  training loss: 0.0745096206665039
epoch 8500  clean testing loss: 0.040649157017469406
epoch 8600  training loss: 0.0742739886045456
epoch 8600  clean testing loss: 0.04065245762467384
epoch 8700  training loss: 0.07399921119213104
epoch 8700  clean testing loss: 0.04107748717069626
epoch 8800  training loss: 0.073980912566185
epoch 8800  clean testing loss: 0.043089400976896286
epoch 8900  training loss: 0.07355067878961563
epoch 8900  clean testing loss: 0.04258584976196289
epoch 9000  training loss: 0.07342541217803955
epoch 9000  clean testing loss: 0.041439738124608994
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 9100  training loss: 0.07304989546537399
epoch 9100  clean testing loss: 0.04211951419711113
epoch 9200  training loss: 0.07285097241401672
epoch 9200  clean testing loss: 0.04224485903978348
epoch 9300  training loss: 0.07265620678663254

  3%|▎         | 10317/300000 [00:35<09:34, 504.15it/s]
epoch 9400  training loss: 0.07248062640428543
epoch 9400  clean testing loss: 0.043011121451854706
epoch 9500  training loss: 0.07221900671720505
epoch 9500  clean testing loss: 0.042710285633802414
epoch 9600  training loss: 0.07202304899692535
epoch 9600  clean testing loss: 0.04296096786856651
epoch 9700  training loss: 0.07183143496513367
epoch 9700  clean testing loss: 0.04337359219789505
epoch 9800  training loss: 0.07170191407203674
epoch 9800  clean testing loss: 0.04450678452849388
epoch 9900  training loss: 0.07141561061143875
epoch 9900  clean testing loss: 0.04422372579574585
epoch 10000  training loss: 0.07122450321912766
epoch 10000  clean testing loss: 0.044654481112957
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 10100  training loss: 0.07093307375907898
epoch 10100  clean testing loss: 0.044583361595869064
epoch 10200  training loss: 0.07073934376239777
epoch 10200  clean testing loss: 0.043639637529850006
epoch 10300  training loss: 0.070478156208992

  4%|▍         | 11295/300000 [00:37<09:30, 505.87it/s]
epoch 10400  training loss: 0.07038799673318863
epoch 10400  clean testing loss: 0.045442961156368256
epoch 10500  training loss: 0.07005991786718369
epoch 10500  clean testing loss: 0.04492354020476341
epoch 10600  training loss: 0.07006499916315079
epoch 10600  clean testing loss: 0.04380195215344429
epoch 10700  training loss: 0.06968653202056885
epoch 10700  clean testing loss: 0.04449724778532982
epoch 10800  training loss: 0.06964953243732452
epoch 10800  clean testing loss: 0.047134581953287125
epoch 10900  training loss: 0.06920790672302246
epoch 10900  clean testing loss: 0.04521649703383446
epoch 11000  training loss: 0.06901455670595169
epoch 11000  clean testing loss: 0.045716822147369385
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 11100  training loss: 0.06882023811340332
epoch 11100  clean testing loss: 0.04574813321232796
epoch 11200  training loss: 0.06860172003507614
epoch 11200  clean testing loss: 0.04596230387687683
epoch 11300  training loss: 0.06837872415781021
epoch 11300  clean testing loss: 0.04633883014321327
epoch 11400  training loss: 0.06809107959270477

  4%|▍         | 12323/300000 [00:39<09:30, 504.48it/s]
epoch 11500  training loss: 0.0679292380809784
epoch 11500  clean testing loss: 0.047403719276189804
epoch 11600  training loss: 0.06777362525463104
epoch 11600  clean testing loss: 0.04733920097351074
epoch 11700  training loss: 0.06778597086668015
epoch 11700  clean testing loss: 0.04645643010735512
epoch 11800  training loss: 0.0676518902182579
epoch 11800  clean testing loss: 0.04644782841205597
epoch 11900  training loss: 0.06744221597909927
epoch 11900  clean testing loss: 0.04659578204154968
epoch 12000  training loss: 0.06721784174442291
epoch 12000  clean testing loss: 0.04712216556072235
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 12100  training loss: 0.06697894632816315
epoch 12100  clean testing loss: 0.04781601205468178
epoch 12200  training loss: 0.06684985756874084
epoch 12200  clean testing loss: 0.04780110344290733
epoch 12300  training loss: 0.06673796474933624
epoch 12300  clean testing loss: 0.048316482454538345
epoch 12400  training loss: 0.06660870462656021

  4%|▍         | 13097/300000 [00:41<11:20, 421.39it/s]
epoch 12500  training loss: 0.06647864729166031
epoch 12500  clean testing loss: 0.04757952317595482
epoch 12600  training loss: 0.06632093340158463
epoch 12600  clean testing loss: 0.04795842245221138
epoch 12700  training loss: 0.06617670506238937
epoch 12700  clean testing loss: 0.048125576227903366
epoch 12800  training loss: 0.0661727637052536
epoch 12800  clean testing loss: 0.0494329072535038
epoch 12900  training loss: 0.06596976518630981
epoch 12900  clean testing loss: 0.049297504127025604
epoch 13000  training loss: 0.06582697480916977
epoch 13000  clean testing loss: 0.04812626913189888
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 13100  training loss: 0.0656459704041481

  4%|▍         | 13347/300000 [00:43<27:46, 172.04it/s]
epoch 13200  training loss: 0.06567418575286865
epoch 13200  clean testing loss: 0.04776002839207649
epoch 13300  training loss: 0.06550543755292892
epoch 13300  clean testing loss: 0.04807732626795769
epoch 13400  training loss: 0.06537153571844101

  5%|▍         | 14373/300000 [00:45<09:23, 506.99it/s]
epoch 13500  training loss: 0.06527339667081833
epoch 13500  clean testing loss: 0.04807902127504349
epoch 13600  training loss: 0.06503148376941681
epoch 13600  clean testing loss: 0.04871932417154312
epoch 13700  training loss: 0.06490765511989594
epoch 13700  clean testing loss: 0.04908051714301109
epoch 13800  training loss: 0.06481753289699554
epoch 13800  clean testing loss: 0.0495903380215168
epoch 13900  training loss: 0.06483256816864014
epoch 13900  clean testing loss: 0.050678592175245285
epoch 14000  training loss: 0.06455085426568985
epoch 14000  clean testing loss: 0.04954950138926506
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 14100  training loss: 0.06461939960718155
epoch 14100  clean testing loss: 0.04868902638554573
epoch 14200  training loss: 0.06452316790819168
epoch 14200  clean testing loss: 0.0486181378364563
epoch 14300  training loss: 0.06423597782850266
epoch 14300  clean testing loss: 0.049161624163389206
epoch 14400  training loss: 0.0641460195183754

  5%|▌         | 15349/300000 [00:47<09:26, 502.85it/s]
epoch 14500  training loss: 0.06408975273370743
epoch 14500  clean testing loss: 0.05096419155597687
epoch 14600  training loss: 0.06392409652471542
epoch 14600  clean testing loss: 0.051004406064748764
epoch 14700  training loss: 0.0638100728392601
epoch 14700  clean testing loss: 0.04982099309563637
epoch 14800  training loss: 0.06382396072149277
epoch 14800  clean testing loss: 0.049240220338106155
epoch 14900  training loss: 0.06355494260787964
epoch 14900  clean testing loss: 0.04984573647379875
epoch 15000  training loss: 0.06356111168861389
epoch 15000  clean testing loss: 0.049725186079740524
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 15100  training loss: 0.06332261115312576
epoch 15100  clean testing loss: 0.05046989023685455
epoch 15200  training loss: 0.0632229745388031
epoch 15200  clean testing loss: 0.05029672756791115
epoch 15300  training loss: 0.06312160938978195
epoch 15300  clean testing loss: 0.05080658197402954
epoch 15400  training loss: 0.06305230408906937

  5%|▌         | 16323/300000 [00:49<09:54, 476.83it/s]
epoch 15500  training loss: 0.06296373903751373
epoch 15500  clean testing loss: 0.05142193287611008
epoch 15600  training loss: 0.06275463104248047
epoch 15600  clean testing loss: 0.05090619623661041
epoch 15700  training loss: 0.06258150935173035
epoch 15700  clean testing loss: 0.05154285207390785
epoch 15800  training loss: 0.06241052970290184
epoch 15800  clean testing loss: 0.051737986505031586
epoch 15900  training loss: 0.062275853008031845
epoch 15900  clean testing loss: 0.05225520581007004
epoch 16000  training loss: 0.062166910618543625
epoch 16000  clean testing loss: 0.05255979299545288
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 16100  training loss: 0.062232472002506256
epoch 16100  clean testing loss: 0.05359723046422005
epoch 16200  training loss: 0.0619925931096077
epoch 16200  clean testing loss: 0.05239434912800789
epoch 16300  training loss: 0.06199527159333229
epoch 16300  clean testing loss: 0.05498031899333
epoch 16400  training loss: 0.06168476119637489

  6%|▌         | 17350/300000 [00:51<09:20, 504.25it/s]
epoch 16500  training loss: 0.06164045259356499
epoch 16500  clean testing loss: 0.052923839539289474
epoch 16600  training loss: 0.061545249074697495
epoch 16600  clean testing loss: 0.05308810621500015
epoch 16700  training loss: 0.06155257672071457
epoch 16700  clean testing loss: 0.05470982939004898
epoch 16800  training loss: 0.061365608125925064
epoch 16800  clean testing loss: 0.05280114337801933
epoch 16900  training loss: 0.06124187633395195
epoch 16900  clean testing loss: 0.05362362414598465
epoch 17000  training loss: 0.06122975051403046
epoch 17000  clean testing loss: 0.054439645260572433
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 17100  training loss: 0.06110113114118576
epoch 17100  clean testing loss: 0.05301353707909584
epoch 17200  training loss: 0.06114538758993149
epoch 17200  clean testing loss: 0.0526324026286602
epoch 17300  training loss: 0.0609176829457283
epoch 17300  clean testing loss: 0.05402328819036484
epoch 17400  training loss: 0.06092914938926697

  6%|▌         | 18377/300000 [00:53<09:13, 508.56it/s]
epoch 17500  training loss: 0.060749493539333344
epoch 17500  clean testing loss: 0.053384073078632355
epoch 17600  training loss: 0.06075189262628555
epoch 17600  clean testing loss: 0.05284901335835457
epoch 17700  training loss: 0.060736071318387985
epoch 17700  clean testing loss: 0.05287061631679535
epoch 17800  training loss: 0.06051138415932655
epoch 17800  clean testing loss: 0.05388650298118591
epoch 17900  training loss: 0.06041533872485161
epoch 17900  clean testing loss: 0.05428995192050934
epoch 18000  training loss: 0.0603456124663353
epoch 18000  clean testing loss: 0.054276566952466965
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 18100  training loss: 0.06025400757789612
epoch 18100  clean testing loss: 0.05390622094273567
epoch 18200  training loss: 0.0601910836994648
epoch 18200  clean testing loss: 0.05417173355817795
epoch 18300  training loss: 0.0601317323744297
epoch 18300  clean testing loss: 0.05434851348400116
epoch 18400  training loss: 0.06008676439523697

  6%|▋         | 19355/300000 [00:55<09:13, 507.47it/s]
epoch 18500  training loss: 0.05996982008218765
epoch 18500  clean testing loss: 0.0540197491645813
epoch 18600  training loss: 0.05993088707327843
epoch 18600  clean testing loss: 0.05509834736585617
epoch 18700  training loss: 0.05989304557442665
epoch 18700  clean testing loss: 0.05353335663676262
epoch 18800  training loss: 0.059810809791088104
epoch 18800  clean testing loss: 0.055081162601709366
epoch 18900  training loss: 0.05976552516222
epoch 18900  clean testing loss: 0.05364018678665161
epoch 19000  training loss: 0.05959233269095421
epoch 19000  clean testing loss: 0.05447764694690704
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 19100  training loss: 0.05952553451061249
epoch 19100  clean testing loss: 0.05420611798763275
epoch 19200  training loss: 0.05951999872922897
epoch 19200  clean testing loss: 0.05396965891122818
epoch 19300  training loss: 0.05946197733283043
epoch 19300  clean testing loss: 0.05552290007472038
epoch 19400  training loss: 0.05945210158824921

  7%|▋         | 20385/300000 [00:57<09:10, 508.33it/s]
epoch 19500  training loss: 0.059318169951438904
epoch 19500  clean testing loss: 0.054104793816804886
epoch 19600  training loss: 0.05934206023812294
epoch 19600  clean testing loss: 0.056020814925432205
epoch 19700  training loss: 0.05914400890469551
epoch 19700  clean testing loss: 0.054433587938547134
epoch 19800  training loss: 0.05904458835721016
epoch 19800  clean testing loss: 0.05529598519206047
epoch 19900  training loss: 0.05902877077460289
epoch 19900  clean testing loss: 0.05558636039495468
epoch 20000  training loss: 0.05889247730374336
epoch 20000  clean testing loss: 0.05476304143667221
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 20100  training loss: 0.05891197547316551
epoch 20100  clean testing loss: 0.05435200035572052
epoch 20200  training loss: 0.058809611946344376
epoch 20200  clean testing loss: 0.05563121661543846
epoch 20300  training loss: 0.05869536101818085
epoch 20300  clean testing loss: 0.05469517782330513
epoch 20400  training loss: 0.05874953791499138

  7%|▋         | 21362/300000 [00:59<10:25, 445.12it/s]
epoch 20500  training loss: 0.05858159437775612
epoch 20500  clean testing loss: 0.05490557849407196
epoch 20600  training loss: 0.05854921415448189
epoch 20600  clean testing loss: 0.05583108961582184
epoch 20700  training loss: 0.058571599423885345
epoch 20700  clean testing loss: 0.0564274787902832
epoch 20800  training loss: 0.058413758873939514
epoch 20800  clean testing loss: 0.055860377848148346
epoch 20900  training loss: 0.05831827223300934
epoch 20900  clean testing loss: 0.05481147766113281
epoch 21000  training loss: 0.05832528695464134
epoch 21000  clean testing loss: 0.05489809811115265
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 21100  training loss: 0.05816540867090225
epoch 21100  clean testing loss: 0.05545965954661369
epoch 21200  training loss: 0.058113135397434235
epoch 21200  clean testing loss: 0.055386029183864594
epoch 21300  training loss: 0.05801314115524292
epoch 21300  clean testing loss: 0.05508523806929588
epoch 21400  training loss: 0.057947512716054916

  7%|▋         | 22387/300000 [01:01<09:07, 507.03it/s]
epoch 21500  training loss: 0.05787533149123192
epoch 21500  clean testing loss: 0.055593062192201614
epoch 21600  training loss: 0.05784612149000168
epoch 21600  clean testing loss: 0.05622236430644989
epoch 21700  training loss: 0.05774921551346779
epoch 21700  clean testing loss: 0.05533229932188988
epoch 21800  training loss: 0.05774160102009773
epoch 21800  clean testing loss: 0.055006884038448334
epoch 21900  training loss: 0.057630907744169235
epoch 21900  clean testing loss: 0.0560285821557045
epoch 22000  training loss: 0.0576016865670681
epoch 22000  clean testing loss: 0.056060802191495895
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 22100  training loss: 0.05751873925328255
epoch 22100  clean testing loss: 0.05586835741996765
epoch 22200  training loss: 0.05746129900217056
epoch 22200  clean testing loss: 0.05535015091300011
epoch 22300  training loss: 0.05744032561779022
epoch 22300  clean testing loss: 0.055263180285692215
epoch 22400  training loss: 0.057326365262269974

  8%|▊         | 23364/300000 [01:03<09:04, 508.14it/s]
epoch 22500  training loss: 0.05731233209371567
epoch 22500  clean testing loss: 0.056575167924165726
epoch 22600  training loss: 0.05725422874093056
epoch 22600  clean testing loss: 0.05653323978185654
epoch 22700  training loss: 0.057212553918361664
epoch 22700  clean testing loss: 0.05668502300977707
epoch 22800  training loss: 0.057104356586933136
epoch 22800  clean testing loss: 0.05606735497713089
epoch 22900  training loss: 0.05704914405941963
epoch 22900  clean testing loss: 0.056018318980932236
epoch 23000  training loss: 0.05703909695148468
epoch 23000  clean testing loss: 0.05691903829574585
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 23100  training loss: 0.05693608894944191
epoch 23100  clean testing loss: 0.05585823953151703
epoch 23200  training loss: 0.05690554156899452
epoch 23200  clean testing loss: 0.055685270577669144
epoch 23300  training loss: 0.05688028410077095
epoch 23300  clean testing loss: 0.05565587058663368
epoch 23400  training loss: 0.05677727237343788

  8%|▊         | 24392/300000 [01:05<09:02, 507.78it/s]
epoch 23500  training loss: 0.05674730986356735
epoch 23500  clean testing loss: 0.057037822902202606
epoch 23600  training loss: 0.056642573326826096
epoch 23600  clean testing loss: 0.05809268727898598
epoch 23700  training loss: 0.05650845542550087
epoch 23700  clean testing loss: 0.05687226355075836
epoch 23800  training loss: 0.056453775614500046
epoch 23800  clean testing loss: 0.05689343810081482
epoch 23900  training loss: 0.056400224566459656
epoch 23900  clean testing loss: 0.05690694972872734
epoch 24000  training loss: 0.056299638003110886
epoch 24000  clean testing loss: 0.05759366974234581
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 24100  training loss: 0.056246690452098846
epoch 24100  clean testing loss: 0.05756203085184097
epoch 24200  training loss: 0.056201715022325516
epoch 24200  clean testing loss: 0.057761676609516144
epoch 24300  training loss: 0.05616253986954689
epoch 24300  clean testing loss: 0.05741467699408531
epoch 24400  training loss: 0.05611800774931908

  8%|▊         | 25370/300000 [01:07<09:01, 507.57it/s]
epoch 24500  training loss: 0.05606178194284439
epoch 24500  clean testing loss: 0.05782226845622063
epoch 24600  training loss: 0.05604015290737152
epoch 24600  clean testing loss: 0.057193346321582794
epoch 24700  training loss: 0.05600911006331444
epoch 24700  clean testing loss: 0.058384448289871216
epoch 24800  training loss: 0.05591582506895065
epoch 24800  clean testing loss: 0.057794779539108276
epoch 24900  training loss: 0.0558907724916935
epoch 24900  clean testing loss: 0.05745694413781166
epoch 25000  training loss: 0.055831428617239
epoch 25000  clean testing loss: 0.05805463716387749
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 25100  training loss: 0.055800434201955795
epoch 25100  clean testing loss: 0.058462806046009064
epoch 25200  training loss: 0.05570925027132034
epoch 25200  clean testing loss: 0.05786796286702156
epoch 25300  training loss: 0.055700235068798065
epoch 25300  clean testing loss: 0.05903299152851105
epoch 25400  training loss: 0.05557975918054581

  9%|▉         | 26398/300000 [01:09<08:58, 508.03it/s]
epoch 25500  training loss: 0.0555579736828804
epoch 25500  clean testing loss: 0.05816404148936272
epoch 25600  training loss: 0.055467527359724045
epoch 25600  clean testing loss: 0.05862588435411453
epoch 25700  training loss: 0.0554494708776474
epoch 25700  clean testing loss: 0.05922222509980202
epoch 25800  training loss: 0.055387068539857864
epoch 25800  clean testing loss: 0.059107374399900436
epoch 25900  training loss: 0.0553206205368042
epoch 25900  clean testing loss: 0.058540619909763336
epoch 26000  training loss: 0.055316630750894547
epoch 26000  clean testing loss: 0.05936989560723305
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 26100  training loss: 0.05522911250591278
epoch 26100  clean testing loss: 0.05942622572183609
epoch 26200  training loss: 0.055192362517118454
epoch 26200  clean testing loss: 0.05948050320148468
epoch 26300  training loss: 0.055114541202783585
epoch 26300  clean testing loss: 0.05847816541790962
epoch 26400  training loss: 0.055073633790016174
epoch 26400  clean testing loss: 0.05843733623623848
epoch 26500  training loss: 0.05503791570663452

  9%|▉         | 27427/300000 [01:11<08:59, 505.20it/s]
epoch 26600  training loss: 0.054997339844703674
epoch 26600  clean testing loss: 0.059359170496463776
epoch 26700  training loss: 0.05491909757256508
epoch 26700  clean testing loss: 0.0587993860244751
epoch 26800  training loss: 0.05487511307001114
epoch 26800  clean testing loss: 0.05908835679292679
epoch 26900  training loss: 0.054841555655002594
epoch 26900  clean testing loss: 0.058600276708602905
epoch 27000  training loss: 0.05481969192624092
epoch 27000  clean testing loss: 0.059333108365535736
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 27100  training loss: 0.0547475628554821
epoch 27100  clean testing loss: 0.059086717665195465
epoch 27200  training loss: 0.05471294745802879
epoch 27200  clean testing loss: 0.05900006368756294
epoch 27300  training loss: 0.05468602851033211
epoch 27300  clean testing loss: 0.05891486257314682
epoch 27400  training loss: 0.05464844033122063
epoch 27400  clean testing loss: 0.05874701961874962
epoch 27500  training loss: 0.054612550884485245

  9%|▉         | 28401/300000 [01:13<09:02, 501.07it/s]
epoch 27600  training loss: 0.054572105407714844
epoch 27600  clean testing loss: 0.05898735672235489
epoch 27700  training loss: 0.05453808233141899
epoch 27700  clean testing loss: 0.05896144360303879
epoch 27800  training loss: 0.054519038647413254
epoch 27800  clean testing loss: 0.05868803337216377
epoch 27900  training loss: 0.05444752052426338
epoch 27900  clean testing loss: 0.05898493900895119
epoch 28000  training loss: 0.05443631112575531
epoch 28000  clean testing loss: 0.05973426252603531
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 28100  training loss: 0.054371606558561325
epoch 28100  clean testing loss: 0.05956340953707695
epoch 28200  training loss: 0.05433984100818634
epoch 28200  clean testing loss: 0.05891748145222664
epoch 28300  training loss: 0.054320987313985825
epoch 28300  clean testing loss: 0.059941478073596954
epoch 28400  training loss: 0.054270967841148376
epoch 28400  clean testing loss: 0.05894196778535843
epoch 28500  training loss: 0.054215479642152786

 10%|▉         | 29430/300000 [01:15<08:56, 504.51it/s]
epoch 28600  training loss: 0.05415233597159386
epoch 28600  clean testing loss: 0.0598120391368866
epoch 28700  training loss: 0.05412554368376732
epoch 28700  clean testing loss: 0.059263989329338074
epoch 28800  training loss: 0.0540957897901535
epoch 28800  clean testing loss: 0.059159524738788605
epoch 28900  training loss: 0.05402792617678642
epoch 28900  clean testing loss: 0.05943221598863602
epoch 29000  training loss: 0.053985595703125
epoch 29000  clean testing loss: 0.059475935995578766
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 29100  training loss: 0.053941577672958374
epoch 29100  clean testing loss: 0.05930822342634201
epoch 29200  training loss: 0.05389034375548363
epoch 29200  clean testing loss: 0.059457164257764816
epoch 29300  training loss: 0.05384833365678787
epoch 29300  clean testing loss: 0.05988064408302307
epoch 29400  training loss: 0.05382634326815605
epoch 29400  clean testing loss: 0.060191791504621506
epoch 29500  training loss: 0.05380254238843918

 10%|█         | 30458/300000 [01:17<08:50, 508.15it/s]
epoch 29600  training loss: 0.053763531148433685
epoch 29600  clean testing loss: 0.05928916856646538
epoch 29700  training loss: 0.05369517207145691
epoch 29700  clean testing loss: 0.05947878584265709
epoch 29800  training loss: 0.05367593467235565
epoch 29800  clean testing loss: 0.05940166115760803
epoch 29900  training loss: 0.053611014038324356
epoch 29900  clean testing loss: 0.05969388782978058
epoch 30000  training loss: 0.05359301716089249
epoch 30000  clean testing loss: 0.060092248022556305
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 30100  training loss: 0.05353536456823349
epoch 30100  clean testing loss: 0.06005364656448364
epoch 30200  training loss: 0.05350764840841293
epoch 30200  clean testing loss: 0.05990518629550934
epoch 30300  training loss: 0.053469933569431305
epoch 30300  clean testing loss: 0.059942927211523056
epoch 30400  training loss: 0.053437989205121994
epoch 30400  clean testing loss: 0.060201432555913925
epoch 30500  training loss: 0.05341491103172302

 10%|█         | 31424/300000 [01:19<09:28, 472.46it/s]
epoch 30600  training loss: 0.05339129641652107
epoch 30600  clean testing loss: 0.060360439121723175
epoch 30700  training loss: 0.053338028490543365
epoch 30700  clean testing loss: 0.05996256694197655
epoch 30800  training loss: 0.05330324172973633
epoch 30800  clean testing loss: 0.06020855903625488
epoch 30900  training loss: 0.053292904049158096
epoch 30900  clean testing loss: 0.059813227504491806
epoch 31000  training loss: 0.05325089395046234
epoch 31000  clean testing loss: 0.06050218641757965
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 31100  training loss: 0.05320446193218231
epoch 31100  clean testing loss: 0.06025280803442001
epoch 31200  training loss: 0.053173914551734924
epoch 31200  clean testing loss: 0.06002684310078621
epoch 31300  training loss: 0.053142208606004715
epoch 31300  clean testing loss: 0.06017939746379852
epoch 31400  training loss: 0.053125228732824326
epoch 31400  clean testing loss: 0.06085149943828583
epoch 31500  training loss: 0.05306633934378624

 11%|█         | 32398/300000 [01:21<08:47, 507.20it/s]
epoch 31600  training loss: 0.053036145865917206
epoch 31600  clean testing loss: 0.06014106050133705
epoch 31700  training loss: 0.05302148312330246
epoch 31700  clean testing loss: 0.0600639171898365
epoch 31800  training loss: 0.05296103283762932
epoch 31800  clean testing loss: 0.060571588575839996
epoch 31900  training loss: 0.05292666330933571
epoch 31900  clean testing loss: 0.060774315148591995
epoch 32000  training loss: 0.05289198458194733
epoch 32000  clean testing loss: 0.060720186680555344
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 32100  training loss: 0.05286552757024765
epoch 32100  clean testing loss: 0.060952845960855484
epoch 32200  training loss: 0.0528244748711586
epoch 32200  clean testing loss: 0.06078280881047249
epoch 32300  training loss: 0.052819836884737015
epoch 32300  clean testing loss: 0.061191458255052567
epoch 32400  training loss: 0.05277695506811142
epoch 32400  clean testing loss: 0.06114798039197922
epoch 32500  training loss: 0.05271723493933678

 11%|█         | 33427/300000 [01:23<08:47, 505.46it/s]
epoch 32600  training loss: 0.052676256746053696
epoch 32600  clean testing loss: 0.06063683331012726
epoch 32700  training loss: 0.05264941602945328
epoch 32700  clean testing loss: 0.061239421367645264
epoch 32800  training loss: 0.05261713266372681
epoch 32800  clean testing loss: 0.06120843440294266
epoch 32900  training loss: 0.052589051425457
epoch 32900  clean testing loss: 0.06132188066840172
epoch 33000  training loss: 0.0525628924369812
epoch 33000  clean testing loss: 0.061170075088739395
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 33100  training loss: 0.05250837281346321
epoch 33100  clean testing loss: 0.060839567333459854
epoch 33200  training loss: 0.05248076096177101
epoch 33200  clean testing loss: 0.0611095130443573
epoch 33300  training loss: 0.05244918167591095
epoch 33300  clean testing loss: 0.06114136055111885
epoch 33400  training loss: 0.05240039527416229
epoch 33400  clean testing loss: 0.061214249581098557
epoch 33500  training loss: 0.0523817352950573

 11%|█▏        | 34455/300000 [01:25<08:49, 501.40it/s]
epoch 33600  training loss: 0.05235125124454498
epoch 33600  clean testing loss: 0.06111641600728035
epoch 33700  training loss: 0.05232364311814308
epoch 33700  clean testing loss: 0.060949359089136124
epoch 33800  training loss: 0.052296124398708344
epoch 33800  clean testing loss: 0.061038464307785034
epoch 33900  training loss: 0.05226153880357742
epoch 33900  clean testing loss: 0.06138711795210838
epoch 34000  training loss: 0.05223264545202255
epoch 34000  clean testing loss: 0.061101626604795456
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 34100  training loss: 0.05220520868897438
epoch 34100  clean testing loss: 0.06156531721353531
epoch 34200  training loss: 0.05219053849577904
epoch 34200  clean testing loss: 0.06166490167379379
epoch 34300  training loss: 0.05216226726770401
epoch 34300  clean testing loss: 0.061628557741642
epoch 34400  training loss: 0.0521235391497612
epoch 34400  clean testing loss: 0.06118364632129669
epoch 34500  training loss: 0.05210813507437706

 12%|█▏        | 35020/300000 [01:26<08:53, 496.28it/s]
epoch 34600  training loss: 0.05208035558462143
epoch 34600  clean testing loss: 0.06116096302866936
epoch 34700  training loss: 0.052043963223695755
epoch 34700  clean testing loss: 0.06161987781524658
epoch 34800  training loss: 0.052013568580150604
epoch 34800  clean testing loss: 0.061576928943395615
epoch 34900  training loss: 0.051986467093229294
epoch 34900  clean testing loss: 0.06163451820611954
epoch 35000  training loss: 0.05194473639130592
epoch 35000  clean testing loss: 0.06187843531370163

 12%|█▏        | 35838/300000 [01:35<09:59, 440.76it/s]
epoch 35100  training loss: 0.051895465701818466
epoch 35100  clean testing loss: 0.06238013878464699
epoch 35200  training loss: 0.05186367407441139
epoch 35200  clean testing loss: 0.062005601823329926
epoch 35300  training loss: 0.05183861404657364
epoch 35300  clean testing loss: 0.06231647729873657
epoch 35400  training loss: 0.05181223899126053
epoch 35400  clean testing loss: 0.06188550218939781
epoch 35500  training loss: 0.051777489483356476
epoch 35500  clean testing loss: 0.062062036246061325
epoch 35600  training loss: 0.05176067352294922
epoch 35600  clean testing loss: 0.06264116615056992
epoch 35700  training loss: 0.05172199383378029
epoch 35700  clean testing loss: 0.06232134625315666
epoch 35800  training loss: 0.051707349717617035
epoch 35800  clean testing loss: 0.06253180652856827
epoch 35900  training loss: 0.05166812613606453

 12%|█▏        | 36816/300000 [01:37<08:41, 504.39it/s]
epoch 36000  training loss: 0.051649998873472214
epoch 36000  clean testing loss: 0.06211087480187416
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 36100  training loss: 0.05162222683429718
epoch 36100  clean testing loss: 0.06219877675175667
epoch 36200  training loss: 0.05160021409392357
epoch 36200  clean testing loss: 0.06236616522073746
epoch 36300  training loss: 0.051586635410785675
epoch 36300  clean testing loss: 0.06260530650615692
epoch 36400  training loss: 0.051566049456596375
epoch 36400  clean testing loss: 0.06213252246379852
epoch 36500  training loss: 0.051542241126298904
epoch 36500  clean testing loss: 0.06260068714618683
epoch 36600  training loss: 0.05151890963315964
epoch 36600  clean testing loss: 0.062209777534008026
epoch 36700  training loss: 0.05150092393159866
epoch 36700  clean testing loss: 0.06274206936359406
epoch 36800  training loss: 0.05147627368569374
epoch 36800  clean testing loss: 0.06272134184837341
epoch 36900  training loss: 0.05145324021577835

 13%|█▎        | 37843/300000 [01:39<08:39, 504.25it/s]
epoch 37000  training loss: 0.05139948055148125
epoch 37000  clean testing loss: 0.06262791156768799
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 37100  training loss: 0.0513702929019928
epoch 37100  clean testing loss: 0.06311612576246262
epoch 37200  training loss: 0.051351647824048996
epoch 37200  clean testing loss: 0.06306178867816925
epoch 37300  training loss: 0.05132637545466423
epoch 37300  clean testing loss: 0.06301025301218033
epoch 37400  training loss: 0.05130521208047867
epoch 37400  clean testing loss: 0.06307877600193024
epoch 37500  training loss: 0.05127732455730438
epoch 37500  clean testing loss: 0.06295005977153778
epoch 37600  training loss: 0.05125541612505913
epoch 37600  clean testing loss: 0.06298820674419403
epoch 37700  training loss: 0.051236238330602646
epoch 37700  clean testing loss: 0.06305687129497528
epoch 37800  training loss: 0.051225703209638596
epoch 37800  clean testing loss: 0.06266391277313232
epoch 37900  training loss: 0.0512034110724926

 13%|█▎        | 38870/300000 [01:41<08:35, 507.03it/s]
epoch 38000  training loss: 0.051180608570575714
epoch 38000  clean testing loss: 0.06318788230419159
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 38100  training loss: 0.051148418337106705
epoch 38100  clean testing loss: 0.06299183517694473
epoch 38200  training loss: 0.05112988501787186
epoch 38200  clean testing loss: 0.06303396075963974
epoch 38300  training loss: 0.051110707223415375
epoch 38300  clean testing loss: 0.06279676407575607
epoch 38400  training loss: 0.051081132143735886
epoch 38400  clean testing loss: 0.06309004127979279
epoch 38500  training loss: 0.05106266960501671
epoch 38500  clean testing loss: 0.06284140795469284
epoch 38600  training loss: 0.05103778466582298
epoch 38600  clean testing loss: 0.06317394971847534
epoch 38700  training loss: 0.05101579427719116
epoch 38700  clean testing loss: 0.06318259984254837
epoch 38800  training loss: 0.051004014909267426
epoch 38800  clean testing loss: 0.06284982711076736
epoch 38900  training loss: 0.05097495764493942

 13%|█▎        | 39846/300000 [01:43<08:37, 502.60it/s]
epoch 39000  training loss: 0.05095704272389412
epoch 39000  clean testing loss: 0.06302273273468018
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 39100  training loss: 0.05093267932534218
epoch 39100  clean testing loss: 0.06310779601335526
epoch 39200  training loss: 0.05091414228081703
epoch 39200  clean testing loss: 0.06331223994493484
epoch 39300  training loss: 0.050898730754852295
epoch 39300  clean testing loss: 0.06337485462427139
epoch 39400  training loss: 0.050875697284936905
epoch 39400  clean testing loss: 0.06333684921264648
epoch 39500  training loss: 0.05085805803537369
epoch 39500  clean testing loss: 0.06331277638673782
epoch 39600  training loss: 0.05084121972322464
epoch 39600  clean testing loss: 0.06312014907598495
epoch 39700  training loss: 0.05081808939576149
epoch 39700  clean testing loss: 0.06326953321695328
epoch 39800  training loss: 0.050806112587451935
epoch 39800  clean testing loss: 0.06356104463338852
epoch 39900  training loss: 0.05078243464231491

 14%|█▎        | 40877/300000 [01:45<08:29, 508.82it/s]
epoch 40000  training loss: 0.05076422914862633
epoch 40000  clean testing loss: 0.06319595128297806
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 40100  training loss: 0.050745103508234024
epoch 40100  clean testing loss: 0.06352484226226807
epoch 40200  training loss: 0.05073409900069237
epoch 40200  clean testing loss: 0.06363717466592789
epoch 40300  training loss: 0.05071130022406578
epoch 40300  clean testing loss: 0.06359248608350754
epoch 40400  training loss: 0.05068228393793106
epoch 40400  clean testing loss: 0.06342068314552307
epoch 40500  training loss: 0.05066527798771858
epoch 40500  clean testing loss: 0.06338584423065186
epoch 40600  training loss: 0.05064667388796806
epoch 40600  clean testing loss: 0.06353621929883957
epoch 40700  training loss: 0.05063089355826378
epoch 40700  clean testing loss: 0.06327813118696213
epoch 40800  training loss: 0.05060482770204544
epoch 40800  clean testing loss: 0.06347228586673737
epoch 40900  training loss: 0.050595298409461975

 14%|█▍        | 41854/300000 [01:47<08:30, 506.14it/s]
epoch 41000  training loss: 0.05056965351104736
epoch 41000  clean testing loss: 0.06375666707754135
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 41100  training loss: 0.05055396631360054
epoch 41100  clean testing loss: 0.06335578858852386
epoch 41200  training loss: 0.050529543310403824
epoch 41200  clean testing loss: 0.0634850263595581
epoch 41300  training loss: 0.05051518604159355
epoch 41300  clean testing loss: 0.06345583498477936
epoch 41400  training loss: 0.05050201714038849
epoch 41400  clean testing loss: 0.06341121345758438
epoch 41500  training loss: 0.05047808215022087
epoch 41500  clean testing loss: 0.06391879171133041
epoch 41600  training loss: 0.05045485869050026
epoch 41600  clean testing loss: 0.06352388113737106
epoch 41700  training loss: 0.050442103296518326
epoch 41700  clean testing loss: 0.06352051347494125
epoch 41800  training loss: 0.050416987389326096
epoch 41800  clean testing loss: 0.06370732933282852
epoch 41900  training loss: 0.050399865955114365

 14%|█▍        | 42821/300000 [01:49<09:38, 444.55it/s]
epoch 42000  training loss: 0.05038643255829811
epoch 42000  clean testing loss: 0.06359957158565521
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 42100  training loss: 0.050361376255750656
epoch 42100  clean testing loss: 0.063805490732193
epoch 42200  training loss: 0.05034971982240677
epoch 42200  clean testing loss: 0.06364509463310242
epoch 42300  training loss: 0.05033363029360771
epoch 42300  clean testing loss: 0.06393492966890335
epoch 42400  training loss: 0.05031607300043106
epoch 42400  clean testing loss: 0.0636562705039978
epoch 42500  training loss: 0.050301942974328995
epoch 42500  clean testing loss: 0.06367917358875275
epoch 42600  training loss: 0.0502837672829628
epoch 42600  clean testing loss: 0.06371336430311203
epoch 42700  training loss: 0.05026623606681824
epoch 42700  clean testing loss: 0.06399241089820862
epoch 42800  training loss: 0.050248101353645325
epoch 42800  clean testing loss: 0.06394144147634506
epoch 42900  training loss: 0.050236545503139496

 15%|█▍        | 43848/300000 [01:51<08:28, 503.87it/s]
epoch 43000  training loss: 0.05021722614765167
epoch 43000  clean testing loss: 0.06403312087059021
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 43100  training loss: 0.05019868537783623
epoch 43100  clean testing loss: 0.06401392072439194
epoch 43200  training loss: 0.05018426105380058
epoch 43200  clean testing loss: 0.06402555853128433
epoch 43300  training loss: 0.05017388239502907
epoch 43300  clean testing loss: 0.06377345323562622
epoch 43400  training loss: 0.050148721784353256
epoch 43400  clean testing loss: 0.06397031247615814
epoch 43500  training loss: 0.050132665783166885
epoch 43500  clean testing loss: 0.06417378783226013
epoch 43600  training loss: 0.05011526867747307
epoch 43600  clean testing loss: 0.06405059248209
epoch 43700  training loss: 0.050102077424526215
epoch 43700  clean testing loss: 0.0642581656575203
epoch 43800  training loss: 0.05008169636130333
epoch 43800  clean testing loss: 0.06386080384254456
epoch 43900  training loss: 0.05007288232445717

 15%|█▍        | 44878/300000 [01:53<08:23, 506.87it/s]
epoch 44000  training loss: 0.05004958435893059
epoch 44000  clean testing loss: 0.06426077336072922
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 44100  training loss: 0.05003323778510094
epoch 44100  clean testing loss: 0.0639326274394989
epoch 44200  training loss: 0.05001432076096535
epoch 44200  clean testing loss: 0.06389599293470383
epoch 44300  training loss: 0.04999426007270813
epoch 44300  clean testing loss: 0.06403503566980362
epoch 44400  training loss: 0.049978822469711304
epoch 44400  clean testing loss: 0.06432754546403885
epoch 44500  training loss: 0.04996008053421974
epoch 44500  clean testing loss: 0.06412661820650101
epoch 44600  training loss: 0.049940865486860275
epoch 44600  clean testing loss: 0.06442763656377792
epoch 44700  training loss: 0.0499277226626873
epoch 44700  clean testing loss: 0.06439977139234543
epoch 44800  training loss: 0.049910034984350204
epoch 44800  clean testing loss: 0.06411917507648468
epoch 44900  training loss: 0.049889061599969864

 15%|█▌        | 45856/300000 [01:55<08:21, 506.44it/s]
epoch 45000  training loss: 0.049879156053066254
epoch 45000  clean testing loss: 0.06422178447246552
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 45100  training loss: 0.04985979571938515
epoch 45100  clean testing loss: 0.06441430002450943
epoch 45200  training loss: 0.04984796792268753
epoch 45200  clean testing loss: 0.06425462663173676
epoch 45300  training loss: 0.04983368143439293
epoch 45300  clean testing loss: 0.06447670608758926
epoch 45400  training loss: 0.049819983541965485
epoch 45400  clean testing loss: 0.06443452835083008
epoch 45500  training loss: 0.04980429261922836
epoch 45500  clean testing loss: 0.06439297646284103
epoch 45600  training loss: 0.04979073628783226
epoch 45600  clean testing loss: 0.06454133242368698
epoch 45700  training loss: 0.04977528750896454
epoch 45700  clean testing loss: 0.06439241766929626
epoch 45800  training loss: 0.0497620515525341
epoch 45800  clean testing loss: 0.06445411592721939
epoch 45900  training loss: 0.049746233969926834

 16%|█▌        | 46885/300000 [01:57<08:20, 505.36it/s]
epoch 46000  training loss: 0.049732230603694916
epoch 46000  clean testing loss: 0.06452184170484543
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 46100  training loss: 0.04971880093216896
epoch 46100  clean testing loss: 0.0646471455693245
epoch 46200  training loss: 0.049702100455760956
epoch 46200  clean testing loss: 0.06461679935455322
epoch 46300  training loss: 0.049692876636981964
epoch 46300  clean testing loss: 0.06436862796545029
epoch 46400  training loss: 0.04967612400650978
epoch 46400  clean testing loss: 0.06475424766540527
epoch 46500  training loss: 0.049660783261060715
epoch 46500  clean testing loss: 0.06443176418542862
epoch 46600  training loss: 0.04964322969317436
epoch 46600  clean testing loss: 0.06455216556787491
epoch 46700  training loss: 0.049632586538791656
epoch 46700  clean testing loss: 0.064706951379776
epoch 46800  training loss: 0.04961607605218887
epoch 46800  clean testing loss: 0.06472025066614151
epoch 46900  training loss: 0.04959949105978012

 16%|█▌        | 47862/300000 [01:59<08:18, 505.74it/s]
epoch 47000  training loss: 0.04958537220954895
epoch 47000  clean testing loss: 0.06480129063129425
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 47100  training loss: 0.049572717398405075
epoch 47100  clean testing loss: 0.06466823071241379
epoch 47200  training loss: 0.04956086352467537
epoch 47200  clean testing loss: 0.06457727402448654
epoch 47300  training loss: 0.04954346641898155
epoch 47300  clean testing loss: 0.06472066044807434
epoch 47400  training loss: 0.04952935129404068
epoch 47400  clean testing loss: 0.06483814120292664
epoch 47500  training loss: 0.049515146762132645
epoch 47500  clean testing loss: 0.06474360823631287
epoch 47600  training loss: 0.04950276389718056
epoch 47600  clean testing loss: 0.06467912346124649
epoch 47700  training loss: 0.04949372261762619
epoch 47700  clean testing loss: 0.06458818912506104
epoch 47800  training loss: 0.0494748093187809
epoch 47800  clean testing loss: 0.06477241963148117
epoch 47900  training loss: 0.04945966601371765

 16%|█▋        | 48891/300000 [02:01<08:14, 507.70it/s]
epoch 48000  training loss: 0.049448542296886444
epoch 48000  clean testing loss: 0.06475454568862915
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 48100  training loss: 0.0494346097111702
epoch 48100  clean testing loss: 0.06487961113452911
epoch 48200  training loss: 0.04942287132143974
epoch 48200  clean testing loss: 0.06487610191106796
epoch 48300  training loss: 0.049411527812480927
epoch 48300  clean testing loss: 0.06484098732471466
epoch 48400  training loss: 0.04939958453178406
epoch 48400  clean testing loss: 0.0648970678448677
epoch 48500  training loss: 0.049387648701667786
epoch 48500  clean testing loss: 0.06500335037708282
epoch 48600  training loss: 0.04937860369682312
epoch 48600  clean testing loss: 0.0650249645113945
epoch 48700  training loss: 0.04936431720852852
epoch 48700  clean testing loss: 0.0649174228310585
epoch 48800  training loss: 0.04935349524021149
epoch 48800  clean testing loss: 0.06484315544366837
epoch 48900  training loss: 0.049340661615133286

 17%|█▋        | 49867/300000 [02:03<08:15, 505.15it/s]
epoch 49000  training loss: 0.0493282824754715
epoch 49000  clean testing loss: 0.06503774970769882
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 49100  training loss: 0.04931715503334999
epoch 49100  clean testing loss: 0.0649835541844368
epoch 49200  training loss: 0.04930365830659866
epoch 49200  clean testing loss: 0.0650547593832016
epoch 49300  training loss: 0.04929223284125328
epoch 49300  clean testing loss: 0.0650617703795433
epoch 49400  training loss: 0.049280740320682526
epoch 49400  clean testing loss: 0.06519109755754471
epoch 49500  training loss: 0.04926779866218567
epoch 49500  clean testing loss: 0.0650506243109703
epoch 49600  training loss: 0.049258023500442505
epoch 49600  clean testing loss: 0.06499186903238297
epoch 49700  training loss: 0.049246057868003845
epoch 49700  clean testing loss: 0.06524921953678131
epoch 49800  training loss: 0.04923339560627937
epoch 49800  clean testing loss: 0.0650719702243805
epoch 49900  training loss: 0.04922153055667877

 17%|█▋        | 50892/300000 [02:05<08:12, 505.38it/s]
epoch 50000  training loss: 0.04920826107263565
epoch 50000  clean testing loss: 0.06506506353616714
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 50100  training loss: 0.049195628613233566
epoch 50100  clean testing loss: 0.06520368158817291
epoch 50200  training loss: 0.04918593168258667
epoch 50200  clean testing loss: 0.0650491937994957
epoch 50300  training loss: 0.049167029559612274
epoch 50300  clean testing loss: 0.06528624147176743
epoch 50400  training loss: 0.049156200140714645
epoch 50400  clean testing loss: 0.06510711461305618
epoch 50500  training loss: 0.04914101958274841
epoch 50500  clean testing loss: 0.06521020829677582
epoch 50600  training loss: 0.049129921942949295
epoch 50600  clean testing loss: 0.06517698615789413
epoch 50700  training loss: 0.049117378890514374
epoch 50700  clean testing loss: 0.06539086997509003
epoch 50800  training loss: 0.04910700395703316
epoch 50800  clean testing loss: 0.06518542021512985
epoch 50900  training loss: 0.0490911565721035

 17%|█▋        | 51354/300000 [02:06<08:15, 502.13it/s]
epoch 51000  training loss: 0.049078479409217834
epoch 51000  clean testing loss: 0.06535571813583374
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 51100  training loss: 0.04906832426786423
epoch 51100  clean testing loss: 0.06541480123996735
epoch 51200  training loss: 0.04905799403786659
epoch 51200  clean testing loss: 0.06543900072574615
epoch 51300  training loss: 0.04904906824231148
epoch 51300  clean testing loss: 0.06551466882228851
epoch 51400  training loss: 0.049038611352443695

 17%|█▋        | 52232/300000 [02:17<1:02:39, 65.90it/s]
epoch 51500  training loss: 0.049026090651750565
epoch 51500  clean testing loss: 0.06546861678361893
epoch 51600  training loss: 0.049012742936611176
epoch 51600  clean testing loss: 0.06550152599811554
epoch 51700  training loss: 0.04900035634636879
epoch 51700  clean testing loss: 0.06551941484212875
epoch 51800  training loss: 0.04898810759186745
epoch 51800  clean testing loss: 0.06564898788928986
epoch 51900  training loss: 0.0489775724709034
epoch 51900  clean testing loss: 0.06571124494075775
epoch 52000  training loss: 0.048968471586704254
epoch 52000  clean testing loss: 0.06574349850416183
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 52100  training loss: 0.048951707780361176
epoch 52100  clean testing loss: 0.06571988016366959
epoch 52200  training loss: 0.048937711864709854
epoch 52200  clean testing loss: 0.06581790000200272
epoch 52300  training loss: 0.04892782121896744

 18%|█▊        | 53193/300000 [02:19<10:07, 406.03it/s]
epoch 52400  training loss: 0.0489153116941452
epoch 52400  clean testing loss: 0.06573528051376343
epoch 52500  training loss: 0.04890511557459831
epoch 52500  clean testing loss: 0.065746009349823
epoch 52600  training loss: 0.04889392480254173
epoch 52600  clean testing loss: 0.06561290472745895
epoch 52700  training loss: 0.048882827162742615
epoch 52700  clean testing loss: 0.06566620618104935
epoch 52800  training loss: 0.04887285828590393
epoch 52800  clean testing loss: 0.06562647968530655
epoch 52900  training loss: 0.04886080324649811
epoch 52900  clean testing loss: 0.06566400825977325
epoch 53000  training loss: 0.04885033890604973
epoch 53000  clean testing loss: 0.0657137930393219
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 53100  training loss: 0.04883953183889389
epoch 53100  clean testing loss: 0.06582291424274445
epoch 53200  training loss: 0.04882876202464104

 18%|█▊        | 54213/300000 [02:21<08:12, 499.31it/s]
epoch 53300  training loss: 0.0488191582262516
epoch 53300  clean testing loss: 0.06566637009382248
epoch 53400  training loss: 0.04880831018090248
epoch 53400  clean testing loss: 0.06586921960115433
epoch 53500  training loss: 0.04879750683903694
epoch 53500  clean testing loss: 0.0657360702753067
epoch 53600  training loss: 0.048787713050842285
epoch 53600  clean testing loss: 0.06587778031826019
epoch 53700  training loss: 0.048776574432849884
epoch 53700  clean testing loss: 0.06589216738939285
epoch 53800  training loss: 0.04876173660159111
epoch 53800  clean testing loss: 0.06598517298698425
epoch 53900  training loss: 0.048739150166511536
epoch 53900  clean testing loss: 0.06578606367111206
epoch 54000  training loss: 0.048728011548519135
epoch 54000  clean testing loss: 0.06577832251787186
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 54100  training loss: 0.04871616140007973
epoch 54100  clean testing loss: 0.06581566482782364
epoch 54200  training loss: 0.04870719462633133

 18%|█▊        | 55190/300000 [02:23<08:06, 503.07it/s]
epoch 54300  training loss: 0.048697419464588165
epoch 54300  clean testing loss: 0.06584402918815613
epoch 54400  training loss: 0.04868828505277634
epoch 54400  clean testing loss: 0.06589431315660477
epoch 54500  training loss: 0.04867766797542572
epoch 54500  clean testing loss: 0.06585386395454407
epoch 54600  training loss: 0.04866853728890419
epoch 54600  clean testing loss: 0.06598439812660217
epoch 54700  training loss: 0.04865884408354759
epoch 54700  clean testing loss: 0.06598946452140808
epoch 54800  training loss: 0.04864862188696861
epoch 54800  clean testing loss: 0.06590662151575089
epoch 54900  training loss: 0.04863898828625679
epoch 54900  clean testing loss: 0.06603332608938217
epoch 55000  training loss: 0.048629146069288254
epoch 55000  clean testing loss: 0.06599900126457214
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 55100  training loss: 0.0486195869743824
epoch 55100  clean testing loss: 0.06587518751621246
epoch 55200  training loss: 0.04860952869057655
epoch 55200  clean testing loss: 0.06588733941316605
epoch 55300  training loss: 0.04859894514083862

 19%|█▊        | 56218/300000 [02:25<08:04, 503.38it/s]
epoch 55400  training loss: 0.04858913645148277
epoch 55400  clean testing loss: 0.06598007678985596
epoch 55500  training loss: 0.0485801063477993
epoch 55500  clean testing loss: 0.06598719209432602
epoch 55600  training loss: 0.04857085272669792
epoch 55600  clean testing loss: 0.0659761056303978
epoch 55700  training loss: 0.04856119677424431
epoch 55700  clean testing loss: 0.06604959070682526
epoch 55800  training loss: 0.04855135828256607
epoch 55800  clean testing loss: 0.06609035283327103
epoch 55900  training loss: 0.04854104667901993
epoch 55900  clean testing loss: 0.06599166244268417
epoch 56000  training loss: 0.04853193089365959
epoch 56000  clean testing loss: 0.06603685021400452
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 56100  training loss: 0.04852211847901344
epoch 56100  clean testing loss: 0.06610818952322006
epoch 56200  training loss: 0.04851377382874489
epoch 56200  clean testing loss: 0.06596903502941132
epoch 56300  training loss: 0.04850399121642113

 19%|█▉        | 57246/300000 [02:27<08:03, 501.99it/s]
epoch 56400  training loss: 0.04849398136138916
epoch 56400  clean testing loss: 0.06600535660982132
epoch 56500  training loss: 0.048484813421964645
epoch 56500  clean testing loss: 0.06607569754123688
epoch 56600  training loss: 0.04847602918744087
epoch 56600  clean testing loss: 0.06602244824171066
epoch 56700  training loss: 0.048465944826602936
epoch 56700  clean testing loss: 0.0661548301577568
epoch 56800  training loss: 0.04845670610666275
epoch 56800  clean testing loss: 0.0661662295460701
epoch 56900  training loss: 0.04844801500439644
epoch 56900  clean testing loss: 0.0660148411989212
epoch 57000  training loss: 0.04843875393271446
epoch 57000  clean testing loss: 0.06607818603515625
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 57100  training loss: 0.048430126160383224
epoch 57100  clean testing loss: 0.06618791073560715
epoch 57200  training loss: 0.04842274263501167
epoch 57200  clean testing loss: 0.0661088079214096
epoch 57300  training loss: 0.04841512441635132

 19%|█▉        | 58218/300000 [02:29<08:02, 500.69it/s]
epoch 57400  training loss: 0.04840676113963127
epoch 57400  clean testing loss: 0.06613114476203918
epoch 57500  training loss: 0.04839896783232689
epoch 57500  clean testing loss: 0.06616053730249405
epoch 57600  training loss: 0.04839136078953743
epoch 57600  clean testing loss: 0.06618793308734894
epoch 57700  training loss: 0.048384085297584534
epoch 57700  clean testing loss: 0.06623982638120651
epoch 57800  training loss: 0.04837564006447792
epoch 57800  clean testing loss: 0.06615697592496872
epoch 57900  training loss: 0.04836849495768547
epoch 57900  clean testing loss: 0.06627698242664337
epoch 58000  training loss: 0.04835906997323036
epoch 58000  clean testing loss: 0.06620408594608307
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 58100  training loss: 0.04834763705730438
epoch 58100  clean testing loss: 0.06631354987621307
epoch 58200  training loss: 0.04833366721868515
epoch 58200  clean testing loss: 0.06637571007013321
epoch 58300  training loss: 0.04832547903060913

 20%|█▉        | 59246/300000 [02:31<07:58, 502.71it/s]
epoch 58400  training loss: 0.04831808805465698
epoch 58400  clean testing loss: 0.06627707928419113
epoch 58500  training loss: 0.04830911010503769
epoch 58500  clean testing loss: 0.06640759855508804
epoch 58600  training loss: 0.04830066114664078
epoch 58600  clean testing loss: 0.06629133969545364
epoch 58700  training loss: 0.04829307645559311
epoch 58700  clean testing loss: 0.0663292333483696
epoch 58800  training loss: 0.04828508943319321
epoch 58800  clean testing loss: 0.06643994897603989
epoch 58900  training loss: 0.0482773594558239
epoch 58900  clean testing loss: 0.0664144903421402
epoch 59000  training loss: 0.04826929420232773
epoch 59000  clean testing loss: 0.06644908338785172
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 59100  training loss: 0.04826080799102783
epoch 59100  clean testing loss: 0.06639637798070908
epoch 59200  training loss: 0.048253681510686874
epoch 59200  clean testing loss: 0.06633219867944717
epoch 59300  training loss: 0.048244889825582504

 20%|██        | 60224/300000 [02:33<07:58, 500.98it/s]
epoch 59400  training loss: 0.04823782667517662
epoch 59400  clean testing loss: 0.06648007035255432
epoch 59500  training loss: 0.048220597207546234
epoch 59500  clean testing loss: 0.06634227186441422
epoch 59600  training loss: 0.048206448554992676
epoch 59600  clean testing loss: 0.06633914262056351
epoch 59700  training loss: 0.04819445684552193
epoch 59700  clean testing loss: 0.0664147213101387
epoch 59800  training loss: 0.048183031380176544
epoch 59800  clean testing loss: 0.06628615409135818
epoch 59900  training loss: 0.04817220941185951
epoch 59900  clean testing loss: 0.06623806804418564
epoch 60000  training loss: 0.04816029965877533
epoch 60000  clean testing loss: 0.06635626405477524
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 60100  training loss: 0.04815158247947693
epoch 60100  clean testing loss: 0.0662870854139328
epoch 60200  training loss: 0.048143282532691956
epoch 60200  clean testing loss: 0.06631259620189667
epoch 60300  training loss: 0.048135075718164444

 20%|██        | 61252/300000 [02:35<07:54, 503.32it/s]
epoch 60400  training loss: 0.048126596957445145
epoch 60400  clean testing loss: 0.0663590133190155
epoch 60500  training loss: 0.04811833053827286
epoch 60500  clean testing loss: 0.0663728192448616
epoch 60600  training loss: 0.04811050742864609
epoch 60600  clean testing loss: 0.06629303097724915
epoch 60700  training loss: 0.04810222238302231
epoch 60700  clean testing loss: 0.06637157499790192
epoch 60800  training loss: 0.04809406399726868
epoch 60800  clean testing loss: 0.0663718432188034
epoch 60900  training loss: 0.04808291047811508
epoch 60900  clean testing loss: 0.0664159506559372
epoch 61000  training loss: 0.048075295984745026
epoch 61000  clean testing loss: 0.06635516881942749
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 61100  training loss: 0.048067644238471985
epoch 61100  clean testing loss: 0.06645630300045013
epoch 61200  training loss: 0.04805980250239372
epoch 61200  clean testing loss: 0.0663825273513794
epoch 61300  training loss: 0.04805230349302292

 21%|██        | 62230/300000 [02:37<07:53, 502.07it/s]
epoch 61400  training loss: 0.04804413765668869
epoch 61400  clean testing loss: 0.0664176195859909
epoch 61500  training loss: 0.04803650081157684
epoch 61500  clean testing loss: 0.06644844263792038
epoch 61600  training loss: 0.048027653247117996
epoch 61600  clean testing loss: 0.06650330126285553
epoch 61700  training loss: 0.04802028089761734
epoch 61700  clean testing loss: 0.06647394597530365
epoch 61800  training loss: 0.0480133555829525
epoch 61800  clean testing loss: 0.06648418307304382
epoch 61900  training loss: 0.04800599813461304
epoch 61900  clean testing loss: 0.06646518409252167
epoch 62000  training loss: 0.047998495399951935
epoch 62000  clean testing loss: 0.06658022105693817
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 62100  training loss: 0.04799086973071098
epoch 62100  clean testing loss: 0.06656602025032043
epoch 62200  training loss: 0.0479837991297245
epoch 62200  clean testing loss: 0.06647077947854996
epoch 62300  training loss: 0.047976408153772354

 21%|██        | 63259/300000 [02:39<07:47, 505.86it/s]
epoch 62400  training loss: 0.04797007888555527
epoch 62400  clean testing loss: 0.06647901982069016
epoch 62500  training loss: 0.04796229302883148
epoch 62500  clean testing loss: 0.06655212491750717
epoch 62600  training loss: 0.0479554757475853
epoch 62600  clean testing loss: 0.06651392579078674
epoch 62700  training loss: 0.047948215156793594
epoch 62700  clean testing loss: 0.06653161346912384
epoch 62800  training loss: 0.04794108867645264
epoch 62800  clean testing loss: 0.06662669777870178
epoch 62900  training loss: 0.0479339137673378
epoch 62900  clean testing loss: 0.0666479617357254
epoch 63000  training loss: 0.04792672023177147
epoch 63000  clean testing loss: 0.06660021841526031
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 63100  training loss: 0.04792071878910065
epoch 63100  clean testing loss: 0.0666208490729332
epoch 63200  training loss: 0.04791488125920296
epoch 63200  clean testing loss: 0.06659917533397675
epoch 63300  training loss: 0.04790904372930527

 21%|██▏       | 64289/300000 [02:41<07:44, 506.91it/s]
epoch 63400  training loss: 0.04790334403514862
epoch 63400  clean testing loss: 0.06668014824390411
epoch 63500  training loss: 0.047897569835186005
epoch 63500  clean testing loss: 0.06668036431074142
epoch 63600  training loss: 0.04789118841290474
epoch 63600  clean testing loss: 0.06667843461036682
epoch 63700  training loss: 0.047885552048683167
epoch 63700  clean testing loss: 0.06665832549333572
epoch 63800  training loss: 0.04787983372807503
epoch 63800  clean testing loss: 0.06662476807832718
epoch 63900  training loss: 0.04787382856011391
epoch 63900  clean testing loss: 0.06664223968982697
epoch 64000  training loss: 0.04786748066544533
epoch 64000  clean testing loss: 0.06671186536550522
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 64100  training loss: 0.04786183312535286
epoch 64100  clean testing loss: 0.06665303558111191
epoch 64200  training loss: 0.04785572364926338
epoch 64200  clean testing loss: 0.06672464311122894
epoch 64300  training loss: 0.04784907028079033

 22%|██▏       | 65261/300000 [02:43<07:48, 501.01it/s]
epoch 64400  training loss: 0.047842662781476974
epoch 64400  clean testing loss: 0.06667422503232956
epoch 64500  training loss: 0.04783644154667854
epoch 64500  clean testing loss: 0.06674560159444809
epoch 64600  training loss: 0.04782984033226967
epoch 64600  clean testing loss: 0.06669598817825317
epoch 64700  training loss: 0.047823838889598846
epoch 64700  clean testing loss: 0.06672224402427673
epoch 64800  training loss: 0.047817621380090714
epoch 64800  clean testing loss: 0.06676855683326721
epoch 64900  training loss: 0.04781121388077736
epoch 64900  clean testing loss: 0.06672368198633194
epoch 65000  training loss: 0.0478048212826252
epoch 65000  clean testing loss: 0.06673342734575272
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 65100  training loss: 0.047798655927181244
epoch 65100  clean testing loss: 0.06672254949808121
epoch 65200  training loss: 0.047792211174964905
epoch 65200  clean testing loss: 0.06671705096960068
epoch 65300  training loss: 0.047786127775907516

 22%|██▏       | 66290/300000 [02:45<07:41, 505.98it/s]
epoch 65400  training loss: 0.04778001457452774
epoch 65400  clean testing loss: 0.0668281838297844
epoch 65500  training loss: 0.04777367413043976
epoch 65500  clean testing loss: 0.06675856560468674
epoch 65600  training loss: 0.047767143696546555
epoch 65600  clean testing loss: 0.06678705662488937
epoch 65700  training loss: 0.04776133969426155
epoch 65700  clean testing loss: 0.06683529913425446
epoch 65800  training loss: 0.047754980623722076
epoch 65800  clean testing loss: 0.06677873432636261
epoch 65900  training loss: 0.04774921014904976
epoch 65900  clean testing loss: 0.06676095724105835
epoch 66000  training loss: 0.04774290323257446
epoch 66000  clean testing loss: 0.0668477937579155
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 66100  training loss: 0.04773753508925438
epoch 66100  clean testing loss: 0.06679879128932953
epoch 66200  training loss: 0.047732576727867126
epoch 66200  clean testing loss: 0.06682423502206802
epoch 66300  training loss: 0.047727957367897034

 22%|██▏       | 67319/300000 [02:47<07:41, 503.75it/s]
epoch 66400  training loss: 0.047722894698381424
epoch 66400  clean testing loss: 0.06684265285730362
epoch 66500  training loss: 0.04771788418292999
epoch 66500  clean testing loss: 0.06682881712913513
epoch 66600  training loss: 0.047713130712509155
epoch 66600  clean testing loss: 0.06682932376861572
epoch 66700  training loss: 0.047708410769701004
epoch 66700  clean testing loss: 0.06685198098421097
epoch 66800  training loss: 0.047703392803668976
epoch 66800  clean testing loss: 0.06688889116048813
epoch 66900  training loss: 0.04769837483763695
epoch 66900  clean testing loss: 0.06690020114183426
epoch 67000  training loss: 0.04769323021173477
epoch 67000  clean testing loss: 0.06687485426664352
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 67100  training loss: 0.04768838733434677
epoch 67100  clean testing loss: 0.06688550859689713
epoch 67200  training loss: 0.047683846205472946
epoch 67200  clean testing loss: 0.06694058328866959
epoch 67300  training loss: 0.04767901822924614

 23%|██▎       | 68245/300000 [02:49<07:40, 503.06it/s]
epoch 67400  training loss: 0.047673776745796204
epoch 67400  clean testing loss: 0.06687206029891968
epoch 67500  training loss: 0.04766872897744179
epoch 67500  clean testing loss: 0.06688562780618668
epoch 67600  training loss: 0.04766400530934334
epoch 67600  clean testing loss: 0.06690993160009384
epoch 67700  training loss: 0.0476587675511837
epoch 67700  clean testing loss: 0.06689908355474472
epoch 67800  training loss: 0.047653742134571075
epoch 67800  clean testing loss: 0.0669548287987709
epoch 67900  training loss: 0.04764902964234352
epoch 67900  clean testing loss: 0.0669068768620491
epoch 68000  training loss: 0.04764343798160553
epoch 68000  clean testing loss: 0.0669357106089592
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 68100  training loss: 0.047636471688747406
epoch 68100  clean testing loss: 0.06691925972700119
epoch 68200  training loss: 0.04762980714440346
epoch 68200  clean testing loss: 0.06689752638339996
epoch 68300  training loss: 0.04762350022792816

 23%|██▎       | 69268/300000 [02:51<07:34, 508.03it/s]
epoch 68400  training loss: 0.04761722683906555
epoch 68400  clean testing loss: 0.06689491868019104
epoch 68500  training loss: 0.04761098697781563
epoch 68500  clean testing loss: 0.0669209286570549
epoch 68600  training loss: 0.04760492220520973
epoch 68600  clean testing loss: 0.06688214838504791
epoch 68700  training loss: 0.04759882763028145
epoch 68700  clean testing loss: 0.06691138446331024
epoch 68800  training loss: 0.04759294539690018
epoch 68800  clean testing loss: 0.06689997762441635
epoch 68900  training loss: 0.04758712276816368
epoch 68900  clean testing loss: 0.06690403074026108
epoch 69000  training loss: 0.0475812628865242
epoch 69000  clean testing loss: 0.06690420210361481
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 69100  training loss: 0.04757644981145859
epoch 69100  clean testing loss: 0.06691400706768036
epoch 69200  training loss: 0.04757184162735939
epoch 69200  clean testing loss: 0.06698549538850784
epoch 69300  training loss: 0.047567177563905716

 23%|██▎       | 70297/300000 [02:53<07:32, 507.51it/s]
epoch 69400  training loss: 0.0475623793900013
epoch 69400  clean testing loss: 0.06695059686899185
epoch 69500  training loss: 0.04755793884396553
epoch 69500  clean testing loss: 0.06697344034910202
epoch 69600  training loss: 0.04755306988954544
epoch 69600  clean testing loss: 0.06697387993335724
epoch 69700  training loss: 0.04754842072725296
epoch 69700  clean testing loss: 0.06696005910634995
epoch 69800  training loss: 0.04754418879747391
epoch 69800  clean testing loss: 0.06693503260612488
epoch 69900  training loss: 0.047538865357637405
epoch 69900  clean testing loss: 0.06696521490812302
epoch 70000  training loss: 0.04753434658050537
epoch 70000  clean testing loss: 0.06698976457118988
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...
epoch 70100  training loss: 0.04752965644001961
epoch 70100  clean testing loss: 0.0670008435845375
epoch 70200  training loss: 0.04752491042017937
epoch 70200  clean testing loss: 0.06696861237287521
epoch 70300  training loss: 0.047520313411951065

 24%|██▎       | 70500/300000 [02:54<09:27, 404.63it/s]
epoch 70400  training loss: 0.04751553386449814
epoch 70400  clean testing loss: 0.0670119896531105
epoch 70500  training loss: 0.04751087725162506
epoch 70500  clean testing loss: 0.06702081859111786
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0 ...