epoch 0  training loss: 0.5262497663497925
epoch 0  clean testing loss: 0.6484571695327759
  1%|▍                                                                                 | 505/100000 [00:02<06:47, 244.45it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 100  training loss: 0.05827391892671585
epoch 100  clean testing loss: 0.05326499789953232
epoch 200  training loss: 0.035807717591524124
epoch 200  clean testing loss: 0.04882657900452614
epoch 300  training loss: 0.026414569467306137
epoch 300  clean testing loss: 0.02676849439740181
epoch 400  training loss: 0.045562975108623505
epoch 400  clean testing loss: 0.03964357450604439
epoch 500  training loss: 0.031643252819776535
epoch 500  clean testing loss: 0.03274167701601982
epoch 600  training loss: 0.023978302255272865
epoch 600  clean testing loss: 0.02459832653403282
epoch 700  training loss: 0.02144147828221321
epoch 700  clean testing loss: 0.022019771859049797
epoch 800  training loss: 0.03962590917944908

  1%|▋                                                                                 | 882/100000 [00:03<06:49, 242.10it/s]
epoch 900  training loss: 0.027713360264897346
epoch 900  clean testing loss: 0.026181630790233612
epoch 1000  training loss: 0.037184443324804306
epoch 1000  clean testing loss: 0.03808775916695595
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 1100  training loss: 0.018988318741321564
epoch 1100  clean testing loss: 0.021121611818671227
epoch 1200  training loss: 0.018214840441942215
epoch 1200  clean testing loss: 0.020252585411071777
epoch 1300  training loss: 0.020858384668827057

  1%|█                                                                                | 1363/100000 [00:05<06:46, 242.90it/s]
epoch 1400  training loss: 0.01676192507147789
epoch 1400  clean testing loss: 0.020092865452170372
epoch 1500  training loss: 0.015122510492801666
epoch 1500  clean testing loss: 0.01833433471620083
epoch 1600  training loss: 0.014645525254309177
epoch 1600  clean testing loss: 0.01776982471346855
epoch 1700  training loss: 0.015781769528985023
epoch 1700  clean testing loss: 0.018314151093363762
epoch 1800  training loss: 0.018446557223796844

  2%|█▍                                                                               | 1836/100000 [00:07<06:51, 238.59it/s]
epoch 1900  training loss: 0.05485823005437851
epoch 1900  clean testing loss: 0.0462447851896286
epoch 2000  training loss: 0.02761034108698368
epoch 2000  clean testing loss: 0.02647830732166767
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 2100  training loss: 0.022700970992445946
epoch 2100  clean testing loss: 0.030925363302230835
epoch 2200  training loss: 0.01574498414993286
epoch 2200  clean testing loss: 0.01874813251197338
epoch 2300  training loss: 0.014644368551671505

  2%|█▉                                                                               | 2315/100000 [00:09<06:42, 242.65it/s]
epoch 2400  training loss: 0.014282291755080223
epoch 2400  clean testing loss: 0.01739971898496151
epoch 2500  training loss: 0.015437735244631767
epoch 2500  clean testing loss: 0.018239213153719902
epoch 2600  training loss: 0.03729294240474701
epoch 2600  clean testing loss: 0.04247085005044937
epoch 2700  training loss: 0.01845049299299717
epoch 2700  clean testing loss: 0.02346176654100418
epoch 2800  training loss: 0.01555247139185667

  3%|██▎                                                                              | 2819/100000 [00:11<06:39, 243.29it/s]
epoch 2900  training loss: 0.014632407575845718
epoch 2900  clean testing loss: 0.018490750342607498
epoch 3000  training loss: 0.014249619096517563
epoch 3000  clean testing loss: 0.017674438655376434
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 3100  training loss: 0.01376473531126976
epoch 3100  clean testing loss: 0.017040787264704704
epoch 3200  training loss: 0.013630894012749195
epoch 3200  clean testing loss: 0.01669885963201523
epoch 3300  training loss: 0.013428873382508755

  3%|██▋                                                                              | 3301/100000 [00:13<06:29, 248.37it/s]
epoch 3400  training loss: 0.013744774274528027
epoch 3400  clean testing loss: 0.01689167134463787
epoch 3500  training loss: 0.013637542724609375
epoch 3500  clean testing loss: 0.016650481149554253
epoch 3600  training loss: 0.01353668887168169
epoch 3600  clean testing loss: 0.01656290888786316
epoch 3700  training loss: 0.013383440673351288

  4%|███                                                                              | 3782/100000 [00:15<06:26, 249.08it/s]
epoch 3800  training loss: 0.06768935173749924
epoch 3800  clean testing loss: 0.08034837990999222
epoch 3900  training loss: 0.0413735993206501
epoch 3900  clean testing loss: 0.037004679441452026
epoch 4000  training loss: 0.029251515865325928
epoch 4000  clean testing loss: 0.028736870735883713
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 4100  training loss: 0.020510230213403702
epoch 4100  clean testing loss: 0.022729406133294106
epoch 4200  training loss: 0.017906028777360916

  4%|███▍                                                                             | 4289/100000 [00:17<06:29, 245.89it/s]
epoch 4300  training loss: 0.0161664430052042
epoch 4300  clean testing loss: 0.019773777574300766
epoch 4400  training loss: 0.016294175758957863
epoch 4400  clean testing loss: 0.019921788945794106
epoch 4500  training loss: 0.015102662146091461
epoch 4500  clean testing loss: 0.018334660679101944
epoch 4600  training loss: 0.014731594361364841
epoch 4600  clean testing loss: 0.01802441105246544
epoch 4700  training loss: 0.014504706487059593

  5%|███▊                                                                             | 4772/100000 [00:19<06:34, 241.26it/s]
epoch 4800  training loss: 0.015417727641761303
epoch 4800  clean testing loss: 0.018696816638112068
epoch 4900  training loss: 0.027508080005645752
epoch 4900  clean testing loss: 0.055876389145851135
epoch 5000  training loss: 0.01985223777592182
epoch 5000  clean testing loss: 0.021727798506617546
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 5100  training loss: 0.015471075661480427
epoch 5100  clean testing loss: 0.018490899354219437
epoch 5200  training loss: 0.014605186879634857

  5%|████▎                                                                            | 5250/100000 [00:21<06:37, 238.36it/s]
epoch 5300  training loss: 0.01437277439981699
epoch 5300  clean testing loss: 0.0173652246594429
epoch 5400  training loss: 0.01421862281858921
epoch 5400  clean testing loss: 0.017482036724686623
epoch 5500  training loss: 0.014388324692845345
epoch 5500  clean testing loss: 0.017650939524173737
epoch 5600  training loss: 0.016805849969387054
epoch 5600  clean testing loss: 0.018111031502485275
epoch 5700  training loss: 0.016697853803634644

  6%|████▋                                                                            | 5731/100000 [00:23<06:24, 245.38it/s]
epoch 5800  training loss: 0.013950501568615437
epoch 5800  clean testing loss: 0.01700398325920105
epoch 5900  training loss: 0.013991349376738071
epoch 5900  clean testing loss: 0.016756756231188774
epoch 6000  training loss: 0.013545370660722256
epoch 6000  clean testing loss: 0.01653345860540867
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 6100  training loss: 0.013488263823091984
epoch 6100  clean testing loss: 0.016486136242747307
epoch 6200  training loss: 0.013466632924973965

  6%|█████                                                                            | 6237/100000 [00:25<06:16, 248.82it/s]
epoch 6300  training loss: 0.01336593460291624
epoch 6300  clean testing loss: 0.01636751927435398
epoch 6400  training loss: 0.014231586828827858
epoch 6400  clean testing loss: 0.017115173861384392
epoch 6500  training loss: 0.01332199014723301
epoch 6500  clean testing loss: 0.016313061118125916
epoch 6600  training loss: 0.01349111832678318
epoch 6600  clean testing loss: 0.016422830522060394
epoch 6700  training loss: 0.013344286940991879

  7%|█████▍                                                                           | 6722/100000 [00:27<06:19, 245.93it/s]
epoch 6800  training loss: 0.014415882527828217
epoch 6800  clean testing loss: 0.017328182235360146
epoch 6900  training loss: 0.013984761200845242
epoch 6900  clean testing loss: 0.016585081815719604
epoch 7000  training loss: 0.013546173460781574
epoch 7000  clean testing loss: 0.016714908182621002
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 7100  training loss: 0.014026947319507599

  7%|█████▊                                                                           | 7203/100000 [00:29<06:19, 244.53it/s]
epoch 7200  training loss: 0.01396289374679327
epoch 7200  clean testing loss: 0.0171943511813879
epoch 7300  training loss: 0.018130876123905182
epoch 7300  clean testing loss: 0.02032642625272274
epoch 7400  training loss: 0.013992436230182648
epoch 7400  clean testing loss: 0.016946380957961082
epoch 7500  training loss: 0.013607651926577091
epoch 7500  clean testing loss: 0.016580989584326744
epoch 7600  training loss: 0.01349844504147768

  8%|██████▏                                                                          | 7683/100000 [00:31<06:14, 246.27it/s]
epoch 7700  training loss: 0.013409005478024483
epoch 7700  clean testing loss: 0.016365407034754753
epoch 7800  training loss: 0.013348611071705818
epoch 7800  clean testing loss: 0.01631784439086914
epoch 7900  training loss: 0.013622891157865524
epoch 7900  clean testing loss: 0.016649262979626656
epoch 8000  training loss: 0.013722998090088367
epoch 8000  clean testing loss: 0.016625355929136276
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 8100  training loss: 0.013344348408281803

  8%|██████▌                                                                          | 8164/100000 [00:33<06:20, 241.20it/s]
epoch 8200  training loss: 0.013320350088179111
epoch 8200  clean testing loss: 0.016281025484204292
epoch 8300  training loss: 0.014466004446148872
epoch 8300  clean testing loss: 0.01767411269247532
epoch 8400  training loss: 0.01502522174268961
epoch 8400  clean testing loss: 0.01911468245089054
epoch 8500  training loss: 0.01360518392175436
epoch 8500  clean testing loss: 0.016532819718122482
epoch 8600  training loss: 0.013430912978947163


  9%|███████▍                                                                         | 9153/100000 [00:37<06:15, 241.76it/s]
epoch 8700  training loss: 0.013368027284741402
epoch 8700  clean testing loss: 0.01628781482577324
epoch 8800  training loss: 0.013327774591743946
epoch 8800  clean testing loss: 0.016256382688879967
epoch 8900  training loss: 0.013394074514508247
epoch 8900  clean testing loss: 0.016261601820588112
epoch 9000  training loss: 0.013543245382606983
epoch 9000  clean testing loss: 0.01633823849260807
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 9100  training loss: 0.013256224803626537

 10%|███████▊                                                                         | 9630/100000 [00:39<06:15, 240.64it/s]
epoch 9200  training loss: 0.013239763677120209
epoch 9200  clean testing loss: 0.016158021986484528
epoch 9300  training loss: 0.013252447359263897
epoch 9300  clean testing loss: 0.01617470383644104
epoch 9400  training loss: 0.013307358138263226
epoch 9400  clean testing loss: 0.01620255410671234
epoch 9500  training loss: 0.013879670761525631
epoch 9500  clean testing loss: 0.01637549325823784
epoch 9600  training loss: 0.013315653428435326

 10%|████████                                                                        | 10111/100000 [00:41<06:13, 240.84it/s]
epoch 9700  training loss: 0.013482323847711086
epoch 9700  clean testing loss: 0.016399197280406952
epoch 9800  training loss: 0.013282012194395065
epoch 9800  clean testing loss: 0.01617315784096718
epoch 9900  training loss: 0.01341990940272808
epoch 9900  clean testing loss: 0.01624373532831669
epoch 10000  training loss: 0.017609039321541786
epoch 10000  clean testing loss: 0.018878208473324776
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 10100  training loss: 0.013743596151471138
epoch 10100  clean testing loss: 0.016665402799844742
epoch 10200  training loss: 0.013430639170110226
epoch 10200  clean testing loss: 0.016330793499946594
epoch 10300  training loss: 0.013348216190934181
epoch 10300  clean testing loss: 0.016247449442744255
epoch 10400  training loss: 0.013309192843735218
epoch 10400  clean testing loss: 0.016223175451159477
epoch 10500  training loss: 0.013274354860186577

 11%|████████▍                                                                       | 10613/100000 [00:43<06:15, 238.08it/s]
epoch 10600  training loss: 0.013291258364915848
epoch 10600  clean testing loss: 0.016180148348212242
epoch 10700  training loss: 0.013495054095983505
epoch 10700  clean testing loss: 0.016340190544724464
epoch 10800  training loss: 0.013287103734910488
epoch 10800  clean testing loss: 0.016261599957942963
epoch 10900  training loss: 0.013300918973982334
epoch 10900  clean testing loss: 0.016194680705666542
epoch 11000  training loss: 0.013331680558621883
epoch 11000  clean testing loss: 0.016273528337478638

 11%|████████▊                                                                       | 11093/100000 [00:45<06:09, 240.78it/s]
epoch 11100  training loss: 0.013385599479079247
epoch 11100  clean testing loss: 0.016728268936276436
epoch 11200  training loss: 0.013716640882194042
epoch 11200  clean testing loss: 0.016447898000478745
epoch 11300  training loss: 0.013340603560209274
epoch 11300  clean testing loss: 0.01624169573187828
epoch 11400  training loss: 0.013280878774821758
epoch 11400  clean testing loss: 0.01618112623691559
epoch 11500  training loss: 0.013259941712021828


 12%|█████████▋                                                                      | 12053/100000 [00:49<06:05, 240.29it/s]
epoch 11600  training loss: 0.013266997411847115
epoch 11600  clean testing loss: 0.016194676980376244
epoch 11700  training loss: 0.013921057805418968
epoch 11700  clean testing loss: 0.01696263626217842
epoch 11800  training loss: 0.013820805586874485
epoch 11800  clean testing loss: 0.016802070662379265
epoch 11900  training loss: 0.015172827057540417
epoch 11900  clean testing loss: 0.016915546730160713
epoch 12000  training loss: 0.013362736441195011
epoch 12000  clean testing loss: 0.01627533510327339

 13%|██████████                                                                      | 12570/100000 [00:51<05:57, 244.27it/s]
epoch 12100  training loss: 0.013267558068037033
epoch 12100  clean testing loss: 0.016161032021045685
epoch 12200  training loss: 0.013235910795629025
epoch 12200  clean testing loss: 0.016129136085510254
epoch 12300  training loss: 0.013224324211478233
epoch 12300  clean testing loss: 0.01611422561109066
epoch 12400  training loss: 0.0132018206641078
epoch 12400  clean testing loss: 0.016098255291581154
epoch 12500  training loss: 0.013195929117500782

 13%|██████████▍                                                                     | 13052/100000 [00:53<06:00, 241.08it/s]
epoch 12600  training loss: 0.013183718547224998
epoch 12600  clean testing loss: 0.01606736145913601
epoch 12700  training loss: 0.013203006237745285
epoch 12700  clean testing loss: 0.0160983894020319
epoch 12800  training loss: 0.013442574068903923
epoch 12800  clean testing loss: 0.01646648533642292
epoch 12900  training loss: 0.013224522583186626
epoch 12900  clean testing loss: 0.01703304424881935
epoch 13000  training loss: 0.013196849264204502
epoch 13000  clean testing loss: 0.016090793535113335

 14%|██████████▊                                                                     | 13530/100000 [00:55<06:00, 239.94it/s]
epoch 13100  training loss: 0.013178948312997818
epoch 13100  clean testing loss: 0.016076942905783653
epoch 13200  training loss: 0.013273567892611027
epoch 13200  clean testing loss: 0.016242962330579758
epoch 13300  training loss: 0.013331838883459568
epoch 13300  clean testing loss: 0.016147661954164505
epoch 13400  training loss: 0.013230995275080204
epoch 13400  clean testing loss: 0.01613222248852253
epoch 13500  training loss: 0.013250389136373997

 14%|███████████▏                                                                    | 14011/100000 [00:57<05:59, 239.13it/s]
epoch 13600  training loss: 0.013194293715059757
epoch 13600  clean testing loss: 0.016111889854073524
epoch 13700  training loss: 0.0135194668546319
epoch 13700  clean testing loss: 0.016511380672454834
epoch 13800  training loss: 0.013342877849936485
epoch 13800  clean testing loss: 0.016215207055211067
epoch 13900  training loss: 0.013504572212696075
epoch 13900  clean testing loss: 0.01638827659189701
epoch 14000  training loss: 0.013218109495937824
epoch 14000  clean testing loss: 0.01614685170352459

 14%|███████████▌                                                                    | 14491/100000 [00:59<05:51, 242.98it/s]
epoch 14100  training loss: 0.01319348905235529
epoch 14100  clean testing loss: 0.016082139685750008
epoch 14200  training loss: 0.013383008539676666
epoch 14200  clean testing loss: 0.016309883445501328
epoch 14300  training loss: 0.013476042076945305
epoch 14300  clean testing loss: 0.016327638179063797
epoch 14400  training loss: 0.01319579966366291

 15%|████████████                                                                    | 15000/100000 [01:01<05:48, 243.94it/s]
epoch 14500  training loss: 0.013356790877878666
epoch 14500  clean testing loss: 0.016301024705171585
epoch 14600  training loss: 0.013234151527285576
epoch 14600  clean testing loss: 0.016112476587295532
epoch 14700  training loss: 0.013286967761814594
epoch 14700  clean testing loss: 0.016268247738480568
epoch 14800  training loss: 0.013313699513673782
epoch 14800  clean testing loss: 0.01620618626475334
epoch 14900  training loss: 0.013436334207654

 16%|████████████▍                                                                   | 15570/100000 [01:03<04:23, 319.95it/s]
epoch 15000  training loss: 0.013350188732147217
epoch 15000  clean testing loss: 0.01608632318675518
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 15100  training loss: 0.013155079446732998
epoch 15100  clean testing loss: 0.01603393629193306
epoch 15200  training loss: 0.013142656534910202
epoch 15200  clean testing loss: 0.016018535941839218
epoch 15300  training loss: 0.013140078634023666
epoch 15300  clean testing loss: 0.016016336157917976
epoch 15400  training loss: 0.013713707216084003
epoch 15400  clean testing loss: 0.016388684511184692
epoch 15500  training loss: 0.01323173101991415

 16%|████████████▉                                                                   | 16226/100000 [01:05<04:24, 316.85it/s]
epoch 15600  training loss: 0.013219793327152729
epoch 15600  clean testing loss: 0.016046570613980293
epoch 15700  training loss: 0.013151226565241814
epoch 15700  clean testing loss: 0.01603107899427414
epoch 15800  training loss: 0.01322129461914301
epoch 15800  clean testing loss: 0.0161467082798481
epoch 15900  training loss: 0.013444440439343452
epoch 15900  clean testing loss: 0.016377892345190048
epoch 16000  training loss: 0.013277659192681313
epoch 16000  clean testing loss: 0.01613117754459381
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 16100  training loss: 0.01322792749851942

 17%|█████████████▍                                                                  | 16852/100000 [01:07<04:18, 321.16it/s]
epoch 16200  training loss: 0.013439139351248741
epoch 16200  clean testing loss: 0.016231218352913857
epoch 16300  training loss: 0.013181405141949654
epoch 16300  clean testing loss: 0.01610894501209259
epoch 16400  training loss: 0.013174549676477909
epoch 16400  clean testing loss: 0.016030635684728622
epoch 16500  training loss: 0.013154357671737671
epoch 16500  clean testing loss: 0.016026662662625313
epoch 16600  training loss: 0.013158583082258701
epoch 16600  clean testing loss: 0.016024643555283546
epoch 16700  training loss: 0.013208975084125996
epoch 16700  clean testing loss: 0.016087094321846962
epoch 16800  training loss: 0.013437751680612564

 18%|██████████████                                                                  | 17509/100000 [01:10<04:16, 321.27it/s]
epoch 16900  training loss: 0.013142379932105541
epoch 16900  clean testing loss: 0.016004370525479317
epoch 17000  training loss: 0.013196209445595741
epoch 17000  clean testing loss: 0.016068464145064354
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 17100  training loss: 0.013168279081583023
epoch 17100  clean testing loss: 0.016021283343434334
epoch 17200  training loss: 0.013184038922190666
epoch 17200  clean testing loss: 0.01603507064282894
epoch 17300  training loss: 0.013176706619560719
epoch 17300  clean testing loss: 0.01607350818812847
epoch 17400  training loss: 0.013524986803531647

 18%|██████████████▌                                                                 | 18136/100000 [01:11<04:15, 320.17it/s]
epoch 17500  training loss: 0.013161114417016506
epoch 17500  clean testing loss: 0.016038818284869194
epoch 17600  training loss: 0.013286362402141094
epoch 17600  clean testing loss: 0.016078008338809013
epoch 17700  training loss: 0.013316234573721886
epoch 17700  clean testing loss: 0.016225919127464294
epoch 17800  training loss: 0.013183781877160072
epoch 17800  clean testing loss: 0.01607527770102024
epoch 17900  training loss: 0.013166544958949089
epoch 17900  clean testing loss: 0.016038166359066963
epoch 18000  training loss: 0.013272074051201344
epoch 18000  clean testing loss: 0.016056491062045097
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 18100  training loss: 0.01312820054590702

 19%|███████████████                                                                 | 18795/100000 [01:14<04:12, 322.06it/s]
epoch 18200  training loss: 0.0131271006539464
epoch 18200  clean testing loss: 0.01599489338696003
epoch 18300  training loss: 0.013113670982420444
epoch 18300  clean testing loss: 0.015981977805495262
epoch 18400  training loss: 0.013174586929380894
epoch 18400  clean testing loss: 0.016034692525863647
epoch 18500  training loss: 0.013269158080220222
epoch 18500  clean testing loss: 0.016157008707523346
epoch 18600  training loss: 0.01313740760087967
epoch 18600  clean testing loss: 0.015994004905223846
epoch 18700  training loss: 0.01314592082053423

 19%|███████████████▌                                                                | 19422/100000 [01:15<04:11, 320.13it/s]
epoch 18800  training loss: 0.013134780339896679
epoch 18800  clean testing loss: 0.0160035640001297
epoch 18900  training loss: 0.013145878911018372
epoch 18900  clean testing loss: 0.016017897054553032
epoch 19000  training loss: 0.013229315169155598
epoch 19000  clean testing loss: 0.016053447499871254
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 19100  training loss: 0.01318602915853262
epoch 19100  clean testing loss: 0.016045918688178062
epoch 19200  training loss: 0.013294716365635395
epoch 19200  clean testing loss: 0.01612151600420475
epoch 19300  training loss: 0.013128205202519894
epoch 19300  clean testing loss: 0.015990648418664932
epoch 19400  training loss: 0.013131079263985157

 20%|████████████████                                                                | 20082/100000 [01:18<04:10, 319.10it/s]
epoch 19500  training loss: 0.013196497224271297
epoch 19500  clean testing loss: 0.016034066677093506
epoch 19600  training loss: 0.013154560700058937
epoch 19600  clean testing loss: 0.015999386087059975
epoch 19700  training loss: 0.013156176544725895
epoch 19700  clean testing loss: 0.01603076234459877
epoch 19800  training loss: 0.013127559795975685
epoch 19800  clean testing loss: 0.015991205349564552
epoch 19900  training loss: 0.013131477870047092
epoch 19900  clean testing loss: 0.015985198318958282
epoch 20000  training loss: 0.013168522156774998
epoch 20000  clean testing loss: 0.016000600531697273

 21%|████████████████▌                                                               | 20708/100000 [01:19<04:07, 320.91it/s]
epoch 20100  training loss: 0.013158733956515789
epoch 20100  clean testing loss: 0.016091497614979744
epoch 20200  training loss: 0.013820873573422432
epoch 20200  clean testing loss: 0.01651354320347309
epoch 20300  training loss: 0.013156893663108349
epoch 20300  clean testing loss: 0.015998249873518944
epoch 20400  training loss: 0.013376575894653797
epoch 20400  clean testing loss: 0.016248201951384544
epoch 20500  training loss: 0.013176959939301014
epoch 20500  clean testing loss: 0.016018349677324295
epoch 20600  training loss: 0.01330295205116272

 21%|█████████████████                                                               | 21368/100000 [01:22<04:04, 321.21it/s]
epoch 20700  training loss: 0.013164776377379894
epoch 20700  clean testing loss: 0.016024243086576462
epoch 20800  training loss: 0.013183209113776684
epoch 20800  clean testing loss: 0.016004955396056175
epoch 20900  training loss: 0.013195250183343887
epoch 20900  clean testing loss: 0.016001857817173004
epoch 21000  training loss: 0.013174881227314472
epoch 21000  clean testing loss: 0.015999840572476387
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 21100  training loss: 0.013104096055030823
epoch 21100  clean testing loss: 0.01595735363662243
epoch 21200  training loss: 0.013097156770527363
epoch 21200  clean testing loss: 0.015953578054904938
epoch 21300  training loss: 0.013095768168568611

 22%|█████████████████▌                                                              | 21995/100000 [01:23<04:03, 320.71it/s]
epoch 21400  training loss: 0.013130729086697102
epoch 21400  clean testing loss: 0.01599397510290146
epoch 21500  training loss: 0.013236816972494125
epoch 21500  clean testing loss: 0.01609147898852825
epoch 21600  training loss: 0.013139298185706139
epoch 21600  clean testing loss: 0.015998639166355133
epoch 21700  training loss: 0.013117133639752865
epoch 21700  clean testing loss: 0.015973210334777832
epoch 21800  training loss: 0.01360398717224598
epoch 21800  clean testing loss: 0.016391882672905922
epoch 21900  training loss: 0.013247959315776825

 23%|██████████████████                                                              | 22653/100000 [01:26<04:01, 320.04it/s]
epoch 22000  training loss: 0.01315340492874384
epoch 22000  clean testing loss: 0.016007693484425545
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 22100  training loss: 0.013155887834727764
epoch 22100  clean testing loss: 0.016008077189326286
epoch 22200  training loss: 0.013112523593008518
epoch 22200  clean testing loss: 0.01597556099295616
epoch 22300  training loss: 0.013124718330800533
epoch 22300  clean testing loss: 0.015993785113096237
epoch 22400  training loss: 0.013285658322274685
epoch 22400  clean testing loss: 0.016173623502254486
epoch 22500  training loss: 0.013128718361258507
epoch 22500  clean testing loss: 0.015986695885658264
epoch 22600  training loss: 0.013266404159367085

 23%|██████████████████▋                                                             | 23312/100000 [01:28<03:58, 321.91it/s]
epoch 22700  training loss: 0.013138609007000923
epoch 22700  clean testing loss: 0.01599891297519207
epoch 22800  training loss: 0.013102001510560513
epoch 22800  clean testing loss: 0.015958670526742935
epoch 22900  training loss: 0.013239645399153233
epoch 22900  clean testing loss: 0.016047809273004532
epoch 23000  training loss: 0.013089832849800587
epoch 23000  clean testing loss: 0.015939312055706978
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 23100  training loss: 0.013356754556298256
epoch 23100  clean testing loss: 0.01624399982392788
epoch 23200  training loss: 0.0131377587094903

 24%|███████████████████▏                                                            | 23939/100000 [01:30<03:56, 321.72it/s]
epoch 23300  training loss: 0.013166903518140316
epoch 23300  clean testing loss: 0.016028359532356262
epoch 23400  training loss: 0.013102955184876919
epoch 23400  clean testing loss: 0.015969131141901016
epoch 23500  training loss: 0.013098068535327911
epoch 23500  clean testing loss: 0.01596451923251152
epoch 23600  training loss: 0.013077273033559322
epoch 23600  clean testing loss: 0.015928080305457115
epoch 23700  training loss: 0.01307996641844511
epoch 23700  clean testing loss: 0.015950411558151245
epoch 23800  training loss: 0.013174023479223251
epoch 23800  clean testing loss: 0.016018269583582878
epoch 23900  training loss: 0.013095318339765072

 25%|███████████████████▋                                                            | 24597/100000 [01:32<03:55, 320.38it/s]
epoch 24000  training loss: 0.01312213484197855
epoch 24000  clean testing loss: 0.015940293669700623
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 24100  training loss: 0.01305431593209505
epoch 24100  clean testing loss: 0.015909496694803238
epoch 24200  training loss: 0.01304845605045557
epoch 24200  clean testing loss: 0.015896521508693695
epoch 24300  training loss: 0.013043266721069813
epoch 24300  clean testing loss: 0.015895245596766472
epoch 24400  training loss: 0.013050743378698826
epoch 24400  clean testing loss: 0.01589910127222538
epoch 24500  training loss: 0.013155592605471611

 25%|████████████████████▏                                                           | 25222/100000 [01:34<03:54, 319.10it/s]
epoch 24600  training loss: 0.013065018691122532
epoch 24600  clean testing loss: 0.015921877697110176
epoch 24700  training loss: 0.01319807581603527
epoch 24700  clean testing loss: 0.016036320477724075
epoch 24800  training loss: 0.013048088178038597
epoch 24800  clean testing loss: 0.01589905470609665
epoch 24900  training loss: 0.013123282231390476
epoch 24900  clean testing loss: 0.01599937118589878
epoch 25000  training loss: 0.013053203001618385
epoch 25000  clean testing loss: 0.01590648666024208
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 25100  training loss: 0.013090879656374454

 26%|████████████████████▋                                                           | 25882/100000 [01:36<03:51, 320.45it/s]
epoch 25200  training loss: 0.013056300580501556
epoch 25200  clean testing loss: 0.0159276332706213
epoch 25300  training loss: 0.013070202432572842
epoch 25300  clean testing loss: 0.01592697948217392
epoch 25400  training loss: 0.013028458692133427
epoch 25400  clean testing loss: 0.015876054763793945
epoch 25500  training loss: 0.013103273697197437
epoch 25500  clean testing loss: 0.015955856069922447
epoch 25600  training loss: 0.01302327774465084
epoch 25600  clean testing loss: 0.015884941443800926
epoch 25700  training loss: 0.013106049038469791
epoch 25700  clean testing loss: 0.015960298478603363
epoch 25800  training loss: 0.013120193965733051

 27%|█████████████████████▏                                                          | 26508/100000 [01:38<03:48, 321.97it/s]
epoch 25900  training loss: 0.013074693270027637
epoch 25900  clean testing loss: 0.015913603827357292
epoch 26000  training loss: 0.013055023737251759
epoch 26000  clean testing loss: 0.015917092561721802
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 26100  training loss: 0.013100272044539452
epoch 26100  clean testing loss: 0.01594635099172592
epoch 26200  training loss: 0.013026433065533638
epoch 26200  clean testing loss: 0.015847375616431236
epoch 26300  training loss: 0.013088444247841835
epoch 26300  clean testing loss: 0.015952402725815773
epoch 26400  training loss: 0.013014843687415123

 27%|█████████████████████▋                                                          | 27166/100000 [01:40<03:46, 321.04it/s]
epoch 26500  training loss: 0.013041340745985508
epoch 26500  clean testing loss: 0.015867670997977257
epoch 26600  training loss: 0.01310250535607338
epoch 26600  clean testing loss: 0.015953168272972107
epoch 26700  training loss: 0.013087647967040539
epoch 26700  clean testing loss: 0.015980513766407967
epoch 26800  training loss: 0.013001110404729843
epoch 26800  clean testing loss: 0.01585414819419384
epoch 26900  training loss: 0.013060501776635647
epoch 26900  clean testing loss: 0.015865348279476166
epoch 27000  training loss: 0.013043095357716084
epoch 27000  clean testing loss: 0.01582292467355728
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 27100  training loss: 0.012957832776010036

 28%|██████████████████████▏                                                         | 27793/100000 [01:42<03:45, 320.02it/s]
epoch 27200  training loss: 0.012951944023370743
epoch 27200  clean testing loss: 0.01579241454601288
epoch 27300  training loss: 0.01294633187353611
epoch 27300  clean testing loss: 0.015771258622407913
epoch 27400  training loss: 0.012943043373525143
epoch 27400  clean testing loss: 0.015781613066792488
epoch 27500  training loss: 0.01294270996004343
epoch 27500  clean testing loss: 0.015771780163049698
epoch 27600  training loss: 0.01294290367513895
epoch 27600  clean testing loss: 0.01576683111488819
epoch 27700  training loss: 0.01295416709035635

 28%|██████████████████████▊                                                         | 28446/100000 [01:44<03:41, 322.52it/s]
epoch 27800  training loss: 0.012960401363670826
epoch 27800  clean testing loss: 0.015796152874827385
epoch 27900  training loss: 0.012951425276696682
epoch 27900  clean testing loss: 0.01576937921345234
epoch 28000  training loss: 0.012961681932210922
epoch 28000  clean testing loss: 0.015798691660165787
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 28100  training loss: 0.012926219962537289
epoch 28100  clean testing loss: 0.01575193554162979
epoch 28200  training loss: 0.012924471870064735
epoch 28200  clean testing loss: 0.015750566497445107
epoch 28300  training loss: 0.012927929870784283

 29%|███████████████████████▎                                                        | 29073/100000 [01:46<03:40, 320.98it/s]
epoch 28400  training loss: 0.01291901059448719
epoch 28400  clean testing loss: 0.015748703852295876
epoch 28500  training loss: 0.012927916832268238
epoch 28500  clean testing loss: 0.015753021463751793
epoch 28600  training loss: 0.012921345420181751
epoch 28600  clean testing loss: 0.01572752743959427
epoch 28700  training loss: 0.012924177572131157
epoch 28700  clean testing loss: 0.015728501603007317
epoch 28800  training loss: 0.012976139783859253
epoch 28800  clean testing loss: 0.015780257061123848
epoch 28900  training loss: 0.012929010204970837
epoch 28900  clean testing loss: 0.015755273401737213
epoch 29000  training loss: 0.012953436933457851
epoch 29000  clean testing loss: 0.01577203907072544

 30%|███████████████████████▊                                                        | 29733/100000 [01:48<03:38, 321.90it/s]
epoch 29100  training loss: 0.012895481660962105
epoch 29100  clean testing loss: 0.015709521248936653
epoch 29200  training loss: 0.012952403165400028
epoch 29200  clean testing loss: 0.015760401263833046
epoch 29300  training loss: 0.012885717675089836
epoch 29300  clean testing loss: 0.015695560723543167
epoch 29400  training loss: 0.013033924624323845
epoch 29400  clean testing loss: 0.0158456452190876
epoch 29500  training loss: 0.012887144461274147
epoch 29500  clean testing loss: 0.01568923331797123
epoch 29600  training loss: 0.012923001311719418

 30%|████████████████████████▎                                                       | 30389/100000 [01:50<03:37, 320.36it/s]
epoch 29700  training loss: 0.012877573259174824
epoch 29700  clean testing loss: 0.01569903828203678
epoch 29800  training loss: 0.012871576473116875
epoch 29800  clean testing loss: 0.01567438617348671
epoch 29900  training loss: 0.012890384532511234
epoch 29900  clean testing loss: 0.015704572200775146
epoch 30000  training loss: 0.012926898896694183
epoch 30000  clean testing loss: 0.015686234459280968
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 30100  training loss: 0.012855879962444305
epoch 30100  clean testing loss: 0.01565183326601982
epoch 30200  training loss: 0.012851664796471596
epoch 30200  clean testing loss: 0.0156675036996603
epoch 30300  training loss: 0.012849775142967701

 31%|████████████████████████▊                                                       | 31017/100000 [01:52<03:37, 316.49it/s]
epoch 30400  training loss: 0.01285564061254263
epoch 30400  clean testing loss: 0.015652306377887726
epoch 30500  training loss: 0.012854663655161858
epoch 30500  clean testing loss: 0.015674052760004997
epoch 30600  training loss: 0.012845742516219616
epoch 30600  clean testing loss: 0.015648599714040756
epoch 30700  training loss: 0.012847727164626122
epoch 30700  clean testing loss: 0.015662891790270805
epoch 30800  training loss: 0.01286299992352724
epoch 30800  clean testing loss: 0.015671847388148308
epoch 30900  training loss: 0.012841278687119484

 32%|█████████████████████████▎                                                      | 31673/100000 [01:54<03:33, 319.69it/s]
epoch 31000  training loss: 0.01284805778414011
epoch 31000  clean testing loss: 0.015662088990211487
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 31100  training loss: 0.012853399850428104
epoch 31100  clean testing loss: 0.01566092111170292
epoch 31200  training loss: 0.012821991927921772
epoch 31200  clean testing loss: 0.015631364658474922
epoch 31300  training loss: 0.012883568182587624
epoch 31300  clean testing loss: 0.015676552429795265
epoch 31400  training loss: 0.012807122431695461
epoch 31400  clean testing loss: 0.015618707984685898
epoch 31500  training loss: 0.012814084999263287
epoch 31500  clean testing loss: 0.015619587153196335
epoch 31600  training loss: 0.012826044112443924

 32%|█████████████████████████▊                                                      | 32296/100000 [01:56<03:31, 320.56it/s]
epoch 31700  training loss: 0.012797664850950241
epoch 31700  clean testing loss: 0.015620074234902859
epoch 31800  training loss: 0.012802375480532646
epoch 31800  clean testing loss: 0.015614727512001991
epoch 31900  training loss: 0.012799137271940708
epoch 31900  clean testing loss: 0.015609363093972206
epoch 32000  training loss: 0.01281142421066761
epoch 32000  clean testing loss: 0.015613171271979809
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 32100  training loss: 0.012818412855267525
epoch 32100  clean testing loss: 0.015611248090863228
epoch 32200  training loss: 0.012781008146703243

 33%|██████████████████████████▎                                                     | 32955/100000 [01:58<03:29, 320.49it/s]
epoch 32300  training loss: 0.012826458550989628
epoch 32300  clean testing loss: 0.015632187947630882
epoch 32400  training loss: 0.012771893292665482
epoch 32400  clean testing loss: 0.015588532201945782
epoch 32500  training loss: 0.012810724787414074
epoch 32500  clean testing loss: 0.0156091945245862
epoch 32600  training loss: 0.012814424932003021
epoch 32600  clean testing loss: 0.015633754432201385
epoch 32700  training loss: 0.012796261347830296
epoch 32700  clean testing loss: 0.01560794748365879
epoch 32800  training loss: 0.012775000184774399

 34%|██████████████████████████▊                                                     | 33582/100000 [02:00<03:25, 323.57it/s]
epoch 32900  training loss: 0.012801582925021648
epoch 32900  clean testing loss: 0.015603024512529373
epoch 33000  training loss: 0.012788212858140469
epoch 33000  clean testing loss: 0.015573784708976746
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 33100  training loss: 0.012742133811116219
epoch 33100  clean testing loss: 0.015576865524053574
epoch 33200  training loss: 0.012737379409372807
epoch 33200  clean testing loss: 0.01556072011590004
epoch 33300  training loss: 0.012732211500406265
epoch 33300  clean testing loss: 0.015552325174212456
epoch 33400  training loss: 0.0127389095723629
epoch 33400  clean testing loss: 0.015537693165242672
epoch 33500  training loss: 0.012728887610137463

 34%|███████████████████████████▍                                                    | 34238/100000 [02:02<03:24, 321.88it/s]
epoch 33600  training loss: 0.012747857719659805
epoch 33600  clean testing loss: 0.015556502155959606
epoch 33700  training loss: 0.012746318243443966
epoch 33700  clean testing loss: 0.015555385500192642
epoch 33800  training loss: 0.012732629664242268
epoch 33800  clean testing loss: 0.015537825413048267
epoch 33900  training loss: 0.012712794356048107
epoch 33900  clean testing loss: 0.01554548554122448
epoch 34000  training loss: 0.012708271853625774
epoch 34000  clean testing loss: 0.015514477156102657
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 34100  training loss: 0.012705822475254536

 35%|███████████████████████████▉                                                    | 34898/100000 [02:04<03:21, 322.65it/s]
epoch 34200  training loss: 0.012718222104012966
epoch 34200  clean testing loss: 0.015525423921644688
epoch 34300  training loss: 0.012729736976325512
epoch 34300  clean testing loss: 0.015537457540631294
epoch 34400  training loss: 0.012710925191640854
epoch 34400  clean testing loss: 0.015531561337411404
epoch 34500  training loss: 0.012699905782938004
epoch 34500  clean testing loss: 0.015525029972195625
epoch 34600  training loss: 0.01268623024225235
epoch 34600  clean testing loss: 0.015501389279961586
epoch 34700  training loss: 0.012711846269667149
epoch 34700  clean testing loss: 0.015498179011046886
epoch 34800  training loss: 0.012685328722000122

 36%|████████████████████████████▍                                                   | 35523/100000 [02:06<03:21, 319.65it/s]
epoch 34900  training loss: 0.012703029438853264
epoch 34900  clean testing loss: 0.015494692139327526
epoch 35000  training loss: 0.012704720720648766
epoch 35000  clean testing loss: 0.015506630763411522
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 35100  training loss: 0.01268043927848339
epoch 35100  clean testing loss: 0.01550918910652399
epoch 35200  training loss: 0.01267921831458807
epoch 35200  clean testing loss: 0.015489703044295311
epoch 35300  training loss: 0.012658837251365185
epoch 35300  clean testing loss: 0.015485040843486786
epoch 35400  training loss: 0.012691861018538475

 36%|████████████████████████████▉                                                   | 36175/100000 [02:08<03:19, 320.26it/s]
epoch 35500  training loss: 0.012651336379349232
epoch 35500  clean testing loss: 0.015466931276023388
epoch 35600  training loss: 0.012652168981730938
epoch 35600  clean testing loss: 0.015467790886759758
epoch 35700  training loss: 0.012665405869483948
epoch 35700  clean testing loss: 0.015486018732190132
epoch 35800  training loss: 0.012645642273128033
epoch 35800  clean testing loss: 0.015442959032952785
epoch 35900  training loss: 0.012636810541152954
epoch 35900  clean testing loss: 0.015462555922567844
epoch 36000  training loss: 0.012647022493183613
epoch 36000  clean testing loss: 0.015449311584234238
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 36100  training loss: 0.012625277042388916

 37%|█████████████████████████████▍                                                  | 36802/100000 [02:10<03:16, 321.45it/s]
epoch 36200  training loss: 0.012620258145034313
epoch 36200  clean testing loss: 0.015426470898091793
epoch 36300  training loss: 0.012619196437299252
epoch 36300  clean testing loss: 0.015441080555319786
epoch 36400  training loss: 0.01261611096560955
epoch 36400  clean testing loss: 0.015443305484950542
epoch 36500  training loss: 0.012627153657376766
epoch 36500  clean testing loss: 0.01544667687267065
epoch 36600  training loss: 0.012624731287360191
epoch 36600  clean testing loss: 0.015427780337631702
epoch 36700  training loss: 0.012619132176041603

 37%|█████████████████████████████▉                                                  | 37454/100000 [02:12<03:14, 321.39it/s]
epoch 36800  training loss: 0.012617586180567741
epoch 36800  clean testing loss: 0.015447991900146008
epoch 36900  training loss: 0.012617785483598709
epoch 36900  clean testing loss: 0.015436994843184948
epoch 37000  training loss: 0.01261140312999487
epoch 37000  clean testing loss: 0.01542926300317049
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 37100  training loss: 0.01260885689407587
epoch 37100  clean testing loss: 0.015424581244587898
epoch 37200  training loss: 0.012589075602591038
epoch 37200  clean testing loss: 0.015411965548992157
epoch 37300  training loss: 0.012587637640535831

 38%|██████████████████████████████▍                                                 | 38080/100000 [02:14<03:15, 317.40it/s]
epoch 37400  training loss: 0.012589497491717339
epoch 37400  clean testing loss: 0.015400653705000877
epoch 37500  training loss: 0.012580526992678642
epoch 37500  clean testing loss: 0.015382562763988972
epoch 37600  training loss: 0.01258763112127781
epoch 37600  clean testing loss: 0.015396651811897755
epoch 37700  training loss: 0.012567699886858463
epoch 37700  clean testing loss: 0.01537808682769537
epoch 37800  training loss: 0.01257589366286993
epoch 37800  clean testing loss: 0.015390259213745594
epoch 37900  training loss: 0.012584412470459938
epoch 37900  clean testing loss: 0.015396670438349247
epoch 38000  training loss: 0.012575531378388405
epoch 38000  clean testing loss: 0.015383467078208923

 39%|██████████████████████████████▉                                                 | 38734/100000 [02:16<03:11, 320.51it/s]
epoch 38100  training loss: 0.012566862627863884
epoch 38100  clean testing loss: 0.015368973836302757
epoch 38200  training loss: 0.012553365901112556
epoch 38200  clean testing loss: 0.015358095988631248
epoch 38300  training loss: 0.012558161281049252
epoch 38300  clean testing loss: 0.015388966538012028
epoch 38400  training loss: 0.012555145658552647
epoch 38400  clean testing loss: 0.015369251370429993
epoch 38500  training loss: 0.012539207935333252
epoch 38500  clean testing loss: 0.015379674732685089
epoch 38600  training loss: 0.012536974623799324

 39%|███████████████████████████████▌                                                | 39391/100000 [02:18<03:08, 321.64it/s]
epoch 38700  training loss: 0.012546512298285961
epoch 38700  clean testing loss: 0.015373350121080875
epoch 38800  training loss: 0.0125284967944026
epoch 38800  clean testing loss: 0.015358101576566696
epoch 38900  training loss: 0.012530640698969364
epoch 38900  clean testing loss: 0.015372389927506447
epoch 39000  training loss: 0.012552445754408836
epoch 39000  clean testing loss: 0.01535937562584877
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 39100  training loss: 0.012524769641458988
epoch 39100  clean testing loss: 0.015341178514063358
epoch 39200  training loss: 0.012516866438090801
epoch 39200  clean testing loss: 0.015343816950917244
epoch 39300  training loss: 0.01251242682337761

 40%|████████████████████████████████                                                | 40018/100000 [02:20<03:10, 314.09it/s]
epoch 39400  training loss: 0.01251041516661644
epoch 39400  clean testing loss: 0.01534999255090952
epoch 39500  training loss: 0.012516275979578495
epoch 39500  clean testing loss: 0.015337033197283745
epoch 39600  training loss: 0.012508759275078773
epoch 39600  clean testing loss: 0.015364113263785839
epoch 39700  training loss: 0.012508311308920383
epoch 39700  clean testing loss: 0.015351108275353909
epoch 39800  training loss: 0.012499352917075157
epoch 39800  clean testing loss: 0.015346411615610123
epoch 39900  training loss: 0.012508315965533257

 41%|████████████████████████████████▌                                               | 40673/100000 [02:22<03:05, 320.66it/s]
epoch 40000  training loss: 0.012506291270256042
epoch 40000  clean testing loss: 0.015316782519221306
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 40100  training loss: 0.012496125884354115
epoch 40100  clean testing loss: 0.015307653695344925
epoch 40200  training loss: 0.01249972265213728
epoch 40200  clean testing loss: 0.015335671603679657
epoch 40300  training loss: 0.012492725625634193
epoch 40300  clean testing loss: 0.015344069339334965
epoch 40400  training loss: 0.012492646463215351
epoch 40400  clean testing loss: 0.01531169656664133
epoch 40500  training loss: 0.012491123750805855

 41%|█████████████████████████████████                                               | 41293/100000 [02:24<03:04, 318.10it/s]
epoch 40600  training loss: 0.012490099295973778
epoch 40600  clean testing loss: 0.015321975573897362
epoch 40700  training loss: 0.012493067421019077
epoch 40700  clean testing loss: 0.015325978398323059
epoch 40800  training loss: 0.012478846125304699
epoch 40800  clean testing loss: 0.015290199778974056
epoch 40900  training loss: 0.012483651749789715
epoch 40900  clean testing loss: 0.015296610072255135
epoch 41000  training loss: 0.01247737742960453
epoch 41000  clean testing loss: 0.015323590487241745
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 41100  training loss: 0.012477953918278217
epoch 41100  clean testing loss: 0.015307643450796604
epoch 41200  training loss: 0.012471532449126244

 42%|█████████████████████████████████▌                                              | 41947/100000 [02:26<03:02, 318.73it/s]
epoch 41300  training loss: 0.012471304275095463
epoch 41300  clean testing loss: 0.015299048274755478
epoch 41400  training loss: 0.012475864961743355
epoch 41400  clean testing loss: 0.01529000699520111
epoch 41500  training loss: 0.012464271858334541
epoch 41500  clean testing loss: 0.015263933688402176
epoch 41600  training loss: 0.012462290935218334
epoch 41600  clean testing loss: 0.01528332382440567
epoch 41700  training loss: 0.012464487925171852
epoch 41700  clean testing loss: 0.015298284590244293
epoch 41800  training loss: 0.012464752420783043

 43%|██████████████████████████████████                                              | 42571/100000 [02:28<02:58, 321.28it/s]
epoch 41900  training loss: 0.012460927478969097
epoch 41900  clean testing loss: 0.015269789844751358
epoch 42000  training loss: 0.012456106022000313
epoch 42000  clean testing loss: 0.015269093215465546
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 42100  training loss: 0.012448682449758053
epoch 42100  clean testing loss: 0.015287076123058796
epoch 42200  training loss: 0.012445932254195213
epoch 42200  clean testing loss: 0.015293046832084656
epoch 42300  training loss: 0.012444096617400646
epoch 42300  clean testing loss: 0.015289722010493279
epoch 42400  training loss: 0.01244381908327341
epoch 42400  clean testing loss: 0.015273489989340305
epoch 42500  training loss: 0.012445018626749516

 43%|██████████████████████████████████▌                                             | 43227/100000 [02:30<02:57, 318.98it/s]
epoch 42600  training loss: 0.012444446794688702
epoch 42600  clean testing loss: 0.015264867804944515
epoch 42700  training loss: 0.012442154809832573
epoch 42700  clean testing loss: 0.015269218944013119
epoch 42800  training loss: 0.01244162768125534
epoch 42800  clean testing loss: 0.01526655163615942
epoch 42900  training loss: 0.012442710809409618
epoch 42900  clean testing loss: 0.015258198603987694
epoch 43000  training loss: 0.01243325974792242
epoch 43000  clean testing loss: 0.01524388324469328
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 43100  training loss: 0.012442455627024174

 44%|███████████████████████████████████                                             | 43852/100000 [02:32<02:55, 319.73it/s]
epoch 43200  training loss: 0.012434587813913822
epoch 43200  clean testing loss: 0.015262770466506481
epoch 43300  training loss: 0.012430662289261818
epoch 43300  clean testing loss: 0.015278704464435577
epoch 43400  training loss: 0.012429495342075825
epoch 43400  clean testing loss: 0.015248674899339676
epoch 43500  training loss: 0.0124365808442235
epoch 43500  clean testing loss: 0.015256449580192566
epoch 43600  training loss: 0.012424645014107227
epoch 43600  clean testing loss: 0.015234866179525852
epoch 43700  training loss: 0.012431737035512924

 45%|███████████████████████████████████▌                                            | 44510/100000 [02:34<02:51, 322.99it/s]
epoch 43800  training loss: 0.012425254099071026
epoch 43800  clean testing loss: 0.015250408090651035
epoch 43900  training loss: 0.01242114044725895
epoch 43900  clean testing loss: 0.015268501825630665
epoch 44000  training loss: 0.012427819892764091
epoch 44000  clean testing loss: 0.015257171355187893
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 44100  training loss: 0.01242536585777998
epoch 44100  clean testing loss: 0.015242953784763813
epoch 44200  training loss: 0.012417042627930641
epoch 44200  clean testing loss: 0.015225664712488651
epoch 44300  training loss: 0.01242013182491064
epoch 44300  clean testing loss: 0.015224569477140903
epoch 44400  training loss: 0.012415353208780289

 45%|████████████████████████████████████                                            | 45134/100000 [02:36<02:52, 318.61it/s]
epoch 44500  training loss: 0.01241136435419321
epoch 44500  clean testing loss: 0.015261214226484299
epoch 44600  training loss: 0.01241936907172203
epoch 44600  clean testing loss: 0.01525499951094389
epoch 44700  training loss: 0.01241020392626524
epoch 44700  clean testing loss: 0.015230594202876091
epoch 44800  training loss: 0.01240663044154644
epoch 44800  clean testing loss: 0.01522110216319561
epoch 44900  training loss: 0.012412352487444878
epoch 44900  clean testing loss: 0.015240754000842571
epoch 45000  training loss: 0.012411096133291721
epoch 45000  clean testing loss: 0.015244336798787117

 46%|████████████████████████████████████▋                                           | 45794/100000 [02:38<02:49, 320.57it/s]
epoch 45100  training loss: 0.012402811087667942
epoch 45100  clean testing loss: 0.01523929089307785
epoch 45200  training loss: 0.012403706088662148
epoch 45200  clean testing loss: 0.015230492688715458
epoch 45300  training loss: 0.012406672351062298
epoch 45300  clean testing loss: 0.015223933383822441
epoch 45400  training loss: 0.012402153573930264
epoch 45400  clean testing loss: 0.015220723114907742
epoch 45500  training loss: 0.012396825477480888
epoch 45500  clean testing loss: 0.015228376723825932
epoch 45600  training loss: 0.012396086007356644
epoch 45600  clean testing loss: 0.015234077349305153
epoch 45700  training loss: 0.012399931438267231

 46%|█████████████████████████████████████▏                                          | 46453/100000 [02:40<02:47, 319.50it/s]
epoch 45800  training loss: 0.012394826859235764
epoch 45800  clean testing loss: 0.015213518403470516
epoch 45900  training loss: 0.012392954900860786
epoch 45900  clean testing loss: 0.015208872966468334
epoch 46000  training loss: 0.012393404729664326
epoch 46000  clean testing loss: 0.015229524113237858
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 46100  training loss: 0.012392041273415089
epoch 46100  clean testing loss: 0.015227028168737888
epoch 46200  training loss: 0.01238996908068657
epoch 46200  clean testing loss: 0.015222504734992981
epoch 46300  training loss: 0.012393566779792309

 47%|█████████████████████████████████████▋                                          | 47079/100000 [02:42<02:44, 320.76it/s]
epoch 46400  training loss: 0.012388654984533787
epoch 46400  clean testing loss: 0.015217694453895092
epoch 46500  training loss: 0.012389471754431725
epoch 46500  clean testing loss: 0.015232418663799763
epoch 46600  training loss: 0.012387114576995373
epoch 46600  clean testing loss: 0.015230334363877773
epoch 46700  training loss: 0.012389442883431911
epoch 46700  clean testing loss: 0.015207567252218723
epoch 46800  training loss: 0.012385396286845207
epoch 46800  clean testing loss: 0.015214113518595695
epoch 46900  training loss: 0.012383569031953812
epoch 46900  clean testing loss: 0.015213372185826302
epoch 47000  training loss: 0.012377550825476646

 48%|██████████████████████████████████████▏                                         | 47739/100000 [02:44<02:41, 323.45it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 47100  training loss: 0.01238107681274414
epoch 47100  clean testing loss: 0.015216284431517124
epoch 47200  training loss: 0.012378775514662266
epoch 47200  clean testing loss: 0.015193182043731213
epoch 47300  training loss: 0.012378308922052383
epoch 47300  clean testing loss: 0.01519912201911211
epoch 47400  training loss: 0.012369913049042225
epoch 47400  clean testing loss: 0.015212210826575756
epoch 47500  training loss: 0.01236926019191742
epoch 47500  clean testing loss: 0.015191156417131424
epoch 47600  training loss: 0.012367073446512222

 48%|██████████████████████████████████████▋                                         | 48366/100000 [02:46<02:40, 321.61it/s]
epoch 47700  training loss: 0.012369483709335327
epoch 47700  clean testing loss: 0.015206478536128998
epoch 47800  training loss: 0.01236472837626934
epoch 47800  clean testing loss: 0.015185404568910599
epoch 47900  training loss: 0.012362251058220863
epoch 47900  clean testing loss: 0.015178835950791836
epoch 48000  training loss: 0.012361794710159302
epoch 48000  clean testing loss: 0.015199943445622921
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 48100  training loss: 0.012360543012619019
epoch 48100  clean testing loss: 0.01518669817596674
epoch 48200  training loss: 0.01235886663198471

 49%|███████████████████████████████████████▏                                        | 49026/100000 [02:48<02:41, 316.52it/s]
epoch 48300  training loss: 0.012356868013739586
epoch 48300  clean testing loss: 0.015203016810119152
epoch 48400  training loss: 0.012356709688901901
epoch 48400  clean testing loss: 0.015197456814348698
epoch 48500  training loss: 0.01235504262149334
epoch 48500  clean testing loss: 0.015199791640043259
epoch 48600  training loss: 0.012356474064290524
epoch 48600  clean testing loss: 0.01519243698567152
epoch 48700  training loss: 0.012353346683084965
epoch 48700  clean testing loss: 0.015199193730950356
epoch 48800  training loss: 0.012355991639196873
epoch 48800  clean testing loss: 0.015189998783171177
epoch 48900  training loss: 0.012354700826108456

 50%|███████████████████████████████████████▋                                        | 49652/100000 [02:50<02:36, 322.18it/s]
epoch 49000  training loss: 0.012354155071079731
epoch 49000  clean testing loss: 0.01518882904201746
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 49100  training loss: 0.012357542291283607
epoch 49100  clean testing loss: 0.015177568420767784
epoch 49200  training loss: 0.012350107543170452
epoch 49200  clean testing loss: 0.015187353827059269
epoch 49300  training loss: 0.012352182529866695
epoch 49300  clean testing loss: 0.015188205987215042
epoch 49400  training loss: 0.012349549680948257
epoch 49400  clean testing loss: 0.015171093866229057
epoch 49500  training loss: 0.012347628362476826

 50%|████████████████████████████████████████▏                                       | 50308/100000 [02:52<02:35, 319.97it/s]
epoch 49600  training loss: 0.01234927773475647
epoch 49600  clean testing loss: 0.015176044777035713
epoch 49700  training loss: 0.012349292635917664
epoch 49700  clean testing loss: 0.015174608677625656
epoch 49800  training loss: 0.012348979711532593
epoch 49800  clean testing loss: 0.015187813900411129
epoch 49900  training loss: 0.012348161078989506
epoch 49900  clean testing loss: 0.015166674740612507
epoch 50000  training loss: 0.012344321236014366
epoch 50000  clean testing loss: 0.015185868367552757
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 50100  training loss: 0.012350045144557953
epoch 50100  clean testing loss: 0.015169740654528141
epoch 50200  training loss: 0.01234448328614235

 51%|████████████████████████████████████████▋                                       | 50934/100000 [02:54<02:33, 320.59it/s]
epoch 50300  training loss: 0.012341729365289211
epoch 50300  clean testing loss: 0.015184312127530575
epoch 50400  training loss: 0.01234244555234909
epoch 50400  clean testing loss: 0.015163476578891277
epoch 50500  training loss: 0.012340717017650604
epoch 50500  clean testing loss: 0.015186171047389507
epoch 50600  training loss: 0.012345016933977604
epoch 50600  clean testing loss: 0.01516221184283495
epoch 50700  training loss: 0.012339141219854355
epoch 50700  clean testing loss: 0.015187210403382778
epoch 50800  training loss: 0.01234175730496645

 52%|█████████████████████████████████████████▎                                      | 51592/100000 [02:56<02:30, 321.59it/s]
epoch 50900  training loss: 0.012338507920503616
epoch 50900  clean testing loss: 0.015172176994383335
epoch 51000  training loss: 0.012340879067778587
epoch 51000  clean testing loss: 0.015177970752120018
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 51100  training loss: 0.012336945161223412
epoch 51100  clean testing loss: 0.015173870138823986
epoch 51200  training loss: 0.012336158193647861
epoch 51200  clean testing loss: 0.015167725272476673
epoch 51300  training loss: 0.012336920015513897
epoch 51300  clean testing loss: 0.015171902254223824
epoch 51400  training loss: 0.012335310690104961
epoch 51400  clean testing loss: 0.015175359323620796
epoch 51500  training loss: 0.012335116975009441

 52%|█████████████████████████████████████████▊                                      | 52251/100000 [02:58<02:28, 321.01it/s]
epoch 51600  training loss: 0.012335156090557575
epoch 51600  clean testing loss: 0.015165225602686405
epoch 51700  training loss: 0.012334183789789677
epoch 51700  clean testing loss: 0.015166234225034714
epoch 51800  training loss: 0.012333640828728676
epoch 51800  clean testing loss: 0.01516861841082573
epoch 51900  training loss: 0.01233295351266861
epoch 51900  clean testing loss: 0.015161393210291862
epoch 52000  training loss: 0.012332220561802387
epoch 52000  clean testing loss: 0.015177237801253796
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 52100  training loss: 0.012332337908446789

 53%|██████████████████████████████████████████▎                                     | 52878/100000 [03:00<02:26, 321.90it/s]
epoch 52200  training loss: 0.012333013117313385
epoch 52200  clean testing loss: 0.015165346674621105
epoch 52300  training loss: 0.012330524623394012
epoch 52300  clean testing loss: 0.01517216581851244
epoch 52400  training loss: 0.012333877384662628
epoch 52400  clean testing loss: 0.015154716558754444
epoch 52500  training loss: 0.01232920866459608
epoch 52500  clean testing loss: 0.015175906009972095
epoch 52600  training loss: 0.01233116164803505
epoch 52600  clean testing loss: 0.01515191514045
epoch 52700  training loss: 0.012327834032475948

 54%|██████████████████████████████████████████▊                                     | 53537/100000 [03:02<02:24, 321.03it/s]
epoch 52800  training loss: 0.0123308589681983
epoch 52800  clean testing loss: 0.015151962637901306
epoch 52900  training loss: 0.012328808195888996
epoch 52900  clean testing loss: 0.01515874732285738
epoch 53000  training loss: 0.012326559983193874
epoch 53000  clean testing loss: 0.015153462998569012
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 53100  training loss: 0.012326069176197052
epoch 53100  clean testing loss: 0.015152698382735252
epoch 53200  training loss: 0.012325510382652283
epoch 53200  clean testing loss: 0.015163370408117771
epoch 53300  training loss: 0.01232670247554779
epoch 53300  clean testing loss: 0.015165100805461407
epoch 53400  training loss: 0.012324281968176365

 54%|███████████████████████████████████████████▎                                    | 54161/100000 [03:04<02:23, 319.15it/s]
epoch 53500  training loss: 0.0123240165412426
epoch 53500  clean testing loss: 0.01515862625092268
epoch 53600  training loss: 0.012323366478085518
epoch 53600  clean testing loss: 0.015157608315348625
epoch 53700  training loss: 0.012324144132435322
epoch 53700  clean testing loss: 0.015156119130551815
epoch 53800  training loss: 0.012323178350925446
epoch 53800  clean testing loss: 0.015159177593886852
epoch 53900  training loss: 0.012322505004703999
epoch 53900  clean testing loss: 0.015147845260798931
epoch 54000  training loss: 0.012323320843279362
epoch 54000  clean testing loss: 0.015148922801017761

 55%|███████████████████████████████████████████▊                                    | 54821/100000 [03:06<02:20, 322.51it/s]
epoch 54100  training loss: 0.012319928035140038
epoch 54100  clean testing loss: 0.015151836909353733
epoch 54200  training loss: 0.012319627217948437
epoch 54200  clean testing loss: 0.015152374282479286
epoch 54300  training loss: 0.012318754568696022
epoch 54300  clean testing loss: 0.015153469517827034
epoch 54400  training loss: 0.012318601831793785
epoch 54400  clean testing loss: 0.015156950801610947
epoch 54500  training loss: 0.012317991815507412
epoch 54500  clean testing loss: 0.015156508423388004
epoch 54600  training loss: 0.012318543158471584
epoch 54600  clean testing loss: 0.015148703008890152
epoch 54700  training loss: 0.012316454201936722

 55%|████████████████████████████████████████████▎                                   | 55447/100000 [03:08<02:18, 321.01it/s]
epoch 54800  training loss: 0.012315659783780575
epoch 54800  clean testing loss: 0.01515969354659319
epoch 54900  training loss: 0.012315911240875721
epoch 54900  clean testing loss: 0.015146336518228054
epoch 55000  training loss: 0.012315299361944199
epoch 55000  clean testing loss: 0.015147050842642784
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 55100  training loss: 0.012313454411923885
epoch 55100  clean testing loss: 0.015145941637456417
epoch 55200  training loss: 0.01231315266340971
epoch 55200  clean testing loss: 0.015140797011554241
epoch 55300  training loss: 0.012313020415604115

 56%|████████████████████████████████████████████▉                                   | 56106/100000 [03:10<02:16, 320.80it/s]
epoch 55400  training loss: 0.012312653474509716
epoch 55400  clean testing loss: 0.015148915350437164
epoch 55500  training loss: 0.012311856262385845
epoch 55500  clean testing loss: 0.015147695317864418
epoch 55600  training loss: 0.012312531471252441
epoch 55600  clean testing loss: 0.015135345980525017
epoch 55700  training loss: 0.012309500016272068
epoch 55700  clean testing loss: 0.01513421256095171
epoch 55800  training loss: 0.012309670448303223
epoch 55800  clean testing loss: 0.015141411684453487
epoch 55900  training loss: 0.012308875098824501
epoch 55900  clean testing loss: 0.015143459662795067
epoch 56000  training loss: 0.012307676486670971
epoch 56000  clean testing loss: 0.015147148631513119

 57%|█████████████████████████████████████████████▍                                  | 56733/100000 [03:12<02:13, 323.44it/s]
epoch 56100  training loss: 0.01230897381901741
epoch 56100  clean testing loss: 0.015138931572437286
epoch 56200  training loss: 0.012308737263083458
epoch 56200  clean testing loss: 0.015140196308493614
epoch 56300  training loss: 0.012306569144129753
epoch 56300  clean testing loss: 0.015139571391046047
epoch 56400  training loss: 0.012306944467127323
epoch 56400  clean testing loss: 0.015131078660488129
epoch 56500  training loss: 0.012306609191000462
epoch 56500  clean testing loss: 0.015135813504457474
epoch 56600  training loss: 0.01230597123503685

 57%|█████████████████████████████████████████████▉                                  | 57394/100000 [03:14<02:12, 322.62it/s]
epoch 56700  training loss: 0.012306499294936657
epoch 56700  clean testing loss: 0.015133704990148544
epoch 56800  training loss: 0.012307669036090374
epoch 56800  clean testing loss: 0.015147852711379528
epoch 56900  training loss: 0.012308713048696518
epoch 56900  clean testing loss: 0.015134262852370739
epoch 57000  training loss: 0.012303438037633896
epoch 57000  clean testing loss: 0.015131274238228798
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 57100  training loss: 0.012303771451115608
epoch 57100  clean testing loss: 0.015143386088311672
epoch 57200  training loss: 0.01230542827397585

 58%|██████████████████████████████████████████████▍                                 | 58054/100000 [03:16<02:11, 319.42it/s]
epoch 57300  training loss: 0.012302975170314312
epoch 57300  clean testing loss: 0.015133964829146862
epoch 57400  training loss: 0.012303872965276241
epoch 57400  clean testing loss: 0.015140394680202007
epoch 57500  training loss: 0.012302525341510773
epoch 57500  clean testing loss: 0.01513493712991476
epoch 57600  training loss: 0.012302618473768234
epoch 57600  clean testing loss: 0.015138592571020126
epoch 57700  training loss: 0.012301906943321228
epoch 57700  clean testing loss: 0.015132117085158825
epoch 57800  training loss: 0.012301290407776833
epoch 57800  clean testing loss: 0.015142460353672504
epoch 57900  training loss: 0.012301504611968994

 59%|██████████████████████████████████████████████▉                                 | 58678/100000 [03:18<02:09, 319.97it/s]
epoch 58000  training loss: 0.01230099331587553
epoch 58000  clean testing loss: 0.015139240771532059
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 58100  training loss: 0.012300542555749416
epoch 58100  clean testing loss: 0.015123391523957253
epoch 58200  training loss: 0.012300441041588783
epoch 58200  clean testing loss: 0.015135003253817558
epoch 58300  training loss: 0.012299546040594578
epoch 58300  clean testing loss: 0.015143832191824913
epoch 58400  training loss: 0.012299265712499619
epoch 58400  clean testing loss: 0.015124143101274967
epoch 58500  training loss: 0.01229910459369421

 59%|███████████████████████████████████████████████▍                                | 59337/100000 [03:20<02:07, 318.01it/s]
epoch 58600  training loss: 0.01229847315698862
epoch 58600  clean testing loss: 0.015125265344977379
epoch 58700  training loss: 0.01229824498295784
epoch 58700  clean testing loss: 0.015125107951462269
epoch 58800  training loss: 0.01229823473840952
epoch 58800  clean testing loss: 0.015128846280276775
epoch 58900  training loss: 0.012297307141125202
epoch 58900  clean testing loss: 0.015126369893550873
epoch 59000  training loss: 0.01229848526418209
epoch 59000  clean testing loss: 0.015131170861423016
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 59100  training loss: 0.012297052890062332
epoch 59100  clean testing loss: 0.01512984186410904
epoch 59200  training loss: 0.012296709232032299

 60%|███████████████████████████████████████████████▉                                | 59963/100000 [03:22<02:04, 320.99it/s]
epoch 59300  training loss: 0.012297278270125389
epoch 59300  clean testing loss: 0.01512700691819191
epoch 59400  training loss: 0.012295311316847801
epoch 59400  clean testing loss: 0.015128025785088539
epoch 59500  training loss: 0.012295047752559185
epoch 59500  clean testing loss: 0.01513753179460764
epoch 59600  training loss: 0.012295720167458057
epoch 59600  clean testing loss: 0.01512434333562851
epoch 59700  training loss: 0.012294561602175236
epoch 59700  clean testing loss: 0.015123293735086918
epoch 59800  training loss: 0.01229497604072094

 61%|████████████████████████████████████████████████▍                               | 60621/100000 [03:24<02:02, 322.26it/s]
epoch 59900  training loss: 0.012293614447116852
epoch 59900  clean testing loss: 0.01512540690600872
epoch 60000  training loss: 0.012294743210077286
epoch 60000  clean testing loss: 0.01512843742966652
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 60100  training loss: 0.012293404899537563
epoch 60100  clean testing loss: 0.01512338686734438
epoch 60200  training loss: 0.012292717583477497
epoch 60200  clean testing loss: 0.015125885605812073
epoch 60300  training loss: 0.012292413972318172
epoch 60300  clean testing loss: 0.015131289139389992
epoch 60400  training loss: 0.012291813269257545
epoch 60400  clean testing loss: 0.015125647187232971
epoch 60500  training loss: 0.012292090803384781

 61%|████████████████████████████████████████████████▉                               | 61248/100000 [03:26<02:00, 322.38it/s]
epoch 60600  training loss: 0.01229183655232191
epoch 60600  clean testing loss: 0.015121042728424072
epoch 60700  training loss: 0.012292076833546162
epoch 60700  clean testing loss: 0.015122446231544018
epoch 60800  training loss: 0.01229157205671072
epoch 60800  clean testing loss: 0.015125628560781479
epoch 60900  training loss: 0.01229092013090849
epoch 60900  clean testing loss: 0.01512722484767437
epoch 61000  training loss: 0.012290412560105324
epoch 61000  clean testing loss: 0.015117866918444633
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 61100  training loss: 0.012291016057133675

 62%|█████████████████████████████████████████████████▌                              | 61905/100000 [03:28<01:58, 322.77it/s]
epoch 61200  training loss: 0.01229033526033163
epoch 61200  clean testing loss: 0.015129840932786465
epoch 61300  training loss: 0.012289916165173054
epoch 61300  clean testing loss: 0.015130018815398216
epoch 61400  training loss: 0.012291179969906807
epoch 61400  clean testing loss: 0.015120407566428185
epoch 61500  training loss: 0.01229002233594656
epoch 61500  clean testing loss: 0.015125224366784096
epoch 61600  training loss: 0.012289430014789104
epoch 61600  clean testing loss: 0.01512589305639267
epoch 61700  training loss: 0.012289962731301785

 63%|██████████████████████████████████████████████████                              | 62565/100000 [03:30<01:56, 321.55it/s]
epoch 61800  training loss: 0.012289170175790787
epoch 61800  clean testing loss: 0.015125971287488937
epoch 61900  training loss: 0.012288947589695454
epoch 61900  clean testing loss: 0.01512288860976696
epoch 62000  training loss: 0.0122890155762434
epoch 62000  clean testing loss: 0.015122948214411736
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 62100  training loss: 0.01228850707411766
epoch 62100  clean testing loss: 0.015124363824725151
epoch 62200  training loss: 0.012289963662624359
epoch 62200  clean testing loss: 0.015116631984710693
epoch 62300  training loss: 0.012288950383663177
epoch 62300  clean testing loss: 0.015123436227440834
epoch 62400  training loss: 0.012288585305213928

 63%|██████████████████████████████████████████████████▌                             | 63192/100000 [03:32<01:54, 321.73it/s]
epoch 62500  training loss: 0.012287826277315617
epoch 62500  clean testing loss: 0.015124182216823101
epoch 62600  training loss: 0.012287563644349575
epoch 62600  clean testing loss: 0.015127652324736118
epoch 62700  training loss: 0.012288471683859825
epoch 62700  clean testing loss: 0.015116758644580841
epoch 62800  training loss: 0.01228843443095684
epoch 62800  clean testing loss: 0.015130355022847652
epoch 62900  training loss: 0.012287996709346771
epoch 62900  clean testing loss: 0.015125179663300514
epoch 63000  training loss: 0.012287270277738571
epoch 63000  clean testing loss: 0.015124323777854443

 64%|███████████████████████████████████████████████████                             | 63852/100000 [03:34<01:52, 320.11it/s]
epoch 63100  training loss: 0.012287041172385216
epoch 63100  clean testing loss: 0.015117285773158073
epoch 63200  training loss: 0.01228678971529007
epoch 63200  clean testing loss: 0.015112538821995258
epoch 63300  training loss: 0.012286651879549026
epoch 63300  clean testing loss: 0.015115654096007347
epoch 63400  training loss: 0.012286480516195297
epoch 63400  clean testing loss: 0.015116660855710506
epoch 63500  training loss: 0.012286136858165264
epoch 63500  clean testing loss: 0.015118037350475788
epoch 63600  training loss: 0.01228567399084568
epoch 63600  clean testing loss: 0.015123102813959122
epoch 63700  training loss: 0.012286119163036346

 64%|███████████████████████████████████████████████████▌                            | 64479/100000 [03:36<01:50, 320.94it/s]
epoch 63800  training loss: 0.012285505421459675
epoch 63800  clean testing loss: 0.015119258314371109
epoch 63900  training loss: 0.012285908684134483
epoch 63900  clean testing loss: 0.015112992376089096
epoch 64000  training loss: 0.012285556644201279
epoch 64000  clean testing loss: 0.01511471252888441
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 64100  training loss: 0.012284660711884499
epoch 64100  clean testing loss: 0.01512233354151249
epoch 64200  training loss: 0.012284265831112862
epoch 64200  clean testing loss: 0.01512215193361044
epoch 64300  training loss: 0.012284230440855026

 65%|████████████████████████████████████████████████████                            | 65138/100000 [03:38<01:48, 321.24it/s]
epoch 64400  training loss: 0.01228434219956398
epoch 64400  clean testing loss: 0.015113760717213154
epoch 64500  training loss: 0.012283695861697197
epoch 64500  clean testing loss: 0.015115008689463139
epoch 64600  training loss: 0.012283592484891415
epoch 64600  clean testing loss: 0.015112989582121372
epoch 64700  training loss: 0.01228307280689478
epoch 64700  clean testing loss: 0.015121008269488811
epoch 64800  training loss: 0.012283672578632832
epoch 64800  clean testing loss: 0.015112116932868958
epoch 64900  training loss: 0.012283140793442726
epoch 64900  clean testing loss: 0.01511584222316742
epoch 65000  training loss: 0.0122830243781209
epoch 65000  clean testing loss: 0.015110637061297894

 66%|████████████████████████████████████████████████████▍                           | 65597/100000 [03:40<01:47, 321.16it/s]
epoch 65100  training loss: 0.012282454408705235
epoch 65100  clean testing loss: 0.01511223055422306
epoch 65200  training loss: 0.012282442301511765
epoch 65200  clean testing loss: 0.015109982341527939
epoch 65300  training loss: 0.012281944043934345
epoch 65300  clean testing loss: 0.015111221931874752
epoch 65400  training loss: 0.012281845323741436
epoch 65400  clean testing loss: 0.015107863582670689
epoch 65500  training loss: 0.0122815677896142
epoch 65500  clean testing loss: 0.015114828012883663
epoch 65600  training loss: 0.012281402945518494

 66%|█████████████████████████████████████████████████████                           | 66257/100000 [03:42<01:44, 321.44it/s]
epoch 65700  training loss: 0.012281566858291626
epoch 65700  clean testing loss: 0.015111830085515976
epoch 65800  training loss: 0.01228121854364872
epoch 65800  clean testing loss: 0.015110486187040806
epoch 65900  training loss: 0.012280654162168503
epoch 65900  clean testing loss: 0.015104521065950394
epoch 66000  training loss: 0.01228086557239294
epoch 66000  clean testing loss: 0.015108871273696423
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 66100  training loss: 0.012280404567718506
epoch 66100  clean testing loss: 0.01511008944362402
epoch 66200  training loss: 0.01228050421923399
epoch 66200  clean testing loss: 0.015107037499547005
epoch 66300  training loss: 0.012280233204364777

 67%|█████████████████████████████████████████████████████▌                          | 66917/100000 [03:44<01:42, 322.38it/s]
epoch 66400  training loss: 0.012279852293431759
epoch 66400  clean testing loss: 0.015111924149096012
epoch 66500  training loss: 0.012280009686946869
epoch 66500  clean testing loss: 0.015107468701899052
epoch 66600  training loss: 0.012279637157917023
epoch 66600  clean testing loss: 0.015106415376067162
epoch 66700  training loss: 0.012279737740755081
epoch 66700  clean testing loss: 0.015107340179383755
epoch 66800  training loss: 0.012279429472982883
epoch 66800  clean testing loss: 0.015109601430594921
epoch 66900  training loss: 0.012279411777853966

 68%|██████████████████████████████████████████████████████                          | 67543/100000 [03:46<01:40, 323.90it/s]
epoch 67000  training loss: 0.012279096990823746
epoch 67000  clean testing loss: 0.015113862231373787
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 67100  training loss: 0.012278704904019833
epoch 67100  clean testing loss: 0.015108880586922169
epoch 67200  training loss: 0.012278690934181213
epoch 67200  clean testing loss: 0.015103110112249851
epoch 67300  training loss: 0.012278555892407894
epoch 67300  clean testing loss: 0.0151120750233531
epoch 67400  training loss: 0.01227874867618084
epoch 67400  clean testing loss: 0.015105373226106167
epoch 67500  training loss: 0.01227887999266386

 68%|██████████████████████████████████████████████████████▌                         | 68203/100000 [03:48<01:38, 323.05it/s]
epoch 67600  training loss: 0.012278207577764988
epoch 67600  clean testing loss: 0.015105647034943104
epoch 67700  training loss: 0.012279100716114044
epoch 67700  clean testing loss: 0.015104597434401512
epoch 67800  training loss: 0.012277748435735703
epoch 67800  clean testing loss: 0.015109533444046974
epoch 67900  training loss: 0.012277569621801376
epoch 67900  clean testing loss: 0.015112453140318394
epoch 68000  training loss: 0.012278396636247635
epoch 68000  clean testing loss: 0.01510641910135746
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 68100  training loss: 0.01227756217122078
epoch 68100  clean testing loss: 0.015105750411748886
epoch 68200  training loss: 0.01227729581296444

 69%|███████████████████████████████████████████████████████                         | 68831/100000 [03:50<01:36, 321.75it/s]
epoch 68300  training loss: 0.012277302332222462
epoch 68300  clean testing loss: 0.015103246085345745
epoch 68400  training loss: 0.012276947498321533
epoch 68400  clean testing loss: 0.015107961371541023
epoch 68500  training loss: 0.012276958674192429
epoch 68500  clean testing loss: 0.015105627477169037
epoch 68600  training loss: 0.012276751920580864
epoch 68600  clean testing loss: 0.01510549709200859
epoch 68700  training loss: 0.012276389636099339
epoch 68700  clean testing loss: 0.015109037980437279
epoch 68800  training loss: 0.012276881374418736

 69%|███████████████████████████████████████████████████████▌                        | 69488/100000 [03:52<01:35, 320.32it/s]
epoch 68900  training loss: 0.012276049703359604
epoch 68900  clean testing loss: 0.015103288926184177
epoch 69000  training loss: 0.012276102788746357
epoch 69000  clean testing loss: 0.015104633755981922
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 69100  training loss: 0.012275921180844307
epoch 69100  clean testing loss: 0.01510661281645298
epoch 69200  training loss: 0.0122760608792305
epoch 69200  clean testing loss: 0.01510517206043005
epoch 69300  training loss: 0.012275699526071548
epoch 69300  clean testing loss: 0.01510446984320879
epoch 69400  training loss: 0.012275747023522854
epoch 69400  clean testing loss: 0.015104933641850948
epoch 69500  training loss: 0.012275739572942257

 70%|████████████████████████████████████████████████████████                        | 70115/100000 [03:54<01:33, 319.64it/s]
epoch 69600  training loss: 0.012275749817490578
epoch 69600  clean testing loss: 0.015099024400115013
epoch 69700  training loss: 0.012275351211428642
epoch 69700  clean testing loss: 0.01510261557996273
epoch 69800  training loss: 0.012275251559913158
epoch 69800  clean testing loss: 0.01510484330356121
epoch 69900  training loss: 0.012275755405426025
epoch 69900  clean testing loss: 0.015100185759365559
epoch 70000  training loss: 0.012275312095880508
epoch 70000  clean testing loss: 0.015101221390068531
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 70100  training loss: 0.012275020591914654

 71%|████████████████████████████████████████████████████████▌                       | 70775/100000 [03:56<01:30, 322.02it/s]
epoch 70200  training loss: 0.012275127694010735
epoch 70200  clean testing loss: 0.015103382989764214
epoch 70300  training loss: 0.0122748464345932
epoch 70300  clean testing loss: 0.015105447731912136
epoch 70400  training loss: 0.01227459404617548
epoch 70400  clean testing loss: 0.015105411410331726
epoch 70500  training loss: 0.012275004759430885
epoch 70500  clean testing loss: 0.015101456083357334
epoch 70600  training loss: 0.012274845503270626
epoch 70600  clean testing loss: 0.015101989731192589
epoch 70700  training loss: 0.012274602428078651
epoch 70700  clean testing loss: 0.015099825337529182
epoch 70800  training loss: 0.012274290435016155

 71%|█████████████████████████████████████████████████████████                       | 71401/100000 [03:58<01:29, 320.53it/s]
epoch 70900  training loss: 0.012274154461920261
epoch 70900  clean testing loss: 0.015103630721569061
epoch 71000  training loss: 0.012273943983018398
epoch 71000  clean testing loss: 0.01510239765048027
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 71100  training loss: 0.012273968197405338
epoch 71100  clean testing loss: 0.015105376951396465
epoch 71200  training loss: 0.012273694388568401
epoch 71200  clean testing loss: 0.015101323835551739
epoch 71300  training loss: 0.012273527681827545
epoch 71300  clean testing loss: 0.015101258642971516
epoch 71400  training loss: 0.012273678556084633

 72%|█████████████████████████████████████████████████████████▋                      | 72060/100000 [04:00<01:28, 316.75it/s]
epoch 71500  training loss: 0.012273482047021389
epoch 71500  clean testing loss: 0.015099935233592987
epoch 71600  training loss: 0.012273520231246948
epoch 71600  clean testing loss: 0.015099425800144672
epoch 71700  training loss: 0.01227305643260479
epoch 71700  clean testing loss: 0.015104205347597599
epoch 71800  training loss: 0.012273178435862064
epoch 71800  clean testing loss: 0.015100300312042236
epoch 71900  training loss: 0.01227288506925106
epoch 71900  clean testing loss: 0.015104198828339577
epoch 72000  training loss: 0.012272595427930355
epoch 72000  clean testing loss: 0.015098735690116882

 73%|██████████████████████████████████████████████████████████▏                     | 72687/100000 [04:02<01:25, 319.91it/s]
epoch 72100  training loss: 0.012272737920284271
epoch 72100  clean testing loss: 0.015101585537195206
epoch 72200  training loss: 0.012272877618670464
epoch 72200  clean testing loss: 0.015098347328603268
epoch 72300  training loss: 0.012272901833057404
epoch 72300  clean testing loss: 0.015098650939762592
epoch 72400  training loss: 0.012272462248802185
epoch 72400  clean testing loss: 0.015102549456059933
epoch 72500  training loss: 0.012272536754608154
epoch 72500  clean testing loss: 0.015099513344466686
epoch 72600  training loss: 0.012272357009351254
epoch 72600  clean testing loss: 0.015101361088454723
epoch 72700  training loss: 0.012272471562027931

 73%|██████████████████████████████████████████████████████████▋                     | 73344/100000 [04:04<01:22, 322.36it/s]
epoch 72800  training loss: 0.01227237656712532
epoch 72800  clean testing loss: 0.015100120566785336
epoch 72900  training loss: 0.012272153981029987
epoch 72900  clean testing loss: 0.015102333389222622
epoch 73000  training loss: 0.012272249907255173
epoch 73000  clean testing loss: 0.015099626034498215
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 73100  training loss: 0.012271948158740997
epoch 73100  clean testing loss: 0.015098810195922852
epoch 73200  training loss: 0.012272014282643795
epoch 73200  clean testing loss: 0.01509788352996111
epoch 73300  training loss: 0.012271911837160587

 74%|███████████████████████████████████████████████████████████▏                    | 74004/100000 [04:06<01:21, 317.43it/s]
epoch 73400  training loss: 0.012271587736904621
epoch 73400  clean testing loss: 0.015101149678230286
epoch 73500  training loss: 0.012271657586097717
epoch 73500  clean testing loss: 0.015097237192094326
epoch 73600  training loss: 0.012271680869162083
epoch 73600  clean testing loss: 0.015098975971341133
epoch 73700  training loss: 0.012271781452000141
epoch 73700  clean testing loss: 0.015097624622285366
epoch 73800  training loss: 0.012271381914615631
epoch 73800  clean testing loss: 0.015101483091711998
epoch 73900  training loss: 0.012271376326680183
epoch 73900  clean testing loss: 0.015101767145097256
epoch 74000  training loss: 0.012271665968000889
epoch 74000  clean testing loss: 0.015098418109118938

 75%|███████████████████████████████████████████████████████████▋                    | 74630/100000 [04:08<01:18, 322.16it/s]
epoch 74100  training loss: 0.012271649204194546
epoch 74100  clean testing loss: 0.015096710994839668
epoch 74200  training loss: 0.012271085754036903
epoch 74200  clean testing loss: 0.015101192519068718
epoch 74300  training loss: 0.012271080166101456
epoch 74300  clean testing loss: 0.015097621828317642
epoch 74400  training loss: 0.01227131299674511
epoch 74400  clean testing loss: 0.01509801670908928
epoch 74500  training loss: 0.012271303683519363
epoch 74500  clean testing loss: 0.015097473748028278
epoch 74600  training loss: 0.012270763516426086

 75%|████████████████████████████████████████████████████████████▏                   | 75290/100000 [04:10<01:16, 324.63it/s]
epoch 74700  training loss: 0.012270763516426086
epoch 74700  clean testing loss: 0.015099486336112022
epoch 74800  training loss: 0.012270932085812092
epoch 74800  clean testing loss: 0.015096263028681278
epoch 74900  training loss: 0.012270741164684296
epoch 74900  clean testing loss: 0.015099000185728073
epoch 75000  training loss: 0.012270944193005562
epoch 75000  clean testing loss: 0.015094554051756859
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 75100  training loss: 0.012270776554942131
epoch 75100  clean testing loss: 0.01509826723486185
epoch 75200  training loss: 0.012270759791135788
epoch 75200  clean testing loss: 0.015097012743353844
epoch 75300  training loss: 0.012270426377654076

 76%|████████████████████████████████████████████████████████████▋                   | 75917/100000 [04:12<01:15, 318.66it/s]
epoch 75400  training loss: 0.012270479463040829
epoch 75400  clean testing loss: 0.015096541494131088
epoch 75500  training loss: 0.01227040495723486
epoch 75500  clean testing loss: 0.015097464434802532
epoch 75600  training loss: 0.012270367704331875
epoch 75600  clean testing loss: 0.015097278170287609
epoch 75700  training loss: 0.012270281091332436
epoch 75700  clean testing loss: 0.015098108910024166
epoch 75800  training loss: 0.012270044535398483
epoch 75800  clean testing loss: 0.015094244852662086
epoch 75900  training loss: 0.012270273640751839

 77%|█████████████████████████████████████████████████████████████▎                  | 76577/100000 [04:14<01:12, 322.16it/s]
epoch 76000  training loss: 0.012270182371139526
epoch 76000  clean testing loss: 0.015096167102456093
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 76100  training loss: 0.012270056642591953
epoch 76100  clean testing loss: 0.015095116570591927
epoch 76200  training loss: 0.0122700659558177
epoch 76200  clean testing loss: 0.015095774084329605
epoch 76300  training loss: 0.012269924394786358
epoch 76300  clean testing loss: 0.01509607769548893
epoch 76400  training loss: 0.012269952334463596
epoch 76400  clean testing loss: 0.015093779191374779
epoch 76500  training loss: 0.012269758619368076
epoch 76500  clean testing loss: 0.015095619484782219
epoch 76600  training loss: 0.012269873172044754

 77%|█████████████████████████████████████████████████████████████▊                  | 77233/100000 [04:16<01:11, 320.55it/s]
epoch 76700  training loss: 0.01226972509175539
epoch 76700  clean testing loss: 0.015098223462700844
epoch 76800  training loss: 0.012269762344658375
epoch 76800  clean testing loss: 0.015095672570168972
epoch 76900  training loss: 0.012269522063434124
epoch 76900  clean testing loss: 0.015096303075551987
epoch 77000  training loss: 0.01226931344717741
epoch 77000  clean testing loss: 0.015095515176653862
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 77100  training loss: 0.012269407510757446
epoch 77100  clean testing loss: 0.01509732473641634
epoch 77200  training loss: 0.012269563972949982

 78%|██████████████████████████████████████████████████████████████▎                 | 77859/100000 [04:18<01:08, 321.41it/s]
epoch 77300  training loss: 0.012269354425370693
epoch 77300  clean testing loss: 0.015095433220267296
epoch 77400  training loss: 0.012269196100533009
epoch 77400  clean testing loss: 0.015096701681613922
epoch 77500  training loss: 0.012269287370145321
epoch 77500  clean testing loss: 0.01509666908532381
epoch 77600  training loss: 0.012269207276403904
epoch 77600  clean testing loss: 0.015095879323780537
epoch 77700  training loss: 0.012269452214241028
epoch 77700  clean testing loss: 0.015096127055585384
epoch 77800  training loss: 0.012269110418856144

 79%|██████████████████████████████████████████████████████████████▊                 | 78517/100000 [04:20<01:06, 321.79it/s]
epoch 77900  training loss: 0.012269235216081142
epoch 77900  clean testing loss: 0.015093731693923473
epoch 78000  training loss: 0.012268893420696259
epoch 78000  clean testing loss: 0.015092127956449986
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 78100  training loss: 0.012268844991922379
epoch 78100  clean testing loss: 0.0150950001552701
epoch 78200  training loss: 0.012268890626728535
epoch 78200  clean testing loss: 0.01509722787886858
epoch 78300  training loss: 0.012268704362213612
epoch 78300  clean testing loss: 0.01509288139641285
epoch 78400  training loss: 0.01226870622485876
epoch 78400  clean testing loss: 0.015097557567059994
epoch 78500  training loss: 0.012268642894923687

 79%|███████████████████████████████████████████████████████████████▎                | 79144/100000 [04:22<01:05, 320.15it/s]
epoch 78600  training loss: 0.012268641032278538
epoch 78600  clean testing loss: 0.015095178969204426
epoch 78700  training loss: 0.01226876862347126
epoch 78700  clean testing loss: 0.015095140784978867
epoch 78800  training loss: 0.01226863730698824
epoch 78800  clean testing loss: 0.015093114227056503
epoch 78900  training loss: 0.012268475256860256
epoch 78900  clean testing loss: 0.015095511451363564
epoch 79000  training loss: 0.012268473394215107
epoch 79000  clean testing loss: 0.015094214119017124
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 79100  training loss: 0.012268378399312496

 80%|███████████████████████████████████████████████████████████████▊                | 79803/100000 [04:24<01:02, 320.66it/s]
epoch 79200  training loss: 0.012268517166376114
epoch 79200  clean testing loss: 0.015095324255526066
epoch 79300  training loss: 0.012268408201634884
epoch 79300  clean testing loss: 0.015096725896000862
epoch 79400  training loss: 0.012268233112990856
epoch 79400  clean testing loss: 0.015093440189957619
epoch 79500  training loss: 0.01226813904941082
epoch 79500  clean testing loss: 0.01509346254169941
epoch 79600  training loss: 0.01226817537099123
epoch 79600  clean testing loss: 0.01509388443082571
epoch 79700  training loss: 0.012268032878637314
epoch 79700  clean testing loss: 0.015093430876731873
epoch 79800  training loss: 0.012268039397895336

 80%|████████████████████████████████████████████████████████████████▎               | 80428/100000 [04:26<01:00, 321.22it/s]
epoch 79900  training loss: 0.012268002144992352
epoch 79900  clean testing loss: 0.015091362409293652
epoch 80000  training loss: 0.012267934158444405
epoch 80000  clean testing loss: 0.015094914473593235
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 80100  training loss: 0.012267929501831532
epoch 80100  clean testing loss: 0.015094859525561333
epoch 80200  training loss: 0.01226773951202631
epoch 80200  clean testing loss: 0.015094421803951263
epoch 80300  training loss: 0.01226780004799366
epoch 80300  clean testing loss: 0.015092097222805023
epoch 80400  training loss: 0.01226778794080019

 81%|████████████████████████████████████████████████████████████████▊               | 81088/100000 [04:28<00:58, 321.55it/s]
epoch 80500  training loss: 0.012267814949154854
epoch 80500  clean testing loss: 0.015090021304786205
epoch 80600  training loss: 0.012267904356122017
epoch 80600  clean testing loss: 0.015092330053448677
epoch 80700  training loss: 0.012268157675862312
epoch 80700  clean testing loss: 0.01509477011859417
epoch 80800  training loss: 0.01226852834224701
epoch 80800  clean testing loss: 0.015094015747308731
epoch 80900  training loss: 0.012268555350601673
epoch 80900  clean testing loss: 0.015093167312443256
epoch 81000  training loss: 0.012268654070794582
epoch 81000  clean testing loss: 0.015093209221959114
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 81100  training loss: 0.012268893420696259

 82%|█████████████████████████████████████████████████████████████████▍              | 81746/100000 [04:30<00:57, 319.79it/s]
epoch 81200  training loss: 0.01226880494505167
epoch 81200  clean testing loss: 0.01509416289627552
epoch 81300  training loss: 0.012268688529729843
epoch 81300  clean testing loss: 0.01509640458971262
epoch 81400  training loss: 0.012268731370568275
epoch 81400  clean testing loss: 0.015095054171979427
epoch 81500  training loss: 0.01226873230189085
epoch 81500  clean testing loss: 0.015094082802534103
epoch 81600  training loss: 0.012268652208149433
epoch 81600  clean testing loss: 0.015092791058123112
epoch 81700  training loss: 0.012268622405827045

 82%|█████████████████████████████████████████████████████████████████▉              | 82373/100000 [04:32<00:54, 321.88it/s]
epoch 81800  training loss: 0.012268579564988613
epoch 81800  clean testing loss: 0.015095321461558342
epoch 81900  training loss: 0.012268505990505219
epoch 81900  clean testing loss: 0.015094849281013012
epoch 82000  training loss: 0.012268630787730217
epoch 82000  clean testing loss: 0.015093235298991203
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 82100  training loss: 0.012268444523215294
epoch 82100  clean testing loss: 0.015092987567186356
epoch 82200  training loss: 0.012268515303730965
epoch 82200  clean testing loss: 0.015095606446266174
epoch 82300  training loss: 0.01226835511624813

 83%|██████████████████████████████████████████████████████████████████▍             | 83032/100000 [04:34<00:53, 319.38it/s]
epoch 82400  training loss: 0.012268371880054474
epoch 82400  clean testing loss: 0.015094428323209286
epoch 82500  training loss: 0.012268263846635818
epoch 82500  clean testing loss: 0.01509388629347086
epoch 82600  training loss: 0.01226832251995802
epoch 82600  clean testing loss: 0.015092517249286175
epoch 82700  training loss: 0.01226809248328209
epoch 82700  clean testing loss: 0.015094716101884842
epoch 82800  training loss: 0.012268123216927052
epoch 82800  clean testing loss: 0.015094392001628876
epoch 82900  training loss: 0.012268158607184887
epoch 82900  clean testing loss: 0.01509466115385294
epoch 83000  training loss: 0.012268099933862686
epoch 83000  clean testing loss: 0.015091588720679283

 84%|██████████████████████████████████████████████████████████████████▉             | 83659/100000 [04:36<00:50, 320.80it/s]
epoch 83100  training loss: 0.012267963960766792
epoch 83100  clean testing loss: 0.015093625523149967
epoch 83200  training loss: 0.012267927639186382
epoch 83200  clean testing loss: 0.0150930630043149
epoch 83300  training loss: 0.012267864309251308
epoch 83300  clean testing loss: 0.01509530283510685
epoch 83400  training loss: 0.01226793136447668
epoch 83400  clean testing loss: 0.015094290487468243
epoch 83500  training loss: 0.01226791087538004
epoch 83500  clean testing loss: 0.015092764981091022
epoch 83600  training loss: 0.012267672456800938

 84%|███████████████████████████████████████████████████████████████████▍            | 84320/100000 [04:38<00:48, 321.12it/s]
epoch 83700  training loss: 0.012267708778381348
epoch 83700  clean testing loss: 0.01509283296763897
epoch 83800  training loss: 0.012267796322703362
epoch 83800  clean testing loss: 0.015091700479388237
epoch 83900  training loss: 0.012267475947737694
epoch 83900  clean testing loss: 0.015092317946255207
epoch 84000  training loss: 0.01226761844009161
epoch 84000  clean testing loss: 0.01509284321218729
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 84100  training loss: 0.01226757001131773
epoch 84100  clean testing loss: 0.015092295594513416
epoch 84200  training loss: 0.01226745080202818
epoch 84200  clean testing loss: 0.015093660913407803
epoch 84300  training loss: 0.012267491780221462

 85%|███████████████████████████████████████████████████████████████████▉            | 84945/100000 [04:40<00:47, 318.69it/s]
epoch 84400  training loss: 0.01226735394448042
epoch 84400  clean testing loss: 0.015092057175934315
epoch 84500  training loss: 0.012267326936125755
epoch 84500  clean testing loss: 0.015093470923602581
epoch 84600  training loss: 0.012267395853996277
epoch 84600  clean testing loss: 0.015092876739799976
epoch 84700  training loss: 0.012267299927771091
epoch 84700  clean testing loss: 0.015092188492417336
epoch 84800  training loss: 0.01226730551570654
epoch 84800  clean testing loss: 0.015091159380972385
epoch 84900  training loss: 0.012267254292964935

 86%|████████████████████████████████████████████████████████████████████▍           | 85603/100000 [04:42<00:44, 321.88it/s]
epoch 85000  training loss: 0.012267217971384525
epoch 85000  clean testing loss: 0.01509242132306099
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 85100  training loss: 0.01226709596812725
epoch 85100  clean testing loss: 0.015092425048351288
epoch 85200  training loss: 0.012267062440514565
epoch 85200  clean testing loss: 0.015091932378709316
epoch 85300  training loss: 0.012266992591321468
epoch 85300  clean testing loss: 0.015091556124389172
epoch 85400  training loss: 0.01226705964654684
epoch 85400  clean testing loss: 0.015092218294739723
epoch 85500  training loss: 0.012266873382031918
epoch 85500  clean testing loss: 0.015090691857039928
epoch 85600  training loss: 0.01226699911057949

 86%|████████████████████████████████████████████████████████████████████▉           | 86228/100000 [04:44<00:42, 322.52it/s]
epoch 85700  training loss: 0.012266937643289566
epoch 85700  clean testing loss: 0.01509062759578228
epoch 85800  training loss: 0.01226693857461214
epoch 85800  clean testing loss: 0.015092115849256516
epoch 85900  training loss: 0.012266859412193298
epoch 85900  clean testing loss: 0.01509176753461361
epoch 86000  training loss: 0.01226678118109703
epoch 86000  clean testing loss: 0.015090221539139748
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 86100  training loss: 0.012266803532838821
epoch 86100  clean testing loss: 0.01509162038564682
epoch 86200  training loss: 0.012266699224710464

 87%|█████████████████████████████████████████████████████████████████████▌          | 86888/100000 [04:46<00:40, 322.94it/s]
epoch 86300  training loss: 0.012266723439097404
epoch 86300  clean testing loss: 0.015090960077941418
epoch 86400  training loss: 0.012266858480870724
epoch 86400  clean testing loss: 0.01509058102965355
epoch 86500  training loss: 0.012266598641872406
epoch 86500  clean testing loss: 0.015091602690517902
epoch 86600  training loss: 0.012266579084098339
epoch 86600  clean testing loss: 0.015091280452907085
epoch 86700  training loss: 0.01226651668548584
epoch 86700  clean testing loss: 0.015088986605405807
epoch 86800  training loss: 0.012266596779227257
epoch 86800  clean testing loss: 0.015092385932803154
epoch 86900  training loss: 0.012266447767615318

 88%|██████████████████████████████████████████████████████████████████████          | 87514/100000 [04:48<00:38, 322.03it/s]
epoch 87000  training loss: 0.012266476638615131
epoch 87000  clean testing loss: 0.015090258792042732
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 87100  training loss: 0.01226643193513155
epoch 87100  clean testing loss: 0.015091254375874996
epoch 87200  training loss: 0.01226646825671196
epoch 87200  clean testing loss: 0.015091621316969395
epoch 87300  training loss: 0.01226638164371252
epoch 87300  clean testing loss: 0.015091667883098125
epoch 87400  training loss: 0.01226640772074461
epoch 87400  clean testing loss: 0.015091557055711746
epoch 87500  training loss: 0.012266361154615879

 88%|██████████████████████████████████████████████████████████████████████▌         | 88172/100000 [04:50<00:36, 322.17it/s]
epoch 87600  training loss: 0.01226633321493864
epoch 87600  clean testing loss: 0.015090830624103546
epoch 87700  training loss: 0.012266269885003567
epoch 87700  clean testing loss: 0.015091709792613983
epoch 87800  training loss: 0.01226623635739088
epoch 87800  clean testing loss: 0.015091552399098873
epoch 87900  training loss: 0.012266308069229126
epoch 87900  clean testing loss: 0.015090389177203178
epoch 88000  training loss: 0.012266280129551888
epoch 88000  clean testing loss: 0.015091469511389732
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 88100  training loss: 0.012266209349036217

 89%|███████████████████████████████████████████████████████████████████████         | 88832/100000 [04:52<00:34, 321.40it/s]
epoch 88200  training loss: 0.012266206555068493
epoch 88200  clean testing loss: 0.015090348199009895
epoch 88300  training loss: 0.01226613949984312
epoch 88300  clean testing loss: 0.015089796856045723
epoch 88400  training loss: 0.012266108766198158
epoch 88400  clean testing loss: 0.015089394524693489
epoch 88500  training loss: 0.012266036123037338
epoch 88500  clean testing loss: 0.015090664848685265
epoch 88600  training loss: 0.012266087345778942
epoch 88600  clean testing loss: 0.015090505592525005
epoch 88700  training loss: 0.012265980243682861
epoch 88700  clean testing loss: 0.015089944936335087
epoch 88800  training loss: 0.012265861965715885

 89%|███████████████████████████████████████████████████████████████████████▌        | 89458/100000 [04:54<00:32, 322.08it/s]
epoch 88900  training loss: 0.012265871278941631
epoch 88900  clean testing loss: 0.01508994959294796
epoch 89000  training loss: 0.012265980243682861
epoch 89000  clean testing loss: 0.015090512111783028
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 89100  training loss: 0.012265900149941444
epoch 89100  clean testing loss: 0.01508967112749815
epoch 89200  training loss: 0.012265726923942566
epoch 89200  clean testing loss: 0.015091356821358204
epoch 89300  training loss: 0.01226586289703846
epoch 89300  clean testing loss: 0.015089893713593483
epoch 89400  training loss: 0.012265922501683235

 90%|████████████████████████████████████████████████████████████████████████        | 90114/100000 [04:56<00:30, 320.39it/s]
epoch 89500  training loss: 0.012265888974070549
epoch 89500  clean testing loss: 0.015090073458850384
epoch 89600  training loss: 0.012265720404684544
epoch 89600  clean testing loss: 0.015089593827724457
epoch 89700  training loss: 0.012265630066394806
epoch 89700  clean testing loss: 0.015090462751686573
epoch 89800  training loss: 0.012265647761523724
epoch 89800  clean testing loss: 0.01508849486708641
epoch 89900  training loss: 0.012265529483556747
epoch 89900  clean testing loss: 0.015091345645487309
epoch 90000  training loss: 0.01226559467613697
epoch 90000  clean testing loss: 0.015088501386344433
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 90100  training loss: 0.012265599332749844

 91%|████████████████████████████████████████████████████████████████████████▌       | 90740/100000 [04:58<00:28, 322.18it/s]
epoch 90200  training loss: 0.012265549041330814
epoch 90200  clean testing loss: 0.015089651569724083
epoch 90300  training loss: 0.012265607714653015
epoch 90300  clean testing loss: 0.01508941687643528
epoch 90400  training loss: 0.012265498749911785
epoch 90400  clean testing loss: 0.015090283006429672
epoch 90500  training loss: 0.012265566736459732
epoch 90500  clean testing loss: 0.015088650397956371
epoch 90600  training loss: 0.012265557423233986
epoch 90600  clean testing loss: 0.01508907787501812
epoch 90700  training loss: 0.012265450321137905

 91%|█████████████████████████████████████████████████████████████████████████       | 91401/100000 [05:00<00:26, 320.56it/s]
epoch 90800  training loss: 0.012265394441783428
epoch 90800  clean testing loss: 0.015089265070855618
epoch 90900  training loss: 0.012265404686331749
epoch 90900  clean testing loss: 0.015089728869497776
epoch 91000  training loss: 0.012265346944332123
epoch 91000  clean testing loss: 0.015088816173374653
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 91100  training loss: 0.0122653404250741
epoch 91100  clean testing loss: 0.01508841197937727
epoch 91200  training loss: 0.012265346944332123
epoch 91200  clean testing loss: 0.015089218504726887
epoch 91300  training loss: 0.012265299446880817
epoch 91300  clean testing loss: 0.015088574960827827
epoch 91400  training loss: 0.012265332043170929

 92%|█████████████████████████████████████████████████████████████████████████▋      | 92061/100000 [05:02<00:24, 319.28it/s]
epoch 91500  training loss: 0.01226531621068716
epoch 91500  clean testing loss: 0.015088233165442944
epoch 91600  training loss: 0.012265225872397423
epoch 91600  clean testing loss: 0.015088467858731747
epoch 91700  training loss: 0.01226531621068716
epoch 91700  clean testing loss: 0.015089098364114761
epoch 91800  training loss: 0.012265166267752647
epoch 91800  clean testing loss: 0.0150893060490489
epoch 91900  training loss: 0.012265119701623917
epoch 91900  clean testing loss: 0.015088495798408985
epoch 92000  training loss: 0.01226496510207653
epoch 92000  clean testing loss: 0.01508956216275692

 93%|██████████████████████████████████████████████████████████████████████████▏     | 92687/100000 [05:04<00:22, 323.36it/s]
epoch 92100  training loss: 0.012265114113688469
epoch 92100  clean testing loss: 0.015089278109371662
epoch 92200  training loss: 0.012265174649655819
epoch 92200  clean testing loss: 0.015087741427123547
epoch 92300  training loss: 0.012265176512300968
epoch 92300  clean testing loss: 0.015089218504726887
epoch 92400  training loss: 0.012265031225979328
epoch 92400  clean testing loss: 0.015089234337210655
epoch 92500  training loss: 0.012264957651495934
epoch 92500  clean testing loss: 0.015088801272213459
epoch 92600  training loss: 0.012264822609722614
epoch 92600  clean testing loss: 0.01508820429444313
epoch 92700  training loss: 0.012265060096979141

 93%|██████████████████████████████████████████████████████████████████████████▋     | 93346/100000 [05:06<00:20, 320.70it/s]
epoch 92800  training loss: 0.012265017256140709
epoch 92800  clean testing loss: 0.015088437125086784
epoch 92900  training loss: 0.012264903634786606
epoch 92900  clean testing loss: 0.01508945133537054
epoch 93000  training loss: 0.012264848686754704
epoch 93000  clean testing loss: 0.015090002678334713
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 93100  training loss: 0.012264937162399292
epoch 93100  clean testing loss: 0.015089194290339947
epoch 93200  training loss: 0.01226484403014183
epoch 93200  clean testing loss: 0.015088181011378765
epoch 93300  training loss: 0.012264741584658623

 94%|███████████████████████████████████████████████████████████████████████████▏    | 93971/100000 [05:08<00:18, 321.73it/s]
epoch 93400  training loss: 0.012264769524335861
epoch 93400  clean testing loss: 0.015088007785379887
epoch 93500  training loss: 0.012264873832464218
epoch 93500  clean testing loss: 0.015088425017893314
epoch 93600  training loss: 0.012264681048691273
epoch 93600  clean testing loss: 0.015088566578924656
epoch 93700  training loss: 0.012264738790690899
epoch 93700  clean testing loss: 0.015088877640664577
epoch 93800  training loss: 0.012264706194400787
epoch 93800  clean testing loss: 0.015088414773344994
epoch 93900  training loss: 0.012264790013432503

 95%|███████████████████████████████████████████████████████████████████████████▋    | 94631/100000 [05:10<00:16, 321.14it/s]
epoch 94000  training loss: 0.012264719232916832
epoch 94000  clean testing loss: 0.015087186358869076
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 94100  training loss: 0.012264685705304146
epoch 94100  clean testing loss: 0.015089074149727821
epoch 94200  training loss: 0.012264649383723736
epoch 94200  clean testing loss: 0.015087953768670559
epoch 94300  training loss: 0.012264705263078213
epoch 94300  clean testing loss: 0.015087996609508991
epoch 94400  training loss: 0.012264574877917767
epoch 94400  clean testing loss: 0.015088507905602455
epoch 94500  training loss: 0.012264678254723549
epoch 94500  clean testing loss: 0.015087733045220375
epoch 94600  training loss: 0.012264573015272617

 95%|████████████████████████████████████████████████████████████████████████████▏   | 95257/100000 [05:12<00:14, 320.26it/s]
epoch 94700  training loss: 0.012264618650078773
epoch 94700  clean testing loss: 0.01508739497512579
epoch 94800  training loss: 0.012264505960047245
epoch 94800  clean testing loss: 0.015090028755366802
epoch 94900  training loss: 0.012264513410627842
epoch 94900  clean testing loss: 0.015088137239217758
epoch 95000  training loss: 0.012264513410627842
epoch 95000  clean testing loss: 0.015087725594639778
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 95100  training loss: 0.012264448218047619
epoch 95100  clean testing loss: 0.015087032690644264
epoch 95200  training loss: 0.012264497578144073

 96%|████████████████████████████████████████████████████████████████████████████▋   | 95917/100000 [05:14<00:12, 320.30it/s]
epoch 95300  training loss: 0.01226456742733717
epoch 95300  clean testing loss: 0.01508807297796011
epoch 95400  training loss: 0.012264274060726166
epoch 95400  clean testing loss: 0.015088459476828575
epoch 95500  training loss: 0.012264445424079895
epoch 95500  clean testing loss: 0.015088330022990704
epoch 95600  training loss: 0.012264427728950977
epoch 95600  clean testing loss: 0.015088492073118687
epoch 95700  training loss: 0.012264378368854523
epoch 95700  clean testing loss: 0.015088612213730812
epoch 95800  training loss: 0.012264324352145195
epoch 95800  clean testing loss: 0.015087425708770752
epoch 95900  training loss: 0.012264364399015903

 97%|█████████████████████████████████████████████████████████████████████████████▏  | 96544/100000 [05:16<00:10, 319.52it/s]
epoch 96000  training loss: 0.012264398857951164
epoch 96000  clean testing loss: 0.015088156796991825
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 96100  training loss: 0.012264336459338665
epoch 96100  clean testing loss: 0.015088194981217384
epoch 96200  training loss: 0.012264376506209373
epoch 96200  clean testing loss: 0.015087734907865524
epoch 96300  training loss: 0.012264334596693516
epoch 96300  clean testing loss: 0.015087603591382504
epoch 96400  training loss: 0.012264246121048927
epoch 96400  clean testing loss: 0.015088308602571487
epoch 96500  training loss: 0.012264147400856018

 97%|█████████████████████████████████████████████████████████████████████████████▊  | 97199/100000 [05:18<00:08, 319.99it/s]
epoch 96600  training loss: 0.012264198623597622
epoch 96600  clean testing loss: 0.015088510699570179
epoch 96700  training loss: 0.012264280579984188
epoch 96700  clean testing loss: 0.015087815001606941
epoch 96800  training loss: 0.012264269404113293
epoch 96800  clean testing loss: 0.015087311156094074
epoch 96900  training loss: 0.012264242395758629
epoch 96900  clean testing loss: 0.01508758869022131
epoch 97000  training loss: 0.01226420421153307
epoch 97000  clean testing loss: 0.015087587758898735
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 97100  training loss: 0.012264273129403591

 98%|██████████████████████████████████████████████████████████████████████████████▎ | 97826/100000 [05:20<00:06, 320.25it/s]
epoch 97200  training loss: 0.012264242395758629
epoch 97200  clean testing loss: 0.015087592415511608
epoch 97300  training loss: 0.012264198623597622
epoch 97300  clean testing loss: 0.015087303705513477
epoch 97400  training loss: 0.012264208868145943
epoch 97400  clean testing loss: 0.015087525360286236
epoch 97500  training loss: 0.012264111079275608
epoch 97500  clean testing loss: 0.015087400563061237
epoch 97600  training loss: 0.01226421445608139
epoch 97600  clean testing loss: 0.015087365172803402
epoch 97700  training loss: 0.012264038436114788
epoch 97700  clean testing loss: 0.015087676234543324
epoch 97800  training loss: 0.012264101766049862

 98%|██████████████████████████████████████████████████████████████████████████████▊ | 98484/100000 [05:22<00:04, 322.71it/s]
epoch 97900  training loss: 0.01226411946117878
epoch 97900  clean testing loss: 0.015087357722222805
epoch 98000  training loss: 0.012264066375792027
epoch 98000  clean testing loss: 0.015087605454027653
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 98100  training loss: 0.012263983488082886
epoch 98100  clean testing loss: 0.015087012201547623
epoch 98200  training loss: 0.012264094315469265
epoch 98200  clean testing loss: 0.01508768554776907
epoch 98300  training loss: 0.012264061719179153
epoch 98300  clean testing loss: 0.015087845735251904
epoch 98400  training loss: 0.012264128774404526

 99%|███████████████████████████████████████████████████████████████████████████████▎| 99144/100000 [05:24<00:02, 318.79it/s]
epoch 98500  training loss: 0.012263943441212177
epoch 98500  clean testing loss: 0.015086704865098
epoch 98600  training loss: 0.012263973243534565
epoch 98600  clean testing loss: 0.0150871267542243
epoch 98700  training loss: 0.012263992801308632
epoch 98700  clean testing loss: 0.01508716493844986
epoch 98800  training loss: 0.012263961136341095
epoch 98800  clean testing loss: 0.015087512321770191
epoch 98900  training loss: 0.012263912707567215
epoch 98900  clean testing loss: 0.015087619423866272
epoch 99000  training loss: 0.012263882905244827
epoch 99000  clean testing loss: 0.015087194740772247
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...
epoch 99100  training loss: 0.012263866141438484

100%|███████████████████████████████████████████████████████████████████████████████▊| 99771/100000 [05:26<00:00, 322.61it/s]
epoch 99200  training loss: 0.012263940647244453
epoch 99200  clean testing loss: 0.015087420120835304
epoch 99300  training loss: 0.012263908050954342
epoch 99300  clean testing loss: 0.015086879953742027
epoch 99400  training loss: 0.012263852171599865
epoch 99400  clean testing loss: 0.015087021514773369
epoch 99500  training loss: 0.012263894081115723
epoch 99500  clean testing loss: 0.015087291598320007
epoch 99600  training loss: 0.012263786979019642
epoch 99600  clean testing loss: 0.015086911618709564
epoch 99700  training loss: 0.012263835407793522

100%|███████████████████████████████████████████████████████████████████████████████| 100000/100000 [05:27<00:00, 305.70it/s]
epoch 99800  training loss: 0.012263922020792961
epoch 99800  clean testing loss: 0.015086830593645573
epoch 99900  training loss: 0.01226377859711647
epoch 99900  clean testing loss: 0.01508722547441721
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise0.00e+00_invop0_lr0.005 ...