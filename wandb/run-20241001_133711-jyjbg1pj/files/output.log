
  0%|▏                                                                                 | 701/300000 [00:01<09:25, 529.38it/s]
epoch 0  training loss: 0.5219123959541321
epoch 0  clean testing loss: 0.4970046281814575
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-02_invop0 ...
epoch 100  training loss: 0.1945577710866928
epoch 100  clean testing loss: 0.1719091832637787
epoch 200  training loss: 0.13635268807411194
epoch 200  clean testing loss: 0.11502132564783096
epoch 300  training loss: 0.12578032910823822
epoch 300  clean testing loss: 0.1021052747964859
epoch 400  training loss: 0.11467865854501724
epoch 400  clean testing loss: 0.08858466893434525
epoch 500  training loss: 0.10479149967432022
epoch 500  clean testing loss: 0.07716359198093414
epoch 600  training loss: 0.09697727113962173
epoch 600  clean testing loss: 0.06896336376667023
epoch 700  training loss: 0.09108968079090118

  1%|▍                                                                                | 1724/300000 [00:03<10:11, 487.78it/s]
epoch 800  training loss: 0.08658324182033539
epoch 800  clean testing loss: 0.05853578448295593
epoch 900  training loss: 0.08286808431148529
epoch 900  clean testing loss: 0.054564908146858215
epoch 1000  training loss: 0.07961955666542053
epoch 1000  clean testing loss: 0.05150711536407471
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-02_invop0 ...
epoch 1100  training loss: 0.0766502246260643
epoch 1100  clean testing loss: 0.048658572137355804
epoch 1200  training loss: 0.0739893689751625
epoch 1200  clean testing loss: 0.04612023010849953
epoch 1300  training loss: 0.0716039165854454
epoch 1300  clean testing loss: 0.044244226068258286
epoch 1400  training loss: 0.06960606575012207
epoch 1400  clean testing loss: 0.042590007185935974
epoch 1500  training loss: 0.06800760328769684
epoch 1500  clean testing loss: 0.041809577494859695
epoch 1600  training loss: 0.06666095554828644
epoch 1600  clean testing loss: 0.04109058529138565
epoch 1700  training loss: 0.0655704140663147
epoch 1700  clean testing loss: 0.04059358313679695
epoch 1800  training loss: 0.06475812196731567

  1%|▊                                                                                | 2802/300000 [00:05<09:18, 532.53it/s]
epoch 1900  training loss: 0.06396546214818954
epoch 1900  clean testing loss: 0.04010046645998955
epoch 2000  training loss: 0.06329475343227386
epoch 2000  clean testing loss: 0.039825864136219025
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-02_invop0 ...
epoch 2100  training loss: 0.06275404989719391
epoch 2100  clean testing loss: 0.039924394339323044
epoch 2200  training loss: 0.062138382345438004
epoch 2200  clean testing loss: 0.03959713876247406
epoch 2300  training loss: 0.0616014190018177
epoch 2300  clean testing loss: 0.03947639837861061
epoch 2400  training loss: 0.061130668967962265
epoch 2400  clean testing loss: 0.03958435729146004
epoch 2500  training loss: 0.060624860227108
epoch 2500  clean testing loss: 0.03930916637182236
epoch 2600  training loss: 0.06016939878463745
epoch 2600  clean testing loss: 0.03930290415883064
epoch 2700  training loss: 0.0597294420003891
epoch 2700  clean testing loss: 0.03929368779063225
epoch 2800  training loss: 0.059316057711839676

  1%|█                                                                                | 3882/300000 [00:07<09:16, 531.79it/s]
epoch 2900  training loss: 0.058950137346982956
epoch 2900  clean testing loss: 0.039220619946718216
epoch 3000  training loss: 0.0585906021296978
epoch 3000  clean testing loss: 0.03939573094248772
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-02_invop0 ...
epoch 3100  training loss: 0.05819552764296532
epoch 3100  clean testing loss: 0.03931794315576553
epoch 3200  training loss: 0.05786583200097084
epoch 3200  clean testing loss: 0.039344802498817444
epoch 3300  training loss: 0.057531338185071945
epoch 3300  clean testing loss: 0.039332207292318344
epoch 3400  training loss: 0.057241253554821014
epoch 3400  clean testing loss: 0.039474967867136
epoch 3500  training loss: 0.056895967572927475
epoch 3500  clean testing loss: 0.0393327921628952
epoch 3600  training loss: 0.056544333696365356
epoch 3600  clean testing loss: 0.039406925439834595
epoch 3700  training loss: 0.05625733733177185
epoch 3700  clean testing loss: 0.039364419877529144
epoch 3800  training loss: 0.05594432353973389
epoch 3800  clean testing loss: 0.03941815719008446
epoch 3900  training loss: 0.0556969940662384

  2%|█▎                                                                               | 4962/300000 [00:09<09:13, 533.42it/s]
epoch 4000  training loss: 0.05542318522930145
epoch 4000  clean testing loss: 0.03937027230858803
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-02_invop0 ...
epoch 4100  training loss: 0.05515492707490921
epoch 4100  clean testing loss: 0.03943502902984619
epoch 4200  training loss: 0.054983559995889664
epoch 4200  clean testing loss: 0.03940067067742348
epoch 4300  training loss: 0.054651934653520584
epoch 4300  clean testing loss: 0.03944388031959534
epoch 4400  training loss: 0.05444323271512985
epoch 4400  clean testing loss: 0.03947215527296066
epoch 4500  training loss: 0.054229479283094406
epoch 4500  clean testing loss: 0.03949351608753204
epoch 4600  training loss: 0.05406108498573303
epoch 4600  clean testing loss: 0.03979988396167755
epoch 4700  training loss: 0.053797341883182526
epoch 4700  clean testing loss: 0.03960020840167999
epoch 4800  training loss: 0.05370674282312393
epoch 4800  clean testing loss: 0.03992842882871628
epoch 4900  training loss: 0.053492527455091476
epoch 4900  clean testing loss: 0.0396571047604084
epoch 5000  training loss: 0.053240809589624405
epoch 5000  clean testing loss: 0.03979586064815521

  2%|█▌                                                                               | 5988/300000 [00:11<09:09, 534.62it/s]
epoch 5100  training loss: 0.05306241661310196
epoch 5100  clean testing loss: 0.0397426038980484
epoch 5200  training loss: 0.052927035838365555
epoch 5200  clean testing loss: 0.039741579443216324
epoch 5300  training loss: 0.05276932939887047
epoch 5300  clean testing loss: 0.03978234902024269
epoch 5400  training loss: 0.05261702835559845
epoch 5400  clean testing loss: 0.04002395644783974
epoch 5500  training loss: 0.052488163113594055
epoch 5500  clean testing loss: 0.04010181128978729
epoch 5600  training loss: 0.0522645004093647
epoch 5600  clean testing loss: 0.04000138118863106
epoch 5700  training loss: 0.0521981455385685
epoch 5700  clean testing loss: 0.04010489955544472
epoch 5800  training loss: 0.05198752135038376
epoch 5800  clean testing loss: 0.0398961566388607
epoch 5900  training loss: 0.051815181970596313
epoch 5900  clean testing loss: 0.03999272361397743
epoch 6000  training loss: 0.051683396100997925
epoch 6000  clean testing loss: 0.039987824857234955

  2%|█▋                                                                               | 6100/300000 [00:11<09:22, 522.72it/s]
epoch 6100  training loss: 0.05152713134884834
epoch 6100  clean testing loss: 0.04001586139202118
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-02_invop0 ...