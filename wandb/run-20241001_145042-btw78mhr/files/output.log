

  0%|▏                                                                                 | 749/300000 [00:07<10:32, 472.87it/s]
epoch 0  training loss: 43.99616241455078
epoch 0  clean testing loss: 0.47397977113723755
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 100  training loss: 43.40073013305664
epoch 100  clean testing loss: 0.15858890116214752
epoch 200  training loss: 42.91409683227539
epoch 200  clean testing loss: 0.231209859251976
epoch 300  training loss: 42.64456558227539
epoch 300  clean testing loss: 0.3403122127056122
epoch 400  training loss: 42.276939392089844
epoch 400  clean testing loss: 0.6049443483352661
epoch 500  training loss: 41.86884307861328
epoch 500  clean testing loss: 1.0610555410385132
epoch 600  training loss: 41.500431060791016
epoch 600  clean testing loss: 1.4504694938659668
epoch 700  training loss: 41.1214714050293

  0%|▍                                                                                | 1454/300000 [00:08<09:14, 538.67it/s]
epoch 800  training loss: 40.68487548828125
epoch 800  clean testing loss: 2.1648690700531006
epoch 900  training loss: 40.188072204589844
epoch 900  clean testing loss: 2.646338939666748
epoch 1000  training loss: 39.59297180175781
epoch 1000  clean testing loss: 3.167027473449707
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 1100  training loss: 38.89664840698242
epoch 1100  clean testing loss: 3.8215181827545166
epoch 1200  training loss: 38.180721282958984
epoch 1200  clean testing loss: 4.599477767944336
epoch 1300  training loss: 37.4708137512207
epoch 1300  clean testing loss: 5.3109612464904785
epoch 1400  training loss: 36.77188491821289
epoch 1400  clean testing loss: 5.9684319496154785
epoch 1500  training loss: 36.09668731689453
epoch 1500  clean testing loss: 6.562224864959717
epoch 1600  training loss: 35.45526885986328
epoch 1600  clean testing loss: 6.965968132019043
epoch 1700  training loss: 34.81822204589844
epoch 1700  clean testing loss: 7.326211929321289
epoch 1800  training loss: 34.21516799926758
epoch 1800  clean testing loss: 7.779635906219482
epoch 1900  training loss: 33.64634704589844
epoch 1900  clean testing loss: 8.243138313293457
epoch 2000  training loss: 33.1403923034668
epoch 2000  clean testing loss: 8.694901466369629

  1%|▊                                                                                | 2806/300000 [00:13<09:36, 515.64it/s]
epoch 2100  training loss: 32.681434631347656
epoch 2100  clean testing loss: 9.147831916809082
epoch 2200  training loss: 32.237083435058594
epoch 2200  clean testing loss: 9.469985008239746
epoch 2300  training loss: 31.759523391723633
epoch 2300  clean testing loss: 9.86733627319336
epoch 2400  training loss: 31.327301025390625
epoch 2400  clean testing loss: 10.139707565307617
epoch 2500  training loss: 30.874759674072266
epoch 2500  clean testing loss: 10.480313301086426
epoch 2600  training loss: 30.493127822875977
epoch 2600  clean testing loss: 10.851606369018555
epoch 2700  training loss: 30.082080841064453
epoch 2700  clean testing loss: 11.210958480834961
epoch 2800  training loss: 29.736576080322266
epoch 2800  clean testing loss: 11.569107055664062
epoch 2900  training loss: 29.36832046508789
epoch 2900  clean testing loss: 11.877814292907715
epoch 3000  training loss: 29.0577392578125
epoch 3000  clean testing loss: 12.281853675842285
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...

epoch 3100  training loss: 28.749216079711914
epoch 3100  clean testing loss: 12.471406936645508
epoch 3200  training loss: 28.49523162841797
epoch 3200  clean testing loss: 12.715751647949219
epoch 3300  training loss: 28.236669540405273
epoch 3300  clean testing loss: 13.004504203796387
epoch 3400  training loss: 27.986284255981445
epoch 3400  clean testing loss: 13.287816047668457
epoch 3500  training loss: 27.774532318115234
epoch 3500  clean testing loss: 13.649090766906738
epoch 3600  training loss: 27.511404037475586
epoch 3600  clean testing loss: 13.8290376663208
epoch 3700  training loss: 27.292877197265625
epoch 3700  clean testing loss: 13.96222972869873
epoch 3800  training loss: 27.044818878173828
epoch 3800  clean testing loss: 14.268596649169922
epoch 3900  training loss: 26.83091163635254
epoch 3900  clean testing loss: 14.510122299194336
epoch 4000  training loss: 26.617576599121094
epoch 4000  clean testing loss: 14.713748931884766
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 4100  training loss: 26.459915161132812

  2%|█▎                                                                               | 4912/300000 [00:17<09:14, 532.00it/s]
epoch 4200  training loss: 26.272024154663086
epoch 4200  clean testing loss: 15.345623016357422
epoch 4300  training loss: 26.036209106445312
epoch 4300  clean testing loss: 15.504908561706543
epoch 4400  training loss: 25.90328025817871
epoch 4400  clean testing loss: 15.614813804626465
epoch 4500  training loss: 25.72950553894043
epoch 4500  clean testing loss: 15.95180892944336
epoch 4600  training loss: 25.485172271728516
epoch 4600  clean testing loss: 16.087081909179688
epoch 4700  training loss: 25.305683135986328
epoch 4700  clean testing loss: 16.26106071472168
epoch 4800  training loss: 25.19853401184082
epoch 4800  clean testing loss: 16.67609214782715
epoch 4900  training loss: 25.00002098083496
epoch 4900  clean testing loss: 16.815397262573242
epoch 5000  training loss: 24.883018493652344
epoch 5000  clean testing loss: 17.21209144592285
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 5100  training loss: 24.678308486938477
epoch 5100  clean testing loss: 17.23636817932129
epoch 5200  training loss: 24.51338005065918

  2%|█▌                                                                               | 5992/300000 [00:19<09:12, 531.67it/s]
epoch 5300  training loss: 24.40117645263672
epoch 5300  clean testing loss: 17.850351333618164
epoch 5400  training loss: 24.168184280395508
epoch 5400  clean testing loss: 17.881357192993164
epoch 5500  training loss: 24.01972007751465
epoch 5500  clean testing loss: 18.12131690979004
epoch 5600  training loss: 23.85988426208496
epoch 5600  clean testing loss: 18.28993797302246
epoch 5700  training loss: 23.722763061523438
epoch 5700  clean testing loss: 18.52776336669922
epoch 5800  training loss: 23.572572708129883
epoch 5800  clean testing loss: 18.730005264282227
epoch 5900  training loss: 23.419532775878906
epoch 5900  clean testing loss: 18.92652130126953
epoch 6000  training loss: 23.282041549682617
epoch 6000  clean testing loss: 19.15312957763672
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 6100  training loss: 23.145822525024414
epoch 6100  clean testing loss: 19.295169830322266
epoch 6200  training loss: 23.020641326904297

  2%|█▊                                                                               | 6856/300000 [00:21<09:08, 534.21it/s]
epoch 6300  training loss: 22.902469635009766
epoch 6300  clean testing loss: 19.624372482299805
epoch 6400  training loss: 22.786470413208008
epoch 6400  clean testing loss: 19.85675811767578
epoch 6500  training loss: 22.619001388549805
epoch 6500  clean testing loss: 20.058029174804688
epoch 6600  training loss: 22.54839324951172
epoch 6600  clean testing loss: 20.360361099243164
epoch 6700  training loss: 22.429779052734375
epoch 6700  clean testing loss: 20.444454193115234
epoch 6800  training loss: 22.297903060913086
epoch 6800  clean testing loss: 20.718400955200195
epoch 6900  training loss: 22.2075252532959

  2%|█▊                                                                              | 7018/300000 [00:25<1:57:09, 41.68it/s]
epoch 7000  training loss: 22.05541229248047
epoch 7000  clean testing loss: 21.005889892578125
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 7100  training loss: 21.9814510345459
epoch 7100  clean testing loss: 21.162555694580078
epoch 7200  training loss: 21.85698127746582
epoch 7200  clean testing loss: 21.434364318847656
epoch 7300  training loss: 21.72007942199707

  3%|██▏                                                                              | 8149/300000 [00:27<09:15, 525.74it/s]
epoch 7400  training loss: 21.641183853149414
epoch 7400  clean testing loss: 21.696590423583984
epoch 7500  training loss: 21.530208587646484
epoch 7500  clean testing loss: 21.75722312927246
epoch 7600  training loss: 21.402496337890625
epoch 7600  clean testing loss: 21.91486930847168
epoch 7700  training loss: 21.295766830444336
epoch 7700  clean testing loss: 22.03636360168457
epoch 7800  training loss: 21.23877716064453
epoch 7800  clean testing loss: 22.19585609436035
epoch 7900  training loss: 21.123212814331055
epoch 7900  clean testing loss: 22.38024139404297
epoch 8000  training loss: 20.993118286132812
epoch 8000  clean testing loss: 22.450672149658203
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 8100  training loss: 20.928207397460938

  3%|██▍                                                                              | 9175/300000 [00:29<09:08, 530.54it/s]
epoch 8200  training loss: 20.786396026611328
epoch 8200  clean testing loss: 22.6860294342041
epoch 8300  training loss: 20.68924331665039
epoch 8300  clean testing loss: 22.858535766601562
epoch 8400  training loss: 20.607465744018555
epoch 8400  clean testing loss: 23.06153106689453
epoch 8500  training loss: 20.433704376220703
epoch 8500  clean testing loss: 23.05569839477539
epoch 8600  training loss: 20.405471801757812
epoch 8600  clean testing loss: 23.18030548095703
epoch 8700  training loss: 20.263273239135742
epoch 8700  clean testing loss: 23.385812759399414
epoch 8800  training loss: 20.184965133666992
epoch 8800  clean testing loss: 23.489524841308594
epoch 8900  training loss: 20.122915267944336
epoch 8900  clean testing loss: 23.60697364807129
epoch 9000  training loss: 19.97136878967285
epoch 9000  clean testing loss: 23.770238876342773
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 9100  training loss: 19.881738662719727
epoch 9100  clean testing loss: 23.846555709838867
epoch 9200  training loss: 19.80584716796875

  3%|██▋                                                                             | 10255/300000 [00:31<09:04, 532.34it/s]
epoch 9300  training loss: 19.721097946166992
epoch 9300  clean testing loss: 24.105669021606445
epoch 9400  training loss: 19.65233039855957
epoch 9400  clean testing loss: 24.23115348815918
epoch 9500  training loss: 19.621917724609375
epoch 9500  clean testing loss: 24.437984466552734
epoch 9600  training loss: 19.482421875
epoch 9600  clean testing loss: 24.4764347076416
epoch 9700  training loss: 19.418434143066406
epoch 9700  clean testing loss: 24.619176864624023
epoch 9800  training loss: 19.347375869750977
epoch 9800  clean testing loss: 24.762331008911133
epoch 9900  training loss: 19.252458572387695
epoch 9900  clean testing loss: 24.94524574279785
epoch 10000  training loss: 19.221006393432617
epoch 10000  clean testing loss: 25.11424446105957
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 10100  training loss: 19.100383758544922
epoch 10100  clean testing loss: 25.19112205505371
epoch 10200  training loss: 19.022634506225586
epoch 10200  clean testing loss: 25.33546257019043
epoch 10300  training loss: 18.93850326538086

  3%|██▊                                                                             | 10471/300000 [00:31<09:03, 532.91it/s]
epoch 10400  training loss: 18.873018264770508
epoch 10400  clean testing loss: 25.647239685058594
epoch 10500  training loss: 18.833572387695312
epoch 10500  clean testing loss: 25.87653350830078
epoch 10600  training loss: 18.751075744628906
epoch 10600  clean testing loss: 25.971298217773438
epoch 10700  training loss: 18.686019897460938
epoch 10700  clean testing loss: 26.152502059936523
epoch 10800  training loss: 18.612154006958008
epoch 10800  clean testing loss: 26.267677307128906
epoch 10900  training loss: 18.519142150878906
epoch 10900  clean testing loss: 26.352317810058594
epoch 11000  training loss: 18.486988067626953
epoch 11000  clean testing loss: 26.43861961364746
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 11100  training loss: 18.364301681518555
epoch 11100  clean testing loss: 26.563907623291016
epoch 11200  training loss: 18.277849197387695
epoch 11200  clean testing loss: 26.701995849609375
epoch 11300  training loss: 18.233407974243164
epoch 11300  clean testing loss: 26.879287719726562
epoch 11400  training loss: 18.179981231689453
epoch 11400  clean testing loss: 27.056962966918945
epoch 11500  training loss: 18.07783317565918
epoch 11500  clean testing loss: 27.13222312927246
epoch 11600  training loss: 18.004911422729492
epoch 11600  clean testing loss: 27.23785972595215
epoch 11700  training loss: 17.994720458984375
epoch 11700  clean testing loss: 27.352441787719727
epoch 11800  training loss: 17.909093856811523

  4%|███▏                                                                            | 11820/300000 [00:36<09:13, 520.60it/s]
epoch 11900  training loss: 17.868677139282227
epoch 11900  clean testing loss: 27.635950088500977
epoch 12000  training loss: 17.754711151123047
epoch 12000  clean testing loss: 27.68642234802246
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 12100  training loss: 17.701080322265625
epoch 12100  clean testing loss: 27.80796241760254
epoch 12200  training loss: 17.65070343017578
epoch 12200  clean testing loss: 27.901565551757812
epoch 12300  training loss: 17.596466064453125
epoch 12300  clean testing loss: 28.02070426940918
epoch 12400  training loss: 17.569334030151367
epoch 12400  clean testing loss: 28.15250015258789
epoch 12500  training loss: 17.520858764648438
epoch 12500  clean testing loss: 28.194259643554688
epoch 12600  training loss: 17.44905662536621
epoch 12600  clean testing loss: 28.358341217041016
epoch 12700  training loss: 17.415048599243164
epoch 12700  clean testing loss: 28.48615837097168
epoch 12800  training loss: 17.36225700378418
epoch 12800  clean testing loss: 28.576473236083984
epoch 12900  training loss: 17.306732177734375

  4%|███▍                                                                            | 12900/300000 [00:38<08:58, 533.01it/s]
epoch 13000  training loss: 17.239160537719727
epoch 13000  clean testing loss: 28.74090003967285
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 13100  training loss: 17.21233558654785
epoch 13100  clean testing loss: 28.92223358154297
epoch 13200  training loss: 17.124835968017578
epoch 13200  clean testing loss: 28.961544036865234
epoch 13300  training loss: 17.090267181396484
epoch 13300  clean testing loss: 29.099958419799805
epoch 13400  training loss: 17.040462493896484
epoch 13400  clean testing loss: 29.1855525970459
epoch 13500  training loss: 16.97403907775879
epoch 13500  clean testing loss: 29.28711700439453
epoch 13600  training loss: 16.942426681518555
epoch 13600  clean testing loss: 29.38167381286621
epoch 13700  training loss: 16.893564224243164
epoch 13700  clean testing loss: 29.48723030090332
epoch 13800  training loss: 16.829084396362305
epoch 13800  clean testing loss: 29.580852508544922
epoch 13900  training loss: 16.757003784179688
epoch 13900  clean testing loss: 29.663618087768555
epoch 14000  training loss: 16.737178802490234
epoch 14000  clean testing loss: 29.846599578857422

  5%|███▋                                                                            | 13980/300000 [00:40<08:55, 534.37it/s]
epoch 14100  training loss: 16.650131225585938
epoch 14100  clean testing loss: 29.940929412841797
epoch 14200  training loss: 16.62346649169922
epoch 14200  clean testing loss: 30.05424690246582
epoch 14300  training loss: 16.608673095703125
epoch 14300  clean testing loss: 30.220413208007812
epoch 14400  training loss: 16.50850486755371
epoch 14400  clean testing loss: 30.28561782836914
epoch 14500  training loss: 16.51701545715332
epoch 14500  clean testing loss: 30.46320915222168
epoch 14600  training loss: 16.42194938659668
epoch 14600  clean testing loss: 30.54132843017578
epoch 14700  training loss: 16.406009674072266
epoch 14700  clean testing loss: 30.689477920532227
epoch 14800  training loss: 16.339147567749023
epoch 14800  clean testing loss: 30.795310974121094
epoch 14900  training loss: 16.263427734375
epoch 14900  clean testing loss: 30.858684539794922
epoch 15000  training loss: 16.240524291992188
epoch 15000  clean testing loss: 30.96855354309082

  5%|████                                                                            | 15060/300000 [00:42<08:56, 531.14it/s]
epoch 15100  training loss: 16.174236297607422
epoch 15100  clean testing loss: 31.073974609375
epoch 15200  training loss: 16.13670539855957
epoch 15200  clean testing loss: 31.173946380615234
epoch 15300  training loss: 16.095428466796875
epoch 15300  clean testing loss: 31.262914657592773
epoch 15400  training loss: 16.05762481689453
epoch 15400  clean testing loss: 31.37320899963379
epoch 15500  training loss: 16.03311538696289
epoch 15500  clean testing loss: 31.511011123657227
epoch 15600  training loss: 15.971053123474121
epoch 15600  clean testing loss: 31.613204956054688
epoch 15700  training loss: 15.928576469421387
epoch 15700  clean testing loss: 31.729978561401367
epoch 15800  training loss: 15.90868854522705
epoch 15800  clean testing loss: 31.83951759338379
epoch 15900  training loss: 15.860057830810547
epoch 15900  clean testing loss: 31.9681339263916
epoch 16000  training loss: 15.822065353393555
epoch 16000  clean testing loss: 32.08758544921875
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 16100  training loss: 15.799280166625977

  5%|████▎                                                                           | 16093/300000 [00:44<08:53, 532.15it/s]
epoch 16200  training loss: 15.73055362701416
epoch 16200  clean testing loss: 32.30244064331055
epoch 16300  training loss: 15.71522331237793
epoch 16300  clean testing loss: 32.4276123046875
epoch 16400  training loss: 15.65527629852295
epoch 16400  clean testing loss: 32.54261016845703
epoch 16500  training loss: 15.59683895111084
epoch 16500  clean testing loss: 32.62060546875
epoch 16600  training loss: 15.561359405517578
epoch 16600  clean testing loss: 32.72579574584961
epoch 16700  training loss: 15.540491104125977
epoch 16700  clean testing loss: 32.86050796508789
epoch 16800  training loss: 15.50513744354248
epoch 16800  clean testing loss: 32.96885299682617
epoch 16900  training loss: 15.471356391906738
epoch 16900  clean testing loss: 33.069461822509766
epoch 17000  training loss: 15.4232816696167
epoch 17000  clean testing loss: 33.127418518066406
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 17100  training loss: 15.373677253723145
epoch 17100  clean testing loss: 33.19355010986328
epoch 17200  training loss: 15.328773498535156

  6%|████▌                                                                           | 17186/300000 [00:46<08:44, 539.54it/s]
epoch 17300  training loss: 15.309399604797363
epoch 17300  clean testing loss: 33.40019607543945
epoch 17400  training loss: 15.246204376220703
epoch 17400  clean testing loss: 33.46928405761719
epoch 17500  training loss: 15.19568920135498
epoch 17500  clean testing loss: 33.57821273803711
epoch 17600  training loss: 15.160760879516602
epoch 17600  clean testing loss: 33.68575668334961
epoch 17700  training loss: 15.131717681884766
epoch 17700  clean testing loss: 33.796913146972656
epoch 17800  training loss: 15.114343643188477
epoch 17800  clean testing loss: 33.873443603515625
epoch 17900  training loss: 15.053678512573242
epoch 17900  clean testing loss: 33.95151901245117
epoch 18000  training loss: 15.018795013427734
epoch 18000  clean testing loss: 34.04226303100586
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 18100  training loss: 14.956663131713867
epoch 18100  clean testing loss: 34.1112060546875
epoch 18200  training loss: 14.919805526733398
epoch 18200  clean testing loss: 34.2049446105957
epoch 18300  training loss: 14.891193389892578

  6%|████▊                                                                           | 18281/300000 [00:48<08:47, 533.66it/s]
epoch 18400  training loss: 14.854942321777344
epoch 18400  clean testing loss: 34.38288116455078
epoch 18500  training loss: 14.824234962463379
epoch 18500  clean testing loss: 34.49113082885742
epoch 18600  training loss: 14.783334732055664
epoch 18600  clean testing loss: 34.550872802734375
epoch 18700  training loss: 14.76407527923584
epoch 18700  clean testing loss: 34.698089599609375
epoch 18800  training loss: 14.735270500183105
epoch 18800  clean testing loss: 34.76707077026367
epoch 18900  training loss: 14.696998596191406
epoch 18900  clean testing loss: 34.837181091308594
epoch 19000  training loss: 14.643567085266113
epoch 19000  clean testing loss: 34.923439025878906
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 19100  training loss: 14.597569465637207
epoch 19100  clean testing loss: 35.024986267089844
epoch 19200  training loss: 14.582058906555176
epoch 19200  clean testing loss: 35.141807556152344
epoch 19300  training loss: 14.55030632019043

  6%|█████▏                                                                          | 19361/300000 [00:50<08:47, 532.37it/s]
epoch 19400  training loss: 14.501995086669922
epoch 19400  clean testing loss: 35.363037109375
epoch 19500  training loss: 14.463700294494629
epoch 19500  clean testing loss: 35.477535247802734
epoch 19600  training loss: 14.44379711151123
epoch 19600  clean testing loss: 35.604793548583984
epoch 19700  training loss: 14.394681930541992
epoch 19700  clean testing loss: 35.71214294433594
epoch 19800  training loss: 14.361981391906738
epoch 19800  clean testing loss: 35.808876037597656
epoch 19900  training loss: 14.345946311950684
epoch 19900  clean testing loss: 35.91948699951172
epoch 20000  training loss: 14.298624038696289
epoch 20000  clean testing loss: 36.038963317871094
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 20100  training loss: 14.266822814941406
epoch 20100  clean testing loss: 36.13718795776367
epoch 20200  training loss: 14.246316909790039
epoch 20200  clean testing loss: 36.276878356933594
epoch 20300  training loss: 14.20383071899414
epoch 20300  clean testing loss: 36.41172409057617
epoch 20400  training loss: 14.173382759094238

  7%|█████▍                                                                          | 20444/300000 [00:52<08:39, 537.84it/s]
epoch 20500  training loss: 14.14522933959961
epoch 20500  clean testing loss: 36.62456130981445
epoch 20600  training loss: 14.114556312561035
epoch 20600  clean testing loss: 36.72455596923828
epoch 20700  training loss: 14.100604057312012
epoch 20700  clean testing loss: 36.86501693725586
epoch 20800  training loss: 14.0524320602417
epoch 20800  clean testing loss: 36.958133697509766
epoch 20900  training loss: 14.023239135742188
epoch 20900  clean testing loss: 37.042789459228516
epoch 21000  training loss: 14.012140274047852
epoch 21000  clean testing loss: 37.16669845581055
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 21100  training loss: 13.963203430175781
epoch 21100  clean testing loss: 37.26285171508789
epoch 21200  training loss: 13.93905258178711
epoch 21200  clean testing loss: 37.34482955932617
epoch 21300  training loss: 13.914945602416992
epoch 21300  clean testing loss: 37.42470932006836
epoch 21400  training loss: 13.894455909729004
epoch 21400  clean testing loss: 37.53297805786133
epoch 21500  training loss: 13.867945671081543

  7%|█████▋                                                                          | 21472/300000 [00:54<08:42, 532.63it/s]
epoch 21600  training loss: 13.837754249572754
epoch 21600  clean testing loss: 37.73424530029297
epoch 21700  training loss: 13.826258659362793
epoch 21700  clean testing loss: 37.84394073486328
epoch 21800  training loss: 13.78569221496582
epoch 21800  clean testing loss: 37.92529296875
epoch 21900  training loss: 13.769100189208984
epoch 21900  clean testing loss: 38.050025939941406
epoch 22000  training loss: 13.747973442077637
epoch 22000  clean testing loss: 38.14806365966797
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 22100  training loss: 13.725053787231445
epoch 22100  clean testing loss: 38.27859115600586
epoch 22200  training loss: 13.695621490478516
epoch 22200  clean testing loss: 38.35531997680664
epoch 22300  training loss: 13.655190467834473
epoch 22300  clean testing loss: 38.42925262451172
epoch 22400  training loss: 13.636260032653809
epoch 22400  clean testing loss: 38.55222702026367
epoch 22500  training loss: 13.604949951171875

  8%|██████                                                                          | 22560/300000 [00:56<08:40, 533.26it/s]
epoch 22600  training loss: 13.579666137695312
epoch 22600  clean testing loss: 38.75377655029297
epoch 22700  training loss: 13.553995132446289
epoch 22700  clean testing loss: 38.8309326171875
epoch 22800  training loss: 13.529998779296875
epoch 22800  clean testing loss: 38.934776306152344
epoch 22900  training loss: 13.505172729492188
epoch 22900  clean testing loss: 39.0269889831543
epoch 23000  training loss: 13.4808931350708
epoch 23000  clean testing loss: 39.120182037353516
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 23100  training loss: 13.458131790161133

  8%|██████▏                                                                         | 23100/300000 [00:57<08:41, 530.71it/s]
epoch 23200  training loss: 13.431885719299316
epoch 23200  clean testing loss: 39.28059387207031
epoch 23300  training loss: 13.427963256835938
epoch 23300  clean testing loss: 39.426422119140625
epoch 23400  training loss: 13.383971214294434
epoch 23400  clean testing loss: 39.4918327331543
epoch 23500  training loss: 13.348238945007324
epoch 23500  clean testing loss: 39.64493942260742
epoch 23600  training loss: 13.345070838928223
epoch 23600  clean testing loss: 39.72755432128906
epoch 23700  training loss: 13.311629295349121
epoch 23700  clean testing loss: 39.84646987915039
epoch 23800  training loss: 13.270121574401855
epoch 23800  clean testing loss: 39.90424346923828
epoch 23900  training loss: 13.241907119750977
epoch 23900  clean testing loss: 39.997276306152344
epoch 24000  training loss: 13.218026161193848
epoch 24000  clean testing loss: 40.100196838378906
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 24100  training loss: 13.197652816772461
epoch 24100  clean testing loss: 40.165122985839844
epoch 24200  training loss: 13.177584648132324
epoch 24200  clean testing loss: 40.2472038269043
epoch 24300  training loss: 13.15683364868164
epoch 24300  clean testing loss: 40.32228469848633
epoch 24400  training loss: 13.142611503601074

  8%|██████▌                                                                         | 24452/300000 [01:04<15:05, 304.15it/s]
epoch 24500  training loss: 13.126481056213379
epoch 24500  clean testing loss: 40.48956298828125
epoch 24600  training loss: 13.095663070678711
epoch 24600  clean testing loss: 40.60868453979492
epoch 24700  training loss: 13.076105117797852
epoch 24700  clean testing loss: 40.67845153808594
epoch 24800  training loss: 13.051278114318848
epoch 24800  clean testing loss: 40.77084732055664
epoch 24900  training loss: 13.03748893737793
epoch 24900  clean testing loss: 40.85070037841797
epoch 25000  training loss: 13.009209632873535
epoch 25000  clean testing loss: 40.93707275390625
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 25100  training loss: 12.990256309509277
epoch 25100  clean testing loss: 41.02439498901367
epoch 25200  training loss: 12.971319198608398
epoch 25200  clean testing loss: 41.09443283081055
epoch 25300  training loss: 12.94747543334961
epoch 25300  clean testing loss: 41.19462585449219
epoch 25400  training loss: 12.927818298339844
epoch 25400  clean testing loss: 41.281005859375
epoch 25500  training loss: 12.920516014099121

  9%|██████▊                                                                         | 25529/300000 [01:06<08:42, 524.99it/s]
epoch 25600  training loss: 12.884254455566406
epoch 25600  clean testing loss: 41.45261764526367
epoch 25700  training loss: 12.871254920959473
epoch 25700  clean testing loss: 41.55208969116211
epoch 25800  training loss: 12.84884262084961
epoch 25800  clean testing loss: 41.604183197021484
epoch 25900  training loss: 12.821111679077148
epoch 25900  clean testing loss: 41.6902961730957
epoch 26000  training loss: 12.814291954040527
epoch 26000  clean testing loss: 41.78865051269531
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 26100  training loss: 12.792201042175293
epoch 26100  clean testing loss: 41.85150909423828
epoch 26200  training loss: 12.776043891906738
epoch 26200  clean testing loss: 41.95699691772461
epoch 26300  training loss: 12.754502296447754

  9%|███████                                                                         | 26283/300000 [01:07<08:35, 530.51it/s]
epoch 26400  training loss: 12.732200622558594
epoch 26400  clean testing loss: 42.1599006652832
epoch 26500  training loss: 12.701881408691406
epoch 26500  clean testing loss: 42.198848724365234
epoch 26600  training loss: 12.695647239685059
epoch 26600  clean testing loss: 42.316917419433594
epoch 26700  training loss: 12.677435874938965
epoch 26700  clean testing loss: 42.366790771484375
epoch 26800  training loss: 12.647154808044434
epoch 26800  clean testing loss: 42.44602584838867
epoch 26900  training loss: 12.63668155670166
epoch 26900  clean testing loss: 42.572383880615234
epoch 27000  training loss: 12.60708236694336
epoch 27000  clean testing loss: 42.60052490234375
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 27100  training loss: 12.587846755981445
epoch 27100  clean testing loss: 42.678375244140625
epoch 27200  training loss: 12.571149826049805
epoch 27200  clean testing loss: 42.73838424682617
epoch 27300  training loss: 12.555479049682617
epoch 27300  clean testing loss: 42.803409576416016
epoch 27400  training loss: 12.540092468261719
epoch 27400  clean testing loss: 42.87479782104492
epoch 27500  training loss: 12.519564628601074
epoch 27500  clean testing loss: 42.93060302734375
epoch 27600  training loss: 12.506394386291504
epoch 27600  clean testing loss: 42.99416732788086
epoch 27700  training loss: 12.486163139343262

  9%|███████▍                                                                        | 27733/300000 [01:14<09:32, 475.89it/s]
epoch 27800  training loss: 12.467512130737305
epoch 27800  clean testing loss: 43.14085006713867
epoch 27900  training loss: 12.450014114379883
epoch 27900  clean testing loss: 43.217777252197266
epoch 28000  training loss: 12.436017990112305
epoch 28000  clean testing loss: 43.29804229736328
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 28100  training loss: 12.414518356323242
epoch 28100  clean testing loss: 43.349857330322266
epoch 28200  training loss: 12.397804260253906
epoch 28200  clean testing loss: 43.42167663574219
epoch 28300  training loss: 12.382625579833984
epoch 28300  clean testing loss: 43.47679901123047
epoch 28400  training loss: 12.362771987915039
epoch 28400  clean testing loss: 43.550872802734375
epoch 28500  training loss: 12.346117973327637
epoch 28500  clean testing loss: 43.6338996887207
epoch 28600  training loss: 12.337111473083496
epoch 28600  clean testing loss: 43.7128791809082
epoch 28700  training loss: 12.317915916442871
epoch 28700  clean testing loss: 43.77391815185547
epoch 28800  training loss: 12.30334186553955

 10%|███████▋                                                                        | 28751/300000 [01:16<08:31, 530.23it/s]
epoch 28900  training loss: 12.277833938598633
epoch 28900  clean testing loss: 43.96749496459961
epoch 29000  training loss: 12.270909309387207
epoch 29000  clean testing loss: 44.030757904052734
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 29100  training loss: 12.244043350219727
epoch 29100  clean testing loss: 44.12031555175781
epoch 29200  training loss: 12.229865074157715
epoch 29200  clean testing loss: 44.21611404418945
epoch 29300  training loss: 12.218873023986816
epoch 29300  clean testing loss: 44.305511474609375
epoch 29400  training loss: 12.198539733886719
epoch 29400  clean testing loss: 44.353370666503906
epoch 29500  training loss: 12.183588981628418
epoch 29500  clean testing loss: 44.415340423583984
epoch 29600  training loss: 12.169451713562012

 10%|███████▉                                                                        | 29559/300000 [01:17<08:29, 531.11it/s]
epoch 29700  training loss: 12.146018981933594
epoch 29700  clean testing loss: 44.60116958618164
epoch 29800  training loss: 12.129969596862793
epoch 29800  clean testing loss: 44.70417404174805
epoch 29900  training loss: 12.116681098937988
epoch 29900  clean testing loss: 44.79216384887695
epoch 30000  training loss: 12.100642204284668
epoch 30000  clean testing loss: 44.86553955078125
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 30100  training loss: 12.083022117614746
epoch 30100  clean testing loss: 44.937774658203125
epoch 30200  training loss: 12.069073677062988

 10%|███████▉                                                                       | 30207/300000 [01:26<1:10:47, 63.52it/s]
epoch 30300  training loss: 12.051446914672852
epoch 30300  clean testing loss: 45.064815521240234
epoch 30400  training loss: 12.036663055419922
epoch 30400  clean testing loss: 45.12324523925781
epoch 30500  training loss: 12.02634048461914
epoch 30500  clean testing loss: 45.190853118896484
epoch 30600  training loss: 12.004749298095703
epoch 30600  clean testing loss: 45.27747344970703
epoch 30700  training loss: 11.995651245117188
epoch 30700  clean testing loss: 45.327693939208984
epoch 30800  training loss: 11.975778579711914
epoch 30800  clean testing loss: 45.41587829589844
epoch 30900  training loss: 11.962740898132324
epoch 30900  clean testing loss: 45.48476028442383
epoch 31000  training loss: 11.949634552001953
epoch 31000  clean testing loss: 45.59029769897461
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 31100  training loss: 11.92958927154541
epoch 31100  clean testing loss: 45.66940689086914
epoch 31200  training loss: 11.919508934020996
epoch 31200  clean testing loss: 45.7455940246582
epoch 31300  training loss: 11.90077018737793

 10%|████████▎                                                                       | 31287/300000 [01:28<08:26, 530.35it/s]
epoch 31400  training loss: 11.8922700881958
epoch 31400  clean testing loss: 45.87150573730469
epoch 31500  training loss: 11.87002944946289
epoch 31500  clean testing loss: 45.967777252197266
epoch 31600  training loss: 11.860404968261719
epoch 31600  clean testing loss: 46.031463623046875
epoch 31700  training loss: 11.841550827026367
epoch 31700  clean testing loss: 46.12725067138672
epoch 31800  training loss: 11.828597068786621
epoch 31800  clean testing loss: 46.227516174316406
epoch 31900  training loss: 11.8157377243042
epoch 31900  clean testing loss: 46.304100036621094
epoch 32000  training loss: 11.802238464355469
epoch 32000  clean testing loss: 46.371456146240234
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 32100  training loss: 11.790822982788086
epoch 32100  clean testing loss: 46.42745590209961
epoch 32200  training loss: 11.767054557800293
epoch 32200  clean testing loss: 46.522727966308594
epoch 32300  training loss: 11.751605987548828
epoch 32300  clean testing loss: 46.596473693847656
epoch 32400  training loss: 11.735965728759766

 11%|████████▋                                                                       | 32367/300000 [01:30<08:21, 533.23it/s]
epoch 32500  training loss: 11.71396541595459
epoch 32500  clean testing loss: 46.82339859008789
epoch 32600  training loss: 11.690228462219238
epoch 32600  clean testing loss: 46.96510314941406
epoch 32700  training loss: 11.669455528259277
epoch 32700  clean testing loss: 47.03968048095703
epoch 32800  training loss: 11.659232139587402
epoch 32800  clean testing loss: 47.173038482666016
epoch 32900  training loss: 11.643062591552734
epoch 32900  clean testing loss: 47.23015594482422
epoch 33000  training loss: 11.62593936920166
epoch 33000  clean testing loss: 47.309478759765625
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 33100  training loss: 11.609402656555176
epoch 33100  clean testing loss: 47.375205993652344
epoch 33200  training loss: 11.597273826599121
epoch 33200  clean testing loss: 47.43350601196289
epoch 33300  training loss: 11.584565162658691
epoch 33300  clean testing loss: 47.50369644165039
epoch 33400  training loss: 11.571924209594727

 11%|████████▉                                                                       | 33447/300000 [01:32<08:19, 533.27it/s]
epoch 33500  training loss: 11.559233665466309
epoch 33500  clean testing loss: 47.68782424926758
epoch 33600  training loss: 11.544900894165039
epoch 33600  clean testing loss: 47.74750900268555
epoch 33700  training loss: 11.534969329833984
epoch 33700  clean testing loss: 47.81222152709961
epoch 33800  training loss: 11.520889282226562
epoch 33800  clean testing loss: 47.91767120361328
epoch 33900  training loss: 11.508153915405273
epoch 33900  clean testing loss: 48.00579071044922
epoch 34000  training loss: 11.495655059814453
epoch 34000  clean testing loss: 48.06989288330078
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 34100  training loss: 11.484853744506836
epoch 34100  clean testing loss: 48.14628219604492
epoch 34200  training loss: 11.465636253356934
epoch 34200  clean testing loss: 48.2052116394043
epoch 34300  training loss: 11.452936172485352
epoch 34300  clean testing loss: 48.29375076293945
epoch 34400  training loss: 11.443460464477539
epoch 34400  clean testing loss: 48.356414794921875
epoch 34500  training loss: 11.43156623840332

 12%|█████████▏                                                                      | 34527/300000 [01:34<08:17, 533.75it/s]
epoch 34600  training loss: 11.416458129882812
epoch 34600  clean testing loss: 48.5430793762207
epoch 34700  training loss: 11.400654792785645
epoch 34700  clean testing loss: 48.601402282714844
epoch 34800  training loss: 11.391666412353516
epoch 34800  clean testing loss: 48.70854187011719
epoch 34900  training loss: 11.378767967224121
epoch 34900  clean testing loss: 48.75444030761719
epoch 35000  training loss: 11.363945960998535
epoch 35000  clean testing loss: 48.86266326904297
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 35100  training loss: 11.350314140319824
epoch 35100  clean testing loss: 48.914791107177734
epoch 35200  training loss: 11.34084415435791
epoch 35200  clean testing loss: 49.024410247802734
epoch 35300  training loss: 11.325394630432129
epoch 35300  clean testing loss: 49.09322738647461
epoch 35400  training loss: 11.3148193359375
epoch 35400  clean testing loss: 49.203182220458984
epoch 35500  training loss: 11.297778129577637
epoch 35500  clean testing loss: 49.24972915649414
epoch 35600  training loss: 11.286399841308594

 12%|█████████▍                                                                      | 35607/300000 [01:36<08:13, 535.28it/s]
epoch 35700  training loss: 11.273945808410645
epoch 35700  clean testing loss: 49.43516540527344
epoch 35800  training loss: 11.258991241455078
epoch 35800  clean testing loss: 49.507606506347656
epoch 35900  training loss: 11.246468544006348
epoch 35900  clean testing loss: 49.59480667114258
epoch 36000  training loss: 11.238134384155273
epoch 36000  clean testing loss: 49.66249465942383
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 36100  training loss: 11.222518920898438
epoch 36100  clean testing loss: 49.74606704711914
epoch 36200  training loss: 11.212052345275879
epoch 36200  clean testing loss: 49.819698333740234
epoch 36300  training loss: 11.20110034942627
epoch 36300  clean testing loss: 49.87377166748047
epoch 36400  training loss: 11.190533638000488
epoch 36400  clean testing loss: 49.94001388549805
epoch 36500  training loss: 11.18010425567627
epoch 36500  clean testing loss: 50.04011917114258
epoch 36600  training loss: 11.169363975524902

 12%|█████████▊                                                                      | 36634/300000 [01:38<08:11, 535.93it/s]
epoch 36700  training loss: 11.157464981079102
epoch 36700  clean testing loss: 50.17264938354492
epoch 36800  training loss: 11.145376205444336
epoch 36800  clean testing loss: 50.24716567993164
epoch 36900  training loss: 11.134166717529297
epoch 36900  clean testing loss: 50.30615234375
epoch 37000  training loss: 11.126409530639648
epoch 37000  clean testing loss: 50.35184860229492
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 37100  training loss: 11.111109733581543
epoch 37100  clean testing loss: 50.42487716674805
epoch 37200  training loss: 11.101069450378418
epoch 37200  clean testing loss: 50.52220153808594
epoch 37300  training loss: 11.091264724731445
epoch 37300  clean testing loss: 50.54826736450195
epoch 37400  training loss: 11.078174591064453
epoch 37400  clean testing loss: 50.6218147277832
epoch 37500  training loss: 11.067281723022461
epoch 37500  clean testing loss: 50.70501708984375
epoch 37600  training loss: 11.056368827819824
epoch 37600  clean testing loss: 50.78966522216797
epoch 37700  training loss: 11.046500205993652

 13%|██████████                                                                      | 37717/300000 [01:40<08:08, 536.85it/s]
epoch 37800  training loss: 11.038458824157715
epoch 37800  clean testing loss: 50.939308166503906
epoch 37900  training loss: 11.021955490112305
epoch 37900  clean testing loss: 50.98155212402344
epoch 38000  training loss: 11.014342308044434
epoch 38000  clean testing loss: 51.07698059082031
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 38100  training loss: 10.999481201171875
epoch 38100  clean testing loss: 51.11863708496094
epoch 38200  training loss: 10.991032600402832
epoch 38200  clean testing loss: 51.179054260253906
epoch 38300  training loss: 10.978347778320312
epoch 38300  clean testing loss: 51.24928283691406
epoch 38400  training loss: 10.965758323669434
epoch 38400  clean testing loss: 51.346900939941406
epoch 38500  training loss: 10.955178260803223
epoch 38500  clean testing loss: 51.373939514160156
epoch 38600  training loss: 10.944846153259277
epoch 38600  clean testing loss: 51.43280792236328
epoch 38700  training loss: 10.932731628417969
epoch 38700  clean testing loss: 51.523433685302734
epoch 38800  training loss: 10.922098159790039

 13%|██████████▎                                                                     | 38799/300000 [01:42<08:04, 538.83it/s]
epoch 38900  training loss: 10.911151885986328
epoch 38900  clean testing loss: 51.59641647338867
epoch 39000  training loss: 10.899316787719727
epoch 39000  clean testing loss: 51.6705207824707
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 39100  training loss: 10.889568328857422
epoch 39100  clean testing loss: 51.728729248046875
epoch 39200  training loss: 10.880224227905273
epoch 39200  clean testing loss: 51.76510238647461
epoch 39300  training loss: 10.87105941772461
epoch 39300  clean testing loss: 51.8258056640625
epoch 39400  training loss: 10.861534118652344
epoch 39400  clean testing loss: 51.893550872802734
epoch 39500  training loss: 10.851492881774902
epoch 39500  clean testing loss: 51.94633102416992
epoch 39600  training loss: 10.842068672180176
epoch 39600  clean testing loss: 51.98298645019531
epoch 39700  training loss: 10.832505226135254
epoch 39700  clean testing loss: 52.06245422363281
epoch 39800  training loss: 10.82496166229248
epoch 39800  clean testing loss: 52.09419631958008
epoch 39900  training loss: 10.813909530639648

 13%|██████████▋                                                                     | 39880/300000 [01:44<08:04, 536.51it/s]
epoch 40000  training loss: 10.805279731750488
epoch 40000  clean testing loss: 52.214088439941406

 13%|██████████▊                                                                      | 40042/300000 [01:46<49:46, 87.05it/s]
epoch 40100  training loss: 10.79370403289795
epoch 40100  clean testing loss: 52.27284622192383
epoch 40200  training loss: 10.783953666687012
epoch 40200  clean testing loss: 52.33235549926758
epoch 40300  training loss: 10.774734497070312
epoch 40300  clean testing loss: 52.37741470336914
epoch 40400  training loss: 10.766666412353516
epoch 40400  clean testing loss: 52.441837310791016
epoch 40500  training loss: 10.756031036376953
epoch 40500  clean testing loss: 52.486324310302734
epoch 40600  training loss: 10.74712085723877
epoch 40600  clean testing loss: 52.56303787231445
epoch 40700  training loss: 10.739045143127441
epoch 40700  clean testing loss: 52.606590270996094
epoch 40800  training loss: 10.728075981140137
epoch 40800  clean testing loss: 52.638187408447266
epoch 40900  training loss: 10.717159271240234
epoch 40900  clean testing loss: 52.701541900634766
epoch 41000  training loss: 10.708521842956543
epoch 41000  clean testing loss: 52.77191162109375
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 41100  training loss: 10.697772026062012

 14%|██████████▉                                                                     | 41114/300000 [01:48<08:13, 525.09it/s]
epoch 41200  training loss: 10.689582824707031
epoch 41200  clean testing loss: 52.87638473510742
epoch 41300  training loss: 10.679014205932617
epoch 41300  clean testing loss: 52.92082214355469
epoch 41400  training loss: 10.671393394470215
epoch 41400  clean testing loss: 52.98897171020508
epoch 41500  training loss: 10.661133766174316
epoch 41500  clean testing loss: 53.03684616088867
epoch 41600  training loss: 10.652542114257812
epoch 41600  clean testing loss: 53.089813232421875
epoch 41700  training loss: 10.642672538757324
epoch 41700  clean testing loss: 53.15005874633789
epoch 41800  training loss: 10.634522438049316
epoch 41800  clean testing loss: 53.23625946044922
epoch 41900  training loss: 10.624615669250488

 14%|███████████▏                                                                    | 41870/300000 [01:49<08:05, 531.74it/s]
epoch 42000  training loss: 10.61510944366455
epoch 42000  clean testing loss: 53.326045989990234
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 42100  training loss: 10.606212615966797
epoch 42100  clean testing loss: 53.3787841796875
epoch 42200  training loss: 10.597955703735352

 14%|███████████▎                                                                    | 42245/300000 [01:52<18:43, 229.46it/s]
epoch 42300  training loss: 10.588812828063965
epoch 42300  clean testing loss: 53.47446060180664
epoch 42400  training loss: 10.581178665161133
epoch 42400  clean testing loss: 53.53065872192383
epoch 42500  training loss: 10.57345199584961
epoch 42500  clean testing loss: 53.573368072509766
epoch 42600  training loss: 10.565408706665039
epoch 42600  clean testing loss: 53.64417266845703
epoch 42700  training loss: 10.55810832977295
epoch 42700  clean testing loss: 53.663536071777344
epoch 42800  training loss: 10.54818058013916
epoch 42800  clean testing loss: 53.740848541259766
epoch 42900  training loss: 10.540141105651855
epoch 42900  clean testing loss: 53.78004837036133
epoch 43000  training loss: 10.532844543457031
epoch 43000  clean testing loss: 53.847930908203125
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 43100  training loss: 10.524051666259766
epoch 43100  clean testing loss: 53.881656646728516
epoch 43200  training loss: 10.515999794006348
epoch 43200  clean testing loss: 53.93893051147461
epoch 43300  training loss: 10.508028030395508

 14%|███████████▌                                                                    | 43321/300000 [01:54<08:08, 525.70it/s]
epoch 43400  training loss: 10.501184463500977
epoch 43400  clean testing loss: 54.00847244262695
epoch 43500  training loss: 10.493138313293457
epoch 43500  clean testing loss: 54.06233596801758
epoch 43600  training loss: 10.48351764678955
epoch 43600  clean testing loss: 54.11518096923828
epoch 43700  training loss: 10.475496292114258
epoch 43700  clean testing loss: 54.14568328857422
epoch 43800  training loss: 10.467398643493652
epoch 43800  clean testing loss: 54.21014404296875
epoch 43900  training loss: 10.459539413452148
epoch 43900  clean testing loss: 54.227195739746094
epoch 44000  training loss: 10.448847770690918
epoch 44000  clean testing loss: 54.25702667236328
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 44100  training loss: 10.440093994140625
epoch 44100  clean testing loss: 54.284461975097656
epoch 44200  training loss: 10.430853843688965
epoch 44200  clean testing loss: 54.303985595703125
epoch 44300  training loss: 10.422486305236816

 15%|███████████▊                                                                    | 44396/300000 [01:56<08:02, 529.71it/s]
epoch 44400  training loss: 10.414010047912598
epoch 44400  clean testing loss: 54.373897552490234
epoch 44500  training loss: 10.40615463256836
epoch 44500  clean testing loss: 54.419918060302734
epoch 44600  training loss: 10.397453308105469
epoch 44600  clean testing loss: 54.460018157958984
epoch 44700  training loss: 10.390414237976074
epoch 44700  clean testing loss: 54.491249084472656
epoch 44800  training loss: 10.3818941116333
epoch 44800  clean testing loss: 54.55183029174805
epoch 44900  training loss: 10.372711181640625
epoch 44900  clean testing loss: 54.60775375366211
epoch 45000  training loss: 10.365053176879883
epoch 45000  clean testing loss: 54.65875244140625
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 45100  training loss: 10.357939720153809
epoch 45100  clean testing loss: 54.71080017089844
epoch 45200  training loss: 10.35134506225586
epoch 45200  clean testing loss: 54.74920654296875
epoch 45300  training loss: 10.34459114074707
epoch 45300  clean testing loss: 54.79265213012695
epoch 45400  training loss: 10.337748527526855

 15%|████████████                                                                    | 45418/300000 [01:58<08:00, 529.56it/s]
epoch 45500  training loss: 10.331197738647461
epoch 45500  clean testing loss: 54.88788604736328
epoch 45600  training loss: 10.323647499084473
epoch 45600  clean testing loss: 54.939857482910156
epoch 45700  training loss: 10.31689167022705
epoch 45700  clean testing loss: 54.96247482299805
epoch 45800  training loss: 10.309686660766602
epoch 45800  clean testing loss: 55.023189544677734
epoch 45900  training loss: 10.302160263061523
epoch 45900  clean testing loss: 55.06705093383789
epoch 46000  training loss: 10.295452117919922
epoch 46000  clean testing loss: 55.09783935546875
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 46100  training loss: 10.288470268249512
epoch 46100  clean testing loss: 55.1678352355957
epoch 46200  training loss: 10.281115531921387
epoch 46200  clean testing loss: 55.191856384277344
epoch 46300  training loss: 10.273945808410645
epoch 46300  clean testing loss: 55.26460266113281
epoch 46400  training loss: 10.265459060668945
epoch 46400  clean testing loss: 55.30359649658203
epoch 46500  training loss: 10.25629711151123

 15%|████████████▍                                                                   | 46496/300000 [02:00<07:57, 531.31it/s]
epoch 46600  training loss: 10.248490333557129
epoch 46600  clean testing loss: 55.385963439941406
epoch 46700  training loss: 10.241817474365234
epoch 46700  clean testing loss: 55.41279220581055
epoch 46800  training loss: 10.234028816223145
epoch 46800  clean testing loss: 55.472103118896484
epoch 46900  training loss: 10.227652549743652
epoch 46900  clean testing loss: 55.50840377807617
epoch 47000  training loss: 10.219379425048828
epoch 47000  clean testing loss: 55.573158264160156
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 47100  training loss: 10.212325096130371
epoch 47100  clean testing loss: 55.61439514160156
epoch 47200  training loss: 10.205535888671875
epoch 47200  clean testing loss: 55.67166519165039
epoch 47300  training loss: 10.198640823364258
epoch 47300  clean testing loss: 55.71998977661133
epoch 47400  training loss: 10.191959381103516
epoch 47400  clean testing loss: 55.74061965942383
epoch 47500  training loss: 10.18305492401123

 16%|████████████▋                                                                   | 47574/300000 [02:02<07:54, 531.74it/s]
epoch 47600  training loss: 10.17435073852539
epoch 47600  clean testing loss: 55.85981369018555
epoch 47700  training loss: 10.167051315307617
epoch 47700  clean testing loss: 55.90287780761719
epoch 47800  training loss: 10.160630226135254
epoch 47800  clean testing loss: 55.97501754760742
epoch 47900  training loss: 10.153606414794922
epoch 47900  clean testing loss: 56.036415100097656
epoch 48000  training loss: 10.14664077758789
epoch 48000  clean testing loss: 56.07516860961914
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 48100  training loss: 10.139951705932617
epoch 48100  clean testing loss: 56.117042541503906
epoch 48200  training loss: 10.134356498718262
epoch 48200  clean testing loss: 56.16781997680664
epoch 48300  training loss: 10.128385543823242
epoch 48300  clean testing loss: 56.20055389404297
epoch 48400  training loss: 10.12224292755127
epoch 48400  clean testing loss: 56.25736618041992
epoch 48500  training loss: 10.115859985351562
epoch 48500  clean testing loss: 56.29526138305664
epoch 48600  training loss: 10.108972549438477

 16%|████████████▉                                                                   | 48599/300000 [02:04<07:52, 531.85it/s]
epoch 48700  training loss: 10.10201644897461
epoch 48700  clean testing loss: 56.40159606933594
epoch 48800  training loss: 10.094890594482422
epoch 48800  clean testing loss: 56.434471130371094
epoch 48900  training loss: 10.088656425476074
epoch 48900  clean testing loss: 56.48177719116211
epoch 49000  training loss: 10.081612586975098
epoch 49000  clean testing loss: 56.53196716308594
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 49100  training loss: 10.075623512268066
epoch 49100  clean testing loss: 56.57426071166992
epoch 49200  training loss: 10.069519996643066
epoch 49200  clean testing loss: 56.6165657043457
epoch 49300  training loss: 10.0635404586792
epoch 49300  clean testing loss: 56.66609191894531
epoch 49400  training loss: 10.05752944946289
epoch 49400  clean testing loss: 56.70711898803711
epoch 49500  training loss: 10.051531791687012
epoch 49500  clean testing loss: 56.74714279174805
epoch 49600  training loss: 10.045473098754883
epoch 49600  clean testing loss: 56.79643630981445
epoch 49700  training loss: 10.039677619934082

 17%|█████████████▏                                                                  | 49679/300000 [02:06<07:49, 533.50it/s]
epoch 49800  training loss: 10.033588409423828
epoch 49800  clean testing loss: 56.86833572387695
epoch 49900  training loss: 10.027814865112305
epoch 49900  clean testing loss: 56.917259216308594
epoch 50000  training loss: 10.022027015686035
epoch 50000  clean testing loss: 56.946720123291016
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 50100  training loss: 10.016362190246582
epoch 50100  clean testing loss: 56.98116683959961
epoch 50200  training loss: 10.009839057922363
epoch 50200  clean testing loss: 57.0327033996582
epoch 50300  training loss: 10.004924774169922
epoch 50300  clean testing loss: 57.06112289428711
epoch 50400  training loss: 9.998748779296875
epoch 50400  clean testing loss: 57.10945510864258
epoch 50500  training loss: 9.991963386535645
epoch 50500  clean testing loss: 57.15870666503906
epoch 50600  training loss: 9.986170768737793
epoch 50600  clean testing loss: 57.19076156616211
epoch 50700  training loss: 9.980125427246094


 17%|█████████████▊                                                                  | 51839/300000 [02:10<07:44, 534.50it/s]
epoch 50800  training loss: 9.974355697631836
epoch 50800  clean testing loss: 57.281166076660156
epoch 50900  training loss: 9.9682035446167
epoch 50900  clean testing loss: 57.31595993041992
epoch 51000  training loss: 9.962105751037598
epoch 51000  clean testing loss: 57.36253356933594
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 51100  training loss: 9.956918716430664
epoch 51100  clean testing loss: 57.39841842651367
epoch 51200  training loss: 9.951971054077148
epoch 51200  clean testing loss: 57.4268684387207
epoch 51300  training loss: 9.947141647338867
epoch 51300  clean testing loss: 57.44883728027344
epoch 51400  training loss: 9.941843032836914
epoch 51400  clean testing loss: 57.49493408203125
epoch 51500  training loss: 9.935559272766113
epoch 51500  clean testing loss: 57.514381408691406
epoch 51600  training loss: 9.930009841918945
epoch 51600  clean testing loss: 57.55833053588867
epoch 51700  training loss: 9.925135612487793
epoch 51700  clean testing loss: 57.60060501098633
epoch 51800  training loss: 9.919824600219727

 18%|██████████████                                                                  | 52919/300000 [02:12<07:45, 531.20it/s]
epoch 51900  training loss: 9.914387702941895
epoch 51900  clean testing loss: 57.67430114746094
epoch 52000  training loss: 9.908778190612793
epoch 52000  clean testing loss: 57.70432662963867
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 52100  training loss: 9.903177261352539
epoch 52100  clean testing loss: 57.75926208496094
epoch 52200  training loss: 9.897930145263672
epoch 52200  clean testing loss: 57.79167938232422
epoch 52300  training loss: 9.892691612243652
epoch 52300  clean testing loss: 57.825462341308594
epoch 52400  training loss: 9.886918067932129
epoch 52400  clean testing loss: 57.875732421875
epoch 52500  training loss: 9.88149356842041
epoch 52500  clean testing loss: 57.909175872802734
epoch 52600  training loss: 9.876514434814453
epoch 52600  clean testing loss: 57.95116424560547
epoch 52700  training loss: 9.871223449707031
epoch 52700  clean testing loss: 58.00370788574219
epoch 52800  training loss: 9.866135597229004
epoch 52800  clean testing loss: 58.01963424682617
epoch 52900  training loss: 9.860641479492188

 18%|██████████████▍                                                                 | 53944/300000 [02:14<07:42, 532.43it/s]
epoch 53000  training loss: 9.855123519897461
epoch 53000  clean testing loss: 58.112449645996094
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 53100  training loss: 9.849886894226074
epoch 53100  clean testing loss: 58.1474494934082
epoch 53200  training loss: 9.84463882446289
epoch 53200  clean testing loss: 58.184268951416016
epoch 53300  training loss: 9.839705467224121
epoch 53300  clean testing loss: 58.215782165527344
epoch 53400  training loss: 9.834485054016113
epoch 53400  clean testing loss: 58.261478424072266
epoch 53500  training loss: 9.829554557800293
epoch 53500  clean testing loss: 58.29789352416992
epoch 53600  training loss: 9.82429313659668
epoch 53600  clean testing loss: 58.34480285644531
epoch 53700  training loss: 9.819199562072754
epoch 53700  clean testing loss: 58.3893928527832
epoch 53800  training loss: 9.814104080200195
epoch 53800  clean testing loss: 58.42076873779297
epoch 53900  training loss: 9.809309005737305

 18%|██████████████▋                                                                 | 55028/300000 [02:16<07:38, 534.53it/s]
epoch 54000  training loss: 9.80444622039795
epoch 54000  clean testing loss: 58.5186882019043
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 54100  training loss: 9.799551010131836
epoch 54100  clean testing loss: 58.548179626464844
epoch 54200  training loss: 9.79544448852539
epoch 54200  clean testing loss: 58.57341766357422
epoch 54300  training loss: 9.791162490844727
epoch 54300  clean testing loss: 58.61224365234375
epoch 54400  training loss: 9.787075996398926
epoch 54400  clean testing loss: 58.638004302978516
epoch 54500  training loss: 9.779580116271973
epoch 54500  clean testing loss: 58.6462516784668
epoch 54600  training loss: 9.772808074951172
epoch 54600  clean testing loss: 58.676692962646484
epoch 54700  training loss: 9.767210960388184
epoch 54700  clean testing loss: 58.71525955200195
epoch 54800  training loss: 9.762648582458496
epoch 54800  clean testing loss: 58.75786209106445
epoch 54900  training loss: 9.757344245910645
epoch 54900  clean testing loss: 58.783721923828125
epoch 55000  training loss: 9.752720832824707
epoch 55000  clean testing loss: 58.83007049560547

 19%|██████████████▉                                                                 | 56108/300000 [02:18<07:42, 526.93it/s]
epoch 55100  training loss: 9.747986793518066
epoch 55100  clean testing loss: 58.855621337890625
epoch 55200  training loss: 9.743500709533691
epoch 55200  clean testing loss: 58.90251541137695
epoch 55300  training loss: 9.73877239227295
epoch 55300  clean testing loss: 58.932762145996094
epoch 55400  training loss: 9.733916282653809
epoch 55400  clean testing loss: 58.96337890625
epoch 55500  training loss: 9.729314804077148
epoch 55500  clean testing loss: 59.0003776550293
epoch 55600  training loss: 9.724637031555176
epoch 55600  clean testing loss: 59.03334045410156
epoch 55700  training loss: 9.719837188720703
epoch 55700  clean testing loss: 59.07121658325195
epoch 55800  training loss: 9.715094566345215
epoch 55800  clean testing loss: 59.10926818847656
epoch 55900  training loss: 9.710082054138184
epoch 55900  clean testing loss: 59.15248489379883
epoch 56000  training loss: 9.7051362991333
epoch 56000  clean testing loss: 59.18647766113281
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 56100  training loss: 9.700545310974121

 19%|███████████████▏                                                                | 57179/300000 [02:20<07:38, 529.30it/s]
epoch 56200  training loss: 9.696142196655273
epoch 56200  clean testing loss: 59.27871322631836
epoch 56300  training loss: 9.691537857055664
epoch 56300  clean testing loss: 59.30986404418945
epoch 56400  training loss: 9.6871919631958
epoch 56400  clean testing loss: 59.34556579589844
epoch 56500  training loss: 9.682230949401855
epoch 56500  clean testing loss: 59.379337310791016
epoch 56600  training loss: 9.677724838256836
epoch 56600  clean testing loss: 59.4136962890625
epoch 56700  training loss: 9.673293113708496
epoch 56700  clean testing loss: 59.450927734375
epoch 56800  training loss: 9.66839599609375
epoch 56800  clean testing loss: 59.48318862915039
epoch 56900  training loss: 9.663864135742188
epoch 56900  clean testing loss: 59.51003646850586
epoch 57000  training loss: 9.659354209899902
epoch 57000  clean testing loss: 59.5546760559082
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 57100  training loss: 9.654773712158203

 19%|███████████████▌                                                                | 58256/300000 [02:22<07:36, 529.77it/s]
epoch 57200  training loss: 9.649996757507324
epoch 57200  clean testing loss: 59.583580017089844
epoch 57300  training loss: 9.645790100097656
epoch 57300  clean testing loss: 59.60186767578125
epoch 57400  training loss: 9.641743659973145
epoch 57400  clean testing loss: 59.63710021972656
epoch 57500  training loss: 9.637924194335938
epoch 57500  clean testing loss: 59.66188049316406
epoch 57600  training loss: 9.63382625579834
epoch 57600  clean testing loss: 59.69468307495117
epoch 57700  training loss: 9.629939079284668
epoch 57700  clean testing loss: 59.7335090637207
epoch 57800  training loss: 9.626032829284668
epoch 57800  clean testing loss: 59.7665901184082
epoch 57900  training loss: 9.621867179870605
epoch 57900  clean testing loss: 59.80856704711914
epoch 58000  training loss: 9.617877960205078
epoch 58000  clean testing loss: 59.853214263916016
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 58100  training loss: 9.613832473754883
epoch 58100  clean testing loss: 59.88017654418945
epoch 58200  training loss: 9.610176086425781

 20%|███████████████▊                                                                | 59279/300000 [02:24<07:32, 531.69it/s]
epoch 58300  training loss: 9.606100082397461
epoch 58300  clean testing loss: 59.950870513916016
epoch 58400  training loss: 9.601930618286133
epoch 58400  clean testing loss: 59.98301696777344
epoch 58500  training loss: 9.598011016845703
epoch 58500  clean testing loss: 60.01679229736328
epoch 58600  training loss: 9.594144821166992
epoch 58600  clean testing loss: 60.04373550415039
epoch 58700  training loss: 9.5900297164917
epoch 58700  clean testing loss: 60.08088684082031
epoch 58800  training loss: 9.586466789245605
epoch 58800  clean testing loss: 60.106597900390625
epoch 58900  training loss: 9.582599639892578
epoch 58900  clean testing loss: 60.15058517456055
epoch 59000  training loss: 9.578926086425781
epoch 59000  clean testing loss: 60.18412780761719
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 59100  training loss: 9.574653625488281
epoch 59100  clean testing loss: 60.20751953125
epoch 59200  training loss: 9.570960998535156

 20%|████████████████                                                                | 60364/300000 [02:26<07:28, 534.68it/s]
epoch 59300  training loss: 9.567000389099121
epoch 59300  clean testing loss: 60.27951431274414
epoch 59400  training loss: 9.563029289245605
epoch 59400  clean testing loss: 60.31147766113281
epoch 59500  training loss: 9.559447288513184
epoch 59500  clean testing loss: 60.34724426269531
epoch 59600  training loss: 9.555428504943848
epoch 59600  clean testing loss: 60.382415771484375
epoch 59700  training loss: 9.551520347595215
epoch 59700  clean testing loss: 60.4075927734375
epoch 59800  training loss: 9.547493934631348
epoch 59800  clean testing loss: 60.4417839050293
epoch 59900  training loss: 9.54381275177002
epoch 59900  clean testing loss: 60.47744369506836
epoch 60000  training loss: 9.540156364440918
epoch 60000  clean testing loss: 60.5124626159668
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 60100  training loss: 9.536648750305176
epoch 60100  clean testing loss: 60.53572463989258
epoch 60200  training loss: 9.533591270446777
epoch 60200  clean testing loss: 60.56300354003906
epoch 60300  training loss: 9.530369758605957

 20%|████████████████▏                                                               | 60472/300000 [02:26<07:31, 531.00it/s]
epoch 60400  training loss: 9.527181625366211
epoch 60400  clean testing loss: 60.60914993286133
epoch 60500  training loss: 9.524040222167969

 21%|████████████████▍                                                               | 61868/300000 [02:31<07:37, 520.19it/s]
epoch 60600  training loss: 9.52068042755127
epoch 60600  clean testing loss: 60.66482925415039
epoch 60700  training loss: 9.517608642578125
epoch 60700  clean testing loss: 60.69133377075195
epoch 60800  training loss: 9.51435375213623
epoch 60800  clean testing loss: 60.718894958496094
epoch 60900  training loss: 9.51098918914795
epoch 60900  clean testing loss: 60.75382995605469
epoch 61000  training loss: 9.507676124572754
epoch 61000  clean testing loss: 60.78337097167969
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 61100  training loss: 9.504438400268555
epoch 61100  clean testing loss: 60.81594467163086
epoch 61200  training loss: 9.501422882080078
epoch 61200  clean testing loss: 60.8506965637207
epoch 61300  training loss: 9.49808406829834
epoch 61300  clean testing loss: 60.88028335571289
epoch 61400  training loss: 9.494794845581055
epoch 61400  clean testing loss: 60.90684509277344
epoch 61500  training loss: 9.491435050964355
epoch 61500  clean testing loss: 60.93419647216797
epoch 61600  training loss: 9.488265991210938
epoch 61600  clean testing loss: 60.968265533447266
epoch 61700  training loss: 9.484896659851074
epoch 61700  clean testing loss: 60.99650955200195
epoch 61800  training loss: 9.481778144836426

 21%|████████████████▋                                                               | 62570/300000 [02:32<07:25, 532.96it/s]
epoch 61900  training loss: 9.478606224060059
epoch 61900  clean testing loss: 61.06108093261719
epoch 62000  training loss: 9.475320816040039
epoch 62000  clean testing loss: 61.07560348510742
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 62100  training loss: 9.471885681152344
epoch 62100  clean testing loss: 61.10512924194336
epoch 62200  training loss: 9.468799591064453
epoch 62200  clean testing loss: 61.14178466796875
epoch 62300  training loss: 9.465422630310059
epoch 62300  clean testing loss: 61.16642379760742
epoch 62400  training loss: 9.462258338928223
epoch 62400  clean testing loss: 61.2037467956543
epoch 62500  training loss: 9.45908260345459
epoch 62500  clean testing loss: 61.230308532714844
epoch 62600  training loss: 9.455817222595215
epoch 62600  clean testing loss: 61.25193786621094
epoch 62700  training loss: 9.452651977539062
epoch 62700  clean testing loss: 61.27833557128906
epoch 62800  training loss: 9.449409484863281
epoch 62800  clean testing loss: 61.310462951660156
epoch 62900  training loss: 9.446081161499023
epoch 62900  clean testing loss: 61.341854095458984
epoch 63000  training loss: 9.443045616149902
epoch 63000  clean testing loss: 61.37188720703125
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 63100  training loss: 9.440229415893555
epoch 63100  clean testing loss: 61.39198684692383
epoch 63200  training loss: 9.437739372253418
epoch 63200  clean testing loss: 61.41416549682617
epoch 63300  training loss: 9.434982299804688

 21%|████████████████▉                                                               | 63379/300000 [02:35<09:22, 420.45it/s]
epoch 63400  training loss: 9.432289123535156
epoch 63400  clean testing loss: 61.46636962890625
epoch 63500  training loss: 9.429588317871094
epoch 63500  clean testing loss: 61.49277877807617
epoch 63600  training loss: 9.426822662353516
epoch 63600  clean testing loss: 61.51934051513672
epoch 63700  training loss: 9.424077033996582
epoch 63700  clean testing loss: 61.543033599853516
epoch 63800  training loss: 9.421304702758789
epoch 63800  clean testing loss: 61.575904846191406
epoch 63900  training loss: 9.418525695800781
epoch 63900  clean testing loss: 61.599220275878906
epoch 64000  training loss: 9.41588306427002
epoch 64000  clean testing loss: 61.622779846191406
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 64100  training loss: 9.413012504577637
epoch 64100  clean testing loss: 61.64652633666992
epoch 64200  training loss: 9.410236358642578
epoch 64200  clean testing loss: 61.66973114013672
epoch 64300  training loss: 9.407585144042969
epoch 64300  clean testing loss: 61.69892120361328
epoch 64400  training loss: 9.404895782470703

 21%|█████████████████▏                                                              | 64459/300000 [02:37<07:22, 531.99it/s]
epoch 64500  training loss: 9.401976585388184
epoch 64500  clean testing loss: 61.75102233886719
epoch 64600  training loss: 9.399307250976562
epoch 64600  clean testing loss: 61.783111572265625
epoch 64700  training loss: 9.396581649780273
epoch 64700  clean testing loss: 61.80621337890625
epoch 64800  training loss: 9.39384937286377
epoch 64800  clean testing loss: 61.836002349853516
epoch 64900  training loss: 9.391101837158203
epoch 64900  clean testing loss: 61.856754302978516
epoch 65000  training loss: 9.388591766357422
epoch 65000  clean testing loss: 61.88922882080078
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 65100  training loss: 9.385638236999512
epoch 65100  clean testing loss: 61.9028205871582
epoch 65200  training loss: 9.382699012756348
epoch 65200  clean testing loss: 61.93541717529297
epoch 65300  training loss: 9.379921913146973
epoch 65300  clean testing loss: 61.957096099853516
epoch 65400  training loss: 9.375
epoch 65400  clean testing loss: 61.99024200439453
epoch 65500  training loss: 9.372161865234375

 22%|█████████████████▍                                                              | 65540/300000 [02:39<07:20, 532.29it/s]
epoch 65600  training loss: 9.369298934936523
epoch 65600  clean testing loss: 62.03825378417969
epoch 65700  training loss: 9.366546630859375
epoch 65700  clean testing loss: 62.058895111083984
epoch 65800  training loss: 9.363759994506836
epoch 65800  clean testing loss: 62.095706939697266
epoch 65900  training loss: 9.36108112335205
epoch 65900  clean testing loss: 62.123783111572266
epoch 66000  training loss: 9.358280181884766
epoch 66000  clean testing loss: 62.147464752197266
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 66100  training loss: 9.3558931350708
epoch 66100  clean testing loss: 62.169837951660156
epoch 66200  training loss: 9.353675842285156
epoch 66200  clean testing loss: 62.192745208740234
epoch 66300  training loss: 9.351390838623047
epoch 66300  clean testing loss: 62.21684646606445
epoch 66400  training loss: 9.34912109375
epoch 66400  clean testing loss: 62.237125396728516
epoch 66500  training loss: 9.346820831298828
epoch 66500  clean testing loss: 62.26423645019531
epoch 66600  training loss: 9.34451961517334

 22%|█████████████████▊                                                              | 66626/300000 [02:41<07:13, 538.94it/s]
epoch 66700  training loss: 9.342257499694824
epoch 66700  clean testing loss: 62.30458068847656
epoch 66800  training loss: 9.339900016784668
epoch 66800  clean testing loss: 62.33454132080078
epoch 66900  training loss: 9.337504386901855
epoch 66900  clean testing loss: 62.35993194580078
epoch 67000  training loss: 9.335241317749023
epoch 67000  clean testing loss: 62.3828239440918
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 67100  training loss: 9.332962036132812
epoch 67100  clean testing loss: 62.403995513916016
epoch 67200  training loss: 9.330588340759277
epoch 67200  clean testing loss: 62.43008804321289
epoch 67300  training loss: 9.328300476074219
epoch 67300  clean testing loss: 62.45343780517578
epoch 67400  training loss: 9.325977325439453
epoch 67400  clean testing loss: 62.47726058959961
epoch 67500  training loss: 9.32362174987793
epoch 67500  clean testing loss: 62.50993347167969
epoch 67600  training loss: 9.321240425109863

 23%|██████████████████                                                              | 67551/300000 [02:43<07:11, 538.87it/s]
epoch 67700  training loss: 9.318902969360352
epoch 67700  clean testing loss: 62.56169891357422
epoch 67800  training loss: 9.316621780395508
epoch 67800  clean testing loss: 62.58391189575195
epoch 67900  training loss: 9.314238548278809
epoch 67900  clean testing loss: 62.60649490356445
epoch 68000  training loss: 9.311874389648438
epoch 68000  clean testing loss: 62.628971099853516
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 68100  training loss: 9.309469223022461
epoch 68100  clean testing loss: 62.65678024291992
epoch 68200  training loss: 9.307090759277344
epoch 68200  clean testing loss: 62.6810302734375
epoch 68300  training loss: 9.30479907989502
epoch 68300  clean testing loss: 62.701683044433594
epoch 68400  training loss: 9.302373886108398
epoch 68400  clean testing loss: 62.72914123535156
epoch 68500  training loss: 9.300004959106445
epoch 68500  clean testing loss: 62.750831604003906
epoch 68600  training loss: 9.29759693145752
epoch 68600  clean testing loss: 62.77492141723633
epoch 68700  training loss: 9.295232772827148
epoch 68700  clean testing loss: 62.79005813598633
epoch 68800  training loss: 9.292938232421875
epoch 68800  clean testing loss: 62.81239318847656
epoch 68900  training loss: 9.290674209594727

 23%|██████████████████▍                                                             | 68966/300000 [03:01<07:55, 485.45it/s]
epoch 69000  training loss: 9.288309097290039
epoch 69000  clean testing loss: 62.8648796081543
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 69100  training loss: 9.28640079498291
epoch 69100  clean testing loss: 62.884220123291016
epoch 69200  training loss: 9.284533500671387
epoch 69200  clean testing loss: 62.90426254272461
epoch 69300  training loss: 9.282593727111816
epoch 69300  clean testing loss: 62.93001174926758
epoch 69400  training loss: 9.280699729919434
epoch 69400  clean testing loss: 62.95000457763672
epoch 69500  training loss: 9.278759956359863
epoch 69500  clean testing loss: 62.966468811035156
epoch 69600  training loss: 9.276785850524902
epoch 69600  clean testing loss: 62.9923210144043
epoch 69700  training loss: 9.274828910827637
epoch 69700  clean testing loss: 63.01161193847656
epoch 69800  training loss: 9.272852897644043
epoch 69800  clean testing loss: 63.03557586669922
epoch 69900  training loss: 9.270943641662598
epoch 69900  clean testing loss: 63.0546875
epoch 70000  training loss: 9.26899528503418
epoch 70000  clean testing loss: 63.081966400146484

 23%|██████████████████▋                                                             | 70050/300000 [03:03<07:11, 533.30it/s]
epoch 70100  training loss: 9.26693058013916
epoch 70100  clean testing loss: 63.09941101074219
epoch 70200  training loss: 9.264999389648438
epoch 70200  clean testing loss: 63.123199462890625
epoch 70300  training loss: 9.262948036193848
epoch 70300  clean testing loss: 63.141666412353516
epoch 70400  training loss: 9.261032104492188
epoch 70400  clean testing loss: 63.16380310058594
epoch 70500  training loss: 9.259015083312988
epoch 70500  clean testing loss: 63.18472671508789
epoch 70600  training loss: 9.25696086883545
epoch 70600  clean testing loss: 63.2049560546875
epoch 70700  training loss: 9.255000114440918
epoch 70700  clean testing loss: 63.23115539550781
epoch 70800  training loss: 9.253111839294434
epoch 70800  clean testing loss: 63.25103759765625
epoch 70900  training loss: 9.251047134399414
epoch 70900  clean testing loss: 63.26889419555664
epoch 71000  training loss: 9.24902057647705
epoch 71000  clean testing loss: 63.29296112060547
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 71100  training loss: 9.24704647064209

 24%|██████████████████▉                                                             | 71133/300000 [03:05<07:05, 537.38it/s]
epoch 71200  training loss: 9.245176315307617
epoch 71200  clean testing loss: 63.3388786315918
epoch 71300  training loss: 9.24312686920166
epoch 71300  clean testing loss: 63.358863830566406
epoch 71400  training loss: 9.241133689880371
epoch 71400  clean testing loss: 63.3818244934082
epoch 71500  training loss: 9.239127159118652
epoch 71500  clean testing loss: 63.39748764038086
epoch 71600  training loss: 9.237112045288086
epoch 71600  clean testing loss: 63.42429733276367
epoch 71700  training loss: 9.235102653503418
epoch 71700  clean testing loss: 63.446502685546875
epoch 71800  training loss: 9.233173370361328
epoch 71800  clean testing loss: 63.467254638671875
epoch 71900  training loss: 9.231162071228027
epoch 71900  clean testing loss: 63.48331069946289
epoch 72000  training loss: 9.229131698608398
epoch 72000  clean testing loss: 63.50847625732422
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 72100  training loss: 9.227521896362305

 24%|███████████████████▎                                                            | 72224/300000 [03:07<07:02, 538.52it/s]
epoch 72200  training loss: 9.225945472717285
epoch 72200  clean testing loss: 63.54384994506836
epoch 72300  training loss: 9.224218368530273
epoch 72300  clean testing loss: 63.56070327758789
epoch 72400  training loss: 9.222620964050293
epoch 72400  clean testing loss: 63.57916259765625
epoch 72500  training loss: 9.220945358276367
epoch 72500  clean testing loss: 63.59913635253906
epoch 72600  training loss: 9.219317436218262
epoch 72600  clean testing loss: 63.61585235595703
epoch 72700  training loss: 9.21764850616455
epoch 72700  clean testing loss: 63.63465881347656
epoch 72800  training loss: 9.21603775024414
epoch 72800  clean testing loss: 63.65144729614258
epoch 72900  training loss: 9.214320182800293
epoch 72900  clean testing loss: 63.67022705078125
epoch 73000  training loss: 9.212667465209961
epoch 73000  clean testing loss: 63.68720626831055
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 73100  training loss: 9.211030006408691
epoch 73100  clean testing loss: 63.70752716064453
epoch 73200  training loss: 9.209354400634766

 24%|███████████████████▌                                                            | 73157/300000 [03:09<07:00, 538.86it/s]
epoch 73300  training loss: 9.207653999328613
epoch 73300  clean testing loss: 63.7464485168457
epoch 73400  training loss: 9.20602035522461
epoch 73400  clean testing loss: 63.76264572143555
epoch 73500  training loss: 9.204298973083496
epoch 73500  clean testing loss: 63.77598190307617
epoch 73600  training loss: 9.202695846557617
epoch 73600  clean testing loss: 63.795997619628906
epoch 73700  training loss: 9.200984954833984
epoch 73700  clean testing loss: 63.8150634765625
epoch 73800  training loss: 9.199307441711426
epoch 73800  clean testing loss: 63.83185577392578
epoch 73900  training loss: 9.197639465332031
epoch 73900  clean testing loss: 63.84769821166992
epoch 74000  training loss: 9.195951461791992
epoch 74000  clean testing loss: 63.868709564208984
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 74100  training loss: 9.194275856018066
epoch 74100  clean testing loss: 63.8883056640625
epoch 74200  training loss: 9.192546844482422
epoch 74200  clean testing loss: 63.90593719482422
epoch 74300  training loss: 9.190889358520508
epoch 74300  clean testing loss: 63.92449188232422
epoch 74400  training loss: 9.189205169677734
epoch 74400  clean testing loss: 63.94578552246094
epoch 74500  training loss: 9.187535285949707

 25%|███████████████████▉                                                            | 74628/300000 [03:15<08:30, 441.41it/s]
epoch 74600  training loss: 9.185871124267578
epoch 74600  clean testing loss: 63.980560302734375
epoch 74700  training loss: 9.184192657470703
epoch 74700  clean testing loss: 63.998558044433594
epoch 74800  training loss: 9.18250846862793
epoch 74800  clean testing loss: 64.022705078125
epoch 74900  training loss: 9.180730819702148
epoch 74900  clean testing loss: 64.03860473632812
epoch 75000  training loss: 9.179037094116211
epoch 75000  clean testing loss: 64.0582046508789
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 75100  training loss: 9.177664756774902
epoch 75100  clean testing loss: 64.07337951660156
epoch 75200  training loss: 9.176305770874023
epoch 75200  clean testing loss: 64.08453369140625
epoch 75300  training loss: 9.174968719482422
epoch 75300  clean testing loss: 64.10330963134766
epoch 75400  training loss: 9.173659324645996
epoch 75400  clean testing loss: 64.1189193725586
epoch 75500  training loss: 9.172262191772461
epoch 75500  clean testing loss: 64.13323211669922
epoch 75600  training loss: 9.170915603637695

 25%|████████████████████▏                                                           | 75654/300000 [03:17<06:59, 535.17it/s]
epoch 75700  training loss: 9.169549942016602
epoch 75700  clean testing loss: 64.16184997558594
epoch 75800  training loss: 9.16817855834961
epoch 75800  clean testing loss: 64.17797088623047
epoch 75900  training loss: 9.166802406311035
epoch 75900  clean testing loss: 64.19337463378906
epoch 76000  training loss: 9.165445327758789
epoch 76000  clean testing loss: 64.20828247070312
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 76100  training loss: 9.164019584655762
epoch 76100  clean testing loss: 64.22075653076172
epoch 76200  training loss: 9.162632942199707
epoch 76200  clean testing loss: 64.2371597290039
epoch 76300  training loss: 9.161248207092285
epoch 76300  clean testing loss: 64.25122833251953
epoch 76400  training loss: 9.159820556640625
epoch 76400  clean testing loss: 64.26657104492188
epoch 76500  training loss: 9.15843391418457
epoch 76500  clean testing loss: 64.28152465820312
epoch 76600  training loss: 9.157028198242188
epoch 76600  clean testing loss: 64.29643249511719
epoch 76700  training loss: 9.155665397644043

 26%|████████████████████▍                                                           | 76734/300000 [03:19<06:57, 534.67it/s]
epoch 76800  training loss: 9.154240608215332
epoch 76800  clean testing loss: 64.3252944946289
epoch 76900  training loss: 9.152856826782227
epoch 76900  clean testing loss: 64.33599090576172
epoch 77000  training loss: 9.151449203491211

 26%|████████████████████▊                                                           | 77974/300000 [03:28<07:07, 519.10it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 77100  training loss: 9.150033950805664
epoch 77100  clean testing loss: 64.36737060546875
epoch 77200  training loss: 9.148615837097168
epoch 77200  clean testing loss: 64.37860870361328
epoch 77300  training loss: 9.147232055664062
epoch 77300  clean testing loss: 64.39412689208984
epoch 77400  training loss: 9.145795822143555
epoch 77400  clean testing loss: 64.4049072265625
epoch 77500  training loss: 9.144424438476562
epoch 77500  clean testing loss: 64.41754150390625
epoch 77600  training loss: 9.143027305603027
epoch 77600  clean testing loss: 64.43245697021484
epoch 77700  training loss: 9.141593933105469
epoch 77700  clean testing loss: 64.44568634033203
epoch 77800  training loss: 9.140141487121582
epoch 77800  clean testing loss: 64.46366119384766
epoch 77900  training loss: 9.138710975646973

 26%|█████████████████████                                                           | 79054/300000 [03:30<07:00, 525.99it/s]
epoch 78000  training loss: 9.137299537658691
epoch 78000  clean testing loss: 64.49993133544922
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 78100  training loss: 9.136089324951172
epoch 78100  clean testing loss: 64.51626586914062
epoch 78200  training loss: 9.134936332702637
epoch 78200  clean testing loss: 64.53107452392578
epoch 78300  training loss: 9.133748054504395
epoch 78300  clean testing loss: 64.54534149169922
epoch 78400  training loss: 9.132566452026367
epoch 78400  clean testing loss: 64.56217956542969
epoch 78500  training loss: 9.131121635437012
epoch 78500  clean testing loss: 64.5760498046875
epoch 78600  training loss: 9.129682540893555
epoch 78600  clean testing loss: 64.58723449707031
epoch 78700  training loss: 9.128361701965332
epoch 78700  clean testing loss: 64.60108947753906
epoch 78800  training loss: 9.12719440460205
epoch 78800  clean testing loss: 64.60982513427734
epoch 78900  training loss: 9.126021385192871
epoch 78900  clean testing loss: 64.62496948242188
epoch 79000  training loss: 9.124767303466797
epoch 79000  clean testing loss: 64.63374328613281

 27%|█████████████████████▎                                                          | 80134/300000 [03:32<06:53, 531.40it/s]
epoch 79100  training loss: 9.12358283996582
epoch 79100  clean testing loss: 64.6474380493164
epoch 79200  training loss: 9.122248649597168
epoch 79200  clean testing loss: 64.66109466552734
epoch 79300  training loss: 9.120890617370605
epoch 79300  clean testing loss: 64.67121887207031
epoch 79400  training loss: 9.119669914245605
epoch 79400  clean testing loss: 64.6834716796875
epoch 79500  training loss: 9.118480682373047
epoch 79500  clean testing loss: 64.69441986083984
epoch 79600  training loss: 9.117321014404297
epoch 79600  clean testing loss: 64.70535278320312
epoch 79700  training loss: 9.11613941192627
epoch 79700  clean testing loss: 64.71867370605469
epoch 79800  training loss: 9.114953994750977
epoch 79800  clean testing loss: 64.72909545898438
epoch 79900  training loss: 9.113761901855469
epoch 79900  clean testing loss: 64.739501953125
epoch 80000  training loss: 9.112613677978516
epoch 80000  clean testing loss: 64.75464630126953

 27%|█████████████████████▋                                                          | 81214/300000 [03:34<06:52, 530.96it/s]
epoch 80100  training loss: 9.111420631408691
epoch 80100  clean testing loss: 64.76444244384766
epoch 80200  training loss: 9.110269546508789
epoch 80200  clean testing loss: 64.77510070800781
epoch 80300  training loss: 9.109110832214355
epoch 80300  clean testing loss: 64.79051208496094
epoch 80400  training loss: 9.10789966583252
epoch 80400  clean testing loss: 64.8001937866211
epoch 80500  training loss: 9.106749534606934
epoch 80500  clean testing loss: 64.81361389160156
epoch 80600  training loss: 9.105562210083008
epoch 80600  clean testing loss: 64.8243408203125
epoch 80700  training loss: 9.104408264160156
epoch 80700  clean testing loss: 64.83650207519531
epoch 80800  training loss: 9.103240966796875
epoch 80800  clean testing loss: 64.84983825683594
epoch 80900  training loss: 9.102060317993164
epoch 80900  clean testing loss: 64.859375
epoch 81000  training loss: 9.100903511047363
epoch 81000  clean testing loss: 64.8709945678711
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 81100  training loss: 9.099908828735352

 27%|█████████████████████▉                                                          | 82242/300000 [03:36<06:48, 533.25it/s]
epoch 81200  training loss: 9.098990440368652
epoch 81200  clean testing loss: 64.89006042480469
epoch 81300  training loss: 9.098031997680664
epoch 81300  clean testing loss: 64.89995574951172
epoch 81400  training loss: 9.097105026245117
epoch 81400  clean testing loss: 64.90912628173828
epoch 81500  training loss: 9.096136093139648
epoch 81500  clean testing loss: 64.91853332519531
epoch 81600  training loss: 9.095178604125977
epoch 81600  clean testing loss: 64.92989349365234
epoch 81700  training loss: 9.094212532043457
epoch 81700  clean testing loss: 64.93976593017578
epoch 81800  training loss: 9.093242645263672
epoch 81800  clean testing loss: 64.9496841430664
epoch 81900  training loss: 9.092276573181152
epoch 81900  clean testing loss: 64.95879364013672
epoch 82000  training loss: 9.091297149658203
epoch 82000  clean testing loss: 64.96862030029297
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 82100  training loss: 9.090357780456543
epoch 82100  clean testing loss: 64.97975158691406
epoch 82200  training loss: 9.08938217163086

 28%|██████████████████████▏                                                         | 83054/300000 [03:37<06:48, 531.42it/s]
epoch 82300  training loss: 9.08841609954834
epoch 82300  clean testing loss: 64.9980239868164
epoch 82400  training loss: 9.087437629699707
epoch 82400  clean testing loss: 65.00923156738281
epoch 82500  training loss: 9.086459159851074
epoch 82500  clean testing loss: 65.01740264892578
epoch 82600  training loss: 9.085506439208984
epoch 82600  clean testing loss: 65.0272216796875
epoch 82700  training loss: 9.084563255310059
epoch 82700  clean testing loss: 65.03963470458984
epoch 82800  training loss: 9.083572387695312
epoch 82800  clean testing loss: 65.04769134521484
epoch 82900  training loss: 9.082605361938477
epoch 82900  clean testing loss: 65.05976104736328
epoch 83000  training loss: 9.081642150878906
epoch 83000  clean testing loss: 65.07007598876953
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...

 28%|██████████████████████▍                                                         | 83988/300000 [03:39<06:37, 543.12it/s]
epoch 83100  clean testing loss: 65.07793426513672
epoch 83200  training loss: 9.079729080200195
epoch 83200  clean testing loss: 65.0881118774414
epoch 83300  training loss: 9.078741073608398
epoch 83300  clean testing loss: 65.09861755371094
epoch 83400  training loss: 9.077779769897461
epoch 83400  clean testing loss: 65.1083755493164
epoch 83500  training loss: 9.07679557800293
epoch 83500  clean testing loss: 65.1185073852539
epoch 83600  training loss: 9.07583999633789
epoch 83600  clean testing loss: 65.12904357910156
epoch 83700  training loss: 9.0748872756958
epoch 83700  clean testing loss: 65.13896942138672
epoch 83800  training loss: 9.073919296264648
epoch 83800  clean testing loss: 65.15025329589844
epoch 83900  training loss: 9.072952270507812
epoch 83900  clean testing loss: 65.15716552734375
epoch 84000  training loss: 9.071989059448242
epoch 84000  clean testing loss: 65.16767883300781

 28%|██████████████████████▋                                                         | 85130/300000 [03:44<06:43, 532.39it/s]
epoch 84100  training loss: 9.071181297302246
epoch 84100  clean testing loss: 65.17609405517578
epoch 84200  training loss: 9.070416450500488
epoch 84200  clean testing loss: 65.18453216552734
epoch 84300  training loss: 9.069642066955566
epoch 84300  clean testing loss: 65.19329071044922
epoch 84400  training loss: 9.068862915039062
epoch 84400  clean testing loss: 65.19967651367188
epoch 84500  training loss: 9.068050384521484
epoch 84500  clean testing loss: 65.20840454101562
epoch 84600  training loss: 9.067302703857422
epoch 84600  clean testing loss: 65.21732330322266
epoch 84700  training loss: 9.06650447845459
epoch 84700  clean testing loss: 65.22512817382812
epoch 84800  training loss: 9.065691947937012
epoch 84800  clean testing loss: 65.23307800292969
epoch 84900  training loss: 9.064908981323242
epoch 84900  clean testing loss: 65.24021911621094
epoch 85000  training loss: 9.064138412475586
epoch 85000  clean testing loss: 65.24970245361328
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 85100  training loss: 9.063326835632324

 29%|██████████████████████▊                                                         | 85566/300000 [03:44<06:36, 540.76it/s]
epoch 85200  training loss: 9.062528610229492
epoch 85200  clean testing loss: 65.26571655273438
epoch 85300  training loss: 9.06174087524414
epoch 85300  clean testing loss: 65.2734146118164
epoch 85400  training loss: 9.060934066772461
epoch 85400  clean testing loss: 65.2812271118164
epoch 85500  training loss: 9.060153007507324
epoch 85500  clean testing loss: 65.29000091552734
epoch 85600  training loss: 9.059353828430176

 29%|███████████████████████                                                         | 86496/300000 [03:50<09:20, 381.25it/s]
epoch 85700  training loss: 9.058554649353027
epoch 85700  clean testing loss: 65.30703735351562
epoch 85800  training loss: 9.057753562927246
epoch 85800  clean testing loss: 65.3157730102539
epoch 85900  training loss: 9.056957244873047
epoch 85900  clean testing loss: 65.32306671142578
epoch 86000  training loss: 9.056166648864746
epoch 86000  clean testing loss: 65.33271026611328
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 86100  training loss: 9.055357933044434
epoch 86100  clean testing loss: 65.339111328125
epoch 86200  training loss: 9.054582595825195
epoch 86200  clean testing loss: 65.3470230102539
epoch 86300  training loss: 9.053791046142578
epoch 86300  clean testing loss: 65.35600280761719
epoch 86400  training loss: 9.053004264831543

 29%|███████████████████████▎                                                        | 87582/300000 [03:52<06:34, 538.21it/s]
epoch 86500  training loss: 9.052206993103027
epoch 86500  clean testing loss: 65.37197875976562
epoch 86600  training loss: 9.051424980163574
epoch 86600  clean testing loss: 65.38032531738281
epoch 86700  training loss: 9.050606727600098
epoch 86700  clean testing loss: 65.38768768310547
epoch 86800  training loss: 9.049813270568848
epoch 86800  clean testing loss: 65.39655303955078
epoch 86900  training loss: 9.049036026000977
epoch 86900  clean testing loss: 65.40325927734375
epoch 87000  training loss: 9.048255920410156
epoch 87000  clean testing loss: 65.41078186035156
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 87100  training loss: 9.047597885131836
epoch 87100  clean testing loss: 65.41922760009766
epoch 87200  training loss: 9.046936988830566
epoch 87200  clean testing loss: 65.42459869384766
epoch 87300  training loss: 9.046304702758789
epoch 87300  clean testing loss: 65.43159484863281
epoch 87400  training loss: 9.045650482177734
epoch 87400  clean testing loss: 65.4386215209961
epoch 87500  training loss: 9.045013427734375

 30%|███████████████████████▋                                                        | 88666/300000 [03:54<06:32, 538.50it/s]
epoch 87600  training loss: 9.044353485107422
epoch 87600  clean testing loss: 65.45162200927734
epoch 87700  training loss: 9.043715476989746
epoch 87700  clean testing loss: 65.45963287353516
epoch 87800  training loss: 9.043050765991211
epoch 87800  clean testing loss: 65.46625518798828
epoch 87900  training loss: 9.042404174804688
epoch 87900  clean testing loss: 65.47293090820312
epoch 88000  training loss: 9.041749954223633
epoch 88000  clean testing loss: 65.47923278808594
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 88100  training loss: 9.04108715057373
epoch 88100  clean testing loss: 65.48661804199219
epoch 88200  training loss: 9.04045295715332
epoch 88200  clean testing loss: 65.49359893798828
epoch 88300  training loss: 9.039799690246582
epoch 88300  clean testing loss: 65.50057220458984
epoch 88400  training loss: 9.039138793945312
epoch 88400  clean testing loss: 65.50699615478516
epoch 88500  training loss: 9.038483619689941
epoch 88500  clean testing loss: 65.51504516601562
epoch 88600  training loss: 9.037808418273926

 30%|███████████████████████▉                                                        | 89755/300000 [03:56<06:29, 539.47it/s]
epoch 88700  training loss: 9.037185668945312
epoch 88700  clean testing loss: 65.52859497070312
epoch 88800  training loss: 9.036520004272461
epoch 88800  clean testing loss: 65.53588104248047
epoch 88900  training loss: 9.035863876342773
epoch 88900  clean testing loss: 65.54353332519531
epoch 89000  training loss: 9.035213470458984
epoch 89000  clean testing loss: 65.54981231689453
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 89100  training loss: 9.034542083740234
epoch 89100  clean testing loss: 65.5570068359375
epoch 89200  training loss: 9.033888816833496
epoch 89200  clean testing loss: 65.56366729736328
epoch 89300  training loss: 9.033238410949707
epoch 89300  clean testing loss: 65.57019805908203
epoch 89400  training loss: 9.032580375671387
epoch 89400  clean testing loss: 65.57928466796875
epoch 89500  training loss: 9.031929969787598
epoch 89500  clean testing loss: 65.58442687988281
epoch 89600  training loss: 9.031281471252441

 30%|████████████████████████▏                                                       | 90789/300000 [03:58<06:27, 540.52it/s]
epoch 89700  training loss: 9.030640602111816
epoch 89700  clean testing loss: 65.60023498535156
epoch 89800  training loss: 9.029985427856445
epoch 89800  clean testing loss: 65.60755920410156
epoch 89900  training loss: 9.029326438903809
epoch 89900  clean testing loss: 65.61445617675781
epoch 90000  training loss: 9.028660774230957
epoch 90000  clean testing loss: 65.62142181396484
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 90100  training loss: 9.028139114379883
epoch 90100  clean testing loss: 65.6270980834961
epoch 90200  training loss: 9.027634620666504
epoch 90200  clean testing loss: 65.63267517089844
epoch 90300  training loss: 9.027108192443848
epoch 90300  clean testing loss: 65.638427734375
epoch 90400  training loss: 9.026603698730469
epoch 90400  clean testing loss: 65.6427230834961
epoch 90500  training loss: 9.026082038879395
epoch 90500  clean testing loss: 65.64884948730469
epoch 90600  training loss: 9.025556564331055
epoch 90600  clean testing loss: 65.65389251708984
epoch 90700  training loss: 9.025038719177246

 31%|████████████████████████▌                                                       | 91882/300000 [04:00<06:25, 539.57it/s]
epoch 90800  training loss: 9.024532318115234
epoch 90800  clean testing loss: 65.66525268554688
epoch 90900  training loss: 9.02400016784668
epoch 90900  clean testing loss: 65.67151641845703
epoch 91000  training loss: 9.023475646972656
epoch 91000  clean testing loss: 65.67810821533203
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 91100  training loss: 9.02297306060791
epoch 91100  clean testing loss: 65.68144226074219
epoch 91200  training loss: 9.022441864013672
epoch 91200  clean testing loss: 65.68840789794922
epoch 91300  training loss: 9.021912574768066
epoch 91300  clean testing loss: 65.69395446777344
epoch 91400  training loss: 9.021416664123535
epoch 91400  clean testing loss: 65.69911193847656
epoch 91500  training loss: 9.020870208740234
epoch 91500  clean testing loss: 65.70586395263672
epoch 91600  training loss: 9.020358085632324
epoch 91600  clean testing loss: 65.71156311035156
epoch 91700  training loss: 9.019835472106934
epoch 91700  clean testing loss: 65.71620178222656
epoch 91800  training loss: 9.019309043884277

 31%|████████████████████████▊                                                       | 92965/300000 [04:02<06:28, 533.08it/s]
epoch 91900  training loss: 9.018789291381836
epoch 91900  clean testing loss: 65.72764587402344
epoch 92000  training loss: 9.018256187438965
epoch 92000  clean testing loss: 65.73365783691406
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 92100  training loss: 9.017739295959473
epoch 92100  clean testing loss: 65.73892211914062
epoch 92200  training loss: 9.017231941223145
epoch 92200  clean testing loss: 65.74525451660156
epoch 92300  training loss: 9.016683578491211
epoch 92300  clean testing loss: 65.7517318725586
epoch 92400  training loss: 9.016175270080566
epoch 92400  clean testing loss: 65.75592041015625
epoch 92500  training loss: 9.015671730041504
epoch 92500  clean testing loss: 65.76217651367188
epoch 92600  training loss: 9.01512622833252
epoch 92600  clean testing loss: 65.76815795898438
epoch 92700  training loss: 9.014598846435547
epoch 92700  clean testing loss: 65.77261352539062
epoch 92800  training loss: 9.014092445373535
epoch 92800  clean testing loss: 65.77806854248047
epoch 92900  training loss: 9.013569831848145

 31%|████████████████████████▉                                                       | 93668/300000 [04:03<06:24, 536.66it/s]
epoch 93000  training loss: 9.013047218322754
epoch 93000  clean testing loss: 65.78892517089844
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 93100  training loss: 9.012625694274902
epoch 93100  clean testing loss: 65.79446411132812
epoch 93200  training loss: 9.012189865112305
epoch 93200  clean testing loss: 65.79930114746094
epoch 93300  training loss: 9.01177978515625
epoch 93300  clean testing loss: 65.80323791503906
epoch 93400  training loss: 9.011326789855957
epoch 93400  clean testing loss: 65.80927276611328
epoch 93500  training loss: 9.010924339294434
epoch 93500  clean testing loss: 65.81363677978516
epoch 93600  training loss: 9.01048469543457
epoch 93600  clean testing loss: 65.81745910644531
epoch 93700  training loss: 9.01005744934082

 31%|████████████████████████▊                                                      | 94266/300000 [04:20<1:17:06, 44.47it/s]
epoch 93800  training loss: 9.009615898132324
epoch 93800  clean testing loss: 65.8276596069336
epoch 93900  training loss: 9.009190559387207
epoch 93900  clean testing loss: 65.83296203613281
epoch 94000  training loss: 9.008767127990723
epoch 94000  clean testing loss: 65.83695983886719
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 94100  training loss: 9.008333206176758
epoch 94100  clean testing loss: 65.8410873413086
epoch 94200  training loss: 9.007899284362793

 32%|█████████████████████████▍                                                      | 95357/300000 [04:22<06:22, 534.33it/s]
epoch 94300  training loss: 9.007472038269043
epoch 94300  clean testing loss: 65.85133361816406
epoch 94400  training loss: 9.007037162780762
epoch 94400  clean testing loss: 65.85596466064453
epoch 94500  training loss: 9.006610870361328
epoch 94500  clean testing loss: 65.8619384765625
epoch 94600  training loss: 9.006174087524414
epoch 94600  clean testing loss: 65.86541748046875
epoch 94700  training loss: 9.005743980407715
epoch 94700  clean testing loss: 65.87129974365234
epoch 94800  training loss: 9.005311012268066
epoch 94800  clean testing loss: 65.87523651123047
epoch 94900  training loss: 9.00489330291748
epoch 94900  clean testing loss: 65.88043975830078
epoch 95000  training loss: 9.004444122314453
epoch 95000  clean testing loss: 65.88521575927734
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...
epoch 95100  training loss: 9.00402545928955
epoch 95100  clean testing loss: 65.8909912109375
epoch 95200  training loss: 9.0035982131958
epoch 95200  clean testing loss: 65.89462280273438
epoch 95300  training loss: 9.003138542175293

 32%|█████████████████████████▌                                                      | 96000/300000 [04:23<09:19, 364.48it/s]
epoch 95400  training loss: 9.002724647521973
epoch 95400  clean testing loss: 65.90603637695312
epoch 95500  training loss: 9.002293586730957
epoch 95500  clean testing loss: 65.91061401367188
epoch 95600  training loss: 9.001848220825195
epoch 95600  clean testing loss: 65.91548156738281
epoch 95700  training loss: 9.001420021057129
epoch 95700  clean testing loss: 65.92044830322266
epoch 95800  training loss: 9.00098705291748
epoch 95800  clean testing loss: 65.92449951171875
epoch 95900  training loss: 9.000560760498047
epoch 95900  clean testing loss: 65.93020629882812
epoch 96000  training loss: 9.000099182128906
epoch 96000  clean testing loss: 65.9345474243164
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e+01_invop0 ...