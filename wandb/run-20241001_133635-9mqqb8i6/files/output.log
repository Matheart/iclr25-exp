
  0%|▏                                                                                 | 702/300000 [00:05<10:32, 473.40it/s]
epoch 0  training loss: 0.5060330033302307
epoch 0  clean testing loss: 0.48533496260643005
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-02_invop0 ...
epoch 100  training loss: 0.18623927235603333
epoch 100  clean testing loss: 0.15811969339847565
epoch 200  training loss: 0.10623305290937424
epoch 200  clean testing loss: 0.08717309683561325
epoch 300  training loss: 0.08956366032361984
epoch 300  clean testing loss: 0.07230743765830994
epoch 400  training loss: 0.07691200077533722
epoch 400  clean testing loss: 0.06051664426922798
epoch 500  training loss: 0.06773189455270767
epoch 500  clean testing loss: 0.051301270723342896
epoch 600  training loss: 0.06095437332987785
epoch 600  clean testing loss: 0.04461168870329857
epoch 700  training loss: 0.05565322935581207

  1%|▍                                                                                | 1801/300000 [00:07<09:11, 541.11it/s]
epoch 800  training loss: 0.05163266137242317
epoch 800  clean testing loss: 0.036442652344703674
epoch 900  training loss: 0.048332467675209045
epoch 900  clean testing loss: 0.03376838192343712
epoch 1000  training loss: 0.045695651322603226
epoch 1000  clean testing loss: 0.03171581029891968
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-02_invop0 ...
epoch 1100  training loss: 0.04343569278717041
epoch 1100  clean testing loss: 0.029916759580373764
epoch 1200  training loss: 0.04145325720310211
epoch 1200  clean testing loss: 0.02853291854262352
epoch 1300  training loss: 0.03978779911994934
epoch 1300  clean testing loss: 0.027388714253902435
epoch 1400  training loss: 0.0383298397064209
epoch 1400  clean testing loss: 0.026446431875228882
epoch 1500  training loss: 0.037035781890153885
epoch 1500  clean testing loss: 0.025588862597942352
epoch 1600  training loss: 0.03591657429933548
epoch 1600  clean testing loss: 0.02487153373658657
epoch 1700  training loss: 0.03487762436270714
epoch 1700  clean testing loss: 0.02427491545677185
epoch 1800  training loss: 0.03401673957705498
epoch 1800  clean testing loss: 0.023832593113183975
epoch 1900  training loss: 0.03330324590206146
epoch 1900  clean testing loss: 0.02348528802394867
epoch 2000  training loss: 0.032685816287994385
epoch 2000  clean testing loss: 0.02319161221385002
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-02_invop0 ...
epoch 2100  training loss: 0.03195343166589737
epoch 2100  clean testing loss: 0.022796839475631714
epoch 2200  training loss: 0.03136313334107399
epoch 2200  clean testing loss: 0.02253052219748497
epoch 2300  training loss: 0.03083614632487297
epoch 2300  clean testing loss: 0.02224329486489296
epoch 2400  training loss: 0.030380133539438248
epoch 2400  clean testing loss: 0.021985165774822235
epoch 2500  training loss: 0.02984572760760784
epoch 2500  clean testing loss: 0.021594777703285217
epoch 2600  training loss: 0.0293384101241827
epoch 2600  clean testing loss: 0.02144753374159336
epoch 2700  training loss: 0.02893594466149807


  1%|▊                                                                                | 3200/300000 [00:19<30:40, 161.24it/s]
epoch 2800  training loss: 0.028574908152222633
epoch 2800  clean testing loss: 0.021022725850343704
epoch 2900  training loss: 0.028311997652053833
epoch 2900  clean testing loss: 0.020901242271065712
epoch 3000  training loss: 0.027984093874692917
epoch 3000  clean testing loss: 0.020727116614580154
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-02_invop0 ...
epoch 3100  training loss: 0.027721254155039787
epoch 3100  clean testing loss: 0.02055269293487072
epoch 3200  training loss: 0.027482975274324417
epoch 3200  clean testing loss: 0.020463284105062485
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-02_invop0 ...