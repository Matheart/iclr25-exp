
  0%|                                                                                | 75/100000 [00:01<28:13, 59.01it/s]
epoch 0  training loss: 45.56682205200195
epoch 0  clean testing loss: 42.339759826660156

  0%|▏                                                                              | 191/100000 [00:03<27:58, 59.47it/s]
epoch 100  training loss: 0.6066281199455261
epoch 100  clean testing loss: 0.037105776369571686
epoch 200  training loss: 0.5814151763916016

  0%|▏                                                                              | 306/100000 [00:05<28:30, 58.27it/s]
epoch 300  training loss: 0.5735892653465271

  0%|▎                                                                              | 420/100000 [00:07<28:09, 58.95it/s]
epoch 400  training loss: 0.5694058537483215

  1%|▍                                                                              | 540/100000 [00:09<28:11, 58.78it/s]
epoch 500  training loss: 0.5666786432266235

  1%|▌                                                                              | 657/100000 [00:11<27:16, 60.70it/s]
epoch 600  training loss: 0.5646111369132996

  1%|▋                                                                              | 809/100000 [00:13<22:45, 72.63it/s]
epoch 700  training loss: 0.5628886818885803
epoch 700  clean testing loss: 0.04467105492949486
epoch 800  training loss: 0.5613288283348083

  1%|▊                                                                              | 953/100000 [00:15<22:43, 72.64it/s]
epoch 900  training loss: 0.5598524212837219

  1%|▊                                                                             | 1097/100000 [00:17<22:42, 72.61it/s]
epoch 1000  training loss: 0.5583869218826294
epoch 1000  clean testing loss: 0.047518350183963776
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 1100  training loss: 0.5569086670875549

  1%|▉                                                                             | 1241/100000 [00:19<22:31, 73.08it/s]
epoch 1200  training loss: 0.5553293228149414

  1%|█                                                                             | 1385/100000 [00:21<22:39, 72.53it/s]
epoch 1300  training loss: 0.5535674691200256

  2%|█▏                                                                            | 1537/100000 [00:23<22:30, 72.91it/s]
epoch 1400  training loss: 0.5514941811561584
epoch 1400  clean testing loss: 0.052866123616695404
epoch 1500  training loss: 0.548777163028717

  2%|█▎                                                                            | 1681/100000 [00:25<22:25, 73.07it/s]
epoch 1600  training loss: 0.5447367429733276

  2%|█▍                                                                            | 1825/100000 [00:27<22:26, 72.92it/s]
epoch 1700  training loss: 0.5378819704055786
epoch 1700  clean testing loss: 0.06530799716711044
epoch 1800  training loss: 0.5276944637298584

  2%|█▌                                                                            | 1969/100000 [00:29<22:27, 72.76it/s]
epoch 1900  training loss: 0.5189707279205322

  2%|█▋                                                                            | 2121/100000 [00:31<22:19, 73.07it/s]
epoch 2000  training loss: 0.5127956867218018
epoch 2000  clean testing loss: 0.11476942896842957
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 2100  training loss: 0.5083046555519104

  2%|█▊                                                                            | 2265/100000 [00:33<22:13, 73.28it/s]
epoch 2200  training loss: 0.5044263601303101

  2%|█▉                                                                            | 2409/100000 [00:35<22:15, 73.08it/s]
epoch 2300  training loss: 0.5006285905838013
epoch 2300  clean testing loss: 0.1370588093996048
epoch 2400  training loss: 0.49645984172821045

  3%|█▉                                                                            | 2553/100000 [00:37<22:19, 72.76it/s]
epoch 2500  training loss: 0.4913952648639679

  3%|██                                                                            | 2705/100000 [00:39<22:15, 72.87it/s]
epoch 2600  training loss: 0.48464781045913696
epoch 2600  clean testing loss: 0.16133801639080048
epoch 2700  training loss: 0.4754294157028198

  3%|██▏                                                                           | 2849/100000 [00:41<22:15, 72.75it/s]
epoch 2800  training loss: 0.4625098407268524

  3%|██▎                                                                           | 2993/100000 [00:43<22:11, 72.87it/s]
epoch 2900  training loss: 0.44917044043540955
epoch 2900  clean testing loss: 0.22027647495269775
epoch 3000  training loss: 0.4365929663181305
epoch 3000  clean testing loss: 0.23624740540981293
  3%|██▎                                                                           | 3025/100000 [00:44<22:34, 71.59it/s][34m[1mwandb[39m[22m: 429 encountered (Filestream rate limit exceeded, retrying in 2.3 seconds.), retrying request
  3%|██▍                                                                           | 3137/100000 [00:45<22:06, 73.00it/s]
epoch 3100  training loss: 0.42549610137939453

  3%|██▌                                                                           | 3281/100000 [00:47<22:13, 72.55it/s]
epoch 3200  training loss: 0.41316768527030945

  3%|██▋                                                                           | 3433/100000 [00:49<22:06, 72.79it/s]
epoch 3300  training loss: 0.4027556777000427
epoch 3300  clean testing loss: 0.282889187335968
epoch 3400  training loss: 0.3938068449497223

  4%|██▊                                                                           | 3577/100000 [00:51<22:01, 72.97it/s]
epoch 3500  training loss: 0.38565191626548767

  4%|██▉                                                                           | 3721/100000 [00:53<22:04, 72.69it/s]
epoch 3600  training loss: 0.37656477093696594
epoch 3600  clean testing loss: 0.3369322121143341
epoch 3700  training loss: 0.3651776611804962

  4%|███                                                                           | 3873/100000 [00:55<22:07, 72.39it/s]
epoch 3800  training loss: 0.3516852557659149

  4%|███▏                                                                          | 4017/100000 [00:57<21:55, 72.98it/s]
epoch 3900  training loss: 0.3354385495185852
epoch 3900  clean testing loss: 0.46540534496307373
epoch 4000  training loss: 0.3192901015281677
epoch 4000  clean testing loss: 0.5098361372947693

  4%|███▏                                                                          | 4161/100000 [00:59<21:55, 72.85it/s]
epoch 4100  training loss: 0.30466532707214355

  4%|███▎                                                                          | 4305/100000 [01:01<21:51, 72.96it/s]
epoch 4200  training loss: 0.29119569063186646
epoch 4200  clean testing loss: 0.6440929174423218
epoch 4300  training loss: 0.27933984994888306

  4%|███▍                                                                          | 4457/100000 [01:03<21:54, 72.69it/s]
epoch 4400  training loss: 0.26871803402900696

  5%|███▌                                                                          | 4601/100000 [01:05<21:52, 72.71it/s]
epoch 4500  training loss: 0.27201369404792786
epoch 4500  clean testing loss: 0.9249675869941711
epoch 4600  training loss: 0.250247061252594

  5%|███▋                                                                          | 4745/100000 [01:07<21:49, 72.73it/s]
epoch 4700  training loss: 0.2420095056295395

  5%|███▊                                                                          | 4889/100000 [01:09<21:47, 72.73it/s]
epoch 4800  training loss: 0.23410172760486603

  5%|███▉                                                                          | 5041/100000 [01:11<21:49, 72.51it/s]
epoch 4900  training loss: 0.2274814397096634
epoch 4900  clean testing loss: 1.4549599885940552
epoch 5000  training loss: 0.22647111117839813
epoch 5000  clean testing loss: 1.636064052581787

  5%|████                                                                          | 5185/100000 [01:13<21:40, 72.92it/s]
epoch 5100  training loss: 0.21136689186096191

  5%|████▏                                                                         | 5329/100000 [01:15<21:34, 73.15it/s]
epoch 5200  training loss: 0.20403318107128143
epoch 5200  clean testing loss: 1.951271414756775
epoch 5300  training loss: 0.19543875753879547

  5%|████▎                                                                         | 5473/100000 [01:17<21:37, 72.83it/s]
epoch 5400  training loss: 0.18694299459457397

  6%|████▍                                                                         | 5625/100000 [01:19<21:39, 72.64it/s]
epoch 5500  training loss: 0.1785651296377182
epoch 5500  clean testing loss: 2.4524881839752197
epoch 5600  training loss: 0.17189551889896393

  6%|████▍                                                                         | 5769/100000 [01:21<21:35, 72.74it/s]
epoch 5700  training loss: 0.16669437289237976

  6%|████▌                                                                         | 5913/100000 [01:23<21:38, 72.47it/s]
epoch 5800  training loss: 0.16172271966934204
epoch 5800  clean testing loss: 2.799725294113159
epoch 5900  training loss: 0.15749292075634003

  6%|████▋                                                                         | 6057/100000 [01:25<21:40, 72.25it/s]
epoch 6000  training loss: 0.15342360734939575
epoch 6000  clean testing loss: 3.006080150604248

  6%|████▊                                                                         | 6209/100000 [01:27<21:27, 72.85it/s]
epoch 6100  training loss: 0.1501418501138687
epoch 6100  clean testing loss: 3.099034070968628
epoch 6200  training loss: 0.14678211510181427

  6%|████▉                                                                         | 6353/100000 [01:29<21:23, 72.94it/s]
epoch 6300  training loss: 0.1433316171169281

  6%|█████                                                                         | 6497/100000 [01:31<21:23, 72.84it/s]
epoch 6400  training loss: 0.14002543687820435

  7%|█████▏                                                                        | 6641/100000 [01:33<21:17, 73.07it/s]
epoch 6500  training loss: 0.13677924871444702
epoch 6500  clean testing loss: 3.4951539039611816
epoch 6600  training loss: 0.13365183770656586

  7%|█████▎                                                                        | 6793/100000 [01:35<21:18, 72.92it/s]
epoch 6700  training loss: 0.13039028644561768

  7%|█████▍                                                                        | 6937/100000 [01:37<21:16, 72.92it/s]
epoch 6800  training loss: 0.12875568866729736
epoch 6800  clean testing loss: 3.7784059047698975
epoch 6900  training loss: 0.12423466145992279

  7%|█████▌                                                                        | 7081/100000 [01:39<21:09, 73.19it/s]
epoch 7000  training loss: 0.12196104228496552
epoch 7000  clean testing loss: 3.9714653491973877

  7%|█████▋                                                                        | 7225/100000 [01:41<21:10, 73.05it/s]
epoch 7100  training loss: 0.11838341504335403
epoch 7100  clean testing loss: 4.068790435791016
epoch 7200  training loss: 0.1174381896853447

  7%|█████▊                                                                        | 7377/100000 [01:43<21:11, 72.86it/s]
epoch 7300  training loss: 0.11452868580818176

  8%|█████▊                                                                        | 7521/100000 [01:45<21:11, 72.75it/s]
epoch 7400  training loss: 0.11490999907255173
epoch 7400  clean testing loss: 4.36137580871582
epoch 7500  training loss: 0.10789313167333603

  8%|█████▉                                                                        | 7665/100000 [01:47<21:03, 73.09it/s]
epoch 7600  training loss: 0.10508032143115997

  8%|██████                                                                        | 7809/100000 [01:49<21:06, 72.79it/s]
epoch 7700  training loss: 0.10444751381874084
epoch 7700  clean testing loss: 4.61440372467041
epoch 7800  training loss: 0.10052280128002167

  8%|██████▏                                                                       | 7961/100000 [01:51<21:04, 72.80it/s]
epoch 7900  training loss: 0.09902805089950562

  8%|██████▎                                                                       | 8105/100000 [01:53<21:02, 72.79it/s]
epoch 8000  training loss: 0.09641818702220917
epoch 8000  clean testing loss: 4.8580708503723145

  8%|██████▍                                                                       | 8185/100000 [01:54<20:57, 73.00it/s]
epoch 8100  training loss: 0.09462037682533264

  9%|██████▋                                                                       | 8582/100000 [01:59<20:47, 73.28it/s]
epoch 8200  training loss: 0.0928773507475853
epoch 8200  clean testing loss: 5.003509998321533
epoch 8300  training loss: 0.09132979065179825
epoch 8300  clean testing loss: 5.070245265960693
epoch 8400  training loss: 0.09010230749845505
epoch 8400  clean testing loss: 5.13072395324707
epoch 8500  training loss: 0.0898275375366211

  9%|██████▊                                                                       | 8726/100000 [02:01<20:52, 72.90it/s]
epoch 8600  training loss: 0.08720126748085022
epoch 8600  clean testing loss: 5.234382629394531
epoch 8700  training loss: 0.08589636534452438

  9%|██████▉                                                                       | 8870/100000 [02:03<20:54, 72.63it/s]
epoch 8800  training loss: 0.08477684110403061

  9%|███████                                                                       | 9022/100000 [02:05<21:17, 71.22it/s]
epoch 8900  training loss: 0.08360590785741806
epoch 8900  clean testing loss: 5.387221813201904
epoch 9000  training loss: 0.08255957067012787
epoch 9000  clean testing loss: 5.429428577423096

  9%|███████▏                                                                      | 9166/100000 [02:07<20:48, 72.74it/s]
epoch 9100  training loss: 0.0816875621676445

  9%|███████▎                                                                      | 9310/100000 [02:09<20:43, 72.94it/s]
epoch 9200  training loss: 0.08082360029220581
epoch 9200  clean testing loss: 5.514102935791016
epoch 9300  training loss: 0.0799422636628151

  9%|███████▎                                                                      | 9454/100000 [02:11<20:44, 72.75it/s]
epoch 9400  training loss: 0.07904205471277237

 10%|███████▍                                                                      | 9598/100000 [02:13<20:37, 73.03it/s]
epoch 9500  training loss: 0.07818544656038284

 10%|███████▌                                                                      | 9750/100000 [02:15<20:40, 72.76it/s]
epoch 9600  training loss: 0.07741885632276535
epoch 9600  clean testing loss: 5.673381328582764
epoch 9700  training loss: 0.07682696729898453

 10%|███████▋                                                                      | 9894/100000 [02:17<20:37, 72.81it/s]
epoch 9800  training loss: 0.07640475034713745

 10%|███████▋                                                                     | 10038/100000 [02:19<20:42, 72.38it/s]
epoch 9900  training loss: 0.07554525136947632
epoch 9900  clean testing loss: 5.801264762878418
epoch 10000  training loss: 0.07869899272918701
epoch 10000  clean testing loss: 5.8601298332214355

 10%|███████▊                                                                     | 10190/100000 [02:21<20:33, 72.79it/s]
epoch 10100  training loss: 0.07417029142379761

 10%|███████▉                                                                     | 10334/100000 [02:23<20:18, 73.59it/s]
epoch 10200  training loss: 0.0728474110364914
epoch 10200  clean testing loss: 5.919875621795654
epoch 10300  training loss: 0.07265568524599075

 10%|████████                                                                     | 10478/100000 [02:25<20:19, 73.40it/s]
epoch 10400  training loss: 0.07158409059047699

 11%|████████▏                                                                    | 10630/100000 [02:27<20:28, 72.74it/s]
epoch 10500  training loss: 0.07074911147356033
epoch 10500  clean testing loss: 6.051363468170166
epoch 10600  training loss: 0.07032839208841324

 11%|████████▎                                                                    | 10774/100000 [02:29<20:23, 72.91it/s]
epoch 10700  training loss: 0.06953717768192291

 11%|████████▍                                                                    | 10918/100000 [02:31<20:28, 72.54it/s]
epoch 10800  training loss: 0.06904777884483337
epoch 10800  clean testing loss: 6.195371150970459
epoch 10900  training loss: 0.06836151331663132

 11%|████████▌                                                                    | 11062/100000 [02:33<20:24, 72.61it/s]
epoch 11000  training loss: 0.06784077733755112
epoch 11000  clean testing loss: 6.303329944610596

 11%|████████▋                                                                    | 11206/100000 [02:35<20:23, 72.55it/s]
epoch 11100  training loss: 0.06793753802776337

 11%|████████▋                                                                    | 11358/100000 [02:38<20:17, 72.83it/s]
epoch 11200  training loss: 0.06653713434934616
epoch 11200  clean testing loss: 6.414391994476318
epoch 11300  training loss: 0.06674899160861969

 12%|████████▊                                                                    | 11502/100000 [02:39<20:15, 72.79it/s]
epoch 11400  training loss: 0.06652330607175827

 12%|████████▉                                                                    | 11646/100000 [02:41<20:17, 72.57it/s]
epoch 11500  training loss: 0.0678354948759079
epoch 11500  clean testing loss: 6.587059497833252
epoch 11600  training loss: 0.06443560868501663

 12%|█████████                                                                    | 11782/100000 [02:43<20:09, 72.95it/s]
epoch 11700  training loss: 0.06387943774461746

 12%|█████████▏                                                                   | 11942/100000 [02:46<20:16, 72.37it/s]
epoch 11800  training loss: 0.06338358670473099
epoch 11800  clean testing loss: 6.814286708831787
epoch 11900  training loss: 0.06347668915987015

 12%|█████████▎                                                                   | 12086/100000 [02:48<20:10, 72.64it/s]
epoch 12000  training loss: 0.0626172125339508
epoch 12000  clean testing loss: 6.965295314788818

 12%|█████████▍                                                                   | 12230/100000 [02:50<20:00, 73.12it/s]
epoch 12100  training loss: 0.062022171914577484
epoch 12100  clean testing loss: 7.036057472229004
epoch 12200  training loss: 0.06161409988999367

 12%|█████████▌                                                                   | 12374/100000 [02:51<20:03, 72.81it/s]
epoch 12300  training loss: 0.06118972226977348

 13%|█████████▋                                                                   | 12526/100000 [02:54<19:58, 72.98it/s]
epoch 12400  training loss: 0.06075870618224144
epoch 12400  clean testing loss: 7.268728733062744
epoch 12500  training loss: 0.06031639128923416

 13%|█████████▊                                                                   | 12670/100000 [02:56<19:51, 73.29it/s]
epoch 12600  training loss: 0.059924714267253876

 13%|█████████▊                                                                   | 12814/100000 [02:58<19:54, 73.02it/s]
epoch 12700  training loss: 0.05980925261974335
epoch 12700  clean testing loss: 7.519664287567139
epoch 12800  training loss: 0.05920633301138878

 13%|█████████▉                                                                   | 12894/100000 [02:59<19:58, 72.67it/s]
epoch 12900  training loss: 0.06353452801704407
epoch 12900  clean testing loss: 7.688110828399658
epoch 13000  training loss: 0.0626949891448021
epoch 13000  clean testing loss: 7.8020548820495605
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 13100  training loss: 0.05805106833577156

 13%|██████████                                                                   | 13110/100000 [03:11<24:38, 58.76it/s]
epoch 13200  training loss: 0.05820973217487335

 13%|██████████▏                                                                  | 13254/100000 [03:13<19:50, 72.87it/s]
epoch 13300  training loss: 0.05700001120567322
epoch 13300  clean testing loss: 8.030864715576172
epoch 13400  training loss: 0.056651681661605835

 13%|██████████▎                                                                  | 13398/100000 [03:15<19:44, 73.09it/s]
epoch 13500  training loss: 0.05616488307714462

 14%|██████████▍                                                                  | 13542/100000 [03:17<19:46, 72.88it/s]
epoch 13600  training loss: 0.055727776139974594
epoch 13600  clean testing loss: 8.298213005065918
epoch 13700  training loss: 0.055371735244989395

 14%|██████████▌                                                                  | 13694/100000 [03:19<19:48, 72.65it/s]
epoch 13800  training loss: 0.05500809848308563


 14%|██████████▊                                                                  | 13982/100000 [03:23<19:42, 72.75it/s]
epoch 13900  training loss: 0.0545043982565403
epoch 13900  clean testing loss: 8.5537748336792
epoch 14000  training loss: 0.05411187931895256
epoch 14000  clean testing loss: 8.636112213134766

 14%|██████████▉                                                                  | 14134/100000 [03:25<19:36, 72.99it/s]
epoch 14100  training loss: 0.05373310297727585

 14%|██████████▉                                                                  | 14278/100000 [03:27<19:39, 72.65it/s]
epoch 14200  training loss: 0.05337109789252281

 14%|███████████                                                                  | 14422/100000 [03:29<19:34, 72.85it/s]
epoch 14300  training loss: 0.055858809500932693
epoch 14300  clean testing loss: 8.881837844848633
epoch 14400  training loss: 0.056445132941007614
epoch 14400  clean testing loss: 8.949231147766113
epoch 14500  training loss: 0.052187561988830566

 15%|███████████▏                                                                 | 14566/100000 [03:31<19:34, 72.76it/s]
epoch 14600  training loss: 0.05176956579089165
epoch 14600  clean testing loss: 9.105871200561523
epoch 14700  training loss: 0.05298079177737236

 15%|███████████▎                                                                 | 14718/100000 [03:33<19:28, 72.98it/s]
epoch 14800  training loss: 0.05088834464550018

 15%|███████████▍                                                                 | 14862/100000 [03:35<19:28, 72.89it/s]
epoch 14900  training loss: 0.05044693127274513
epoch 14900  clean testing loss: 9.323042869567871
epoch 15000  training loss: 0.050154779106378555
epoch 15000  clean testing loss: 9.393451690673828

 15%|███████████▌                                                                 | 15006/100000 [03:37<19:39, 72.08it/s]
epoch 15100  training loss: 0.049673181027173996

 15%|███████████▋                                                                 | 15158/100000 [03:39<19:25, 72.81it/s]
epoch 15200  training loss: 0.04930274561047554
epoch 15200  clean testing loss: 9.51320743560791
epoch 15300  training loss: 0.04890986159443855

 15%|███████████▊                                                                 | 15302/100000 [03:41<19:23, 72.82it/s]
epoch 15400  training loss: 0.04849439859390259

 15%|███████████▉                                                                 | 15446/100000 [03:43<19:17, 73.08it/s]
epoch 15500  training loss: 0.04807654023170471
epoch 15500  clean testing loss: 9.69987964630127
epoch 15600  training loss: 0.04786026477813721

 16%|████████████                                                                 | 15598/100000 [03:45<19:20, 72.70it/s]
epoch 15700  training loss: 0.04737263545393944

 16%|████████████                                                                 | 15742/100000 [03:47<19:16, 72.89it/s]
epoch 15800  training loss: 0.04742716997861862
epoch 15800  clean testing loss: 9.888453483581543
epoch 15900  training loss: 0.04640505090355873

 16%|████████████▏                                                                | 15886/100000 [03:49<19:14, 72.83it/s]
epoch 16000  training loss: 0.04594595730304718
epoch 16000  clean testing loss: 9.9822359085083

 16%|████████████▎                                                                | 16030/100000 [03:51<19:18, 72.46it/s]
epoch 16100  training loss: 0.04554560407996178


 17%|████████████▊                                                                | 16694/100000 [04:00<18:56, 73.28it/s]
epoch 16200  training loss: 0.04606534168124199
epoch 16200  clean testing loss: 10.08435344696045
epoch 16300  training loss: 0.04478132352232933
epoch 16300  clean testing loss: 10.140701293945312
epoch 16400  training loss: 0.044304009526968
epoch 16400  clean testing loss: 10.184744834899902
epoch 16500  training loss: 0.046308647841215134
epoch 16500  clean testing loss: 10.212564468383789
epoch 16600  training loss: 0.04345550388097763
epoch 16600  clean testing loss: 10.286149024963379
epoch 16700  training loss: 0.042954109609127045

 17%|████████████▉                                                                | 16838/100000 [04:02<18:57, 73.10it/s]
epoch 16800  training loss: 0.042751580476760864

 17%|█████████████                                                                | 16982/100000 [04:04<18:56, 73.06it/s]
epoch 16900  training loss: 0.04240706190466881

 17%|█████████████▏                                                               | 17134/100000 [04:06<18:49, 73.38it/s]
epoch 17000  training loss: 0.04197433590888977
epoch 17000  clean testing loss: 10.468840599060059
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 17100  training loss: 0.041250769048929214

 17%|█████████████▎                                                               | 17278/100000 [04:08<18:53, 73.00it/s]
epoch 17200  training loss: 0.04122203215956688

 17%|█████████████▍                                                               | 17422/100000 [04:10<18:50, 73.06it/s]
epoch 17300  training loss: 0.04064524918794632
epoch 17300  clean testing loss: 10.618051528930664
epoch 17400  training loss: 0.04017208516597748

 18%|█████████████▌                                                               | 17574/100000 [04:12<18:49, 72.98it/s]
epoch 17500  training loss: 0.039943255484104156

 18%|█████████████▋                                                               | 17718/100000 [04:14<18:42, 73.29it/s]
epoch 17600  training loss: 0.03942791372537613
epoch 17600  clean testing loss: 10.751701354980469
epoch 17700  training loss: 0.03896528109908104

 18%|█████████████▊                                                               | 17862/100000 [04:16<18:51, 72.57it/s]
epoch 17800  training loss: 0.039539799094200134

 18%|█████████████▊                                                               | 18006/100000 [04:18<18:51, 72.46it/s]
epoch 17900  training loss: 0.03813377395272255
epoch 17900  clean testing loss: 10.88815689086914
epoch 18000  training loss: 0.03788240998983383
epoch 18000  clean testing loss: 10.934209823608398

 18%|█████████████▉                                                               | 18158/100000 [04:20<18:43, 72.82it/s]
epoch 18100  training loss: 0.03742852434515953

 18%|██████████████                                                               | 18302/100000 [04:22<18:39, 72.99it/s]
epoch 18200  training loss: 0.03712044656276703
epoch 18200  clean testing loss: 11.011967658996582
epoch 18300  training loss: 0.03680150955915451

 18%|██████████████▏                                                              | 18446/100000 [04:24<18:38, 72.93it/s]
epoch 18400  training loss: 0.036471158266067505

 19%|██████████████▎                                                              | 18590/100000 [04:26<18:40, 72.65it/s]
epoch 18500  training loss: 0.03618040308356285
epoch 18500  clean testing loss: 11.13540267944336
epoch 18600  training loss: 0.035816263407468796

 19%|██████████████▍                                                              | 18742/100000 [04:28<18:31, 73.11it/s]
epoch 18700  training loss: 0.0355028472840786

 19%|██████████████▌                                                              | 18886/100000 [04:30<18:34, 72.79it/s]
epoch 18800  training loss: 0.03520035743713379

 19%|██████████████▋                                                              | 19030/100000 [04:32<18:33, 72.69it/s]
epoch 18900  training loss: 0.03488948941230774
epoch 18900  clean testing loss: 11.292703628540039
epoch 19000  training loss: 0.03457188606262207
epoch 19000  clean testing loss: 11.334606170654297

 19%|██████████████▊                                                              | 19182/100000 [04:34<18:23, 73.26it/s]
epoch 19100  training loss: 0.035547152161598206

 19%|██████████████▉                                                              | 19326/100000 [04:36<18:26, 72.91it/s]
epoch 19200  training loss: 0.034374382346868515
epoch 19200  clean testing loss: 11.425551414489746
epoch 19300  training loss: 0.03370659798383713

 19%|██████████████▉                                                              | 19470/100000 [04:38<18:24, 72.91it/s]
epoch 19400  training loss: 0.033441752195358276

 20%|███████████████                                                              | 19622/100000 [04:40<18:21, 72.99it/s]
epoch 19500  training loss: 0.03308812156319618
epoch 19500  clean testing loss: 11.515119552612305
epoch 19600  training loss: 0.03286431357264519

 20%|███████████████▏                                                             | 19766/100000 [04:42<18:14, 73.30it/s]
epoch 19700  training loss: 0.03256770595908165

 20%|███████████████▎                                                             | 19910/100000 [04:44<18:19, 72.85it/s]
epoch 19800  training loss: 0.032255131751298904
epoch 19800  clean testing loss: 11.620378494262695
epoch 19900  training loss: 0.03249731659889221

 20%|███████████████▍                                                             | 20054/100000 [04:46<18:15, 72.99it/s]
epoch 20000  training loss: 0.032139480113983154
epoch 20000  clean testing loss: 11.693744659423828

 20%|███████████████▌                                                             | 20206/100000 [04:48<18:18, 72.64it/s]
epoch 20100  training loss: 0.031699493527412415
epoch 20100  clean testing loss: 11.715773582458496
epoch 20200  training loss: 0.031269337981939316

 20%|███████████████▋                                                             | 20350/100000 [04:50<18:09, 73.11it/s]
epoch 20300  training loss: 0.0308783371001482

 20%|███████████████▊                                                             | 20494/100000 [04:52<18:07, 73.11it/s]
epoch 20400  training loss: 0.03061152808368206
epoch 20400  clean testing loss: 11.819615364074707
epoch 20500  training loss: 0.03035437874495983

 21%|███████████████▉                                                             | 20646/100000 [04:54<18:10, 72.76it/s]
epoch 20600  training loss: 0.030127640813589096

 21%|████████████████                                                             | 20790/100000 [04:56<18:08, 72.80it/s]
epoch 20700  training loss: 0.029830919578671455

 21%|████████████████                                                             | 20934/100000 [04:58<18:06, 72.74it/s]
epoch 20800  training loss: 0.029574239626526833
epoch 20800  clean testing loss: 11.962038040161133
epoch 20900  training loss: 0.029324356466531754

 21%|████████████████▏                                                            | 21078/100000 [05:00<18:04, 72.75it/s]
epoch 21000  training loss: 0.02957364358007908
epoch 21000  clean testing loss: 12.035520553588867

 21%|████████████████▎                                                            | 21230/100000 [05:02<17:56, 73.16it/s]
epoch 21100  training loss: 0.028828086331486702
epoch 21100  clean testing loss: 12.068401336669922
epoch 21200  training loss: 0.02860734611749649

 21%|████████████████▍                                                            | 21374/100000 [05:04<18:04, 72.49it/s]
epoch 21300  training loss: 0.028375854715704918

 22%|████████████████▌                                                            | 21518/100000 [05:06<18:13, 71.76it/s]
epoch 21400  training loss: 0.028133388608694077
epoch 21400  clean testing loss: 12.185104370117188
epoch 21500  training loss: 0.027894876897335052

 22%|████████████████▋                                                            | 21662/100000 [05:08<17:57, 72.69it/s]
epoch 21600  training loss: 0.02764546312391758

 22%|████████████████▊                                                            | 21814/100000 [05:10<17:51, 72.98it/s]
epoch 21700  training loss: 0.027658754959702492
epoch 21700  clean testing loss: 12.298736572265625
epoch 21800  training loss: 0.027282781898975372

 22%|████████████████▉                                                            | 21958/100000 [05:12<17:48, 73.04it/s]
epoch 21900  training loss: 0.026930490508675575

 22%|█████████████████                                                            | 22102/100000 [05:14<17:50, 72.79it/s]
epoch 22000  training loss: 0.026758965104818344
epoch 22000  clean testing loss: 12.454243659973145
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 22100  training loss: 0.026689058169722557

 22%|█████████████████▏                                                           | 22246/100000 [05:16<17:49, 72.67it/s]
epoch 22200  training loss: 0.02646601013839245

 22%|█████████████████▏                                                           | 22398/100000 [05:18<17:48, 72.63it/s]
epoch 22300  training loss: 0.026005730032920837

 23%|█████████████████▎                                                           | 22542/100000 [05:20<17:44, 72.79it/s]
epoch 22400  training loss: 0.02580529823899269
epoch 22400  clean testing loss: 12.6441068649292
epoch 22500  training loss: 0.025768747553229332

 23%|█████████████████▍                                                           | 22686/100000 [05:22<17:42, 72.73it/s]
epoch 22600  training loss: 0.02523704431951046

 23%|█████████████████▌                                                           | 22830/100000 [05:24<17:39, 72.84it/s]
epoch 22700  training loss: 0.025019995868206024
epoch 22700  clean testing loss: 12.820772171020508
epoch 22800  training loss: 0.024771125987172127

 23%|█████████████████▋                                                           | 22982/100000 [05:26<17:33, 73.08it/s]
epoch 22900  training loss: 0.024586720392107964

 23%|█████████████████▊                                                           | 23126/100000 [05:28<17:36, 72.78it/s]
epoch 23000  training loss: 0.024321122094988823
epoch 23000  clean testing loss: 12.994499206542969
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 23100  training loss: 0.02412247471511364

 23%|█████████████████▉                                                           | 23270/100000 [05:30<17:31, 73.00it/s]
epoch 23200  training loss: 0.02473921701312065

 23%|██████████████████                                                           | 23414/100000 [05:32<17:32, 72.78it/s]
epoch 23300  training loss: 0.023637691512703896
epoch 23300  clean testing loss: 13.179852485656738
epoch 23400  training loss: 0.023707127198576927

 24%|██████████████████▏                                                          | 23558/100000 [05:34<17:35, 72.43it/s]
epoch 23500  training loss: 0.023201482370495796

 24%|██████████████████▎                                                          | 23710/100000 [05:36<17:35, 72.27it/s]
epoch 23600  training loss: 0.02294527366757393
epoch 23600  clean testing loss: 13.37183666229248
epoch 23700  training loss: 0.022720621898770332

 24%|██████████████████▎                                                          | 23854/100000 [05:38<17:29, 72.57it/s]
epoch 23800  training loss: 0.022504445165395737

 24%|██████████████████▍                                                          | 23998/100000 [05:40<17:30, 72.36it/s]
epoch 23900  training loss: 0.022392626851797104

 24%|██████████████████▌                                                          | 24142/100000 [05:42<17:28, 72.36it/s]
epoch 24000  training loss: 0.023180626332759857
epoch 24000  clean testing loss: 13.6483793258667
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 24100  training loss: 0.021867871284484863

 24%|██████████████████▋                                                          | 24286/100000 [05:44<17:24, 72.51it/s]
epoch 24200  training loss: 0.021679170429706573

 24%|██████████████████▊                                                          | 24438/100000 [05:46<17:24, 72.36it/s]
epoch 24300  training loss: 0.02148076333105564
epoch 24300  clean testing loss: 13.83639144897461
epoch 24400  training loss: 0.021272113546729088

 25%|██████████████████▉                                                          | 24582/100000 [05:48<17:23, 72.31it/s]
epoch 24500  training loss: 0.021313849836587906

 25%|███████████████████                                                          | 24726/100000 [05:50<17:26, 71.91it/s]
epoch 24600  training loss: 0.02086416445672512
epoch 24600  clean testing loss: 14.053656578063965
epoch 24700  training loss: 0.020627852529287338

 25%|███████████████████▏                                                         | 24870/100000 [05:52<17:12, 72.77it/s]
epoch 24800  training loss: 0.02041015401482582

 25%|███████████████████▎                                                         | 25013/100000 [05:54<17:28, 71.54it/s]
epoch 24900  training loss: 0.020192189142107964
epoch 24900  clean testing loss: 14.284219741821289
epoch 25000  training loss: 0.019977955147624016
epoch 25000  clean testing loss: 14.364264488220215

 25%|███████████████████▎                                                         | 25157/100000 [05:56<17:18, 72.04it/s]
epoch 25100  training loss: 0.019819332286715508

 25%|███████████████████▍                                                         | 25301/100000 [05:58<17:15, 72.11it/s]
epoch 25200  training loss: 0.019672833383083344

 25%|███████████████████▌                                                         | 25445/100000 [06:00<17:12, 72.20it/s]
epoch 25300  training loss: 0.01934421993792057
epoch 25300  clean testing loss: 14.604545593261719
epoch 25400  training loss: 0.019138742238283157

 26%|███████████████████▋                                                         | 25560/100000 [06:02<24:31, 50.60it/s]
epoch 25500  training loss: 0.018934495747089386

 26%|███████████████████▊                                                         | 25658/100000 [06:04<25:24, 48.77it/s]
epoch 25600  training loss: 0.01873338781297207

 26%|███████████████████▊                                                         | 25759/100000 [06:06<24:56, 49.61it/s]
epoch 25700  training loss: 0.01871723122894764

 26%|███████████████████▉                                                         | 25859/100000 [06:08<24:55, 49.59it/s]
epoch 25800  training loss: 0.018332980573177338

 26%|███████████████████▉                                                         | 25960/100000 [06:10<24:53, 49.58it/s]
epoch 25900  training loss: 0.018113618716597557

 26%|████████████████████                                                         | 26057/100000 [06:12<24:56, 49.42it/s]
epoch 26000  training loss: 0.017918270081281662
epoch 26000  clean testing loss: 15.216691970825195

 26%|████████████████████▏                                                        | 26157/100000 [06:14<24:53, 49.46it/s]
epoch 26100  training loss: 0.017927758395671844

 26%|████████████████████▏                                                        | 26257/100000 [06:16<24:50, 49.46it/s]
epoch 26200  training loss: 0.017681928351521492

 26%|████████████████████▎                                                        | 26352/100000 [06:18<24:51, 49.38it/s]
epoch 26300  training loss: 0.017394185066223145

 26%|████████████████████▎                                                        | 26452/100000 [06:20<24:47, 49.43it/s]
epoch 26400  training loss: 0.017154546454548836

 27%|████████████████████▍                                                        | 26554/100000 [06:22<24:42, 49.54it/s]
epoch 26500  training loss: 0.016965137794613838

 27%|████████████████████▌                                                        | 26654/100000 [06:24<24:42, 49.49it/s]
epoch 26600  training loss: 0.017383597791194916

 27%|████████████████████▌                                                        | 26751/100000 [06:26<24:39, 49.50it/s]
epoch 26700  training loss: 0.016886921599507332

 27%|████████████████████▋                                                        | 26826/100000 [06:28<24:36, 49.56it/s]
epoch 26800  training loss: 0.016476977616548538

 27%|████████████████████▋                                                        | 26926/100000 [06:30<24:39, 49.39it/s]
epoch 26900  training loss: 0.01630500890314579

 27%|████████████████████▊                                                        | 27023/100000 [06:32<24:37, 49.41it/s]
epoch 27000  training loss: 0.016320321708917618
epoch 27000  clean testing loss: 16.218542098999023

 27%|████████████████████▉                                                        | 27123/100000 [06:34<24:31, 49.51it/s]
epoch 27100  training loss: 0.01589140109717846

 27%|████████████████████▉                                                        | 27223/100000 [06:36<24:30, 49.49it/s]
epoch 27200  training loss: 0.015736430883407593

 27%|█████████████████████                                                        | 27323/100000 [06:38<24:30, 49.43it/s]
epoch 27300  training loss: 0.015574371442198753

 27%|█████████████████████                                                        | 27423/100000 [06:40<24:25, 49.52it/s]
epoch 27400  training loss: 0.01540403999388218

 28%|█████████████████████▏                                                       | 27519/100000 [06:42<24:24, 49.48it/s]
epoch 27500  training loss: 0.015230768360197544

 28%|█████████████████████▎                                                       | 27621/100000 [06:44<24:30, 49.22it/s]
epoch 27600  training loss: 0.015105551108717918

 28%|█████████████████████▎                                                       | 27718/100000 [06:46<24:21, 49.46it/s]
epoch 27700  training loss: 0.014885498210787773

 28%|█████████████████████▍                                                       | 27819/100000 [06:48<24:07, 49.87it/s]
epoch 27800  training loss: 0.015085626393556595

 28%|█████████████████████▌                                                       | 27937/100000 [06:50<20:24, 58.84it/s]
epoch 27900  training loss: 0.01453961618244648

 28%|█████████████████████▌                                                       | 28053/100000 [06:52<20:17, 59.07it/s]
epoch 28000  training loss: 0.014417796395719051
epoch 28000  clean testing loss: 17.370243072509766

 28%|█████████████████████▋                                                       | 28173/100000 [06:54<20:20, 58.85it/s]
epoch 28100  training loss: 0.014217223040759563

 28%|█████████████████████▊                                                       | 28287/100000 [06:56<20:16, 58.93it/s]
epoch 28200  training loss: 0.014028118923306465
epoch 28200  clean testing loss: 17.63425636291504
epoch 28300  training loss: 0.013856738805770874

 28%|█████████████████████▊                                                       | 28407/100000 [06:58<20:16, 58.86it/s]
epoch 28400  training loss: 0.013686440885066986

 29%|█████████████████████▉                                                       | 28528/100000 [07:00<20:11, 58.99it/s]
epoch 28500  training loss: 0.013520777225494385

 29%|██████████████████████                                                       | 28643/100000 [07:02<20:08, 59.03it/s]
epoch 28600  training loss: 0.01335439458489418

 29%|██████████████████████▏                                                      | 28793/100000 [07:04<16:19, 72.72it/s]
epoch 28700  training loss: 0.013190239667892456
epoch 28700  clean testing loss: 18.323226928710938
epoch 28800  training loss: 0.013036108575761318

 29%|██████████████████████▎                                                      | 28937/100000 [07:06<16:16, 72.77it/s]
epoch 28900  training loss: 0.012885577976703644

 29%|██████████████████████▍                                                      | 29081/100000 [07:08<16:19, 72.37it/s]
epoch 29000  training loss: 0.012693529017269611
epoch 29000  clean testing loss: 18.774593353271484

 29%|██████████████████████▌                                                      | 29225/100000 [07:10<16:11, 72.82it/s]
epoch 29100  training loss: 0.012530825100839138
epoch 29100  clean testing loss: 18.927127838134766
epoch 29200  training loss: 0.012522818520665169

 29%|██████████████████████▌                                                      | 29369/100000 [07:12<16:18, 72.21it/s]
epoch 29300  training loss: 0.012244791723787785

 30%|██████████████████████▋                                                      | 29521/100000 [07:14<16:13, 72.40it/s]
epoch 29400  training loss: 0.012049959972500801
epoch 29400  clean testing loss: 19.412429809570312
epoch 29500  training loss: 0.011883965693414211

 30%|██████████████████████▊                                                      | 29665/100000 [07:16<16:21, 71.65it/s]
epoch 29600  training loss: 0.012077427469193935

 30%|██████████████████████▉                                                      | 29798/100000 [07:18<18:53, 61.95it/s]
epoch 29700  training loss: 0.011624201200902462
epoch 29700  clean testing loss: 19.92032814025879
epoch 29800  training loss: 0.011411740444600582

 30%|███████████████████████                                                      | 29917/100000 [07:20<19:42, 59.28it/s]
epoch 29900  training loss: 0.01125653088092804

 30%|███████████████████████▏                                                     | 30035/100000 [07:22<20:03, 58.14it/s]
epoch 30000  training loss: 0.011106960475444794
epoch 30000  clean testing loss: 20.44054412841797
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 30100  training loss: 0.010973844677209854

 30%|███████████████████████▏                                                     | 30153/100000 [07:24<19:27, 59.84it/s]
epoch 30200  training loss: 0.010844024829566479

 30%|███████████████████████▎                                                     | 30274/100000 [07:26<19:25, 59.80it/s]
epoch 30300  training loss: 0.010707808658480644
epoch 30300  clean testing loss: 20.925453186035156
epoch 30400  training loss: 0.010570187121629715

 30%|███████████████████████▍                                                     | 30391/100000 [07:28<22:18, 52.02it/s]
epoch 30500  training loss: 0.010428747162222862


 31%|███████████████████████▌                                                     | 30588/100000 [07:32<23:19, 49.60it/s]
epoch 30600  training loss: 0.010290396399796009

 31%|███████████████████████▋                                                     | 30690/100000 [07:34<23:15, 49.65it/s]
epoch 30700  training loss: 0.010154937393963337

 31%|███████████████████████▋                                                     | 30787/100000 [07:36<23:07, 49.88it/s]
epoch 30800  training loss: 0.010018103756010532

 31%|███████████████████████▊                                                     | 30890/100000 [07:38<23:11, 49.66it/s]
epoch 30900  training loss: 0.009884562343358994

 31%|███████████████████████▊                                                     | 30990/100000 [07:40<23:11, 49.58it/s]
epoch 31000  training loss: 0.010142010636627674
epoch 31000  clean testing loss: 22.24546241760254

 31%|███████████████████████▉                                                     | 31087/100000 [07:42<23:13, 49.46it/s]
epoch 31100  training loss: 0.009691563434898853

 31%|████████████████████████                                                     | 31187/100000 [07:44<23:08, 49.57it/s]
epoch 31200  training loss: 0.009511219337582588

 31%|████████████████████████                                                     | 31287/100000 [07:46<23:05, 49.60it/s]
epoch 31300  training loss: 0.009381342679262161

 31%|████████████████████████▏                                                    | 31384/100000 [07:48<22:54, 49.91it/s]
epoch 31400  training loss: 0.009286129847168922


 31%|████████████████████████▏                                                    | 31489/100000 [07:50<22:58, 49.71it/s]
epoch 31500  training loss: 0.009145403280854225
epoch 31500  clean testing loss: 23.246614456176758
epoch 31600  training loss: 0.009216396138072014

 32%|████████████████████████▍                                                    | 31707/100000 [07:54<22:46, 49.99it/s]
epoch 31700  training loss: 0.008919475600123405

 32%|████████████████████████▍                                                    | 31808/100000 [07:57<22:57, 49.49it/s]
epoch 31800  training loss: 0.008799721486866474

 32%|████████████████████████▌                                                    | 31909/100000 [07:59<22:52, 49.62it/s]
epoch 31900  training loss: 0.00870455615222454

 32%|████████████████████████▋                                                    | 32004/100000 [08:01<23:35, 48.03it/s]
epoch 32000  training loss: 0.008709746412932873
epoch 32000  clean testing loss: 24.264318466186523

 32%|████████████████████████▋                                                    | 32107/100000 [08:03<22:33, 50.15it/s]
epoch 32100  training loss: 0.008492439053952694

 32%|████████████████████████▊                                                    | 32203/100000 [08:05<22:48, 49.54it/s]
epoch 32200  training loss: 0.00865017157047987

 32%|████████████████████████▊                                                    | 32303/100000 [08:07<22:45, 49.57it/s]
epoch 32300  training loss: 0.008287522941827774

 32%|████████████████████████▉                                                    | 32405/100000 [08:09<22:41, 49.63it/s]
epoch 32400  training loss: 0.00825453270226717

 33%|█████████████████████████                                                    | 32505/100000 [08:11<22:44, 49.45it/s]
epoch 32500  training loss: 0.008128936402499676

 33%|█████████████████████████                                                    | 32600/100000 [08:13<22:56, 48.98it/s]
epoch 32600  training loss: 0.008019017055630684

 33%|█████████████████████████▏                                                   | 32700/100000 [08:15<22:40, 49.47it/s]
epoch 32700  training loss: 0.007924076169729233

 33%|█████████████████████████▎                                                   | 32799/100000 [08:17<22:31, 49.71it/s]
epoch 32800  training loss: 0.00783394742757082

 33%|█████████████████████████▎                                                   | 32900/100000 [08:19<22:33, 49.58it/s]
epoch 32900  training loss: 0.00775213772431016

 33%|█████████████████████████▍                                                   | 33001/100000 [08:21<22:47, 48.99it/s]
epoch 33000  training loss: 0.007675785105675459
epoch 33000  clean testing loss: 26.28120231628418

 33%|█████████████████████████▍                                                   | 33101/100000 [08:23<22:32, 49.48it/s]
epoch 33100  training loss: 0.0076079904101789

 33%|█████████████████████████▌                                                   | 33197/100000 [08:25<22:28, 49.53it/s]
epoch 33200  training loss: 0.007542135193943977

 33%|█████████████████████████▋                                                   | 33298/100000 [08:27<22:29, 49.44it/s]
epoch 33300  training loss: 0.007474031299352646

 33%|█████████████████████████▋                                                   | 33396/100000 [08:29<22:20, 49.70it/s]
epoch 33400  training loss: 0.007404366973787546

 33%|█████████████████████████▊                                                   | 33497/100000 [08:31<22:24, 49.46it/s]
epoch 33500  training loss: 0.007340437266975641

 34%|█████████████████████████▊                                                   | 33597/100000 [08:33<22:19, 49.56it/s]
epoch 33600  training loss: 0.0072725387290120125

 34%|█████████████████████████▉                                                   | 33697/100000 [08:35<22:19, 49.50it/s]
epoch 33700  training loss: 0.00721109239384532

 34%|██████████████████████████                                                   | 33798/100000 [08:37<22:12, 49.69it/s]
epoch 33800  training loss: 0.007134484592825174

 34%|██████████████████████████                                                   | 33894/100000 [08:39<22:13, 49.57it/s]
epoch 33900  training loss: 0.007068441715091467

 34%|██████████████████████████▏                                                  | 33994/100000 [08:41<22:12, 49.53it/s]
epoch 34000  training loss: 0.007005793042480946
epoch 34000  clean testing loss: 28.045629501342773

 34%|██████████████████████████▎                                                  | 34095/100000 [08:43<22:09, 49.58it/s]
epoch 34100  training loss: 0.006944253109395504

 34%|██████████████████████████▎                                                  | 34196/100000 [08:45<22:01, 49.81it/s]
epoch 34200  training loss: 0.006884284317493439

 34%|██████████████████████████▍                                                  | 34291/100000 [08:47<22:06, 49.54it/s]
epoch 34300  training loss: 0.006825299933552742

 34%|██████████████████████████▍                                                  | 34392/100000 [08:49<21:57, 49.80it/s]
epoch 34400  training loss: 0.006769448518753052

 34%|██████████████████████████▌                                                  | 34492/100000 [08:51<22:04, 49.47it/s]
epoch 34500  training loss: 0.006718963850289583

 35%|██████████████████████████▋                                                  | 34593/100000 [08:53<22:02, 49.47it/s]
epoch 34600  training loss: 0.0067053865641355515

 35%|██████████████████████████▋                                                  | 34690/100000 [08:55<21:48, 49.90it/s]
epoch 34700  training loss: 0.006623150780797005

 35%|██████████████████████████▊                                                  | 34791/100000 [08:57<21:47, 49.86it/s]
epoch 34800  training loss: 0.006573911756277084

 35%|██████████████████████████▊                                                  | 34893/100000 [08:59<21:51, 49.65it/s]
epoch 34900  training loss: 0.006505385972559452

 35%|██████████████████████████▉                                                  | 34988/100000 [09:01<21:52, 49.52it/s]
epoch 35000  training loss: 0.006608948577195406
epoch 35000  clean testing loss: 29.671611785888672

 35%|███████████████████████████                                                  | 35089/100000 [09:03<21:49, 49.59it/s]
epoch 35100  training loss: 0.006410375703126192

 35%|███████████████████████████                                                  | 35189/100000 [09:05<21:47, 49.56it/s]
epoch 35200  training loss: 0.006546596996486187

 35%|███████████████████████████▏                                                 | 35285/100000 [09:07<21:47, 49.49it/s]
epoch 35300  training loss: 0.006409123539924622

 35%|███████████████████████████▏                                                 | 35387/100000 [09:09<21:37, 49.80it/s]
epoch 35400  training loss: 0.00626268470659852

 35%|███████████████████████████▎                                                 | 35462/100000 [09:10<21:46, 49.39it/s]
epoch 35500  training loss: 0.006254580803215504

 36%|███████████████████████████▍                                                 | 35562/100000 [09:12<21:41, 49.53it/s]
epoch 35600  training loss: 0.006181410979479551

 36%|███████████████████████████▍                                                 | 35662/100000 [09:14<21:36, 49.64it/s]
epoch 35700  training loss: 0.006128780543804169

 36%|███████████████████████████▌                                                 | 35762/100000 [09:16<21:36, 49.55it/s]
epoch 35800  training loss: 0.006141523830592632

 36%|███████████████████████████▌                                                 | 35858/100000 [09:18<21:35, 49.52it/s]
epoch 35900  training loss: 0.006096186116337776

 36%|███████████████████████████▋                                                 | 35958/100000 [09:20<21:34, 49.46it/s]
epoch 36000  training loss: 0.006003112532198429
epoch 36000  clean testing loss: 31.082469940185547

 36%|███████████████████████████▊                                                 | 36059/100000 [09:22<21:31, 49.52it/s]
epoch 36100  training loss: 0.005965555552393198

 36%|███████████████████████████▊                                                 | 36155/100000 [09:24<21:29, 49.53it/s]
epoch 36200  training loss: 0.005930408835411072

 36%|███████████████████████████▉                                                 | 36255/100000 [09:26<21:28, 49.46it/s]
epoch 36300  training loss: 0.005894384812563658

 36%|███████████████████████████▉                                                 | 36355/100000 [09:28<21:27, 49.45it/s]
epoch 36400  training loss: 0.0058568185195326805

 36%|████████████████████████████                                                 | 36457/100000 [09:30<21:22, 49.53it/s]
epoch 36500  training loss: 0.00582124525681138

 37%|████████████████████████████▏                                                | 36553/100000 [09:32<21:16, 49.69it/s]
epoch 36600  training loss: 0.0057825492694973946

 37%|████████████████████████████▏                                                | 36653/100000 [09:34<21:17, 49.60it/s]
epoch 36700  training loss: 0.005745982751250267

 37%|████████████████████████████▎                                                | 36753/100000 [09:36<21:19, 49.43it/s]
epoch 36800  training loss: 0.0057113757357001305

 37%|████████████████████████████▍                                                | 36855/100000 [09:38<21:10, 49.68it/s]
epoch 36900  training loss: 0.005682740360498428

 37%|████████████████████████████▍                                                | 36951/100000 [09:40<21:40, 48.48it/s]
epoch 37000  training loss: 0.005640411749482155
epoch 37000  clean testing loss: 32.23271179199219

 37%|████████████████████████████▌                                                | 37052/100000 [09:42<21:13, 49.42it/s]
epoch 37100  training loss: 0.005674792919307947

 37%|████████████████████████████▌                                                | 37147/100000 [09:44<21:07, 49.58it/s]
epoch 37200  training loss: 0.005578896030783653

 37%|████████████████████████████▋                                                | 37247/100000 [09:46<21:05, 49.59it/s]
epoch 37300  training loss: 0.005671014543622732

 37%|████████████████████████████▊                                                | 37347/100000 [09:48<21:04, 49.56it/s]
epoch 37400  training loss: 0.005541347898542881

 38%|████████████████████████████▉                                                | 37536/100000 [09:52<21:00, 49.57it/s]
epoch 37500  training loss: 0.005480325780808926

 38%|████████████████████████████▉                                                | 37636/100000 [09:54<20:58, 49.54it/s]
epoch 37600  training loss: 0.005445989780128002

 38%|█████████████████████████████                                                | 37736/100000 [09:56<21:01, 49.37it/s]
epoch 37700  training loss: 0.005520847626030445

 38%|█████████████████████████████▏                                               | 37832/100000 [09:58<20:53, 49.60it/s]
epoch 37800  training loss: 0.005383150652050972

 38%|█████████████████████████████▏                                               | 37933/100000 [10:00<20:51, 49.60it/s]
epoch 37900  training loss: 0.005493867211043835

 38%|█████████████████████████████▎                                               | 38030/100000 [10:02<20:52, 49.46it/s]
epoch 38000  training loss: 0.005322454962879419
epoch 38000  clean testing loss: 33.25139617919922

 38%|█████████████████████████████▎                                               | 38130/100000 [10:04<20:50, 49.48it/s]
epoch 38100  training loss: 0.005413800943642855

 38%|█████████████████████████████▍                                               | 38230/100000 [10:06<20:46, 49.57it/s]
epoch 38200  training loss: 0.0052674380131065845

 38%|█████████████████████████████▌                                               | 38330/100000 [10:08<20:42, 49.62it/s]
epoch 38300  training loss: 0.005242546554654837

 38%|█████████████████████████████▌                                               | 38430/100000 [10:10<20:36, 49.80it/s]
epoch 38400  training loss: 0.005212238524109125

 39%|█████████████████████████████▋                                               | 38531/100000 [10:12<20:40, 49.57it/s]
epoch 38500  training loss: 0.005194447934627533

 39%|█████████████████████████████▋                                               | 38628/100000 [10:14<20:38, 49.56it/s]
epoch 38600  training loss: 0.00515388697385788

 39%|█████████████████████████████▊                                               | 38728/100000 [10:16<20:40, 49.41it/s]
epoch 38700  training loss: 0.005140290129929781

 39%|█████████████████████████████▉                                               | 38829/100000 [10:18<20:35, 49.51it/s]
epoch 38800  training loss: 0.005328754428774118

 39%|█████████████████████████████▉                                               | 38925/100000 [10:20<20:34, 49.49it/s]
epoch 38900  training loss: 0.005073470529168844

 39%|██████████████████████████████                                               | 39028/100000 [10:22<20:39, 49.17it/s]
epoch 39000  training loss: 0.005052788183093071
epoch 39000  clean testing loss: 34.1218376159668

 39%|██████████████████████████████▏                                              | 39128/100000 [10:24<20:28, 49.55it/s]
epoch 39100  training loss: 0.005025820806622505

 39%|██████████████████████████████▏                                              | 39225/100000 [10:26<20:24, 49.62it/s]
epoch 39200  training loss: 0.005004044156521559

 39%|██████████████████████████████▎                                              | 39325/100000 [10:28<20:33, 49.20it/s]
epoch 39300  training loss: 0.00498128542676568

 39%|██████████████████████████████▎                                              | 39425/100000 [10:30<20:21, 49.58it/s]
epoch 39400  training loss: 0.004957722965627909

 40%|██████████████████████████████▍                                              | 39521/100000 [10:32<20:18, 49.62it/s]
epoch 39500  training loss: 0.004937627352774143

 40%|██████████████████████████████▌                                              | 39622/100000 [10:34<20:16, 49.63it/s]
epoch 39600  training loss: 0.0049133822321891785

 40%|██████████████████████████████▌                                              | 39722/100000 [10:36<20:15, 49.59it/s]
epoch 39700  training loss: 0.004888564348220825

 40%|██████████████████████████████▋                                              | 39820/100000 [10:38<20:13, 49.58it/s]
epoch 39800  training loss: 0.004866516683250666

 40%|██████████████████████████████▋                                              | 39920/100000 [10:40<20:11, 49.61it/s]
epoch 39900  training loss: 0.004841275047510862

 40%|██████████████████████████████▊                                              | 40021/100000 [10:42<20:23, 49.03it/s]
epoch 40000  training loss: 0.0048224348574876785
epoch 40000  clean testing loss: 34.84157943725586

 40%|██████████████████████████████▉                                              | 40121/100000 [10:44<20:08, 49.55it/s]
epoch 40100  training loss: 0.004803005140274763

 40%|██████████████████████████████▉                                              | 40221/100000 [10:46<20:04, 49.63it/s]
epoch 40200  training loss: 0.004783151671290398

 40%|███████████████████████████████                                              | 40316/100000 [10:48<20:04, 49.54it/s]
epoch 40300  training loss: 0.004751498345285654

 40%|███████████████████████████████                                              | 40416/100000 [10:50<20:03, 49.53it/s]
epoch 40400  training loss: 0.004729593172669411

 41%|███████████████████████████████▏                                             | 40519/100000 [10:52<19:53, 49.86it/s]
epoch 40500  training loss: 0.0047079105861485004

 41%|███████████████████████████████▎                                             | 40614/100000 [10:54<19:54, 49.70it/s]
epoch 40600  training loss: 0.0046908073127269745

 41%|███████████████████████████████▎                                             | 40715/100000 [10:56<19:56, 49.54it/s]
epoch 40700  training loss: 0.004668845795094967

 41%|███████████████████████████████▍                                             | 40818/100000 [10:58<19:55, 49.51it/s]
epoch 40800  training loss: 0.004650702700018883

 41%|███████████████████████████████▌                                             | 40918/100000 [11:00<19:51, 49.58it/s]
epoch 40900  training loss: 0.004623756743967533

 41%|███████████████████████████████▌                                             | 41013/100000 [11:02<20:21, 48.31it/s]
epoch 41000  training loss: 0.004648539237678051
epoch 41000  clean testing loss: 35.49089431762695

 41%|███████████████████████████████▋                                             | 41114/100000 [11:04<19:50, 49.47it/s]
epoch 41100  training loss: 0.004590645898133516

 41%|███████████████████████████████▋                                             | 41214/100000 [11:06<19:44, 49.62it/s]
epoch 41200  training loss: 0.004568979609757662

 41%|███████████████████████████████▊                                             | 41312/100000 [11:08<19:33, 50.00it/s]
epoch 41300  training loss: 0.004546414595097303

 41%|███████████████████████████████▉                                             | 41412/100000 [11:10<19:41, 49.59it/s]
epoch 41400  training loss: 0.004525289870798588

 42%|███████████████████████████████▉                                             | 41511/100000 [11:12<19:38, 49.65it/s]
epoch 41500  training loss: 0.004505526274442673

 42%|████████████████████████████████                                             | 41612/100000 [11:14<19:39, 49.51it/s]
epoch 41600  training loss: 0.004492199048399925

 42%|████████████████████████████████                                             | 41707/100000 [11:16<19:45, 49.15it/s]
epoch 41700  training loss: 0.00447194604203105

 42%|████████████████████████████████▏                                            | 41810/100000 [11:18<19:34, 49.56it/s]
epoch 41800  training loss: 0.0044502937234938145

 42%|████████████████████████████████▎                                            | 41910/100000 [11:20<19:35, 49.42it/s]
epoch 41900  training loss: 0.0045003341510891914

 42%|████████████████████████████████▎                                            | 42005/100000 [11:22<20:06, 48.09it/s]
epoch 42000  training loss: 0.004409960005432367
epoch 42000  clean testing loss: 36.063621520996094

 42%|████████████████████████████████▍                                            | 42106/100000 [11:24<19:26, 49.63it/s]
epoch 42100  training loss: 0.004394604824483395

 42%|████████████████████████████████▍                                            | 42203/100000 [11:26<19:29, 49.41it/s]
epoch 42200  training loss: 0.00437915837392211

 42%|████████████████████████████████▌                                            | 42303/100000 [11:28<19:23, 49.60it/s]
epoch 42300  training loss: 0.004362944979220629

 42%|████████████████████████████████▋                                            | 42405/100000 [11:30<19:18, 49.71it/s]
epoch 42400  training loss: 0.0043458836153149605

 43%|████████████████████████████████▋                                            | 42502/100000 [11:32<19:19, 49.61it/s]
epoch 42500  training loss: 0.004333827178925276

 43%|████████████████████████████████▊                                            | 42602/100000 [11:34<19:15, 49.66it/s]
epoch 42600  training loss: 0.004313105717301369

 43%|████████████████████████████████▉                                            | 42702/100000 [11:36<19:14, 49.64it/s]
epoch 42700  training loss: 0.004298636224120855

 43%|████████████████████████████████▉                                            | 42803/100000 [11:38<19:14, 49.55it/s]
epoch 42800  training loss: 0.004275886341929436

 43%|█████████████████████████████████                                            | 42903/100000 [11:40<19:13, 49.51it/s]
epoch 42900  training loss: 0.004258712753653526

 43%|█████████████████████████████████                                            | 43003/100000 [11:42<19:27, 48.84it/s]
epoch 43000  training loss: 0.004241907969117165
epoch 43000  clean testing loss: 36.5479621887207

 43%|█████████████████████████████████▏                                           | 43099/100000 [11:44<19:05, 49.67it/s]
epoch 43100  training loss: 0.004236980807036161

 43%|█████████████████████████████████▎                                           | 43199/100000 [11:46<19:05, 49.61it/s]
epoch 43200  training loss: 0.0042425282299518585

 43%|█████████████████████████████████▎                                           | 43299/100000 [11:48<19:05, 49.50it/s]
epoch 43300  training loss: 0.004191408399492502

 43%|█████████████████████████████████▍                                           | 43399/100000 [11:50<19:06, 49.36it/s]
epoch 43400  training loss: 0.004286961164325476

 43%|█████████████████████████████████▍                                           | 43496/100000 [11:52<19:00, 49.54it/s]
epoch 43500  training loss: 0.004182212986052036


 44%|█████████████████████████████████▋                                           | 43697/100000 [11:56<18:56, 49.53it/s]
epoch 43600  training loss: 0.004143931902945042

 44%|█████████████████████████████████▋                                           | 43795/100000 [11:58<16:51, 55.57it/s]
epoch 43700  training loss: 0.0041395085863769054
epoch 43700  clean testing loss: 36.871517181396484
epoch 43800  training loss: 0.004154824651777744

 44%|█████████████████████████████████▊                                           | 43903/100000 [12:00<18:56, 49.34it/s]
epoch 43900  training loss: 0.004105061292648315

 44%|█████████████████████████████████▉                                           | 43998/100000 [12:02<18:51, 49.51it/s]
epoch 44000  training loss: 0.004077248740941286
epoch 44000  clean testing loss: 37.00333023071289

 44%|█████████████████████████████████▉                                           | 44099/100000 [12:04<18:47, 49.57it/s]
epoch 44100  training loss: 0.004065151326358318

 44%|██████████████████████████████████                                           | 44201/100000 [12:06<18:47, 49.47it/s]
epoch 44200  training loss: 0.004045800305902958

 44%|██████████████████████████████████                                           | 44301/100000 [12:08<18:47, 49.41it/s]
epoch 44300  training loss: 0.0040299794636666775


 44%|██████████████████████████████████▎                                          | 44499/100000 [12:12<18:37, 49.65it/s]
epoch 44400  training loss: 0.004016588442027569

 45%|██████████████████████████████████▎                                          | 44600/100000 [12:14<18:37, 49.57it/s]
epoch 44500  training loss: 0.004001561552286148

 45%|██████████████████████████████████▍                                          | 44695/100000 [12:16<18:38, 49.44it/s]
epoch 44600  training loss: 0.004010451026260853

 45%|██████████████████████████████████▍                                          | 44795/100000 [12:18<18:35, 49.48it/s]
epoch 44700  training loss: 0.003980342764407396

 45%|██████████████████████████████████▌                                          | 44896/100000 [12:20<18:33, 49.48it/s]
epoch 44800  training loss: 0.003953792620450258

 45%|██████████████████████████████████▋                                          | 44996/100000 [12:22<18:31, 49.50it/s]
epoch 44900  training loss: 0.0040089464746415615

 45%|██████████████████████████████████▋                                          | 45093/100000 [12:24<18:29, 49.51it/s]
epoch 45000  training loss: 0.003952745348215103
epoch 45000  clean testing loss: 37.422664642333984

 45%|██████████████████████████████████▊                                          | 45194/100000 [12:26<18:25, 49.58it/s]
epoch 45100  training loss: 0.003911416046321392

 45%|██████████████████████████████████▊                                          | 45289/100000 [12:28<18:24, 49.52it/s]
epoch 45200  training loss: 0.003898492781445384

 45%|██████████████████████████████████▉                                          | 45395/100000 [12:31<18:17, 49.77it/s]
epoch 45300  training loss: 0.0038851394783705473

 45%|███████████████████████████████████                                          | 45492/100000 [12:32<18:14, 49.79it/s]
epoch 45400  training loss: 0.0038712327368557453

 46%|███████████████████████████████████                                          | 45593/100000 [12:35<18:17, 49.58it/s]
epoch 45500  training loss: 0.0038584202993661165

 46%|███████████████████████████████████▏                                         | 45690/100000 [12:36<18:09, 49.83it/s]
epoch 45600  training loss: 0.0038440683856606483

 46%|███████████████████████████████████▎                                         | 45790/100000 [12:39<18:13, 49.56it/s]
epoch 45700  training loss: 0.0038673721719533205

 46%|███████████████████████████████████▎                                         | 45892/100000 [12:41<18:08, 49.70it/s]
epoch 45800  training loss: 0.003814789466559887

 46%|███████████████████████████████████▍                                         | 45987/100000 [12:42<18:11, 49.50it/s]
epoch 45900  training loss: 0.003800450125709176

 46%|███████████████████████████████████▍                                         | 46089/100000 [12:45<18:06, 49.62it/s]
epoch 46000  training loss: 0.0038078059442341328
epoch 46000  clean testing loss: 37.789222717285156

 46%|███████████████████████████████████▌                                         | 46186/100000 [12:47<18:01, 49.77it/s]
epoch 46100  training loss: 0.0038262861780822277

 46%|███████████████████████████████████▌                                         | 46261/100000 [12:48<18:04, 49.55it/s]
epoch 46200  training loss: 0.0037608682177960873

 46%|███████████████████████████████████▋                                         | 46361/100000 [12:50<18:01, 49.58it/s]
epoch 46300  training loss: 0.0037445880006998777

 46%|███████████████████████████████████▊                                         | 46463/100000 [12:52<17:50, 50.01it/s]
epoch 46400  training loss: 0.0037319031544029713

 47%|███████████████████████████████████▊                                         | 46559/100000 [12:54<17:58, 49.57it/s]
epoch 46500  training loss: 0.0037258199881762266

 47%|███████████████████████████████████▉                                         | 46599/100000 [12:55<17:57, 49.55it/s]
epoch 46600  training loss: 0.0037034256383776665

 47%|███████████████████████████████████▉                                         | 46699/100000 [12:57<17:55, 49.57it/s]
epoch 46700  training loss: 0.0036909892223775387


 47%|████████████████████████████████████▍                                        | 47259/100000 [13:08<17:43, 49.59it/s]
epoch 46800  training loss: 0.003680212190374732
epoch 46800  clean testing loss: 38.07282257080078
epoch 46900  training loss: 0.003678178181871772
epoch 46900  clean testing loss: 38.10853958129883
epoch 47000  training loss: 0.0036587740760296583
epoch 47000  clean testing loss: 38.142303466796875
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 47100  training loss: 0.0036367177963256836
epoch 47100  clean testing loss: 38.1795654296875
epoch 47200  training loss: 0.0036337405908852816

 47%|████████████████████████████████████▍                                        | 47360/100000 [13:10<17:41, 49.60it/s]
epoch 47300  training loss: 0.0036124158650636673

 47%|████████████████████████████████████▌                                        | 47460/100000 [13:12<17:41, 49.49it/s]
epoch 47400  training loss: 0.003604784607887268

 48%|████████████████████████████████████▌                                        | 47558/100000 [13:14<17:35, 49.68it/s]
epoch 47500  training loss: 0.003584421006962657

 48%|████████████████████████████████████▋                                        | 47659/100000 [13:16<17:38, 49.43it/s]
epoch 47600  training loss: 0.0035735266283154488

 48%|████████████████████████████████████▊                                        | 47758/100000 [13:18<17:32, 49.65it/s]
epoch 47700  training loss: 0.0035589472390711308

 48%|████████████████████████████████████▊                                        | 47859/100000 [13:20<17:25, 49.85it/s]
epoch 47800  training loss: 0.0035558147355914116

 48%|████████████████████████████████████▉                                        | 47956/100000 [13:22<17:29, 49.59it/s]
epoch 47900  training loss: 0.0035335756838321686

 48%|█████████████████████████████████████                                        | 48057/100000 [13:24<17:28, 49.54it/s]
epoch 48000  training loss: 0.003521154634654522
epoch 48000  clean testing loss: 38.48370361328125

 48%|█████████████████████████████████████                                        | 48153/100000 [13:26<17:25, 49.61it/s]
epoch 48100  training loss: 0.0035107648000121117

 48%|█████████████████████████████████████▏                                       | 48255/100000 [13:28<17:23, 49.60it/s]
epoch 48200  training loss: 0.003500134451314807

 48%|█████████████████████████████████████▏                                       | 48356/100000 [13:30<17:21, 49.57it/s]
epoch 48300  training loss: 0.0034889942035079002

 48%|█████████████████████████████████████▎                                       | 48456/100000 [13:32<17:20, 49.54it/s]
epoch 48400  training loss: 0.0034773843362927437

 49%|█████████████████████████████████████▍                                       | 48552/100000 [13:34<17:22, 49.35it/s]
epoch 48500  training loss: 0.003466408234089613

 49%|█████████████████████████████████████▍                                       | 48652/100000 [13:36<17:17, 49.51it/s]
epoch 48600  training loss: 0.003453833982348442

 49%|█████████████████████████████████████▌                                       | 48752/100000 [13:38<17:15, 49.49it/s]
epoch 48700  training loss: 0.003441959386691451

 49%|█████████████████████████████████████▌                                       | 48852/100000 [13:40<17:01, 50.05it/s]
epoch 48800  training loss: 0.0034303823485970497

 49%|█████████████████████████████████████▋                                       | 48948/100000 [13:42<17:10, 49.55it/s]
epoch 48900  training loss: 0.0034450117964297533

 49%|█████████████████████████████████████▊                                       | 49051/100000 [13:44<17:08, 49.56it/s]
epoch 49000  training loss: 0.0034069449175149202
epoch 49000  clean testing loss: 38.79169464111328

 49%|█████████████████████████████████████▊                                       | 49151/100000 [13:46<17:06, 49.51it/s]
epoch 49100  training loss: 0.0033992340322583914

 49%|█████████████████████████████████████▉                                       | 49251/100000 [13:48<17:05, 49.48it/s]
epoch 49200  training loss: 0.0033860437106341124

 49%|█████████████████████████████████████▉                                       | 49347/100000 [13:50<17:04, 49.45it/s]
epoch 49300  training loss: 0.0033723507076501846

 49%|██████████████████████████████████████                                       | 49447/100000 [13:52<17:18, 48.68it/s]
epoch 49400  training loss: 0.003362976247444749

 50%|██████████████████████████████████████▏                                      | 49544/100000 [13:54<16:55, 49.71it/s]
epoch 49500  training loss: 0.0033499218989163637

 50%|██████████████████████████████████████▏                                      | 49644/100000 [13:56<17:00, 49.32it/s]
epoch 49600  training loss: 0.0033405444119125605

 50%|██████████████████████████████████████▎                                      | 49745/100000 [13:58<16:55, 49.50it/s]
epoch 49700  training loss: 0.003327199025079608

 50%|██████████████████████████████████████▍                                      | 49845/100000 [14:00<16:54, 49.42it/s]
epoch 49800  training loss: 0.0033162590116262436

 50%|██████████████████████████████████████▍                                      | 49942/100000 [14:02<16:48, 49.64it/s]
epoch 49900  training loss: 0.003305689198896289

 50%|██████████████████████████████████████▌                                      | 50043/100000 [14:04<16:49, 49.47it/s]
epoch 50000  training loss: 0.0032951990142464638
epoch 50000  clean testing loss: 39.104759216308594

 50%|██████████████████████████████████████▌                                      | 50143/100000 [14:06<16:45, 49.59it/s]
epoch 50100  training loss: 0.003285069949924946

 50%|██████████████████████████████████████▋                                      | 50239/100000 [14:08<16:43, 49.57it/s]
epoch 50200  training loss: 0.0032764829229563475

 50%|██████████████████████████████████████▊                                      | 50340/100000 [14:10<16:36, 49.86it/s]
epoch 50300  training loss: 0.003263484686613083

 50%|██████████████████████████████████████▊                                      | 50440/100000 [14:12<16:40, 49.54it/s]
epoch 50400  training loss: 0.0032524405978620052

 51%|██████████████████████████████████████▉                                      | 50541/100000 [14:14<16:36, 49.62it/s]
epoch 50500  training loss: 0.0032417725306004286

 51%|██████████████████████████████████████▉                                      | 50641/100000 [14:16<16:37, 49.50it/s]
epoch 50600  training loss: 0.0032312022522091866

 51%|███████████████████████████████████████                                      | 50739/100000 [14:18<16:32, 49.61it/s]
epoch 50700  training loss: 0.0032280208542943

 51%|███████████████████████████████████████▏                                     | 50839/100000 [14:20<16:32, 49.54it/s]
epoch 50800  training loss: 0.0032186475582420826

 51%|███████████████████████████████████████▏                                     | 50937/100000 [14:22<16:22, 49.92it/s]
epoch 50900  training loss: 0.0032003247179090977

 51%|███████████████████████████████████████▎                                     | 51038/100000 [14:24<16:30, 49.42it/s]
epoch 51000  training loss: 0.0031994725577533245
epoch 51000  clean testing loss: 39.402984619140625

 51%|███████████████████████████████████████▎                                     | 51134/100000 [14:26<16:45, 48.59it/s]
epoch 51100  training loss: 0.0031817781273275614

 51%|███████████████████████████████████████▍                                     | 51234/100000 [14:28<16:25, 49.48it/s]
epoch 51200  training loss: 0.0031733724754303694

 51%|███████████████████████████████████████▌                                     | 51336/100000 [14:30<16:18, 49.72it/s]
epoch 51300  training loss: 0.003164538647979498

 51%|███████████████████████████████████████▌                                     | 51437/100000 [14:32<16:15, 49.77it/s]
epoch 51400  training loss: 0.0031552051659673452

 52%|███████████████████████████████████████▋                                     | 51534/100000 [14:34<16:18, 49.56it/s]
epoch 51500  training loss: 0.0031656785868108273

 52%|███████████████████████████████████████▊                                     | 51635/100000 [14:36<16:17, 49.50it/s]
epoch 51600  training loss: 0.0031365652102977037

 52%|███████████████████████████████████████▊                                     | 51735/100000 [14:38<16:12, 49.61it/s]
epoch 51700  training loss: 0.0031274918001145124

 52%|███████████████████████████████████████▉                                     | 51835/100000 [14:40<16:12, 49.53it/s]
epoch 51800  training loss: 0.0031177522614598274

 52%|███████████████████████████████████████▉                                     | 51932/100000 [14:42<16:12, 49.44it/s]
epoch 51900  training loss: 0.0031112395226955414

 52%|████████████████████████████████████████                                     | 52029/100000 [14:44<16:09, 49.49it/s]
epoch 52000  training loss: 0.003104483475908637
epoch 52000  clean testing loss: 39.6912841796875

 52%|████████████████████████████████████████▏                                    | 52129/100000 [14:46<16:05, 49.60it/s]
epoch 52100  training loss: 0.0030982561875134706

 52%|████████████████████████████████████████▏                                    | 52229/100000 [14:48<16:06, 49.43it/s]
epoch 52200  training loss: 0.003084370866417885

 52%|████████████████████████████████████████▎                                    | 52330/100000 [14:51<16:24, 48.42it/s]
epoch 52300  training loss: 0.0030716729816049337

 52%|████████████████████████████████████████▎                                    | 52425/100000 [14:52<16:01, 49.50it/s]
epoch 52400  training loss: 0.003062623552978039

 53%|████████████████████████████████████████▍                                    | 52527/100000 [14:55<15:58, 49.50it/s]
epoch 52500  training loss: 0.003054603235796094

 53%|████████████████████████████████████████▌                                    | 52625/100000 [14:56<15:50, 49.83it/s]
epoch 52600  training loss: 0.0030456907115876675

 53%|████████████████████████████████████████▌                                    | 52715/100000 [14:58<15:53, 49.61it/s]
epoch 52700  training loss: 0.003048744285479188

 53%|████████████████████████████████████████▋                                    | 52827/100000 [15:01<15:49, 49.66it/s]
epoch 52800  training loss: 0.0030267369002103806

 53%|████████████████████████████████████████▊                                    | 52923/100000 [15:03<15:50, 49.54it/s]
epoch 52900  training loss: 0.003021979471668601

 53%|████████████████████████████████████████▊                                    | 53021/100000 [15:04<15:59, 48.98it/s]
epoch 53000  training loss: 0.003009469248354435
epoch 53000  clean testing loss: 39.98497772216797

 53%|████████████████████████████████████████▉                                    | 53123/100000 [15:07<15:44, 49.62it/s]
epoch 53100  training loss: 0.0030046175234019756

 53%|████████████████████████████████████████▉                                    | 53223/100000 [15:09<15:45, 49.49it/s]
epoch 53200  training loss: 0.002992829540744424

 53%|█████████████████████████████████████████                                    | 53318/100000 [15:11<16:05, 48.33it/s]
epoch 53300  training loss: 0.002984653227031231

 53%|█████████████████████████████████████████▏                                   | 53418/100000 [15:13<15:40, 49.54it/s]
epoch 53400  training loss: 0.002975792158395052

 54%|█████████████████████████████████████████▏                                   | 53519/100000 [15:15<15:37, 49.59it/s]
epoch 53500  training loss: 0.002969641238451004

 54%|█████████████████████████████████████████▎                                   | 53616/100000 [15:17<15:31, 49.81it/s]
epoch 53600  training loss: 0.002960030920803547

 54%|█████████████████████████████████████████▎                                   | 53716/100000 [15:19<15:36, 49.44it/s]
epoch 53700  training loss: 0.002953385468572378

 54%|█████████████████████████████████████████▍                                   | 53817/100000 [15:21<15:31, 49.55it/s]
epoch 53800  training loss: 0.0029437043704092503

 54%|█████████████████████████████████████████▌                                   | 53918/100000 [15:23<15:29, 49.56it/s]
epoch 53900  training loss: 0.002935833530500531

 54%|█████████████████████████████████████████▌                                   | 54014/100000 [15:25<15:46, 48.60it/s]
epoch 54000  training loss: 0.002927737310528755
epoch 54000  clean testing loss: 40.27567672729492

 54%|█████████████████████████████████████████▋                                   | 54115/100000 [15:27<15:27, 49.47it/s]
epoch 54100  training loss: 0.0029212881345301867

 54%|█████████████████████████████████████████▋                                   | 54215/100000 [15:29<15:42, 48.60it/s]
epoch 54200  training loss: 0.002914650598540902

 54%|█████████████████████████████████████████▊                                   | 54311/100000 [15:31<15:24, 49.43it/s]
epoch 54300  training loss: 0.002907674526795745

 54%|█████████████████████████████████████████▉                                   | 54411/100000 [15:33<15:20, 49.51it/s]
epoch 54400  training loss: 0.002900445833802223

 55%|█████████████████████████████████████████▉                                   | 54512/100000 [15:35<15:33, 48.70it/s]
epoch 54500  training loss: 0.00289356242865324

 55%|██████████████████████████████████████████                                   | 54608/100000 [15:37<15:19, 49.37it/s]
epoch 54600  training loss: 0.0028856804128736258

 55%|██████████████████████████████████████████▏                                  | 54708/100000 [15:39<15:15, 49.48it/s]
epoch 54700  training loss: 0.0028828876093029976

 55%|██████████████████████████████████████████▏                                  | 54808/100000 [15:41<15:14, 49.41it/s]
epoch 54800  training loss: 0.002871451433748007

 55%|██████████████████████████████████████████▎                                  | 54911/100000 [15:43<15:10, 49.53it/s]
epoch 54900  training loss: 0.0028640637174248695

 55%|██████████████████████████████████████████▎                                  | 55006/100000 [15:45<15:41, 47.77it/s]
epoch 55000  training loss: 0.0028588594868779182
epoch 55000  clean testing loss: 40.55174255371094

 55%|██████████████████████████████████████████▍                                  | 55109/100000 [15:47<15:07, 49.49it/s]
epoch 55100  training loss: 0.0028497406747192144

 55%|██████████████████████████████████████████▌                                  | 55209/100000 [15:49<15:05, 49.46it/s]
epoch 55200  training loss: 0.0028426102362573147

 55%|██████████████████████████████████████████▌                                  | 55304/100000 [15:51<15:05, 49.35it/s]
epoch 55300  training loss: 0.0028356730472296476

 55%|██████████████████████████████████████████▋                                  | 55406/100000 [15:53<15:00, 49.54it/s]
epoch 55400  training loss: 0.002828786848112941

 56%|██████████████████████████████████████████▋                                  | 55505/100000 [15:55<14:52, 49.85it/s]
epoch 55500  training loss: 0.002827366115525365

 56%|██████████████████████████████████████████▊                                  | 55602/100000 [15:57<14:55, 49.58it/s]
epoch 55600  training loss: 0.002816164866089821

 56%|██████████████████████████████████████████▉                                  | 55702/100000 [15:59<14:54, 49.52it/s]
epoch 55700  training loss: 0.002809781115502119

 56%|██████████████████████████████████████████▉                                  | 55802/100000 [16:01<14:54, 49.43it/s]
epoch 55800  training loss: 0.0028022252954542637

 56%|███████████████████████████████████████████                                  | 55903/100000 [16:03<14:48, 49.63it/s]
epoch 55900  training loss: 0.002796007553115487

 56%|███████████████████████████████████████████                                  | 56003/100000 [16:05<15:15, 48.04it/s]
epoch 56000  training loss: 0.002796376356855035

 56%|███████████████████████████████████████████▏                                 | 56099/100000 [16:07<14:47, 49.47it/s]

 56%|███████████████████████████████████████████▎                                 | 56200/100000 [16:09<14:40, 49.73it/s]
epoch 56100  training loss: 0.0027837955858558416

 56%|███████████████████████████████████████████▍                                 | 56375/100000 [16:12<14:40, 49.53it/s]
epoch 56200  training loss: 0.0027768868021667004
epoch 56200  clean testing loss: 40.896305084228516
epoch 56300  training loss: 0.002770110499113798
epoch 56300  clean testing loss: 40.924434661865234
epoch 56400  training loss: 0.0027656753081828356

 56%|███████████████████████████████████████████▍                                 | 56473/100000 [16:14<14:31, 49.92it/s]
epoch 56500  training loss: 0.002757701789960265

 57%|███████████████████████████████████████████▌                                 | 56573/100000 [16:16<14:35, 49.62it/s]
epoch 56600  training loss: 0.0027515594847500324

 57%|███████████████████████████████████████████▌                                 | 56596/100000 [16:17<14:28, 49.98it/s]
epoch 56700  training loss: 0.002745342440903187
epoch 56700  clean testing loss: 41.03826141357422
epoch 56800  training loss: 0.0027427137829363346


 57%|███████████████████████████████████████████▊                                 | 56929/100000 [16:26<14:30, 49.46it/s]
epoch 56900  training loss: 0.0027329984586685896

 57%|███████████████████████████████████████████▉                                 | 57027/100000 [16:28<14:04, 50.89it/s]
epoch 57000  training loss: 0.0027269197162240744
epoch 57000  clean testing loss: 41.123260498046875

 57%|███████████████████████████████████████████▉                                 | 57129/100000 [16:30<14:23, 49.62it/s]
epoch 57100  training loss: 0.002722089411690831

 57%|████████████████████████████████████████████                                 | 57230/100000 [16:32<14:23, 49.56it/s]
epoch 57200  training loss: 0.002717071445658803

 57%|████████████████████████████████████████████▏                                | 57330/100000 [16:34<14:19, 49.65it/s]
epoch 57300  training loss: 0.00271169887855649

 57%|████████████████████████████████████████████▏                                | 57426/100000 [16:36<14:14, 49.84it/s]
epoch 57400  training loss: 0.0027063461020588875

 58%|████████████████████████████████████████████▎                                | 57527/100000 [16:38<14:16, 49.56it/s]
epoch 57500  training loss: 0.0027010999619960785

 58%|████████████████████████████████████████████▎                                | 57627/100000 [16:40<14:14, 49.56it/s]
epoch 57600  training loss: 0.002695554168894887

 58%|████████████████████████████████████████████▍                                | 57727/100000 [16:42<14:13, 49.53it/s]
epoch 57700  training loss: 0.0026898044161498547

 58%|████████████████████████████████████████████▌                                | 57827/100000 [16:44<14:12, 49.45it/s]
epoch 57800  training loss: 0.002684260718524456

 58%|████████████████████████████████████████████▌                                | 57927/100000 [16:46<14:04, 49.81it/s]
epoch 57900  training loss: 0.002679289784282446

 58%|████████████████████████████████████████████▋                                | 58024/100000 [16:48<14:08, 49.47it/s]
epoch 58000  training loss: 0.0026734780985862017
epoch 58000  clean testing loss: 41.3922119140625

 58%|████████████████████████████████████████████▊                                | 58125/100000 [16:50<14:04, 49.60it/s]
epoch 58100  training loss: 0.002668035449460149

 58%|████████████████████████████████████████████▊                                | 58226/100000 [16:52<14:02, 49.59it/s]
epoch 58200  training loss: 0.0026671444065868855

 58%|████████████████████████████████████████████▉                                | 58321/100000 [16:54<14:00, 49.61it/s]
epoch 58300  training loss: 0.002657538978382945

 58%|████████████████████████████████████████████▉                                | 58421/100000 [16:56<14:04, 49.21it/s]
epoch 58400  training loss: 0.0026554171927273273

 59%|█████████████████████████████████████████████                                | 58520/100000 [16:58<13:59, 49.42it/s]
epoch 58500  training loss: 0.0026469470467418432

 59%|█████████████████████████████████████████████▏                               | 58620/100000 [17:00<13:53, 49.65it/s]
epoch 58600  training loss: 0.002641925122588873

 59%|█████████████████████████████████████████████▏                               | 58721/100000 [17:02<13:47, 49.86it/s]
epoch 58700  training loss: 0.002636868506669998

 59%|█████████████████████████████████████████████▎                               | 58817/100000 [17:04<13:49, 49.63it/s]
epoch 58800  training loss: 0.0026371681597083807

 59%|█████████████████████████████████████████████▎                               | 58920/100000 [17:06<14:02, 48.79it/s]
epoch 58900  training loss: 0.0026267084758728743

 59%|█████████████████████████████████████████████▍                               | 59016/100000 [17:08<14:01, 48.68it/s]
epoch 59000  training loss: 0.002621836494654417
epoch 59000  clean testing loss: 41.67539978027344

 59%|█████████████████████████████████████████████▌                               | 59119/100000 [17:10<13:35, 50.16it/s]
epoch 59100  training loss: 0.002620275830850005

 59%|█████████████████████████████████████████████▌                               | 59214/100000 [17:12<13:42, 49.57it/s]
epoch 59200  training loss: 0.0026125465519726276

 59%|█████████████████████████████████████████████▋                               | 59314/100000 [17:14<13:40, 49.56it/s]
epoch 59300  training loss: 0.002610741415992379

 59%|█████████████████████████████████████████████▊                               | 59416/100000 [17:16<13:39, 49.53it/s]
epoch 59400  training loss: 0.0026024538092315197

 60%|█████████████████████████████████████████████▊                               | 59517/100000 [17:18<13:38, 49.47it/s]
epoch 59500  training loss: 0.0025984272360801697

 60%|█████████████████████████████████████████████▉                               | 59612/100000 [17:20<13:35, 49.51it/s]
epoch 59600  training loss: 0.0025930264964699745

 60%|█████████████████████████████████████████████▉                               | 59712/100000 [17:22<13:34, 49.45it/s]
epoch 59700  training loss: 0.0025918795727193356

 60%|██████████████████████████████████████████████                               | 59815/100000 [17:24<13:30, 49.60it/s]
epoch 59800  training loss: 0.0025843745097517967

 60%|██████████████████████████████████████████████▏                              | 59911/100000 [17:26<13:29, 49.55it/s]
epoch 59900  training loss: 0.0025792857632040977

 60%|██████████████████████████████████████████████▏                              | 60014/100000 [17:28<13:41, 48.65it/s]
epoch 60000  training loss: 0.0025751881767064333
epoch 60000  clean testing loss: 41.955501556396484


 60%|██████████████████████████████████████████████▎                              | 60211/100000 [17:32<13:24, 49.43it/s]
epoch 60100  training loss: 0.002570984186604619
epoch 60100  clean testing loss: 41.97861099243164
epoch 60200  training loss: 0.002567201154306531

 60%|██████████████████████████████████████████████▍                              | 60313/100000 [17:34<13:20, 49.58it/s]
epoch 60300  training loss: 0.002563286107033491

 60%|██████████████████████████████████████████████▌                              | 60408/100000 [17:36<13:19, 49.55it/s]
epoch 60400  training loss: 0.002559094689786434

 61%|██████████████████████████████████████████████▌                              | 60510/100000 [17:38<13:16, 49.56it/s]
epoch 60500  training loss: 0.0025549419224262238

 61%|██████████████████████████████████████████████▋                              | 60611/100000 [17:40<13:13, 49.62it/s]
epoch 60600  training loss: 0.0025525158271193504

 61%|██████████████████████████████████████████████▋                              | 60711/100000 [17:42<13:12, 49.59it/s]
epoch 60700  training loss: 0.0025479523465037346

 61%|██████████████████████████████████████████████▊                              | 60806/100000 [17:44<13:10, 49.60it/s]
epoch 60800  training loss: 0.002542229602113366
epoch 60800  clean testing loss: 42.16389083862305
epoch 60900  training loss: 0.002538382075726986

 61%|██████████████████████████████████████████████▉                              | 60925/100000 [17:46<11:05, 58.75it/s]
epoch 61000  training loss: 0.0025339291896671057
epoch 61000  clean testing loss: 42.21952819824219

 61%|███████████████████████████████████████████████                              | 61040/100000 [17:48<10:59, 59.11it/s]
epoch 61100  training loss: 0.0025297568645328283

 61%|███████████████████████████████████████████████                              | 61161/100000 [17:50<10:57, 59.06it/s]
epoch 61200  training loss: 0.002527686534449458

 61%|███████████████████████████████████████████████▏                             | 61281/100000 [17:52<10:56, 58.98it/s]
epoch 61300  training loss: 0.002521533751860261

 61%|███████████████████████████████████████████████▎                             | 61396/100000 [17:54<10:53, 59.05it/s]
epoch 61400  training loss: 0.002519682515412569

 62%|███████████████████████████████████████████████▎                             | 61517/100000 [17:56<10:50, 59.16it/s]
epoch 61500  training loss: 0.002514009829610586
epoch 61500  clean testing loss: 42.35895538330078
epoch 61600  training loss: 0.0025095578748732805

 62%|███████████████████████████████████████████████▍                             | 61637/100000 [17:58<10:48, 59.17it/s]
epoch 61700  training loss: 0.002507265657186508

 62%|███████████████████████████████████████████████▌                             | 61751/100000 [18:00<10:49, 58.89it/s]
epoch 61800  training loss: 0.0025016749277710915

 62%|███████████████████████████████████████████████▋                             | 61872/100000 [18:02<10:43, 59.28it/s]
epoch 61900  training loss: 0.002500145463272929

 62%|███████████████████████████████████████████████▋                             | 61986/100000 [18:04<10:45, 58.89it/s]
epoch 62000  training loss: 0.002493951003998518
epoch 62000  clean testing loss: 42.496986389160156

 62%|███████████████████████████████████████████████▊                             | 62107/100000 [18:06<10:40, 59.19it/s]
epoch 62100  training loss: 0.0024916999973356724
epoch 62100  clean testing loss: 42.52633285522461
epoch 62200  training loss: 0.0024863858707249165

 62%|███████████████████████████████████████████████▉                             | 62227/100000 [18:08<10:40, 59.00it/s]
epoch 62300  training loss: 0.0024829122703522444

 62%|████████████████████████████████████████████████                             | 62341/100000 [18:10<10:38, 58.94it/s]
epoch 62400  training loss: 0.0024790321476757526

 62%|████████████████████████████████████████████████                             | 62463/100000 [18:12<10:27, 59.85it/s]
epoch 62500  training loss: 0.002475689398124814

 63%|████████████████████████████████████████████████▏                            | 62579/100000 [18:14<10:34, 59.00it/s]
epoch 62600  training loss: 0.0024716309271752834

 63%|████████████████████████████████████████████████▎                            | 62699/100000 [18:16<10:33, 58.84it/s]
epoch 62700  training loss: 0.002468025777488947

 63%|████████████████████████████████████████████████▎                            | 62819/100000 [18:18<10:31, 58.87it/s]
epoch 62800  training loss: 0.00246601365506649
epoch 62800  clean testing loss: 42.71897888183594
epoch 62900  training loss: 0.0024609938263893127

 63%|████████████████████████████████████████████████▍                            | 62934/100000 [18:20<10:29, 58.90it/s]
epoch 63000  training loss: 0.002457084832713008
epoch 63000  clean testing loss: 42.77241516113281

 63%|████████████████████████████████████████████████▌                            | 63054/100000 [18:22<10:30, 58.64it/s]
epoch 63100  training loss: 0.0024540855083614588

 63%|████████████████████████████████████████████████▋                            | 63169/100000 [18:24<10:24, 58.95it/s]
epoch 63200  training loss: 0.002451168140396476

 63%|████████████████████████████████████████████████▋                            | 63289/100000 [18:26<10:18, 59.32it/s]
epoch 63300  training loss: 0.002447916194796562

 63%|████████████████████████████████████████████████▊                            | 63409/100000 [18:28<10:21, 58.86it/s]
epoch 63400  training loss: 0.0024446824099868536
epoch 63400  clean testing loss: 42.86922836303711
epoch 63500  training loss: 0.0024417471140623093

 64%|████████████████████████████████████████████████▉                            | 63524/100000 [18:30<10:19, 58.89it/s]
epoch 63600  training loss: 0.0024382874835282564

 64%|█████████████████████████████████████████████████                            | 63644/100000 [18:32<10:17, 58.89it/s]
epoch 63700  training loss: 0.0024361058603972197

 64%|█████████████████████████████████████████████████                            | 63764/100000 [18:34<10:13, 59.11it/s]
epoch 63800  training loss: 0.002431562403216958

 64%|█████████████████████████████████████████████████▏                           | 63879/100000 [18:36<10:13, 58.88it/s]
epoch 63900  training loss: 0.0024292138405144215

 64%|█████████████████████████████████████████████████▎                           | 63999/100000 [18:38<10:12, 58.79it/s]
epoch 64000  training loss: 0.002425204496830702
epoch 64000  clean testing loss: 43.03147506713867

 64%|█████████████████████████████████████████████████▎                           | 64120/100000 [18:40<10:09, 58.90it/s]
epoch 64100  training loss: 0.002422397257760167
epoch 64100  clean testing loss: 43.05915069580078
epoch 64200  training loss: 0.002418599557131529

 64%|█████████████████████████████████████████████████▍                           | 64205/100000 [18:42<10:03, 59.31it/s]
epoch 64300  training loss: 0.002417283831164241

 64%|█████████████████████████████████████████████████▌                           | 64325/100000 [18:44<10:04, 59.03it/s]
epoch 64400  training loss: 0.00241206050850451

 64%|█████████████████████████████████████████████████▌                           | 64445/100000 [18:46<10:01, 59.08it/s]
epoch 64500  training loss: 0.002408707747235894

 65%|█████████████████████████████████████████████████▋                           | 64561/100000 [18:48<10:00, 59.04it/s]
epoch 64600  training loss: 0.002405742648988962

 65%|█████████████████████████████████████████████████▊                           | 64682/100000 [18:50<09:58, 59.05it/s]
epoch 64700  training loss: 0.002402480226010084
epoch 64700  clean testing loss: 43.22181701660156
epoch 64800  training loss: 0.0023992368951439857

 65%|█████████████████████████████████████████████████▉                           | 64802/100000 [18:52<09:55, 59.09it/s]
epoch 64900  training loss: 0.0023963169660419226

 65%|█████████████████████████████████████████████████▉                           | 64918/100000 [18:54<09:56, 58.81it/s]
epoch 65000  training loss: 0.0023932026233524084
epoch 65000  clean testing loss: 43.301734924316406

 65%|██████████████████████████████████████████████████                           | 65038/100000 [18:56<09:55, 58.72it/s]
epoch 65100  training loss: 0.0023918210063129663

 65%|██████████████████████████████████████████████████▏                          | 65154/100000 [18:58<09:49, 59.08it/s]
epoch 65200  training loss: 0.002387942746281624

 65%|██████████████████████████████████████████████████▎                          | 65275/100000 [19:00<09:49, 58.91it/s]
epoch 65300  training loss: 0.0023840030189603567

 65%|██████████████████████████████████████████████████▎                          | 65390/100000 [19:02<09:46, 58.99it/s]
epoch 65400  training loss: 0.0023809175472706556
epoch 65400  clean testing loss: 43.40898513793945
epoch 65500  training loss: 0.0023780108895152807

 66%|██████████████████████████████████████████████████▍                          | 65511/100000 [19:04<09:44, 59.05it/s]
epoch 65600  training loss: 0.0023762371856719255

 66%|██████████████████████████████████████████████████▌                          | 65625/100000 [19:06<09:43, 58.96it/s]
epoch 65700  training loss: 0.0023720557801425457

 66%|██████████████████████████████████████████████████▌                          | 65745/100000 [19:08<09:39, 59.12it/s]
epoch 65800  training loss: 0.0023694403935223818

 66%|██████████████████████████████████████████████████▋                          | 65866/100000 [19:10<09:37, 59.07it/s]
epoch 65900  training loss: 0.0023681269958615303

 66%|██████████████████████████████████████████████████▊                          | 65980/100000 [19:12<09:36, 59.02it/s]
epoch 66000  training loss: 0.0023637828417122364
epoch 66000  clean testing loss: 43.568790435791016
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 66100  training loss: 0.002360908780246973

 66%|██████████████████████████████████████████████████▉                          | 66101/100000 [19:14<09:34, 58.97it/s]
epoch 66200  training loss: 0.002358528785407543

 66%|██████████████████████████████████████████████████▉                          | 66221/100000 [19:16<09:32, 58.97it/s]
epoch 66300  training loss: 0.002355976030230522

 66%|███████████████████████████████████████████████████                          | 66335/100000 [19:18<09:31, 58.88it/s]
epoch 66400  training loss: 0.0023533389903604984

 66%|███████████████████████████████████████████████████▏                         | 66455/100000 [19:20<09:29, 58.95it/s]
epoch 66500  training loss: 0.0023518246598541737

 67%|███████████████████████████████████████████████████▎                         | 66575/100000 [19:22<09:24, 59.22it/s]
epoch 66600  training loss: 0.0023482106626033783

 67%|███████████████████████████████████████████████████▎                         | 66695/100000 [19:24<09:24, 59.03it/s]
epoch 66700  training loss: 0.0023451726883649826
epoch 66700  clean testing loss: 43.740203857421875
epoch 66800  training loss: 0.0023425172548741102

 67%|███████████████████████████████████████████████████▍                         | 66809/100000 [19:26<09:23, 58.87it/s]
epoch 66900  training loss: 0.0023400792852044106

 67%|███████████████████████████████████████████████████▌                         | 66930/100000 [19:28<09:21, 58.87it/s]
epoch 67000  training loss: 0.002337158191949129
epoch 67000  clean testing loss: 43.81840896606445

 67%|███████████████████████████████████████████████████▌                         | 67045/100000 [19:30<09:20, 58.82it/s]
epoch 67100  training loss: 0.002334508579224348

 67%|███████████████████████████████████████████████████▋                         | 67166/100000 [19:32<09:13, 59.34it/s]
epoch 67200  training loss: 0.0023325502406805754

 67%|███████████████████████████████████████████████████▊                         | 67286/100000 [19:34<09:14, 58.97it/s]
epoch 67300  training loss: 0.0023303446359932423
epoch 67300  clean testing loss: 43.89829635620117
epoch 67400  training loss: 0.002327027963474393

 67%|███████████████████████████████████████████████████▉                         | 67406/100000 [19:36<09:13, 58.90it/s]
epoch 67500  training loss: 0.0023238970898091793

 68%|███████████████████████████████████████████████████▉                         | 67521/100000 [19:38<09:11, 58.93it/s]
epoch 67600  training loss: 0.0023216954432427883

 68%|████████████████████████████████████████████████████                         | 67642/100000 [19:40<09:08, 59.01it/s]
epoch 67700  training loss: 0.002318853512406349

 68%|████████████████████████████████████████████████████▏                        | 67756/100000 [19:42<09:06, 58.98it/s]
epoch 67800  training loss: 0.0023162257857620716

 68%|████████████████████████████████████████████████████▎                        | 67878/100000 [19:44<09:04, 59.04it/s]
epoch 67900  training loss: 0.0023138716351240873

 68%|████████████████████████████████████████████████████▎                        | 67998/100000 [19:46<09:03, 58.89it/s]
epoch 68000  training loss: 0.0023119107354432344
epoch 68000  clean testing loss: 44.07747268676758
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise7.00e-01_invop1 ...
epoch 68100  training loss: 0.0023086064029484987

 68%|████████████████████████████████████████████████████▍                        | 68112/100000 [19:48<09:01, 58.92it/s]
epoch 68200  training loss: 0.0023060578387230635

 68%|████████████████████████████████████████████████████▌                        | 68232/100000 [19:50<09:00, 58.79it/s]
epoch 68300  training loss: 0.0023036336060613394

 68%|████████████████████████████████████████████████████▋                        | 68352/100000 [19:52<08:57, 58.89it/s]
epoch 68400  training loss: 0.002301723463460803

 68%|████████████████████████████████████████████████████▋                        | 68466/100000 [19:54<08:56, 58.73it/s]
epoch 68500  training loss: 0.002299244049936533

 69%|████████████████████████████████████████████████████▊                        | 68587/100000 [19:56<08:52, 59.01it/s]
epoch 68600  training loss: 0.0022963332012295723

 69%|████████████████████████████████████████████████████▉                        | 68707/100000 [19:58<08:51, 58.89it/s]
epoch 68700  training loss: 0.002294831909239292
epoch 68700  clean testing loss: 44.25906753540039
epoch 68800  training loss: 0.0022914723958820105

 69%|████████████████████████████████████████████████████▉                        | 68821/100000 [20:00<08:49, 58.93it/s]
epoch 68900  training loss: 0.0022891254629939795
epoch 68900  clean testing loss: 44.3087043762207
Validation loss variation < 1e-6, trained to interpolation, stop

 69%|█████████████████████████████████████████████████████                        | 68900/100000 [20:01<09:02, 57.33it/s]