
  1%|          | 985/100000 [00:02<03:11, 517.17it/s]
epoch 0  training loss: 1.5763006210327148
epoch 0  clean testing loss: 0.45126873254776
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 100  training loss: 1.1955987215042114
epoch 100  clean testing loss: 0.12370601296424866
epoch 200  training loss: 1.1256272792816162
epoch 200  clean testing loss: 0.08132746070623398
epoch 300  training loss: 1.0981011390686035
epoch 300  clean testing loss: 0.0694466382265091
epoch 400  training loss: 1.0696035623550415
epoch 400  clean testing loss: 0.0640808716416359
epoch 500  training loss: 1.0485079288482666
epoch 500  clean testing loss: 0.06472963094711304
epoch 600  training loss: 1.033249020576477
epoch 600  clean testing loss: 0.06630588322877884
epoch 700  training loss: 1.0207867622375488

  2%|▏         | 1926/100000 [00:03<03:16, 499.95it/s]
epoch 800  training loss: 1.0096970796585083
epoch 800  clean testing loss: 0.07213309407234192
epoch 900  training loss: 0.9995257258415222
epoch 900  clean testing loss: 0.07511061429977417
epoch 1000  training loss: 0.9892758131027222
epoch 1000  clean testing loss: 0.07865261286497116
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 1100  training loss: 0.9786806702613831
epoch 1100  clean testing loss: 0.08340945839881897
epoch 1200  training loss: 0.9686287641525269
epoch 1200  clean testing loss: 0.08885068446397781
epoch 1300  training loss: 0.9585681557655334
epoch 1300  clean testing loss: 0.09456624835729599
epoch 1400  training loss: 0.9485651254653931
epoch 1400  clean testing loss: 0.09883483499288559
epoch 1500  training loss: 0.939385175704956
epoch 1500  clean testing loss: 0.10470044612884521
epoch 1600  training loss: 0.9294471740722656
epoch 1600  clean testing loss: 0.11059913039207458
epoch 1700  training loss: 0.9204166531562805

  3%|▎         | 2975/100000 [00:06<03:06, 519.59it/s]
epoch 1800  training loss: 0.910622239112854
epoch 1800  clean testing loss: 0.12058307230472565
epoch 1900  training loss: 0.9017521142959595
epoch 1900  clean testing loss: 0.1276179552078247
epoch 2000  training loss: 0.8911790251731873
epoch 2000  clean testing loss: 0.13226161897182465
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 2100  training loss: 0.8821538686752319
epoch 2100  clean testing loss: 0.13454660773277283
epoch 2200  training loss: 0.8721980452537537
epoch 2200  clean testing loss: 0.13983234763145447
epoch 2300  training loss: 0.8631421327590942
epoch 2300  clean testing loss: 0.1444191336631775
epoch 2400  training loss: 0.8547981977462769
epoch 2400  clean testing loss: 0.14587678015232086
epoch 2500  training loss: 0.8453261256217957
epoch 2500  clean testing loss: 0.1540355533361435
epoch 2600  training loss: 0.8356582522392273
epoch 2600  clean testing loss: 0.1527373492717743
epoch 2700  training loss: 0.8265613317489624

  3%|▎         | 3394/100000 [00:06<03:06, 516.90it/s]
epoch 2800  training loss: 0.8164130449295044
epoch 2800  clean testing loss: 0.1610296070575714
epoch 2900  training loss: 0.8072001934051514
epoch 2900  clean testing loss: 0.1711146980524063
epoch 3000  training loss: 0.7959613800048828
epoch 3000  clean testing loss: 0.17042596638202667
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 3100  training loss: 0.787613034248352
epoch 3100  clean testing loss: 0.17523722350597382
epoch 3200  training loss: 0.779341995716095
epoch 3200  clean testing loss: 0.17846499383449554
epoch 3300  training loss: 0.7706312537193298
epoch 3300  clean testing loss: 0.18596071004867554
epoch 3400  training loss: 0.7634925246238708

  4%|▍         | 3972/100000 [00:11<04:22, 365.21it/s]
epoch 3500  training loss: 0.7563443183898926
epoch 3500  clean testing loss: 0.19213877618312836
epoch 3600  training loss: 0.7470768094062805
epoch 3600  clean testing loss: 0.20126138627529144
epoch 3700  training loss: 0.7396660447120667
epoch 3700  clean testing loss: 0.20375357568264008
epoch 3800  training loss: 0.7329205870628357
epoch 3800  clean testing loss: 0.2091187834739685
epoch 3900  training loss: 0.7268800139427185
epoch 3900  clean testing loss: 0.22199584543704987
epoch 4000  training loss: 0.7183459401130676
epoch 4000  clean testing loss: 0.22138740122318268

  5%|▍         | 4972/100000 [00:13<03:03, 518.36it/s]
epoch 4100  training loss: 0.7119643688201904
epoch 4100  clean testing loss: 0.2299489825963974
epoch 4200  training loss: 0.7067935466766357
epoch 4200  clean testing loss: 0.23729108273983002
epoch 4300  training loss: 0.6997768878936768
epoch 4300  clean testing loss: 0.2385198175907135
epoch 4400  training loss: 0.6958750486373901
epoch 4400  clean testing loss: 0.24305184185504913
epoch 4500  training loss: 0.6877280473709106
epoch 4500  clean testing loss: 0.2521122992038727
epoch 4600  training loss: 0.682077169418335
epoch 4600  clean testing loss: 0.2579641044139862
epoch 4700  training loss: 0.6750194430351257
epoch 4700  clean testing loss: 0.26521238684654236
epoch 4800  training loss: 0.6713061928749084
epoch 4800  clean testing loss: 0.27104127407073975
epoch 4900  training loss: 0.6639038324356079
epoch 4900  clean testing loss: 0.27952370047569275
epoch 5000  training loss: 0.6615957617759705
epoch 5000  clean testing loss: 0.291378378868103

  5%|▌         | 5286/100000 [00:14<03:03, 515.95it/s]
epoch 5100  training loss: 0.6541390419006348
epoch 5100  clean testing loss: 0.28807157278060913
epoch 5200  training loss: 0.6495165824890137
epoch 5200  clean testing loss: 0.2936464846134186
epoch 5300  training loss: 0.6448628306388855

  6%|▋         | 6275/100000 [00:20<03:05, 504.91it/s]
epoch 5400  training loss: 0.6412929892539978
epoch 5400  clean testing loss: 0.30023816227912903
epoch 5500  training loss: 0.6389067769050598
epoch 5500  clean testing loss: 0.30328086018562317
epoch 5600  training loss: 0.6333351135253906
epoch 5600  clean testing loss: 0.30863669514656067
epoch 5700  training loss: 0.627897322177887
epoch 5700  clean testing loss: 0.31582561135292053
epoch 5800  training loss: 0.6239585280418396
epoch 5800  clean testing loss: 0.3208959996700287
epoch 5900  training loss: 0.6195511817932129
epoch 5900  clean testing loss: 0.3315320611000061
epoch 6000  training loss: 0.6179910898208618
epoch 6000  clean testing loss: 0.3414391577243805
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 6100  training loss: 0.6117354035377502
epoch 6100  clean testing loss: 0.3408551514148712
epoch 6200  training loss: 0.608468770980835
epoch 6200  clean testing loss: 0.3471139073371887
epoch 6300  training loss: 0.6052612066268921

  7%|▋         | 7271/100000 [00:22<02:58, 518.78it/s]
epoch 6400  training loss: 0.6045357584953308
epoch 6400  clean testing loss: 0.36180150508880615
epoch 6500  training loss: 0.6005831360816956
epoch 6500  clean testing loss: 0.36402472853660583
epoch 6600  training loss: 0.5979213118553162
epoch 6600  clean testing loss: 0.368732213973999
epoch 6700  training loss: 0.5952555537223816
epoch 6700  clean testing loss: 0.3750196695327759
epoch 6800  training loss: 0.5901285409927368
epoch 6800  clean testing loss: 0.3724849224090576
epoch 6900  training loss: 0.5871699452400208
epoch 6900  clean testing loss: 0.3714742660522461
epoch 7000  training loss: 0.584221601486206
epoch 7000  clean testing loss: 0.3761679232120514
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 7100  training loss: 0.5817621350288391
epoch 7100  clean testing loss: 0.3787829279899597
epoch 7200  training loss: 0.5789309144020081
epoch 7200  clean testing loss: 0.3829764723777771
epoch 7300  training loss: 0.5787380933761597

  8%|▊         | 8319/100000 [00:24<02:58, 513.00it/s]
epoch 7400  training loss: 0.5762978196144104
epoch 7400  clean testing loss: 0.38673707842826843
epoch 7500  training loss: 0.571778416633606
epoch 7500  clean testing loss: 0.39146241545677185
epoch 7600  training loss: 0.571516752243042
epoch 7600  clean testing loss: 0.39388811588287354
epoch 7700  training loss: 0.5672743916511536
epoch 7700  clean testing loss: 0.3999745547771454
epoch 7800  training loss: 0.5640771389007568
epoch 7800  clean testing loss: 0.4047147333621979
epoch 7900  training loss: 0.5623213052749634
epoch 7900  clean testing loss: 0.4066019356250763
epoch 8000  training loss: 0.5662961602210999
epoch 8000  clean testing loss: 0.4125937819480896
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 8100  training loss: 0.5573018789291382
epoch 8100  clean testing loss: 0.4238731861114502
epoch 8200  training loss: 0.5564767122268677
epoch 8200  clean testing loss: 0.419369637966156
epoch 8300  training loss: 0.5538973212242126

  9%|▉         | 9305/100000 [00:26<02:58, 509.13it/s]
epoch 8400  training loss: 0.5513095855712891
epoch 8400  clean testing loss: 0.4270573854446411
epoch 8500  training loss: 0.550563395023346
epoch 8500  clean testing loss: 0.42829629778862
epoch 8600  training loss: 0.548456609249115
epoch 8600  clean testing loss: 0.43077802658081055
epoch 8700  training loss: 0.5477955341339111
epoch 8700  clean testing loss: 0.4328528642654419
epoch 8800  training loss: 0.5460038185119629
epoch 8800  clean testing loss: 0.4356444180011749
epoch 8900  training loss: 0.543849527835846
epoch 8900  clean testing loss: 0.4392114281654358
epoch 9000  training loss: 0.5401703119277954
epoch 9000  clean testing loss: 0.44347408413887024
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 9100  training loss: 0.5370311737060547
epoch 9100  clean testing loss: 0.4493955671787262
epoch 9200  training loss: 0.535598635673523
epoch 9200  clean testing loss: 0.45059943199157715
epoch 9300  training loss: 0.5340442061424255

 10%|█         | 10355/100000 [00:28<02:53, 515.30it/s]
epoch 9400  training loss: 0.5323783755302429
epoch 9400  clean testing loss: 0.45777007937431335
epoch 9500  training loss: 0.5326130390167236
epoch 9500  clean testing loss: 0.45591115951538086
epoch 9600  training loss: 0.5287690758705139
epoch 9600  clean testing loss: 0.46386900544166565
epoch 9700  training loss: 0.5281199216842651
epoch 9700  clean testing loss: 0.4731113910675049
epoch 9800  training loss: 0.5253155827522278
epoch 9800  clean testing loss: 0.4691724479198456
epoch 9900  training loss: 0.52458256483078
epoch 9900  clean testing loss: 0.47603824734687805
epoch 10000  training loss: 0.5225210189819336
epoch 10000  clean testing loss: 0.47644031047821045
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 10100  training loss: 0.520423173904419
epoch 10100  clean testing loss: 0.4773898422718048
epoch 10200  training loss: 0.518620491027832
epoch 10200  clean testing loss: 0.47572940587997437
epoch 10300  training loss: 0.5166470408439636

 11%|█▏        | 11347/100000 [00:30<02:51, 516.34it/s]
epoch 10400  training loss: 0.5154463052749634
epoch 10400  clean testing loss: 0.48804789781570435
epoch 10500  training loss: 0.5148341059684753
epoch 10500  clean testing loss: 0.493950217962265
epoch 10600  training loss: 0.5138897895812988
epoch 10600  clean testing loss: 0.4973903000354767
epoch 10700  training loss: 0.5109720826148987
epoch 10700  clean testing loss: 0.4973090589046478
epoch 10800  training loss: 0.5101251602172852
epoch 10800  clean testing loss: 0.5021279454231262
epoch 10900  training loss: 0.5079728960990906
epoch 10900  clean testing loss: 0.5028707385063171
epoch 11000  training loss: 0.5065836310386658
epoch 11000  clean testing loss: 0.5049129128456116
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 11100  training loss: 0.5051699876785278
epoch 11100  clean testing loss: 0.49972769618034363
epoch 11200  training loss: 0.503069281578064
epoch 11200  clean testing loss: 0.5061420202255249
epoch 11300  training loss: 0.5021259188652039
epoch 11300  clean testing loss: 0.5053144097328186
epoch 11400  training loss: 0.5011352300643921

 12%|█▏        | 12401/100000 [00:32<02:49, 516.94it/s]
epoch 11500  training loss: 0.5018272399902344
epoch 11500  clean testing loss: 0.5068830251693726
epoch 11600  training loss: 0.49967160820961
epoch 11600  clean testing loss: 0.510104238986969
epoch 11700  training loss: 0.4983035922050476
epoch 11700  clean testing loss: 0.511224091053009
epoch 11800  training loss: 0.4971964955329895
epoch 11800  clean testing loss: 0.5135114789009094
epoch 11900  training loss: 0.49574726819992065
epoch 11900  clean testing loss: 0.5165860652923584
epoch 12000  training loss: 0.49400052428245544
epoch 12000  clean testing loss: 0.5194149613380432
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 12100  training loss: 0.4912025034427643
epoch 12100  clean testing loss: 0.5235722661018372
epoch 12200  training loss: 0.4902167022228241
epoch 12200  clean testing loss: 0.5271212458610535
epoch 12300  training loss: 0.4890213906764984
epoch 12300  clean testing loss: 0.5270271301269531
epoch 12400  training loss: 0.48838454484939575

 13%|█▎        | 13247/100000 [00:33<02:48, 514.64it/s]
epoch 12500  training loss: 0.48691806197166443
epoch 12500  clean testing loss: 0.5334749221801758
epoch 12600  training loss: 0.48588302731513977
epoch 12600  clean testing loss: 0.531830370426178
epoch 12700  training loss: 0.4852769374847412
epoch 12700  clean testing loss: 0.5332521200180054
epoch 12800  training loss: 0.4833109378814697
epoch 12800  clean testing loss: 0.5392987728118896
epoch 12900  training loss: 0.4824484586715698
epoch 12900  clean testing loss: 0.5442078113555908
epoch 13000  training loss: 0.48218628764152527
epoch 13000  clean testing loss: 0.5493374466896057
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 13100  training loss: 0.4818650186061859
epoch 13100  clean testing loss: 0.5521842837333679
epoch 13200  training loss: 0.480797678232193
epoch 13200  clean testing loss: 0.5552259087562561
epoch 13300  training loss: 0.47823289036750793

 14%|█▍        | 14254/100000 [00:40<11:28, 124.60it/s]
epoch 13400  training loss: 0.4768768548965454
epoch 13400  clean testing loss: 0.5509375333786011
epoch 13500  training loss: 0.47576943039894104
epoch 13500  clean testing loss: 0.5526633858680725
epoch 13600  training loss: 0.47460082173347473
epoch 13600  clean testing loss: 0.5564579367637634
epoch 13700  training loss: 0.47370901703834534
epoch 13700  clean testing loss: 0.5601563453674316
epoch 13800  training loss: 0.47301149368286133
epoch 13800  clean testing loss: 0.564013659954071
epoch 13900  training loss: 0.47172871232032776
epoch 13900  clean testing loss: 0.5651464462280273
epoch 14000  training loss: 0.4706161618232727
epoch 14000  clean testing loss: 0.563648521900177
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 14100  training loss: 0.4714532792568207
epoch 14100  clean testing loss: 0.5736788511276245
epoch 14200  training loss: 0.4685255289077759
epoch 14200  clean testing loss: 0.5677400231361389
epoch 14300  training loss: 0.46851328015327454

 15%|█▌        | 15297/100000 [00:42<02:43, 516.50it/s]
epoch 14400  training loss: 0.4672147333621979
epoch 14400  clean testing loss: 0.5741709470748901
epoch 14500  training loss: 0.4654531478881836
epoch 14500  clean testing loss: 0.5727519392967224
epoch 14600  training loss: 0.4655855894088745
epoch 14600  clean testing loss: 0.5794620513916016
epoch 14700  training loss: 0.4654183089733124
epoch 14700  clean testing loss: 0.585130512714386
epoch 14800  training loss: 0.4626539349555969
epoch 14800  clean testing loss: 0.5825521945953369
epoch 14900  training loss: 0.46266722679138184
epoch 14900  clean testing loss: 0.5881311297416687
epoch 15000  training loss: 0.4624019265174866
epoch 15000  clean testing loss: 0.5877678990364075
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 15100  training loss: 0.45976248383522034
epoch 15100  clean testing loss: 0.5856630206108093
epoch 15200  training loss: 0.4590570330619812
epoch 15200  clean testing loss: 0.5889987945556641
epoch 15300  training loss: 0.4584929943084717

 16%|█▋        | 16293/100000 [00:44<02:41, 518.01it/s]
epoch 15400  training loss: 0.4573969841003418
epoch 15400  clean testing loss: 0.5919293761253357
epoch 15500  training loss: 0.4576730728149414
epoch 15500  clean testing loss: 0.5904214382171631
epoch 15600  training loss: 0.4568948447704315
epoch 15600  clean testing loss: 0.5931832790374756
epoch 15700  training loss: 0.45530807971954346
epoch 15700  clean testing loss: 0.5962139368057251
epoch 15800  training loss: 0.4550764858722687
epoch 15800  clean testing loss: 0.6060320138931274
epoch 15900  training loss: 0.4533003270626068
epoch 15900  clean testing loss: 0.6019326448440552
epoch 16000  training loss: 0.45286211371421814
epoch 16000  clean testing loss: 0.6023402214050293
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 16100  training loss: 0.452957421541214
epoch 16100  clean testing loss: 0.6030392646789551
epoch 16200  training loss: 0.45207226276397705
epoch 16200  clean testing loss: 0.6124955415725708
epoch 16300  training loss: 0.45069918036460876

 17%|█▋        | 17342/100000 [00:46<02:40, 515.92it/s]
epoch 16400  training loss: 0.4499441087245941
epoch 16400  clean testing loss: 0.6086410284042358
epoch 16500  training loss: 0.44946813583374023
epoch 16500  clean testing loss: 0.609191358089447
epoch 16600  training loss: 0.4488803446292877
epoch 16600  clean testing loss: 0.6113324165344238
epoch 16700  training loss: 0.4471237361431122
epoch 16700  clean testing loss: 0.6194220185279846
epoch 16800  training loss: 0.44641023874282837
epoch 16800  clean testing loss: 0.6164530515670776
epoch 16900  training loss: 0.4453918933868408
epoch 16900  clean testing loss: 0.6196005344390869
epoch 17000  training loss: 0.444873183965683
epoch 17000  clean testing loss: 0.6204177737236023
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 17100  training loss: 0.44384145736694336
epoch 17100  clean testing loss: 0.6223575472831726
epoch 17200  training loss: 0.44326502084732056
epoch 17200  clean testing loss: 0.625810980796814
epoch 17300  training loss: 0.44229447841644287

 18%|█▊        | 18393/100000 [00:48<02:37, 519.70it/s]
epoch 17400  training loss: 0.44185054302215576
epoch 17400  clean testing loss: 0.6272934675216675
epoch 17500  training loss: 0.4415508508682251
epoch 17500  clean testing loss: 0.6286360025405884
epoch 17600  training loss: 0.4404011368751526
epoch 17600  clean testing loss: 0.6313802599906921
epoch 17700  training loss: 0.43928414583206177
epoch 17700  clean testing loss: 0.6349421143531799
epoch 17800  training loss: 0.43853768706321716
epoch 17800  clean testing loss: 0.637833297252655
epoch 17900  training loss: 0.43822863698005676
epoch 17900  clean testing loss: 0.6417397856712341
epoch 18000  training loss: 0.4374098479747772
epoch 18000  clean testing loss: 0.6382807493209839
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 18100  training loss: 0.43638452887535095
epoch 18100  clean testing loss: 0.6421334743499756
epoch 18200  training loss: 0.435588002204895
epoch 18200  clean testing loss: 0.6430960893630981
epoch 18300  training loss: 0.43500256538391113
epoch 18300  clean testing loss: 0.6466706991195679
epoch 18400  training loss: 0.43402528762817383

 19%|█▉        | 19388/100000 [00:50<02:35, 518.22it/s]
epoch 18500  training loss: 0.43252137303352356
epoch 18500  clean testing loss: 0.6479854583740234
epoch 18600  training loss: 0.4319150447845459
epoch 18600  clean testing loss: 0.6505494713783264
epoch 18700  training loss: 0.4317544102668762
epoch 18700  clean testing loss: 0.648758053779602
epoch 18800  training loss: 0.4308411478996277
epoch 18800  clean testing loss: 0.6508194804191589
epoch 18900  training loss: 0.42984479665756226
epoch 18900  clean testing loss: 0.6526886224746704
epoch 19000  training loss: 0.42987462878227234
epoch 19000  clean testing loss: 0.6528831720352173
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 19100  training loss: 0.4288792014122009
epoch 19100  clean testing loss: 0.6551339626312256
epoch 19200  training loss: 0.42853814363479614
epoch 19200  clean testing loss: 0.6633862853050232
epoch 19300  training loss: 0.4271065294742584
epoch 19300  clean testing loss: 0.6586251854896545
epoch 19400  training loss: 0.42730990052223206

 20%|██        | 20433/100000 [00:52<02:34, 514.76it/s]
epoch 19500  training loss: 0.42580968141555786
epoch 19500  clean testing loss: 0.6644030809402466
epoch 19600  training loss: 0.425957053899765
epoch 19600  clean testing loss: 0.6691220998764038
epoch 19700  training loss: 0.4246616065502167
epoch 19700  clean testing loss: 0.6638090014457703
epoch 19800  training loss: 0.4248892366886139
epoch 19800  clean testing loss: 0.6639702916145325
epoch 19900  training loss: 0.42328789830207825
epoch 19900  clean testing loss: 0.6702622771263123
epoch 20000  training loss: 0.4225802719593048
epoch 20000  clean testing loss: 0.6705381870269775
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 20100  training loss: 0.4234025776386261
epoch 20100  clean testing loss: 0.6687827110290527
epoch 20200  training loss: 0.42207539081573486
epoch 20200  clean testing loss: 0.6766781210899353
epoch 20300  training loss: 0.4207262396812439
epoch 20300  clean testing loss: 0.6751306653022766
epoch 20400  training loss: 0.4204530119895935

 21%|██        | 21064/100000 [00:53<02:33, 512.64it/s]
epoch 20500  training loss: 0.4206635355949402
epoch 20500  clean testing loss: 0.6827371716499329
epoch 20600  training loss: 0.418994277715683
epoch 20600  clean testing loss: 0.6791490912437439
epoch 20700  training loss: 0.41858944296836853
epoch 20700  clean testing loss: 0.6792412400245667
epoch 20800  training loss: 0.4185259938240051
epoch 20800  clean testing loss: 0.6797082424163818
epoch 20900  training loss: 0.4183178246021271
epoch 20900  clean testing loss: 0.6806279420852661
epoch 21000  training loss: 0.4178244173526764
epoch 21000  clean testing loss: 0.6826683282852173
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 21100  training loss: 0.41621097922325134

 21%|██▏       | 21323/100000 [00:58<13:30, 97.05it/s]
epoch 21200  training loss: 0.41575363278388977
epoch 21200  clean testing loss: 0.6883847713470459
epoch 21300  training loss: 0.4152747392654419
epoch 21300  clean testing loss: 0.6887279152870178
epoch 21400  training loss: 0.4151723086833954

 22%|██▏       | 22263/100000 [00:59<02:31, 512.03it/s]
epoch 21500  training loss: 0.41426199674606323
epoch 21500  clean testing loss: 0.6922736167907715
epoch 21600  training loss: 0.4138651490211487
epoch 21600  clean testing loss: 0.691791296005249
epoch 21700  training loss: 0.4136463403701782
epoch 21700  clean testing loss: 0.6981490850448608
epoch 21800  training loss: 0.4128209948539734
epoch 21800  clean testing loss: 0.6944374442100525
epoch 21900  training loss: 0.4122300148010254
epoch 21900  clean testing loss: 0.6976746916770935
epoch 22000  training loss: 0.41223669052124023
epoch 22000  clean testing loss: 0.6960886716842651
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 22100  training loss: 0.4116665720939636
epoch 22100  clean testing loss: 0.702886164188385
epoch 22200  training loss: 0.4113732576370239
epoch 22200  clean testing loss: 0.6993862390518188
epoch 22300  training loss: 0.4106714129447937

 23%|██▎       | 23254/100000 [01:08<02:34, 496.94it/s]
epoch 22400  training loss: 0.4097684919834137
epoch 22400  clean testing loss: 0.7052193880081177
epoch 22500  training loss: 0.4098096191883087
epoch 22500  clean testing loss: 0.7100732922554016
epoch 22600  training loss: 0.40896132588386536
epoch 22600  clean testing loss: 0.706325113773346
epoch 22700  training loss: 0.40893203020095825
epoch 22700  clean testing loss: 0.7134281396865845
epoch 22800  training loss: 0.407681405544281
epoch 22800  clean testing loss: 0.7123313546180725
epoch 22900  training loss: 0.4075321853160858
epoch 22900  clean testing loss: 0.7095792293548584
epoch 23000  training loss: 0.40668100118637085
epoch 23000  clean testing loss: 0.713162899017334
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 23100  training loss: 0.4061495065689087
epoch 23100  clean testing loss: 0.715719997882843
epoch 23200  training loss: 0.406052827835083
epoch 23200  clean testing loss: 0.7195304036140442
epoch 23300  training loss: 0.4058382213115692

 24%|██▍       | 24306/100000 [01:10<02:26, 515.54it/s]
epoch 23400  training loss: 0.4046294093132019
epoch 23400  clean testing loss: 0.7174985408782959
epoch 23500  training loss: 0.4041389524936676
epoch 23500  clean testing loss: 0.7205720543861389
epoch 23600  training loss: 0.4041420519351959
epoch 23600  clean testing loss: 0.7185961008071899
epoch 23700  training loss: 0.40334343910217285
epoch 23700  clean testing loss: 0.7231727838516235
epoch 23800  training loss: 0.4028454124927521
epoch 23800  clean testing loss: 0.7221521735191345
epoch 23900  training loss: 0.402417927980423
epoch 23900  clean testing loss: 0.722869336605072
epoch 24000  training loss: 0.4017340838909149
epoch 24000  clean testing loss: 0.7257539629936218
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 24100  training loss: 0.40122872591018677
epoch 24100  clean testing loss: 0.727716863155365
epoch 24200  training loss: 0.4008306860923767
epoch 24200  clean testing loss: 0.7285309433937073
epoch 24300  training loss: 0.4004059135913849

 25%|██▍       | 24991/100000 [01:11<02:24, 519.28it/s]
epoch 24400  training loss: 0.4002675414085388
epoch 24400  clean testing loss: 0.7303430438041687
epoch 24500  training loss: 0.3995712697505951
epoch 24500  clean testing loss: 0.7327985167503357
epoch 24600  training loss: 0.3994770348072052
epoch 24600  clean testing loss: 0.7361205220222473
epoch 24700  training loss: 0.3988121449947357
epoch 24700  clean testing loss: 0.7348148226737976
epoch 24800  training loss: 0.3988654911518097
epoch 24800  clean testing loss: 0.7400002479553223
epoch 24900  training loss: 0.39823397994041443
epoch 24900  clean testing loss: 0.7413966655731201
epoch 25000  training loss: 0.39752504229545593

 25%|██▌       | 25201/100000 [01:14<07:59, 156.00it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 25100  training loss: 0.3975487947463989
epoch 25100  clean testing loss: 0.7447836995124817
epoch 25200  training loss: 0.396721214056015

 26%|██▌       | 26246/100000 [01:16<02:23, 513.19it/s]
epoch 25300  training loss: 0.3966352641582489
epoch 25300  clean testing loss: 0.7424183487892151
epoch 25400  training loss: 0.39584311842918396
epoch 25400  clean testing loss: 0.7459145784378052
epoch 25500  training loss: 0.39549413323402405
epoch 25500  clean testing loss: 0.7454625368118286
epoch 25600  training loss: 0.3950745463371277
epoch 25600  clean testing loss: 0.7470238208770752
epoch 25700  training loss: 0.394517183303833
epoch 25700  clean testing loss: 0.7487539649009705
epoch 25800  training loss: 0.39437007904052734
epoch 25800  clean testing loss: 0.7521892786026001
epoch 25900  training loss: 0.3939271867275238
epoch 25900  clean testing loss: 0.7527992725372314
epoch 26000  training loss: 0.39345571398735046
epoch 26000  clean testing loss: 0.7509779930114746
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 26100  training loss: 0.3932933211326599
epoch 26100  clean testing loss: 0.7568984627723694
epoch 26200  training loss: 0.39252522587776184

 27%|██▋       | 27239/100000 [01:18<02:21, 513.81it/s]
epoch 26300  training loss: 0.39219900965690613
epoch 26300  clean testing loss: 0.7555714845657349
epoch 26400  training loss: 0.39191123843193054
epoch 26400  clean testing loss: 0.7585805654525757
epoch 26500  training loss: 0.3919121325016022
epoch 26500  clean testing loss: 0.7622319459915161
epoch 26600  training loss: 0.39111506938934326
epoch 26600  clean testing loss: 0.7601340413093567
epoch 26700  training loss: 0.39052486419677734
epoch 26700  clean testing loss: 0.7605175375938416
epoch 26800  training loss: 0.3901676833629608
epoch 26800  clean testing loss: 0.7629634141921997
epoch 26900  training loss: 0.38991037011146545
epoch 26900  clean testing loss: 0.7615253329277039
epoch 27000  training loss: 0.38995686173439026
epoch 27000  clean testing loss: 0.7627370953559875
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 27100  training loss: 0.38901373744010925
epoch 27100  clean testing loss: 0.7656759023666382
epoch 27200  training loss: 0.3887190520763397
epoch 27200  clean testing loss: 0.7667162418365479
epoch 27300  training loss: 0.3883977234363556

 28%|██▊       | 28289/100000 [01:20<02:18, 518.38it/s]
epoch 27400  training loss: 0.38805124163627625
epoch 27400  clean testing loss: 0.7694764137268066
epoch 27500  training loss: 0.387693852186203
epoch 27500  clean testing loss: 0.76938796043396
epoch 27600  training loss: 0.38735389709472656
epoch 27600  clean testing loss: 0.7707109451293945
epoch 27700  training loss: 0.3872379958629608
epoch 27700  clean testing loss: 0.7745586037635803
epoch 27800  training loss: 0.38663244247436523
epoch 27800  clean testing loss: 0.7727770209312439
epoch 27900  training loss: 0.3866358697414398
epoch 27900  clean testing loss: 0.7765477895736694
epoch 28000  training loss: 0.38608357310295105
epoch 28000  clean testing loss: 0.7778364419937134
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 28100  training loss: 0.3856520354747772
epoch 28100  clean testing loss: 0.776021420955658
epoch 28200  training loss: 0.3854152262210846
epoch 28200  clean testing loss: 0.776228666305542
epoch 28300  training loss: 0.3851573169231415

 29%|██▉       | 29337/100000 [01:22<02:17, 514.80it/s]
epoch 28400  training loss: 0.3847709000110626
epoch 28400  clean testing loss: 0.7812467813491821
epoch 28500  training loss: 0.3843388855457306
epoch 28500  clean testing loss: 0.7814267873764038
epoch 28600  training loss: 0.38396456837654114
epoch 28600  clean testing loss: 0.7836315035820007
epoch 28700  training loss: 0.3836904764175415
epoch 28700  clean testing loss: 0.7848697304725647
epoch 28800  training loss: 0.3833186626434326
epoch 28800  clean testing loss: 0.7826289534568787
epoch 28900  training loss: 0.3831869661808014
epoch 28900  clean testing loss: 0.787312924861908
epoch 29000  training loss: 0.3828451633453369
epoch 29000  clean testing loss: 0.7841758728027344
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 29100  training loss: 0.38217633962631226
epoch 29100  clean testing loss: 0.7864961624145508
epoch 29200  training loss: 0.38208651542663574
epoch 29200  clean testing loss: 0.7862128019332886
epoch 29300  training loss: 0.3812386095523834

 30%|███       | 30331/100000 [01:24<02:15, 514.16it/s]
epoch 29400  training loss: 0.3811093866825104
epoch 29400  clean testing loss: 0.7910718321800232
epoch 29500  training loss: 0.3803524076938629
epoch 29500  clean testing loss: 0.7910172343254089
epoch 29600  training loss: 0.3800883889198303
epoch 29600  clean testing loss: 0.7911338210105896
epoch 29700  training loss: 0.37961632013320923
epoch 29700  clean testing loss: 0.7935945391654968
epoch 29800  training loss: 0.379672110080719
epoch 29800  clean testing loss: 0.7927725911140442
epoch 29900  training loss: 0.37908124923706055
epoch 29900  clean testing loss: 0.7980893850326538
epoch 30000  training loss: 0.3788696825504303
epoch 30000  clean testing loss: 0.7963705062866211
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 30100  training loss: 0.3783188760280609
epoch 30100  clean testing loss: 0.7979279160499573
epoch 30200  training loss: 0.3780668079853058
epoch 30200  clean testing loss: 0.7985963225364685
epoch 30300  training loss: 0.3778133690357208
epoch 30300  clean testing loss: 0.8007276654243469
epoch 30400  training loss: 0.37754151225090027

 31%|███       | 30541/100000 [01:24<02:16, 509.80it/s]
epoch 30500  training loss: 0.3772194981575012

 31%|███       | 30646/100000 [01:28<24:42, 46.80it/s]
epoch 30600  training loss: 0.37682175636291504
epoch 30600  clean testing loss: 0.8026655316352844
epoch 30700  training loss: 0.3765178322792053

 32%|███▏      | 31692/100000 [01:30<02:12, 515.11it/s]
epoch 30800  training loss: 0.3763652741909027
epoch 30800  clean testing loss: 0.8068692684173584
epoch 30900  training loss: 0.3759438097476959
epoch 30900  clean testing loss: 0.8071134090423584
epoch 31000  training loss: 0.37592869997024536
epoch 31000  clean testing loss: 0.8101017475128174
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 31100  training loss: 0.3754862844944
epoch 31100  clean testing loss: 0.8073846697807312
epoch 31200  training loss: 0.3751780390739441
epoch 31200  clean testing loss: 0.8085742592811584
epoch 31300  training loss: 0.37473583221435547
epoch 31300  clean testing loss: 0.8108813166618347
epoch 31400  training loss: 0.37463894486427307
epoch 31400  clean testing loss: 0.8132783770561218
epoch 31500  training loss: 0.3742111325263977
epoch 31500  clean testing loss: 0.8127007484436035
epoch 31600  training loss: 0.37400686740875244
epoch 31600  clean testing loss: 0.8131243586540222
epoch 31700  training loss: 0.37322676181793213

 33%|███▎      | 32738/100000 [01:32<02:10, 516.25it/s]
epoch 31800  training loss: 0.3727555274963379
epoch 31800  clean testing loss: 0.8186706900596619
epoch 31900  training loss: 0.3720470666885376
epoch 31900  clean testing loss: 0.820058286190033
epoch 32000  training loss: 0.37175893783569336
epoch 32000  clean testing loss: 0.8225614428520203
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 32100  training loss: 0.371584415435791
epoch 32100  clean testing loss: 0.8215881586074829
epoch 32200  training loss: 0.3710549771785736
epoch 32200  clean testing loss: 0.8229421377182007
epoch 32300  training loss: 0.3709859251976013
epoch 32300  clean testing loss: 0.8236373066902161
epoch 32400  training loss: 0.3703954815864563
epoch 32400  clean testing loss: 0.8261229395866394
epoch 32500  training loss: 0.37010109424591064
epoch 32500  clean testing loss: 0.8270970582962036
epoch 32600  training loss: 0.3698999285697937
epoch 32600  clean testing loss: 0.8271013498306274
epoch 32700  training loss: 0.3694477081298828

 34%|███▎      | 33738/100000 [01:34<02:08, 516.32it/s]
epoch 32800  training loss: 0.36914026737213135
epoch 32800  clean testing loss: 0.8304833173751831
epoch 32900  training loss: 0.3690706491470337
epoch 32900  clean testing loss: 0.829765796661377
epoch 33000  training loss: 0.3685029447078705
epoch 33000  clean testing loss: 0.8323192596435547
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 33100  training loss: 0.3682238757610321
epoch 33100  clean testing loss: 0.8334695100784302
epoch 33200  training loss: 0.3680006265640259
epoch 33200  clean testing loss: 0.8336473107337952
epoch 33300  training loss: 0.36778461933135986
epoch 33300  clean testing loss: 0.8343484401702881
epoch 33400  training loss: 0.3674784004688263
epoch 33400  clean testing loss: 0.8349967002868652
epoch 33500  training loss: 0.36732351779937744
epoch 33500  clean testing loss: 0.8353633880615234
epoch 33600  training loss: 0.367025762796402
epoch 33600  clean testing loss: 0.8368066549301147
epoch 33700  training loss: 0.3667761981487274
epoch 33700  clean testing loss: 0.837815523147583
epoch 33800  training loss: 0.36645394563674927

 35%|███▍      | 34791/100000 [01:36<02:05, 520.30it/s]
epoch 33900  training loss: 0.36614614725112915
epoch 33900  clean testing loss: 0.8410143256187439
epoch 34000  training loss: 0.36588427424430847
epoch 34000  clean testing loss: 0.8416754603385925
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 34100  training loss: 0.3657037317752838
epoch 34100  clean testing loss: 0.8415884971618652
epoch 34200  training loss: 0.3653435707092285
epoch 34200  clean testing loss: 0.8433712124824524
epoch 34300  training loss: 0.36516833305358887
epoch 34300  clean testing loss: 0.8464328050613403
epoch 34400  training loss: 0.364807665348053
epoch 34400  clean testing loss: 0.8454557657241821
epoch 34500  training loss: 0.364714115858078
epoch 34500  clean testing loss: 0.8484359383583069
epoch 34600  training loss: 0.36441612243652344
epoch 34600  clean testing loss: 0.8464527726173401
epoch 34700  training loss: 0.3641743063926697
epoch 34700  clean testing loss: 0.84745192527771
epoch 34800  training loss: 0.3637697696685791

 36%|███▌      | 35684/100000 [01:37<02:04, 517.70it/s]
epoch 34900  training loss: 0.36361488699913025
epoch 34900  clean testing loss: 0.8498152494430542
epoch 35000  training loss: 0.3634512424468994
epoch 35000  clean testing loss: 0.8507012128829956
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 35100  training loss: 0.3632124662399292
epoch 35100  clean testing loss: 0.8518096208572388
epoch 35200  training loss: 0.36288440227508545
epoch 35200  clean testing loss: 0.8555024862289429
epoch 35300  training loss: 0.362529993057251
epoch 35300  clean testing loss: 0.8552905917167664
epoch 35400  training loss: 0.36243146657943726
epoch 35400  clean testing loss: 0.8572170734405518
epoch 35500  training loss: 0.36217859387397766
epoch 35500  clean testing loss: 0.8557586669921875
epoch 35600  training loss: 0.3617420792579651
epoch 35600  clean testing loss: 0.8590501546859741
epoch 35700  training loss: 0.36150655150413513

 37%|███▋      | 36786/100000 [01:50<02:05, 505.43it/s]
epoch 35800  training loss: 0.3611856997013092
epoch 35800  clean testing loss: 0.8604764342308044
epoch 35900  training loss: 0.3609621226787567
epoch 35900  clean testing loss: 0.8608315587043762
epoch 36000  training loss: 0.36068007349967957
epoch 36000  clean testing loss: 0.8621191382408142
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 36100  training loss: 0.360468327999115
epoch 36100  clean testing loss: 0.8628805875778198
epoch 36200  training loss: 0.36025241017341614
epoch 36200  clean testing loss: 0.8637191653251648
epoch 36300  training loss: 0.3600665330886841
epoch 36300  clean testing loss: 0.8641226291656494
epoch 36400  training loss: 0.359910786151886
epoch 36400  clean testing loss: 0.8648251891136169
epoch 36500  training loss: 0.3597163259983063
epoch 36500  clean testing loss: 0.86714106798172
epoch 36600  training loss: 0.35938912630081177
epoch 36600  clean testing loss: 0.8667885065078735
epoch 36700  training loss: 0.3591975271701813
epoch 36700  clean testing loss: 0.8674749135971069
epoch 36800  training loss: 0.35907018184661865

 38%|███▊      | 37781/100000 [01:52<02:00, 517.27it/s]
epoch 36900  training loss: 0.358794629573822
epoch 36900  clean testing loss: 0.8691417574882507
epoch 37000  training loss: 0.3584959805011749
epoch 37000  clean testing loss: 0.8709346055984497
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 37100  training loss: 0.3582763671875
epoch 37100  clean testing loss: 0.8714032173156738
epoch 37200  training loss: 0.3580529987812042
epoch 37200  clean testing loss: 0.8736211061477661
epoch 37300  training loss: 0.3578258752822876
epoch 37300  clean testing loss: 0.8732028603553772
epoch 37400  training loss: 0.357718288898468
epoch 37400  clean testing loss: 0.8734425902366638
epoch 37500  training loss: 0.35744282603263855
epoch 37500  clean testing loss: 0.8767317533493042
epoch 37600  training loss: 0.3571213483810425
epoch 37600  clean testing loss: 0.8761630058288574
epoch 37700  training loss: 0.3570058047771454
epoch 37700  clean testing loss: 0.8785991072654724
epoch 37800  training loss: 0.35665062069892883

 39%|███▉      | 38833/100000 [01:54<01:59, 511.50it/s]
epoch 37900  training loss: 0.356404572725296
epoch 37900  clean testing loss: 0.8793267011642456
epoch 38000  training loss: 0.3562476634979248
epoch 38000  clean testing loss: 0.8794209361076355
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 38100  training loss: 0.3559628427028656
epoch 38100  clean testing loss: 0.8807929754257202
epoch 38200  training loss: 0.3557737469673157
epoch 38200  clean testing loss: 0.8811138272285461
epoch 38300  training loss: 0.35557666420936584
epoch 38300  clean testing loss: 0.8816652297973633
epoch 38400  training loss: 0.3553069531917572
epoch 38400  clean testing loss: 0.883120059967041
epoch 38500  training loss: 0.3551253378391266
epoch 38500  clean testing loss: 0.8836413621902466
epoch 38600  training loss: 0.35488495230674744
epoch 38600  clean testing loss: 0.886191725730896
epoch 38700  training loss: 0.35463911294937134
epoch 38700  clean testing loss: 0.8862107396125793
epoch 38800  training loss: 0.3544318377971649

 40%|███▉      | 39824/100000 [01:56<01:57, 513.02it/s]
epoch 38900  training loss: 0.35424086451530457
epoch 38900  clean testing loss: 0.886986494064331
epoch 39000  training loss: 0.3539920151233673
epoch 39000  clean testing loss: 0.888956606388092
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 39100  training loss: 0.3537958860397339
epoch 39100  clean testing loss: 0.8891439437866211
epoch 39200  training loss: 0.35361412167549133
epoch 39200  clean testing loss: 0.8904392123222351
epoch 39300  training loss: 0.35345879197120667
epoch 39300  clean testing loss: 0.8914226293563843
epoch 39400  training loss: 0.35323745012283325
epoch 39400  clean testing loss: 0.8913483023643494
epoch 39500  training loss: 0.3530493378639221
epoch 39500  clean testing loss: 0.8924447298049927
epoch 39600  training loss: 0.352851003408432
epoch 39600  clean testing loss: 0.8937880992889404
epoch 39700  training loss: 0.3526494801044464
epoch 39700  clean testing loss: 0.8943091034889221
epoch 39800  training loss: 0.3524707853794098

 41%|████      | 40817/100000 [01:58<01:55, 513.67it/s]
epoch 39900  training loss: 0.35225239396095276
epoch 39900  clean testing loss: 0.8958689570426941
epoch 40000  training loss: 0.35205763578414917
epoch 40000  clean testing loss: 0.8964827060699463
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 40100  training loss: 0.3519118130207062
epoch 40100  clean testing loss: 0.8983275890350342
epoch 40200  training loss: 0.35169002413749695
epoch 40200  clean testing loss: 0.8975774645805359
epoch 40300  training loss: 0.35145825147628784
epoch 40300  clean testing loss: 0.8991435766220093
epoch 40400  training loss: 0.35130536556243896
epoch 40400  clean testing loss: 0.8995692133903503
epoch 40500  training loss: 0.35108962655067444
epoch 40500  clean testing loss: 0.9009215235710144
epoch 40600  training loss: 0.35088691115379333
epoch 40600  clean testing loss: 0.901003360748291
epoch 40700  training loss: 0.35067370533943176
epoch 40700  clean testing loss: 0.9022959470748901
epoch 40800  training loss: 0.3504856824874878

 42%|████▏     | 41865/100000 [02:00<01:52, 517.87it/s]
epoch 40900  training loss: 0.35029271245002747
epoch 40900  clean testing loss: 0.9042918682098389
epoch 41000  training loss: 0.35007545351982117
epoch 41000  clean testing loss: 0.9053428769111633
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 41100  training loss: 0.349905401468277
epoch 41100  clean testing loss: 0.905646800994873
epoch 41200  training loss: 0.34975525736808777
epoch 41200  clean testing loss: 0.906026303768158
epoch 41300  training loss: 0.34959179162979126
epoch 41300  clean testing loss: 0.9088255167007446
epoch 41400  training loss: 0.34936434030532837
epoch 41400  clean testing loss: 0.9077020883560181
epoch 41500  training loss: 0.3491601049900055
epoch 41500  clean testing loss: 0.9099113941192627
epoch 41600  training loss: 0.34895455837249756
epoch 41600  clean testing loss: 0.9096317291259766
epoch 41700  training loss: 0.3488229811191559
epoch 41700  clean testing loss: 0.9096024632453918
epoch 41800  training loss: 0.3485739231109619
epoch 41800  clean testing loss: 0.9121489524841309
epoch 41900  training loss: 0.3483380377292633

 43%|████▎     | 42913/100000 [02:02<01:50, 514.76it/s]
epoch 42000  training loss: 0.3481680452823639
epoch 42000  clean testing loss: 0.9126286506652832
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 42100  training loss: 0.3479529023170471
epoch 42100  clean testing loss: 0.9137346744537354
epoch 42200  training loss: 0.34780219197273254
epoch 42200  clean testing loss: 0.9146986603736877
epoch 42300  training loss: 0.347646564245224
epoch 42300  clean testing loss: 0.914743959903717
epoch 42400  training loss: 0.347488135099411
epoch 42400  clean testing loss: 0.9153459668159485
epoch 42500  training loss: 0.3473047614097595
epoch 42500  clean testing loss: 0.9161868095397949
epoch 42600  training loss: 0.3471139967441559
epoch 42600  clean testing loss: 0.917626142501831
epoch 42700  training loss: 0.3469592332839966
epoch 42700  clean testing loss: 0.9176481366157532
epoch 42800  training loss: 0.3468122184276581
epoch 42800  clean testing loss: 0.9181720018386841
epoch 42900  training loss: 0.34664514660835266

 44%|████▍     | 43911/100000 [02:04<01:48, 514.96it/s]
epoch 43000  training loss: 0.3464646637439728
epoch 43000  clean testing loss: 0.9196290969848633
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 43100  training loss: 0.346237450838089
epoch 43100  clean testing loss: 0.9208453297615051
epoch 43200  training loss: 0.346044659614563
epoch 43200  clean testing loss: 0.9216561913490295
epoch 43300  training loss: 0.3458794355392456
epoch 43300  clean testing loss: 0.9227887392044067
epoch 43400  training loss: 0.3456658720970154
epoch 43400  clean testing loss: 0.9237473607063293
epoch 43500  training loss: 0.34549373388290405
epoch 43500  clean testing loss: 0.9244316816329956
epoch 43600  training loss: 0.34531518816947937
epoch 43600  clean testing loss: 0.9245470762252808
epoch 43700  training loss: 0.34512099623680115
epoch 43700  clean testing loss: 0.9262650609016418
epoch 43800  training loss: 0.3449474275112152
epoch 43800  clean testing loss: 0.9257907271385193
epoch 43900  training loss: 0.3447117209434509

 45%|████▍     | 44959/100000 [02:06<01:46, 517.43it/s]
epoch 44000  training loss: 0.3446025848388672
epoch 44000  clean testing loss: 0.926592230796814
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 44100  training loss: 0.3443581163883209
epoch 44100  clean testing loss: 0.929287850856781
epoch 44200  training loss: 0.34418708086013794
epoch 44200  clean testing loss: 0.9296945929527283
epoch 44300  training loss: 0.3439847528934479
epoch 44300  clean testing loss: 0.930047869682312
epoch 44400  training loss: 0.34386110305786133
epoch 44400  clean testing loss: 0.9314343333244324
epoch 44500  training loss: 0.3436068892478943
epoch 44500  clean testing loss: 0.9314690232276917
epoch 44600  training loss: 0.3434324562549591
epoch 44600  clean testing loss: 0.9324109554290771
epoch 44700  training loss: 0.3432890772819519
epoch 44700  clean testing loss: 0.931906521320343
epoch 44800  training loss: 0.34310346841812134
epoch 44800  clean testing loss: 0.9325098991394043
epoch 44900  training loss: 0.3428908884525299
epoch 44900  clean testing loss: 0.9344414472579956
epoch 45000  training loss: 0.3426981270313263
epoch 45000  clean testing loss: 0.9344707131385803

 46%|████▌     | 46006/100000 [02:08<01:45, 510.14it/s]
epoch 45100  training loss: 0.3425673246383667
epoch 45100  clean testing loss: 0.9356891512870789
epoch 45200  training loss: 0.3424040675163269
epoch 45200  clean testing loss: 0.9359646439552307
epoch 45300  training loss: 0.34227651357650757
epoch 45300  clean testing loss: 0.9358868598937988
epoch 45400  training loss: 0.3421179950237274
epoch 45400  clean testing loss: 0.9375472664833069
epoch 45500  training loss: 0.34195736050605774
epoch 45500  clean testing loss: 0.9372206926345825
epoch 45600  training loss: 0.341818243265152
epoch 45600  clean testing loss: 0.9378618597984314
epoch 45700  training loss: 0.3416838049888611

 47%|████▋     | 47001/100000 [02:10<01:44, 508.85it/s]
epoch 45800  training loss: 0.34151002764701843
epoch 45800  clean testing loss: 0.940152645111084
epoch 45900  training loss: 0.341342568397522
epoch 45900  clean testing loss: 0.940330982208252
epoch 46000  training loss: 0.34119951725006104
epoch 46000  clean testing loss: 0.9404538869857788
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 46100  training loss: 0.3410469591617584
epoch 46100  clean testing loss: 0.9411579966545105
epoch 46200  training loss: 0.3408966660499573
epoch 46200  clean testing loss: 0.9424294233322144
epoch 46300  training loss: 0.34070083498954773
epoch 46300  clean testing loss: 0.9424409866333008
epoch 46400  training loss: 0.3405459225177765
epoch 46400  clean testing loss: 0.9426986575126648
epoch 46500  training loss: 0.34039106965065
epoch 46500  clean testing loss: 0.9435829520225525
epoch 46600  training loss: 0.340237557888031
epoch 46600  clean testing loss: 0.9442257285118103
epoch 46700  training loss: 0.3400900661945343
epoch 46700  clean testing loss: 0.944322943687439
epoch 46800  training loss: 0.3399781584739685

 48%|████▊     | 48050/100000 [02:12<01:41, 509.51it/s]
epoch 46900  training loss: 0.3398112952709198
epoch 46900  clean testing loss: 0.9450275897979736
epoch 47000  training loss: 0.3396279513835907
epoch 47000  clean testing loss: 0.9464166760444641
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 47100  training loss: 0.33950677514076233
epoch 47100  clean testing loss: 0.947271466255188
epoch 47200  training loss: 0.33932557702064514
epoch 47200  clean testing loss: 0.947353184223175
epoch 47300  training loss: 0.3391772508621216
epoch 47300  clean testing loss: 0.9479877948760986
epoch 47400  training loss: 0.33903080224990845
epoch 47400  clean testing loss: 0.948482096195221
epoch 47500  training loss: 0.3389098346233368
epoch 47500  clean testing loss: 0.949844241142273
epoch 47600  training loss: 0.33876246213912964
epoch 47600  clean testing loss: 0.9504635334014893
epoch 47700  training loss: 0.3385961353778839
epoch 47700  clean testing loss: 0.9502485990524292
epoch 47800  training loss: 0.3384261727333069

 48%|████▊     | 48363/100000 [02:12<01:40, 515.25it/s]
epoch 47900  training loss: 0.33828192949295044
epoch 47900  clean testing loss: 0.9524670839309692
epoch 48000  training loss: 0.3381580412387848
epoch 48000  clean testing loss: 0.9520964622497559
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 48100  training loss: 0.33799847960472107
epoch 48100  clean testing loss: 0.9528900384902954
epoch 48200  training loss: 0.3378902077674866
epoch 48200  clean testing loss: 0.9531643986701965
epoch 48300  training loss: 0.3377576172351837
epoch 48300  clean testing loss: 0.9542925357818604
epoch 48400  training loss: 0.33763569593429565

 49%|████▉     | 49089/100000 [02:23<02:18, 368.56it/s]
epoch 48500  training loss: 0.3375096023082733
epoch 48500  clean testing loss: 0.9556694626808167
epoch 48600  training loss: 0.3373980224132538
epoch 48600  clean testing loss: 0.9561340808868408
epoch 48700  training loss: 0.3372596800327301
epoch 48700  clean testing loss: 0.9568396210670471
epoch 48800  training loss: 0.3371133506298065
epoch 48800  clean testing loss: 0.9571430087089539
epoch 48900  training loss: 0.336986243724823
epoch 48900  clean testing loss: 0.9580954313278198
epoch 49000  training loss: 0.3368789255619049
epoch 49000  clean testing loss: 0.9586170315742493
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 49100  training loss: 0.33673354983329773

 50%|████▉     | 49820/100000 [02:28<01:49, 458.98it/s]
epoch 49200  training loss: 0.3366159200668335
epoch 49200  clean testing loss: 0.9599235653877258
epoch 49300  training loss: 0.33646053075790405
epoch 49300  clean testing loss: 0.9597589373588562
epoch 49400  training loss: 0.33635056018829346
epoch 49400  clean testing loss: 0.959976851940155
epoch 49500  training loss: 0.3362162113189697
epoch 49500  clean testing loss: 0.9617851376533508
epoch 49600  training loss: 0.33605554699897766
epoch 49600  clean testing loss: 0.9623216390609741
epoch 49700  training loss: 0.33591464161872864
epoch 49700  clean testing loss: 0.9628129005432129
epoch 49800  training loss: 0.3357934057712555
epoch 49800  clean testing loss: 0.9629971981048584
epoch 49900  training loss: 0.33566024899482727
epoch 49900  clean testing loss: 0.9643399119377136
epoch 50000  training loss: 0.33552229404449463
epoch 50000  clean testing loss: 0.965076208114624
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 50100  training loss: 0.3354327976703644

 50%|█████     | 50340/100000 [02:29<01:37, 510.12it/s]
epoch 50200  training loss: 0.335269033908844
epoch 50200  clean testing loss: 0.9660059213638306
epoch 50300  training loss: 0.33514201641082764

 51%|█████     | 50758/100000 [02:38<06:08, 133.78it/s]
epoch 50400  training loss: 0.3350280821323395
epoch 50400  clean testing loss: 0.9670359492301941
epoch 50500  training loss: 0.3348880410194397
epoch 50500  clean testing loss: 0.9681262373924255
epoch 50600  training loss: 0.3347552716732025
epoch 50600  clean testing loss: 0.9690407514572144
epoch 50700  training loss: 0.33463114500045776
epoch 50700  clean testing loss: 0.96950364112854
epoch 50800  training loss: 0.334494024515152
epoch 50800  clean testing loss: 0.970153272151947
epoch 50900  training loss: 0.3343813717365265
epoch 50900  clean testing loss: 0.970386266708374
epoch 51000  training loss: 0.3342406153678894
epoch 51000  clean testing loss: 0.9712269902229309
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 51100  training loss: 0.33413031697273254
epoch 51100  clean testing loss: 0.9719489216804504
epoch 51200  training loss: 0.3340241611003876
epoch 51200  clean testing loss: 0.9723671078681946
epoch 51300  training loss: 0.3339173197746277

 52%|█████▏    | 51754/100000 [02:40<01:33, 514.66it/s]
epoch 51400  training loss: 0.33380934596061707
epoch 51400  clean testing loss: 0.9734233021736145
epoch 51500  training loss: 0.3336917757987976
epoch 51500  clean testing loss: 0.9743378162384033
epoch 51600  training loss: 0.3335908353328705
epoch 51600  clean testing loss: 0.9744759798049927
epoch 51700  training loss: 0.33347243070602417
epoch 51700  clean testing loss: 0.9750812649726868
epoch 51800  training loss: 0.33338063955307007

 52%|█████▏    | 51909/100000 [02:46<20:13, 39.63it/s]
epoch 51900  training loss: 0.3332635164260864
epoch 51900  clean testing loss: 0.9767998456954956
epoch 52000  training loss: 0.3331388831138611
epoch 52000  clean testing loss: 0.9768245220184326
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 52100  training loss: 0.3330380916595459
epoch 52100  clean testing loss: 0.9778854846954346
epoch 52200  training loss: 0.3329240381717682

 52%|█████▏    | 52168/100000 [02:46<04:40, 170.82it/s]
epoch 52300  training loss: 0.3328164219856262
epoch 52300  clean testing loss: 0.9786799550056458
epoch 52400  training loss: 0.3327041268348694
epoch 52400  clean testing loss: 0.9792215824127197
epoch 52500  training loss: 0.3325972855091095
epoch 52500  clean testing loss: 0.9798229932785034
epoch 52600  training loss: 0.3325132727622986

 53%|█████▎    | 52638/100000 [02:59<04:37, 170.86it/s]
epoch 52700  training loss: 0.33239537477493286
epoch 52700  clean testing loss: 0.9811869859695435
epoch 52800  training loss: 0.3322867453098297
epoch 52800  clean testing loss: 0.9819749593734741
epoch 52900  training loss: 0.3321912884712219
epoch 52900  clean testing loss: 0.9814499616622925
epoch 53000  training loss: 0.33207210898399353
epoch 53000  clean testing loss: 0.9830185770988464
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 53100  training loss: 0.33196020126342773
epoch 53100  clean testing loss: 0.9829680323600769
epoch 53200  training loss: 0.3318538963794708
epoch 53200  clean testing loss: 0.9837372899055481
epoch 53300  training loss: 0.33175134658813477
epoch 53300  clean testing loss: 0.9837296009063721
epoch 53400  training loss: 0.3316625654697418
epoch 53400  clean testing loss: 0.984825611114502
epoch 53500  training loss: 0.3315345048904419
epoch 53500  clean testing loss: 0.9847458004951477
epoch 53600  training loss: 0.3314357399940491

 54%|█████▎    | 53629/100000 [03:01<01:30, 511.96it/s]
epoch 53700  training loss: 0.33132466673851013
epoch 53700  clean testing loss: 0.9863715171813965
epoch 53800  training loss: 0.3312240540981293
epoch 53800  clean testing loss: 0.9864900708198547
epoch 53900  training loss: 0.33111485838890076
epoch 53900  clean testing loss: 0.9877077341079712
epoch 54000  training loss: 0.3310011029243469
epoch 54000  clean testing loss: 0.9877089262008667
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 54100  training loss: 0.330900639295578
epoch 54100  clean testing loss: 0.988274097442627
epoch 54200  training loss: 0.3308061361312866

 54%|█████▍    | 54154/100000 [03:02<01:29, 515.05it/s]
epoch 54300  training loss: 0.3307167589664459
epoch 54300  clean testing loss: 0.989468514919281
epoch 54400  training loss: 0.3306252658367157
epoch 54400  clean testing loss: 0.9898316264152527
epoch 54500  training loss: 0.33053040504455566
epoch 54500  clean testing loss: 0.9900158047676086
epoch 54600  training loss: 0.33044570684432983
epoch 54600  clean testing loss: 0.9909045696258545
epoch 54700  training loss: 0.3303481638431549
epoch 54700  clean testing loss: 0.9906682372093201
epoch 54800  training loss: 0.3302464485168457
epoch 54800  clean testing loss: 0.9916077256202698
epoch 54900  training loss: 0.3301611542701721

 55%|█████▍    | 54882/100000 [03:09<01:46, 422.70it/s]
epoch 55000  training loss: 0.33005666732788086
epoch 55000  clean testing loss: 0.9922094941139221
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 55100  training loss: 0.3299683928489685
epoch 55100  clean testing loss: 0.9931496977806091
epoch 55200  training loss: 0.3298737704753876
epoch 55200  clean testing loss: 0.993326723575592
epoch 55300  training loss: 0.3297857344150543
epoch 55300  clean testing loss: 0.994167149066925
epoch 55400  training loss: 0.32968398928642273
epoch 55400  clean testing loss: 0.9942949414253235
epoch 55500  training loss: 0.3296007215976715
epoch 55500  clean testing loss: 0.9949024319648743
epoch 55600  training loss: 0.3295084834098816
epoch 55600  clean testing loss: 0.9953194856643677
epoch 55700  training loss: 0.3294101655483246
epoch 55700  clean testing loss: 0.9959492683410645
epoch 55800  training loss: 0.3293115794658661
epoch 55800  clean testing loss: 0.9961823225021362
epoch 55900  training loss: 0.32922640442848206

 56%|█████▌    | 55931/100000 [03:11<01:25, 515.63it/s]
epoch 56000  training loss: 0.3291301429271698
epoch 56000  clean testing loss: 0.9972209930419922
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 56100  training loss: 0.32902729511260986
epoch 56100  clean testing loss: 0.9975824952125549
epoch 56200  training loss: 0.32893916964530945
epoch 56200  clean testing loss: 0.9982146620750427
epoch 56300  training loss: 0.32885146141052246
epoch 56300  clean testing loss: 0.9981896877288818
epoch 56400  training loss: 0.3287554383277893
epoch 56400  clean testing loss: 0.9986145496368408
epoch 56500  training loss: 0.3286537826061249
epoch 56500  clean testing loss: 0.9993313550949097
epoch 56600  training loss: 0.3285500109195709
epoch 56600  clean testing loss: 1.0004065036773682
epoch 56700  training loss: 0.32846084237098694
epoch 56700  clean testing loss: 1.0004091262817383
epoch 56800  training loss: 0.32835498452186584
epoch 56800  clean testing loss: 1.0012952089309692
epoch 56900  training loss: 0.32825782895088196
epoch 56900  clean testing loss: 1.0021382570266724
epoch 57000  training loss: 0.32816392183303833
epoch 57000  clean testing loss: 1.0021458864212036

 57%|█████▋    | 56979/100000 [03:13<01:23, 517.77it/s]
epoch 57100  training loss: 0.3280818462371826
epoch 57100  clean testing loss: 1.002494215965271
epoch 57200  training loss: 0.3280002176761627
epoch 57200  clean testing loss: 1.0029360055923462
epoch 57300  training loss: 0.3279159963130951
epoch 57300  clean testing loss: 1.0034680366516113
epoch 57400  training loss: 0.3278351128101349
epoch 57400  clean testing loss: 1.0038139820098877
epoch 57500  training loss: 0.32775604724884033
epoch 57500  clean testing loss: 1.0041087865829468
epoch 57600  training loss: 0.32767176628112793
epoch 57600  clean testing loss: 1.004547119140625
epoch 57700  training loss: 0.32758551836013794
epoch 57700  clean testing loss: 1.0051097869873047
epoch 57800  training loss: 0.32750844955444336
epoch 57800  clean testing loss: 1.0057706832885742
epoch 57900  training loss: 0.32741841673851013

 58%|█████▊    | 57923/100000 [03:15<01:21, 515.07it/s]
epoch 58000  training loss: 0.3273349106311798
epoch 58000  clean testing loss: 1.0062605142593384
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 58100  training loss: 0.327251136302948
epoch 58100  clean testing loss: 1.007096290588379
epoch 58200  training loss: 0.3271680176258087
epoch 58200  clean testing loss: 1.0070735216140747
epoch 58300  training loss: 0.3270862102508545
epoch 58300  clean testing loss: 1.0076814889907837
epoch 58400  training loss: 0.3269946873188019

 58%|█████▊    | 58393/100000 [03:23<03:42, 186.71it/s]
epoch 58500  training loss: 0.3269195854663849
epoch 58500  clean testing loss: 1.008440613746643
epoch 58600  training loss: 0.32682597637176514
epoch 58600  clean testing loss: 1.0088658332824707
epoch 58700  training loss: 0.3267407715320587
epoch 58700  clean testing loss: 1.0096070766448975
epoch 58800  training loss: 0.32666516304016113
epoch 58800  clean testing loss: 1.01024329662323
epoch 58900  training loss: 0.32657498121261597
epoch 58900  clean testing loss: 1.0106911659240723
epoch 59000  training loss: 0.32649290561676025
epoch 59000  clean testing loss: 1.010952115058899
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 59100  training loss: 0.3264073133468628
epoch 59100  clean testing loss: 1.0112214088439941
epoch 59200  training loss: 0.32632988691329956
epoch 59200  clean testing loss: 1.0124151706695557
epoch 59300  training loss: 0.32624152302742004
epoch 59300  clean testing loss: 1.0128183364868164
epoch 59400  training loss: 0.3261622190475464

 59%|█████▉    | 59385/100000 [03:25<01:21, 497.75it/s]
epoch 59500  training loss: 0.3260751962661743
epoch 59500  clean testing loss: 1.0133845806121826
epoch 59600  training loss: 0.32599300146102905
epoch 59600  clean testing loss: 1.0141361951828003
epoch 59700  training loss: 0.3259109556674957
epoch 59700  clean testing loss: 1.0143150091171265
epoch 59800  training loss: 0.325825035572052
epoch 59800  clean testing loss: 1.015181541442871
epoch 59900  training loss: 0.32573652267456055
epoch 59900  clean testing loss: 1.015580177307129
epoch 60000  training loss: 0.3256559669971466
epoch 60000  clean testing loss: 1.01584792137146
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 60100  training loss: 0.32558661699295044
epoch 60100  clean testing loss: 1.0163905620574951
epoch 60200  training loss: 0.32551857829093933
epoch 60200  clean testing loss: 1.0167099237442017
epoch 60300  training loss: 0.325451135635376
epoch 60300  clean testing loss: 1.0171393156051636
epoch 60400  training loss: 0.32538551092147827

 60%|██████    | 60379/100000 [03:27<01:17, 511.40it/s]
epoch 60500  training loss: 0.3253134787082672
epoch 60500  clean testing loss: 1.0180515050888062
epoch 60600  training loss: 0.32524415850639343
epoch 60600  clean testing loss: 1.0183067321777344
epoch 60700  training loss: 0.32517382502555847

 61%|██████    | 60693/100000 [03:28<01:16, 515.84it/s]
epoch 60800  training loss: 0.32510408759117126
epoch 60800  clean testing loss: 1.019385814666748
epoch 60900  training loss: 0.32503464818000793
epoch 60900  clean testing loss: 1.0196974277496338
epoch 61000  training loss: 0.324965238571167
epoch 61000  clean testing loss: 1.0199216604232788
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 61100  training loss: 0.3248918652534485
epoch 61100  clean testing loss: 1.0205020904541016
epoch 61200  training loss: 0.32482442259788513
epoch 61200  clean testing loss: 1.020694375038147
epoch 61300  training loss: 0.32474851608276367
epoch 61300  clean testing loss: 1.0213543176651
epoch 61400  training loss: 0.32468467950820923

 61%|██████▏   | 61368/100000 [03:31<01:23, 461.89it/s]
epoch 61500  training loss: 0.32460853457450867
epoch 61500  clean testing loss: 1.022308111190796
epoch 61600  training loss: 0.32453620433807373
epoch 61600  clean testing loss: 1.0229014158248901
epoch 61700  training loss: 0.3244626522064209
epoch 61700  clean testing loss: 1.023008942604065
epoch 61800  training loss: 0.3243902921676636
epoch 61800  clean testing loss: 1.0233961343765259
epoch 61900  training loss: 0.3243173062801361
epoch 61900  clean testing loss: 1.0239323377609253
epoch 62000  training loss: 0.3242468535900116
epoch 62000  clean testing loss: 1.0241284370422363
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 62100  training loss: 0.32417574524879456
epoch 62100  clean testing loss: 1.0245712995529175
epoch 62200  training loss: 0.3241092562675476
epoch 62200  clean testing loss: 1.025261640548706
epoch 62300  training loss: 0.3240346312522888
epoch 62300  clean testing loss: 1.0257080793380737
epoch 62400  training loss: 0.3239610195159912

 62%|██████▏   | 62414/100000 [03:33<01:13, 512.76it/s]
epoch 62500  training loss: 0.32388782501220703
epoch 62500  clean testing loss: 1.026530146598816
epoch 62600  training loss: 0.3238176703453064

 63%|██████▎   | 62571/100000 [03:34<01:12, 514.21it/s]
epoch 62700  training loss: 0.3237520158290863
epoch 62700  clean testing loss: 1.027420163154602
epoch 62800  training loss: 0.3236817717552185
epoch 62800  clean testing loss: 1.0274555683135986
epoch 62900  training loss: 0.32360541820526123
epoch 62900  clean testing loss: 1.0280230045318604
epoch 63000  training loss: 0.323538601398468
epoch 63000  clean testing loss: 1.0284532308578491
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 63100  training loss: 0.3234746754169464
epoch 63100  clean testing loss: 1.0289456844329834
epoch 63200  training loss: 0.32341858744621277
epoch 63200  clean testing loss: 1.0291924476623535
epoch 63300  training loss: 0.3233534097671509
epoch 63300  clean testing loss: 1.029426097869873
epoch 63400  training loss: 0.32329368591308594
epoch 63400  clean testing loss: 1.0299652814865112
epoch 63500  training loss: 0.3232351839542389
epoch 63500  clean testing loss: 1.0302717685699463
epoch 63600  training loss: 0.3231755197048187
epoch 63600  clean testing loss: 1.030527114868164
epoch 63700  training loss: 0.32311394810676575
epoch 63700  clean testing loss: 1.0309851169586182
epoch 63800  training loss: 0.32305532693862915

 64%|██████▍   | 63830/100000 [03:39<01:12, 496.62it/s]
epoch 63900  training loss: 0.3229981064796448
epoch 63900  clean testing loss: 1.0315721035003662
epoch 64000  training loss: 0.32293376326560974
epoch 64000  clean testing loss: 1.0321789979934692
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 64100  training loss: 0.3228779733181
epoch 64100  clean testing loss: 1.0324856042861938
epoch 64200  training loss: 0.3228195607662201
epoch 64200  clean testing loss: 1.0327839851379395
epoch 64300  training loss: 0.32275912165641785
epoch 64300  clean testing loss: 1.0334246158599854
epoch 64400  training loss: 0.32269424200057983
epoch 64400  clean testing loss: 1.0337285995483398
epoch 64500  training loss: 0.32263562083244324
epoch 64500  clean testing loss: 1.0340772867202759
epoch 64600  training loss: 0.3225767910480499
epoch 64600  clean testing loss: 1.0343210697174072
epoch 64700  training loss: 0.3225176930427551
epoch 64700  clean testing loss: 1.0347915887832642
epoch 64800  training loss: 0.32245922088623047
epoch 64800  clean testing loss: 1.0353418588638306
epoch 64900  training loss: 0.322398841381073

 65%|██████▍   | 64828/100000 [03:41<01:08, 515.83it/s]
epoch 65000  training loss: 0.3223375082015991
epoch 65000  clean testing loss: 1.0358432531356812
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 65100  training loss: 0.32227858901023865
epoch 65100  clean testing loss: 1.0363796949386597
epoch 65200  training loss: 0.32222139835357666
epoch 65200  clean testing loss: 1.036512017250061
epoch 65300  training loss: 0.3221627175807953
epoch 65300  clean testing loss: 1.0371378660202026
epoch 65400  training loss: 0.3220996558666229
epoch 65400  clean testing loss: 1.037308692932129
epoch 65500  training loss: 0.3220438063144684
epoch 65500  clean testing loss: 1.0377061367034912
epoch 65600  training loss: 0.32198408246040344
epoch 65600  clean testing loss: 1.0383257865905762
epoch 65700  training loss: 0.3219224512577057
epoch 65700  clean testing loss: 1.0385065078735352
epoch 65800  training loss: 0.3218640089035034
epoch 65800  clean testing loss: 1.0388743877410889
epoch 65900  training loss: 0.32180455327033997

 66%|██████▌   | 65874/100000 [03:43<01:06, 515.87it/s]
epoch 66000  training loss: 0.32174691557884216
epoch 66000  clean testing loss: 1.039661169052124
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 66100  training loss: 0.3216957449913025

 66%|██████▌   | 66189/100000 [03:44<01:05, 512.86it/s]
epoch 66200  training loss: 0.3216475248336792
epoch 66200  clean testing loss: 1.0403259992599487
epoch 66300  training loss: 0.3215998709201813
epoch 66300  clean testing loss: 1.0407609939575195
epoch 66400  training loss: 0.3215489089488983
epoch 66400  clean testing loss: 1.040964961051941
epoch 66500  training loss: 0.3215011656284332
epoch 66500  clean testing loss: 1.0412099361419678
epoch 66600  training loss: 0.3214503824710846
epoch 66600  clean testing loss: 1.0414707660675049
epoch 66700  training loss: 0.32140055298805237
epoch 66700  clean testing loss: 1.0419321060180664
epoch 66800  training loss: 0.3213532567024231
epoch 66800  clean testing loss: 1.0424575805664062
epoch 66900  training loss: 0.32130196690559387
epoch 66900  clean testing loss: 1.0425827503204346
epoch 67000  training loss: 0.3212532699108124
epoch 67000  clean testing loss: 1.0428152084350586
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 67100  training loss: 0.32120412588119507

 67%|██████▋   | 67034/100000 [03:47<06:28, 84.76it/s]
epoch 67200  training loss: 0.3211519122123718
epoch 67200  clean testing loss: 1.0433759689331055
epoch 67300  training loss: 0.32110267877578735
epoch 67300  clean testing loss: 1.043668508529663
epoch 67400  training loss: 0.32105275988578796
epoch 67400  clean testing loss: 1.0440962314605713
epoch 67500  training loss: 0.32100343704223633
epoch 67500  clean testing loss: 1.044562578201294
epoch 67600  training loss: 0.3209526538848877
epoch 67600  clean testing loss: 1.0446544885635376
epoch 67700  training loss: 0.3208947777748108
epoch 67700  clean testing loss: 1.0450682640075684
epoch 67800  training loss: 0.32083576917648315
epoch 67800  clean testing loss: 1.045305848121643
epoch 67900  training loss: 0.3207692503929138
epoch 67900  clean testing loss: 1.0455979108810425
epoch 68000  training loss: 0.32071301341056824
epoch 68000  clean testing loss: 1.0458921194076538
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 68100  training loss: 0.3206513226032257

 68%|██████▊   | 68074/100000 [03:49<01:02, 512.51it/s]
epoch 68200  training loss: 0.32058796286582947
epoch 68200  clean testing loss: 1.0462385416030884
epoch 68300  training loss: 0.3205317556858063
epoch 68300  clean testing loss: 1.0466123819351196
epoch 68400  training loss: 0.32047075033187866
epoch 68400  clean testing loss: 1.0467779636383057
epoch 68500  training loss: 0.3204164206981659
epoch 68500  clean testing loss: 1.047202229499817
epoch 68600  training loss: 0.3203619420528412
epoch 68600  clean testing loss: 1.0474523305892944
epoch 68700  training loss: 0.3203127384185791
epoch 68700  clean testing loss: 1.0477550029754639
epoch 68800  training loss: 0.32025763392448425
epoch 68800  clean testing loss: 1.0482345819473267
epoch 68900  training loss: 0.3202066421508789
epoch 68900  clean testing loss: 1.048529028892517
epoch 69000  training loss: 0.32015565037727356
epoch 69000  clean testing loss: 1.0489376783370972
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 69100  training loss: 0.32011133432388306

 69%|██████▉   | 69123/100000 [03:51<01:00, 512.65it/s]
epoch 69200  training loss: 0.32006996870040894
epoch 69200  clean testing loss: 1.0493354797363281
epoch 69300  training loss: 0.3200293183326721
epoch 69300  clean testing loss: 1.0496010780334473
epoch 69400  training loss: 0.3199858069419861
epoch 69400  clean testing loss: 1.0499024391174316
epoch 69500  training loss: 0.3199424147605896
epoch 69500  clean testing loss: 1.050040602684021
epoch 69600  training loss: 0.3199000358581543
epoch 69600  clean testing loss: 1.0502827167510986
epoch 69700  training loss: 0.3198556900024414
epoch 69700  clean testing loss: 1.0505925416946411
epoch 69800  training loss: 0.3198121190071106
epoch 69800  clean testing loss: 1.0507704019546509
epoch 69900  training loss: 0.31976887583732605
epoch 69900  clean testing loss: 1.0510227680206299
epoch 70000  training loss: 0.3197247385978699
epoch 70000  clean testing loss: 1.051405906677246
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 70100  training loss: 0.31968098878860474
epoch 70100  clean testing loss: 1.0515042543411255
epoch 70200  training loss: 0.3196357786655426

 70%|███████   | 70120/100000 [03:53<00:58, 509.78it/s]
epoch 70300  training loss: 0.31958913803100586
epoch 70300  clean testing loss: 1.0520917177200317
epoch 70400  training loss: 0.3195452392101288
epoch 70400  clean testing loss: 1.0523498058319092
epoch 70500  training loss: 0.3195009231567383
epoch 70500  clean testing loss: 1.052664875984192
epoch 70600  training loss: 0.31945860385894775
epoch 70600  clean testing loss: 1.0527864694595337
epoch 70700  training loss: 0.3194134533405304
epoch 70700  clean testing loss: 1.0530507564544678
epoch 70800  training loss: 0.3193685710430145
epoch 70800  clean testing loss: 1.0534497499465942
epoch 70900  training loss: 0.31932568550109863
epoch 70900  clean testing loss: 1.053634524345398
epoch 71000  training loss: 0.3192823529243469
epoch 71000  clean testing loss: 1.0540812015533447
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 71100  training loss: 0.31923750042915344

 71%|███████   | 71112/100000 [03:55<01:01, 471.61it/s]
epoch 71200  training loss: 0.31919288635253906
epoch 71200  clean testing loss: 1.0544047355651855
epoch 71300  training loss: 0.3191494345664978
epoch 71300  clean testing loss: 1.0545750856399536
epoch 71400  training loss: 0.31910717487335205
epoch 71400  clean testing loss: 1.0549097061157227
epoch 71500  training loss: 0.31906238198280334
epoch 71500  clean testing loss: 1.0550918579101562
epoch 71600  training loss: 0.31901878118515015
epoch 71600  clean testing loss: 1.0553642511367798
epoch 71700  training loss: 0.31897634267807007
epoch 71700  clean testing loss: 1.055719256401062
epoch 71800  training loss: 0.3189312815666199
epoch 71800  clean testing loss: 1.0559378862380981
epoch 71900  training loss: 0.31888869404792786
epoch 71900  clean testing loss: 1.0562800168991089
epoch 72000  training loss: 0.31884345412254333
epoch 72000  clean testing loss: 1.056433916091919
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 72100  training loss: 0.3188077211380005
epoch 72100  clean testing loss: 1.0566365718841553
epoch 72200  training loss: 0.3187706470489502

 72%|███████▏  | 72156/100000 [03:57<00:54, 510.58it/s]
epoch 72300  training loss: 0.31873655319213867
epoch 72300  clean testing loss: 1.0569393634796143
epoch 72400  training loss: 0.3186994791030884
epoch 72400  clean testing loss: 1.0571484565734863
epoch 72500  training loss: 0.31866198778152466
epoch 72500  clean testing loss: 1.0574233531951904
epoch 72600  training loss: 0.31862735748291016
epoch 72600  clean testing loss: 1.0577422380447388
epoch 72700  training loss: 0.31859102845191956
epoch 72700  clean testing loss: 1.0579135417938232
epoch 72800  training loss: 0.3185557425022125
epoch 72800  clean testing loss: 1.0580177307128906
epoch 72900  training loss: 0.31851816177368164
epoch 72900  clean testing loss: 1.0583112239837646
epoch 73000  training loss: 0.31848132610321045
epoch 73000  clean testing loss: 1.0585098266601562
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 73100  training loss: 0.3184446394443512
epoch 73100  clean testing loss: 1.0587787628173828
epoch 73200  training loss: 0.3184066414833069

 73%|███████▎  | 73206/100000 [03:59<00:52, 510.16it/s]
epoch 73300  training loss: 0.31837067008018494
epoch 73300  clean testing loss: 1.0591673851013184
epoch 73400  training loss: 0.3183342516422272
epoch 73400  clean testing loss: 1.0594053268432617
epoch 73500  training loss: 0.31829768419265747
epoch 73500  clean testing loss: 1.0594905614852905
epoch 73600  training loss: 0.3182588517665863
epoch 73600  clean testing loss: 1.0597556829452515
epoch 73700  training loss: 0.31822237372398376
epoch 73700  clean testing loss: 1.0598933696746826
epoch 73800  training loss: 0.3181859254837036
epoch 73800  clean testing loss: 1.0602165460586548
epoch 73900  training loss: 0.31814929842948914
epoch 73900  clean testing loss: 1.0603688955307007
epoch 74000  training loss: 0.3181120753288269
epoch 74000  clean testing loss: 1.0605329275131226
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 74100  training loss: 0.3180752396583557
epoch 74100  clean testing loss: 1.0607478618621826
epoch 74200  training loss: 0.31803804636001587

 74%|███████▍  | 74201/100000 [04:01<00:50, 511.33it/s]
epoch 74300  training loss: 0.3180001676082611
epoch 74300  clean testing loss: 1.061219334602356
epoch 74400  training loss: 0.3179643154144287
epoch 74400  clean testing loss: 1.061414122581482
epoch 74500  training loss: 0.31792691349983215
epoch 74500  clean testing loss: 1.061514139175415
epoch 74600  training loss: 0.3178901970386505
epoch 74600  clean testing loss: 1.0617245435714722
epoch 74700  training loss: 0.3178519010543823
epoch 74700  clean testing loss: 1.0619316101074219
epoch 74800  training loss: 0.3178149163722992
epoch 74800  clean testing loss: 1.0622016191482544
epoch 74900  training loss: 0.31777846813201904
epoch 74900  clean testing loss: 1.0624452829360962
epoch 75000  training loss: 0.3177401125431061
epoch 75000  clean testing loss: 1.0625994205474854
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 75100  training loss: 0.31770941615104675
epoch 75100  clean testing loss: 1.0627549886703491
epoch 75200  training loss: 0.31768113374710083
epoch 75200  clean testing loss: 1.0629726648330688
epoch 75300  training loss: 0.31765007972717285

 75%|███████▌  | 75247/100000 [04:03<00:48, 511.67it/s]
epoch 75400  training loss: 0.31762009859085083
epoch 75400  clean testing loss: 1.06329345703125
epoch 75500  training loss: 0.3175901770591736
epoch 75500  clean testing loss: 1.0634572505950928
epoch 75600  training loss: 0.31756043434143066
epoch 75600  clean testing loss: 1.0636001825332642
epoch 75700  training loss: 0.31752920150756836
epoch 75700  clean testing loss: 1.0638552904129028
epoch 75800  training loss: 0.3174997568130493
epoch 75800  clean testing loss: 1.0640310049057007
epoch 75900  training loss: 0.3174690008163452


 77%|███████▋  | 76760/100000 [04:11<00:48, 482.87it/s]
epoch 76000  training loss: 0.3174372911453247
epoch 76000  clean testing loss: 1.0642913579940796
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 76100  training loss: 0.31740763783454895
epoch 76100  clean testing loss: 1.0645086765289307
epoch 76200  training loss: 0.317376047372818
epoch 76200  clean testing loss: 1.064664602279663
epoch 76300  training loss: 0.31734612584114075
epoch 76300  clean testing loss: 1.0647863149642944
epoch 76400  training loss: 0.3173163831233978
epoch 76400  clean testing loss: 1.0649900436401367
epoch 76500  training loss: 0.3172849416732788
epoch 76500  clean testing loss: 1.065182089805603
epoch 76600  training loss: 0.31725364923477173
epoch 76600  clean testing loss: 1.065400242805481
epoch 76700  training loss: 0.3172237277030945
epoch 76700  clean testing loss: 1.065633773803711
epoch 76800  training loss: 0.31719258427619934

 77%|███████▋  | 77176/100000 [04:12<00:44, 511.35it/s]
epoch 76900  training loss: 0.3171623647212982
epoch 76900  clean testing loss: 1.065887451171875
epoch 77000  training loss: 0.3171318769454956
epoch 77000  clean testing loss: 1.0660120248794556
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 77100  training loss: 0.31710201501846313
epoch 77100  clean testing loss: 1.0663208961486816
epoch 77200  training loss: 0.317069411277771

 78%|███████▊  | 78166/100000 [04:17<00:43, 505.25it/s]
epoch 77300  training loss: 0.31703588366508484
epoch 77300  clean testing loss: 1.066673994064331
epoch 77400  training loss: 0.31700411438941956
epoch 77400  clean testing loss: 1.0667822360992432
epoch 77500  training loss: 0.31697118282318115
epoch 77500  clean testing loss: 1.0669275522232056
epoch 77600  training loss: 0.31693971157073975
epoch 77600  clean testing loss: 1.067086935043335
epoch 77700  training loss: 0.3169080913066864
epoch 77700  clean testing loss: 1.0672706365585327
epoch 77800  training loss: 0.3168768584728241
epoch 77800  clean testing loss: 1.0674622058868408
epoch 77900  training loss: 0.31684455275535583
epoch 77900  clean testing loss: 1.067502737045288
epoch 78000  training loss: 0.31681275367736816
epoch 78000  clean testing loss: 1.0676928758621216
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 78100  training loss: 0.31678566336631775
epoch 78100  clean testing loss: 1.0678443908691406
epoch 78200  training loss: 0.3167600929737091

 79%|███████▉  | 79161/100000 [04:19<00:40, 516.22it/s]
epoch 78300  training loss: 0.31673428416252136
epoch 78300  clean testing loss: 1.0680445432662964
epoch 78400  training loss: 0.31670933961868286
epoch 78400  clean testing loss: 1.068243384361267
epoch 78500  training loss: 0.31668341159820557
epoch 78500  clean testing loss: 1.0683740377426147
epoch 78600  training loss: 0.31665778160095215
epoch 78600  clean testing loss: 1.0685105323791504
epoch 78700  training loss: 0.3166317343711853
epoch 78700  clean testing loss: 1.0686513185501099
epoch 78800  training loss: 0.3166061341762543
epoch 78800  clean testing loss: 1.0688884258270264
epoch 78900  training loss: 0.3165801465511322
epoch 78900  clean testing loss: 1.0690327882766724
epoch 79000  training loss: 0.31655392050743103
epoch 79000  clean testing loss: 1.06918203830719
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 79100  training loss: 0.31652840971946716
epoch 79100  clean testing loss: 1.0693347454071045
epoch 79200  training loss: 0.31650230288505554

 80%|████████  | 80210/100000 [04:21<00:38, 513.95it/s]
epoch 79300  training loss: 0.3164771795272827
epoch 79300  clean testing loss: 1.069583535194397
epoch 79400  training loss: 0.3164510726928711
epoch 79400  clean testing loss: 1.0697985887527466
epoch 79500  training loss: 0.31642457842826843
epoch 79500  clean testing loss: 1.0699821710586548
epoch 79600  training loss: 0.3163994550704956
epoch 79600  clean testing loss: 1.0701621770858765
epoch 79700  training loss: 0.31637337803840637
epoch 79700  clean testing loss: 1.0703232288360596
epoch 79800  training loss: 0.31634771823883057
epoch 79800  clean testing loss: 1.0704619884490967
epoch 79900  training loss: 0.3163219094276428
epoch 79900  clean testing loss: 1.0704997777938843
epoch 80000  training loss: 0.3162970244884491
epoch 80000  clean testing loss: 1.070683479309082
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 80100  training loss: 0.31627127528190613
epoch 80100  clean testing loss: 1.0708951950073242
epoch 80200  training loss: 0.3162444531917572

 81%|████████▏ | 81260/100000 [04:24<00:36, 515.49it/s]
epoch 80300  training loss: 0.3162192106246948
epoch 80300  clean testing loss: 1.07122004032135
epoch 80400  training loss: 0.3161933422088623
epoch 80400  clean testing loss: 1.0714298486709595
epoch 80500  training loss: 0.31616708636283875
epoch 80500  clean testing loss: 1.0715984106063843
epoch 80600  training loss: 0.3161420226097107
epoch 80600  clean testing loss: 1.071646809577942
epoch 80700  training loss: 0.31611570715904236
epoch 80700  clean testing loss: 1.0718472003936768
epoch 80800  training loss: 0.31609004735946655
epoch 80800  clean testing loss: 1.0720798969268799
epoch 80900  training loss: 0.31606361269950867
epoch 80900  clean testing loss: 1.072253942489624
epoch 81000  training loss: 0.3160375654697418
epoch 81000  clean testing loss: 1.0723176002502441
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 81100  training loss: 0.31601569056510925
epoch 81100  clean testing loss: 1.072470784187317
epoch 81200  training loss: 0.31599557399749756
epoch 81200  clean testing loss: 1.0726702213287354
epoch 81300  training loss: 0.31597429513931274

 81%|████████▏ | 81469/100000 [04:24<00:36, 511.16it/s]
epoch 81400  training loss: 0.3159533143043518
epoch 81400  clean testing loss: 1.0728849172592163
epoch 81500  training loss: 0.31593164801597595

 82%|████████▏ | 82046/100000 [04:36<01:05, 272.43it/s]
epoch 81600  training loss: 0.31591007113456726
epoch 81600  clean testing loss: 1.0731900930404663
epoch 81700  training loss: 0.31588906049728394
epoch 81700  clean testing loss: 1.0733565092086792
epoch 81800  training loss: 0.3158678412437439
epoch 81800  clean testing loss: 1.0734515190124512
epoch 81900  training loss: 0.3158476650714874
epoch 81900  clean testing loss: 1.0735503435134888
epoch 82000  training loss: 0.3158251941204071
epoch 82000  clean testing loss: 1.0737413167953491
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 82100  training loss: 0.31580355763435364
epoch 82100  clean testing loss: 1.0738890171051025
epoch 82200  training loss: 0.31578201055526733
epoch 82200  clean testing loss: 1.0740033388137817
epoch 82300  training loss: 0.31576094031333923

 83%|████████▎ | 83041/100000 [04:37<00:33, 511.58it/s]
epoch 82400  training loss: 0.31573954224586487
epoch 82400  clean testing loss: 1.0742204189300537
epoch 82500  training loss: 0.3157190680503845
epoch 82500  clean testing loss: 1.0744469165802002
epoch 82600  training loss: 0.31569704413414
epoch 82600  clean testing loss: 1.0745292901992798
epoch 82700  training loss: 0.31567659974098206
epoch 82700  clean testing loss: 1.074703574180603
epoch 82800  training loss: 0.3156549036502838
epoch 82800  clean testing loss: 1.0748273134231567
epoch 82900  training loss: 0.315633624792099
epoch 82900  clean testing loss: 1.0749683380126953
epoch 83000  training loss: 0.3156115710735321
epoch 83000  clean testing loss: 1.0751230716705322
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 83100  training loss: 0.3155902922153473
epoch 83100  clean testing loss: 1.0752017498016357
epoch 83200  training loss: 0.3155688941478729
epoch 83200  clean testing loss: 1.075330376625061
epoch 83300  training loss: 0.31554844975471497

 83%|████████▎ | 83252/100000 [04:38<00:32, 513.31it/s]
epoch 83400  training loss: 0.31552746891975403
epoch 83400  clean testing loss: 1.0756893157958984
epoch 83500  training loss: 0.31550538539886475
epoch 83500  clean testing loss: 1.0757285356521606
epoch 83600  training loss: 0.3154836595058441
epoch 83600  clean testing loss: 1.0759367942810059
epoch 83700  training loss: 0.3154631555080414
epoch 83700  clean testing loss: 1.076093316078186
epoch 83800  training loss: 0.3154427111148834
epoch 83800  clean testing loss: 1.0761796236038208
epoch 83900  training loss: 0.3154210150241852
epoch 83900  clean testing loss: 1.0763665437698364
epoch 84000  training loss: 0.3153996765613556
epoch 84000  clean testing loss: 1.076440691947937
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 84100  training loss: 0.3153814971446991
epoch 84100  clean testing loss: 1.0765721797943115
epoch 84200  training loss: 0.3153643310070038

 85%|████████▍ | 84723/100000 [04:43<00:31, 483.95it/s]
epoch 84300  training loss: 0.3153470754623413
epoch 84300  clean testing loss: 1.076748013496399
epoch 84400  training loss: 0.3153296709060669
epoch 84400  clean testing loss: 1.0769284963607788
epoch 84500  training loss: 0.31531283259391785
epoch 84500  clean testing loss: 1.077030062675476
epoch 84600  training loss: 0.3152938485145569
epoch 84600  clean testing loss: 1.07711660861969
epoch 84700  training loss: 0.31527504324913025
epoch 84700  clean testing loss: 1.0771424770355225
epoch 84800  training loss: 0.31525617837905884
epoch 84800  clean testing loss: 1.0772390365600586
epoch 84900  training loss: 0.31523799896240234
epoch 84900  clean testing loss: 1.077359676361084
epoch 85000  training loss: 0.3152189552783966
epoch 85000  clean testing loss: 1.0774204730987549
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 85100  training loss: 0.3151971697807312
epoch 85100  clean testing loss: 1.077591896057129
epoch 85200  training loss: 0.3151780068874359
epoch 85200  clean testing loss: 1.0777417421340942
epoch 85300  training loss: 0.3151586949825287

 86%|████████▌ | 85772/100000 [04:45<00:27, 517.17it/s]
epoch 85400  training loss: 0.3151393532752991
epoch 85400  clean testing loss: 1.077939748764038
epoch 85500  training loss: 0.3151199519634247
epoch 85500  clean testing loss: 1.077987551689148
epoch 85600  training loss: 0.3151015043258667
epoch 85600  clean testing loss: 1.0781524181365967
epoch 85700  training loss: 0.31508344411849976
epoch 85700  clean testing loss: 1.0782493352890015

 86%|████████▌ | 86245/100000 [04:53<02:41, 85.39it/s]
epoch 85800  clean testing loss: 1.078314185142517
epoch 85900  training loss: 0.3150455355644226
epoch 85900  clean testing loss: 1.078382134437561
epoch 86000  training loss: 0.3150281608104706
epoch 86000  clean testing loss: 1.078502893447876
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 86100  training loss: 0.31500905752182007
epoch 86100  clean testing loss: 1.0785274505615234
epoch 86200  training loss: 0.3149908781051636
epoch 86200  clean testing loss: 1.0786676406860352
epoch 86300  training loss: 0.3149734139442444
epoch 86300  clean testing loss: 1.0787439346313477
epoch 86400  training loss: 0.314954549074173
epoch 86400  clean testing loss: 1.078848958015442
epoch 86500  training loss: 0.3149360120296478
epoch 86500  clean testing loss: 1.0789471864700317
epoch 86600  training loss: 0.3149179220199585
epoch 86600  clean testing loss: 1.0791057348251343
epoch 86700  training loss: 0.31490010023117065
epoch 86700  clean testing loss: 1.0791858434677124
epoch 86800  training loss: 0.314881831407547

 87%|████████▋ | 87293/100000 [04:55<00:24, 515.57it/s]
epoch 86900  training loss: 0.31486403942108154
epoch 86900  clean testing loss: 1.079345703125
epoch 87000  training loss: 0.3148461878299713
epoch 87000  clean testing loss: 1.0794719457626343
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 87100  training loss: 0.3148309886455536
epoch 87100  clean testing loss: 1.0795255899429321
epoch 87200  training loss: 0.3148156404495239
epoch 87200  clean testing loss: 1.0796536207199097
epoch 87300  training loss: 0.3148016035556793
epoch 87300  clean testing loss: 1.0797537565231323
epoch 87400  training loss: 0.3147866427898407
epoch 87400  clean testing loss: 1.0798368453979492
epoch 87500  training loss: 0.3147713840007782
epoch 87500  clean testing loss: 1.079933762550354
epoch 87600  training loss: 0.31475701928138733
epoch 87600  clean testing loss: 1.0799978971481323
epoch 87700  training loss: 0.3147420883178711
epoch 87700  clean testing loss: 1.0801045894622803
epoch 87800  training loss: 0.3147270679473877

 88%|████████▊ | 88279/100000 [04:57<00:22, 510.12it/s]
epoch 87900  training loss: 0.3147127032279968
epoch 87900  clean testing loss: 1.0802793502807617
epoch 88000  training loss: 0.31469759345054626
epoch 88000  clean testing loss: 1.0803771018981934
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 88100  training loss: 0.31468233466148376
epoch 88100  clean testing loss: 1.0804849863052368
epoch 88200  training loss: 0.3146674633026123
epoch 88200  clean testing loss: 1.0805920362472534
epoch 88300  training loss: 0.31465232372283936
epoch 88300  clean testing loss: 1.0806736946105957
epoch 88400  training loss: 0.31463754177093506
epoch 88400  clean testing loss: 1.0807898044586182
epoch 88500  training loss: 0.31462234258651733
epoch 88500  clean testing loss: 1.0808968544006348
epoch 88600  training loss: 0.31460773944854736
epoch 88600  clean testing loss: 1.08098566532135
epoch 88700  training loss: 0.31459277868270874
epoch 88700  clean testing loss: 1.0810599327087402
epoch 88800  training loss: 0.3145780563354492

 89%|████████▉ | 89323/100000 [04:59<00:20, 512.13it/s]
epoch 88900  training loss: 0.31456267833709717
epoch 88900  clean testing loss: 1.0813050270080566
epoch 89000  training loss: 0.3145473003387451
epoch 89000  clean testing loss: 1.0814266204833984
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 89100  training loss: 0.31453266739845276
epoch 89100  clean testing loss: 1.0814727544784546
epoch 89200  training loss: 0.3145177364349365
epoch 89200  clean testing loss: 1.0816036462783813
epoch 89300  training loss: 0.3145025074481964
epoch 89300  clean testing loss: 1.0816459655761719
epoch 89400  training loss: 0.3144875466823578
epoch 89400  clean testing loss: 1.0817898511886597
epoch 89500  training loss: 0.31447261571884155
epoch 89500  clean testing loss: 1.0818606615066528
epoch 89600  training loss: 0.3144575357437134
epoch 89600  clean testing loss: 1.0819330215454102
epoch 89700  training loss: 0.31444263458251953
epoch 89700  clean testing loss: 1.0820726156234741
epoch 89800  training loss: 0.31442776322364807

 90%|█████████ | 90318/100000 [05:01<00:18, 513.22it/s]
epoch 89900  training loss: 0.3144126832485199
epoch 89900  clean testing loss: 1.0822679996490479
epoch 90000  training loss: 0.3143976628780365
epoch 90000  clean testing loss: 1.0823782682418823
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 90100  training loss: 0.31438568234443665
epoch 90100  clean testing loss: 1.0824207067489624
epoch 90200  training loss: 0.31437408924102783
epoch 90200  clean testing loss: 1.082555890083313
epoch 90300  training loss: 0.3143622577190399
epoch 90300  clean testing loss: 1.0826140642166138
epoch 90400  training loss: 0.31435027718544006
epoch 90400  clean testing loss: 1.082658052444458
epoch 90500  training loss: 0.3143385350704193
epoch 90500  clean testing loss: 1.0827440023422241
epoch 90600  training loss: 0.31432655453681946
epoch 90600  clean testing loss: 1.0828286409378052
epoch 90700  training loss: 0.3143148422241211
epoch 90700  clean testing loss: 1.0829343795776367
epoch 90800  training loss: 0.31430312991142273
epoch 90800  clean testing loss: 1.0830190181732178
epoch 90900  training loss: 0.3142909109592438

 91%|█████████▏| 91366/100000 [05:03<00:16, 517.67it/s]
epoch 91000  training loss: 0.3142792582511902
epoch 91000  clean testing loss: 1.0831540822982788
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 91100  training loss: 0.31426680088043213
epoch 91100  clean testing loss: 1.0832397937774658
epoch 91200  training loss: 0.3142552673816681
epoch 91200  clean testing loss: 1.0833375453948975
epoch 91300  training loss: 0.31424304842948914
epoch 91300  clean testing loss: 1.0833978652954102
epoch 91400  training loss: 0.31423118710517883
epoch 91400  clean testing loss: 1.0834943056106567
epoch 91500  training loss: 0.31421950459480286
epoch 91500  clean testing loss: 1.0835820436477661
epoch 91600  training loss: 0.3142074644565582
epoch 91600  clean testing loss: 1.0836519002914429
epoch 91700  training loss: 0.31419530510902405
epoch 91700  clean testing loss: 1.0837353467941284
epoch 91800  training loss: 0.3141835331916809

 92%|█████████▏| 91786/100000 [05:04<00:15, 517.62it/s]
epoch 91900  training loss: 0.3141716420650482
epoch 91900  clean testing loss: 1.083907961845398
epoch 92000  training loss: 0.3141593635082245
epoch 92000  clean testing loss: 1.0839831829071045
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 92100  training loss: 0.3141480088233948
epoch 92100  clean testing loss: 1.0840630531311035
epoch 92200  training loss: 0.3141358196735382

 92%|█████████▏| 92458/100000 [05:11<00:19, 392.46it/s]
epoch 92300  training loss: 0.31412410736083984
epoch 92300  clean testing loss: 1.0842046737670898
epoch 92400  training loss: 0.3141115605831146
epoch 92400  clean testing loss: 1.0842983722686768
epoch 92500  training loss: 0.31409916281700134

 93%|█████████▎| 93092/100000 [05:13<00:47, 145.56it/s]
epoch 92600  training loss: 0.31408753991127014
epoch 92600  clean testing loss: 1.0844581127166748
epoch 92700  training loss: 0.31407496333122253
epoch 92700  clean testing loss: 1.08455228805542
epoch 92800  training loss: 0.3140624165534973
epoch 92800  clean testing loss: 1.084620714187622
epoch 92900  training loss: 0.3140506148338318
epoch 92900  clean testing loss: 1.084726095199585
epoch 93000  training loss: 0.31403878331184387
epoch 93000  clean testing loss: 1.0847971439361572
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 93100  training loss: 0.314028799533844
epoch 93100  clean testing loss: 1.084855318069458
epoch 93200  training loss: 0.3140185475349426
epoch 93200  clean testing loss: 1.084934115409851
epoch 93300  training loss: 0.31400883197784424
epoch 93300  clean testing loss: 1.0850131511688232
epoch 93400  training loss: 0.3139985501766205
epoch 93400  clean testing loss: 1.0850805044174194
epoch 93500  training loss: 0.3139883577823639
epoch 93500  clean testing loss: 1.0851472616195679
epoch 93600  training loss: 0.3139778673648834
epoch 93600  clean testing loss: 1.0852434635162354
epoch 93700  training loss: 0.31396570801734924
epoch 93700  clean testing loss: 1.0853452682495117
epoch 93800  training loss: 0.3139549195766449
epoch 93800  clean testing loss: 1.085411548614502
epoch 93900  training loss: 0.3139433264732361

 94%|█████████▍| 94132/100000 [05:15<00:11, 508.24it/s]
epoch 94000  training loss: 0.3139312267303467
epoch 94000  clean testing loss: 1.0855979919433594
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 94100  training loss: 0.31391945481300354
epoch 94100  clean testing loss: 1.0856568813323975
epoch 94200  training loss: 0.3139089345932007
epoch 94200  clean testing loss: 1.0857452154159546
epoch 94300  training loss: 0.3138975501060486
epoch 94300  clean testing loss: 1.085822343826294
epoch 94400  training loss: 0.3138866424560547
epoch 94400  clean testing loss: 1.0859087705612183
epoch 94500  training loss: 0.313875675201416
epoch 94500  clean testing loss: 1.0859907865524292
epoch 94600  training loss: 0.31386512517929077
epoch 94600  clean testing loss: 1.0860539674758911
epoch 94700  training loss: 0.31385380029678345
epoch 94700  clean testing loss: 1.086145043373108
epoch 94800  training loss: 0.3138435184955597
epoch 94800  clean testing loss: 1.0862189531326294
epoch 94900  training loss: 0.31383267045021057

 95%|█████████▌| 95183/100000 [05:17<00:09, 516.17it/s]
epoch 95000  training loss: 0.3138217329978943
epoch 95000  clean testing loss: 1.0863525867462158
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...
epoch 95100  training loss: 0.3138108551502228
epoch 95100  clean testing loss: 1.0864313840866089
epoch 95200  training loss: 0.3138008713722229
epoch 95200  clean testing loss: 1.0864932537078857
epoch 95300  training loss: 0.3137900233268738
epoch 95300  clean testing loss: 1.0865576267242432
epoch 95400  training loss: 0.3137791156768799
epoch 95400  clean testing loss: 1.0866514444351196
epoch 95500  training loss: 0.31376880407333374
epoch 95500  clean testing loss: 1.0867046117782593
epoch 95600  training loss: 0.3137580156326294
epoch 95600  clean testing loss: 1.086777687072754
epoch 95700  training loss: 0.31374797224998474
epoch 95700  clean testing loss: 1.0868468284606934
epoch 95800  training loss: 0.3137369453907013
epoch 95800  clean testing loss: 1.0869029760360718
epoch 95900  training loss: 0.313726544380188
epoch 95900  clean testing loss: 1.0869847536087036
epoch 96000  training loss: 0.3137161135673523
epoch 96000  clean testing loss: 1.0870469808578491

 96%|█████████▌| 96100/100000 [05:19<00:12, 300.88it/s]
epoch 96100  training loss: 0.3137073516845703
epoch 96100  clean testing loss: 1.0870931148529053
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop0 ...