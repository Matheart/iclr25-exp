
  0%|          | 707/300000 [00:11<11:50, 421.07it/s]
epoch 0  training loss: 1.2079639434814453
epoch 0  clean testing loss: 0.5018214583396912
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 100  training loss: 0.8544462323188782
epoch 100  clean testing loss: 0.16133108735084534
epoch 200  training loss: 0.8034431338310242
epoch 200  clean testing loss: 0.11112099885940552
epoch 300  training loss: 0.7839948534965515
epoch 300  clean testing loss: 0.09954674541950226
epoch 400  training loss: 0.7635090351104736
epoch 400  clean testing loss: 0.09148404002189636
epoch 500  training loss: 0.7475839257240295
epoch 500  clean testing loss: 0.08995712548494339
epoch 600  training loss: 0.7365135550498962
epoch 600  clean testing loss: 0.09173090010881424
epoch 700  training loss: 0.7283977270126343

  1%|          | 1691/300000 [00:13<10:06, 491.94it/s]
epoch 800  training loss: 0.7208409309387207
epoch 800  clean testing loss: 0.09475470334291458
epoch 900  training loss: 0.7130083441734314
epoch 900  clean testing loss: 0.09542091935873032
epoch 1000  training loss: 0.704106330871582
epoch 1000  clean testing loss: 0.09659630060195923
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 1100  training loss: 0.6943093538284302
epoch 1100  clean testing loss: 0.09720496088266373
epoch 1200  training loss: 0.6838921308517456
epoch 1200  clean testing loss: 0.09883926063776016
epoch 1300  training loss: 0.6734664440155029
epoch 1300  clean testing loss: 0.10068310797214508
epoch 1400  training loss: 0.6628184914588928
epoch 1400  clean testing loss: 0.10098474472761154
epoch 1500  training loss: 0.651668131351471
epoch 1500  clean testing loss: 0.10381216555833817
epoch 1600  training loss: 0.6411709189414978
epoch 1600  clean testing loss: 0.10481187701225281
epoch 1700  training loss: 0.6297585964202881

  1%|          | 2723/300000 [00:15<09:48, 504.85it/s]
epoch 1800  training loss: 0.6188607215881348
epoch 1800  clean testing loss: 0.11166449636220932
epoch 1900  training loss: 0.6091411709785461
epoch 1900  clean testing loss: 0.11684808880090714
epoch 2000  training loss: 0.6010422706604004
epoch 2000  clean testing loss: 0.11738449335098267
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 2100  training loss: 0.5925642848014832
epoch 2100  clean testing loss: 0.12740680575370789
epoch 2200  training loss: 0.5846768021583557
epoch 2200  clean testing loss: 0.13047078251838684
epoch 2300  training loss: 0.5774654746055603
epoch 2300  clean testing loss: 0.1359703689813614
epoch 2400  training loss: 0.5697289109230042
epoch 2400  clean testing loss: 0.13515208661556244
epoch 2500  training loss: 0.5628547668457031
epoch 2500  clean testing loss: 0.1424005776643753
epoch 2600  training loss: 0.5560296177864075
epoch 2600  clean testing loss: 0.1456070840358734
epoch 2700  training loss: 0.549511730670929

  1%|          | 3707/300000 [00:17<09:45, 506.06it/s]
epoch 2800  training loss: 0.5433092713356018
epoch 2800  clean testing loss: 0.1520194709300995
epoch 2900  training loss: 0.5375989079475403
epoch 2900  clean testing loss: 0.15899482369422913
epoch 3000  training loss: 0.5336363315582275
epoch 3000  clean testing loss: 0.15746444463729858
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 3100  training loss: 0.5265979766845703
epoch 3100  clean testing loss: 0.16347037255764008
epoch 3200  training loss: 0.5217111706733704
epoch 3200  clean testing loss: 0.16692939400672913
epoch 3300  training loss: 0.5165712237358093
epoch 3300  clean testing loss: 0.16778913140296936
epoch 3400  training loss: 0.5118275880813599
epoch 3400  clean testing loss: 0.17543992400169373
epoch 3500  training loss: 0.5066951513290405
epoch 3500  clean testing loss: 0.17657391726970673
epoch 3600  training loss: 0.5028894543647766
epoch 3600  clean testing loss: 0.1777092069387436
epoch 3700  training loss: 0.497355192899704

  1%|▏         | 3968/300000 [00:17<09:36, 513.86it/s]
epoch 3800  training loss: 0.493045836687088
epoch 3800  clean testing loss: 0.19199858605861664
epoch 3900  training loss: 0.48926815390586853
epoch 3900  clean testing loss: 0.19721482694149017
epoch 4000  training loss: 0.48587238788604736

  2%|▏         | 4794/300000 [00:27<10:41, 459.87it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 4100  training loss: 0.4814366400241852
epoch 4100  clean testing loss: 0.20361477136611938
epoch 4200  training loss: 0.47558626532554626
epoch 4200  clean testing loss: 0.2021971195936203
epoch 4300  training loss: 0.4728763699531555
epoch 4300  clean testing loss: 0.20223993062973022
epoch 4400  training loss: 0.4694042503833771
epoch 4400  clean testing loss: 0.20521531999111176
epoch 4500  training loss: 0.46425750851631165
epoch 4500  clean testing loss: 0.20900046825408936
epoch 4600  training loss: 0.4604533016681671
epoch 4600  clean testing loss: 0.21218693256378174
epoch 4700  training loss: 0.4554901421070099
epoch 4700  clean testing loss: 0.21991367638111115
epoch 4800  training loss: 0.45292928814888

  2%|▏         | 5363/300000 [00:28<09:39, 508.43it/s]
epoch 4900  training loss: 0.4495323598384857
epoch 4900  clean testing loss: 0.23432466387748718
epoch 5000  training loss: 0.44625717401504517
epoch 5000  clean testing loss: 0.2395164966583252
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 5100  training loss: 0.4423135817050934
epoch 5100  clean testing loss: 0.2400699257850647
epoch 5200  training loss: 0.4374507665634155
epoch 5200  clean testing loss: 0.23845459520816803
epoch 5300  training loss: 0.43684473633766174
epoch 5300  clean testing loss: 0.24893471598625183
epoch 5400  training loss: 0.43256279826164246

  2%|▏         | 6249/300000 [00:31<17:57, 272.65it/s]
epoch 5500  training loss: 0.4279707372188568
epoch 5500  clean testing loss: 0.24966254830360413
epoch 5600  training loss: 0.4269510805606842
epoch 5600  clean testing loss: 0.2463700771331787
epoch 5700  training loss: 0.4233286380767822
epoch 5700  clean testing loss: 0.2577735185623169
epoch 5800  training loss: 0.42091304063796997
epoch 5800  clean testing loss: 0.26334619522094727
epoch 5900  training loss: 0.4160476326942444
epoch 5900  clean testing loss: 0.2610870599746704
epoch 6000  training loss: 0.41357746720314026
epoch 6000  clean testing loss: 0.26456812024116516
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 6100  training loss: 0.41096338629722595
epoch 6100  clean testing loss: 0.2643205225467682
epoch 6200  training loss: 0.4086417555809021

  2%|▏         | 7230/300000 [00:33<09:38, 506.28it/s]
epoch 6300  training loss: 0.4065661132335663
epoch 6300  clean testing loss: 0.26791462302207947
epoch 6400  training loss: 0.40400293469429016
epoch 6400  clean testing loss: 0.27693238854408264
epoch 6500  training loss: 0.40162697434425354
epoch 6500  clean testing loss: 0.27970975637435913
epoch 6600  training loss: 0.4009997248649597
epoch 6600  clean testing loss: 0.28639283776283264
epoch 6700  training loss: 0.3970473110675812
epoch 6700  clean testing loss: 0.2818525433540344
epoch 6800  training loss: 0.3949577212333679
epoch 6800  clean testing loss: 0.2837470769882202
epoch 6900  training loss: 0.3931868374347687
epoch 6900  clean testing loss: 0.2854388356208801
epoch 7000  training loss: 0.39262306690216064
epoch 7000  clean testing loss: 0.28704163432121277
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 7100  training loss: 0.38901081681251526
epoch 7100  clean testing loss: 0.2922344505786896
epoch 7200  training loss: 0.38686424493789673

  3%|▎         | 8266/300000 [00:35<09:32, 509.74it/s]
epoch 7300  training loss: 0.38506385684013367
epoch 7300  clean testing loss: 0.30231672525405884
epoch 7400  training loss: 0.38278883695602417
epoch 7400  clean testing loss: 0.30107927322387695
epoch 7500  training loss: 0.3833524286746979
epoch 7500  clean testing loss: 0.29904904961586
epoch 7600  training loss: 0.3791942894458771
epoch 7600  clean testing loss: 0.30443230271339417
epoch 7700  training loss: 0.3770405352115631
epoch 7700  clean testing loss: 0.307467520236969
epoch 7800  training loss: 0.37701064348220825
epoch 7800  clean testing loss: 0.30607038736343384
epoch 7900  training loss: 0.3740919530391693
epoch 7900  clean testing loss: 0.3087005019187927
epoch 8000  training loss: 0.3712579607963562
epoch 8000  clean testing loss: 0.3138219714164734
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 8100  training loss: 0.3694513738155365
epoch 8100  clean testing loss: 0.3170635998249054
epoch 8200  training loss: 0.36769387125968933

  3%|▎         | 9300/300000 [00:37<09:29, 510.82it/s]
epoch 8300  training loss: 0.366118848323822
epoch 8300  clean testing loss: 0.32238057255744934
epoch 8400  training loss: 0.3653874695301056
epoch 8400  clean testing loss: 0.3280090093612671
epoch 8500  training loss: 0.3637785017490387
epoch 8500  clean testing loss: 0.33261096477508545
epoch 8600  training loss: 0.3613515794277191
epoch 8600  clean testing loss: 0.32423925399780273
epoch 8700  training loss: 0.36006540060043335
epoch 8700  clean testing loss: 0.32497382164001465
epoch 8800  training loss: 0.35806894302368164
epoch 8800  clean testing loss: 0.3277037441730499
epoch 8900  training loss: 0.3563026785850525
epoch 8900  clean testing loss: 0.3287394046783447
epoch 9000  training loss: 0.3532143235206604
epoch 9000  clean testing loss: 0.3345679044723511
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 9100  training loss: 0.35158807039260864
epoch 9100  clean testing loss: 0.3375437259674072
epoch 9200  training loss: 0.3501266539096832
epoch 9200  clean testing loss: 0.33901458978652954
epoch 9300  training loss: 0.3486769497394562

  3%|▎         | 10287/300000 [00:39<09:26, 511.59it/s]
epoch 9400  training loss: 0.3474695682525635
epoch 9400  clean testing loss: 0.3408949673175812
epoch 9500  training loss: 0.34615522623062134
epoch 9500  clean testing loss: 0.34434938430786133
epoch 9600  training loss: 0.34405717253685
epoch 9600  clean testing loss: 0.3497568964958191
epoch 9700  training loss: 0.3424720764160156
epoch 9700  clean testing loss: 0.3513905704021454
epoch 9800  training loss: 0.34113556146621704
epoch 9800  clean testing loss: 0.35559865832328796
epoch 9900  training loss: 0.3397902250289917
epoch 9900  clean testing loss: 0.3536526560783386
epoch 10000  training loss: 0.33859536051750183
epoch 10000  clean testing loss: 0.3542397618293762
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 10100  training loss: 0.33682963252067566
epoch 10100  clean testing loss: 0.3552526831626892
epoch 10200  training loss: 0.3357127904891968
epoch 10200  clean testing loss: 0.35544300079345703
epoch 10300  training loss: 0.3335704803466797

  4%|▍         | 11325/300000 [00:41<09:27, 509.02it/s]
epoch 10400  training loss: 0.3318590223789215
epoch 10400  clean testing loss: 0.3619013726711273
epoch 10500  training loss: 0.33047640323638916
epoch 10500  clean testing loss: 0.36628809571266174
epoch 10600  training loss: 0.3291882574558258
epoch 10600  clean testing loss: 0.3664303123950958
epoch 10700  training loss: 0.3280903100967407
epoch 10700  clean testing loss: 0.3748626410961151
epoch 10800  training loss: 0.3263739049434662
epoch 10800  clean testing loss: 0.3737974464893341
epoch 10900  training loss: 0.3253188133239746
epoch 10900  clean testing loss: 0.3779088258743286
epoch 11000  training loss: 0.3248448669910431
epoch 11000  clean testing loss: 0.3824949562549591
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 11100  training loss: 0.3231181800365448
epoch 11100  clean testing loss: 0.3827187418937683
epoch 11200  training loss: 0.3209152817726135
epoch 11200  clean testing loss: 0.3781401216983795
epoch 11300  training loss: 0.3203916847705841

  4%|▍         | 12313/300000 [00:43<09:24, 509.66it/s]
epoch 11400  training loss: 0.3189197778701782
epoch 11400  clean testing loss: 0.37978658080101013
epoch 11500  training loss: 0.3187508285045624
epoch 11500  clean testing loss: 0.3797539174556732
epoch 11600  training loss: 0.3175468146800995
epoch 11600  clean testing loss: 0.3817403018474579
epoch 11700  training loss: 0.3156273365020752
epoch 11700  clean testing loss: 0.3835376799106598
epoch 11800  training loss: 0.31537288427352905
epoch 11800  clean testing loss: 0.39601191878318787
epoch 11900  training loss: 0.31292828917503357
epoch 11900  clean testing loss: 0.393643319606781
epoch 12000  training loss: 0.3130369484424591
epoch 12000  clean testing loss: 0.3975334167480469
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 12100  training loss: 0.3101344108581543
epoch 12100  clean testing loss: 0.3954178988933563
epoch 12200  training loss: 0.30913564562797546
epoch 12200  clean testing loss: 0.3968845009803772
epoch 12300  training loss: 0.3081223666667938

  4%|▍         | 13350/300000 [00:45<09:21, 510.13it/s]
epoch 12400  training loss: 0.3069039583206177
epoch 12400  clean testing loss: 0.39938709139823914
epoch 12500  training loss: 0.30645662546157837
epoch 12500  clean testing loss: 0.3988792896270752
epoch 12600  training loss: 0.3046312630176544
epoch 12600  clean testing loss: 0.40399232506752014
epoch 12700  training loss: 0.30416762828826904
epoch 12700  clean testing loss: 0.4032636880874634
epoch 12800  training loss: 0.30340471863746643
epoch 12800  clean testing loss: 0.404939204454422
epoch 12900  training loss: 0.3014892637729645
epoch 12900  clean testing loss: 0.40936270356178284
epoch 13000  training loss: 0.30086997151374817
epoch 13000  clean testing loss: 0.40917879343032837
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 13100  training loss: 0.2997739613056183
epoch 13100  clean testing loss: 0.4162426292896271
epoch 13200  training loss: 0.2997104525566101
epoch 13200  clean testing loss: 0.42246201634407043
epoch 13300  training loss: 0.29767757654190063

  5%|▍         | 14389/300000 [00:47<09:15, 514.16it/s]
epoch 13400  training loss: 0.29685819149017334
epoch 13400  clean testing loss: 0.4212047755718231
epoch 13500  training loss: 0.29732102155685425
epoch 13500  clean testing loss: 0.4297448396682739
epoch 13600  training loss: 0.29475709795951843
epoch 13600  clean testing loss: 0.4257064163684845
epoch 13700  training loss: 0.29386842250823975
epoch 13700  clean testing loss: 0.4241692125797272
epoch 13800  training loss: 0.2942710816860199
epoch 13800  clean testing loss: 0.42248696088790894
epoch 13900  training loss: 0.2930208742618561
epoch 13900  clean testing loss: 0.42481881380081177
epoch 14000  training loss: 0.2910696268081665
epoch 14000  clean testing loss: 0.4292212128639221
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 14100  training loss: 0.2908635437488556
epoch 14100  clean testing loss: 0.43699872493743896
epoch 14200  training loss: 0.2893264591693878
epoch 14200  clean testing loss: 0.4335712790489197
epoch 14300  training loss: 0.2895957827568054

  5%|▌         | 15370/300000 [00:49<09:15, 512.07it/s]
epoch 14400  training loss: 0.2876463532447815
epoch 14400  clean testing loss: 0.4358166456222534
epoch 14500  training loss: 0.28735530376434326
epoch 14500  clean testing loss: 0.44291335344314575
epoch 14600  training loss: 0.285993367433548
epoch 14600  clean testing loss: 0.4386546015739441
epoch 14700  training loss: 0.2869986891746521
epoch 14700  clean testing loss: 0.4356202483177185
epoch 14800  training loss: 0.2844696044921875
epoch 14800  clean testing loss: 0.43986257910728455
epoch 14900  training loss: 0.2847580015659332
epoch 14900  clean testing loss: 0.45115897059440613
epoch 15000  training loss: 0.28289923071861267
epoch 15000  clean testing loss: 0.4449450373649597
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 15100  training loss: 0.2819254994392395
epoch 15100  clean testing loss: 0.4469667077064514
epoch 15200  training loss: 0.2812407910823822
epoch 15200  clean testing loss: 0.448654443025589
epoch 15300  training loss: 0.2805377244949341
epoch 15300  clean testing loss: 0.44951459765434265
epoch 15400  training loss: 0.2798670828342438

  5%|▌         | 15889/300000 [00:50<09:15, 511.61it/s]
epoch 15500  training loss: 0.279268741607666
epoch 15500  clean testing loss: 0.454598605632782
epoch 15600  training loss: 0.27856552600860596
epoch 15600  clean testing loss: 0.456349641084671
epoch 15700  training loss: 0.2780976891517639
epoch 15700  clean testing loss: 0.46134090423583984
epoch 15800  training loss: 0.2769176661968231
epoch 15800  clean testing loss: 0.45948952436447144
epoch 15900  training loss: 0.27709949016571045

  5%|▌         | 16044/300000 [00:55<2:17:38, 34.38it/s]
epoch 16000  training loss: 0.27644068002700806
epoch 16000  clean testing loss: 0.45743778347969055

  6%|▌         | 16560/300000 [00:56<12:49, 368.23it/s]
epoch 16100  training loss: 0.27483069896698
epoch 16100  clean testing loss: 0.4611235558986664
epoch 16200  training loss: 0.2741159200668335
epoch 16200  clean testing loss: 0.4629139006137848
epoch 16300  training loss: 0.2734515368938446
epoch 16300  clean testing loss: 0.46516358852386475
epoch 16400  training loss: 0.2727552056312561
epoch 16400  clean testing loss: 0.4673742949962616
epoch 16500  training loss: 0.2727683484554291
epoch 16500  clean testing loss: 0.47396916151046753
epoch 16600  training loss: 0.27140626311302185

  6%|▌         | 17594/300000 [01:01<10:16, 457.78it/s]
epoch 16700  training loss: 0.27093300223350525
epoch 16700  clean testing loss: 0.4689400792121887
epoch 16800  training loss: 0.2700858414173126
epoch 16800  clean testing loss: 0.4735427498817444
epoch 16900  training loss: 0.2695954740047455
epoch 16900  clean testing loss: 0.47565150260925293
epoch 17000  training loss: 0.2694743573665619
epoch 17000  clean testing loss: 0.4796335995197296
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 17100  training loss: 0.268288791179657
epoch 17100  clean testing loss: 0.48011600971221924
epoch 17200  training loss: 0.26764988899230957
epoch 17200  clean testing loss: 0.477169394493103
epoch 17300  training loss: 0.26780396699905396
epoch 17300  clean testing loss: 0.4762507677078247
epoch 17400  training loss: 0.26705384254455566
epoch 17400  clean testing loss: 0.4770599901676178
epoch 17500  training loss: 0.2666187584400177
epoch 17500  clean testing loss: 0.4876718819141388
epoch 17600  training loss: 0.2654503881931305

  6%|▌         | 18633/300000 [01:03<09:10, 511.17it/s]
epoch 17700  training loss: 0.2650597095489502
epoch 17700  clean testing loss: 0.48202961683273315
epoch 17800  training loss: 0.263797789812088
epoch 17800  clean testing loss: 0.48737064003944397
epoch 17900  training loss: 0.26373597979545593
epoch 17900  clean testing loss: 0.4851513206958771
epoch 18000  training loss: 0.2625479996204376
epoch 18000  clean testing loss: 0.4897540509700775
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 18100  training loss: 0.2620076835155487
epoch 18100  clean testing loss: 0.4907016456127167
epoch 18200  training loss: 0.26155757904052734
epoch 18200  clean testing loss: 0.49263954162597656
epoch 18300  training loss: 0.26105183362960815
epoch 18300  clean testing loss: 0.49396616220474243
epoch 18400  training loss: 0.2606014013290405
epoch 18400  clean testing loss: 0.4950774908065796
epoch 18500  training loss: 0.2605644166469574
epoch 18500  clean testing loss: 0.4992867708206177
epoch 18600  training loss: 0.25998660922050476

  6%|▋         | 19415/300000 [01:05<09:13, 507.21it/s]
epoch 18700  training loss: 0.25944918394088745
epoch 18700  clean testing loss: 0.49494174122810364
epoch 18800  training loss: 0.2591700553894043
epoch 18800  clean testing loss: 0.49501705169677734
epoch 18900  training loss: 0.2587214410305023
epoch 18900  clean testing loss: 0.5038460493087769
epoch 19000  training loss: 0.2574118971824646
epoch 19000  clean testing loss: 0.4997982084751129
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 19100  training loss: 0.2569236755371094
epoch 19100  clean testing loss: 0.5009644627571106
epoch 19200  training loss: 0.2563673257827759
epoch 19200  clean testing loss: 0.502902090549469
epoch 19300  training loss: 0.25622498989105225
epoch 19300  clean testing loss: 0.5017749071121216
epoch 19400  training loss: 0.25530552864074707

  7%|▋         | 20249/300000 [01:17<10:31, 442.65it/s]
epoch 19500  training loss: 0.25478947162628174
epoch 19500  clean testing loss: 0.5070957541465759
epoch 19600  training loss: 0.2544923424720764
epoch 19600  clean testing loss: 0.5107719302177429
epoch 19700  training loss: 0.25439688563346863
epoch 19700  clean testing loss: 0.5142064690589905
epoch 19800  training loss: 0.25376543402671814
epoch 19800  clean testing loss: 0.5146007537841797
epoch 19900  training loss: 0.2531633675098419
epoch 19900  clean testing loss: 0.5165868997573853
epoch 20000  training loss: 0.25225746631622314
epoch 20000  clean testing loss: 0.5149009823799133
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 20100  training loss: 0.2519918382167816
epoch 20100  clean testing loss: 0.5124274492263794
epoch 20200  training loss: 0.2515268325805664
epoch 20200  clean testing loss: 0.519646942615509
epoch 20300  training loss: 0.2507365047931671

  7%|▋         | 21288/300000 [01:19<09:03, 512.43it/s]
epoch 20400  training loss: 0.2503850758075714
epoch 20400  clean testing loss: 0.516387939453125
epoch 20500  training loss: 0.25042974948883057
epoch 20500  clean testing loss: 0.5149912238121033
epoch 20600  training loss: 0.2498949021100998
epoch 20600  clean testing loss: 0.5164105296134949
epoch 20700  training loss: 0.24880433082580566
epoch 20700  clean testing loss: 0.5225133299827576
epoch 20800  training loss: 0.2483338862657547
epoch 20800  clean testing loss: 0.5217409133911133
epoch 20900  training loss: 0.2486550360918045
epoch 20900  clean testing loss: 0.5280219912528992
epoch 21000  training loss: 0.24738797545433044
epoch 21000  clean testing loss: 0.5243228077888489
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 21100  training loss: 0.2469433695077896
epoch 21100  clean testing loss: 0.524739146232605
epoch 21200  training loss: 0.24655872583389282
epoch 21200  clean testing loss: 0.5268335938453674
epoch 21300  training loss: 0.24620765447616577

  7%|▋         | 22329/300000 [01:21<09:05, 509.43it/s]
epoch 21400  training loss: 0.2456895262002945
epoch 21400  clean testing loss: 0.5274583101272583
epoch 21500  training loss: 0.24556443095207214
epoch 21500  clean testing loss: 0.5309874415397644
epoch 21600  training loss: 0.24496476352214813
epoch 21600  clean testing loss: 0.5271673798561096
epoch 21700  training loss: 0.24437636137008667
epoch 21700  clean testing loss: 0.5302678346633911
epoch 21800  training loss: 0.24398991465568542
epoch 21800  clean testing loss: 0.5318253636360168
epoch 21900  training loss: 0.24376840889453888
epoch 21900  clean testing loss: 0.5347314476966858
epoch 22000  training loss: 0.2434764802455902
epoch 22000  clean testing loss: 0.5371073484420776
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 22100  training loss: 0.24289384484291077
epoch 22100  clean testing loss: 0.5366776585578918
epoch 22200  training loss: 0.24241627752780914
epoch 22200  clean testing loss: 0.5371843576431274
epoch 22300  training loss: 0.24191103875637054

  8%|▊         | 23317/300000 [01:23<09:03, 509.02it/s]
epoch 22400  training loss: 0.24177896976470947
epoch 22400  clean testing loss: 0.5354142189025879
epoch 22500  training loss: 0.241501122713089
epoch 22500  clean testing loss: 0.535550057888031
epoch 22600  training loss: 0.2410193830728531
epoch 22600  clean testing loss: 0.5376665592193604
epoch 22700  training loss: 0.2407117784023285
epoch 22700  clean testing loss: 0.5380117297172546
epoch 22800  training loss: 0.24022121727466583
epoch 22800  clean testing loss: 0.53984534740448
epoch 22900  training loss: 0.23979075253009796
epoch 22900  clean testing loss: 0.5415763854980469
epoch 23000  training loss: 0.23912155628204346
epoch 23000  clean testing loss: 0.5469675660133362
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 23100  training loss: 0.23897571861743927
epoch 23100  clean testing loss: 0.5493538975715637
epoch 23200  training loss: 0.23827692866325378
epoch 23200  clean testing loss: 0.546393096446991
epoch 23300  training loss: 0.23811939358711243

  8%|▊         | 24300/300000 [01:25<09:17, 494.27it/s]
epoch 23400  training loss: 0.2379206269979477
epoch 23400  clean testing loss: 0.546339750289917
epoch 23500  training loss: 0.23751254379749298
epoch 23500  clean testing loss: 0.5471143126487732
epoch 23600  training loss: 0.23695474863052368
epoch 23600  clean testing loss: 0.5481055974960327
epoch 23700  training loss: 0.23629538714885712
epoch 23700  clean testing loss: 0.5523371696472168
epoch 23800  training loss: 0.23596717417240143
epoch 23800  clean testing loss: 0.5530480742454529
epoch 23900  training loss: 0.23599055409431458
epoch 23900  clean testing loss: 0.5507963299751282
epoch 24000  training loss: 0.23565328121185303
epoch 24000  clean testing loss: 0.5534730553627014
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 24100  training loss: 0.23484690487384796
epoch 24100  clean testing loss: 0.5557109713554382
epoch 24200  training loss: 0.2345348298549652
epoch 24200  clean testing loss: 0.5570313930511475
epoch 24300  training loss: 0.23428098857402802

  8%|▊         | 25333/300000 [01:27<08:59, 509.29it/s]
epoch 24400  training loss: 0.23389649391174316
epoch 24400  clean testing loss: 0.5592107772827148
epoch 24500  training loss: 0.2337198555469513
epoch 24500  clean testing loss: 0.5570876598358154
epoch 24600  training loss: 0.23327317833900452
epoch 24600  clean testing loss: 0.5600765943527222
epoch 24700  training loss: 0.23304249346256256
epoch 24700  clean testing loss: 0.5649169087409973
epoch 24800  training loss: 0.23251096904277802
epoch 24800  clean testing loss: 0.5637633204460144
epoch 24900  training loss: 0.23226985335350037
epoch 24900  clean testing loss: 0.5615107417106628
epoch 25000  training loss: 0.2318415641784668
epoch 25000  clean testing loss: 0.5641658306121826
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 25100  training loss: 0.23151953518390656
epoch 25100  clean testing loss: 0.5659491419792175
epoch 25200  training loss: 0.23140810430049896
epoch 25200  clean testing loss: 0.5689883232116699
epoch 25300  training loss: 0.231318399310112

  9%|▊         | 26164/300000 [01:29<08:59, 507.68it/s]
epoch 25400  training loss: 0.23078930377960205
epoch 25400  clean testing loss: 0.5656908750534058
epoch 25500  training loss: 0.2301865965127945
epoch 25500  clean testing loss: 0.5699474811553955
epoch 25600  training loss: 0.23024338483810425
epoch 25600  clean testing loss: 0.5738658905029297
epoch 25700  training loss: 0.22968415915966034
epoch 25700  clean testing loss: 0.5687495470046997
epoch 25800  training loss: 0.22932538390159607
epoch 25800  clean testing loss: 0.569442629814148
epoch 25900  training loss: 0.22889700531959534
epoch 25900  clean testing loss: 0.5721977949142456
epoch 26000  training loss: 0.2285892516374588
epoch 26000  clean testing loss: 0.574437141418457
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 26100  training loss: 0.22826378047466278
epoch 26100  clean testing loss: 0.5747748613357544
epoch 26200  training loss: 0.22792908549308777

  9%|▉         | 27144/300000 [01:35<09:11, 494.77it/s]
epoch 26300  training loss: 0.22775539755821228
epoch 26300  clean testing loss: 0.5748132467269897
epoch 26400  training loss: 0.22752149403095245
epoch 26400  clean testing loss: 0.5744802951812744
epoch 26500  training loss: 0.22702321410179138
epoch 26500  clean testing loss: 0.5785629749298096
epoch 26600  training loss: 0.22682514786720276
epoch 26600  clean testing loss: 0.5776505470275879
epoch 26700  training loss: 0.2265298217535019
epoch 26700  clean testing loss: 0.5833508372306824
epoch 26800  training loss: 0.2260594218969345
epoch 26800  clean testing loss: 0.5825725197792053
epoch 26900  training loss: 0.2261923849582672
epoch 26900  clean testing loss: 0.5783403515815735
epoch 27000  training loss: 0.22546778619289398
epoch 27000  clean testing loss: 0.58426433801651
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 27100  training loss: 0.2250513732433319

  9%|▉         | 28134/300000 [01:37<08:53, 509.61it/s]
epoch 27200  training loss: 0.22477249801158905
epoch 27200  clean testing loss: 0.5836736559867859
epoch 27300  training loss: 0.2244870662689209
epoch 27300  clean testing loss: 0.5843585133552551
epoch 27400  training loss: 0.22421833872795105
epoch 27400  clean testing loss: 0.5846241116523743
epoch 27500  training loss: 0.22404004633426666
epoch 27500  clean testing loss: 0.5842310786247253
epoch 27600  training loss: 0.22379228472709656
epoch 27600  clean testing loss: 0.5902331471443176
epoch 27700  training loss: 0.2233702540397644
epoch 27700  clean testing loss: 0.589394211769104
epoch 27800  training loss: 0.22301694750785828
epoch 27800  clean testing loss: 0.5889071226119995
epoch 27900  training loss: 0.22275196015834808
epoch 27900  clean testing loss: 0.5894930362701416
epoch 28000  training loss: 0.22266264259815216
epoch 28000  clean testing loss: 0.5885923504829407
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 28100  training loss: 0.22213980555534363

 10%|▉         | 29180/300000 [01:39<08:48, 512.60it/s]
epoch 28200  training loss: 0.22194065153598785
epoch 28200  clean testing loss: 0.5913422107696533
epoch 28300  training loss: 0.22168216109275818
epoch 28300  clean testing loss: 0.5953742265701294
epoch 28400  training loss: 0.2214251160621643
epoch 28400  clean testing loss: 0.597771406173706
epoch 28500  training loss: 0.2209668755531311
epoch 28500  clean testing loss: 0.5947719812393188
epoch 28600  training loss: 0.22091515362262726
epoch 28600  clean testing loss: 0.5942227840423584
epoch 28700  training loss: 0.2204064428806305
epoch 28700  clean testing loss: 0.5968132019042969
epoch 28800  training loss: 0.2201496809720993
epoch 28800  clean testing loss: 0.5980343818664551
epoch 28900  training loss: 0.2199820727109909
epoch 28900  clean testing loss: 0.5963327884674072
epoch 29000  training loss: 0.2198067307472229
epoch 29000  clean testing loss: 0.5970619916915894
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 29100  training loss: 0.21951980888843536

 10%|█         | 30167/300000 [01:41<08:47, 511.65it/s]
epoch 29200  training loss: 0.21936197578907013
epoch 29200  clean testing loss: 0.5983039736747742
epoch 29300  training loss: 0.218826025724411
epoch 29300  clean testing loss: 0.6037724614143372
epoch 29400  training loss: 0.21861326694488525
epoch 29400  clean testing loss: 0.6018027663230896
epoch 29500  training loss: 0.21830128133296967
epoch 29500  clean testing loss: 0.6032403111457825
epoch 29600  training loss: 0.21783922612667084
epoch 29600  clean testing loss: 0.6059933304786682
epoch 29700  training loss: 0.2175990790128708
epoch 29700  clean testing loss: 0.6078314185142517
epoch 29800  training loss: 0.21726325154304504
epoch 29800  clean testing loss: 0.6067034006118774
epoch 29900  training loss: 0.21697492897510529
epoch 29900  clean testing loss: 0.6074532866477966
epoch 30000  training loss: 0.21683014929294586
epoch 30000  clean testing loss: 0.6072063446044922
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 30100  training loss: 0.21644367277622223
epoch 30100  clean testing loss: 0.6094921231269836
epoch 30200  training loss: 0.2162107676267624

 10%|█         | 31158/300000 [01:43<08:47, 509.66it/s]
epoch 30300  training loss: 0.21596764028072357
epoch 30300  clean testing loss: 0.6110814213752747
epoch 30400  training loss: 0.2158268839120865
epoch 30400  clean testing loss: 0.6100454330444336
epoch 30500  training loss: 0.21551313996315002
epoch 30500  clean testing loss: 0.6118191480636597
epoch 30600  training loss: 0.2152746170759201
epoch 30600  clean testing loss: 0.611729621887207
epoch 30700  training loss: 0.21497973799705505
epoch 30700  clean testing loss: 0.6143427491188049
epoch 30800  training loss: 0.2147437483072281
epoch 30800  clean testing loss: 0.613289475440979
epoch 30900  training loss: 0.21448682248592377
epoch 30900  clean testing loss: 0.6153737902641296
epoch 31000  training loss: 0.21423044800758362
epoch 31000  clean testing loss: 0.6157962679862976
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 31100  training loss: 0.2140919417142868
epoch 31100  clean testing loss: 0.6179414391517639
epoch 31200  training loss: 0.21388746798038483

 11%|█         | 32196/300000 [01:45<08:43, 511.66it/s]
epoch 31300  training loss: 0.21347935497760773
epoch 31300  clean testing loss: 0.617168664932251
epoch 31400  training loss: 0.21319971978664398
epoch 31400  clean testing loss: 0.619047999382019
epoch 31500  training loss: 0.21292968094348907
epoch 31500  clean testing loss: 0.6185707449913025
epoch 31600  training loss: 0.21274563670158386
epoch 31600  clean testing loss: 0.6162307262420654
epoch 31700  training loss: 0.21239951252937317
epoch 31700  clean testing loss: 0.6187224388122559
epoch 31800  training loss: 0.21218009293079376
epoch 31800  clean testing loss: 0.620146632194519
epoch 31900  training loss: 0.21196000277996063
epoch 31900  clean testing loss: 0.6192616820335388
epoch 32000  training loss: 0.21172870695590973
epoch 32000  clean testing loss: 0.6198363304138184
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 32100  training loss: 0.21146593987941742
epoch 32100  clean testing loss: 0.6217211484909058
epoch 32200  training loss: 0.21126078069210052

 11%|█         | 33233/300000 [01:47<08:40, 512.63it/s]
epoch 32300  training loss: 0.21105298399925232
epoch 32300  clean testing loss: 0.6217647790908813
epoch 32400  training loss: 0.21083898842334747
epoch 32400  clean testing loss: 0.6259901523590088
epoch 32500  training loss: 0.21054938435554504
epoch 32500  clean testing loss: 0.625593900680542
epoch 32600  training loss: 0.2103157788515091
epoch 32600  clean testing loss: 0.6251932382583618
epoch 32700  training loss: 0.21015037596225739
epoch 32700  clean testing loss: 0.6251189112663269
epoch 32800  training loss: 0.2098778933286667
epoch 32800  clean testing loss: 0.6270191669464111
epoch 32900  training loss: 0.20973597466945648
epoch 32900  clean testing loss: 0.6288793087005615
epoch 33000  training loss: 0.20950745046138763
epoch 33000  clean testing loss: 0.6270527839660645
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 33100  training loss: 0.20923946797847748
epoch 33100  clean testing loss: 0.6287656426429749
epoch 33200  training loss: 0.2090482860803604

 11%|█         | 33390/300000 [01:48<08:37, 515.08it/s]
epoch 33300  training loss: 0.20889350771903992
epoch 33300  clean testing loss: 0.6291276812553406
epoch 33400  training loss: 0.20869965851306915

 11%|█▏        | 34330/300000 [02:01<09:23, 471.71it/s]
epoch 33500  training loss: 0.20851990580558777
epoch 33500  clean testing loss: 0.6332646608352661
epoch 33600  training loss: 0.20831279456615448
epoch 33600  clean testing loss: 0.6328298449516296
epoch 33700  training loss: 0.20816567540168762
epoch 33700  clean testing loss: 0.634308934211731
epoch 33800  training loss: 0.20787949860095978
epoch 33800  clean testing loss: 0.6331027150154114
epoch 33900  training loss: 0.2077353298664093
epoch 33900  clean testing loss: 0.6362525224685669
epoch 34000  training loss: 0.2075841724872589
epoch 34000  clean testing loss: 0.6374230980873108
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 34100  training loss: 0.20729954540729523
epoch 34100  clean testing loss: 0.6348867416381836
epoch 34200  training loss: 0.2071731686592102
epoch 34200  clean testing loss: 0.6356726884841919
epoch 34300  training loss: 0.20701852440834045

 12%|█▏        | 35325/300000 [02:03<08:38, 509.99it/s]
epoch 34400  training loss: 0.20669782161712646
epoch 34400  clean testing loss: 0.6375723481178284
epoch 34500  training loss: 0.2065228521823883
epoch 34500  clean testing loss: 0.6401199102401733
epoch 34600  training loss: 0.20630502700805664
epoch 34600  clean testing loss: 0.6388612389564514
epoch 34700  training loss: 0.20635642111301422
epoch 34700  clean testing loss: 0.6433082222938538
epoch 34800  training loss: 0.20592151582241058
epoch 34800  clean testing loss: 0.6408325433731079
epoch 34900  training loss: 0.20573517680168152
epoch 34900  clean testing loss: 0.6402899622917175
epoch 35000  training loss: 0.20553232729434967
epoch 35000  clean testing loss: 0.6425880789756775
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 35100  training loss: 0.20533841848373413
epoch 35100  clean testing loss: 0.6431412696838379
epoch 35200  training loss: 0.2052312046289444
epoch 35200  clean testing loss: 0.645503580570221
epoch 35300  training loss: 0.20503506064414978

 12%|█▏        | 36367/300000 [02:05<08:42, 504.93it/s]
epoch 35400  training loss: 0.20477044582366943
epoch 35400  clean testing loss: 0.6442866325378418
epoch 35500  training loss: 0.20463672280311584
epoch 35500  clean testing loss: 0.6466838717460632
epoch 35600  training loss: 0.20439237356185913
epoch 35600  clean testing loss: 0.6453149914741516
epoch 35700  training loss: 0.2042076140642166
epoch 35700  clean testing loss: 0.6480392217636108
epoch 35800  training loss: 0.2041083127260208
epoch 35800  clean testing loss: 0.6492856740951538
epoch 35900  training loss: 0.2038378119468689
epoch 35900  clean testing loss: 0.6468375325202942
epoch 36000  training loss: 0.20364172756671906
epoch 36000  clean testing loss: 0.6498807668685913
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 36100  training loss: 0.20344547927379608
epoch 36100  clean testing loss: 0.6497068405151367
epoch 36200  training loss: 0.2032962143421173
epoch 36200  clean testing loss: 0.6500303149223328
epoch 36300  training loss: 0.2031288892030716

 12%|█▏        | 37357/300000 [02:07<08:34, 510.29it/s]
epoch 36400  training loss: 0.20301681756973267
epoch 36400  clean testing loss: 0.6504693627357483
epoch 36500  training loss: 0.20283547043800354
epoch 36500  clean testing loss: 0.653589129447937
epoch 36600  training loss: 0.20268890261650085
epoch 36600  clean testing loss: 0.6542173027992249
epoch 36700  training loss: 0.20250771939754486
epoch 36700  clean testing loss: 0.6541567444801331
epoch 36800  training loss: 0.20231741666793823
epoch 36800  clean testing loss: 0.6555083394050598
epoch 36900  training loss: 0.20214055478572845
epoch 36900  clean testing loss: 0.6558352112770081
epoch 37000  training loss: 0.20194540917873383
epoch 37000  clean testing loss: 0.6553342342376709
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 37100  training loss: 0.20185518264770508
epoch 37100  clean testing loss: 0.6579622626304626
epoch 37200  training loss: 0.20166099071502686
epoch 37200  clean testing loss: 0.6550849676132202
epoch 37300  training loss: 0.2014668881893158
epoch 37300  clean testing loss: 0.6590914726257324
epoch 37400  training loss: 0.20130980014801025

 13%|█▎        | 37772/300000 [02:08<08:32, 511.22it/s]
epoch 37500  training loss: 0.20118938386440277
epoch 37500  clean testing loss: 0.6604246497154236
epoch 37600  training loss: 0.20105405151844025
epoch 37600  clean testing loss: 0.6576710343360901
epoch 37700  training loss: 0.20089365541934967
epoch 37700  clean testing loss: 0.6626326441764832
epoch 37800  training loss: 0.20060548186302185

 13%|█▎        | 38387/300000 [02:15<12:51, 339.03it/s]
epoch 37900  training loss: 0.20044410228729248
epoch 37900  clean testing loss: 0.6616689562797546
epoch 38000  training loss: 0.20030143857002258
epoch 38000  clean testing loss: 0.6614853739738464
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 38100  training loss: 0.20011745393276215
epoch 38100  clean testing loss: 0.6630444526672363
epoch 38200  training loss: 0.2000608742237091
epoch 38200  clean testing loss: 0.6652565598487854
epoch 38300  training loss: 0.19979988038539886
epoch 38300  clean testing loss: 0.6642153859138489
epoch 38400  training loss: 0.19970287382602692

 13%|█▎        | 39429/300000 [02:17<08:35, 505.75it/s]
epoch 38500  training loss: 0.19949592649936676
epoch 38500  clean testing loss: 0.6662858724594116
epoch 38600  training loss: 0.1993180364370346
epoch 38600  clean testing loss: 0.6657097935676575
epoch 38700  training loss: 0.19918590784072876
epoch 38700  clean testing loss: 0.6659890413284302
epoch 38800  training loss: 0.19906499981880188
epoch 38800  clean testing loss: 0.6653626561164856
epoch 38900  training loss: 0.19886106252670288
epoch 38900  clean testing loss: 0.6688101887702942
epoch 39000  training loss: 0.19876541197299957
epoch 39000  clean testing loss: 0.6675149202346802
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 39100  training loss: 0.19854989647865295
epoch 39100  clean testing loss: 0.6683038473129272
epoch 39200  training loss: 0.19841940701007843
epoch 39200  clean testing loss: 0.6687845587730408
epoch 39300  training loss: 0.1982848346233368
epoch 39300  clean testing loss: 0.6700232625007629
epoch 39400  training loss: 0.19814881682395935

 13%|█▎        | 40416/300000 [02:19<08:32, 506.31it/s]
epoch 39500  training loss: 0.19805258512496948
epoch 39500  clean testing loss: 0.6720183491706848
epoch 39600  training loss: 0.19786600768566132
epoch 39600  clean testing loss: 0.6713632941246033
epoch 39700  training loss: 0.1977367401123047
epoch 39700  clean testing loss: 0.67296302318573
epoch 39800  training loss: 0.1976316273212433
epoch 39800  clean testing loss: 0.6719726920127869
epoch 39900  training loss: 0.1974629908800125
epoch 39900  clean testing loss: 0.6740795969963074
epoch 40000  training loss: 0.1973387449979782
epoch 40000  clean testing loss: 0.673132598400116
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 40100  training loss: 0.19717255234718323
epoch 40100  clean testing loss: 0.6746243834495544
epoch 40200  training loss: 0.19705821573734283
epoch 40200  clean testing loss: 0.6767483353614807
epoch 40300  training loss: 0.19690079987049103
epoch 40300  clean testing loss: 0.6766029596328735
epoch 40400  training loss: 0.19674508273601532

 14%|█▍        | 41459/300000 [02:21<08:25, 511.69it/s]
epoch 40500  training loss: 0.19664402306079865
epoch 40500  clean testing loss: 0.6766641736030579
epoch 40600  training loss: 0.1965300738811493
epoch 40600  clean testing loss: 0.6767561435699463
epoch 40700  training loss: 0.19633308053016663
epoch 40700  clean testing loss: 0.6785954236984253
epoch 40800  training loss: 0.19623136520385742
epoch 40800  clean testing loss: 0.6781857013702393
epoch 40900  training loss: 0.19611218571662903
epoch 40900  clean testing loss: 0.6815354824066162
epoch 41000  training loss: 0.19596046209335327
epoch 41000  clean testing loss: 0.6791134476661682
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 41100  training loss: 0.1958068609237671
epoch 41100  clean testing loss: 0.6820859909057617
epoch 41200  training loss: 0.19567935168743134
epoch 41200  clean testing loss: 0.6807405948638916
epoch 41300  training loss: 0.1955215036869049
epoch 41300  clean testing loss: 0.6824591755867004
epoch 41400  training loss: 0.1954394280910492

 14%|█▍        | 41773/300000 [02:22<08:23, 512.77it/s]
epoch 41500  training loss: 0.19527661800384521
epoch 41500  clean testing loss: 0.6838065385818481
epoch 41600  training loss: 0.1951165497303009
epoch 41600  clean testing loss: 0.6844717264175415
epoch 41700  training loss: 0.19502566754817963
epoch 41700  clean testing loss: 0.6860009431838989
epoch 41800  training loss: 0.1948792189359665

 14%|█▍        | 42295/300000 [02:33<18:46, 228.75it/s]
epoch 41900  training loss: 0.1947244256734848
epoch 41900  clean testing loss: 0.6865191459655762
epoch 42000  training loss: 0.19461657106876373
epoch 42000  clean testing loss: 0.6858354210853577
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 42100  training loss: 0.19447685778141022
epoch 42100  clean testing loss: 0.6866128444671631
epoch 42200  training loss: 0.19436216354370117
epoch 42200  clean testing loss: 0.6875737905502319
epoch 42300  training loss: 0.19425523281097412

 14%|█▍        | 43288/300000 [02:35<08:19, 514.25it/s]
epoch 42400  training loss: 0.19414277374744415
epoch 42400  clean testing loss: 0.6882451772689819
epoch 42500  training loss: 0.19402271509170532
epoch 42500  clean testing loss: 0.6885396838188171
epoch 42600  training loss: 0.1939060091972351
epoch 42600  clean testing loss: 0.6901882290840149
epoch 42700  training loss: 0.19378800690174103
epoch 42700  clean testing loss: 0.6898732781410217
epoch 42800  training loss: 0.1936919391155243
epoch 42800  clean testing loss: 0.6918116211891174
epoch 42900  training loss: 0.1935519427061081
epoch 42900  clean testing loss: 0.691636323928833
epoch 43000  training loss: 0.1934378743171692
epoch 43000  clean testing loss: 0.6909958124160767
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 43100  training loss: 0.19331501424312592
epoch 43100  clean testing loss: 0.6925402879714966
epoch 43200  training loss: 0.19319163262844086
epoch 43200  clean testing loss: 0.6927000880241394
epoch 43300  training loss: 0.19307290017604828

 15%|█▍        | 44332/300000 [02:37<08:21, 509.42it/s]
epoch 43400  training loss: 0.1929599642753601
epoch 43400  clean testing loss: 0.6933326721191406
epoch 43500  training loss: 0.19284123182296753
epoch 43500  clean testing loss: 0.6948720812797546
epoch 43600  training loss: 0.19271790981292725
epoch 43600  clean testing loss: 0.6950697302818298
epoch 43700  training loss: 0.19260770082473755
epoch 43700  clean testing loss: 0.6952288150787354
epoch 43800  training loss: 0.19250959157943726
epoch 43800  clean testing loss: 0.6971584558486938
epoch 43900  training loss: 0.19235968589782715
epoch 43900  clean testing loss: 0.6967446804046631
epoch 44000  training loss: 0.19226661324501038
epoch 44000  clean testing loss: 0.696306049823761
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 44100  training loss: 0.19215042889118195
epoch 44100  clean testing loss: 0.6964578032493591
epoch 44200  training loss: 0.19202902913093567
epoch 44200  clean testing loss: 0.6989443302154541
epoch 44300  training loss: 0.19189149141311646

 15%|█▌        | 45320/300000 [02:39<08:21, 507.89it/s]
epoch 44400  training loss: 0.19177646934986115
epoch 44400  clean testing loss: 0.7000308632850647
epoch 44500  training loss: 0.19167335331439972
epoch 44500  clean testing loss: 0.6987385749816895
epoch 44600  training loss: 0.19153395295143127
epoch 44600  clean testing loss: 0.7003996968269348
epoch 44700  training loss: 0.19140970706939697
epoch 44700  clean testing loss: 0.6997537016868591
epoch 44800  training loss: 0.19129137694835663
epoch 44800  clean testing loss: 0.7018641233444214
epoch 44900  training loss: 0.19118498265743256
epoch 44900  clean testing loss: 0.7005182504653931
epoch 45000  training loss: 0.1910419762134552
epoch 45000  clean testing loss: 0.7020218372344971
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 45100  training loss: 0.19093790650367737
epoch 45100  clean testing loss: 0.7021927833557129
epoch 45200  training loss: 0.19084018468856812
epoch 45200  clean testing loss: 0.7030534148216248
epoch 45300  training loss: 0.19074232876300812

 15%|█▌        | 45684/300000 [02:40<08:18, 510.43it/s]
epoch 45400  training loss: 0.19063182175159454
epoch 45400  clean testing loss: 0.7040154337882996
epoch 45500  training loss: 0.19053475558757782
epoch 45500  clean testing loss: 0.7046302556991577
epoch 45600  training loss: 0.1904202103614807
epoch 45600  clean testing loss: 0.7048187255859375
epoch 45700  training loss: 0.19033239781856537

 15%|█▌        | 46401/300000 [02:45<09:43, 434.58it/s]
epoch 45800  training loss: 0.19020916521549225
epoch 45800  clean testing loss: 0.7064260244369507
epoch 45900  training loss: 0.1901080161333084
epoch 45900  clean testing loss: 0.7066068649291992
epoch 46000  training loss: 0.1900009661912918
epoch 46000  clean testing loss: 0.7061887979507446
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 46100  training loss: 0.18991391360759735
epoch 46100  clean testing loss: 0.7063497304916382
epoch 46200  training loss: 0.18978583812713623
epoch 46200  clean testing loss: 0.7076060175895691
epoch 46300  training loss: 0.18968844413757324
epoch 46300  clean testing loss: 0.7075093388557434
epoch 46400  training loss: 0.18959219753742218

 16%|█▌        | 47390/300000 [02:47<08:12, 513.04it/s]
epoch 46500  training loss: 0.18947511911392212
epoch 46500  clean testing loss: 0.7094375491142273
epoch 46600  training loss: 0.18940822780132294
epoch 46600  clean testing loss: 0.7087576985359192
epoch 46700  training loss: 0.18928876519203186
epoch 46700  clean testing loss: 0.7094694375991821
epoch 46800  training loss: 0.18918107450008392
epoch 46800  clean testing loss: 0.7115001082420349
epoch 46900  training loss: 0.18907003104686737
epoch 46900  clean testing loss: 0.7105873823165894
epoch 47000  training loss: 0.188982293009758
epoch 47000  clean testing loss: 0.7107846140861511
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 47100  training loss: 0.18887101113796234
epoch 47100  clean testing loss: 0.7126327753067017
epoch 47200  training loss: 0.18877078592777252
epoch 47200  clean testing loss: 0.7135846018791199
epoch 47300  training loss: 0.18865393102169037
epoch 47300  clean testing loss: 0.7137214541435242
epoch 47400  training loss: 0.18858496844768524

 16%|█▌        | 48433/300000 [02:49<08:15, 508.11it/s]
epoch 47500  training loss: 0.18846248090267181
epoch 47500  clean testing loss: 0.7150550484657288
epoch 47600  training loss: 0.18836675584316254
epoch 47600  clean testing loss: 0.7140160202980042
epoch 47700  training loss: 0.1882553994655609
epoch 47700  clean testing loss: 0.7145016193389893
epoch 47800  training loss: 0.1881500631570816
epoch 47800  clean testing loss: 0.7150481343269348
epoch 47900  training loss: 0.1880505084991455
epoch 47900  clean testing loss: 0.7163534164428711
epoch 48000  training loss: 0.18794721364974976
epoch 48000  clean testing loss: 0.7160301804542542
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 48100  training loss: 0.18785417079925537
epoch 48100  clean testing loss: 0.716949999332428
epoch 48200  training loss: 0.18776969611644745
epoch 48200  clean testing loss: 0.7172801494598389
epoch 48300  training loss: 0.18768885731697083
epoch 48300  clean testing loss: 0.7173795700073242
epoch 48400  training loss: 0.1875963807106018

 16%|█▋        | 49425/300000 [02:51<08:10, 510.46it/s]
epoch 48500  training loss: 0.18750907480716705
epoch 48500  clean testing loss: 0.7182080149650574
epoch 48600  training loss: 0.18742524087429047
epoch 48600  clean testing loss: 0.7193764448165894
epoch 48700  training loss: 0.18734107911586761
epoch 48700  clean testing loss: 0.7188622355461121
epoch 48800  training loss: 0.18723498284816742
epoch 48800  clean testing loss: 0.7195190787315369
epoch 48900  training loss: 0.1871529072523117
epoch 48900  clean testing loss: 0.7196808457374573
epoch 49000  training loss: 0.1870548576116562
epoch 49000  clean testing loss: 0.7209997773170471
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 49100  training loss: 0.18696469068527222
epoch 49100  clean testing loss: 0.7213889360427856
epoch 49200  training loss: 0.18688496947288513
epoch 49200  clean testing loss: 0.7211529612541199
epoch 49300  training loss: 0.18679800629615784
epoch 49300  clean testing loss: 0.7223528027534485
epoch 49400  training loss: 0.18671207129955292

 17%|█▋        | 50469/300000 [02:53<08:06, 512.53it/s]
epoch 49500  training loss: 0.1866137832403183
epoch 49500  clean testing loss: 0.7231136560440063
epoch 49600  training loss: 0.18653933703899384
epoch 49600  clean testing loss: 0.7229297161102295
epoch 49700  training loss: 0.18643958866596222
epoch 49700  clean testing loss: 0.7236623167991638
epoch 49800  training loss: 0.18635326623916626
epoch 49800  clean testing loss: 0.7241504192352295
epoch 49900  training loss: 0.18627989292144775
epoch 49900  clean testing loss: 0.724443793296814
epoch 50000  training loss: 0.18618997931480408
epoch 50000  clean testing loss: 0.7249488830566406
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 50100  training loss: 0.1860998123884201
epoch 50100  clean testing loss: 0.7257713675498962
epoch 50200  training loss: 0.18601033091545105
epoch 50200  clean testing loss: 0.7258973717689514
epoch 50300  training loss: 0.18592654168605804
epoch 50300  clean testing loss: 0.7261556386947632
epoch 50400  training loss: 0.18584394454956055
epoch 50400  clean testing loss: 0.7270932793617249
epoch 50500  training loss: 0.1857730746269226

 17%|█▋        | 51459/300000 [02:55<08:05, 511.46it/s]
epoch 50600  training loss: 0.18567584455013275
epoch 50600  clean testing loss: 0.7280930280685425
epoch 50700  training loss: 0.18560691177845
epoch 50700  clean testing loss: 0.729335367679596
epoch 50800  training loss: 0.1855035424232483
epoch 50800  clean testing loss: 0.7284762263298035
epoch 50900  training loss: 0.1854369193315506
epoch 50900  clean testing loss: 0.7297439575195312
epoch 51000  training loss: 0.18533070385456085
epoch 51000  clean testing loss: 0.7296215295791626
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 51100  training loss: 0.18525584042072296
epoch 51100  clean testing loss: 0.7301702499389648
epoch 51200  training loss: 0.1851881593465805
epoch 51200  clean testing loss: 0.7302374839782715
epoch 51300  training loss: 0.18511676788330078
epoch 51300  clean testing loss: 0.7308090329170227
epoch 51400  training loss: 0.18504612147808075
epoch 51400  clean testing loss: 0.7316007614135742
epoch 51500  training loss: 0.1849670708179474

 17%|█▋        | 52490/300000 [02:57<08:02, 512.88it/s]
epoch 51600  training loss: 0.18490055203437805
epoch 51600  clean testing loss: 0.7323777079582214
epoch 51700  training loss: 0.18482622504234314
epoch 51700  clean testing loss: 0.7329887747764587
epoch 51800  training loss: 0.18474799394607544
epoch 51800  clean testing loss: 0.7331223487854004
epoch 51900  training loss: 0.18467791378498077
epoch 51900  clean testing loss: 0.732913613319397
epoch 52000  training loss: 0.18459773063659668
epoch 52000  clean testing loss: 0.7332183122634888
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 52100  training loss: 0.1845325380563736
epoch 52100  clean testing loss: 0.7333265542984009
epoch 52200  training loss: 0.18444746732711792
epoch 52200  clean testing loss: 0.7341948747634888
epoch 52300  training loss: 0.1843765527009964
epoch 52300  clean testing loss: 0.7350009083747864
epoch 52400  training loss: 0.18430009484291077
epoch 52400  clean testing loss: 0.7348901033401489
epoch 52500  training loss: 0.1842234581708908

 18%|█▊        | 53476/300000 [02:59<08:01, 511.76it/s]
epoch 52600  training loss: 0.18414631485939026
epoch 52600  clean testing loss: 0.7356747388839722
epoch 52700  training loss: 0.18407364189624786
epoch 52700  clean testing loss: 0.7367209196090698
epoch 52800  training loss: 0.18399344384670258
epoch 52800  clean testing loss: 0.7367821335792542
epoch 52900  training loss: 0.18392571806907654
epoch 52900  clean testing loss: 0.7376163005828857
epoch 53000  training loss: 0.1838522106409073
epoch 53000  clean testing loss: 0.7375050187110901
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 53100  training loss: 0.18377719819545746
epoch 53100  clean testing loss: 0.7376765012741089
epoch 53200  training loss: 0.183700293302536
epoch 53200  clean testing loss: 0.7382988929748535
epoch 53300  training loss: 0.18363229930400848
epoch 53300  clean testing loss: 0.7394660711288452
epoch 53400  training loss: 0.18355108797550201
epoch 53400  clean testing loss: 0.7395619750022888
epoch 53500  training loss: 0.18347974121570587

 18%|█▊        | 54517/300000 [03:01<08:00, 510.86it/s]
epoch 53600  training loss: 0.18341153860092163
epoch 53600  clean testing loss: 0.740684986114502
epoch 53700  training loss: 0.18333351612091064
epoch 53700  clean testing loss: 0.7399465441703796
epoch 53800  training loss: 0.183258518576622
epoch 53800  clean testing loss: 0.7408242225646973
epoch 53900  training loss: 0.18319666385650635
epoch 53900  clean testing loss: 0.7419746518135071
epoch 54000  training loss: 0.18311260640621185
epoch 54000  clean testing loss: 0.7418475151062012
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 54100  training loss: 0.1830516755580902
epoch 54100  clean testing loss: 0.7416821718215942
epoch 54200  training loss: 0.18299371004104614
epoch 54200  clean testing loss: 0.7421293258666992
epoch 54300  training loss: 0.18293257057666779
epoch 54300  clean testing loss: 0.7431427240371704
epoch 54400  training loss: 0.1828671395778656
epoch 54400  clean testing loss: 0.7429932355880737
epoch 54500  training loss: 0.18280598521232605

 19%|█▊        | 55510/300000 [03:03<07:57, 511.51it/s]
epoch 54600  training loss: 0.18274210393428802
epoch 54600  clean testing loss: 0.7440977692604065
epoch 54700  training loss: 0.1826772838830948
epoch 54700  clean testing loss: 0.7438929080963135
epoch 54800  training loss: 0.18261143565177917
epoch 54800  clean testing loss: 0.7441775798797607
epoch 54900  training loss: 0.1825515180826187
epoch 54900  clean testing loss: 0.7442439198493958
epoch 55000  training loss: 0.18247883021831512
epoch 55000  clean testing loss: 0.7450896501541138
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 55100  training loss: 0.18241353332996368
epoch 55100  clean testing loss: 0.7457992434501648
epoch 55200  training loss: 0.18234869837760925
epoch 55200  clean testing loss: 0.7454593777656555
epoch 55300  training loss: 0.18228362500667572
epoch 55300  clean testing loss: 0.746680498123169
epoch 55400  training loss: 0.18221986293792725
epoch 55400  clean testing loss: 0.7468655109405518
epoch 55500  training loss: 0.18216349184513092

 19%|█▊        | 55876/300000 [03:04<07:56, 512.07it/s]
epoch 55600  training loss: 0.18210053443908691
epoch 55600  clean testing loss: 0.7466438412666321
epoch 55700  training loss: 0.18202805519104004
epoch 55700  clean testing loss: 0.7476990222930908
epoch 55800  training loss: 0.18197001516819
epoch 55800  clean testing loss: 0.7485601305961609
epoch 55900  training loss: 0.18190045654773712

 19%|█▊        | 56085/300000 [03:15<3:05:57, 21.86it/s]
epoch 56000  training loss: 0.18183615803718567
epoch 56000  clean testing loss: 0.7487334609031677
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 56100  training loss: 0.18177488446235657

 19%|█▉        | 57129/300000 [03:17<08:05, 500.67it/s]
epoch 56200  training loss: 0.18171341717243195
epoch 56200  clean testing loss: 0.7490772008895874
epoch 56300  training loss: 0.18165117502212524
epoch 56300  clean testing loss: 0.7496199607849121
epoch 56400  training loss: 0.18158474564552307
epoch 56400  clean testing loss: 0.7498818635940552
epoch 56500  training loss: 0.18152213096618652
epoch 56500  clean testing loss: 0.750166118144989
epoch 56600  training loss: 0.1814577281475067
epoch 56600  clean testing loss: 0.7508191466331482
epoch 56700  training loss: 0.18140262365341187
epoch 56700  clean testing loss: 0.7507450580596924
epoch 56800  training loss: 0.18132883310317993
epoch 56800  clean testing loss: 0.7513952255249023
epoch 56900  training loss: 0.1812703013420105
epoch 56900  clean testing loss: 0.7515931725502014
epoch 57000  training loss: 0.18120476603507996
epoch 57000  clean testing loss: 0.7522940635681152
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 57100  training loss: 0.1811511516571045

 19%|█▉        | 57600/300000 [03:18<07:51, 514.11it/s]
epoch 57200  training loss: 0.18109868466854095
epoch 57200  clean testing loss: 0.7531431317329407
epoch 57300  training loss: 0.18104790151119232
epoch 57300  clean testing loss: 0.7536026835441589
epoch 57400  training loss: 0.18099328875541687
epoch 57400  clean testing loss: 0.7533421516418457
epoch 57500  training loss: 0.18094071745872498
epoch 57500  clean testing loss: 0.7536786794662476
epoch 57600  training loss: 0.1808834820985794

 19%|█▉        | 58170/300000 [03:21<09:39, 417.32it/s]
epoch 57700  training loss: 0.18083201348781586
epoch 57700  clean testing loss: 0.7548761367797852
epoch 57800  training loss: 0.18077443540096283
epoch 57800  clean testing loss: 0.7545633912086487
epoch 57900  training loss: 0.18071961402893066
epoch 57900  clean testing loss: 0.7555313110351562
epoch 58000  training loss: 0.18066559731960297
epoch 58000  clean testing loss: 0.7553997039794922
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 58100  training loss: 0.18061023950576782
epoch 58100  clean testing loss: 0.7560051679611206
epoch 58200  training loss: 0.1805567741394043

 20%|█▉        | 59211/300000 [03:23<07:54, 507.25it/s]
epoch 58300  training loss: 0.18049903213977814
epoch 58300  clean testing loss: 0.756523609161377
epoch 58400  training loss: 0.18044830858707428
epoch 58400  clean testing loss: 0.7571909427642822
epoch 58500  training loss: 0.18038977682590485
epoch 58500  clean testing loss: 0.7573177814483643
epoch 58600  training loss: 0.18033669888973236
epoch 58600  clean testing loss: 0.757043182849884
epoch 58700  training loss: 0.18028004467487335
epoch 58700  clean testing loss: 0.7575211524963379
epoch 58800  training loss: 0.1802309900522232
epoch 58800  clean testing loss: 0.7576044201850891
epoch 58900  training loss: 0.18017087876796722
epoch 58900  clean testing loss: 0.7586261034011841
epoch 59000  training loss: 0.18011674284934998
epoch 59000  clean testing loss: 0.7584973573684692
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 59100  training loss: 0.180059015750885
epoch 59100  clean testing loss: 0.7587453126907349
epoch 59200  training loss: 0.1800045222043991

 20%|██        | 60253/300000 [03:25<07:53, 506.83it/s]
epoch 59300  training loss: 0.17995530366897583
epoch 59300  clean testing loss: 0.7601191997528076
epoch 59400  training loss: 0.17989563941955566
epoch 59400  clean testing loss: 0.7598547339439392
epoch 59500  training loss: 0.17983923852443695
epoch 59500  clean testing loss: 0.7603720426559448
epoch 59600  training loss: 0.17978861927986145
epoch 59600  clean testing loss: 0.7603532075881958
epoch 59700  training loss: 0.17973259091377258
epoch 59700  clean testing loss: 0.7611204981803894
epoch 59800  training loss: 0.17967955768108368
epoch 59800  clean testing loss: 0.7616256475448608
epoch 59900  training loss: 0.1796303242444992
epoch 59900  clean testing loss: 0.7620453238487244
epoch 60000  training loss: 0.1795721799135208
epoch 60000  clean testing loss: 0.7617046236991882
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 60100  training loss: 0.17952251434326172
epoch 60100  clean testing loss: 0.7620134353637695
epoch 60200  training loss: 0.17947879433631897

 20%|██        | 61200/300000 [03:27<13:30, 294.78it/s]
epoch 60300  training loss: 0.17943426966667175
epoch 60300  clean testing loss: 0.7627195119857788
epoch 60400  training loss: 0.17938873171806335
epoch 60400  clean testing loss: 0.7628291249275208
epoch 60500  training loss: 0.17934255301952362
epoch 60500  clean testing loss: 0.7633646130561829
epoch 60600  training loss: 0.17929813265800476
epoch 60600  clean testing loss: 0.7633745670318604
epoch 60700  training loss: 0.1792515367269516
epoch 60700  clean testing loss: 0.7635706067085266
epoch 60800  training loss: 0.1792045682668686
epoch 60800  clean testing loss: 0.7639000415802002
epoch 60900  training loss: 0.17915920913219452
epoch 60900  clean testing loss: 0.7648717761039734
epoch 61000  training loss: 0.17911173403263092
epoch 61000  clean testing loss: 0.7649993896484375
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...
epoch 61100  training loss: 0.17906305193901062
epoch 61100  clean testing loss: 0.7652494311332703
epoch 61200  training loss: 0.1790156364440918
epoch 61200  clean testing loss: 0.7653770446777344
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise7.00e-01_invop0 ...