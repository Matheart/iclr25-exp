
  0%|                                                             | 197/300000 [00:04<1:54:32, 43.62it/s]
epoch 0  training loss: 0.6112536787986755
epoch 0  clean testing loss: 0.4627951383590698
epoch 100  training loss: 0.11646666377782822
epoch 100  clean testing loss: 0.023091081529855728
epoch 200  training loss: 0.12262029200792313


  0%|                                                             | 377/300000 [00:08<1:56:01, 43.04it/s]
epoch 300  training loss: 0.12954117357730865

  0%|                                                             | 463/300000 [00:10<1:53:11, 44.11it/s]
epoch 400  training loss: 0.1205964982509613

  0%|                                                             | 498/300000 [00:11<1:56:17, 42.92it/s]
epoch 500  training loss: 0.11288095265626907

  0%|▏                                                            | 962/300000 [00:22<1:54:56, 43.36it/s]
epoch 600  training loss: 0.2741139531135559
epoch 600  clean testing loss: 0.11544518917798996
epoch 700  training loss: 0.09625020623207092
epoch 700  clean testing loss: 0.026569539681077003
epoch 800  training loss: 0.09822659939527512
epoch 800  clean testing loss: 0.04755692556500435
epoch 900  training loss: 0.08408233523368835

  0%|▏                                                           | 1048/300000 [00:24<1:54:40, 43.45it/s]
epoch 1000  training loss: 0.0836782231926918

  0%|▏                                                           | 1133/300000 [00:26<1:54:06, 43.65it/s]
epoch 1100  training loss: 0.09791867434978485

  0%|▏                                                           | 1198/300000 [00:27<1:55:05, 43.27it/s]
epoch 1200  training loss: 0.1386609524488449

  1%|▎                                                           | 1567/300000 [00:36<1:54:01, 43.62it/s]
epoch 1300  training loss: 0.1075843870639801
epoch 1300  clean testing loss: 0.03097771294414997
epoch 1400  training loss: 0.08620581030845642
epoch 1400  clean testing loss: 0.020934345200657845
epoch 1500  training loss: 0.08599327504634857
epoch 1500  clean testing loss: 0.020535286515951157
epoch 1600  training loss: 0.10814286768436432

  1%|▎                                                           | 1658/300000 [00:38<1:54:59, 43.24it/s]
epoch 1700  training loss: 0.08763028681278229

  1%|▎                                                           | 1698/300000 [00:39<1:53:56, 43.64it/s]
epoch 1800  training loss: 0.11030690371990204
epoch 1800  clean testing loss: 0.028068356215953827
epoch 1900  training loss: 0.13804276287555695

  1%|▍                                                           | 1977/300000 [00:45<1:53:17, 43.84it/s]
epoch 2000  training loss: 0.09287980943918228

  1%|▍                                                           | 2068/300000 [00:47<1:55:21, 43.05it/s]
epoch 2100  training loss: 0.20102034509181976

  1%|▍                                                           | 2433/300000 [00:56<1:52:09, 44.22it/s]
epoch 2200  training loss: 0.08769235014915466
epoch 2200  clean testing loss: 0.031945034861564636
epoch 2300  training loss: 0.10562983900308609
epoch 2300  clean testing loss: 0.030046816915273666
epoch 2400  training loss: 0.08132952451705933

  1%|▌                                                           | 2512/300000 [00:58<1:49:30, 45.28it/s]
epoch 2500  training loss: 0.11358089745044708

  1%|▌                                                           | 2602/300000 [01:00<2:27:16, 33.66it/s]
epoch 2600  training loss: 0.08446267247200012

  1%|▌                                                           | 2693/300000 [01:02<1:54:14, 43.37it/s]
epoch 2700  training loss: 0.1053544208407402


  1%|▌                                                           | 2863/300000 [01:06<1:53:55, 43.47it/s]
epoch 2800  training loss: 0.07828523963689804

  1%|▌                                                           | 2952/300000 [01:08<1:54:26, 43.26it/s]
epoch 2900  training loss: 0.12479341775178909
epoch 2900  clean testing loss: 0.0444062203168869
epoch 3000  training loss: 0.0844942033290863

  1%|▌                                                           | 3038/300000 [01:10<1:52:51, 43.86it/s]
epoch 3100  training loss: 0.07553672790527344

  1%|▋                                                           | 3127/300000 [01:12<1:52:33, 43.96it/s]
epoch 3200  training loss: 0.09553460031747818

  1%|▋                                                           | 3212/300000 [01:14<1:46:41, 46.36it/s]
epoch 3300  training loss: 0.07558366656303406


  1%|▋                                                           | 3387/300000 [01:18<1:55:27, 42.82it/s]
epoch 3400  training loss: 0.11081423610448837

  1%|▋                                                           | 3558/300000 [01:22<1:54:17, 43.23it/s]
epoch 3500  training loss: 0.08908781409263611

  1%|▋                                                           | 3647/300000 [01:24<1:53:07, 43.66it/s]
epoch 3600  training loss: 0.0834684669971466

  1%|▋                                                           | 3697/300000 [01:25<1:54:02, 43.30it/s]

epoch 3700  training loss: 0.07970671355724335
epoch 3700  clean testing loss: 0.030697263777256012
epoch 3800  training loss: 0.08852586895227432

  1%|▊                                                           | 3897/300000 [01:30<1:54:56, 42.94it/s]
epoch 3900  training loss: 0.07393097132444382

  1%|▊                                                           | 3993/300000 [01:32<1:53:27, 43.48it/s]
epoch 4000  training loss: 0.20967167615890503

  1%|▊                                                           | 4077/300000 [01:34<1:54:02, 43.25it/s]
epoch 4100  training loss: 0.09443829208612442

  1%|▊                                                           | 4168/300000 [01:36<1:54:12, 43.17it/s]
epoch 4200  training loss: 0.08405333012342453

  1%|▊                                                           | 4253/300000 [01:38<1:54:08, 43.19it/s]
epoch 4300  training loss: 0.08172336220741272

  1%|▊                                                           | 4298/300000 [01:39<1:54:36, 43.00it/s]
epoch 4400  training loss: 0.07408741861581802

  1%|▉                                                           | 4448/300000 [01:43<1:53:25, 43.43it/s]
epoch 4500  training loss: 0.2034725546836853


  2%|▉                                                           | 4623/300000 [01:47<1:49:37, 44.90it/s]
epoch 4600  training loss: 0.07407630980014801

  2%|▉                                                           | 4703/300000 [01:49<2:21:55, 34.68it/s]
epoch 4700  training loss: 0.08174926787614822

  2%|▉                                                           | 4792/300000 [01:50<1:54:39, 42.91it/s]
epoch 4800  training loss: 0.07185208052396774

  2%|▉                                                           | 4883/300000 [01:53<1:53:35, 43.30it/s]
epoch 4900  training loss: 0.10262305289506912

  2%|▉                                                           | 4967/300000 [01:55<1:53:59, 43.14it/s]
epoch 5000  training loss: 0.07251699268817902

  2%|█                                                           | 5053/300000 [01:57<1:54:04, 43.09it/s]
epoch 5100  training loss: 0.06756879389286041


  2%|█                                                           | 5228/300000 [02:01<1:51:06, 44.22it/s]
epoch 5200  training loss: 0.06583206355571747

  2%|█                                                           | 5312/300000 [02:03<1:47:16, 45.78it/s]
epoch 5300  training loss: 0.09426514059305191

  2%|█                                                           | 5397/300000 [02:05<1:54:03, 43.05it/s]
epoch 5400  training loss: 0.06395004689693451

  2%|█                                                           | 5488/300000 [02:07<1:52:53, 43.48it/s]
epoch 5500  training loss: 0.06829443573951721

  2%|█                                                           | 5573/300000 [02:09<1:53:58, 43.05it/s]
epoch 5600  training loss: 0.06277356296777725

  2%|█▏                                                          | 5662/300000 [02:11<1:53:20, 43.28it/s]
epoch 5700  training loss: 0.09356294572353363


  2%|█▏                                                          | 5833/300000 [02:15<1:50:47, 44.26it/s]
epoch 5800  training loss: 0.061104774475097656

  2%|█▏                                                          | 5898/300000 [02:16<1:53:09, 43.32it/s]
epoch 5900  training loss: 0.13946880400180817
epoch 5900  clean testing loss: 0.058356206864118576
epoch 6000  training loss: 0.06552966684103012
epoch 6000  clean testing loss: 0.047319766134023666
epoch 6100  training loss: 0.061646029353141785
epoch 6100  clean testing loss: 0.047809142619371414
epoch 6200  training loss: 0.059550631791353226


  2%|█▎                                                          | 6288/300000 [02:25<1:51:34, 43.87it/s]
epoch 6300  training loss: 0.05858372151851654

  2%|█▎                                                          | 6377/300000 [02:27<1:51:42, 43.81it/s]
epoch 6400  training loss: 0.05939638987183571

  2%|█▎                                                          | 6397/300000 [02:28<1:53:24, 43.15it/s]
epoch 6500  training loss: 0.11842948198318481
epoch 6500  clean testing loss: 0.056738972663879395
epoch 6600  training loss: 0.05585296079516411
epoch 6600  clean testing loss: 0.049734022468328476
epoch 6700  training loss: 0.08591647446155548
epoch 6700  clean testing loss: 0.054664477705955505
epoch 6800  training loss: 0.05462642014026642
epoch 6800  clean testing loss: 0.05044306814670563
epoch 6900  training loss: 0.05787590518593788

  2%|█▍                                                          | 6998/300000 [02:42<1:53:17, 43.10it/s]
epoch 7000  training loss: 0.0546078123152256

  2%|█▍                                                          | 7087/300000 [02:44<1:52:03, 43.57it/s]
epoch 7100  training loss: 0.05963363125920296

  2%|█▍                                                          | 7178/300000 [02:46<1:53:02, 43.17it/s]
epoch 7200  training loss: 0.060212641954422

  2%|█▍                                                          | 7263/300000 [02:48<1:52:39, 43.31it/s]
epoch 7300  training loss: 0.06048533692955971


  2%|█▍                                                          | 7397/300000 [02:51<1:53:22, 43.02it/s]
epoch 7400  training loss: 0.05356688052415848
epoch 7400  clean testing loss: 0.05186614766716957
epoch 7500  training loss: 0.0542733259499073
epoch 7500  clean testing loss: 0.06515199691057205
epoch 7600  training loss: 0.05634131282567978
epoch 7600  clean testing loss: 0.05509994179010391
epoch 7700  training loss: 0.0632338672876358
epoch 7700  clean testing loss: 0.054510585963726044
epoch 7800  training loss: 0.05119892209768295

  3%|█▌                                                          | 7869/300000 [03:02<1:53:04, 43.06it/s]
epoch 7900  training loss: 0.050662811845541

  3%|█▌                                                          | 7957/300000 [03:04<1:51:49, 43.52it/s]
epoch 8000  training loss: 0.054242271929979324

  3%|█▌                                                          | 7997/300000 [03:05<1:52:56, 43.09it/s]
epoch 8100  training loss: 0.057588689029216766
epoch 8100  clean testing loss: 0.056738704442977905
epoch 8200  training loss: 0.049189455807209015
epoch 8200  clean testing loss: 0.06084961071610451
epoch 8300  training loss: 0.04999000206589699
epoch 8300  clean testing loss: 0.062994085252285
epoch 8400  training loss: 0.04857993498444557

  3%|█▋                                                          | 8473/300000 [03:16<1:51:00, 43.77it/s]
epoch 8500  training loss: 0.06001761183142662

  3%|█▋                                                          | 8557/300000 [03:18<1:52:37, 43.13it/s]
epoch 8600  training loss: 0.04759078100323677

  3%|█▋                                                          | 8643/300000 [03:20<1:51:24, 43.59it/s]
epoch 8700  training loss: 0.07812317460775375

  3%|█▋                                                          | 8698/300000 [03:21<1:54:15, 42.49it/s]
epoch 8800  training loss: 0.047841571271419525

  3%|█▊                                                          | 8863/300000 [03:25<1:50:50, 43.78it/s]
epoch 8900  training loss: 0.04891146346926689

  3%|█▊                                                          | 8947/300000 [03:27<1:53:23, 42.78it/s]
epoch 9000  training loss: 0.04657552391290665

  3%|█▊                                                          | 8997/300000 [03:28<1:51:15, 43.59it/s]
epoch 9100  training loss: 0.045012421905994415

  3%|█▊                                                          | 9118/300000 [03:31<1:47:14, 45.21it/s]
epoch 9200  training loss: 0.04564109072089195


  3%|█▊                                                          | 9293/300000 [03:35<1:51:40, 43.39it/s]
epoch 9300  training loss: 0.04480919986963272

  3%|█▉                                                          | 9383/300000 [03:37<1:52:54, 42.90it/s]
epoch 9400  training loss: 0.05099121108651161

  3%|█▉                                                          | 9467/300000 [03:39<1:49:23, 44.26it/s]
epoch 9500  training loss: 0.044483575969934464

  3%|█▉                                                          | 9553/300000 [03:41<1:52:13, 43.14it/s]
epoch 9600  training loss: 0.046758294105529785

  3%|█▉                                                          | 9637/300000 [03:43<1:50:19, 43.86it/s]
epoch 9700  training loss: 0.0630241110920906

  3%|█▉                                                          | 9728/300000 [03:45<1:49:18, 44.26it/s]
epoch 9800  training loss: 0.044387973845005035

  3%|█▉                                                          | 9812/300000 [03:47<1:45:21, 45.90it/s]
epoch 9900  training loss: 0.041752610355615616

  3%|█▉                                                          | 9897/300000 [03:49<1:51:55, 43.20it/s]
epoch 10000  training loss: 0.04250746965408325
epoch 10000  clean testing loss: 0.08232144266366959
epoch 10100  training loss: 0.042823195457458496
epoch 10100  clean testing loss: 0.08329319953918457
epoch 10200  training loss: 0.10651332885026932
epoch 10200  clean testing loss: 0.09981383383274078
epoch 10300  training loss: 0.04161370173096657

  3%|██                                                         | 10333/300000 [03:59<1:49:36, 44.05it/s]
epoch 10400  training loss: 0.04104764014482498

  3%|██                                                         | 10417/300000 [04:01<1:47:05, 45.07it/s]
epoch 10500  training loss: 0.046490542590618134


  4%|██                                                         | 10743/300000 [04:08<1:49:42, 43.94it/s]
epoch 10600  training loss: 0.040783174335956573
epoch 10600  clean testing loss: 0.08576595038175583
epoch 10700  training loss: 0.04425879940390587
epoch 10700  clean testing loss: 0.08016421645879745
epoch 10800  training loss: 0.040623024106025696

  4%|██▏                                                        | 10827/300000 [04:10<1:50:35, 43.58it/s]
epoch 10900  training loss: 0.04175867140293121


  4%|██▏                                                        | 10998/300000 [04:14<1:51:22, 43.25it/s]
epoch 11000  training loss: 0.041290368884801865

  4%|██▏                                                        | 11088/300000 [04:17<1:50:59, 43.38it/s]
epoch 11100  training loss: 0.04101123288273811

  4%|██▏                                                        | 11183/300000 [04:18<1:14:04, 64.99it/s]
epoch 11200  training loss: 0.04622586816549301
epoch 11200  clean testing loss: 0.07513904571533203
epoch 11300  training loss: 0.03804231435060501

  4%|██▏                                                        | 11332/300000 [04:20<1:03:03, 76.29it/s]
epoch 11400  training loss: 0.038788676261901855

  4%|██▎                                                        | 11488/300000 [04:23<1:04:02, 75.09it/s]
epoch 11500  training loss: 0.03967231139540672
epoch 11500  clean testing loss: 0.08716408163309097
epoch 11600  training loss: 0.04001975804567337

  4%|██▎                                                        | 11632/300000 [04:24<1:02:56, 76.36it/s]
epoch 11700  training loss: 0.04339396208524704

  4%|██▎                                                        | 11740/300000 [04:26<1:03:20, 75.85it/s]
epoch 11800  training loss: 0.03608331456780434
epoch 11800  clean testing loss: 0.1004200205206871
epoch 11900  training loss: 0.042269278317689896
epoch 11900  clean testing loss: 0.09487821906805038
epoch 12000  training loss: 0.03541154786944389
epoch 12000  clean testing loss: 0.10085716843605042
epoch 12100  training loss: 0.0351702980697155
epoch 12100  clean testing loss: 0.10211051255464554
epoch 12200  training loss: 0.03451130539178848
epoch 12200  clean testing loss: 0.11472916603088379
epoch 12300  training loss: 0.03680486977100372
epoch 12300  clean testing loss: 0.1524907350540161
epoch 12400  training loss: 0.03321763128042221
epoch 12400  clean testing loss: 0.10820809006690979
epoch 12500  training loss: 0.044161051511764526
epoch 12500  clean testing loss: 0.1700642853975296
epoch 12600  training loss: 0.03298215568065643
epoch 12600  clean testing loss: 0.10564073920249939
epoch 12700  training loss: 0.04420609399676323
epoch 12700  clean testing loss: 0.0990130752325058
epoch 12800  training loss: 0.03277410939335823
epoch 12800  clean testing loss: 0.1136823445558548
epoch 12900  training loss: 0.033527325838804245
epoch 12900  clean testing loss: 0.11504453420639038
epoch 13000  training loss: 0.031283192336559296
epoch 13000  clean testing loss: 0.11501467227935791
epoch 13100  training loss: 0.04762899875640869
epoch 13100  clean testing loss: 0.1322077065706253
epoch 13200  training loss: 0.031330469995737076
epoch 13200  clean testing loss: 0.10691463202238083
epoch 13300  training loss: 0.030537493526935577
epoch 13300  clean testing loss: 0.11398636549711227
epoch 13400  training loss: 0.03584633022546768

  4%|██▋                                                         | 13482/300000 [04:43<40:28, 118.00it/s]
epoch 13500  training loss: 0.03175031393766403
epoch 13500  clean testing loss: 0.12191171944141388
epoch 13600  training loss: 0.03816813975572586
epoch 13600  clean testing loss: 0.08986255526542664
epoch 13700  training loss: 0.029191244393587112

  5%|██▋                                                         | 13706/300000 [04:45<42:59, 110.97it/s]
epoch 13800  training loss: 0.033044952899217606
epoch 13800  clean testing loss: 0.12336453050374985
epoch 13900  training loss: 0.030217245221138


  5%|██▊                                                         | 14182/300000 [04:49<40:19, 118.11it/s]
epoch 14000  training loss: 0.028637222945690155
epoch 14000  clean testing loss: 0.11308925598859787
epoch 14100  training loss: 0.032794151455163956

  5%|██▉                                                         | 14421/300000 [04:51<39:47, 119.63it/s]
epoch 14200  training loss: 0.03840966522693634
epoch 14200  clean testing loss: 0.08845210820436478
epoch 14300  training loss: 0.02775443345308304
epoch 14300  clean testing loss: 0.11112204194068909
epoch 14400  training loss: 0.028087954968214035

  5%|██▉                                                         | 14594/300000 [04:52<40:19, 117.96it/s]
epoch 14500  training loss: 0.034076426178216934
epoch 14500  clean testing loss: 0.1020062193274498
epoch 14600  training loss: 0.02990857884287834

  5%|██▉                                                         | 14893/300000 [04:55<40:18, 117.86it/s]
epoch 14700  training loss: 0.05244109034538269
epoch 14700  clean testing loss: 0.1414628028869629
epoch 14800  training loss: 0.026002896949648857

  5%|███                                                         | 15121/300000 [04:57<39:39, 119.71it/s]
epoch 14900  training loss: 0.040028154850006104
epoch 14900  clean testing loss: 0.09410687536001205
epoch 15000  training loss: 0.025365199893712997
epoch 15000  clean testing loss: 0.11611108481884003
epoch 15100  training loss: 0.02505788579583168

  5%|███                                                         | 15358/300000 [04:59<40:02, 118.47it/s]
epoch 15200  training loss: 0.02809062786400318
epoch 15200  clean testing loss: 0.13380539417266846
epoch 15300  training loss: 0.03315124660730362

  5%|███                                                         | 15594/300000 [05:01<40:11, 117.95it/s]
epoch 15400  training loss: 0.025183381512761116
epoch 15400  clean testing loss: 0.11753417551517487
epoch 15500  training loss: 0.03143366053700447

  5%|███▏                                                        | 15834/300000 [05:03<39:47, 119.00it/s]
epoch 15600  training loss: 0.024065740406513214
epoch 15600  clean testing loss: 0.11179984360933304
epoch 15700  training loss: 0.024854982271790504
epoch 15700  clean testing loss: 0.11576332151889801
epoch 15800  training loss: 0.022805916145443916

  5%|███▏                                                        | 16070/300000 [05:05<40:01, 118.25it/s]
epoch 15900  training loss: 0.034753914922475815
epoch 15900  clean testing loss: 0.10081640630960464
epoch 16000  training loss: 0.02219010330736637

  5%|███▏                                                        | 16094/300000 [05:05<40:06, 118.00it/s]
epoch 16100  training loss: 0.023697011172771454

  6%|███▍                                                        | 17246/300000 [05:15<39:41, 118.71it/s]
epoch 16200  training loss: 0.02405477687716484
epoch 16200  clean testing loss: 0.14732199907302856
epoch 16300  training loss: 0.021836906671524048
epoch 16300  clean testing loss: 0.11251767724752426
epoch 16400  training loss: 0.022718142718076706
epoch 16400  clean testing loss: 0.11556299030780792
epoch 16500  training loss: 0.021136078983545303
epoch 16500  clean testing loss: 0.11349890381097794
epoch 16600  training loss: 0.027907785028219223
epoch 16600  clean testing loss: 0.1242699846625328
epoch 16700  training loss: 0.02491745911538601
epoch 16700  clean testing loss: 0.11346867680549622
epoch 16800  training loss: 0.021570373326539993
epoch 16800  clean testing loss: 0.10766960680484772
epoch 16900  training loss: 0.020424405112862587
epoch 16900  clean testing loss: 0.11490170657634735
epoch 17000  training loss: 0.01960853487253189
epoch 17000  clean testing loss: 0.11962881684303284
epoch 17100  training loss: 0.019532348960638046
epoch 17100  clean testing loss: 0.11992163956165314
epoch 17200  training loss: 0.0230993814766407

  6%|███▍                                                        | 17482/300000 [05:17<39:51, 118.14it/s]
epoch 17300  training loss: 0.019574910402297974
epoch 17300  clean testing loss: 0.11935525387525558
epoch 17400  training loss: 0.02690867707133293
  6%|███▍                                                       | 17617/300000 [05:18<1:25:01, 55.35it/s]
Traceback (most recent call last):
  File "/home/howon/aistats25-exp/nn_exp.py", line 238, in <module>
    losses.backward()
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
epoch 17500  training loss: 0.055730413645505905
epoch 17500  clean testing loss: 0.15025247633457184
epoch 17600  training loss: 0.019243035465478897
epoch 17600  clean testing loss: 0.11031316220760345