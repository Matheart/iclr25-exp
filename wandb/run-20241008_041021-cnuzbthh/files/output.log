
  0%|▎                                                                                 | 424/100000 [00:01<05:13, 317.19it/s]
epoch 0  training loss: 0.5765089392662048
epoch 0  clean testing loss: 0.46372517943382263
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 100  training loss: 0.1533011794090271
epoch 100  clean testing loss: 0.06901312619447708
epoch 200  training loss: 0.13983458280563354
epoch 200  clean testing loss: 0.05715438351035118
epoch 300  training loss: 0.1371956467628479
epoch 300  clean testing loss: 0.05567658320069313
epoch 400  training loss: 0.11698424071073532

  1%|▊                                                                                | 1054/100000 [00:03<05:06, 322.32it/s]
epoch 500  training loss: 0.10687264055013657
epoch 500  clean testing loss: 0.04123664274811745
epoch 600  training loss: 0.12460269033908844
epoch 600  clean testing loss: 0.049629710614681244
epoch 700  training loss: 0.10569864511489868
epoch 700  clean testing loss: 0.041100312024354935
epoch 800  training loss: 0.10263266414403915
epoch 800  clean testing loss: 0.041879791766405106
epoch 900  training loss: 0.10006701946258545
epoch 900  clean testing loss: 0.040985483676195145
epoch 1000  training loss: 0.10136998444795609
epoch 1000  clean testing loss: 0.04073585569858551
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 1100  training loss: 0.09827473759651184

  2%|█▍                                                                               | 1710/100000 [00:05<05:07, 319.71it/s]
epoch 1200  training loss: 0.10053056478500366
epoch 1200  clean testing loss: 0.041102852672338486
epoch 1300  training loss: 0.09756680577993393
epoch 1300  clean testing loss: 0.060435857623815536
epoch 1400  training loss: 0.09398467093706131
epoch 1400  clean testing loss: 0.045830920338630676
epoch 1500  training loss: 0.09606783092021942
epoch 1500  clean testing loss: 0.04225737228989601
epoch 1600  training loss: 0.09541391581296921
epoch 1600  clean testing loss: 0.04235152527689934
epoch 1700  training loss: 0.09679410606622696

  2%|█▊                                                                               | 2281/100000 [00:07<05:55, 274.60it/s]
epoch 1800  training loss: 0.0979551300406456
epoch 1800  clean testing loss: 0.05692838504910469
epoch 1900  training loss: 0.09476110339164734
epoch 1900  clean testing loss: 0.04480623081326485
epoch 2000  training loss: 0.09232457727193832
epoch 2000  clean testing loss: 0.04338601976633072
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 2100  training loss: 0.08934137225151062
epoch 2100  clean testing loss: 0.04546472430229187
epoch 2200  training loss: 0.0920647531747818
epoch 2200  clean testing loss: 0.05557217448949814
epoch 2300  training loss: 0.08918239176273346

  3%|██▎                                                                              | 2820/100000 [00:09<05:52, 275.99it/s]
epoch 2400  training loss: 0.08779483288526535
epoch 2400  clean testing loss: 0.044429630041122437
epoch 2500  training loss: 0.08886377513408661
epoch 2500  clean testing loss: 0.055347852408885956
epoch 2600  training loss: 0.08760025352239609
epoch 2600  clean testing loss: 0.053644634783267975
epoch 2700  training loss: 0.08501427620649338
epoch 2700  clean testing loss: 0.04661155864596367
epoch 2800  training loss: 0.16635683178901672

  3%|██▊                                                                              | 3474/100000 [00:11<04:59, 321.84it/s]
epoch 2900  training loss: 0.0873483270406723
epoch 2900  clean testing loss: 0.046042200177907944
epoch 3000  training loss: 0.08621266484260559
epoch 3000  clean testing loss: 0.05063951015472412
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 3100  training loss: 0.08249863982200623
epoch 3100  clean testing loss: 0.04731575399637222
epoch 3200  training loss: 0.0814957469701767
epoch 3200  clean testing loss: 0.05392814055085182
epoch 3300  training loss: 0.08192677795886993
epoch 3300  clean testing loss: 0.04756537824869156
epoch 3400  training loss: 0.0794486477971077
epoch 3400  clean testing loss: 0.051877040416002274
epoch 3500  training loss: 0.0798749327659607

  4%|███▎                                                                             | 4094/100000 [00:13<05:03, 316.39it/s]
epoch 3600  training loss: 0.08043181896209717
epoch 3600  clean testing loss: 0.047483064234256744
epoch 3700  training loss: 0.07966113090515137
epoch 3700  clean testing loss: 0.061978161334991455
epoch 3800  training loss: 0.07948316633701324
epoch 3800  clean testing loss: 0.048311080783605576
epoch 3900  training loss: 0.07605284452438354
epoch 3900  clean testing loss: 0.050558846443891525
epoch 4000  training loss: 0.07539842277765274
epoch 4000  clean testing loss: 0.05648991838097572
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 4100  training loss: 0.0750974789261818

  5%|███▊                                                                             | 4748/100000 [00:15<05:10, 307.09it/s]
epoch 4200  training loss: 0.07493269443511963
epoch 4200  clean testing loss: 0.053024303168058395
epoch 4300  training loss: 0.07371986657381058
epoch 4300  clean testing loss: 0.05709370598196983
epoch 4400  training loss: 0.07486703991889954
epoch 4400  clean testing loss: 0.057394254952669144
epoch 4500  training loss: 0.073987677693367
epoch 4500  clean testing loss: 0.05028396472334862
epoch 4600  training loss: 0.0749627873301506
epoch 4600  clean testing loss: 0.062801294028759
epoch 4700  training loss: 0.0750475525856018

  5%|████▎                                                                            | 5371/100000 [00:17<04:53, 322.12it/s]
epoch 4800  training loss: 0.10442066192626953
epoch 4800  clean testing loss: 0.054565295577049255
epoch 4900  training loss: 0.07168277353048325
epoch 4900  clean testing loss: 0.054526735097169876
epoch 5000  training loss: 0.0707223191857338
epoch 5000  clean testing loss: 0.055365391075611115
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 5100  training loss: 0.06997400522232056
epoch 5100  clean testing loss: 0.054651692509651184
epoch 5200  training loss: 0.07699420303106308
epoch 5200  clean testing loss: 0.07098222523927689
epoch 5300  training loss: 0.07189871370792389
epoch 5300  clean testing loss: 0.05377256125211716
epoch 5400  training loss: 0.06994777172803879

  6%|████▉                                                                            | 6030/100000 [00:19<04:54, 319.07it/s]
epoch 5500  training loss: 0.07040195167064667
epoch 5500  clean testing loss: 0.0635925680398941
epoch 5600  training loss: 0.07103340327739716
epoch 5600  clean testing loss: 0.053604934364557266
epoch 5700  training loss: 0.06944102793931961
epoch 5700  clean testing loss: 0.06457866728305817
epoch 5800  training loss: 0.06856798380613327
epoch 5800  clean testing loss: 0.05384790152311325
epoch 5900  training loss: 0.07119613140821457
epoch 5900  clean testing loss: 0.053719352930784225
epoch 6000  training loss: 0.0674673467874527
epoch 6000  clean testing loss: 0.060398370027542114

  7%|█████▍                                                                           | 6653/100000 [00:21<04:48, 323.08it/s]
epoch 6100  training loss: 0.06661263853311539
epoch 6100  clean testing loss: 0.056079261004924774
epoch 6200  training loss: 0.0675140842795372
epoch 6200  clean testing loss: 0.055763956159353256
epoch 6300  training loss: 0.06862922757863998
epoch 6300  clean testing loss: 0.056421518325805664
epoch 6400  training loss: 0.068397156894207
epoch 6400  clean testing loss: 0.06695384532213211
epoch 6500  training loss: 0.06526193767786026
epoch 6500  clean testing loss: 0.056533150374889374
epoch 6600  training loss: 0.06544912606477737
epoch 6600  clean testing loss: 0.06811542063951492
epoch 6700  training loss: 0.0656287744641304

  7%|█████▉                                                                           | 7294/100000 [00:23<05:29, 281.65it/s]
epoch 6800  training loss: 0.06559902429580688
epoch 6800  clean testing loss: 0.058832403272390366
epoch 6900  training loss: 0.06424824893474579
epoch 6900  clean testing loss: 0.06215829402208328
epoch 7000  training loss: 0.06533795595169067
epoch 7000  clean testing loss: 0.06316794455051422
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 7100  training loss: 0.06731758266687393
epoch 7100  clean testing loss: 0.06213923171162605
epoch 7200  training loss: 0.06340724229812622
epoch 7200  clean testing loss: 0.06088174134492874
epoch 7300  training loss: 0.06222493574023247

  8%|██████▎                                                                          | 7837/100000 [00:25<05:27, 281.05it/s]
epoch 7400  training loss: 0.06476550549268723
epoch 7400  clean testing loss: 0.0577918104827404
epoch 7500  training loss: 0.06158382445573807
epoch 7500  clean testing loss: 0.06098727509379387
epoch 7600  training loss: 0.06226305291056633
epoch 7600  clean testing loss: 0.06476825475692749
epoch 7700  training loss: 0.06451674550771713
epoch 7700  clean testing loss: 0.06558595597743988
epoch 7800  training loss: 0.0629197284579277

  8%|██████▊                                                                          | 8405/100000 [00:27<05:31, 276.52it/s]
epoch 7900  training loss: 0.060502465814352036
epoch 7900  clean testing loss: 0.0621420294046402
epoch 8000  training loss: 0.062309782952070236
epoch 8000  clean testing loss: 0.06090487167239189
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 8100  training loss: 0.06082622706890106
epoch 8100  clean testing loss: 0.06473337113857269
epoch 8200  training loss: 0.06638544052839279
epoch 8200  clean testing loss: 0.06932583451271057
epoch 8300  training loss: 0.05941969156265259
epoch 8300  clean testing loss: 0.061334796249866486
epoch 8400  training loss: 0.07200343906879425

  9%|███████▏                                                                         | 8942/100000 [00:29<05:31, 274.97it/s]
epoch 8500  training loss: 0.06062333285808563
epoch 8500  clean testing loss: 0.05894481763243675
epoch 8600  training loss: 0.059188902378082275
epoch 8600  clean testing loss: 0.0678824782371521
epoch 8700  training loss: 0.05853429436683655
epoch 8700  clean testing loss: 0.061668865382671356
epoch 8800  training loss: 0.07411792874336243
epoch 8800  clean testing loss: 0.06692178547382355
epoch 8900  training loss: 0.05912022665143013

  9%|███████▋                                                                         | 9455/100000 [00:31<06:14, 242.03it/s]
epoch 9000  training loss: 0.05957648158073425
epoch 9000  clean testing loss: 0.06256832182407379
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 9100  training loss: 0.05919154733419418
epoch 9100  clean testing loss: 0.06252831965684891
epoch 9200  training loss: 0.05872883275151253
epoch 9200  clean testing loss: 0.06816324591636658
epoch 9300  training loss: 0.05685102194547653
epoch 9300  clean testing loss: 0.06682710349559784
epoch 9400  training loss: 0.05635574460029602

 10%|████████                                                                         | 9964/100000 [00:33<06:08, 244.35it/s]
epoch 9500  training loss: 0.05854623764753342
epoch 9500  clean testing loss: 0.06396554410457611
epoch 9600  training loss: 0.05801979452371597
epoch 9600  clean testing loss: 0.06341462582349777
epoch 9700  training loss: 0.055804137140512466
epoch 9700  clean testing loss: 0.06416445970535278
epoch 9800  training loss: 0.05558788776397705
epoch 9800  clean testing loss: 0.06761050969362259
epoch 9900  training loss: 0.06046305224299431

 10%|████████▎                                                                       | 10445/100000 [00:35<06:02, 246.89it/s]
epoch 10000  training loss: 0.0562339723110199
epoch 10000  clean testing loss: 0.06306830793619156
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 10100  training loss: 0.05836902931332588
epoch 10100  clean testing loss: 0.07068684697151184
epoch 10200  training loss: 0.055498603731393814
epoch 10200  clean testing loss: 0.06787440925836563
epoch 10300  training loss: 0.05842465162277222
epoch 10300  clean testing loss: 0.06996936351060867
epoch 10400  training loss: 0.05496176704764366
epoch 10400  clean testing loss: 0.0649029016494751
epoch 10500  training loss: 0.05420725420117378

 11%|████████▋                                                                       | 10925/100000 [00:37<06:05, 243.60it/s]
epoch 10600  training loss: 0.05658864229917526
epoch 10600  clean testing loss: 0.07089132070541382
epoch 10700  training loss: 0.0551246739923954
epoch 10700  clean testing loss: 0.06793046742677689
epoch 10800  training loss: 0.054906148463487625
epoch 10800  clean testing loss: 0.07154658436775208
epoch 10900  training loss: 0.05481274798512459
epoch 10900  clean testing loss: 0.0660717561841011
epoch 11000  training loss: 0.053771521896123886
epoch 11000  clean testing loss: 0.07034045457839966

 11%|█████████▏                                                                      | 11409/100000 [00:39<06:01, 244.95it/s]
epoch 11100  training loss: 0.05518704652786255
epoch 11100  clean testing loss: 0.07239312678575516
epoch 11200  training loss: 0.05631258711218834
epoch 11200  clean testing loss: 0.07491307705640793
epoch 11300  training loss: 0.05341570824384689
epoch 11300  clean testing loss: 0.06800319999456406
epoch 11400  training loss: 0.05391225963830948
epoch 11400  clean testing loss: 0.0738183930516243
epoch 11500  training loss: 0.05352073162794113

 12%|█████████▌                                                                      | 11915/100000 [00:41<06:05, 240.89it/s]
epoch 11600  training loss: 0.05404699966311455
epoch 11600  clean testing loss: 0.07298054546117783
epoch 11700  training loss: 0.05600915104150772
epoch 11700  clean testing loss: 0.07687026262283325
epoch 11800  training loss: 0.052468232810497284
epoch 11800  clean testing loss: 0.06824230402708054
epoch 11900  training loss: 0.051859255880117416
epoch 11900  clean testing loss: 0.07071423530578613
epoch 12000  training loss: 0.05287759751081467
epoch 12000  clean testing loss: 0.07204452157020569

 12%|█████████▉                                                                      | 12371/100000 [00:43<05:58, 244.56it/s]
epoch 12100  training loss: 0.05204267427325249
epoch 12100  clean testing loss: 0.06725338101387024
epoch 12200  training loss: 0.051691439002752304
epoch 12200  clean testing loss: 0.06800927221775055
epoch 12300  training loss: 0.052218832075595856
epoch 12300  clean testing loss: 0.0717136487364769
epoch 12400  training loss: 0.05171998217701912
epoch 12400  clean testing loss: 0.07125647366046906
epoch 12500  training loss: 0.052010782063007355

 13%|██████████▎                                                                     | 12876/100000 [00:45<05:49, 249.23it/s]
epoch 12600  training loss: 0.05117768049240112
epoch 12600  clean testing loss: 0.07223393023014069
epoch 12700  training loss: 0.052501171827316284
epoch 12700  clean testing loss: 0.0693182721734047
epoch 12800  training loss: 0.05179455876350403
epoch 12800  clean testing loss: 0.07237870246171951
epoch 12900  training loss: 0.05239202454686165
epoch 12900  clean testing loss: 0.0703439712524414
epoch 13000  training loss: 0.05055445432662964
epoch 13000  clean testing loss: 0.06957462430000305

 13%|██████████▋                                                                     | 13356/100000 [00:47<05:56, 243.26it/s]
epoch 13100  training loss: 0.05056663602590561
epoch 13100  clean testing loss: 0.06934749335050583
epoch 13200  training loss: 0.05058204010128975
epoch 13200  clean testing loss: 0.06895920634269714
epoch 13300  training loss: 0.050076764076948166
epoch 13300  clean testing loss: 0.06991670280694962
epoch 13400  training loss: 0.05120249465107918
epoch 13400  clean testing loss: 0.06902197748422623
epoch 13500  training loss: 0.04983176663517952

 14%|███████████                                                                     | 13863/100000 [00:49<05:59, 239.57it/s]
epoch 13600  training loss: 0.05293471738696098
epoch 13600  clean testing loss: 0.07615654170513153
epoch 13700  training loss: 0.05250411853194237
epoch 13700  clean testing loss: 0.07605001330375671
epoch 13800  training loss: 0.04927223175764084
epoch 13800  clean testing loss: 0.07170799374580383
epoch 13900  training loss: 0.04977650195360184
epoch 13900  clean testing loss: 0.07217015326023102
epoch 14000  training loss: 0.050357259809970856

 14%|███████████▍                                                                    | 14337/100000 [00:51<05:51, 243.91it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 14100  training loss: 0.0498054064810276
epoch 14100  clean testing loss: 0.07284586131572723
epoch 14200  training loss: 0.049230676144361496
epoch 14200  clean testing loss: 0.07242289930582047
epoch 14300  training loss: 0.0524972528219223

 15%|███████████▊                                                                    | 14816/100000 [00:53<05:51, 242.43it/s]
epoch 14400  training loss: 0.04896499589085579
epoch 14400  clean testing loss: 0.07386514544487
epoch 14500  training loss: 0.05173980072140694
epoch 14500  clean testing loss: 0.07217913866043091
epoch 14600  training loss: 0.05134481191635132
epoch 14600  clean testing loss: 0.07770105451345444
epoch 14700  training loss: 0.04866821691393852
epoch 14700  clean testing loss: 0.07367796450853348
epoch 14800  training loss: 0.05055207014083862

 15%|████████████▎                                                                   | 15324/100000 [00:55<05:45, 244.86it/s]
epoch 14900  training loss: 0.04828115925192833
epoch 14900  clean testing loss: 0.07174678891897202
epoch 15000  training loss: 0.0480908565223217
epoch 15000  clean testing loss: 0.07239598780870438
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 15100  training loss: 0.048148903995752335
epoch 15100  clean testing loss: 0.07451976090669632
epoch 15200  training loss: 0.04807676002383232
epoch 15200  clean testing loss: 0.07525534927845001
epoch 15300  training loss: 0.04795047268271446

 16%|████████████▋                                                                   | 15804/100000 [00:57<05:46, 242.67it/s]
epoch 15400  training loss: 0.04839041456580162
epoch 15400  clean testing loss: 0.07273011654615402
epoch 15500  training loss: 0.04822069779038429
epoch 15500  clean testing loss: 0.07311516255140305
epoch 15600  training loss: 0.047494351863861084
epoch 15600  clean testing loss: 0.07530180364847183
epoch 15700  training loss: 0.04767746105790138
epoch 15700  clean testing loss: 0.07296037673950195
epoch 15800  training loss: 0.04772469401359558
 16%|████████████▊                                                                   | 16056/100000 [00:58<05:52, 237.97it/s][34m[1mwandb[39m[22m: 429 encountered (Filestream rate limit exceeded, retrying in 2.3 seconds.), retrying request
 16%|█████████████                                                                   | 16287/100000 [00:59<05:40, 245.70it/s]
epoch 15900  training loss: 0.0472307987511158
epoch 15900  clean testing loss: 0.07328855991363525
epoch 16000  training loss: 0.046920374035835266
epoch 16000  clean testing loss: 0.07600635290145874
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 16100  training loss: 0.04724471643567085
epoch 16100  clean testing loss: 0.07555458694696426
epoch 16200  training loss: 0.04737601429224014
epoch 16200  clean testing loss: 0.07320785522460938
epoch 16300  training loss: 0.04868905991315842

 17%|█████████████▍                                                                  | 16769/100000 [01:01<05:42, 242.93it/s]
epoch 16400  training loss: 0.050928745418787
epoch 16400  clean testing loss: 0.08017359673976898
epoch 16500  training loss: 0.04738025367259979
epoch 16500  clean testing loss: 0.07600000500679016
epoch 16600  training loss: 0.04664628207683563
epoch 16600  clean testing loss: 0.07681354135274887
epoch 16700  training loss: 0.04712475836277008
epoch 16700  clean testing loss: 0.07693535834550858
epoch 16800  training loss: 0.04709684103727341

 17%|█████████████▊                                                                  | 17256/100000 [01:03<05:44, 240.44it/s]
epoch 16900  training loss: 0.04643998295068741
epoch 16900  clean testing loss: 0.0746404156088829
epoch 17000  training loss: 0.046551138162612915
epoch 17000  clean testing loss: 0.07732386887073517
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 17100  training loss: 0.046591997146606445
epoch 17100  clean testing loss: 0.07480569928884506
epoch 17200  training loss: 0.046800028532743454

 18%|██████████████▏                                                                 | 17760/100000 [01:05<05:40, 241.52it/s]
epoch 17300  training loss: 0.04585711658000946
epoch 17300  clean testing loss: 0.07615029066801071
epoch 17400  training loss: 0.05252933129668236
epoch 17400  clean testing loss: 0.08418838679790497
epoch 17500  training loss: 0.045739032328128815
epoch 17500  clean testing loss: 0.07668665051460266
epoch 17600  training loss: 0.04734760895371437
epoch 17600  clean testing loss: 0.08060351759195328
epoch 17700  training loss: 0.04569900035858154

 18%|██████████████▌                                                                 | 18237/100000 [01:07<05:38, 241.66it/s]
epoch 17800  training loss: 0.04584125056862831
epoch 17800  clean testing loss: 0.07786571234464645
epoch 17900  training loss: 0.04557593911886215
epoch 17900  clean testing loss: 0.07573036104440689
epoch 18000  training loss: 0.04570219665765762
epoch 18000  clean testing loss: 0.07801903039216995
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 18100  training loss: 0.04546155780553818
epoch 18100  clean testing loss: 0.0778777226805687
epoch 18200  training loss: 0.04508278891444206

 19%|██████████████▉                                                                 | 18739/100000 [01:09<05:39, 239.27it/s]
epoch 18300  training loss: 0.045032747089862823
epoch 18300  clean testing loss: 0.07700944691896439
epoch 18400  training loss: 0.0452398918569088
epoch 18400  clean testing loss: 0.07770158350467682
epoch 18500  training loss: 0.0483393557369709
epoch 18500  clean testing loss: 0.07780604064464569
epoch 18600  training loss: 0.04720277711749077
epoch 18600  clean testing loss: 0.0776701420545578
epoch 18700  training loss: 0.04523954167962074

 19%|███████████████▎                                                                | 19217/100000 [01:11<05:31, 243.58it/s]
epoch 18800  training loss: 0.04506281763315201
epoch 18800  clean testing loss: 0.07920454442501068
epoch 18900  training loss: 0.0448959618806839
epoch 18900  clean testing loss: 0.07960470020771027
epoch 19000  training loss: 0.04508503898978233
epoch 19000  clean testing loss: 0.07951076328754425
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 19100  training loss: 0.044794678688049316
epoch 19100  clean testing loss: 0.0793992206454277
epoch 19200  training loss: 0.04441813752055168

 20%|███████████████▊                                                                | 19696/100000 [01:13<05:33, 240.74it/s]
epoch 19300  training loss: 0.04476824402809143
epoch 19300  clean testing loss: 0.07890006899833679
epoch 19400  training loss: 0.045019105076789856
epoch 19400  clean testing loss: 0.07978036999702454
epoch 19500  training loss: 0.04441442713141441
epoch 19500  clean testing loss: 0.07898852974176407
epoch 19600  training loss: 0.04451822116971016
epoch 19600  clean testing loss: 0.07925204932689667
epoch 19700  training loss: 0.044802241027355194

 20%|████████████████▏                                                               | 20203/100000 [01:15<05:25, 245.33it/s]
epoch 19800  training loss: 0.04810136929154396
epoch 19800  clean testing loss: 0.0805271789431572
epoch 19900  training loss: 0.04430883750319481
epoch 19900  clean testing loss: 0.07976040989160538
epoch 20000  training loss: 0.04412008076906204
epoch 20000  clean testing loss: 0.08060980588197708
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 20100  training loss: 0.04549378529191017
epoch 20100  clean testing loss: 0.07896208763122559
epoch 20200  training loss: 0.04383423179388046

 21%|████████████████▌                                                               | 20682/100000 [01:17<05:30, 240.12it/s]
epoch 20300  training loss: 0.04420187696814537
epoch 20300  clean testing loss: 0.08084599673748016
epoch 20400  training loss: 0.04428708180785179
epoch 20400  clean testing loss: 0.0813671424984932
epoch 20500  training loss: 0.044338952749967575
epoch 20500  clean testing loss: 0.07804449647665024
epoch 20600  training loss: 0.044604942202568054

 21%|████████████████▉                                                               | 21161/100000 [01:19<05:27, 241.08it/s]
epoch 20700  training loss: 0.04649822413921356
epoch 20700  clean testing loss: 0.08110571652650833
epoch 20800  training loss: 0.043313052505254745
epoch 20800  clean testing loss: 0.08005653321743011
epoch 20900  training loss: 0.04338464513421059
epoch 20900  clean testing loss: 0.08131050318479538
epoch 21000  training loss: 0.04368417337536812
epoch 21000  clean testing loss: 0.07889314740896225
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 21100  training loss: 0.04309627413749695

 22%|█████████████████▎                                                              | 21637/100000 [01:21<05:23, 242.47it/s]
epoch 21200  training loss: 0.04299462214112282
epoch 21200  clean testing loss: 0.08008299767971039
epoch 21300  training loss: 0.04293547943234444
epoch 21300  clean testing loss: 0.08177798986434937
epoch 21400  training loss: 0.04298217222094536
epoch 21400  clean testing loss: 0.08016565442085266
epoch 21500  training loss: 0.04289702698588371
epoch 21500  clean testing loss: 0.07964377105236053
epoch 21600  training loss: 0.04284514859318733

 22%|█████████████████▋                                                              | 22141/100000 [01:23<05:24, 239.69it/s]
epoch 21700  training loss: 0.0436856783926487
epoch 21700  clean testing loss: 0.08185876905918121
epoch 21800  training loss: 0.04470153898000717
epoch 21800  clean testing loss: 0.08492529392242432
epoch 21900  training loss: 0.04400642588734627
epoch 21900  clean testing loss: 0.08477482944726944
epoch 22000  training loss: 0.04446016997098923
epoch 22000  clean testing loss: 0.08112666755914688
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 22100  training loss: 0.042485110461711884

 23%|██████████████████                                                              | 22622/100000 [01:25<05:19, 242.39it/s]
epoch 22200  training loss: 0.0424879752099514
epoch 22200  clean testing loss: 0.08164658397436142
epoch 22300  training loss: 0.04299800097942352
epoch 22300  clean testing loss: 0.08238247781991959
epoch 22400  training loss: 0.044899675995111465
epoch 22400  clean testing loss: 0.08227168768644333
epoch 22500  training loss: 0.042343638837337494
epoch 22500  clean testing loss: 0.08242715895175934
epoch 22600  training loss: 0.04204458370804787

 23%|██████████████████▍                                                             | 23104/100000 [01:27<05:21, 239.53it/s]
epoch 22700  training loss: 0.041987836360931396
epoch 22700  clean testing loss: 0.0818168967962265
epoch 22800  training loss: 0.04327772557735443
epoch 22800  clean testing loss: 0.08236823230981827
epoch 22900  training loss: 0.04184703156352043
epoch 22900  clean testing loss: 0.0821598619222641
epoch 23000  training loss: 0.042451757937669754
epoch 23000  clean testing loss: 0.08270178735256195
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 23100  training loss: 0.042944759130477905

 24%|██████████████████▊                                                             | 23586/100000 [01:29<05:09, 246.52it/s]
epoch 23200  training loss: 0.04290110245347023
epoch 23200  clean testing loss: 0.083707794547081
epoch 23300  training loss: 0.041858937591314316
epoch 23300  clean testing loss: 0.0830070823431015
epoch 23400  training loss: 0.04170806333422661
epoch 23400  clean testing loss: 0.08158013969659805
epoch 23500  training loss: 0.04177330061793327
epoch 23500  clean testing loss: 0.08306048810482025
epoch 23600  training loss: 0.04207971319556236

 24%|███████████████████▎                                                            | 24089/100000 [01:31<05:16, 240.16it/s]
epoch 23700  training loss: 0.041599761694669724
epoch 23700  clean testing loss: 0.08421733975410461
epoch 23800  training loss: 0.04147382825613022
epoch 23800  clean testing loss: 0.08374852687120438
epoch 23900  training loss: 0.04127611219882965
epoch 23900  clean testing loss: 0.08384488523006439
epoch 24000  training loss: 0.041526202112436295
epoch 24000  clean testing loss: 0.08316854387521744

 25%|███████████████████▋                                                            | 24572/100000 [01:33<05:03, 248.32it/s]
epoch 24100  training loss: 0.04121418669819832
epoch 24100  clean testing loss: 0.08400855958461761
epoch 24200  training loss: 0.041131746023893356
epoch 24200  clean testing loss: 0.0830838531255722
epoch 24300  training loss: 0.0410175658762455
epoch 24300  clean testing loss: 0.0833595022559166
epoch 24400  training loss: 0.04120079055428505
epoch 24400  clean testing loss: 0.08359170705080032
epoch 24500  training loss: 0.041170015931129456

 25%|████████████████████                                                            | 25050/100000 [01:35<05:15, 237.50it/s]
epoch 24600  training loss: 0.04100332409143448
epoch 24600  clean testing loss: 0.08427852392196655
epoch 24700  training loss: 0.040851861238479614
epoch 24700  clean testing loss: 0.08492836356163025
epoch 24800  training loss: 0.04099762812256813
epoch 24800  clean testing loss: 0.08376356959342957
epoch 24900  training loss: 0.04067159444093704
epoch 24900  clean testing loss: 0.083643339574337
epoch 25000  training loss: 0.04062936455011368
epoch 25000  clean testing loss: 0.0845121368765831

 26%|████████████████████▍                                                           | 25536/100000 [01:37<04:59, 248.54it/s]
epoch 25100  training loss: 0.04109027981758118
epoch 25100  clean testing loss: 0.0846223384141922
epoch 25200  training loss: 0.04068852588534355
epoch 25200  clean testing loss: 0.08494989573955536
epoch 25300  training loss: 0.04126924276351929
epoch 25300  clean testing loss: 0.08626346290111542
epoch 25400  training loss: 0.04048851877450943
epoch 25400  clean testing loss: 0.08536482602357864
epoch 25500  training loss: 0.04115157946944237

 26%|████████████████████▊                                                           | 26040/100000 [01:39<05:06, 241.62it/s]
epoch 25600  training loss: 0.04084519296884537
epoch 25600  clean testing loss: 0.08543353527784348
epoch 25700  training loss: 0.04029479995369911
epoch 25700  clean testing loss: 0.08520430326461792
epoch 25800  training loss: 0.04097366705536842
epoch 25800  clean testing loss: 0.08535940200090408
epoch 25900  training loss: 0.04025823250412941
epoch 25900  clean testing loss: 0.08598413318395615
epoch 26000  training loss: 0.04039747640490532
epoch 26000  clean testing loss: 0.08520668745040894

 27%|█████████████████████▏                                                          | 26523/100000 [01:41<04:59, 245.60it/s]
epoch 26100  training loss: 0.04024428501725197
epoch 26100  clean testing loss: 0.08605346828699112
epoch 26200  training loss: 0.04203791916370392
epoch 26200  clean testing loss: 0.08598225563764572
epoch 26300  training loss: 0.040487125515937805
epoch 26300  clean testing loss: 0.08462079614400864
epoch 26400  training loss: 0.04104458913207054
epoch 26400  clean testing loss: 0.08589386194944382
epoch 26500  training loss: 0.04036900773644447

 27%|█████████████████████▌                                                          | 27007/100000 [01:43<05:00, 243.21it/s]
epoch 26600  training loss: 0.0406753309071064
epoch 26600  clean testing loss: 0.08715113997459412
epoch 26700  training loss: 0.04071638733148575
epoch 26700  clean testing loss: 0.08735912293195724
epoch 26800  training loss: 0.04225216060876846
epoch 26800  clean testing loss: 0.08859910070896149
epoch 26900  training loss: 0.04015856981277466
epoch 26900  clean testing loss: 0.0865599736571312
epoch 27000  training loss: 0.03996278718113899
epoch 27000  clean testing loss: 0.08644597232341766

 28%|██████████████████████                                                          | 27509/100000 [01:45<04:59, 242.37it/s]
epoch 27100  training loss: 0.03968757763504982
epoch 27100  clean testing loss: 0.08596467226743698
epoch 27200  training loss: 0.03983065113425255
epoch 27200  clean testing loss: 0.08563509583473206
epoch 27300  training loss: 0.03950047492980957
epoch 27300  clean testing loss: 0.08651389181613922
epoch 27400  training loss: 0.03964019566774368
epoch 27400  clean testing loss: 0.08641186356544495
epoch 27500  training loss: 0.03940211609005928

 28%|██████████████████████▍                                                         | 27984/100000 [01:47<05:04, 236.75it/s]
epoch 27600  training loss: 0.039525263011455536
epoch 27600  clean testing loss: 0.08709845691919327
epoch 27700  training loss: 0.039421144872903824
epoch 27700  clean testing loss: 0.0869789645075798
epoch 27800  training loss: 0.03938665986061096
epoch 27800  clean testing loss: 0.0861552283167839
epoch 27900  training loss: 0.039439309388399124

 28%|██████████████████████▊                                                         | 28468/100000 [01:49<04:47, 248.98it/s]
epoch 28000  training loss: 0.039377521723508835
epoch 28000  clean testing loss: 0.0868280678987503
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 28100  training loss: 0.039275988936424255
epoch 28100  clean testing loss: 0.0878184363245964
epoch 28200  training loss: 0.039093516767024994
epoch 28200  clean testing loss: 0.08689038455486298
epoch 28300  training loss: 0.03944198042154312
epoch 28300  clean testing loss: 0.08782611787319183
epoch 28400  training loss: 0.039013903588056564

 29%|███████████████████████▏                                                        | 28949/100000 [01:51<04:53, 241.88it/s]
epoch 28500  training loss: 0.03904447332024574
epoch 28500  clean testing loss: 0.0869569480419159
epoch 28600  training loss: 0.03929070383310318
epoch 28600  clean testing loss: 0.08801799267530441
epoch 28700  training loss: 0.039093829691410065
epoch 28700  clean testing loss: 0.08693794906139374
epoch 28800  training loss: 0.0393734946846962
epoch 28800  clean testing loss: 0.08733892440795898
epoch 28900  training loss: 0.039600204676389694

 29%|███████████████████████▌                                                        | 29456/100000 [01:53<04:53, 240.14it/s]
epoch 29000  training loss: 0.039687175303697586
epoch 29000  clean testing loss: 0.08791786432266235
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 29100  training loss: 0.03879321366548538
epoch 29100  clean testing loss: 0.08751387894153595
epoch 29200  training loss: 0.040190063416957855
epoch 29200  clean testing loss: 0.0907931849360466
epoch 29300  training loss: 0.03893738612532616
epoch 29300  clean testing loss: 0.08817464113235474
epoch 29400  training loss: 0.038603752851486206

 30%|███████████████████████▉                                                        | 29939/100000 [01:55<04:48, 243.14it/s]
epoch 29500  training loss: 0.03881577402353287
epoch 29500  clean testing loss: 0.08814984560012817
epoch 29600  training loss: 0.038522690534591675
epoch 29600  clean testing loss: 0.08899462223052979
epoch 29700  training loss: 0.03882472962141037
epoch 29700  clean testing loss: 0.08832094073295593
epoch 29800  training loss: 0.038961563259363174
epoch 29800  clean testing loss: 0.08781322091817856
epoch 29900  training loss: 0.03867305442690849

 30%|████████████████████████▎                                                       | 30420/100000 [01:57<04:43, 245.67it/s]
epoch 30000  training loss: 0.038442231714725494
epoch 30000  clean testing loss: 0.08847904205322266
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 30100  training loss: 0.038306109607219696
epoch 30100  clean testing loss: 0.08928386867046356
epoch 30200  training loss: 0.03828848898410797
epoch 30200  clean testing loss: 0.08915648609399796
epoch 30300  training loss: 0.03817491605877876
epoch 30300  clean testing loss: 0.08916374295949936
epoch 30400  training loss: 0.038145553320646286

 31%|████████████████████████▋                                                       | 30879/100000 [01:59<04:43, 244.00it/s]
epoch 30500  training loss: 0.038372308015823364
epoch 30500  clean testing loss: 0.08930975943803787
epoch 30600  training loss: 0.038328006863594055
epoch 30600  clean testing loss: 0.08904406428337097
epoch 30700  training loss: 0.03813620284199715
epoch 30700  clean testing loss: 0.08989804983139038
epoch 30800  training loss: 0.039039045572280884
epoch 30800  clean testing loss: 0.08993764221668243
epoch 30900  training loss: 0.03886019438505173

 31%|█████████████████████████▏                                                      | 31413/100000 [02:01<04:47, 238.79it/s]
epoch 31000  training loss: 0.03797300159931183
epoch 31000  clean testing loss: 0.08976088464260101
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 31100  training loss: 0.03799038007855415
epoch 31100  clean testing loss: 0.09010541439056396
epoch 31200  training loss: 0.03844216465950012
epoch 31200  clean testing loss: 0.08942174166440964
epoch 31300  training loss: 0.03780775144696236
epoch 31300  clean testing loss: 0.08978402614593506
epoch 31400  training loss: 0.03779620677232742

 32%|█████████████████████████▌                                                      | 31898/100000 [02:03<04:41, 241.53it/s]
epoch 31500  training loss: 0.037778452038764954
epoch 31500  clean testing loss: 0.09024171531200409
epoch 31600  training loss: 0.03776972368359566
epoch 31600  clean testing loss: 0.0900966227054596
epoch 31700  training loss: 0.03795076161623001
epoch 31700  clean testing loss: 0.09079928696155548
epoch 31800  training loss: 0.03770620375871658

 32%|█████████████████████████▉                                                      | 32377/100000 [02:05<04:39, 241.62it/s]
epoch 31900  training loss: 0.03848884999752045
epoch 31900  clean testing loss: 0.09218700230121613
epoch 32000  training loss: 0.03774978220462799
epoch 32000  clean testing loss: 0.09086534380912781
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 32100  training loss: 0.037626974284648895
epoch 32100  clean testing loss: 0.09018517285585403
epoch 32200  training loss: 0.03777267783880234
epoch 32200  clean testing loss: 0.09160652756690979
epoch 32300  training loss: 0.039234746247529984

 33%|██████████████████████████▎                                                     | 32859/100000 [02:07<04:40, 239.50it/s]
epoch 32400  training loss: 0.037630971521139145
epoch 32400  clean testing loss: 0.09162738174200058
epoch 32500  training loss: 0.03778579458594322
epoch 32500  clean testing loss: 0.09041014313697815
epoch 32600  training loss: 0.03738134354352951
epoch 32600  clean testing loss: 0.09094713628292084
epoch 32700  training loss: 0.03745800629258156
epoch 32700  clean testing loss: 0.09147174656391144
epoch 32800  training loss: 0.037651997059583664

 33%|██████████████████████████▋                                                     | 33364/100000 [02:09<04:37, 239.98it/s]
epoch 32900  training loss: 0.03731357306241989
epoch 32900  clean testing loss: 0.09181960672140121
epoch 33000  training loss: 0.03725248575210571
epoch 33000  clean testing loss: 0.09174059331417084
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 33100  training loss: 0.037217989563941956
epoch 33100  clean testing loss: 0.09137802571058273
epoch 33200  training loss: 0.037165913730859756
epoch 33200  clean testing loss: 0.09141290932893753
epoch 33300  training loss: 0.03728626295924187

 34%|███████████████████████████                                                     | 33845/100000 [02:11<04:32, 242.84it/s]
epoch 33400  training loss: 0.03718358278274536
epoch 33400  clean testing loss: 0.09143565595149994
epoch 33500  training loss: 0.03715858235955238
epoch 33500  clean testing loss: 0.09226240962743759
epoch 33600  training loss: 0.03714446723461151
epoch 33600  clean testing loss: 0.09222379326820374
epoch 33700  training loss: 0.03702748194336891
epoch 33700  clean testing loss: 0.09197217226028442
epoch 33800  training loss: 0.037029165774583817

 34%|███████████████████████████▍                                                    | 34327/100000 [02:13<04:27, 245.34it/s]
epoch 33900  training loss: 0.037229813635349274
epoch 33900  clean testing loss: 0.09251198172569275
epoch 34000  training loss: 0.03731170669198036
epoch 34000  clean testing loss: 0.09293126314878464
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 34100  training loss: 0.0368964783847332
epoch 34100  clean testing loss: 0.09263838082551956
epoch 34200  training loss: 0.03688487410545349
epoch 34200  clean testing loss: 0.09233181923627853
epoch 34300  training loss: 0.03725721314549446

 35%|███████████████████████████▊                                                    | 34837/100000 [02:15<04:20, 250.20it/s]
epoch 34400  training loss: 0.03680025041103363
epoch 34400  clean testing loss: 0.09235727787017822
epoch 34500  training loss: 0.03678574413061142
epoch 34500  clean testing loss: 0.09258225560188293
epoch 34600  training loss: 0.03718171641230583
epoch 34600  clean testing loss: 0.09236497431993484
epoch 34700  training loss: 0.036753807216882706
epoch 34700  clean testing loss: 0.09275117516517639
epoch 34800  training loss: 0.03710200637578964

 35%|████████████████████████████▎                                                   | 35318/100000 [02:17<04:31, 238.13it/s]
epoch 34900  training loss: 0.03692348301410675
epoch 34900  clean testing loss: 0.09386082738637924
epoch 35000  training loss: 0.03684518486261368
epoch 35000  clean testing loss: 0.093512624502182
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 35100  training loss: 0.03675232455134392
epoch 35100  clean testing loss: 0.09345824271440506
epoch 35200  training loss: 0.03657414764165878
epoch 35200  clean testing loss: 0.0932067483663559
epoch 35300  training loss: 0.036691561341285706

 36%|████████████████████████████▋                                                   | 35805/100000 [02:19<04:16, 249.97it/s]
epoch 35400  training loss: 0.03669510409235954
epoch 35400  clean testing loss: 0.09359709918498993
epoch 35500  training loss: 0.03664550930261612
epoch 35500  clean testing loss: 0.09362030029296875
epoch 35600  training loss: 0.03658897429704666
epoch 35600  clean testing loss: 0.09380887448787689
epoch 35700  training loss: 0.036446839570999146
epoch 35700  clean testing loss: 0.09392471611499786
epoch 35800  training loss: 0.03664404898881912

 36%|█████████████████████████████                                                   | 36290/100000 [02:21<04:16, 248.06it/s]
epoch 35900  training loss: 0.03634188324213028
epoch 35900  clean testing loss: 0.09349948167800903
epoch 36000  training loss: 0.036604151129722595
epoch 36000  clean testing loss: 0.09370604902505875
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 36100  training loss: 0.03631054237484932
epoch 36100  clean testing loss: 0.09406918287277222
epoch 36200  training loss: 0.03625775873661041

 37%|█████████████████████████████▍                                                  | 36796/100000 [02:24<04:22, 240.73it/s]
epoch 36300  training loss: 0.036239489912986755
epoch 36300  clean testing loss: 0.09414192289113998
epoch 36400  training loss: 0.036190759390592575
epoch 36400  clean testing loss: 0.09425296634435654
epoch 36500  training loss: 0.03619905933737755
epoch 36500  clean testing loss: 0.09413763135671616
epoch 36600  training loss: 0.03623141348361969
epoch 36600  clean testing loss: 0.0941474512219429
epoch 36700  training loss: 0.03620821610093117

 37%|█████████████████████████████▊                                                  | 37277/100000 [02:25<04:15, 245.30it/s]
epoch 36800  training loss: 0.03627980500459671
epoch 36800  clean testing loss: 0.09426699578762054
epoch 36900  training loss: 0.03621339052915573
epoch 36900  clean testing loss: 0.0949278250336647
epoch 37000  training loss: 0.03634818270802498
epoch 37000  clean testing loss: 0.09537730365991592
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 37100  training loss: 0.03617360070347786
epoch 37100  clean testing loss: 0.09520678967237473
epoch 37200  training loss: 0.03601227328181267

 38%|██████████████████████████████▏                                                 | 37759/100000 [02:27<04:15, 243.76it/s]
epoch 37300  training loss: 0.03645998612046242
epoch 37300  clean testing loss: 0.09525159001350403
epoch 37400  training loss: 0.0360155887901783
epoch 37400  clean testing loss: 0.09460271894931793
epoch 37500  training loss: 0.0359993539750576
epoch 37500  clean testing loss: 0.09447700530290604
epoch 37600  training loss: 0.035892192274332047
epoch 37600  clean testing loss: 0.09524907171726227
epoch 37700  training loss: 0.03606364130973816

 38%|██████████████████████████████▌                                                 | 38241/100000 [02:29<04:15, 242.18it/s]
epoch 37800  training loss: 0.03592291846871376
epoch 37800  clean testing loss: 0.09497769922018051
epoch 37900  training loss: 0.035832613706588745
epoch 37900  clean testing loss: 0.09494426101446152
epoch 38000  training loss: 0.035831816494464874
epoch 38000  clean testing loss: 0.0953487828373909
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 38100  training loss: 0.035751376301050186
epoch 38100  clean testing loss: 0.09504612535238266
epoch 38200  training loss: 0.03590541332960129

 39%|██████████████████████████████▉                                                 | 38695/100000 [02:31<04:10, 244.35it/s]
epoch 38300  training loss: 0.03609083592891693
epoch 38300  clean testing loss: 0.09590988606214523
epoch 38400  training loss: 0.03575539588928223
epoch 38400  clean testing loss: 0.09598944336175919
epoch 38500  training loss: 0.03571287915110588
epoch 38500  clean testing loss: 0.09563949704170227
epoch 38600  training loss: 0.03572235628962517
epoch 38600  clean testing loss: 0.09544763714075089
epoch 38700  training loss: 0.03577112779021263

 39%|███████████████████████████████▍                                                | 39224/100000 [02:34<04:09, 243.29it/s]
epoch 38800  training loss: 0.035717856138944626
epoch 38800  clean testing loss: 0.09587593376636505
epoch 38900  training loss: 0.035783007740974426
epoch 38900  clean testing loss: 0.09572282433509827
epoch 39000  training loss: 0.03560195118188858
epoch 39000  clean testing loss: 0.09582684189081192
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 39100  training loss: 0.03550686687231064
epoch 39100  clean testing loss: 0.09571748226881027
epoch 39200  training loss: 0.035477615892887115

 40%|███████████████████████████████▊                                                | 39705/100000 [02:36<04:11, 239.77it/s]
epoch 39300  training loss: 0.035461436957120895
epoch 39300  clean testing loss: 0.09589117020368576
epoch 39400  training loss: 0.03546004742383957
epoch 39400  clean testing loss: 0.09606360644102097
epoch 39500  training loss: 0.03546135127544403
epoch 39500  clean testing loss: 0.0961407795548439
epoch 39600  training loss: 0.035465043038129807

 40%|████████████████████████████████▏                                               | 40185/100000 [02:37<04:03, 245.74it/s]
epoch 39700  training loss: 0.03561137616634369
epoch 39700  clean testing loss: 0.09675605595111847
epoch 39800  training loss: 0.03535102680325508
epoch 39800  clean testing loss: 0.09640132635831833
epoch 39900  training loss: 0.035323888063430786
epoch 39900  clean testing loss: 0.0964619368314743
epoch 40000  training loss: 0.035457078367471695
epoch 40000  clean testing loss: 0.09705481678247452
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 40100  training loss: 0.035381752997636795

 41%|████████████████████████████████▌                                               | 40693/100000 [02:40<04:04, 242.33it/s]
epoch 40200  training loss: 0.03527774289250374
epoch 40200  clean testing loss: 0.0966213122010231
epoch 40300  training loss: 0.035274140536785126
epoch 40300  clean testing loss: 0.09656134247779846
epoch 40400  training loss: 0.035414133220911026
epoch 40400  clean testing loss: 0.09712185710668564
epoch 40500  training loss: 0.03527667000889778
epoch 40500  clean testing loss: 0.09661882370710373
epoch 40600  training loss: 0.03547075018286705

 41%|████████████████████████████████▉                                               | 41169/100000 [02:42<04:02, 242.88it/s]
epoch 40700  training loss: 0.03526538237929344
epoch 40700  clean testing loss: 0.09661885350942612
epoch 40800  training loss: 0.03536910563707352
epoch 40800  clean testing loss: 0.09677834063768387
epoch 40900  training loss: 0.035132307559251785
epoch 40900  clean testing loss: 0.09703052043914795
epoch 41000  training loss: 0.03508513793349266
epoch 41000  clean testing loss: 0.09689868986606598
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 41100  training loss: 0.0351269468665123

 42%|█████████████████████████████████▎                                              | 41647/100000 [02:43<03:59, 243.54it/s]
epoch 41200  training loss: 0.035183317959308624
epoch 41200  clean testing loss: 0.09763124585151672
epoch 41300  training loss: 0.03514634445309639
epoch 41300  clean testing loss: 0.09716662764549255
epoch 41400  training loss: 0.0350496731698513
epoch 41400  clean testing loss: 0.0974353700876236
epoch 41500  training loss: 0.03500662371516228
epoch 41500  clean testing loss: 0.09702146053314209
epoch 41600  training loss: 0.035020533949136734

 42%|█████████████████████████████████▋                                              | 42153/100000 [02:46<04:00, 240.36it/s]
epoch 41700  training loss: 0.03501942381262779
epoch 41700  clean testing loss: 0.09734349697828293
epoch 41800  training loss: 0.03494593873620033
epoch 41800  clean testing loss: 0.09731616824865341
epoch 41900  training loss: 0.0349535197019577
epoch 41900  clean testing loss: 0.09767290949821472
epoch 42000  training loss: 0.03491392731666565
epoch 42000  clean testing loss: 0.09749647974967957
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 42100  training loss: 0.03484572097659111

 43%|██████████████████████████████████                                              | 42635/100000 [02:48<03:56, 242.69it/s]
epoch 42200  training loss: 0.034828707575798035
epoch 42200  clean testing loss: 0.0978936105966568
epoch 42300  training loss: 0.03484027832746506
epoch 42300  clean testing loss: 0.09779474139213562
epoch 42400  training loss: 0.034820932894945145
epoch 42400  clean testing loss: 0.09781277924776077
epoch 42500  training loss: 0.034803155809640884
epoch 42500  clean testing loss: 0.09780588746070862
epoch 42600  training loss: 0.03474902734160423

 43%|██████████████████████████████████▍                                             | 43118/100000 [02:50<03:54, 242.79it/s]
epoch 42700  training loss: 0.034826867282390594
epoch 42700  clean testing loss: 0.09810046851634979
epoch 42800  training loss: 0.03475584834814072
epoch 42800  clean testing loss: 0.09777775406837463
epoch 42900  training loss: 0.03474285081028938
epoch 42900  clean testing loss: 0.09841316938400269
epoch 43000  training loss: 0.034735243767499924
epoch 43000  clean testing loss: 0.09784422069787979

 44%|██████████████████████████████████▉                                             | 43600/100000 [02:52<03:51, 244.04it/s]
epoch 43100  training loss: 0.0347130224108696
epoch 43100  clean testing loss: 0.09802752733230591
epoch 43200  training loss: 0.034660156816244125
epoch 43200  clean testing loss: 0.09861035645008087
epoch 43300  training loss: 0.03474774211645126
epoch 43300  clean testing loss: 0.09804703295230865
epoch 43400  training loss: 0.0346505306661129
epoch 43400  clean testing loss: 0.09843479841947556
epoch 43500  training loss: 0.03459736704826355

 44%|███████████████████████████████████▎                                            | 44082/100000 [02:54<03:49, 243.83it/s]
epoch 43600  training loss: 0.03459276631474495
epoch 43600  clean testing loss: 0.0982731506228447
epoch 43700  training loss: 0.03460858762264252
epoch 43700  clean testing loss: 0.0981283187866211
epoch 43800  training loss: 0.034610942006111145
epoch 43800  clean testing loss: 0.09877245128154755
epoch 43900  training loss: 0.03453048691153526
epoch 43900  clean testing loss: 0.09832566231489182
epoch 44000  training loss: 0.03449395298957825
epoch 44000  clean testing loss: 0.09867145866155624

 45%|███████████████████████████████████▋                                            | 44593/100000 [02:56<03:45, 245.92it/s]
epoch 44100  training loss: 0.03447425365447998
epoch 44100  clean testing loss: 0.09881673008203506
epoch 44200  training loss: 0.03450566157698631
epoch 44200  clean testing loss: 0.09854406863451004
epoch 44300  training loss: 0.034443747252225876
epoch 44300  clean testing loss: 0.09857576340436935
epoch 44400  training loss: 0.034431092441082
epoch 44400  clean testing loss: 0.09866844117641449
epoch 44500  training loss: 0.03444470465183258

 45%|████████████████████████████████████                                            | 45071/100000 [02:58<03:47, 240.92it/s]
epoch 44600  training loss: 0.03438292071223259
epoch 44600  clean testing loss: 0.09868008643388748
epoch 44700  training loss: 0.03433888405561447
epoch 44700  clean testing loss: 0.09892993420362473
epoch 44800  training loss: 0.03438049554824829
epoch 44800  clean testing loss: 0.09917326271533966
epoch 44900  training loss: 0.03436316177248955
epoch 44900  clean testing loss: 0.09866958111524582
epoch 45000  training loss: 0.03433966264128685
epoch 45000  clean testing loss: 0.09936320036649704

 46%|████████████████████████████████████▍                                           | 45559/100000 [03:00<03:37, 249.93it/s]
epoch 45100  training loss: 0.03426973521709442
epoch 45100  clean testing loss: 0.09920312464237213
epoch 45200  training loss: 0.034277573227882385
epoch 45200  clean testing loss: 0.09906790405511856
epoch 45300  training loss: 0.03424007445573807
epoch 45300  clean testing loss: 0.09916232526302338
epoch 45400  training loss: 0.034225352108478546
epoch 45400  clean testing loss: 0.09932150691747665
epoch 45500  training loss: 0.03425264731049538

 46%|████████████████████████████████████▊                                           | 46042/100000 [03:02<03:43, 240.90it/s]
epoch 45600  training loss: 0.03432057052850723
epoch 45600  clean testing loss: 0.09968417137861252
epoch 45700  training loss: 0.0342264249920845
epoch 45700  clean testing loss: 0.09929868578910828
epoch 45800  training loss: 0.034169554710388184
epoch 45800  clean testing loss: 0.09934625029563904
epoch 45900  training loss: 0.03420420363545418
epoch 45900  clean testing loss: 0.09933406114578247
epoch 46000  training loss: 0.034133292734622955
epoch 46000  clean testing loss: 0.09951210767030716

 47%|█████████████████████████████████████▏                                          | 46527/100000 [03:04<03:38, 245.05it/s]
epoch 46100  training loss: 0.03415725752711296
epoch 46100  clean testing loss: 0.0993298813700676
epoch 46200  training loss: 0.034141283482313156
epoch 46200  clean testing loss: 0.09935341030359268
epoch 46300  training loss: 0.034110937267541885
epoch 46300  clean testing loss: 0.09998518228530884
epoch 46400  training loss: 0.03408052399754524
epoch 46400  clean testing loss: 0.09982480108737946
epoch 46500  training loss: 0.03402556851506233

 47%|█████████████████████████████████████▋                                          | 47033/100000 [03:06<03:39, 241.80it/s]
epoch 46600  training loss: 0.03404757007956505
epoch 46600  clean testing loss: 0.09966038912534714
epoch 46700  training loss: 0.03403368219733238
epoch 46700  clean testing loss: 0.0999046117067337
epoch 46800  training loss: 0.0340145118534565
epoch 46800  clean testing loss: 0.0998748242855072
epoch 46900  training loss: 0.03398796170949936

 47%|█████████████████████████████████████▉                                          | 47386/100000 [03:07<03:38, 240.36it/s]
epoch 47000  training loss: 0.033958010375499725
epoch 47000  clean testing loss: 0.09987051784992218
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 47100  training loss: 0.03398856148123741
epoch 47100  clean testing loss: 0.10004157572984695
epoch 47200  training loss: 0.033966951072216034
epoch 47200  clean testing loss: 0.09979531168937683
epoch 47300  training loss: 0.03394675254821777
epoch 47300  clean testing loss: 0.10003779828548431
epoch 47400  training loss: 0.03392357751727104

 48%|██████████████████████████████████████▍                                         | 47996/100000 [03:10<03:33, 243.31it/s]
epoch 47500  training loss: 0.03389548882842064
epoch 47500  clean testing loss: 0.10021038353443146
epoch 47600  training loss: 0.03388156369328499
epoch 47600  clean testing loss: 0.09987114369869232
epoch 47700  training loss: 0.033828455954790115
epoch 47700  clean testing loss: 0.09999286383390427
epoch 47800  training loss: 0.033836480230093
epoch 47800  clean testing loss: 0.10019177943468094
epoch 47900  training loss: 0.03380059450864792

 48%|██████████████████████████████████████▊                                         | 48475/100000 [03:12<03:32, 242.88it/s]
epoch 48000  training loss: 0.03382549434900284
epoch 48000  clean testing loss: 0.1001223474740982
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 48100  training loss: 0.033787019550800323
epoch 48100  clean testing loss: 0.10019886493682861
epoch 48200  training loss: 0.03375721722841263
epoch 48200  clean testing loss: 0.10022804886102676
epoch 48300  training loss: 0.0337529256939888
epoch 48300  clean testing loss: 0.10026241093873978
epoch 48400  training loss: 0.033751536160707474

 49%|███████████████████████████████████████▏                                        | 48953/100000 [03:14<03:29, 243.12it/s]
epoch 48500  training loss: 0.033710040152072906
epoch 48500  clean testing loss: 0.100459024310112
epoch 48600  training loss: 0.033703628927469254
epoch 48600  clean testing loss: 0.10048951953649521
epoch 48700  training loss: 0.03369102627038956
epoch 48700  clean testing loss: 0.10036904364824295
epoch 48800  training loss: 0.03368758037686348
epoch 48800  clean testing loss: 0.10061442852020264
epoch 48900  training loss: 0.033753711730241776

 49%|███████████████████████████████████████▌                                        | 49457/100000 [03:16<03:28, 242.11it/s]
epoch 49000  training loss: 0.03365383297204971
epoch 49000  clean testing loss: 0.10047995299100876
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 49100  training loss: 0.03364061936736107
epoch 49100  clean testing loss: 0.10058300942182541
epoch 49200  training loss: 0.03372860699892044
epoch 49200  clean testing loss: 0.10045718401670456
epoch 49300  training loss: 0.03361933305859566
epoch 49300  clean testing loss: 0.10050532966852188
epoch 49400  training loss: 0.03363935276865959

 50%|███████████████████████████████████████▉                                        | 49939/100000 [03:18<03:23, 245.91it/s]
epoch 49500  training loss: 0.033575136214494705
epoch 49500  clean testing loss: 0.10056517273187637
epoch 49600  training loss: 0.033605799078941345
epoch 49600  clean testing loss: 0.10059794783592224
epoch 49700  training loss: 0.0335572175681591
epoch 49700  clean testing loss: 0.10092481225728989
epoch 49800  training loss: 0.03359655290842056
epoch 49800  clean testing loss: 0.1005639061331749
epoch 49900  training loss: 0.03354250639677048

 50%|████████████████████████████████████████▎                                       | 50414/100000 [03:20<03:26, 240.53it/s]
epoch 50000  training loss: 0.03350771963596344
epoch 50000  clean testing loss: 0.1007533147931099
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 50100  training loss: 0.03350666165351868
epoch 50100  clean testing loss: 0.10093985497951508
epoch 50200  training loss: 0.03348853439092636
epoch 50200  clean testing loss: 0.10113751888275146
epoch 50300  training loss: 0.0334743894636631

 51%|████████████████████████████████████████▋                                       | 50851/100000 [03:22<04:04, 200.64it/s]
epoch 50400  training loss: 0.03345513343811035
epoch 50400  clean testing loss: 0.10105424374341965
epoch 50500  training loss: 0.03344639390707016
epoch 50500  clean testing loss: 0.10092946141958237
epoch 50600  training loss: 0.03345014527440071
epoch 50600  clean testing loss: 0.10138153284788132
epoch 50700  training loss: 0.033442649990320206
epoch 50700  clean testing loss: 0.10096237808465958
epoch 50800  training loss: 0.03339247778058052

 51%|████████████████████████████████████████▉                                       | 51224/100000 [03:24<04:08, 196.54it/s]
epoch 50900  training loss: 0.03339487686753273
epoch 50900  clean testing loss: 0.10120923072099686
epoch 51000  training loss: 0.033432334661483765
epoch 51000  clean testing loss: 0.10147073864936829
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 51100  training loss: 0.03335830196738243
epoch 51100  clean testing loss: 0.10135579854249954
epoch 51200  training loss: 0.0333380289375782

 52%|█████████████████████████████████████████▏                                      | 51541/100000 [03:25<04:02, 200.06it/s]
epoch 51300  training loss: 0.03333767130970955
epoch 51300  clean testing loss: 0.10132186114788055
epoch 51400  training loss: 0.03331804648041725
epoch 51400  clean testing loss: 0.10147164016962051
epoch 51500  training loss: 0.03330167755484581
epoch 51500  clean testing loss: 0.10148228704929352
epoch 51600  training loss: 0.03328358754515648

 52%|█████████████████████████████████████████▌                                      | 51938/100000 [03:27<04:06, 194.97it/s]
epoch 51700  training loss: 0.0332702212035656
epoch 51700  clean testing loss: 0.10124208778142929
epoch 51800  training loss: 0.03325905650854111
epoch 51800  clean testing loss: 0.10151515901088715
epoch 51900  training loss: 0.03329160809516907
epoch 51900  clean testing loss: 0.10128157585859299
epoch 52000  training loss: 0.033241547644138336
epoch 52000  clean testing loss: 0.10148599743843079

 52%|█████████████████████████████████████████▊                                      | 52330/100000 [03:29<04:03, 195.45it/s]
epoch 52100  training loss: 0.03322703018784523
epoch 52100  clean testing loss: 0.10173051804304123
epoch 52200  training loss: 0.03319908306002617
epoch 52200  clean testing loss: 0.10152047872543335
epoch 52300  training loss: 0.033227793872356415

 53%|██████████████████████████████████████████▏                                     | 52722/100000 [03:31<04:06, 191.55it/s]
epoch 52400  training loss: 0.03318833187222481
epoch 52400  clean testing loss: 0.10150552541017532
epoch 52500  training loss: 0.03323433920741081
epoch 52500  clean testing loss: 0.10206339508295059
epoch 52600  training loss: 0.03314778208732605
epoch 52600  clean testing loss: 0.10171657055616379
epoch 52700  training loss: 0.0331454873085022

 53%|██████████████████████████████████████████▍                                     | 53112/100000 [03:33<03:56, 197.91it/s]
epoch 52800  training loss: 0.033124398440122604
epoch 52800  clean testing loss: 0.10160566866397858
epoch 52900  training loss: 0.033111393451690674
epoch 52900  clean testing loss: 0.10173799842596054
epoch 53000  training loss: 0.0331815630197525
epoch 53000  clean testing loss: 0.10206900537014008
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 53100  training loss: 0.03310876712203026

 53%|██████████████████████████████████████████▊                                     | 53483/100000 [03:35<04:05, 189.76it/s]
epoch 53200  training loss: 0.03307062014937401
epoch 53200  clean testing loss: 0.10196533054113388
epoch 53300  training loss: 0.033084966242313385
epoch 53300  clean testing loss: 0.10186722874641418
epoch 53400  training loss: 0.03305729106068611
epoch 53400  clean testing loss: 0.10186560451984406
epoch 53500  training loss: 0.03305665776133537

 54%|███████████████████████████████████████████                                     | 53890/100000 [03:37<03:51, 198.82it/s]
epoch 53600  training loss: 0.03306015953421593
epoch 53600  clean testing loss: 0.10194358974695206
epoch 53700  training loss: 0.03301357850432396
epoch 53700  clean testing loss: 0.1020735576748848
epoch 53800  training loss: 0.03299637883901596
epoch 53800  clean testing loss: 0.10199049860239029
epoch 53900  training loss: 0.033023491501808167

 54%|███████████████████████████████████████████▍                                    | 54283/100000 [03:39<03:54, 195.09it/s]
epoch 54000  training loss: 0.032988984137773514
epoch 54000  clean testing loss: 0.1023058369755745
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 54100  training loss: 0.0329580157995224
epoch 54100  clean testing loss: 0.10221613198518753
epoch 54200  training loss: 0.03295337036252022
epoch 54200  clean testing loss: 0.10224664956331253
epoch 54300  training loss: 0.03293536230921745

 55%|███████████████████████████████████████████▋                                    | 54672/100000 [03:41<03:56, 191.41it/s]
epoch 54400  training loss: 0.032934390008449554
epoch 54400  clean testing loss: 0.10229440033435822
epoch 54500  training loss: 0.03292235732078552
epoch 54500  clean testing loss: 0.1024237871170044
epoch 54600  training loss: 0.0329071581363678
epoch 54600  clean testing loss: 0.10221199691295624
epoch 54700  training loss: 0.032907359302043915

 55%|████████████████████████████████████████████                                    | 55062/100000 [03:43<03:53, 192.17it/s]
epoch 54800  training loss: 0.032923515886068344
epoch 54800  clean testing loss: 0.1026749312877655
epoch 54900  training loss: 0.032867684960365295
epoch 54900  clean testing loss: 0.1023687794804573
epoch 55000  training loss: 0.03286590054631233
epoch 55000  clean testing loss: 0.10233355313539505
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 55100  training loss: 0.0328545905649662

 55%|████████████████████████████████████████████▎                                   | 55454/100000 [03:45<03:51, 192.14it/s]
epoch 55200  training loss: 0.03283169865608215
epoch 55200  clean testing loss: 0.1024450734257698
epoch 55300  training loss: 0.032830074429512024
epoch 55300  clean testing loss: 0.10249499976634979
epoch 55400  training loss: 0.032810963690280914
epoch 55400  clean testing loss: 0.10266692191362381
epoch 55500  training loss: 0.03280077129602432

 56%|████████████████████████████████████████████▋                                   | 55845/100000 [03:47<03:46, 194.59it/s]
epoch 55600  training loss: 0.032788295298814774
epoch 55600  clean testing loss: 0.10259249061346054
epoch 55700  training loss: 0.03278154879808426
epoch 55700  clean testing loss: 0.10272213816642761
epoch 55800  training loss: 0.03278636187314987

 56%|████████████████████████████████████████████▉                                   | 56238/100000 [03:49<03:43, 195.65it/s]
epoch 55900  training loss: 0.032759830355644226
epoch 55900  clean testing loss: 0.10271525382995605
epoch 56000  training loss: 0.032754722982645035
epoch 56000  clean testing loss: 0.10257720202207565
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 56100  training loss: 0.03273765370249748
epoch 56100  clean testing loss: 0.10276257991790771
epoch 56200  training loss: 0.032725654542446136

 57%|█████████████████████████████████████████████▎                                  | 56587/100000 [03:51<03:42, 195.06it/s]
epoch 56300  training loss: 0.03272252902388573
epoch 56300  clean testing loss: 0.10277357697486877
epoch 56400  training loss: 0.032699789851903915
epoch 56400  clean testing loss: 0.10280828177928925
epoch 56500  training loss: 0.03272099792957306
epoch 56500  clean testing loss: 0.10301663726568222
epoch 56600  training loss: 0.032680463045835495

 57%|█████████████████████████████████████████████▌                                  | 57020/100000 [03:53<03:46, 190.03it/s]
epoch 56700  training loss: 0.032666005194187164
epoch 56700  clean testing loss: 0.10285428166389465
epoch 56800  training loss: 0.032654114067554474
epoch 56800  clean testing loss: 0.10296786576509476
epoch 56900  training loss: 0.03264927491545677
epoch 56900  clean testing loss: 0.10291258245706558
epoch 57000  training loss: 0.032633014023303986
epoch 57000  clean testing loss: 0.103043332695961

 57%|█████████████████████████████████████████████▉                                  | 57411/100000 [03:55<03:40, 193.02it/s]
epoch 57100  training loss: 0.03262870013713837
epoch 57100  clean testing loss: 0.1031322106719017
epoch 57200  training loss: 0.03261513635516167
epoch 57200  clean testing loss: 0.10307306051254272
epoch 57300  training loss: 0.0326114147901535
epoch 57300  clean testing loss: 0.10310002416372299
epoch 57400  training loss: 0.032604243606328964

 58%|██████████████████████████████████████████████▏                                 | 57802/100000 [03:57<03:39, 192.10it/s]
epoch 57500  training loss: 0.0326043963432312
epoch 57500  clean testing loss: 0.10303929448127747
epoch 57600  training loss: 0.032575927674770355
epoch 57600  clean testing loss: 0.10323033481836319
epoch 57700  training loss: 0.032565969973802567
epoch 57700  clean testing loss: 0.10324413329362869
epoch 57800  training loss: 0.032567597925662994

 58%|██████████████████████████████████████████████▌                                 | 58196/100000 [03:59<03:31, 197.77it/s]
epoch 57900  training loss: 0.03254587575793266
epoch 57900  clean testing loss: 0.10319007188081741
epoch 58000  training loss: 0.032556213438510895
epoch 58000  clean testing loss: 0.10326842218637466
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 58100  training loss: 0.032530877739191055
epoch 58100  clean testing loss: 0.10333609580993652
epoch 58200  training loss: 0.032531462609767914

 59%|██████████████████████████████████████████████▊                                 | 58585/100000 [04:01<03:32, 194.61it/s]
epoch 58300  training loss: 0.032526079565286636
epoch 58300  clean testing loss: 0.10322853922843933
epoch 58400  training loss: 0.032502371817827225
epoch 58400  clean testing loss: 0.10327156633138657
epoch 58500  training loss: 0.03254257142543793
epoch 58500  clean testing loss: 0.10361281037330627
epoch 58600  training loss: 0.03248937427997589

 59%|███████████████████████████████████████████████▏                                | 58976/100000 [04:03<03:30, 195.08it/s]
epoch 58700  training loss: 0.03247120976448059
epoch 58700  clean testing loss: 0.10357031971216202
epoch 58800  training loss: 0.03246930241584778
epoch 58800  clean testing loss: 0.10345125198364258
epoch 58900  training loss: 0.03245309740304947
epoch 58900  clean testing loss: 0.1033443734049797
epoch 59000  training loss: 0.03243657201528549
epoch 59000  clean testing loss: 0.10344790667295456

 59%|███████████████████████████████████████████████▍                                | 59367/100000 [04:05<03:25, 197.96it/s]
epoch 59100  training loss: 0.03245704621076584
epoch 59100  clean testing loss: 0.10367674380540848
epoch 59200  training loss: 0.03241473436355591
epoch 59200  clean testing loss: 0.10363810509443283
epoch 59300  training loss: 0.032405123114585876
epoch 59300  clean testing loss: 0.10354511439800262
epoch 59400  training loss: 0.03240630403161049

 60%|███████████████████████████████████████████████▊                                | 59762/100000 [04:07<03:27, 193.49it/s]
epoch 59500  training loss: 0.03240302577614784
epoch 59500  clean testing loss: 0.10364744812250137
epoch 59600  training loss: 0.032376378774642944
epoch 59600  clean testing loss: 0.10361803323030472
epoch 59700  training loss: 0.03236695006489754
epoch 59700  clean testing loss: 0.10378841310739517
epoch 59800  training loss: 0.03239399194717407

 60%|████████████████████████████████████████████████                                | 60154/100000 [04:09<03:22, 196.72it/s]
epoch 59900  training loss: 0.03235800191760063
epoch 59900  clean testing loss: 0.10383937507867813
epoch 60000  training loss: 0.03235069289803505
epoch 60000  clean testing loss: 0.10375916212797165
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 60100  training loss: 0.032324422150850296
epoch 60100  clean testing loss: 0.10383797436952591
epoch 60200  training loss: 0.03233141079545021

 61%|████████████████████████████████████████████████▍                               | 60545/100000 [04:11<03:25, 192.19it/s]
epoch 60300  training loss: 0.03231535851955414
epoch 60300  clean testing loss: 0.10383852571249008
epoch 60400  training loss: 0.032301098108291626
epoch 60400  clean testing loss: 0.10388579219579697
epoch 60500  training loss: 0.03230614587664604

 61%|████████████████████████████████████████████████▋                               | 60937/100000 [04:13<03:16, 198.30it/s]
epoch 60600  training loss: 0.03228670358657837
epoch 60600  clean testing loss: 0.10398248583078384
epoch 60700  training loss: 0.03228028863668442
epoch 60700  clean testing loss: 0.1040639728307724
epoch 60800  training loss: 0.032270073890686035
epoch 60800  clean testing loss: 0.10402125120162964
epoch 60900  training loss: 0.032263122498989105

 61%|█████████████████████████████████████████████████                               | 61328/100000 [04:15<03:17, 196.01it/s]
epoch 61000  training loss: 0.03225288540124893
epoch 61000  clean testing loss: 0.10403741151094437
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 61100  training loss: 0.03226307034492493
epoch 61100  clean testing loss: 0.1039915382862091
epoch 61200  training loss: 0.03224465996026993
epoch 61200  clean testing loss: 0.10415084660053253
epoch 61300  training loss: 0.032237596809864044

 62%|█████████████████████████████████████████████████▍                              | 61721/100000 [04:17<03:12, 198.38it/s]
epoch 61400  training loss: 0.03223143145442009
epoch 61400  clean testing loss: 0.10421691834926605
epoch 61500  training loss: 0.03220868110656738
epoch 61500  clean testing loss: 0.10420707613229752
epoch 61600  training loss: 0.03221095725893974
epoch 61600  clean testing loss: 0.10415440797805786
epoch 61700  training loss: 0.032206978648900986

 62%|█████████████████████████████████████████████████▋                              | 62111/100000 [04:19<03:14, 195.14it/s]
epoch 61800  training loss: 0.03218730539083481
epoch 61800  clean testing loss: 0.10441647469997406
epoch 61900  training loss: 0.03217656910419464
epoch 61900  clean testing loss: 0.10425823926925659
epoch 62000  training loss: 0.032170508056879044
epoch 62000  clean testing loss: 0.10433724522590637
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 62100  training loss: 0.03217010572552681

 63%|██████████████████████████████████████████████████                              | 62503/100000 [04:21<03:14, 193.09it/s]
epoch 62200  training loss: 0.032161563634872437
epoch 62200  clean testing loss: 0.10421428084373474
epoch 62300  training loss: 0.0321439765393734
epoch 62300  clean testing loss: 0.10442240536212921
epoch 62400  training loss: 0.032133422791957855
epoch 62400  clean testing loss: 0.10444260388612747
epoch 62500  training loss: 0.032138511538505554

 63%|██████████████████████████████████████████████████▎                             | 62892/100000 [04:23<03:08, 196.88it/s]
epoch 62600  training loss: 0.032122138887643814
epoch 62600  clean testing loss: 0.10441658645868301
epoch 62700  training loss: 0.03212267532944679
epoch 62700  clean testing loss: 0.10458701848983765
epoch 62800  training loss: 0.03210577741265297
epoch 62800  clean testing loss: 0.10447189211845398
epoch 62900  training loss: 0.032094720751047134

 63%|██████████████████████████████████████████████████▋                             | 63282/100000 [04:25<03:11, 191.96it/s]
epoch 63000  training loss: 0.03208201751112938
epoch 63000  clean testing loss: 0.10452046990394592
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 63100  training loss: 0.032074153423309326
epoch 63100  clean testing loss: 0.10462281107902527
epoch 63200  training loss: 0.032073136419057846
epoch 63200  clean testing loss: 0.1045403853058815
epoch 63300  training loss: 0.03206982463598251

 64%|██████████████████████████████████████████████████▉                             | 63674/100000 [04:27<03:05, 196.06it/s]
epoch 63400  training loss: 0.03205535188317299
epoch 63400  clean testing loss: 0.10469942539930344
epoch 63500  training loss: 0.03204591944813728
epoch 63500  clean testing loss: 0.1046721562743187
epoch 63600  training loss: 0.03203459456562996
epoch 63600  clean testing loss: 0.1047268882393837
epoch 63700  training loss: 0.032032351940870285

 64%|███████████████████████████████████████████████████▏                            | 64061/100000 [04:29<03:06, 192.80it/s]
epoch 63800  training loss: 0.03202998265624046
epoch 63800  clean testing loss: 0.1047244593501091
epoch 63900  training loss: 0.03201621398329735
epoch 63900  clean testing loss: 0.10474058985710144
epoch 64000  training loss: 0.03201138228178024
epoch 64000  clean testing loss: 0.10483007878065109
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 64100  training loss: 0.03199997544288635

 64%|███████████████████████████████████████████████████▌                            | 64454/100000 [04:31<02:58, 199.28it/s]
epoch 64200  training loss: 0.03199548274278641
epoch 64200  clean testing loss: 0.10484794527292252
epoch 64300  training loss: 0.0319916233420372
epoch 64300  clean testing loss: 0.10476390272378922
epoch 64400  training loss: 0.031984079629182816

 65%|███████████████████████████████████████████████████▊                            | 64842/100000 [04:33<03:00, 195.03it/s]
epoch 64500  training loss: 0.03196924179792404
epoch 64500  clean testing loss: 0.10486940294504166
epoch 64600  training loss: 0.03196549415588379
epoch 64600  clean testing loss: 0.1049724817276001
epoch 64700  training loss: 0.03195856511592865
epoch 64700  clean testing loss: 0.1049935445189476
epoch 64800  training loss: 0.031956154853105545

 65%|████████████████████████████████████████████████████▏                           | 65237/100000 [04:35<02:54, 198.75it/s]
epoch 64900  training loss: 0.031945813447237015
epoch 64900  clean testing loss: 0.10491617023944855
epoch 65000  training loss: 0.031932760030031204
epoch 65000  clean testing loss: 0.10497269034385681
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 65100  training loss: 0.031922370195388794
epoch 65100  clean testing loss: 0.10497517138719559
epoch 65200  training loss: 0.03192007541656494

 66%|████████████████████████████████████████████████████▌                           | 65636/100000 [04:37<02:56, 194.89it/s]
epoch 65300  training loss: 0.031916167587041855
epoch 65300  clean testing loss: 0.10509610176086426
epoch 65400  training loss: 0.03190194070339203
epoch 65400  clean testing loss: 0.10512396693229675
epoch 65500  training loss: 0.031897883862257004
epoch 65500  clean testing loss: 0.1050410345196724
epoch 65600  training loss: 0.031892161816358566

 66%|████████████████████████████████████████████████████▊                           | 66030/100000 [04:39<02:54, 194.59it/s]
epoch 65700  training loss: 0.03188539668917656
epoch 65700  clean testing loss: 0.1051376536488533
epoch 65800  training loss: 0.031877581030130386
epoch 65800  clean testing loss: 0.10514432191848755
epoch 65900  training loss: 0.03187400475144386
epoch 65900  clean testing loss: 0.10526332259178162
epoch 66000  training loss: 0.0318644717335701
epoch 66000  clean testing loss: 0.10521171241998672

 66%|█████████████████████████████████████████████████████▏                          | 66422/100000 [04:41<02:51, 195.99it/s]
epoch 66100  training loss: 0.03185141459107399
epoch 66100  clean testing loss: 0.105181485414505
epoch 66200  training loss: 0.031842466443777084
epoch 66200  clean testing loss: 0.10522174090147018
epoch 66300  training loss: 0.031838368624448776
epoch 66300  clean testing loss: 0.10529431700706482
epoch 66400  training loss: 0.031834784895181656

 67%|█████████████████████████████████████████████████████▍                          | 66814/100000 [04:43<02:46, 199.14it/s]
epoch 66500  training loss: 0.03182981163263321
epoch 66500  clean testing loss: 0.1052306592464447
epoch 66600  training loss: 0.03182988986372948
epoch 66600  clean testing loss: 0.10525722056627274
epoch 66700  training loss: 0.03182216361165047
epoch 66700  clean testing loss: 0.10524669289588928
epoch 66800  training loss: 0.0318094827234745

 67%|█████████████████████████████████████████████████████▊                          | 67201/100000 [04:45<02:48, 194.69it/s]
epoch 66900  training loss: 0.03180088847875595
epoch 66900  clean testing loss: 0.10525385290384293
epoch 67000  training loss: 0.03179656341671944
epoch 67000  clean testing loss: 0.10526685416698456
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 67100  training loss: 0.03179376199841499
epoch 67100  clean testing loss: 0.10529965907335281
epoch 67200  training loss: 0.031782522797584534

 68%|██████████████████████████████████████████████████████                          | 67592/100000 [04:47<02:48, 191.97it/s]
epoch 67300  training loss: 0.03178046643733978
epoch 67300  clean testing loss: 0.10529433190822601
epoch 67400  training loss: 0.031768836081027985
epoch 67400  clean testing loss: 0.10539166629314423
epoch 67500  training loss: 0.03176381438970566
epoch 67500  clean testing loss: 0.10539312660694122
epoch 67600  training loss: 0.031757086515426636

 68%|██████████████████████████████████████████████████████▍                         | 67984/100000 [04:49<02:41, 198.41it/s]
epoch 67700  training loss: 0.03175562620162964
epoch 67700  clean testing loss: 0.10544228553771973
epoch 67800  training loss: 0.03174769878387451
epoch 67800  clean testing loss: 0.10543039441108704
epoch 67900  training loss: 0.03174035623669624
epoch 67900  clean testing loss: 0.1054709404706955
epoch 68000  training loss: 0.031737372279167175
epoch 68000  clean testing loss: 0.10542590916156769

 68%|██████████████████████████████████████████████████████▋                         | 68375/100000 [04:51<02:43, 193.97it/s]
epoch 68100  training loss: 0.031728316098451614
epoch 68100  clean testing loss: 0.10536783188581467
epoch 68200  training loss: 0.03172101080417633
epoch 68200  clean testing loss: 0.10554047673940659
epoch 68300  training loss: 0.03171102702617645
epoch 68300  clean testing loss: 0.10554500669240952
epoch 68400  training loss: 0.0317053385078907

 69%|███████████████████████████████████████████████████████                         | 68772/100000 [04:53<02:37, 197.67it/s]
epoch 68500  training loss: 0.03169741481542587
epoch 68500  clean testing loss: 0.1055893748998642
epoch 68600  training loss: 0.03169788047671318
epoch 68600  clean testing loss: 0.10546944290399551
epoch 68700  training loss: 0.03168601542711258
epoch 68700  clean testing loss: 0.10561392456293106
epoch 68800  training loss: 0.031684406101703644

 69%|███████████████████████████████████████████████████████▎                        | 69164/100000 [04:55<02:38, 195.12it/s]
epoch 68900  training loss: 0.03167082369327545
epoch 68900  clean testing loss: 0.10554257780313492
epoch 69000  training loss: 0.031668294221162796
epoch 69000  clean testing loss: 0.10552392899990082
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 69100  training loss: 0.0316614955663681
epoch 69100  clean testing loss: 0.10559110343456268
epoch 69200  training loss: 0.03165304288268089

 70%|███████████████████████████████████████████████████████▋                        | 69558/100000 [04:57<02:31, 200.87it/s]
epoch 69300  training loss: 0.03164560720324516
epoch 69300  clean testing loss: 0.1055988147854805
epoch 69400  training loss: 0.03164088353514671
epoch 69400  clean testing loss: 0.10556098073720932
epoch 69500  training loss: 0.03163576126098633

 70%|███████████████████████████████████████████████████████▉                        | 69951/100000 [04:59<02:33, 196.05it/s]
epoch 69600  training loss: 0.03163277730345726
epoch 69600  clean testing loss: 0.10553015023469925
epoch 69700  training loss: 0.031630728393793106
epoch 69700  clean testing loss: 0.10560191422700882
epoch 69800  training loss: 0.031617891043424606
epoch 69800  clean testing loss: 0.10550179332494736
epoch 69900  training loss: 0.03161555156111717

 70%|████████████████████████████████████████████████████████▎                       | 70344/100000 [05:01<02:28, 199.69it/s]
epoch 70000  training loss: 0.03160611912608147
epoch 70000  clean testing loss: 0.1055498719215393
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 70100  training loss: 0.03160340338945389
epoch 70100  clean testing loss: 0.10551291704177856
epoch 70200  training loss: 0.0315990224480629
epoch 70200  clean testing loss: 0.10550447553396225
epoch 70300  training loss: 0.031593985855579376

 71%|████████████████████████████████████████████████████████▌                       | 70734/100000 [05:03<02:28, 196.96it/s]
epoch 70400  training loss: 0.031581662595272064
epoch 70400  clean testing loss: 0.10551059246063232
epoch 70500  training loss: 0.0315803624689579
epoch 70500  clean testing loss: 0.10536081343889236
epoch 70600  training loss: 0.03157135471701622
epoch 70600  clean testing loss: 0.10539719462394714
epoch 70700  training loss: 0.03156062960624695

 71%|████████████████████████████████████████████████████████▉                       | 71125/100000 [05:05<02:30, 191.76it/s]
epoch 70800  training loss: 0.03155509755015373
epoch 70800  clean testing loss: 0.105355404317379
epoch 70900  training loss: 0.03154582530260086
epoch 70900  clean testing loss: 0.10536682605743408
epoch 71000  training loss: 0.03153927996754646
epoch 71000  clean testing loss: 0.10531947761774063
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 71100  training loss: 0.03153520077466965

 72%|█████████████████████████████████████████████████████████▏                      | 71519/100000 [05:07<02:25, 195.76it/s]
epoch 71200  training loss: 0.03152703866362572
epoch 71200  clean testing loss: 0.1053074523806572
epoch 71300  training loss: 0.03152144327759743
epoch 71300  clean testing loss: 0.10536204278469086
epoch 71400  training loss: 0.0315130390226841
epoch 71400  clean testing loss: 0.10522134602069855
epoch 71500  training loss: 0.0315040722489357

 72%|█████████████████████████████████████████████████████████▌                      | 71912/100000 [05:10<02:27, 190.86it/s]
epoch 71600  training loss: 0.03149403631687164
epoch 71600  clean testing loss: 0.10535132139921188
epoch 71700  training loss: 0.03148917108774185
epoch 71700  clean testing loss: 0.10531386733055115
epoch 71800  training loss: 0.031479477882385254
epoch 71800  clean testing loss: 0.1053713858127594
epoch 71900  training loss: 0.03147515654563904

 72%|█████████████████████████████████████████████████████████▊                      | 72326/100000 [05:12<02:20, 196.97it/s]
epoch 72000  training loss: 0.03146692365407944
epoch 72000  clean testing loss: 0.10530854016542435
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 72100  training loss: 0.03146069124341011
epoch 72100  clean testing loss: 0.10530261695384979
epoch 72200  training loss: 0.03145647421479225
epoch 72200  clean testing loss: 0.10530851036310196
epoch 72300  training loss: 0.031449299305677414

 73%|██████████████████████████████████████████████████████████▏                     | 72720/100000 [05:14<02:17, 199.08it/s]
epoch 72400  training loss: 0.03145001828670502
epoch 72400  clean testing loss: 0.10531758517026901
epoch 72500  training loss: 0.031444426625967026
epoch 72500  clean testing loss: 0.10529663413763046
epoch 72600  training loss: 0.03143429383635521
epoch 72600  clean testing loss: 0.10529076308012009
epoch 72700  training loss: 0.031433265656232834

 73%|██████████████████████████████████████████████████████████▍                     | 73094/100000 [05:16<02:16, 196.89it/s]
epoch 72800  training loss: 0.03142775967717171
epoch 72800  clean testing loss: 0.10527601093053818
epoch 72900  training loss: 0.03142537176609039
epoch 72900  clean testing loss: 0.10524997115135193
epoch 73000  training loss: 0.03141588717699051
epoch 73000  clean testing loss: 0.10528957098722458
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 73100  training loss: 0.03140952065587044

 73%|██████████████████████████████████████████████████████████▊                     | 73485/100000 [05:18<02:23, 185.40it/s]
epoch 73200  training loss: 0.03140245005488396
epoch 73200  clean testing loss: 0.10531259328126907
epoch 73300  training loss: 0.03139838948845863
epoch 73300  clean testing loss: 0.10534265637397766
epoch 73400  training loss: 0.03139866888523102
epoch 73400  clean testing loss: 0.10529471188783646
epoch 73500  training loss: 0.031388115137815475

 74%|███████████████████████████████████████████████████████████                     | 73876/100000 [05:20<02:11, 198.05it/s]
epoch 73600  training loss: 0.0313861146569252
epoch 73600  clean testing loss: 0.10525548458099365
epoch 73700  training loss: 0.031380169093608856
epoch 73700  clean testing loss: 0.10525921732187271
epoch 73800  training loss: 0.03137155994772911
epoch 73800  clean testing loss: 0.10531288385391235
epoch 73900  training loss: 0.03136632218956947

 74%|███████████████████████████████████████████████████████████▍                    | 74269/100000 [05:22<02:12, 193.59it/s]
epoch 74000  training loss: 0.031361665576696396
epoch 74000  clean testing loss: 0.1053534522652626
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 74100  training loss: 0.03136046603322029
epoch 74100  clean testing loss: 0.10527747124433517
epoch 74200  training loss: 0.031352415680885315

 75%|███████████████████████████████████████████████████████████▋                    | 74666/100000 [05:24<02:07, 198.12it/s]
epoch 74300  training loss: 0.03135310113430023
epoch 74300  clean testing loss: 0.10531066358089447
epoch 74400  training loss: 0.03134532272815704
epoch 74400  clean testing loss: 0.10536442697048187
epoch 74500  training loss: 0.03134133294224739
epoch 74500  clean testing loss: 0.10532219707965851
epoch 74600  training loss: 0.031332194805145264

 75%|████████████████████████████████████████████████████████████                    | 75058/100000 [05:26<02:09, 192.00it/s]
epoch 74700  training loss: 0.031331900507211685
epoch 74700  clean testing loss: 0.10530699789524078
epoch 74800  training loss: 0.03132088482379913
epoch 74800  clean testing loss: 0.1053156778216362
epoch 74900  training loss: 0.0313163623213768
epoch 74900  clean testing loss: 0.10532626509666443
epoch 75000  training loss: 0.03131180256605148
epoch 75000  clean testing loss: 0.10533490777015686

 75%|████████████████████████████████████████████████████████████▎                   | 75455/100000 [05:28<02:04, 197.88it/s]
epoch 75100  training loss: 0.03130646049976349
epoch 75100  clean testing loss: 0.10536668449640274
epoch 75200  training loss: 0.03130146861076355
epoch 75200  clean testing loss: 0.10535410046577454
epoch 75300  training loss: 0.031297314912080765
epoch 75300  clean testing loss: 0.10533174127340317
epoch 75400  training loss: 0.031291961669921875

 76%|████████████████████████████████████████████████████████████▋                   | 75847/100000 [05:30<02:06, 191.60it/s]
epoch 75500  training loss: 0.031288910657167435
epoch 75500  clean testing loss: 0.10539133101701736
epoch 75600  training loss: 0.03128395602107048
epoch 75600  clean testing loss: 0.10536414384841919
epoch 75700  training loss: 0.03127874806523323
epoch 75700  clean testing loss: 0.1053674966096878
epoch 75800  training loss: 0.031274955719709396

 76%|████████████████████████████████████████████████████████████▉                   | 76241/100000 [05:32<02:00, 197.20it/s]
epoch 75900  training loss: 0.03127334266901016
epoch 75900  clean testing loss: 0.10535058379173279
epoch 76000  training loss: 0.031265899538993835
epoch 76000  clean testing loss: 0.10539903491735458
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 76100  training loss: 0.031262923032045364
epoch 76100  clean testing loss: 0.10539966821670532
epoch 76200  training loss: 0.031255852431058884

 77%|█████████████████████████████████████████████████████████████▎                  | 76635/100000 [05:34<02:00, 193.53it/s]
epoch 76300  training loss: 0.03125184029340744
epoch 76300  clean testing loss: 0.10534746199846268
epoch 76400  training loss: 0.031246626749634743
epoch 76400  clean testing loss: 0.10539393126964569
epoch 76500  training loss: 0.031246356666088104
epoch 76500  clean testing loss: 0.1053805872797966
epoch 76600  training loss: 0.031238729134202003

 77%|█████████████████████████████████████████████████████████████▌                  | 76980/100000 [05:35<01:44, 221.15it/s]
epoch 76700  training loss: 0.031236259266734123
epoch 76700  clean testing loss: 0.10544077306985855
epoch 76800  training loss: 0.031229592859745026
epoch 76800  clean testing loss: 0.10544804483652115
epoch 76900  training loss: 0.031226791441440582
epoch 76900  clean testing loss: 0.10540387779474258
epoch 77000  training loss: 0.03122008591890335
epoch 77000  clean testing loss: 0.10541166365146637

 77%|█████████████████████████████████████████████████████████████▉                  | 77393/100000 [05:46<01:46, 211.86it/s]
epoch 77100  training loss: 0.031220491975545883
epoch 77100  clean testing loss: 0.10535009950399399
epoch 77200  training loss: 0.031213967129588127
epoch 77200  clean testing loss: 0.10546761006116867
epoch 77300  training loss: 0.031206902116537094
epoch 77300  clean testing loss: 0.10540079325437546
epoch 77400  training loss: 0.031204434111714363

 78%|██████████████████████████████████████████████████████████████▎                 | 77835/100000 [05:48<01:41, 219.05it/s]
epoch 77500  training loss: 0.031198576092720032
epoch 77500  clean testing loss: 0.10544389486312866
epoch 77600  training loss: 0.031193014234304428
epoch 77600  clean testing loss: 0.10543906688690186
epoch 77700  training loss: 0.031191766262054443
epoch 77700  clean testing loss: 0.10550441592931747
epoch 77800  training loss: 0.031188081949949265

 78%|██████████████████████████████████████████████████████████████▌                 | 78246/100000 [05:50<01:39, 217.97it/s]
epoch 77900  training loss: 0.031181039288640022
epoch 77900  clean testing loss: 0.10549846291542053
epoch 78000  training loss: 0.031178921461105347
epoch 78000  clean testing loss: 0.1054299995303154
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 78100  training loss: 0.031171342357993126
epoch 78100  clean testing loss: 0.10547652095556259
epoch 78200  training loss: 0.031169114634394646

 79%|██████████████████████████████████████████████████████████████▉                 | 78686/100000 [05:52<01:39, 214.83it/s]
epoch 78300  training loss: 0.03116524964570999
epoch 78300  clean testing loss: 0.1054948940873146
epoch 78400  training loss: 0.03116203285753727
epoch 78400  clean testing loss: 0.10546907782554626
epoch 78500  training loss: 0.03115851804614067
epoch 78500  clean testing loss: 0.10547030717134476
epoch 78600  training loss: 0.031153466552495956
epoch 78600  clean testing loss: 0.10550917685031891
epoch 78700  training loss: 0.031149469316005707

 79%|███████████████████████████████████████████████████████████████▎                | 79126/100000 [05:54<01:34, 221.63it/s]
epoch 78800  training loss: 0.03114805556833744
epoch 78800  clean testing loss: 0.10548073053359985
epoch 78900  training loss: 0.031141210347414017
epoch 78900  clean testing loss: 0.10549238324165344
epoch 79000  training loss: 0.031138185411691666
epoch 79000  clean testing loss: 0.10550015419721603
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 79100  training loss: 0.031134191900491714

 80%|███████████████████████████████████████████████████████████████▋                | 79563/100000 [05:56<01:33, 218.05it/s]
epoch 79200  training loss: 0.031131871044635773
epoch 79200  clean testing loss: 0.10546126961708069
epoch 79300  training loss: 0.031127039343118668
epoch 79300  clean testing loss: 0.10551980882883072
epoch 79400  training loss: 0.03112264722585678
epoch 79400  clean testing loss: 0.10547616332769394
epoch 79500  training loss: 0.031119421124458313

 80%|████████████████████████████████████████████████████████████████                | 80005/100000 [05:58<01:30, 220.92it/s]
epoch 79600  training loss: 0.03111659549176693
epoch 79600  clean testing loss: 0.10549527406692505
epoch 79700  training loss: 0.031111881136894226
epoch 79700  clean testing loss: 0.10551615059375763
epoch 79800  training loss: 0.0311074648052454
epoch 79800  clean testing loss: 0.10551510006189346
epoch 79900  training loss: 0.031103970482945442
epoch 79900  clean testing loss: 0.10553917288780212
epoch 80000  training loss: 0.031099660322070122
epoch 80000  clean testing loss: 0.10551785677671432

 80%|████████████████████████████████████████████████████████████████▎               | 80442/100000 [06:00<01:28, 220.02it/s]
epoch 80100  training loss: 0.031095042824745178
epoch 80100  clean testing loss: 0.10551245510578156
epoch 80200  training loss: 0.031092045828700066
epoch 80200  clean testing loss: 0.10557941347360611
epoch 80300  training loss: 0.03108738176524639
epoch 80300  clean testing loss: 0.10555905103683472
epoch 80400  training loss: 0.03108369931578636

 81%|████████████████████████████████████████████████████████████████▋               | 80883/100000 [06:02<01:29, 213.87it/s]
epoch 80500  training loss: 0.031082654371857643
epoch 80500  clean testing loss: 0.10555847734212875
epoch 80600  training loss: 0.03107629530131817
epoch 80600  clean testing loss: 0.10550574958324432
epoch 80700  training loss: 0.031070526689291
epoch 80700  clean testing loss: 0.10557109117507935
epoch 80800  training loss: 0.031067071482539177
epoch 80800  clean testing loss: 0.10560241341590881
epoch 80900  training loss: 0.03106270544230938

 81%|█████████████████████████████████████████████████████████████████               | 81326/100000 [06:04<01:24, 219.71it/s]
epoch 81000  training loss: 0.031059302389621735
epoch 81000  clean testing loss: 0.10560983419418335
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 81100  training loss: 0.031055716797709465
epoch 81100  clean testing loss: 0.10554872453212738
epoch 81200  training loss: 0.031052906066179276
epoch 81200  clean testing loss: 0.10556958615779877
epoch 81300  training loss: 0.031049534678459167

 82%|█████████████████████████████████████████████████████████████████▍              | 81769/100000 [06:06<01:25, 214.13it/s]
epoch 81400  training loss: 0.031045682728290558
epoch 81400  clean testing loss: 0.10555897653102875
epoch 81500  training loss: 0.031042901799082756
epoch 81500  clean testing loss: 0.10561485588550568
epoch 81600  training loss: 0.03104088082909584
epoch 81600  clean testing loss: 0.10557692497968674
epoch 81700  training loss: 0.031036676838994026

 82%|█████████████████████████████████████████████████████████████████▊              | 82217/100000 [06:08<01:20, 219.95it/s]
epoch 81800  training loss: 0.031033333390951157
epoch 81800  clean testing loss: 0.10557474195957184
epoch 81900  training loss: 0.03102882392704487
epoch 81900  clean testing loss: 0.10562576353549957
epoch 82000  training loss: 0.031027140095829964
epoch 82000  clean testing loss: 0.10558860003948212
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 82100  training loss: 0.031021157279610634
epoch 82100  clean testing loss: 0.10566556453704834
epoch 82200  training loss: 0.031019296497106552

 83%|██████████████████████████████████████████████████████████████████▏             | 82662/100000 [06:10<01:20, 215.36it/s]
epoch 82300  training loss: 0.03101460076868534
epoch 82300  clean testing loss: 0.10561033338308334
epoch 82400  training loss: 0.031011635437607765
epoch 82400  clean testing loss: 0.10565844923257828
epoch 82500  training loss: 0.0310071911662817
epoch 82500  clean testing loss: 0.10561355203390121
epoch 82600  training loss: 0.03100508078932762

 83%|██████████████████████████████████████████████████████████████████▍             | 83085/100000 [06:12<01:19, 213.84it/s]
epoch 82700  training loss: 0.031001746654510498
epoch 82700  clean testing loss: 0.10568854957818985
epoch 82800  training loss: 0.030998095870018005
epoch 82800  clean testing loss: 0.10563777387142181
epoch 82900  training loss: 0.03099510259926319
epoch 82900  clean testing loss: 0.10570532828569412
epoch 83000  training loss: 0.0309904795140028
epoch 83000  clean testing loss: 0.10568898171186447
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 83100  training loss: 0.030988309532403946

 84%|██████████████████████████████████████████████████████████████████▊             | 83530/100000 [06:14<01:14, 222.21it/s]
epoch 83200  training loss: 0.030984465032815933
epoch 83200  clean testing loss: 0.10566000640392303
epoch 83300  training loss: 0.030980611220002174
epoch 83300  clean testing loss: 0.10568882524967194
epoch 83400  training loss: 0.030978253111243248
epoch 83400  clean testing loss: 0.10572150349617004
epoch 83500  training loss: 0.030973302200436592

 84%|███████████████████████████████████████████████████████████████████▏            | 83978/100000 [06:16<01:13, 218.76it/s]
epoch 83600  training loss: 0.030970757827162743
epoch 83600  clean testing loss: 0.10571817308664322
epoch 83700  training loss: 0.03096713311970234
epoch 83700  clean testing loss: 0.10572739690542221
epoch 83800  training loss: 0.030963202938437462
epoch 83800  clean testing loss: 0.10573605448007584
epoch 83900  training loss: 0.030959608033299446

 84%|███████████████████████████████████████████████████████████████████▌            | 84420/100000 [06:18<01:10, 219.73it/s]
epoch 84000  training loss: 0.030956927686929703
epoch 84000  clean testing loss: 0.10573621094226837
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 84100  training loss: 0.030952712520956993
epoch 84100  clean testing loss: 0.10577776283025742
epoch 84200  training loss: 0.03094910830259323
epoch 84200  clean testing loss: 0.10576067119836807
epoch 84300  training loss: 0.03094710037112236
epoch 84300  clean testing loss: 0.10580185800790787
epoch 84400  training loss: 0.03094644844532013

 84%|███████████████████████████████████████████████████████████████████▌            | 84487/100000 [06:18<01:16, 203.54it/s]
epoch 84500  training loss: 0.03094090148806572
epoch 84500  clean testing loss: 0.1058078184723854
epoch 84600  training loss: 0.030938168987631798
epoch 84600  clean testing loss: 0.10578834265470505
epoch 84700  training loss: 0.030935628339648247
epoch 84700  clean testing loss: 0.10581439733505249
epoch 84800  training loss: 0.03093220293521881
epoch 84800  clean testing loss: 0.10580731183290482
epoch 84900  training loss: 0.03093002177774906
epoch 84900  clean testing loss: 0.10580223053693771
epoch 85000  training loss: 0.030927008017897606
epoch 85000  clean testing loss: 0.10584504157304764
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 85100  training loss: 0.030924005433917046
epoch 85100  clean testing loss: 0.1058441698551178
epoch 85200  training loss: 0.03092085011303425
epoch 85200  clean testing loss: 0.10584548860788345
epoch 85300  training loss: 0.0309173371642828

 85%|████████████████████████████████████████████████████████████████████▎           | 85357/100000 [06:23<01:16, 191.66it/s]
epoch 85400  training loss: 0.03091501072049141
epoch 85400  clean testing loss: 0.10587543249130249
epoch 85500  training loss: 0.03091251850128174
epoch 85500  clean testing loss: 0.1058482751250267
epoch 85600  training loss: 0.030909884721040726
epoch 85600  clean testing loss: 0.10586720705032349
epoch 85700  training loss: 0.03090609423816204

 86%|████████████████████████████████████████████████████████████████████▌           | 85754/100000 [06:25<01:10, 201.31it/s]
epoch 85800  training loss: 0.030902745202183723
epoch 85800  clean testing loss: 0.10590755194425583
epoch 85900  training loss: 0.030899664387106895
epoch 85900  clean testing loss: 0.10591965168714523
epoch 86000  training loss: 0.03089604713022709
epoch 86000  clean testing loss: 0.10590102523565292
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 86100  training loss: 0.03089420311152935

 86%|████████████████████████████████████████████████████████████████████▉           | 86144/100000 [06:27<01:14, 185.82it/s]
epoch 86200  training loss: 0.03089076839387417
epoch 86200  clean testing loss: 0.10595105588436127
epoch 86300  training loss: 0.030887480825185776
epoch 86300  clean testing loss: 0.10594858229160309
epoch 86400  training loss: 0.030885180458426476
epoch 86400  clean testing loss: 0.10595396161079407
epoch 86500  training loss: 0.030883541330695152

 87%|█████████████████████████████████████████████████████████████████████▏          | 86539/100000 [06:29<01:06, 201.84it/s]
epoch 86600  training loss: 0.030877992510795593
epoch 86600  clean testing loss: 0.10598186403512955
epoch 86700  training loss: 0.03087598644196987
epoch 86700  clean testing loss: 0.1059776023030281
epoch 86800  training loss: 0.030873693525791168
epoch 86800  clean testing loss: 0.10595498234033585
epoch 86900  training loss: 0.030871938914060593

 87%|█████████████████████████████████████████████████████████████████████▌          | 86934/100000 [06:31<01:06, 195.89it/s]
epoch 87000  training loss: 0.030868062749505043
epoch 87000  clean testing loss: 0.10598690062761307
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 87100  training loss: 0.030863923951983452
epoch 87100  clean testing loss: 0.10598691552877426
epoch 87200  training loss: 0.0308612622320652
epoch 87200  clean testing loss: 0.1059926375746727
epoch 87300  training loss: 0.03085894137620926

 87%|█████████████████████████████████████████████████████████████████████▊          | 87329/100000 [06:33<01:03, 199.07it/s]
epoch 87400  training loss: 0.030857719480991364
epoch 87400  clean testing loss: 0.10600734502077103
epoch 87500  training loss: 0.030853858217597008
epoch 87500  clean testing loss: 0.10601210594177246
epoch 87600  training loss: 0.03085072711110115
epoch 87600  clean testing loss: 0.10603119432926178
epoch 87700  training loss: 0.030848786234855652

 88%|██████████████████████████████████████████████████████████████████████▏         | 87719/100000 [06:35<01:04, 191.88it/s]
epoch 87800  training loss: 0.03084641322493553
epoch 87800  clean testing loss: 0.10601392388343811
epoch 87900  training loss: 0.030843431130051613
epoch 87900  clean testing loss: 0.10604474693536758
epoch 88000  training loss: 0.03084094449877739
epoch 88000  clean testing loss: 0.10607175529003143
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 88100  training loss: 0.030838171020150185

 88%|██████████████████████████████████████████████████████████████████████▍         | 88112/100000 [06:37<00:59, 200.67it/s]
epoch 88200  training loss: 0.03083624877035618
epoch 88200  clean testing loss: 0.10607495158910751
epoch 88300  training loss: 0.03083294816315174
epoch 88300  clean testing loss: 0.10606009513139725
epoch 88400  training loss: 0.03083118610084057
epoch 88400  clean testing loss: 0.1060996726155281
epoch 88500  training loss: 0.0308273583650589

 89%|██████████████████████████████████████████████████████████████████████▊         | 88505/100000 [06:39<00:58, 197.18it/s]
epoch 88600  training loss: 0.030824674293398857
epoch 88600  clean testing loss: 0.1061079129576683
epoch 88700  training loss: 0.030822385102510452
epoch 88700  clean testing loss: 0.10608159750699997
epoch 88800  training loss: 0.030819416046142578

 89%|███████████████████████████████████████████████████████████████████████         | 88899/100000 [06:41<00:55, 199.84it/s]
epoch 88900  training loss: 0.030817139893770218
epoch 88900  clean testing loss: 0.10611075162887573
epoch 89000  training loss: 0.030814355239272118
epoch 89000  clean testing loss: 0.10610809922218323
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 89100  training loss: 0.0308124590665102
epoch 89100  clean testing loss: 0.10614088922739029
epoch 89200  training loss: 0.03080928884446621

 89%|███████████████████████████████████████████████████████████████████████▍        | 89291/100000 [06:43<00:54, 197.39it/s]
epoch 89300  training loss: 0.03080654703080654
epoch 89300  clean testing loss: 0.10613729059696198
epoch 89400  training loss: 0.03080437332391739
epoch 89400  clean testing loss: 0.10615018010139465
epoch 89500  training loss: 0.030801720917224884
epoch 89500  clean testing loss: 0.10611779987812042
epoch 89600  training loss: 0.03079885058104992

 90%|███████████████████████████████████████████████████████████████████████▊        | 89688/100000 [06:45<00:52, 197.36it/s]
epoch 89700  training loss: 0.03079698607325554
epoch 89700  clean testing loss: 0.10616637766361237
epoch 89800  training loss: 0.03079381212592125
epoch 89800  clean testing loss: 0.10616607964038849
epoch 89900  training loss: 0.030790911987423897
epoch 89900  clean testing loss: 0.10616371780633926
epoch 90000  training loss: 0.030788211151957512
epoch 90000  clean testing loss: 0.1061779335141182

 90%|████████████████████████████████████████████████████████████████████████        | 90081/100000 [06:47<00:51, 193.42it/s]
epoch 90100  training loss: 0.030785908922553062
epoch 90100  clean testing loss: 0.10619527846574783
epoch 90200  training loss: 0.03078332357108593
epoch 90200  clean testing loss: 0.10619853436946869
epoch 90300  training loss: 0.030781425535678864
epoch 90300  clean testing loss: 0.10621730238199234
epoch 90400  training loss: 0.030779030174016953

 90%|████████████████████████████████████████████████████████████████████████▍       | 90473/100000 [06:49<00:48, 195.93it/s]
epoch 90500  training loss: 0.0307773370295763
epoch 90500  clean testing loss: 0.10621506720781326
epoch 90600  training loss: 0.030774854123592377
epoch 90600  clean testing loss: 0.10624557733535767
epoch 90700  training loss: 0.03077281266450882
epoch 90700  clean testing loss: 0.1062380000948906
epoch 90800  training loss: 0.03077038750052452

 91%|████████████████████████████████████████████████████████████████████████▋       | 90848/100000 [06:51<00:48, 190.41it/s]
epoch 90900  training loss: 0.030767839401960373
epoch 90900  clean testing loss: 0.10624147206544876
epoch 91000  training loss: 0.030765503644943237
epoch 91000  clean testing loss: 0.10624600946903229
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 91100  training loss: 0.030763687565922737
epoch 91100  clean testing loss: 0.10625976324081421
epoch 91200  training loss: 0.030761055648326874

 91%|█████████████████████████████████████████████████████████████████████████       | 91260/100000 [06:53<00:44, 194.43it/s]
epoch 91300  training loss: 0.030758187174797058
epoch 91300  clean testing loss: 0.10627265274524689
epoch 91400  training loss: 0.030756628140807152
epoch 91400  clean testing loss: 0.10629326105117798
epoch 91500  training loss: 0.030754830688238144
epoch 91500  clean testing loss: 0.10627425462007523
epoch 91600  training loss: 0.030752034857869148

 92%|█████████████████████████████████████████████████████████████████████████▎      | 91654/100000 [06:55<00:42, 198.28it/s]
epoch 91700  training loss: 0.030749352648854256
epoch 91700  clean testing loss: 0.1062873899936676
epoch 91800  training loss: 0.030746979638934135
epoch 91800  clean testing loss: 0.10630436986684799
epoch 91900  training loss: 0.030744118615984917
epoch 91900  clean testing loss: 0.10633028298616409
epoch 92000  training loss: 0.030742378905415535
epoch 92000  clean testing loss: 0.10631713271141052


 92%|█████████████████████████████████████████████████████████████████████████▉      | 92448/100000 [06:59<00:38, 196.59it/s]
epoch 92100  training loss: 0.030739309266209602
epoch 92100  clean testing loss: 0.10634162276983261
epoch 92200  training loss: 0.030737213790416718
epoch 92200  clean testing loss: 0.10632547736167908
epoch 92300  training loss: 0.030734874308109283
epoch 92300  clean testing loss: 0.1063464879989624
epoch 92400  training loss: 0.030732590705156326

 93%|██████████████████████████████████████████████████████████████████████████▎     | 92825/100000 [07:01<00:38, 188.42it/s]
epoch 92500  training loss: 0.030730172991752625
epoch 92500  clean testing loss: 0.10634037107229233
epoch 92600  training loss: 0.03072827309370041
epoch 92600  clean testing loss: 0.10635295510292053
epoch 92700  training loss: 0.03072548843920231
epoch 92700  clean testing loss: 0.10637620836496353
epoch 92800  training loss: 0.030723579227924347

 93%|██████████████████████████████████████████████████████████████████████████▌     | 93222/100000 [07:03<00:33, 199.39it/s]
epoch 92900  training loss: 0.03072083555161953
epoch 92900  clean testing loss: 0.10637003183364868
epoch 93000  training loss: 0.030718551948666573
epoch 93000  clean testing loss: 0.10638724267482758
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 93100  training loss: 0.030717039480805397
epoch 93100  clean testing loss: 0.1064014807343483
epoch 93200  training loss: 0.030714163556694984
epoch 93200  clean testing loss: 0.10640379786491394
epoch 93300  training loss: 0.030712271109223366
epoch 93300  clean testing loss: 0.10641138255596161
epoch 93400  training loss: 0.030710451304912567
epoch 93400  clean testing loss: 0.10643118619918823
epoch 93500  training loss: 0.030708072707057
epoch 93500  clean testing loss: 0.10640901327133179
epoch 93600  training loss: 0.030706247314810753

 94%|██████████████████████████████████████████████████████████████████████████▉     | 93617/100000 [07:05<00:32, 195.65it/s]
epoch 93700  training loss: 0.030704213306307793
epoch 93700  clean testing loss: 0.10645251721143723
epoch 93800  training loss: 0.030702117830514908
epoch 93800  clean testing loss: 0.10644503682851791
epoch 93900  training loss: 0.03069980815052986
epoch 93900  clean testing loss: 0.1064431443810463
epoch 94000  training loss: 0.030697684735059738
epoch 94000  clean testing loss: 0.10646196454763412


 94%|███████████████████████████████████████████████████████████████████████████▌    | 94405/100000 [07:09<00:29, 190.22it/s]
epoch 94100  training loss: 0.03069560043513775
epoch 94100  clean testing loss: 0.10647229105234146
epoch 94200  training loss: 0.03069431520998478
epoch 94200  clean testing loss: 0.10647593438625336
epoch 94300  training loss: 0.030691733583807945

 95%|███████████████████████████████████████████████████████████████████████████▊    | 94796/100000 [07:11<00:26, 198.98it/s]
epoch 94400  training loss: 0.030690910294651985
epoch 94400  clean testing loss: 0.10647882521152496
epoch 94500  training loss: 0.03068828582763672
epoch 94500  clean testing loss: 0.10648199915885925
epoch 94600  training loss: 0.030685126781463623
epoch 94600  clean testing loss: 0.10649565607309341
epoch 94700  training loss: 0.030683385208249092

 95%|████████████████████████████████████████████████████████████████████████████▏   | 95187/100000 [07:13<00:24, 196.06it/s]
epoch 94800  training loss: 0.030682828277349472
epoch 94800  clean testing loss: 0.10650753229856491
epoch 94900  training loss: 0.03067946806550026
epoch 94900  clean testing loss: 0.1065138429403305
epoch 95000  training loss: 0.03067759796977043
epoch 95000  clean testing loss: 0.10651221126317978
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 95100  training loss: 0.030675653368234634

 96%|████████████████████████████████████████████████████████████████████████████▍   | 95581/100000 [07:15<00:22, 198.83it/s]
epoch 95200  training loss: 0.03067351132631302
epoch 95200  clean testing loss: 0.10653091967105865
epoch 95300  training loss: 0.030671583488583565
epoch 95300  clean testing loss: 0.10653360188007355
epoch 95400  training loss: 0.030669700354337692
epoch 95400  clean testing loss: 0.10653677582740784
epoch 95500  training loss: 0.030667094513773918

 96%|████████████████████████████████████████████████████████████████████████████▊   | 95977/100000 [07:17<00:20, 193.13it/s]
epoch 95600  training loss: 0.030665267258882523
epoch 95600  clean testing loss: 0.1065535917878151
epoch 95700  training loss: 0.030663663521409035
epoch 95700  clean testing loss: 0.10656365752220154
epoch 95800  training loss: 0.03066125139594078
epoch 95800  clean testing loss: 0.10656283050775528
epoch 95900  training loss: 0.030658891424536705

 96%|█████████████████████████████████████████████████████████████████████████████   | 96370/100000 [07:19<00:18, 199.47it/s]
epoch 96000  training loss: 0.030657008290290833
epoch 96000  clean testing loss: 0.10658678412437439
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 96100  training loss: 0.030654963105916977
epoch 96100  clean testing loss: 0.1065884456038475
epoch 96200  training loss: 0.030653635039925575
epoch 96200  clean testing loss: 0.10658762603998184
epoch 96300  training loss: 0.03065178357064724

 97%|█████████████████████████████████████████████████████████████████████████████▍  | 96766/100000 [07:21<00:16, 196.08it/s]
epoch 96400  training loss: 0.030650058761239052
epoch 96400  clean testing loss: 0.10660675913095474
epoch 96500  training loss: 0.03064855746924877
epoch 96500  clean testing loss: 0.10661251842975616
epoch 96600  training loss: 0.03064695931971073
epoch 96600  clean testing loss: 0.10660263895988464
epoch 96700  training loss: 0.030644560232758522

 97%|█████████████████████████████████████████████████████████████████████████████▋  | 97155/100000 [07:23<00:14, 193.74it/s]
epoch 96800  training loss: 0.03064286895096302
epoch 96800  clean testing loss: 0.10659558326005936
epoch 96900  training loss: 0.03064131550490856
epoch 96900  clean testing loss: 0.10660680383443832
epoch 97000  training loss: 0.030639370903372765
epoch 97000  clean testing loss: 0.1066221371293068
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 97100  training loss: 0.030637800693511963

 98%|██████████████████████████████████████████████████████████████████████████████  | 97549/100000 [07:25<00:12, 197.88it/s]
epoch 97200  training loss: 0.03063630871474743
epoch 97200  clean testing loss: 0.10661385208368301
epoch 97300  training loss: 0.030634790658950806
epoch 97300  clean testing loss: 0.10664243251085281
epoch 97400  training loss: 0.030632246285676956
epoch 97400  clean testing loss: 0.10665586590766907
epoch 97500  training loss: 0.030630281195044518

 98%|██████████████████████████████████████████████████████████████████████████████▎ | 97841/100000 [07:26<00:11, 192.86it/s]
epoch 97600  training loss: 0.03062819503247738
epoch 97600  clean testing loss: 0.10665448755025864
epoch 97700  training loss: 0.030626678839325905
epoch 97700  clean testing loss: 0.10665810853242874
epoch 97800  training loss: 0.030624905601143837
epoch 97800  clean testing loss: 0.10665254294872284
epoch 97900  training loss: 0.030622946098446846
epoch 97900  clean testing loss: 0.10665448009967804
epoch 98000  training loss: 0.030621163547039032
epoch 98000  clean testing loss: 0.10666506737470627
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 98100  training loss: 0.030619263648986816
epoch 98100  clean testing loss: 0.10666441917419434
epoch 98200  training loss: 0.030617717653512955
epoch 98200  clean testing loss: 0.10667737573385239
epoch 98300  training loss: 0.030615856871008873


 99%|██████████████████████████████████████████████████████████████████████████████▉ | 98629/100000 [07:30<00:07, 187.01it/s]
epoch 98400  training loss: 0.030614260584115982
epoch 98400  clean testing loss: 0.10668237507343292
epoch 98500  training loss: 0.03061271831393242
epoch 98500  clean testing loss: 0.1066899448633194
epoch 98600  training loss: 0.030610620975494385
epoch 98600  clean testing loss: 0.10668756067752838
epoch 98700  training loss: 0.03060963749885559

 99%|███████████████████████████████████████████████████████████████████████████████▏| 99020/100000 [07:32<00:05, 193.03it/s]
epoch 98800  training loss: 0.030607152730226517
epoch 98800  clean testing loss: 0.10670555382966995
epoch 98900  training loss: 0.03060535155236721
epoch 98900  clean testing loss: 0.10671143233776093
epoch 99000  training loss: 0.03060358576476574
epoch 99000  clean testing loss: 0.10670096427202225
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...
epoch 99100  training loss: 0.030601484701037407

 99%|███████████████████████████████████████████████████████████████████████████████▌| 99413/100000 [07:35<00:03, 193.15it/s]
epoch 99200  training loss: 0.030600378289818764
epoch 99200  clean testing loss: 0.10671927779912949
epoch 99300  training loss: 0.03059905767440796
epoch 99300  clean testing loss: 0.10672344267368317
epoch 99400  training loss: 0.030597921460866928

100%|███████████████████████████████████████████████████████████████████████████████▊| 99810/100000 [07:37<00:00, 199.35it/s]
epoch 99500  training loss: 0.030596766620874405
epoch 99500  clean testing loss: 0.10672537237405777
epoch 99600  training loss: 0.0305947232991457
epoch 99600  clean testing loss: 0.10672742128372192
epoch 99700  training loss: 0.030593233183026314
epoch 99700  clean testing loss: 0.10672696679830551
epoch 99800  training loss: 0.030591851100325584

100%|███████████████████████████████████████████████████████████████████████████████| 100000/100000 [07:37<00:00, 218.35it/s]
epoch 99900  training loss: 0.030590413138270378
epoch 99900  clean testing loss: 0.106732077896595
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e-01_invop0_lr0.001 ...