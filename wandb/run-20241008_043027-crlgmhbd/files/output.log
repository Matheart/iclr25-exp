
  0%|                                                                                    | 37/100000 [00:01<58:17, 28.58it/s]
epoch 0  training loss: 43.48748016357422
epoch 0  clean testing loss: 224.58135986328125

  0%|                                                                                    | 93/100000 [00:03<59:25, 28.02it/s]
epoch 100  training loss: 0.28737738728523254


  0%|▏                                                                                | 207/100000 [00:07<1:02:14, 26.72it/s]
epoch 200  training loss: 0.1335643082857132


  0%|▎                                                                                | 315/100000 [00:11<1:02:20, 26.65it/s]
epoch 300  training loss: 0.1681196391582489


  0%|▎                                                                                | 414/100000 [00:15<1:08:25, 24.26it/s]
epoch 400  training loss: 0.09502432495355606


  1%|▍                                                                                | 507/100000 [00:19<1:14:03, 22.39it/s]
epoch 500  training loss: 0.09727534651756287



  1%|▌                                                                                | 639/100000 [00:25<1:17:40, 21.32it/s]
epoch 600  training loss: 0.13164179027080536


  1%|▌                                                                                | 721/100000 [00:29<1:19:21, 20.85it/s]
epoch 700  training loss: 0.0764942392706871


  1%|▋                                                                                | 797/100000 [00:33<1:23:12, 19.87it/s]
epoch 800  training loss: 0.08154366910457611



  1%|▋                                                                                | 917/100000 [00:39<1:24:11, 19.61it/s]
epoch 900  training loss: 0.08537207543849945



  1%|▊                                                                               | 1037/100000 [00:45<1:23:36, 19.73it/s]
epoch 1000  training loss: 0.09002961963415146
epoch 1000  clean testing loss: 0.08583007007837296


  1%|▉                                                                               | 1116/100000 [00:49<1:21:51, 20.13it/s]
epoch 1100  training loss: 0.19114330410957336



  1%|▉                                                                               | 1231/100000 [00:55<1:24:34, 19.46it/s]
epoch 1200  training loss: 0.07919890433549881


  1%|█                                                                               | 1311/100000 [00:59<1:23:03, 19.80it/s]
epoch 1300  training loss: 0.11091558635234833



  1%|█▏                                                                              | 1430/100000 [01:05<1:23:01, 19.79it/s]
epoch 1400  training loss: 0.0760776698589325


  2%|█▏                                                                              | 1509/100000 [01:09<1:18:21, 20.95it/s]
epoch 1500  training loss: 0.06785430759191513



  2%|█▎                                                                              | 1629/100000 [01:15<1:30:53, 18.04it/s]
epoch 1600  training loss: 0.08061301708221436


  2%|█▎                                                                              | 1706/100000 [01:19<1:24:53, 19.30it/s]
epoch 1700  training loss: 0.07257474213838577



  2%|█▍                                                                              | 1825/100000 [01:25<1:23:18, 19.64it/s]
epoch 1800  training loss: 0.0722687840461731


  2%|█▌                                                                              | 1904/100000 [01:29<1:23:42, 19.53it/s]
epoch 1900  training loss: 0.3052422106266022



  2%|█▌                                                                              | 2022/100000 [01:35<1:23:15, 19.61it/s]
epoch 2000  training loss: 0.0728624016046524
epoch 2000  clean testing loss: 0.05072109401226044


  2%|█▋                                                                              | 2100/100000 [01:39<1:21:05, 20.12it/s]
epoch 2100  training loss: 0.11978717148303986



  2%|█▊                                                                              | 2220/100000 [01:45<1:21:22, 20.03it/s]
epoch 2200  training loss: 0.06663783639669418


  2%|█▊                                                                              | 2300/100000 [01:49<1:22:38, 19.70it/s]
epoch 2300  training loss: 0.20488756895065308



  2%|█▉                                                                              | 2419/100000 [01:55<1:27:43, 18.54it/s]
epoch 2400  training loss: 0.07990144938230515



  3%|██                                                                              | 2538/100000 [02:01<1:19:59, 20.31it/s]
epoch 2500  training loss: 0.07733357697725296


  3%|██                                                                              | 2615/100000 [02:05<1:20:21, 20.20it/s]
epoch 2600  training loss: 0.06849858909845352



  3%|██▏                                                                             | 2731/100000 [02:11<1:23:53, 19.32it/s]
epoch 2700  training loss: 0.07625316828489304


  3%|██▎                                                                             | 2813/100000 [02:16<1:21:05, 19.97it/s]
epoch 2800  training loss: 0.07030585408210754



  3%|██▎                                                                             | 2929/100000 [02:21<1:19:31, 20.34it/s]
epoch 2900  training loss: 0.2405790537595749


  3%|██▍                                                                             | 3010/100000 [02:26<1:22:08, 19.68it/s]
epoch 3000  training loss: 0.08168480545282364
epoch 3000  clean testing loss: 0.04330095648765564



  3%|██▌                                                                             | 3130/100000 [02:32<1:21:22, 19.84it/s]
epoch 3100  training loss: 0.07593130320310593


  3%|██▌                                                                             | 3207/100000 [02:36<1:33:02, 17.34it/s]
epoch 3200  training loss: 0.08290770649909973



  3%|██▋                                                                             | 3324/100000 [02:42<1:23:48, 19.23it/s]
epoch 3300  training loss: 0.07877103239297867


  3%|██▋                                                                             | 3405/100000 [02:46<1:22:23, 19.54it/s]
epoch 3400  training loss: 0.07425497472286224



  4%|██▊                                                                             | 3520/100000 [02:52<1:25:12, 18.87it/s]
epoch 3500  training loss: 0.07154697179794312


  4%|██▉                                                                             | 3601/100000 [02:56<1:20:24, 19.98it/s]
epoch 3600  training loss: 0.06748887151479721



  4%|██▉                                                                             | 3710/100000 [03:01<1:22:41, 19.41it/s]
epoch 3700  training loss: 0.07879990339279175



  4%|███                                                                             | 3831/100000 [03:07<1:22:49, 19.35it/s]
epoch 3800  training loss: 0.12322249263525009


  4%|███▏                                                                            | 3909/100000 [03:11<1:21:01, 19.77it/s]
epoch 3900  training loss: 0.07093411684036255



  4%|███▏                                                                            | 4028/100000 [03:17<1:18:52, 20.28it/s]
epoch 4000  training loss: 0.07848978787660599
epoch 4000  clean testing loss: 0.03967145085334778


  4%|███▎                                                                            | 4107/100000 [03:21<1:22:48, 19.30it/s]
epoch 4100  training loss: 0.07187697291374207



  4%|███▍                                                                            | 4224/100000 [03:27<1:21:41, 19.54it/s]
epoch 4200  training loss: 0.06931660324335098


  4%|███▍                                                                            | 4307/100000 [03:31<1:21:52, 19.48it/s]
epoch 4300  training loss: 0.07288077473640442



  4%|███▌                                                                            | 4424/100000 [03:37<1:20:37, 19.76it/s]
epoch 4400  training loss: 0.08538739383220673


  5%|███▌                                                                            | 4504/100000 [03:41<1:24:02, 18.94it/s]
epoch 4500  training loss: 0.07625497877597809



  5%|███▋                                                                            | 4621/100000 [03:47<1:22:44, 19.21it/s]
epoch 4600  training loss: 0.07761163264513016


  5%|███▊                                                                            | 4698/100000 [03:51<1:21:04, 19.59it/s]
epoch 4700  training loss: 0.16167451441287994



  5%|███▊                                                                            | 4818/100000 [03:57<1:19:22, 19.99it/s]
epoch 4800  training loss: 0.07002273947000504


  5%|███▉                                                                            | 4898/100000 [04:01<1:20:37, 19.66it/s]
epoch 4900  training loss: 0.0664948895573616



  5%|████                                                                            | 5018/100000 [04:07<1:18:10, 20.25it/s]
epoch 5000  training loss: 0.0684000551700592
epoch 5000  clean testing loss: 0.032766494899988174


  5%|████                                                                            | 5099/100000 [04:11<1:19:06, 20.00it/s]
epoch 5100  training loss: 0.07360471785068512



  5%|████▏                                                                           | 5217/100000 [04:17<1:20:36, 19.60it/s]
epoch 5200  training loss: 0.06479287147521973


  5%|████▏                                                                           | 5297/100000 [04:22<1:18:32, 20.10it/s]
epoch 5300  training loss: 0.07155127078294754



  5%|████▎                                                                           | 5416/100000 [04:28<1:18:36, 20.05it/s]
epoch 5400  training loss: 0.06346219033002853


  5%|████▍                                                                           | 5494/100000 [04:32<1:20:51, 19.48it/s]
epoch 5500  training loss: 0.12649816274642944



  6%|████▍                                                                           | 5613/100000 [04:38<1:22:33, 19.06it/s]
epoch 5600  training loss: 0.08093224465847015



  6%|████▌                                                                           | 5733/100000 [04:44<1:18:49, 19.93it/s]
epoch 5700  training loss: 0.08065074682235718


  6%|████▋                                                                           | 5812/100000 [04:48<1:18:02, 20.12it/s]
epoch 5800  training loss: 0.07491376996040344



  6%|████▋                                                                           | 5933/100000 [04:54<1:20:41, 19.43it/s]
epoch 5900  training loss: 0.07154594361782074


  6%|████▊                                                                           | 6012/100000 [04:58<1:18:35, 19.93it/s]
epoch 6000  training loss: 0.06992048025131226
epoch 6000  clean testing loss: 0.03209952637553215



  6%|████▉                                                                           | 6132/100000 [05:04<1:17:36, 20.16it/s]
epoch 6100  training loss: 0.06462591141462326


  6%|████▉                                                                           | 6211/100000 [05:08<1:20:30, 19.42it/s]
epoch 6200  training loss: 0.066500723361969



  6%|█████                                                                           | 6331/100000 [05:14<1:16:39, 20.37it/s]
epoch 6300  training loss: 0.06089107692241669


  6%|█████▏                                                                          | 6411/100000 [05:18<1:18:04, 19.98it/s]
epoch 6400  training loss: 0.09432163834571838



  7%|█████▏                                                                          | 6528/100000 [05:24<1:19:53, 19.50it/s]
epoch 6500  training loss: 0.07067915797233582


  7%|█████▎                                                                          | 6608/100000 [05:28<1:17:26, 20.10it/s]
epoch 6600  training loss: 0.06537359952926636



  7%|█████▍                                                                          | 6724/100000 [05:34<1:21:37, 19.05it/s]
epoch 6700  training loss: 0.06091153994202614


  7%|█████▍                                                                          | 6805/100000 [05:38<1:18:19, 19.83it/s]
epoch 6800  training loss: 0.10111905634403229



  7%|█████▌                                                                          | 6925/100000 [05:44<1:17:22, 20.05it/s]
epoch 6900  training loss: 0.06437923014163971


  7%|█████▌                                                                          | 7003/100000 [05:48<1:21:06, 19.11it/s]
epoch 7000  training loss: 0.06653836369514465
epoch 7000  clean testing loss: 0.030557066202163696



  7%|█████▋                                                                          | 7121/100000 [05:54<1:18:16, 19.77it/s]
epoch 7100  training loss: 0.061202891170978546


  7%|█████▊                                                                          | 7200/100000 [05:58<1:15:43, 20.43it/s]
epoch 7200  training loss: 0.08170491456985474



  7%|█████▊                                                                          | 7312/100000 [06:03<1:17:47, 19.86it/s]
epoch 7300  training loss: 0.06778066605329514


  7%|█████▉                                                                          | 7390/100000 [06:07<1:20:09, 19.26it/s]
epoch 7400  training loss: 0.06423965841531754



  8%|██████                                                                          | 7508/100000 [06:13<1:31:43, 16.81it/s]
epoch 7500  training loss: 0.06275055557489395



  8%|██████                                                                          | 7626/100000 [06:20<1:16:24, 20.15it/s]
epoch 7600  training loss: 0.06617529690265656


  8%|██████▏                                                                         | 7706/100000 [06:24<1:14:59, 20.51it/s]
epoch 7700  training loss: 0.06378158181905746



  8%|██████▎                                                                         | 7825/100000 [06:30<1:18:02, 19.69it/s]
epoch 7800  training loss: 0.0653102844953537


  8%|██████▎                                                                         | 7903/100000 [06:34<1:17:28, 19.81it/s]
epoch 7900  training loss: 0.06665114313364029



  8%|██████▍                                                                         | 8021/100000 [06:40<1:16:34, 20.02it/s]
epoch 8000  training loss: 0.08322930335998535
epoch 8000  clean testing loss: 0.04261535033583641


  8%|██████▍                                                                         | 8099/100000 [06:44<1:16:17, 20.08it/s]
epoch 8100  training loss: 0.07412577420473099



  8%|██████▌                                                                         | 8218/100000 [06:50<1:18:30, 19.49it/s]
epoch 8200  training loss: 0.06666097790002823


  8%|██████▋                                                                         | 8295/100000 [06:54<1:23:42, 18.26it/s]
epoch 8300  training loss: 0.06737351417541504



  8%|██████▋                                                                         | 8415/100000 [07:00<1:18:15, 19.51it/s]
epoch 8400  training loss: 0.06775972247123718



  9%|██████▊                                                                         | 8533/100000 [07:06<1:17:17, 19.72it/s]
epoch 8500  training loss: 0.07578789442777634


  9%|██████▉                                                                         | 8612/100000 [07:10<1:17:44, 19.59it/s]
epoch 8600  training loss: 0.07170834392309189



  9%|██████▉                                                                         | 8732/100000 [07:16<1:14:52, 20.31it/s]
epoch 8700  training loss: 0.07542325556278229


  9%|███████                                                                         | 8810/100000 [07:20<1:18:02, 19.48it/s]
epoch 8800  training loss: 0.07813644409179688



  9%|███████▏                                                                        | 8929/100000 [07:26<1:16:34, 19.82it/s]
epoch 8900  training loss: 0.07451506704092026


  9%|███████▏                                                                        | 9010/100000 [07:30<1:17:22, 19.60it/s]
epoch 9000  training loss: 0.08068181574344635
epoch 9000  clean testing loss: 0.033673860132694244



  9%|███████▎                                                                        | 9128/100000 [07:36<1:15:31, 20.05it/s]
epoch 9100  training loss: 0.06721670180559158


  9%|███████▎                                                                        | 9207/100000 [07:40<1:17:18, 19.57it/s]
epoch 9200  training loss: 0.06683759391307831



  9%|███████▍                                                                        | 9325/100000 [07:46<1:17:34, 19.48it/s]
epoch 9300  training loss: 0.06338365375995636


  9%|███████▌                                                                        | 9404/100000 [07:50<1:15:42, 19.95it/s]
epoch 9400  training loss: 0.5527246594429016



 10%|███████▌                                                                        | 9525/100000 [07:56<1:18:30, 19.21it/s]
epoch 9500  training loss: 0.07854119688272476


 10%|███████▋                                                                        | 9602/100000 [08:00<1:18:34, 19.18it/s]
epoch 9600  training loss: 0.07431599497795105



 10%|███████▊                                                                        | 9723/100000 [08:06<1:15:35, 19.91it/s]
epoch 9700  training loss: 0.07206207513809204


 10%|███████▊                                                                        | 9801/100000 [08:10<1:16:19, 19.70it/s]
epoch 9800  training loss: 0.07389870285987854



 10%|███████▉                                                                        | 9921/100000 [08:16<1:15:22, 19.92it/s]
epoch 9900  training loss: 0.06682606786489487



 10%|███████▉                                                                       | 10038/100000 [08:22<1:16:19, 19.65it/s]
epoch 10000  training loss: 0.06463310867547989
epoch 10000  clean testing loss: 0.03794886916875839


 10%|███████▉                                                                       | 10118/100000 [08:26<1:15:42, 19.79it/s]
epoch 10100  training loss: 0.062440890818834305



 10%|████████                                                                       | 10236/100000 [08:32<1:13:23, 20.39it/s]
epoch 10200  training loss: 0.07145494222640991


 10%|████████▏                                                                      | 10315/100000 [08:36<1:15:04, 19.91it/s]
epoch 10300  training loss: 0.06476878374814987



 10%|████████▏                                                                      | 10432/100000 [08:42<1:19:55, 18.68it/s]
epoch 10400  training loss: 0.06403027474880219


 11%|████████▎                                                                      | 10511/100000 [08:46<1:19:35, 18.74it/s]
epoch 10500  training loss: 0.06541767716407776



 11%|████████▍                                                                      | 10628/100000 [08:52<1:16:21, 19.51it/s]
epoch 10600  training loss: 0.2751578986644745


 11%|████████▍                                                                      | 10706/100000 [08:56<1:14:51, 19.88it/s]
epoch 10700  training loss: 0.07550180703401566



 11%|████████▌                                                                      | 10827/100000 [09:02<1:15:17, 19.74it/s]
epoch 10800  training loss: 0.06662037968635559


 11%|████████▌                                                                      | 10894/100000 [09:06<1:15:19, 19.71it/s]
epoch 10900  training loss: 0.07907024025917053



 11%|████████▋                                                                      | 11009/100000 [09:12<1:22:27, 17.99it/s]
epoch 11000  training loss: 0.06635334342718124
epoch 11000  clean testing loss: 0.03324880823493004



 11%|████████▊                                                                      | 11127/100000 [09:18<1:15:28, 19.63it/s]
epoch 11100  training loss: 0.06408662348985672


 11%|████████▊                                                                      | 11205/100000 [09:22<1:15:36, 19.58it/s]
epoch 11200  training loss: 0.06398217380046844



 11%|████████▉                                                                      | 11327/100000 [09:28<1:13:55, 19.99it/s]
epoch 11300  training loss: 0.065121129155159


 11%|█████████                                                                      | 11408/100000 [09:32<1:14:23, 19.85it/s]
epoch 11400  training loss: 0.061614200472831726



 12%|█████████                                                                      | 11525/100000 [09:38<1:16:10, 19.36it/s]
epoch 11500  training loss: 0.06401962786912918


 12%|█████████▏                                                                     | 11606/100000 [09:42<1:14:23, 19.80it/s]
epoch 11600  training loss: 0.06348460912704468



 12%|█████████▎                                                                     | 11724/100000 [09:48<1:20:46, 18.21it/s]
epoch 11700  training loss: 0.06161559745669365


 12%|█████████▎                                                                     | 11804/100000 [09:52<1:13:16, 20.06it/s]
epoch 11800  training loss: 0.06571272760629654



 12%|█████████▍                                                                     | 11919/100000 [09:58<1:18:56, 18.60it/s]
epoch 11900  training loss: 0.06075505539774895


 12%|█████████▍                                                                     | 11999/100000 [10:02<1:13:04, 20.07it/s]
epoch 12000  training loss: 0.078421451151371
epoch 12000  clean testing loss: 0.039625491946935654



 12%|█████████▌                                                                     | 12115/100000 [10:08<1:18:48, 18.59it/s]
epoch 12100  training loss: 0.06889782845973969



 12%|█████████▋                                                                     | 12232/100000 [10:14<1:11:39, 20.41it/s]
epoch 12200  training loss: 0.06918784230947495


 12%|█████████▋                                                                     | 12313/100000 [10:18<1:14:56, 19.50it/s]
epoch 12300  training loss: 0.06789755821228027



 12%|█████████▊                                                                     | 12432/100000 [10:24<1:15:50, 19.24it/s]
epoch 12400  training loss: 0.07798094302415848


 13%|█████████▉                                                                     | 12511/100000 [10:28<1:14:11, 19.66it/s]
epoch 12500  training loss: 0.06411875039339066



 13%|█████████▉                                                                     | 12630/100000 [10:34<1:14:32, 19.54it/s]
epoch 12600  training loss: 0.06858976930379868


 13%|██████████                                                                     | 12709/100000 [10:38<1:14:20, 19.57it/s]
epoch 12700  training loss: 0.0631001740694046



 13%|██████████▏                                                                    | 12828/100000 [10:44<1:14:38, 19.47it/s]
epoch 12800  training loss: 0.09228881448507309


 13%|██████████▏                                                                    | 12907/100000 [10:48<1:12:40, 19.98it/s]
epoch 12900  training loss: 0.07222116738557816



 13%|██████████▎                                                                    | 13024/100000 [10:54<1:08:46, 21.08it/s]
epoch 13000  training loss: 0.06716707348823547
epoch 13000  clean testing loss: 0.03085203841328621


 13%|██████████▎                                                                    | 13104/100000 [10:58<1:12:20, 20.02it/s]
epoch 13100  training loss: 0.06661923229694366



 13%|██████████▍                                                                    | 13224/100000 [11:04<1:14:26, 19.43it/s]
epoch 13200  training loss: 0.06420633941888809


 13%|██████████▌                                                                    | 13304/100000 [11:08<1:12:55, 19.81it/s]
epoch 13300  training loss: 0.06287950277328491



 13%|██████████▌                                                                    | 13421/100000 [11:14<1:18:42, 18.33it/s]
epoch 13400  training loss: 0.05998522415757179


 13%|██████████▋                                                                    | 13499/100000 [11:18<1:13:03, 19.73it/s]
epoch 13500  training loss: 0.06531652808189392



 14%|██████████▊                                                                    | 13616/100000 [11:24<1:12:06, 19.96it/s]
epoch 13600  training loss: 0.06816348433494568



 14%|██████████▊                                                                    | 13737/100000 [11:30<1:11:52, 20.00it/s]
epoch 13700  training loss: 0.059809885919094086


 14%|██████████▉                                                                    | 13815/100000 [11:34<1:11:12, 20.17it/s]
epoch 13800  training loss: 0.059803079813718796



 14%|███████████                                                                    | 13935/100000 [11:40<1:09:03, 20.77it/s]
epoch 13900  training loss: 0.05994782969355583


 14%|███████████                                                                    | 14012/100000 [11:44<1:12:33, 19.75it/s]
epoch 14000  training loss: 0.05783858895301819
epoch 14000  clean testing loss: 0.038825858384370804



 14%|███████████▏                                                                   | 14132/100000 [11:50<1:11:05, 20.13it/s]
epoch 14100  training loss: 0.07965412735939026


 14%|███████████▏                                                                   | 14210/100000 [11:54<1:11:26, 20.01it/s]
epoch 14200  training loss: 0.054457616060972214



 14%|███████████▎                                                                   | 14328/100000 [12:00<1:14:29, 19.17it/s]
epoch 14300  training loss: 0.06012405455112457


 14%|███████████▍                                                                   | 14409/100000 [12:04<1:13:36, 19.38it/s]
epoch 14400  training loss: 0.05999448522925377



 15%|███████████▍                                                                   | 14529/100000 [12:10<1:12:49, 19.56it/s]
epoch 14500  training loss: 0.05483710765838623


 15%|███████████▌                                                                   | 14604/100000 [12:14<1:12:45, 19.56it/s]
epoch 14600  training loss: 0.056224673986434937



 15%|███████████▋                                                                   | 14723/100000 [12:20<1:12:17, 19.66it/s]
epoch 14700  training loss: 0.055995676666498184


 15%|███████████▋                                                                   | 14802/100000 [12:24<1:12:07, 19.69it/s]
epoch 14800  training loss: 0.061404019594192505



 15%|███████████▊                                                                   | 14921/100000 [12:30<1:13:40, 19.25it/s]
epoch 14900  training loss: 0.05871797353029251


 15%|███████████▊                                                                   | 14991/100000 [12:34<1:11:06, 19.93it/s]
epoch 15000  training loss: 0.05988866835832596
epoch 15000  clean testing loss: 0.043974991887807846



 15%|███████████▉                                                                   | 15108/100000 [12:40<1:13:00, 19.38it/s]
epoch 15100  training loss: 0.05623596906661987



 15%|████████████                                                                   | 15229/100000 [12:46<1:11:33, 19.74it/s]
epoch 15200  training loss: 0.055118050426244736


 15%|████████████                                                                   | 15308/100000 [12:50<1:10:40, 19.97it/s]
epoch 15300  training loss: 0.0698561817407608



 15%|████████████▏                                                                  | 15427/100000 [12:56<1:10:59, 19.86it/s]
epoch 15400  training loss: 0.05529816076159477


 16%|████████████▏                                                                  | 15504/100000 [13:00<1:12:38, 19.39it/s]
epoch 15500  training loss: 0.056554220616817474



 16%|████████████▎                                                                  | 15624/100000 [13:06<1:12:18, 19.45it/s]
epoch 15600  training loss: 0.10614759474992752


 16%|████████████▍                                                                  | 15704/100000 [13:10<1:11:38, 19.61it/s]
epoch 15700  training loss: 0.05811990797519684



 16%|████████████▍                                                                  | 15822/100000 [13:16<1:13:59, 18.96it/s]
epoch 15800  training loss: 0.05518747866153717


 16%|████████████▌                                                                  | 15899/100000 [13:20<1:09:49, 20.07it/s]
epoch 15900  training loss: 0.05656478554010391



 16%|████████████▋                                                                  | 16020/100000 [13:26<1:11:13, 19.65it/s]
epoch 16000  training loss: 0.05256146192550659
epoch 16000  clean testing loss: 0.04334709793329239



 16%|████████████▋                                                                  | 16138/100000 [13:32<1:14:34, 18.74it/s]
epoch 16100  training loss: 0.05721907317638397


 16%|████████████▊                                                                  | 16218/100000 [13:36<1:09:15, 20.16it/s]
epoch 16200  training loss: 0.06101761385798454



 16%|████████████▉                                                                  | 16335/100000 [13:42<1:10:35, 19.75it/s]
epoch 16300  training loss: 0.06165910139679909


 16%|████████████▉                                                                  | 16414/100000 [13:46<1:05:04, 21.41it/s]
epoch 16400  training loss: 0.0601656436920166



 17%|█████████████                                                                  | 16536/100000 [13:52<1:08:41, 20.25it/s]
epoch 16500  training loss: 0.05939515680074692


 17%|█████████████▏                                                                 | 16616/100000 [13:56<1:10:39, 19.67it/s]
epoch 16600  training loss: 0.0713689774274826



 17%|█████████████▏                                                                 | 16731/100000 [14:02<1:11:21, 19.45it/s]
epoch 16700  training loss: 0.06150779873132706


 17%|█████████████▎                                                                 | 16809/100000 [14:06<1:11:12, 19.47it/s]
epoch 16800  training loss: 0.05776448920369148



 17%|█████████████▎                                                                 | 16925/100000 [14:12<1:11:13, 19.44it/s]
epoch 16900  training loss: 0.06077338010072708


 17%|█████████████▍                                                                 | 17005/100000 [14:16<1:09:52, 19.79it/s]
epoch 17000  training loss: 0.07603414356708527
epoch 17000  clean testing loss: 0.04246675968170166



 17%|█████████████▌                                                                 | 17122/100000 [14:22<1:08:47, 20.08it/s]
epoch 17100  training loss: 0.05789848417043686


 17%|█████████████▌                                                                 | 17210/100000 [14:26<1:00:33, 22.79it/s]
epoch 17200  training loss: 0.0548982098698616


 17%|██████████████                                                                   | 17313/100000 [14:30<47:23, 29.08it/s]
epoch 17300  training loss: 0.05723794177174568
 17%|█████████████▋                                                                 | 17340/100000 [14:31<1:09:15, 19.89it/s]
Traceback (most recent call last):
  File "/home/howon/aistats25-exp/nn_exp.py", line 272, in <module>
    for i in tqdm(range(epoch)):
  File "/home/howon/aistats25-exp/nn_exp.py", line 261, in closure
    clean_test_loss_record = []
  File "/home/howon/aistats25-exp/nn_exp.py", line 227, in compute_loss
    assert(train_y.shape == (args.sample_size, 1))
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/autograd/__init__.py", line 412, in grad
    result = _engine_run_backward(
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt