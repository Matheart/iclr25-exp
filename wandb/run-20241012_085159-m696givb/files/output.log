
  0%|          | 29/100000 [00:02<1:44:07, 16.00it/s]
epoch 0  training loss: 46.71798324584961
epoch 0  clean testing loss: 43.02288055419922



  0%|          | 117/100000 [00:07<1:43:40, 16.06it/s]
epoch 100  training loss: 17.53489875793457



  0%|          | 213/100000 [00:13<1:43:38, 16.05it/s]
epoch 200  training loss: 16.440853118896484



  0%|          | 309/100000 [00:19<1:43:41, 16.02it/s]
epoch 300  training loss: 15.041752815246582



  0%|          | 405/100000 [00:25<1:43:46, 16.00it/s]
epoch 400  training loss: 11.459256172180176



  1%|          | 501/100000 [00:31<1:43:34, 16.01it/s]
epoch 500  training loss: 5.163613796234131




  1%|          | 629/100000 [00:39<1:43:19, 16.03it/s]
epoch 600  training loss: 1.5706803798675537



  1%|          | 727/100000 [00:45<1:43:15, 16.02it/s]
epoch 700  training loss: 0.9521304368972778



  1%|          | 823/100000 [00:51<1:43:08, 16.02it/s]
epoch 800  training loss: 0.6336233019828796



  1%|          | 917/100000 [00:57<1:43:18, 15.98it/s]
epoch 900  training loss: 0.46292752027511597



  1%|          | 1013/100000 [01:03<1:43:16, 15.98it/s]
epoch 1000  training loss: 0.36577722430229187
epoch 1000  clean testing loss: 0.2749824523925781



  1%|          | 1109/100000 [01:09<1:43:09, 15.98it/s]
epoch 1100  training loss: 0.29703283309936523



  1%|          | 1207/100000 [01:15<1:43:02, 15.98it/s]
epoch 1200  training loss: 0.24039320647716522



  1%|▏         | 1303/100000 [01:21<1:43:14, 15.93it/s]
epoch 1300  training loss: 0.20996281504631042




  1%|▏         | 1429/100000 [01:29<1:42:37, 16.01it/s]
epoch 1400  training loss: 0.18585385382175446



  2%|▏         | 1525/100000 [01:35<1:42:32, 16.01it/s]
epoch 1500  training loss: 0.17796696722507477



  2%|▏         | 1623/100000 [01:41<1:42:28, 16.00it/s]
epoch 1600  training loss: 0.16587451100349426



  2%|▏         | 1719/100000 [01:47<1:42:36, 15.96it/s]
epoch 1700  training loss: 0.1552121490240097



  2%|▏         | 1813/100000 [01:53<1:42:43, 15.93it/s]
epoch 1800  training loss: 0.14859041571617126



  2%|▏         | 1909/100000 [01:59<1:42:18, 15.98it/s]
epoch 1900  training loss: 0.14409364759922028



  2%|▏         | 2005/100000 [02:05<1:42:45, 15.89it/s]
epoch 2000  training loss: 0.13749733567237854
epoch 2000  clean testing loss: 0.05153365805745125



  2%|▏         | 2103/100000 [02:11<1:42:08, 15.97it/s]
epoch 2100  training loss: 0.1317175328731537




  2%|▏         | 2231/100000 [02:19<1:41:39, 16.03it/s]
epoch 2200  training loss: 0.12774771451950073



  2%|▏         | 2325/100000 [02:25<1:41:34, 16.03it/s]
epoch 2300  training loss: 0.1252351701259613



  2%|▏         | 2423/100000 [02:31<1:41:27, 16.03it/s]
epoch 2400  training loss: 0.12229889631271362



  3%|▎         | 2519/100000 [02:37<1:41:26, 16.02it/s]
epoch 2500  training loss: 0.11907806247472763



  3%|▎         | 2615/100000 [02:43<1:41:24, 16.01it/s]
epoch 2600  training loss: 0.11540304869413376



  3%|▎         | 2711/100000 [02:49<1:41:13, 16.02it/s]
epoch 2700  training loss: 0.11382497102022171



  3%|▎         | 2807/100000 [02:55<1:41:19, 15.99it/s]
epoch 2800  training loss: 0.11321142315864563



  3%|▎         | 2903/100000 [03:01<1:41:19, 15.97it/s]
epoch 2900  training loss: 0.11430822312831879




  3%|▎         | 3031/100000 [03:09<1:40:52, 16.02it/s]
epoch 3000  training loss: 0.11245812475681305
epoch 3000  clean testing loss: 0.025452733039855957



  3%|▎         | 3127/100000 [03:15<1:40:46, 16.02it/s]
epoch 3100  training loss: 0.10952631384134293



  3%|▎         | 3223/100000 [03:21<1:40:38, 16.03it/s]
epoch 3200  training loss: 0.10829749703407288



  3%|▎         | 3319/100000 [03:27<1:40:42, 16.00it/s]
epoch 3300  training loss: 0.10714806616306305



  3%|▎         | 3415/100000 [03:33<1:40:28, 16.02it/s]
epoch 3400  training loss: 0.10588118433952332



  4%|▎         | 3511/100000 [03:39<1:40:31, 16.00it/s]
epoch 3500  training loss: 0.104847751557827



  4%|▎         | 3609/100000 [03:46<1:40:39, 15.96it/s]
epoch 3600  training loss: 0.104413703083992



  4%|▎         | 3705/100000 [03:52<1:40:46, 15.93it/s]
epoch 3700  training loss: 0.10347117483615875



  4%|▍         | 3801/100000 [03:58<1:40:08, 16.01it/s]
epoch 3800  training loss: 0.10397490859031677




  4%|▍         | 3929/100000 [04:06<1:40:05, 16.00it/s]
epoch 3900  training loss: 0.10324018448591232



  4%|▍         | 4025/100000 [04:12<1:39:49, 16.02it/s]
epoch 4000  training loss: 0.1034448966383934
epoch 4000  clean testing loss: 0.018137166276574135



  4%|▍         | 4121/100000 [04:18<1:39:56, 15.99it/s]
epoch 4100  training loss: 0.10275634378194809



  4%|▍         | 4217/100000 [04:24<1:40:39, 15.86it/s]
epoch 4200  training loss: 0.1049816831946373



  4%|▍         | 4313/100000 [04:30<1:39:45, 15.99it/s]
epoch 4300  training loss: 0.10556049644947052



  4%|▍         | 4409/100000 [04:36<1:39:47, 15.96it/s]
epoch 4400  training loss: 0.10685812681913376



  5%|▍         | 4505/100000 [04:42<1:39:36, 15.98it/s]
epoch 4500  training loss: 0.10813552141189575



  5%|▍         | 4601/100000 [04:48<1:39:20, 16.01it/s]
epoch 4600  training loss: 0.10739801824092865




  5%|▍         | 4729/100000 [04:56<1:39:13, 16.00it/s]
epoch 4700  training loss: 0.10725311189889908



  5%|▍         | 4825/100000 [05:02<1:39:07, 16.00it/s]
epoch 4800  training loss: 0.10764579474925995



  5%|▍         | 4921/100000 [05:08<1:39:00, 16.01it/s]
epoch 4900  training loss: 0.11122177541255951



  5%|▌         | 5017/100000 [05:14<1:39:08, 15.97it/s]
epoch 5000  training loss: 0.11033274978399277
epoch 5000  clean testing loss: 0.02137521281838417



  5%|▌         | 5113/100000 [05:20<1:39:03, 15.96it/s]
epoch 5100  training loss: 0.11086933314800262



  5%|▌         | 5209/100000 [05:26<1:38:51, 15.98it/s]
epoch 5200  training loss: 0.10946743190288544



  5%|▌         | 5305/100000 [05:32<1:38:48, 15.97it/s]
epoch 5300  training loss: 0.10759555548429489



  5%|▌         | 5401/100000 [05:38<1:38:26, 16.02it/s]
epoch 5400  training loss: 0.10871604830026627




  6%|▌         | 5531/100000 [05:46<1:38:26, 15.99it/s]
epoch 5500  training loss: 0.1079401820898056



  6%|▌         | 5627/100000 [05:52<1:38:29, 15.97it/s]
epoch 5600  training loss: 0.10550235211849213



  6%|▌         | 5721/100000 [05:58<1:38:18, 15.98it/s]
epoch 5700  training loss: 0.10330143570899963



  6%|▌         | 5819/100000 [06:04<1:37:56, 16.03it/s]
epoch 5800  training loss: 0.10290522128343582



  6%|▌         | 5915/100000 [06:10<1:37:49, 16.03it/s]
epoch 5900  training loss: 0.10230530053377151



  6%|▌         | 6011/100000 [06:16<1:38:09, 15.96it/s]
epoch 6000  training loss: 0.10233841091394424
epoch 6000  clean testing loss: 0.01606132835149765



  6%|▌         | 6107/100000 [06:22<1:37:55, 15.98it/s]
epoch 6100  training loss: 0.10051187127828598



  6%|▌         | 6203/100000 [06:28<1:38:06, 15.94it/s]
epoch 6200  training loss: 0.09982982277870178




  6%|▋         | 6331/100000 [06:36<1:37:33, 16.00it/s]
epoch 6300  training loss: 0.0997805967926979



  6%|▋         | 6427/100000 [06:42<1:37:19, 16.02it/s]
epoch 6400  training loss: 0.09997399896383286



  7%|▋         | 6523/100000 [06:48<1:37:12, 16.03it/s]
epoch 6500  training loss: 0.09943219274282455



  7%|▋         | 6619/100000 [06:54<1:40:41, 15.46it/s]
epoch 6600  training loss: 0.09934287518262863



  7%|▋         | 6715/100000 [07:00<1:37:21, 15.97it/s]
epoch 6700  training loss: 0.09949864447116852



  7%|▋         | 6811/100000 [07:06<1:37:08, 15.99it/s]
epoch 6800  training loss: 0.09878010302782059



  7%|▋         | 6907/100000 [07:12<1:37:07, 15.97it/s]
epoch 6900  training loss: 0.09831779450178146



  7%|▋         | 7003/100000 [07:18<1:38:19, 15.76it/s]
epoch 7000  training loss: 0.09819861501455307
epoch 7000  clean testing loss: 0.01372601743787527




  7%|▋         | 7131/100000 [07:26<1:36:37, 16.02it/s]
epoch 7100  training loss: 0.09775954484939575



  7%|▋         | 7227/100000 [07:32<1:36:37, 16.00it/s]
epoch 7200  training loss: 0.09763245284557343



  7%|▋         | 7325/100000 [07:38<1:36:28, 16.01it/s]
epoch 7300  training loss: 0.09876340627670288



  7%|▋         | 7413/100000 [07:44<1:36:22, 16.01it/s]
epoch 7400  training loss: 0.09924085438251495



  8%|▊         | 7509/100000 [07:50<1:36:33, 15.96it/s]
epoch 7500  training loss: 0.10013365000486374



  8%|▊         | 7605/100000 [07:56<1:36:43, 15.92it/s]
epoch 7600  training loss: 0.09808637201786041



  8%|▊         | 7701/100000 [08:02<1:35:59, 16.03it/s]
epoch 7700  training loss: 0.09785468131303787



  8%|▊         | 7797/100000 [08:08<1:35:53, 16.03it/s]
epoch 7800  training loss: 0.09669441729784012



  8%|▊         | 7893/100000 [08:14<1:35:54, 16.01it/s]
epoch 7900  training loss: 0.0976853296160698




  8%|▊         | 8021/100000 [08:22<1:35:47, 16.00it/s]
epoch 8000  training loss: 0.09741230309009552
epoch 8000  clean testing loss: 0.012445937842130661



  8%|▊         | 8117/100000 [08:28<1:35:46, 15.99it/s]
epoch 8100  training loss: 0.0965212732553482



  8%|▊         | 8213/100000 [08:34<1:35:34, 16.01it/s]
epoch 8200  training loss: 0.09679234027862549



  8%|▊         | 8309/100000 [08:40<1:35:45, 15.96it/s]
epoch 8300  training loss: 0.09636595100164413



  8%|▊         | 8405/100000 [08:46<1:35:29, 15.99it/s]
epoch 8400  training loss: 0.09641405940055847



  9%|▊         | 8501/100000 [08:52<1:35:13, 16.01it/s]
epoch 8500  training loss: 0.10050863772630692



  9%|▊         | 8597/100000 [08:58<1:35:07, 16.01it/s]
epoch 8600  training loss: 0.09819617122411728



  9%|▊         | 8693/100000 [09:04<1:34:50, 16.04it/s]
epoch 8700  training loss: 0.1006542444229126




  9%|▉         | 8823/100000 [09:12<1:34:38, 16.06it/s]
epoch 8800  training loss: 0.09867853671312332



  9%|▉         | 8919/100000 [09:18<1:34:35, 16.05it/s]
epoch 8900  training loss: 0.09946627914905548



  9%|▉         | 9015/100000 [09:24<1:34:35, 16.03it/s]
epoch 9000  training loss: 0.09954217076301575
epoch 9000  clean testing loss: 0.013191008940339088



  9%|▉         | 9111/100000 [09:30<1:34:37, 16.01it/s]
epoch 9100  training loss: 0.09907601773738861



  9%|▉         | 9207/100000 [09:36<1:34:25, 16.02it/s]
epoch 9200  training loss: 0.09918219596147537



  9%|▉         | 9303/100000 [09:42<1:34:43, 15.96it/s]
epoch 9300  training loss: 0.09842012822628021



  9%|▉         | 9401/100000 [09:48<1:34:06, 16.04it/s]
epoch 9400  training loss: 0.09788110107183456




 10%|▉         | 9529/100000 [09:56<1:34:10, 16.01it/s]
epoch 9500  training loss: 0.0974133163690567



 10%|▉         | 9625/100000 [10:02<1:33:50, 16.05it/s]
epoch 9600  training loss: 0.09623169898986816



 10%|▉         | 9721/100000 [10:08<1:33:44, 16.05it/s]
epoch 9700  training loss: 0.10133510082960129



 10%|▉         | 9817/100000 [10:14<1:33:40, 16.05it/s]
epoch 9800  training loss: 0.09597604721784592



 10%|▉         | 9915/100000 [10:20<1:33:49, 16.00it/s]
epoch 9900  training loss: 0.09590760618448257



 10%|█         | 10009/100000 [10:26<1:34:17, 15.91it/s]
epoch 10000  training loss: 0.09576693922281265
epoch 10000  clean testing loss: 0.010491536930203438



 10%|█         | 10105/100000 [10:32<1:33:35, 16.01it/s]
epoch 10100  training loss: 0.09563891589641571



 10%|█         | 10203/100000 [10:38<1:33:29, 16.01it/s]
epoch 10200  training loss: 0.09711869806051254




 10%|█         | 10331/100000 [10:46<1:33:09, 16.04it/s]
epoch 10300  training loss: 0.09577580541372299



 10%|█         | 10427/100000 [10:52<1:33:17, 16.00it/s]
epoch 10400  training loss: 0.09600537270307541



 11%|█         | 10523/100000 [10:58<1:32:59, 16.04it/s]
epoch 10500  training loss: 0.09509500861167908



 11%|█         | 10619/100000 [11:04<1:33:00, 16.02it/s]
epoch 10600  training loss: 0.09507731348276138



 11%|█         | 10715/100000 [11:10<1:32:59, 16.00it/s]
epoch 10700  training loss: 0.09447411447763443



 11%|█         | 10813/100000 [11:16<1:32:37, 16.05it/s]
epoch 10800  training loss: 0.09524815529584885



 11%|█         | 10909/100000 [11:22<1:32:38, 16.03it/s]
epoch 10900  training loss: 0.09437032043933868



 11%|█         | 11003/100000 [11:28<1:33:40, 15.83it/s]
epoch 11000  training loss: 0.09465010464191437
epoch 11000  clean testing loss: 0.010012947954237461



 11%|█         | 11101/100000 [11:34<1:32:14, 16.06it/s]
epoch 11100  training loss: 0.09521055966615677




 11%|█         | 11229/100000 [11:42<1:32:08, 16.06it/s]
epoch 11200  training loss: 0.09511127322912216



 11%|█▏        | 11325/100000 [11:48<1:32:08, 16.04it/s]
epoch 11300  training loss: 0.09583748131990433



 11%|█▏        | 11423/100000 [11:54<1:31:55, 16.06it/s]
epoch 11400  training loss: 0.09511968493461609



 12%|█▏        | 11517/100000 [12:00<1:31:54, 16.05it/s]
epoch 11500  training loss: 0.09561623632907867



 12%|█▏        | 11615/100000 [12:06<1:31:50, 16.04it/s]
epoch 11600  training loss: 0.09591614454984665



 12%|█▏        | 11711/100000 [12:12<1:31:43, 16.04it/s]
epoch 11700  training loss: 0.09569101780653



 12%|█▏        | 11807/100000 [12:18<1:31:42, 16.03it/s]
epoch 11800  training loss: 0.09460154175758362



 12%|█▏        | 11903/100000 [12:24<1:31:49, 15.99it/s]
epoch 11900  training loss: 0.09467813372612




 12%|█▏        | 12031/100000 [12:32<1:31:30, 16.02it/s]
epoch 12000  training loss: 0.09497284144163132
epoch 12000  clean testing loss: 0.009718384593725204



 12%|█▏        | 12127/100000 [12:38<1:31:11, 16.06it/s]
epoch 12100  training loss: 0.09428035467863083



 12%|█▏        | 12223/100000 [12:44<1:31:08, 16.05it/s]
epoch 12200  training loss: 0.09483741968870163



 12%|█▏        | 12321/100000 [12:50<1:31:09, 16.03it/s]
epoch 12300  training loss: 0.09502092003822327



 12%|█▏        | 12417/100000 [12:56<1:31:57, 15.87it/s]
epoch 12400  training loss: 0.09461838006973267



 13%|█▎        | 12513/100000 [13:02<1:30:53, 16.04it/s]
epoch 12500  training loss: 0.09471551328897476



 13%|█▎        | 12609/100000 [13:08<1:30:48, 16.04it/s]
epoch 12600  training loss: 0.09431157261133194



 13%|█▎        | 12705/100000 [13:14<1:30:57, 16.00it/s]
epoch 12700  training loss: 0.09916876256465912



 13%|█▎        | 12801/100000 [13:20<1:30:40, 16.03it/s]
epoch 12800  training loss: 0.09393316507339478




 13%|█▎        | 12929/100000 [13:28<1:30:29, 16.04it/s]
epoch 12900  training loss: 0.09363879263401031



 13%|█▎        | 13025/100000 [13:34<1:30:24, 16.03it/s]
epoch 13000  training loss: 0.09470580518245697
epoch 13000  clean testing loss: 0.009767216630280018



 13%|█▎        | 13123/100000 [13:40<1:30:17, 16.04it/s]
epoch 13100  training loss: 0.09540457278490067



 13%|█▎        | 13219/100000 [13:46<1:30:08, 16.05it/s]
epoch 13200  training loss: 0.09696868807077408



 13%|█▎        | 13315/100000 [13:52<1:30:04, 16.04it/s]
epoch 13300  training loss: 0.09655511379241943



 13%|█▎        | 13411/100000 [13:58<1:29:54, 16.05it/s]
epoch 13400  training loss: 0.09572002291679382



 14%|█▎        | 13507/100000 [14:04<1:29:54, 16.03it/s]
epoch 13500  training loss: 0.09519725292921066



 14%|█▎        | 13603/100000 [14:10<1:30:02, 15.99it/s]
epoch 13600  training loss: 0.09507451206445694




 14%|█▎        | 13733/100000 [14:18<1:29:32, 16.06it/s]
epoch 13700  training loss: 0.09471479058265686



 14%|█▍        | 13829/100000 [14:24<1:29:26, 16.06it/s]
epoch 13800  training loss: 0.0944652184844017



 14%|█▍        | 13925/100000 [14:30<1:29:16, 16.07it/s]
epoch 13900  training loss: 0.09478002041578293



 14%|█▍        | 14021/100000 [14:36<1:29:14, 16.06it/s]
epoch 14000  training loss: 0.09431039541959763
epoch 14000  clean testing loss: 0.008818927221000195



 14%|█▍        | 14117/100000 [14:42<1:29:05, 16.07it/s]
epoch 14100  training loss: 0.09446513652801514



 14%|█▍        | 14215/100000 [14:48<1:28:58, 16.07it/s]
epoch 14200  training loss: 0.09398426115512848



 14%|█▍        | 14311/100000 [14:54<1:29:00, 16.05it/s]
epoch 14300  training loss: 0.09375518560409546



 14%|█▍        | 14407/100000 [15:00<1:28:55, 16.04it/s]
epoch 14400  training loss: 0.09352380037307739



 14%|█▍        | 14495/100000 [15:06<1:28:43, 16.06it/s]
epoch 14500  training loss: 0.09331631660461426




 15%|█▍        | 14623/100000 [15:14<1:28:31, 16.07it/s]
epoch 14600  training loss: 0.09424865245819092



 15%|█▍        | 14721/100000 [15:20<1:28:49, 16.00it/s]
epoch 14700  training loss: 0.09380806982517242



 15%|█▍        | 14817/100000 [15:26<1:33:15, 15.22it/s]
epoch 14800  training loss: 0.0934915617108345



 15%|█▍        | 14913/100000 [15:32<1:28:18, 16.06it/s]
epoch 14900  training loss: 0.09306725114583969



 15%|█▌        | 15009/100000 [15:38<1:28:34, 15.99it/s]
epoch 15000  training loss: 0.09349040687084198
epoch 15000  clean testing loss: 0.009119979105889797



 15%|█▌        | 15105/100000 [15:44<1:28:20, 16.02it/s]
epoch 15100  training loss: 0.09362839162349701



 15%|█▌        | 15201/100000 [15:50<1:28:07, 16.04it/s]
epoch 15200  training loss: 0.09331957995891571



 15%|█▌        | 15299/100000 [15:56<1:27:57, 16.05it/s]
epoch 15300  training loss: 0.0931834951043129



 15%|█▌        | 15395/100000 [16:02<1:27:49, 16.06it/s]
epoch 15400  training loss: 0.0927739217877388




 16%|█▌        | 15523/100000 [16:10<1:27:42, 16.05it/s]
epoch 15500  training loss: 0.09300939738750458



 16%|█▌        | 15619/100000 [16:16<1:27:33, 16.06it/s]
epoch 15600  training loss: 0.09292291104793549



 16%|█▌        | 15715/100000 [16:22<1:27:33, 16.04it/s]
epoch 15700  training loss: 0.09293648600578308



 16%|█▌        | 15811/100000 [16:28<1:27:38, 16.01it/s]
epoch 15800  training loss: 0.09310733526945114



 16%|█▌        | 15907/100000 [16:34<1:27:30, 16.02it/s]
epoch 15900  training loss: 0.09295137971639633



 16%|█▌        | 16003/100000 [16:40<1:28:19, 15.85it/s]
epoch 16000  training loss: 0.09257525950670242
epoch 16000  clean testing loss: 0.009073957800865173



 16%|█▌        | 16101/100000 [16:46<1:27:08, 16.05it/s]
epoch 16100  training loss: 0.09266860038042068



 16%|█▌        | 16197/100000 [16:52<1:27:01, 16.05it/s]
epoch 16200  training loss: 0.0927921012043953



 16%|█▋        | 16293/100000 [16:58<1:26:59, 16.04it/s]
epoch 16300  training loss: 0.09243731200695038




 16%|█▋        | 16421/100000 [17:06<1:26:50, 16.04it/s]
epoch 16400  training loss: 0.09247033298015594



 17%|█▋        | 16517/100000 [17:12<1:26:43, 16.04it/s]
epoch 16500  training loss: 0.09325415641069412



 17%|█▋        | 16613/100000 [17:18<1:26:37, 16.04it/s]
epoch 16600  training loss: 0.09292266517877579



 17%|█▋        | 16711/100000 [17:24<1:26:30, 16.04it/s]
epoch 16700  training loss: 0.09320517629384995



 17%|█▋        | 16805/100000 [17:30<1:26:36, 16.01it/s]
epoch 16800  training loss: 0.09273670613765717



 17%|█▋        | 16903/100000 [17:36<1:26:34, 16.00it/s]
epoch 16900  training loss: 0.09253392368555069




 17%|█▋        | 17031/100000 [17:44<1:26:04, 16.07it/s]
epoch 17000  training loss: 0.09274674206972122
epoch 17000  clean testing loss: 0.008828457444906235



 17%|█▋        | 17127/100000 [17:50<1:25:58, 16.07it/s]
epoch 17100  training loss: 0.09276337921619415



 17%|█▋        | 17225/100000 [17:56<1:25:55, 16.05it/s]
epoch 17200  training loss: 0.092288538813591



 17%|█▋        | 17319/100000 [18:02<1:25:48, 16.06it/s]
epoch 17300  training loss: 0.09274300932884216



 17%|█▋        | 17417/100000 [18:08<1:25:41, 16.06it/s]
epoch 17400  training loss: 0.09275854378938675



 18%|█▊        | 17513/100000 [18:14<1:25:38, 16.05it/s]
epoch 17500  training loss: 0.09256444871425629



 18%|█▊        | 17609/100000 [18:20<1:25:36, 16.04it/s]
epoch 17600  training loss: 0.09245667606592178



 18%|█▊        | 17705/100000 [18:26<1:25:31, 16.04it/s]
epoch 17700  training loss: 0.09245080500841141



 18%|█▊        | 17801/100000 [18:32<1:25:18, 16.06it/s]
epoch 17800  training loss: 0.09265568107366562




 18%|█▊        | 17931/100000 [18:40<1:25:09, 16.06it/s]
epoch 17900  training loss: 0.09260430932044983



 18%|█▊        | 18027/100000 [18:46<1:25:04, 16.06it/s]
epoch 18000  training loss: 0.09251882135868073
epoch 18000  clean testing loss: 0.00915923248976469



 18%|█▊        | 18123/100000 [18:52<1:24:56, 16.06it/s]
epoch 18100  training loss: 0.09236099570989609



 18%|█▊        | 18219/100000 [18:58<1:25:16, 15.99it/s]
epoch 18200  training loss: 0.09205061942338943



 18%|█▊        | 18315/100000 [19:04<1:24:47, 16.06it/s]
epoch 18300  training loss: 0.09220481663942337



 18%|█▊        | 18413/100000 [19:11<1:24:46, 16.04it/s]
epoch 18400  training loss: 0.09143776446580887



 19%|█▊        | 18509/100000 [19:17<1:24:43, 16.03it/s]
epoch 18500  training loss: 0.09163077175617218



 19%|█▊        | 18605/100000 [19:22<1:24:44, 16.01it/s]
epoch 18600  training loss: 0.0918550118803978



 19%|█▊        | 18701/100000 [19:29<1:24:51, 15.97it/s]
epoch 18700  training loss: 0.09169935435056686




 19%|█▉        | 18829/100000 [19:36<1:24:14, 16.06it/s]
epoch 18800  training loss: 0.09135762602090836



 19%|█▉        | 18927/100000 [19:43<1:24:14, 16.04it/s]
epoch 18900  training loss: 0.0920552983880043



 19%|█▉        | 19023/100000 [19:49<1:24:03, 16.05it/s]
epoch 19000  training loss: 0.09325740486383438
epoch 19000  clean testing loss: 0.009177432395517826



 19%|█▉        | 19119/100000 [19:55<1:23:53, 16.07it/s]
epoch 19100  training loss: 0.09236305952072144



 19%|█▉        | 19215/100000 [20:01<1:23:53, 16.05it/s]
epoch 19200  training loss: 0.09227265417575836



 19%|█▉        | 19311/100000 [20:07<1:23:42, 16.07it/s]
epoch 19300  training loss: 0.09211254119873047



 19%|█▉        | 19407/100000 [20:13<1:23:47, 16.03it/s]
epoch 19400  training loss: 0.09164711833000183



 20%|█▉        | 19505/100000 [20:19<1:23:36, 16.05it/s]
epoch 19500  training loss: 0.09218055754899979



 20%|█▉        | 19601/100000 [20:25<1:23:38, 16.02it/s]
epoch 19600  training loss: 0.09151351451873779




 20%|█▉        | 19729/100000 [20:33<1:23:13, 16.08it/s]
epoch 19700  training loss: 0.09217125922441483



 20%|█▉        | 19825/100000 [20:39<1:23:10, 16.07it/s]
epoch 19800  training loss: 0.09125492721796036



 20%|█▉        | 19921/100000 [20:45<1:23:05, 16.06it/s]
epoch 19900  training loss: 0.09141941368579865



 20%|██        | 20019/100000 [20:51<1:23:02, 16.05it/s]
epoch 20000  training loss: 0.09190942347049713
epoch 20000  clean testing loss: 0.009158434346318245



 20%|██        | 20115/100000 [20:57<1:22:55, 16.06it/s]
epoch 20100  training loss: 0.09112957119941711



 20%|██        | 20211/100000 [21:03<1:22:48, 16.06it/s]
epoch 20200  training loss: 0.0912398174405098



 20%|██        | 20307/100000 [21:09<1:22:51, 16.03it/s]
epoch 20300  training loss: 0.09112916886806488



 20%|██        | 20403/100000 [21:15<1:22:57, 15.99it/s]
epoch 20400  training loss: 0.09139184653759003



 20%|██        | 20499/100000 [21:21<1:22:32, 16.05it/s]
epoch 20500  training loss: 0.09127242118120193




 21%|██        | 20627/100000 [21:29<1:24:05, 15.73it/s]
epoch 20600  training loss: 0.09088058769702911



 21%|██        | 20725/100000 [21:35<1:22:19, 16.05it/s]
epoch 20700  training loss: 0.09139519929885864



 21%|██        | 20821/100000 [21:41<1:22:11, 16.06it/s]
epoch 20800  training loss: 0.09180231392383575



 21%|██        | 20917/100000 [21:47<1:22:04, 16.06it/s]
epoch 20900  training loss: 0.09112055599689484



 21%|██        | 21013/100000 [21:53<1:22:13, 16.01it/s]
epoch 21000  training loss: 0.09199677407741547
epoch 21000  clean testing loss: 0.009192940779030323



 21%|██        | 21109/100000 [21:59<1:24:15, 15.60it/s]
epoch 21100  training loss: 0.09073595702648163



 21%|██        | 21207/100000 [22:05<1:21:56, 16.03it/s]
epoch 21200  training loss: 0.09100092202425003



 21%|██▏       | 21303/100000 [22:11<1:21:54, 16.01it/s]
epoch 21300  training loss: 0.0911082997918129




 21%|██▏       | 21431/100000 [22:19<1:21:35, 16.05it/s]
epoch 21400  training loss: 0.09117905050516129



 22%|██▏       | 21519/100000 [22:24<1:21:27, 16.06it/s]
epoch 21500  training loss: 0.09105513244867325



 22%|██▏       | 21615/100000 [22:30<1:21:26, 16.04it/s]
epoch 21600  training loss: 0.09140945225954056



 22%|██▏       | 21711/100000 [22:36<1:21:17, 16.05it/s]
epoch 21700  training loss: 0.09106166660785675



 22%|██▏       | 21809/100000 [22:42<1:21:36, 15.97it/s]
epoch 21800  training loss: 0.09088589996099472



 22%|██▏       | 21905/100000 [22:48<1:21:16, 16.01it/s]
epoch 21900  training loss: 0.09114348888397217



 22%|██▏       | 22001/100000 [22:54<1:22:40, 15.72it/s]
epoch 22000  training loss: 0.09072960168123245
epoch 22000  clean testing loss: 0.008925462141633034



 22%|██▏       | 22097/100000 [23:00<1:20:53, 16.05it/s]
epoch 22100  training loss: 0.09050273150205612



 22%|██▏       | 22193/100000 [23:06<1:20:44, 16.06it/s]
epoch 22200  training loss: 0.09036900103092194




 22%|██▏       | 22323/100000 [23:15<1:20:38, 16.05it/s]
epoch 22300  training loss: 0.09060321748256683



 22%|██▏       | 22419/100000 [23:21<1:20:31, 16.06it/s]
epoch 22400  training loss: 0.09040438383817673



 23%|██▎       | 22515/100000 [23:27<1:20:29, 16.04it/s]
epoch 22500  training loss: 0.09021405875682831



 23%|██▎       | 22611/100000 [23:33<1:20:22, 16.05it/s]
epoch 22600  training loss: 0.09004034101963043



 23%|██▎       | 22707/100000 [23:39<1:20:23, 16.02it/s]
epoch 22700  training loss: 0.08959246426820755



 23%|██▎       | 22803/100000 [23:45<1:20:25, 16.00it/s]
epoch 22800  training loss: 0.08998599648475647



 23%|██▎       | 22901/100000 [23:51<1:20:05, 16.04it/s]
epoch 22900  training loss: 0.08979770541191101



 23%|██▎       | 22997/100000 [23:57<1:19:46, 16.09it/s]
epoch 23000  training loss: 0.09006156027317047
epoch 23000  clean testing loss: 0.009559576399624348



 23%|██▎       | 23093/100000 [24:03<1:19:46, 16.07it/s]
epoch 23100  training loss: 0.08987778425216675




 23%|██▎       | 23221/100000 [24:11<1:19:39, 16.07it/s]
epoch 23200  training loss: 0.09125600010156631



 23%|██▎       | 23317/100000 [24:17<1:19:34, 16.06it/s]
epoch 23300  training loss: 0.08991691470146179



 23%|██▎       | 23415/100000 [24:23<1:19:33, 16.04it/s]
epoch 23400  training loss: 0.09047900140285492



 24%|██▎       | 23511/100000 [24:29<1:19:24, 16.05it/s]
epoch 23500  training loss: 0.08972001820802689



 24%|██▎       | 23607/100000 [24:35<1:19:22, 16.04it/s]
epoch 23600  training loss: 0.0895303413271904



 24%|██▎       | 23703/100000 [24:41<1:19:26, 16.01it/s]
epoch 23700  training loss: 0.08931975811719894




 24%|██▍       | 23831/100000 [24:49<1:18:56, 16.08it/s]
epoch 23800  training loss: 0.08963474631309509



 24%|██▍       | 23929/100000 [24:55<1:18:51, 16.08it/s]
epoch 23900  training loss: 0.08964049816131592



 24%|██▍       | 24025/100000 [25:01<1:18:51, 16.06it/s]
epoch 24000  training loss: 0.09010356664657593
epoch 24000  clean testing loss: 0.009544221684336662



 24%|██▍       | 24121/100000 [25:07<1:18:40, 16.07it/s]
epoch 24100  training loss: 0.08970162272453308



 24%|██▍       | 24217/100000 [25:13<1:18:37, 16.06it/s]
epoch 24200  training loss: 0.08948655426502228



 24%|██▍       | 24313/100000 [25:19<1:18:32, 16.06it/s]
epoch 24300  training loss: 0.08954894542694092



 24%|██▍       | 24411/100000 [25:25<1:18:28, 16.05it/s]
epoch 24400  training loss: 0.08955201506614685



 25%|██▍       | 24507/100000 [25:31<1:18:36, 16.01it/s]
epoch 24500  training loss: 0.08952672779560089



 25%|██▍       | 24603/100000 [25:37<1:18:31, 16.00it/s]
epoch 24600  training loss: 0.08955897390842438




 25%|██▍       | 24731/100000 [25:45<1:18:06, 16.06it/s]
epoch 24700  training loss: 0.08934031426906586



 25%|██▍       | 24829/100000 [25:51<1:18:00, 16.06it/s]
epoch 24800  training loss: 0.08919158577919006



 25%|██▍       | 24925/100000 [25:57<1:17:49, 16.08it/s]
epoch 24900  training loss: 0.08972004801034927



 25%|██▌       | 25021/100000 [26:03<1:17:45, 16.07it/s]
epoch 25000  training loss: 0.09014285355806351
epoch 25000  clean testing loss: 0.009224222041666508



 25%|██▌       | 25117/100000 [26:09<1:17:41, 16.07it/s]
epoch 25100  training loss: 0.09010548889636993



 25%|██▌       | 25213/100000 [26:15<1:17:33, 16.07it/s]
epoch 25200  training loss: 0.09025749564170837



 25%|██▌       | 25311/100000 [26:21<1:17:30, 16.06it/s]
epoch 25300  training loss: 0.0903480127453804



 25%|██▌       | 25407/100000 [26:27<1:17:29, 16.04it/s]
epoch 25400  training loss: 0.08987565338611603



 26%|██▌       | 25503/100000 [26:33<1:17:30, 16.02it/s]
epoch 25500  training loss: 0.09001818299293518




 26%|██▌       | 25631/100000 [26:41<1:17:09, 16.06it/s]
epoch 25600  training loss: 0.08980826288461685



 26%|██▌       | 25727/100000 [26:47<1:17:02, 16.07it/s]
epoch 25700  training loss: 0.09013883769512177



 26%|██▌       | 25825/100000 [26:53<1:16:57, 16.07it/s]
epoch 25800  training loss: 0.08977379649877548



 26%|██▌       | 25921/100000 [26:59<1:16:51, 16.06it/s]
epoch 25900  training loss: 0.09000512212514877



 26%|██▌       | 26017/100000 [27:05<1:16:48, 16.05it/s]
epoch 26000  training loss: 0.08962234854698181
epoch 26000  clean testing loss: 0.009609594009816647



 26%|██▌       | 26113/100000 [27:11<1:16:40, 16.06it/s]
epoch 26100  training loss: 0.08950245380401611



 26%|██▌       | 26209/100000 [27:17<1:16:36, 16.05it/s]
epoch 26200  training loss: 0.08949064463376999



 26%|██▋       | 26307/100000 [27:23<1:16:37, 16.03it/s]
epoch 26300  training loss: 0.0893825888633728



 26%|██▋       | 26403/100000 [27:29<1:16:41, 15.99it/s]
epoch 26400  training loss: 0.0892813429236412




 27%|██▋       | 26531/100000 [27:37<1:16:12, 16.07it/s]
epoch 26500  training loss: 0.08950110524892807



 27%|██▋       | 26627/100000 [27:43<1:16:04, 16.08it/s]
epoch 26600  training loss: 0.08931799978017807



 27%|██▋       | 26723/100000 [27:49<1:16:02, 16.06it/s]
epoch 26700  training loss: 0.08944821357727051



 27%|██▋       | 26819/100000 [27:55<1:15:55, 16.06it/s]
epoch 26800  training loss: 0.08943517506122589



 27%|██▋       | 26915/100000 [28:01<1:16:26, 15.93it/s]
epoch 26900  training loss: 0.08920613676309586



 27%|██▋       | 27013/100000 [28:07<1:15:48, 16.05it/s]
epoch 27000  training loss: 0.08890723437070847
epoch 27000  clean testing loss: 0.009925978258252144



 27%|██▋       | 27109/100000 [28:13<1:15:36, 16.07it/s]
epoch 27100  training loss: 0.08916006237268448



 27%|██▋       | 27205/100000 [28:19<1:15:39, 16.04it/s]
epoch 27200  training loss: 0.08922658115625381



 27%|██▋       | 27301/100000 [28:25<1:15:25, 16.07it/s]
epoch 27300  training loss: 0.08856791257858276




 27%|██▋       | 27431/100000 [28:33<1:15:11, 16.08it/s]
epoch 27400  training loss: 0.08874689787626266



 28%|██▊       | 27527/100000 [28:39<1:15:08, 16.08it/s]
epoch 27500  training loss: 0.08835328370332718



 28%|██▊       | 27623/100000 [28:45<1:15:04, 16.07it/s]
epoch 27600  training loss: 0.08893812447786331



 28%|██▊       | 27719/100000 [28:51<1:14:55, 16.08it/s]
epoch 27700  training loss: 0.08834604918956757



 28%|██▊       | 27817/100000 [28:57<1:14:54, 16.06it/s]
epoch 27800  training loss: 0.08889109641313553



 28%|██▊       | 27913/100000 [29:03<1:14:50, 16.05it/s]
epoch 27900  training loss: 0.0889400765299797



 28%|██▊       | 28009/100000 [29:09<1:15:02, 15.99it/s]
epoch 28000  training loss: 0.08871062844991684
epoch 28000  clean testing loss: 0.010068153962492943



 28%|██▊       | 28105/100000 [29:15<1:14:42, 16.04it/s]
epoch 28100  training loss: 0.08860735595226288



 28%|██▊       | 28201/100000 [29:21<1:14:26, 16.07it/s]
epoch 28200  training loss: 0.08880635350942612




 28%|██▊       | 28331/100000 [29:29<1:14:15, 16.08it/s]
epoch 28300  training loss: 0.08893666416406631



 28%|██▊       | 28419/100000 [29:35<1:14:13, 16.07it/s]
epoch 28400  training loss: 0.08840900659561157



 29%|██▊       | 28515/100000 [29:41<1:14:08, 16.07it/s]
epoch 28500  training loss: 0.08834556490182877



 29%|██▊       | 28611/100000 [29:47<1:14:14, 16.03it/s]
epoch 28600  training loss: 0.088942751288414



 29%|██▊       | 28709/100000 [29:53<1:13:59, 16.06it/s]
epoch 28700  training loss: 0.08889425545930862



 29%|██▉       | 28805/100000 [29:59<1:13:57, 16.04it/s]
epoch 28800  training loss: 0.08901911228895187



 29%|██▉       | 28901/100000 [30:05<1:13:46, 16.06it/s]
epoch 28900  training loss: 0.0888034775853157



 29%|██▉       | 28997/100000 [30:11<1:13:40, 16.06it/s]
epoch 29000  training loss: 0.0887325182557106
epoch 29000  clean testing loss: 0.010153585113584995



 29%|██▉       | 29095/100000 [30:17<1:13:30, 16.08it/s]
epoch 29100  training loss: 0.08877728134393692




 29%|██▉       | 29223/100000 [30:25<1:13:27, 16.06it/s]
epoch 29200  training loss: 0.08859631419181824



 29%|██▉       | 29319/100000 [30:31<1:20:51, 14.57it/s]
epoch 29300  training loss: 0.08869863301515579



 29%|██▉       | 29415/100000 [30:37<1:13:12, 16.07it/s]
epoch 29400  training loss: 0.08815208077430725



 30%|██▉       | 29511/100000 [30:43<1:13:10, 16.06it/s]
epoch 29500  training loss: 0.08839773386716843



 30%|██▉       | 29609/100000 [30:49<1:14:02, 15.85it/s]
epoch 29600  training loss: 0.08846034854650497



 30%|██▉       | 29705/100000 [30:55<1:13:10, 16.01it/s]
epoch 29700  training loss: 0.08838893473148346



 30%|██▉       | 29801/100000 [31:01<1:15:16, 15.54it/s]
epoch 29800  training loss: 0.08832376450300217



 30%|██▉       | 29897/100000 [31:07<1:12:39, 16.08it/s]
epoch 29900  training loss: 0.08832065016031265



 30%|██▉       | 29993/100000 [31:13<1:12:37, 16.07it/s]
epoch 30000  training loss: 0.08828724175691605
epoch 30000  clean testing loss: 0.010162746533751488




 30%|███       | 30123/100000 [31:21<1:12:37, 16.03it/s]
epoch 30100  training loss: 0.08838039636611938



 30%|███       | 30219/100000 [31:27<1:12:21, 16.07it/s]
epoch 30200  training loss: 0.08839784562587738



 30%|███       | 30315/100000 [31:33<1:12:22, 16.05it/s]
epoch 30300  training loss: 0.08839041739702225



 30%|███       | 30411/100000 [31:39<1:12:13, 16.06it/s]
epoch 30400  training loss: 0.08820495754480362



 31%|███       | 30507/100000 [31:45<1:12:09, 16.05it/s]
epoch 30500  training loss: 0.08845192939043045



 31%|███       | 30605/100000 [31:51<1:12:07, 16.04it/s]
epoch 30600  training loss: 0.08830856531858444



 31%|███       | 30701/100000 [31:57<1:11:51, 16.07it/s]
epoch 30700  training loss: 0.0881606861948967




 31%|███       | 30829/100000 [32:05<1:11:40, 16.08it/s]
epoch 30800  training loss: 0.08814691752195358



 31%|███       | 30925/100000 [32:11<1:11:38, 16.07it/s]
epoch 30900  training loss: 0.0885436162352562



 31%|███       | 31023/100000 [32:17<1:11:27, 16.09it/s]
epoch 31000  training loss: 0.08869468420743942
epoch 31000  clean testing loss: 0.010378648526966572



 31%|███       | 31119/100000 [32:23<1:11:22, 16.09it/s]
epoch 31100  training loss: 0.08952198177576065



 31%|███       | 31215/100000 [32:29<1:11:18, 16.08it/s]
epoch 31200  training loss: 0.09221407026052475



 31%|███▏      | 31311/100000 [32:35<1:11:14, 16.07it/s]
epoch 31300  training loss: 0.09226671606302261



 31%|███▏      | 31409/100000 [32:41<1:11:13, 16.05it/s]
epoch 31400  training loss: 0.09130900353193283



 32%|███▏      | 31505/100000 [32:47<1:11:13, 16.03it/s]
epoch 31500  training loss: 0.09067610651254654



 32%|███▏      | 31601/100000 [32:53<1:10:57, 16.06it/s]
epoch 31600  training loss: 0.09082625806331635




 32%|███▏      | 31731/100000 [33:01<1:10:47, 16.07it/s]
epoch 31700  training loss: 0.09033796191215515



 32%|███▏      | 31825/100000 [33:07<1:10:39, 16.08it/s]
epoch 31800  training loss: 0.09057828038930893



 32%|███▏      | 31923/100000 [33:13<1:10:36, 16.07it/s]
epoch 31900  training loss: 0.09055858105421066



 32%|███▏      | 32019/100000 [33:19<1:10:30, 16.07it/s]
epoch 32000  training loss: 0.0902152955532074
epoch 32000  clean testing loss: 0.009218118153512478



 32%|███▏      | 32115/100000 [33:25<1:10:24, 16.07it/s]
epoch 32100  training loss: 0.09024423360824585



 32%|███▏      | 32213/100000 [33:31<1:10:18, 16.07it/s]
epoch 32200  training loss: 0.09027514606714249



 32%|███▏      | 32309/100000 [33:37<1:10:14, 16.06it/s]
epoch 32300  training loss: 0.09019405394792557



 32%|███▏      | 32405/100000 [33:43<1:10:17, 16.03it/s]
epoch 32400  training loss: 0.08993513137102127



 33%|███▎      | 32501/100000 [33:49<1:09:59, 16.07it/s]
epoch 32500  training loss: 0.09003791958093643




 33%|███▎      | 32631/100000 [33:57<1:09:48, 16.08it/s]
epoch 32600  training loss: 0.09001874923706055



 33%|███▎      | 32727/100000 [34:03<1:09:52, 16.05it/s]
epoch 32700  training loss: 0.08991343528032303



 33%|███▎      | 32823/100000 [34:09<1:09:37, 16.08it/s]
epoch 32800  training loss: 0.0895950198173523



 33%|███▎      | 32919/100000 [34:15<1:09:33, 16.07it/s]
epoch 32900  training loss: 0.09021752327680588



 33%|███▎      | 33015/100000 [34:21<1:09:38, 16.03it/s]
epoch 33000  training loss: 0.08964525163173676
epoch 33000  clean testing loss: 0.00944676622748375



 33%|███▎      | 33113/100000 [34:28<1:09:20, 16.07it/s]
epoch 33100  training loss: 0.08987880498170853



 33%|███▎      | 33209/100000 [34:34<1:09:31, 16.01it/s]
epoch 33200  training loss: 0.08979237079620361



 33%|███▎      | 33305/100000 [34:40<1:09:15, 16.05it/s]
epoch 33300  training loss: 0.0895405039191246



 33%|███▎      | 33401/100000 [34:45<1:09:02, 16.08it/s]
epoch 33400  training loss: 0.08977805823087692




 34%|███▎      | 33531/100000 [34:54<1:08:51, 16.09it/s]
epoch 33500  training loss: 0.0896177589893341



 34%|███▎      | 33627/100000 [35:00<1:08:46, 16.08it/s]
epoch 33600  training loss: 0.08973084390163422



 34%|███▎      | 33723/100000 [35:06<1:08:38, 16.09it/s]
epoch 33700  training loss: 0.08919623494148254



 34%|███▍      | 33819/100000 [35:12<1:08:31, 16.10it/s]
epoch 33800  training loss: 0.08959008008241653



 34%|███▍      | 33917/100000 [35:18<1:08:29, 16.08it/s]
epoch 33900  training loss: 0.08950657397508621



 34%|███▍      | 34013/100000 [35:24<1:08:33, 16.04it/s]
epoch 34000  training loss: 0.08954712748527527
epoch 34000  clean testing loss: 0.009488589130342007



 34%|███▍      | 34109/100000 [35:30<1:08:24, 16.05it/s]
epoch 34100  training loss: 0.08952698111534119



 34%|███▍      | 34205/100000 [35:36<1:08:20, 16.04it/s]
epoch 34200  training loss: 0.08946488797664642



 34%|███▍      | 34303/100000 [35:42<1:08:18, 16.03it/s]
epoch 34300  training loss: 0.08928515762090683




 34%|███▍      | 34431/100000 [35:50<1:07:54, 16.09it/s]
epoch 34400  training loss: 0.08939626067876816



 35%|███▍      | 34527/100000 [35:56<1:07:51, 16.08it/s]
epoch 34500  training loss: 0.0892678052186966



 35%|███▍      | 34625/100000 [36:02<1:07:46, 16.08it/s]
epoch 34600  training loss: 0.08920106291770935



 35%|███▍      | 34721/100000 [36:08<1:07:40, 16.08it/s]
epoch 34700  training loss: 0.0890612006187439



 35%|███▍      | 34817/100000 [36:14<1:07:35, 16.07it/s]
epoch 34800  training loss: 0.08932691067457199



 35%|███▍      | 34913/100000 [36:20<1:07:30, 16.07it/s]
epoch 34900  training loss: 0.08895528316497803



 35%|███▌      | 35009/100000 [36:26<1:07:40, 16.01it/s]
epoch 35000  training loss: 0.08966477960348129
epoch 35000  clean testing loss: 0.009617763571441174



 35%|███▌      | 35107/100000 [36:32<1:07:21, 16.06it/s]
epoch 35100  training loss: 0.0893794447183609



 35%|███▌      | 35203/100000 [36:38<1:07:23, 16.02it/s]
epoch 35200  training loss: 0.08911298960447311




 35%|███▌      | 35331/100000 [36:46<1:07:02, 16.07it/s]
epoch 35300  training loss: 0.08959963172674179



 35%|███▌      | 35419/100000 [36:51<1:06:56, 16.08it/s]
epoch 35400  training loss: 0.08919879794120789



 36%|███▌      | 35517/100000 [36:57<1:06:57, 16.05it/s]
epoch 35500  training loss: 0.08931851387023926



 36%|███▌      | 35611/100000 [37:03<1:11:05, 15.10it/s]
epoch 35600  training loss: 0.08942487835884094



 36%|███▌      | 35709/100000 [37:09<1:06:44, 16.06it/s]
epoch 35700  training loss: 0.08936094492673874



 36%|███▌      | 35805/100000 [37:15<1:06:44, 16.03it/s]
epoch 35800  training loss: 0.0893276259303093



 36%|███▌      | 35901/100000 [37:21<1:06:30, 16.06it/s]
epoch 35900  training loss: 0.08898161351680756



 36%|███▌      | 35999/100000 [37:27<1:06:32, 16.03it/s]
epoch 36000  training loss: 0.08901999890804291
epoch 36000  clean testing loss: 0.009373323991894722



 36%|███▌      | 36093/100000 [37:33<1:10:27, 15.12it/s]
epoch 36100  training loss: 0.0891004428267479




 36%|███▌      | 36223/100000 [37:41<1:06:08, 16.07it/s]
epoch 36200  training loss: 0.08942639827728271



 36%|███▋      | 36319/100000 [37:47<1:06:04, 16.06it/s]
epoch 36300  training loss: 0.089204341173172



 36%|███▋      | 36415/100000 [37:53<1:05:56, 16.07it/s]
epoch 36400  training loss: 0.08927050232887268



 37%|███▋      | 36513/100000 [37:59<1:05:54, 16.06it/s]
epoch 36500  training loss: 0.08896937221288681



 37%|███▋      | 36609/100000 [38:05<1:05:51, 16.04it/s]
epoch 36600  training loss: 0.089146688580513



 37%|███▋      | 36705/100000 [38:11<1:05:46, 16.04it/s]
epoch 36700  training loss: 0.08939734101295471



 37%|███▋      | 36801/100000 [38:17<1:05:30, 16.08it/s]
epoch 36800  training loss: 0.0891820639371872



 37%|███▋      | 36899/100000 [38:24<1:05:19, 16.10it/s]
epoch 36900  training loss: 0.08902440220117569



 37%|███▋      | 36995/100000 [38:29<1:05:17, 16.08it/s]
epoch 37000  training loss: 0.08868489414453506
epoch 37000  clean testing loss: 0.009628767147660255




 37%|███▋      | 37123/100000 [38:38<1:05:10, 16.08it/s]
epoch 37100  training loss: 0.08892137557268143



 37%|███▋      | 37219/100000 [38:43<1:05:02, 16.09it/s]
epoch 37200  training loss: 0.08884849399328232



 37%|███▋      | 37317/100000 [38:50<1:05:01, 16.07it/s]
epoch 37300  training loss: 0.0887511596083641



 37%|███▋      | 37413/100000 [38:56<1:04:51, 16.08it/s]
epoch 37400  training loss: 0.08900215476751328



 38%|███▊      | 37509/100000 [39:02<1:04:47, 16.07it/s]
epoch 37500  training loss: 0.0889650210738182



 38%|███▊      | 37605/100000 [39:08<1:04:48, 16.05it/s]
epoch 37600  training loss: 0.0890408456325531



 38%|███▊      | 37703/100000 [39:14<1:04:39, 16.06it/s]
epoch 37700  training loss: 0.0886596292257309




 38%|███▊      | 37831/100000 [39:22<1:04:22, 16.10it/s]
epoch 37800  training loss: 0.08883879333734512



 38%|███▊      | 37929/100000 [39:28<1:04:32, 16.03it/s]
epoch 37900  training loss: 0.08870720118284225



 38%|███▊      | 38023/100000 [39:34<1:04:12, 16.09it/s]
epoch 38000  training loss: 0.08845999836921692
epoch 38000  clean testing loss: 0.009853332303464413



 38%|███▊      | 38121/100000 [39:40<1:04:07, 16.08it/s]
epoch 38100  training loss: 0.08891851454973221



 38%|███▊      | 38217/100000 [39:46<1:04:00, 16.09it/s]
epoch 38200  training loss: 0.0888117179274559



 38%|███▊      | 38313/100000 [39:52<1:03:55, 16.08it/s]
epoch 38300  training loss: 0.08823108673095703



 38%|███▊      | 38411/100000 [39:58<1:03:54, 16.06it/s]
epoch 38400  training loss: 0.08853466063737869



 39%|███▊      | 38507/100000 [40:04<1:03:49, 16.06it/s]
epoch 38500  training loss: 0.0883808508515358



 39%|███▊      | 38603/100000 [40:10<1:03:49, 16.03it/s]
epoch 38600  training loss: 0.08877021819353104




 39%|███▊      | 38731/100000 [40:18<1:03:27, 16.09it/s]
epoch 38700  training loss: 0.08867257088422775



 39%|███▉      | 38829/100000 [40:24<1:03:22, 16.09it/s]
epoch 38800  training loss: 0.0883319228887558



 39%|███▉      | 38925/100000 [40:30<1:03:20, 16.07it/s]
epoch 38900  training loss: 0.08834785968065262



 39%|███▉      | 39021/100000 [40:36<1:03:16, 16.06it/s]
epoch 39000  training loss: 0.08860006183385849
epoch 39000  clean testing loss: 0.010042659938335419



 39%|███▉      | 39117/100000 [40:42<1:03:05, 16.08it/s]
epoch 39100  training loss: 0.08828659355640411



 39%|███▉      | 39215/100000 [40:48<1:03:02, 16.07it/s]
epoch 39200  training loss: 0.08805310726165771



 39%|███▉      | 39311/100000 [40:54<1:02:58, 16.06it/s]
epoch 39300  training loss: 0.08828290551900864



 39%|███▉      | 39407/100000 [41:00<1:02:54, 16.05it/s]
epoch 39400  training loss: 0.08850374817848206



 40%|███▉      | 39503/100000 [41:06<1:03:01, 16.00it/s]
epoch 39500  training loss: 0.08830641210079193




 40%|███▉      | 39633/100000 [41:14<1:02:34, 16.08it/s]
epoch 39600  training loss: 0.08799006789922714



 40%|███▉      | 39729/100000 [41:20<1:02:26, 16.09it/s]
epoch 39700  training loss: 0.08809540420770645



 40%|███▉      | 39825/100000 [41:26<1:02:21, 16.08it/s]
epoch 39800  training loss: 0.08832941949367523



 40%|███▉      | 39921/100000 [41:32<1:02:17, 16.07it/s]
epoch 39900  training loss: 0.08833179622888565



 40%|████      | 40017/100000 [41:38<1:02:13, 16.07it/s]
epoch 40000  training loss: 0.08841833472251892
epoch 40000  clean testing loss: 0.010170599445700645



 40%|████      | 40115/100000 [41:44<1:02:07, 16.07it/s]
epoch 40100  training loss: 0.08845449239015579



 40%|████      | 40211/100000 [41:50<1:02:02, 16.06it/s]
epoch 40200  training loss: 0.08828537166118622



 40%|████      | 40307/100000 [41:56<1:01:57, 16.06it/s]
epoch 40300  training loss: 0.08826710283756256



 40%|████      | 40403/100000 [42:02<1:01:59, 16.02it/s]
epoch 40400  training loss: 0.08843199908733368




 41%|████      | 40531/100000 [42:10<1:01:39, 16.08it/s]
epoch 40500  training loss: 0.08790908753871918



 41%|████      | 40629/100000 [42:16<1:01:31, 16.08it/s]
epoch 40600  training loss: 0.08794423937797546



 41%|████      | 40725/100000 [42:22<1:01:21, 16.10it/s]
epoch 40700  training loss: 0.08790584653615952



 41%|████      | 40821/100000 [42:28<1:01:22, 16.07it/s]
epoch 40800  training loss: 0.08831160515546799



 41%|████      | 40919/100000 [42:34<1:01:11, 16.09it/s]
epoch 40900  training loss: 0.0880764052271843



 41%|████      | 41015/100000 [42:40<1:01:10, 16.07it/s]
epoch 41000  training loss: 0.08811146020889282
epoch 41000  clean testing loss: 0.010418534278869629



 41%|████      | 41111/100000 [42:46<1:01:06, 16.06it/s]
epoch 41100  training loss: 0.08777934312820435



 41%|████      | 41207/100000 [42:52<1:00:59, 16.07it/s]
epoch 41200  training loss: 0.08779441565275192



 41%|████▏     | 41305/100000 [42:58<1:01:00, 16.03it/s]
epoch 41300  training loss: 0.0878593698143959



 41%|████▏     | 41401/100000 [43:04<1:00:46, 16.07it/s]
epoch 41400  training loss: 0.08761115372180939




 42%|████▏     | 41529/100000 [43:12<1:00:39, 16.07it/s]
epoch 41500  training loss: 0.08763138204813004



 42%|████▏     | 41625/100000 [43:18<1:00:29, 16.08it/s]
epoch 41600  training loss: 0.08740168064832687



 42%|████▏     | 41723/100000 [43:24<1:00:27, 16.06it/s]
epoch 41700  training loss: 0.08781775832176208



 42%|████▏     | 41819/100000 [43:30<1:00:17, 16.08it/s]
epoch 41800  training loss: 0.08788735419511795



 42%|████▏     | 41915/100000 [43:36<1:00:51, 15.91it/s]
epoch 41900  training loss: 0.0878399908542633



 42%|████▏     | 42011/100000 [43:42<1:00:15, 16.04it/s]
epoch 42000  training loss: 0.08741524070501328
epoch 42000  clean testing loss: 0.010525683872401714



 42%|████▏     | 42107/100000 [43:48<1:00:03, 16.06it/s]
epoch 42100  training loss: 0.08784385770559311



 42%|████▏     | 42205/100000 [43:54<59:59, 16.06it/s]
epoch 42200  training loss: 0.08812002092599869



 42%|████▏     | 42301/100000 [44:00<59:47, 16.08it/s]
epoch 42300  training loss: 0.08801191300153732




 42%|████▏     | 42429/100000 [44:08<59:38, 16.09it/s]
epoch 42400  training loss: 0.08778142184019089



 43%|████▎     | 42527/100000 [44:14<59:32, 16.09it/s]
epoch 42500  training loss: 0.08749190717935562



 43%|████▎     | 42615/100000 [44:20<59:28, 16.08it/s]
epoch 42600  training loss: 0.08756325393915176



 43%|████▎     | 42711/100000 [44:26<59:22, 16.08it/s]
epoch 42700  training loss: 0.08782364428043365



 43%|████▎     | 42809/100000 [44:32<59:20, 16.06it/s]
epoch 42800  training loss: 0.08752443641424179



 43%|████▎     | 42903/100000 [44:38<59:30, 15.99it/s]
epoch 42900  training loss: 0.08727771788835526



 43%|████▎     | 43001/100000 [44:44<1:00:06, 15.81it/s]
epoch 43000  training loss: 0.0876484215259552
epoch 43000  clean testing loss: 0.010490898042917252



 43%|████▎     | 43097/100000 [44:50<58:53, 16.10it/s]
epoch 43100  training loss: 0.0879141092300415



 43%|████▎     | 43193/100000 [44:56<58:55, 16.07it/s]
epoch 43200  training loss: 0.08761245757341385




 43%|████▎     | 43323/100000 [45:04<58:41, 16.09it/s]
epoch 43300  training loss: 0.08763941377401352



 43%|████▎     | 43419/100000 [45:10<58:35, 16.10it/s]
epoch 43400  training loss: 0.08775511384010315



 44%|████▎     | 43515/100000 [45:16<58:39, 16.05it/s]
epoch 43500  training loss: 0.08772061765193939



 44%|████▎     | 43613/100000 [45:22<58:28, 16.07it/s]
epoch 43600  training loss: 0.08765000849962234



 44%|████▎     | 43709/100000 [45:28<58:38, 16.00it/s]
epoch 43700  training loss: 0.08788857609033585



 44%|████▍     | 43805/100000 [45:34<58:22, 16.05it/s]
epoch 43800  training loss: 0.08821781724691391



 44%|████▍     | 43901/100000 [45:40<58:10, 16.07it/s]
epoch 43900  training loss: 0.08813472092151642



 44%|████▍     | 43997/100000 [45:46<58:01, 16.08it/s]
epoch 44000  training loss: 0.0878986045718193
epoch 44000  clean testing loss: 0.010586562566459179



 44%|████▍     | 44095/100000 [45:52<57:55, 16.09it/s]
epoch 44100  training loss: 0.08759956806898117




 44%|████▍     | 44223/100000 [46:00<58:33, 15.88it/s]
epoch 44200  training loss: 0.08801060914993286



 44%|████▍     | 44319/100000 [46:06<59:39, 15.56it/s]
epoch 44300  training loss: 0.08816258609294891



 44%|████▍     | 44417/100000 [46:12<57:34, 16.09it/s]
epoch 44400  training loss: 0.08810335397720337



 45%|████▍     | 44513/100000 [46:18<57:31, 16.08it/s]
epoch 44500  training loss: 0.08848847448825836



 45%|████▍     | 44609/100000 [46:24<57:23, 16.08it/s]
epoch 44600  training loss: 0.08805905282497406



 45%|████▍     | 44707/100000 [46:30<57:24, 16.05it/s]
epoch 44700  training loss: 0.08820275962352753



 45%|████▍     | 44803/100000 [46:36<57:27, 16.01it/s]
epoch 44800  training loss: 0.08822327852249146




 45%|████▍     | 44931/100000 [46:44<57:01, 16.09it/s]
epoch 44900  training loss: 0.08802573382854462



 45%|████▌     | 45029/100000 [46:50<56:55, 16.10it/s]
epoch 45000  training loss: 0.08784519881010056
epoch 45000  clean testing loss: 0.010525839403271675



 45%|████▌     | 45125/100000 [46:56<56:50, 16.09it/s]
epoch 45100  training loss: 0.08806273341178894



 45%|████▌     | 45221/100000 [47:02<56:45, 16.08it/s]
epoch 45200  training loss: 0.08804938942193985



 45%|████▌     | 45317/100000 [47:08<56:43, 16.07it/s]
epoch 45300  training loss: 0.08762571215629578



 45%|████▌     | 45415/100000 [47:14<56:34, 16.08it/s]
epoch 45400  training loss: 0.0878741592168808



 46%|████▌     | 45511/100000 [47:20<56:33, 16.06it/s]
epoch 45500  training loss: 0.08771391212940216



 46%|████▌     | 45607/100000 [47:26<56:27, 16.06it/s]
epoch 45600  training loss: 0.08796858042478561



 46%|████▌     | 45705/100000 [47:32<56:25, 16.04it/s]
epoch 45700  training loss: 0.08747202157974243




 46%|████▌     | 45833/100000 [47:40<56:06, 16.09it/s]
epoch 45800  training loss: 0.08737250417470932



 46%|████▌     | 45929/100000 [47:46<56:02, 16.08it/s]
epoch 45900  training loss: 0.08763186633586884



 46%|████▌     | 46025/100000 [47:52<56:02, 16.05it/s]
epoch 46000  training loss: 0.08752992749214172
epoch 46000  clean testing loss: 0.010817092843353748



 46%|████▌     | 46121/100000 [47:58<56:06, 16.01it/s]
epoch 46100  training loss: 0.08790204674005508



 46%|████▌     | 46219/100000 [48:04<55:44, 16.08it/s]
epoch 46200  training loss: 0.08752601593732834



 46%|████▋     | 46315/100000 [48:10<55:33, 16.11it/s]
epoch 46300  training loss: 0.08735176175832748



 46%|████▋     | 46411/100000 [48:16<55:39, 16.05it/s]
epoch 46400  training loss: 0.08744611591100693



 47%|████▋     | 46507/100000 [48:22<55:45, 15.99it/s]
epoch 46500  training loss: 0.08749295771121979



 47%|████▋     | 46605/100000 [48:28<55:29, 16.04it/s]
epoch 46600  training loss: 0.08755369484424591




 47%|████▋     | 46733/100000 [48:36<55:10, 16.09it/s]
epoch 46700  training loss: 0.08733712136745453



 47%|████▋     | 46829/100000 [48:42<55:16, 16.03it/s]
epoch 46800  training loss: 0.08761414885520935



 47%|████▋     | 46927/100000 [48:48<55:00, 16.08it/s]
epoch 46900  training loss: 0.08735296875238419



 47%|████▋     | 47023/100000 [48:54<55:05, 16.03it/s]
epoch 47000  training loss: 0.08744072914123535
epoch 47000  clean testing loss: 0.0108961071819067



 47%|████▋     | 47119/100000 [49:00<54:49, 16.08it/s]
epoch 47100  training loss: 0.08732383698225021



 47%|████▋     | 47215/100000 [49:06<54:43, 16.08it/s]
epoch 47200  training loss: 0.08704689890146255



 47%|████▋     | 47311/100000 [49:12<54:44, 16.04it/s]
epoch 47300  training loss: 0.08760455250740051



 47%|████▋     | 47409/100000 [49:19<54:34, 16.06it/s]
epoch 47400  training loss: 0.08732293546199799



 48%|████▊     | 47505/100000 [49:24<54:37, 16.02it/s]
epoch 47500  training loss: 0.08728976547718048




 48%|████▊     | 47633/100000 [49:32<54:17, 16.07it/s]
epoch 47600  training loss: 0.08741986751556396



 48%|████▊     | 47729/100000 [49:38<54:27, 16.00it/s]
epoch 47700  training loss: 0.0872502401471138



 48%|████▊     | 47827/100000 [49:45<54:02, 16.09it/s]
epoch 47800  training loss: 0.08743833005428314



 48%|████▊     | 47923/100000 [49:51<53:58, 16.08it/s]
epoch 47900  training loss: 0.08695272356271744



 48%|████▊     | 48019/100000 [49:57<53:56, 16.06it/s]
epoch 48000  training loss: 0.08725252747535706
epoch 48000  clean testing loss: 0.011166185140609741



 48%|████▊     | 48115/100000 [50:03<53:47, 16.08it/s]
epoch 48100  training loss: 0.08697836846113205



 48%|████▊     | 48211/100000 [50:09<54:12, 15.92it/s]
epoch 48200  training loss: 0.08684249967336655



 48%|████▊     | 48309/100000 [50:15<53:39, 16.05it/s]
epoch 48300  training loss: 0.08736085146665573



 48%|████▊     | 48405/100000 [50:21<53:45, 16.00it/s]
epoch 48400  training loss: 0.08734731376171112




 49%|████▊     | 48533/100000 [50:29<53:24, 16.06it/s]
epoch 48500  training loss: 0.08723889291286469



 49%|████▊     | 48631/100000 [50:35<53:21, 16.05it/s]
epoch 48600  training loss: 0.08723825216293335



 49%|████▊     | 48725/100000 [50:41<53:18, 16.03it/s]
epoch 48700  training loss: 0.08706562221050262



 49%|████▉     | 48823/100000 [50:47<53:05, 16.07it/s]
epoch 48800  training loss: 0.08707448840141296



 49%|████▉     | 48911/100000 [50:52<53:02, 16.05it/s]
epoch 48900  training loss: 0.08718713372945786



 49%|████▉     | 49007/100000 [50:58<53:11, 15.98it/s]
epoch 49000  training loss: 0.08734691888093948
epoch 49000  clean testing loss: 0.011306281201541424



 49%|████▉     | 49105/100000 [51:04<52:55, 16.02it/s]
epoch 49100  training loss: 0.08706826716661453



 49%|████▉     | 49199/100000 [51:10<52:42, 16.06it/s]
epoch 49200  training loss: 0.08718392997980118




 49%|████▉     | 49329/100000 [51:18<52:35, 16.06it/s]
epoch 49300  training loss: 0.08698979020118713



 49%|████▉     | 49425/100000 [51:24<52:29, 16.06it/s]
epoch 49400  training loss: 0.08698933571577072



 50%|████▉     | 49521/100000 [51:30<52:22, 16.06it/s]
epoch 49500  training loss: 0.08691616356372833



 50%|████▉     | 49619/100000 [51:36<52:16, 16.07it/s]
epoch 49600  training loss: 0.08724681288003922



 50%|████▉     | 49713/100000 [51:42<52:18, 16.02it/s]
epoch 49700  training loss: 0.0869959220290184



 50%|████▉     | 49811/100000 [51:48<52:09, 16.04it/s]
epoch 49800  training loss: 0.0869467481970787



 50%|████▉     | 49907/100000 [51:54<52:14, 15.98it/s]
epoch 49900  training loss: 0.08679802715778351



 50%|█████     | 50003/100000 [52:00<52:35, 15.85it/s]
epoch 50000  training loss: 0.08701514452695847
epoch 50000  clean testing loss: 0.011315840296447277



 50%|█████     | 50099/100000 [52:06<51:47, 16.06it/s]
epoch 50100  training loss: 0.08724045008420944




 50%|█████     | 50227/100000 [52:14<51:35, 16.08it/s]
epoch 50200  training loss: 0.0871446505188942



 50%|█████     | 50325/100000 [52:20<51:32, 16.06it/s]
epoch 50300  training loss: 0.08697213232517242



 50%|█████     | 50421/100000 [52:26<51:26, 16.06it/s]
epoch 50400  training loss: 0.08699890226125717



 51%|█████     | 50517/100000 [52:32<51:18, 16.07it/s]
epoch 50500  training loss: 0.08680817484855652



 51%|█████     | 50615/100000 [52:38<51:14, 16.06it/s]
epoch 50600  training loss: 0.08664534986019135



 51%|█████     | 50709/100000 [52:44<51:09, 16.06it/s]
epoch 50700  training loss: 0.08719053864479065



 51%|█████     | 50807/100000 [52:50<51:04, 16.05it/s]
epoch 50800  training loss: 0.08723166584968567



 51%|█████     | 50903/100000 [52:56<51:11, 15.99it/s]
epoch 50900  training loss: 0.08671427518129349



 51%|█████     | 50999/100000 [53:02<50:46, 16.09it/s]
epoch 51000  training loss: 0.08674486726522446
epoch 51000  clean testing loss: 0.01137042697519064




 51%|█████     | 51127/100000 [53:10<50:43, 16.06it/s]
epoch 51100  training loss: 0.08682619780302048



 51%|█████     | 51225/100000 [53:17<50:36, 16.06it/s]
epoch 51200  training loss: 0.08685354143381119



 51%|█████▏    | 51321/100000 [53:23<50:28, 16.07it/s]
epoch 51300  training loss: 0.08710985630750656



 51%|█████▏    | 51417/100000 [53:28<50:21, 16.08it/s]
epoch 51400  training loss: 0.0868743360042572



 52%|█████▏    | 51513/100000 [53:34<50:18, 16.06it/s]
epoch 51500  training loss: 0.0870039239525795



 52%|█████▏    | 51609/100000 [53:40<50:19, 16.03it/s]
epoch 51600  training loss: 0.08675766736268997



 52%|█████▏    | 51707/100000 [53:47<50:10, 16.04it/s]
epoch 51700  training loss: 0.08662006258964539



 52%|█████▏    | 51803/100000 [53:53<50:10, 16.01it/s]
epoch 51800  training loss: 0.08657217770814896




 52%|█████▏    | 51931/100000 [54:01<49:49, 16.08it/s]
epoch 51900  training loss: 0.08704718202352524



 52%|█████▏    | 52027/100000 [54:07<49:45, 16.07it/s]
epoch 52000  training loss: 0.086850106716156
epoch 52000  clean testing loss: 0.011456480249762535



 52%|█████▏    | 52123/100000 [54:13<49:39, 16.07it/s]
epoch 52100  training loss: 0.08695564419031143



 52%|█████▏    | 52221/100000 [54:19<49:33, 16.07it/s]
epoch 52200  training loss: 0.0868755504488945



 52%|█████▏    | 52317/100000 [54:25<49:40, 16.00it/s]
epoch 52300  training loss: 0.08697425574064255



 52%|█████▏    | 52413/100000 [54:31<49:24, 16.05it/s]
epoch 52400  training loss: 0.08688069880008698



 53%|█████▎    | 52511/100000 [54:37<49:25, 16.01it/s]
epoch 52500  training loss: 0.08675564080476761



 53%|█████▎    | 52607/100000 [54:43<49:17, 16.02it/s]
epoch 52600  training loss: 0.08686098456382751



 53%|█████▎    | 52703/100000 [54:49<49:13, 16.01it/s]
epoch 52700  training loss: 0.08676774799823761




 53%|█████▎    | 52831/100000 [54:57<48:57, 16.06it/s]
epoch 52800  training loss: 0.08704538643360138



 53%|█████▎    | 52927/100000 [55:03<48:49, 16.07it/s]
epoch 52900  training loss: 0.08697038143873215



 53%|█████▎    | 53025/100000 [55:09<48:44, 16.06it/s]
epoch 53000  training loss: 0.08691663295030594
epoch 53000  clean testing loss: 0.01140892319381237



 53%|█████▎    | 53121/100000 [55:15<48:39, 16.06it/s]
epoch 53100  training loss: 0.08697439730167389



 53%|█████▎    | 53217/100000 [55:21<48:31, 16.07it/s]
epoch 53200  training loss: 0.08664069324731827



 53%|█████▎    | 53313/100000 [55:27<48:31, 16.03it/s]
epoch 53300  training loss: 0.08704879134893417



 53%|█████▎    | 53409/100000 [55:33<48:22, 16.05it/s]
epoch 53400  training loss: 0.08655747026205063



 54%|█████▎    | 53507/100000 [55:39<48:23, 16.02it/s]
epoch 53500  training loss: 0.08730633556842804



 54%|█████▎    | 53601/100000 [55:45<48:09, 16.06it/s]
epoch 53600  training loss: 0.08713851869106293




 54%|█████▎    | 53731/100000 [55:53<48:00, 16.06it/s]
epoch 53700  training loss: 0.08747970312833786



 54%|█████▍    | 53827/100000 [55:59<47:59, 16.03it/s]
epoch 53800  training loss: 0.08745807409286499



 54%|█████▍    | 53923/100000 [56:05<47:46, 16.07it/s]
epoch 53900  training loss: 0.08722132444381714



 54%|█████▍    | 54019/100000 [56:11<47:59, 15.97it/s]
epoch 54000  training loss: 0.08700849115848541
epoch 54000  clean testing loss: 0.011464918032288551



 54%|█████▍    | 54115/100000 [56:17<47:38, 16.05it/s]
epoch 54100  training loss: 0.08731843531131744



 54%|█████▍    | 54213/100000 [56:23<47:31, 16.06it/s]
epoch 54200  training loss: 0.08716637641191483



 54%|█████▍    | 54309/100000 [56:29<47:28, 16.04it/s]
epoch 54300  training loss: 0.08728327602148056



 54%|█████▍    | 54405/100000 [56:35<47:25, 16.02it/s]
epoch 54400  training loss: 0.08701620995998383



 55%|█████▍    | 54501/100000 [56:41<47:36, 15.93it/s]
epoch 54500  training loss: 0.0872223973274231




 55%|█████▍    | 54629/100000 [56:49<47:08, 16.04it/s]
epoch 54600  training loss: 0.08721589297056198



 55%|█████▍    | 54727/100000 [56:55<46:55, 16.08it/s]
epoch 54700  training loss: 0.08724361658096313



 55%|█████▍    | 54823/100000 [57:01<46:52, 16.06it/s]
epoch 54800  training loss: 0.08706542104482651



 55%|█████▍    | 54919/100000 [57:07<46:43, 16.08it/s]
epoch 54900  training loss: 0.08702921122312546



 55%|█████▌    | 55015/100000 [57:13<46:42, 16.05it/s]
epoch 55000  training loss: 0.08720698207616806
epoch 55000  clean testing loss: 0.01153381448239088



 55%|█████▌    | 55111/100000 [57:19<46:35, 16.06it/s]
epoch 55100  training loss: 0.08715639263391495



 55%|█████▌    | 55209/100000 [57:25<46:27, 16.07it/s]
epoch 55200  training loss: 0.08726217597723007



 55%|█████▌    | 55305/100000 [57:31<46:26, 16.04it/s]
epoch 55300  training loss: 0.0870392844080925



 55%|█████▌    | 55401/100000 [57:37<46:16, 16.07it/s]
epoch 55400  training loss: 0.08668038994073868




 56%|█████▌    | 55529/100000 [57:45<46:03, 16.09it/s]
epoch 55500  training loss: 0.08685435354709625



 56%|█████▌    | 55627/100000 [57:51<46:01, 16.07it/s]
epoch 55600  training loss: 0.08711375296115875



 56%|█████▌    | 55723/100000 [57:57<45:54, 16.07it/s]
epoch 55700  training loss: 0.08704789727926254



 56%|█████▌    | 55819/100000 [58:03<45:50, 16.06it/s]
epoch 55800  training loss: 0.08709000051021576



 56%|█████▌    | 55909/100000 [58:09<45:48, 16.04it/s]
epoch 55900  training loss: 0.08679692447185516



 56%|█████▌    | 56005/100000 [58:15<46:00, 15.94it/s]
epoch 56000  training loss: 0.08708235621452332
epoch 56000  clean testing loss: 0.011493328027427197



 56%|█████▌    | 56101/100000 [58:21<45:34, 16.05it/s]
epoch 56100  training loss: 0.08676183968782425



 56%|█████▌    | 56197/100000 [58:27<45:30, 16.04it/s]
epoch 56200  training loss: 0.08695690333843231



 56%|█████▋    | 56293/100000 [58:33<45:20, 16.07it/s]
epoch 56300  training loss: 0.08656510710716248




 56%|█████▋    | 56421/100000 [58:41<49:36, 14.64it/s]
epoch 56400  training loss: 0.08704953640699387



 57%|█████▋    | 56519/100000 [58:47<45:06, 16.07it/s]
epoch 56500  training loss: 0.08663792163133621



 57%|█████▋    | 56615/100000 [58:53<45:02, 16.05it/s]
epoch 56600  training loss: 0.0866151675581932



 57%|█████▋    | 56711/100000 [58:59<45:03, 16.01it/s]
epoch 56700  training loss: 0.08683368563652039



 57%|█████▋    | 56807/100000 [59:05<44:59, 16.00it/s]
epoch 56800  training loss: 0.08684650808572769



 57%|█████▋    | 56903/100000 [59:11<49:50, 14.41it/s]
epoch 56900  training loss: 0.08714568614959717



 57%|█████▋    | 57001/100000 [59:17<45:23, 15.79it/s]
epoch 57000  training loss: 0.08676657825708389
epoch 57000  clean testing loss: 0.011555337347090244



 57%|█████▋    | 57097/100000 [59:23<44:31, 16.06it/s]
epoch 57100  training loss: 0.08701557666063309



 57%|█████▋    | 57193/100000 [59:29<44:23, 16.07it/s]
epoch 57200  training loss: 0.08672218024730682




 57%|█████▋    | 57323/100000 [59:37<44:14, 16.07it/s]
epoch 57300  training loss: 0.08671125769615173



 57%|█████▋    | 57419/100000 [59:43<44:19, 16.01it/s]
epoch 57400  training loss: 0.08710172772407532



 58%|█████▊    | 57515/100000 [59:49<44:03, 16.07it/s]
epoch 57500  training loss: 0.08670103549957275



 58%|█████▊    | 57611/100000 [59:55<43:58, 16.07it/s]
epoch 57600  training loss: 0.08652737736701965



 58%|█████▊    | 57707/100000 [1:00:01<44:00, 16.02it/s]
epoch 57700  training loss: 0.08667629212141037



 58%|█████▊    | 57805/100000 [1:00:07<43:50, 16.04it/s]
epoch 57800  training loss: 0.0871003195643425



 58%|█████▊    | 57901/100000 [1:00:13<43:40, 16.06it/s]
epoch 57900  training loss: 0.08692926913499832




 58%|█████▊    | 58029/100000 [1:00:21<43:30, 16.08it/s]
epoch 58000  training loss: 0.08665156364440918
epoch 58000  clean testing loss: 0.011704524978995323



 58%|█████▊    | 58125/100000 [1:00:27<43:23, 16.09it/s]
epoch 58100  training loss: 0.08662969619035721



 58%|█████▊    | 58223/100000 [1:00:33<43:22, 16.05it/s]
epoch 58200  training loss: 0.08672911673784256



 58%|█████▊    | 58319/100000 [1:00:39<43:12, 16.08it/s]
epoch 58300  training loss: 0.08642800152301788



 58%|█████▊    | 58415/100000 [1:00:45<43:05, 16.08it/s]
epoch 58400  training loss: 0.08690474927425385



 59%|█████▊    | 58511/100000 [1:00:51<43:07, 16.04it/s]
epoch 58500  training loss: 0.08659545332193375



 59%|█████▊    | 58609/100000 [1:00:57<42:57, 16.06it/s]
epoch 58600  training loss: 0.08672866225242615



 59%|█████▊    | 58705/100000 [1:01:03<42:57, 16.02it/s]
epoch 58700  training loss: 0.0867069810628891



 59%|█████▉    | 58801/100000 [1:01:09<42:44, 16.06it/s]
epoch 58800  training loss: 0.08673959970474243




 59%|█████▉    | 58929/100000 [1:01:17<42:36, 16.07it/s]
epoch 58900  training loss: 0.08681485801935196



 59%|█████▉    | 59025/100000 [1:01:23<42:29, 16.07it/s]
epoch 59000  training loss: 0.08713649958372116
epoch 59000  clean testing loss: 0.011640342883765697



 59%|█████▉    | 59123/100000 [1:01:29<42:24, 16.06it/s]
epoch 59100  training loss: 0.08666113018989563



 59%|█████▉    | 59219/100000 [1:01:35<42:18, 16.06it/s]
epoch 59200  training loss: 0.08639196306467056



 59%|█████▉    | 59315/100000 [1:01:41<42:17, 16.04it/s]
epoch 59300  training loss: 0.08698040246963501



 59%|█████▉    | 59411/100000 [1:01:47<42:05, 16.07it/s]
epoch 59400  training loss: 0.08661672472953796



 60%|█████▉    | 59507/100000 [1:01:53<42:04, 16.04it/s]
epoch 59500  training loss: 0.08690937608480453



 60%|█████▉    | 59605/100000 [1:01:59<42:02, 16.01it/s]
epoch 59600  training loss: 0.08710969984531403



 60%|█████▉    | 59701/100000 [1:02:05<41:51, 16.04it/s]
epoch 59700  training loss: 0.08668453246355057




 60%|█████▉    | 59829/100000 [1:02:13<41:39, 16.07it/s]
epoch 59800  training loss: 0.0863582193851471



 60%|█████▉    | 59925/100000 [1:02:19<41:33, 16.07it/s]
epoch 59900  training loss: 0.08693401515483856



 60%|██████    | 60023/100000 [1:02:25<41:26, 16.08it/s]
epoch 60000  training loss: 0.08643627911806107
epoch 60000  clean testing loss: 0.011847197078168392



 60%|██████    | 60119/100000 [1:02:31<41:21, 16.07it/s]
epoch 60100  training loss: 0.0863034650683403



 60%|██████    | 60215/100000 [1:02:37<41:14, 16.08it/s]
epoch 60200  training loss: 0.08686896413564682



 60%|██████    | 60311/100000 [1:02:43<41:17, 16.02it/s]
epoch 60300  training loss: 0.0864296704530716



 60%|██████    | 60409/100000 [1:02:49<41:05, 16.06it/s]
epoch 60400  training loss: 0.08678736537694931



 61%|██████    | 60505/100000 [1:02:55<41:05, 16.02it/s]
epoch 60500  training loss: 0.08689413964748383



 61%|██████    | 60601/100000 [1:03:01<40:50, 16.07it/s]
epoch 60600  training loss: 0.0866759717464447




 61%|██████    | 60731/100000 [1:03:09<40:42, 16.08it/s]
epoch 60700  training loss: 0.0865618959069252



 61%|██████    | 60827/100000 [1:03:15<40:36, 16.07it/s]
epoch 60800  training loss: 0.08682464063167572



 61%|██████    | 60923/100000 [1:03:21<40:30, 16.08it/s]
epoch 60900  training loss: 0.08673470467329025



 61%|██████    | 61019/100000 [1:03:27<40:35, 16.01it/s]
epoch 61000  training loss: 0.08613923192024231
epoch 61000  clean testing loss: 0.011951669119298458



 61%|██████    | 61117/100000 [1:03:33<40:17, 16.08it/s]
epoch 61100  training loss: 0.0866156592965126



 61%|██████    | 61213/100000 [1:03:39<40:11, 16.08it/s]
epoch 61200  training loss: 0.08637913316488266



 61%|██████▏   | 61309/100000 [1:03:45<40:07, 16.07it/s]
epoch 61300  training loss: 0.08645018190145493



 61%|██████▏   | 61405/100000 [1:03:51<40:06, 16.04it/s]
epoch 61400  training loss: 0.08656071871519089



 62%|██████▏   | 61503/100000 [1:03:57<40:01, 16.03it/s]
epoch 61500  training loss: 0.08650802075862885




 62%|██████▏   | 61631/100000 [1:04:05<39:46, 16.08it/s]
epoch 61600  training loss: 0.08636855334043503



 62%|██████▏   | 61727/100000 [1:04:11<39:38, 16.09it/s]
epoch 61700  training loss: 0.08633463829755783



 62%|██████▏   | 61823/100000 [1:04:17<39:35, 16.07it/s]
epoch 61800  training loss: 0.08655563741922379



 62%|██████▏   | 61921/100000 [1:04:23<39:28, 16.07it/s]
epoch 61900  training loss: 0.0861859992146492



 62%|██████▏   | 62017/100000 [1:04:29<39:21, 16.08it/s]
epoch 62000  training loss: 0.08629031479358673
epoch 62000  clean testing loss: 0.01197087299078703



 62%|██████▏   | 62113/100000 [1:04:35<39:16, 16.08it/s]
epoch 62100  training loss: 0.08611775189638138



 62%|██████▏   | 62211/100000 [1:04:42<39:11, 16.07it/s]
epoch 62200  training loss: 0.08655211329460144



 62%|██████▏   | 62305/100000 [1:04:47<39:09, 16.04it/s]
epoch 62300  training loss: 0.08638070523738861



 62%|██████▏   | 62403/100000 [1:04:54<39:05, 16.03it/s]
epoch 62400  training loss: 0.08648631721735




 63%|██████▎   | 62531/100000 [1:05:01<38:49, 16.08it/s]
epoch 62500  training loss: 0.08655385673046112



 63%|██████▎   | 62629/100000 [1:05:08<38:42, 16.09it/s]
epoch 62600  training loss: 0.08686316013336182



 63%|██████▎   | 62725/100000 [1:05:14<38:46, 16.02it/s]
epoch 62700  training loss: 0.0869913175702095



 63%|██████▎   | 62813/100000 [1:05:19<38:40, 16.03it/s]
epoch 62800  training loss: 0.08666229248046875



 63%|██████▎   | 62909/100000 [1:05:25<38:29, 16.06it/s]
epoch 62900  training loss: 0.08697357773780823



 63%|██████▎   | 63007/100000 [1:05:31<38:32, 15.99it/s]
epoch 63000  training loss: 0.08709724247455597
epoch 63000  clean testing loss: 0.011904357001185417



 63%|██████▎   | 63103/100000 [1:05:37<38:21, 16.03it/s]
epoch 63100  training loss: 0.08672545850276947



 63%|██████▎   | 63199/100000 [1:05:43<39:28, 15.54it/s]
epoch 63200  training loss: 0.0864425003528595



 63%|██████▎   | 63295/100000 [1:05:49<38:03, 16.07it/s]
epoch 63300  training loss: 0.08637207001447678



 63%|██████▎   | 63393/100000 [1:05:55<37:57, 16.07it/s]
epoch 63400  training loss: 0.08671485632658005




 64%|██████▎   | 63521/100000 [1:06:03<37:49, 16.07it/s]
epoch 63500  training loss: 0.08676984906196594



 64%|██████▎   | 63617/100000 [1:06:09<37:46, 16.05it/s]
epoch 63600  training loss: 0.0865015983581543



 64%|██████▎   | 63713/100000 [1:06:15<37:40, 16.05it/s]
epoch 63700  training loss: 0.08642441034317017



 64%|██████▍   | 63811/100000 [1:06:21<37:33, 16.06it/s]
epoch 63800  training loss: 0.08698353171348572



 64%|██████▍   | 63905/100000 [1:06:27<37:30, 16.04it/s]
epoch 63900  training loss: 0.08694880455732346



 64%|██████▍   | 64003/100000 [1:06:33<37:46, 15.88it/s]
epoch 64000  training loss: 0.08675962686538696
epoch 64000  clean testing loss: 0.011848045513033867



 64%|██████▍   | 64099/100000 [1:06:39<37:15, 16.06it/s]
epoch 64100  training loss: 0.08638212829828262



 64%|██████▍   | 64195/100000 [1:06:45<37:07, 16.08it/s]
epoch 64200  training loss: 0.08652959018945694



 64%|██████▍   | 64293/100000 [1:06:51<37:02, 16.06it/s]
epoch 64300  training loss: 0.08695945888757706




 64%|██████▍   | 64421/100000 [1:06:59<36:52, 16.08it/s]
epoch 64400  training loss: 0.08682453632354736



 65%|██████▍   | 64517/100000 [1:07:05<36:54, 16.02it/s]
epoch 64500  training loss: 0.08655031770467758



 65%|██████▍   | 64615/100000 [1:07:11<36:40, 16.08it/s]
epoch 64600  training loss: 0.08664720505475998



 65%|██████▍   | 64711/100000 [1:07:17<36:36, 16.06it/s]
epoch 64700  training loss: 0.08663470298051834



 65%|██████▍   | 64807/100000 [1:07:23<36:38, 16.01it/s]
epoch 64800  training loss: 0.08676157891750336



 65%|██████▍   | 64903/100000 [1:07:29<36:34, 15.99it/s]
epoch 64900  training loss: 0.08649566769599915



 65%|██████▍   | 64999/100000 [1:07:35<36:16, 16.08it/s]
epoch 65000  training loss: 0.08679582178592682
epoch 65000  clean testing loss: 0.011768536642193794



 65%|██████▌   | 65097/100000 [1:07:41<36:11, 16.07it/s]
epoch 65100  training loss: 0.0866326242685318




 65%|██████▌   | 65225/100000 [1:07:49<36:07, 16.04it/s]
epoch 65200  training loss: 0.08656158298254013



 65%|██████▌   | 65321/100000 [1:07:55<35:56, 16.08it/s]
epoch 65300  training loss: 0.08634922653436661



 65%|██████▌   | 65405/100000 [1:08:05<36:02, 16.00it/s]
epoch 65400  training loss: 0.08656922727823257



 66%|██████▌   | 65503/100000 [1:08:11<35:52, 16.03it/s]
epoch 65500  training loss: 0.08628449589014053




 66%|██████▌   | 65631/100000 [1:08:19<35:36, 16.09it/s]
epoch 65600  training loss: 0.08650695532560349



 66%|██████▌   | 65727/100000 [1:08:25<35:31, 16.08it/s]
epoch 65700  training loss: 0.08674219995737076



 66%|██████▌   | 65823/100000 [1:08:31<35:25, 16.08it/s]
epoch 65800  training loss: 0.08691283315420151



 66%|██████▌   | 65921/100000 [1:08:38<35:22, 16.06it/s]
epoch 65900  training loss: 0.0864967480301857



 66%|██████▌   | 66017/100000 [1:08:44<36:53, 15.35it/s]
epoch 66000  training loss: 0.08646035939455032
epoch 66000  clean testing loss: 0.011750642210245132



 66%|██████▌   | 66113/100000 [1:08:50<35:08, 16.07it/s]
epoch 66100  training loss: 0.08679347485303879



 66%|██████▌   | 66209/100000 [1:08:56<35:06, 16.04it/s]
epoch 66200  training loss: 0.08670994639396667



 66%|██████▋   | 66305/100000 [1:09:01<35:00, 16.04it/s]
epoch 66300  training loss: 0.08677123486995697



 66%|██████▋   | 66403/100000 [1:09:08<34:57, 16.02it/s]
epoch 66400  training loss: 0.08648098260164261




 67%|██████▋   | 66531/100000 [1:09:16<34:43, 16.07it/s]
epoch 66500  training loss: 0.08652054518461227



 67%|██████▋   | 66627/100000 [1:09:22<34:36, 16.07it/s]
epoch 66600  training loss: 0.0864216536283493



 67%|██████▋   | 66723/100000 [1:09:28<34:31, 16.07it/s]
epoch 66700  training loss: 0.08674846589565277



 67%|██████▋   | 66819/100000 [1:09:34<34:25, 16.07it/s]
epoch 66800  training loss: 0.08680733293294907



 67%|██████▋   | 66917/100000 [1:09:40<34:18, 16.07it/s]
epoch 66900  training loss: 0.08685595542192459



 67%|██████▋   | 67013/100000 [1:09:46<34:19, 16.02it/s]
epoch 67000  training loss: 0.08647075295448303
epoch 67000  clean testing loss: 0.011834025382995605



 67%|██████▋   | 67109/100000 [1:09:52<34:09, 16.05it/s]
epoch 67100  training loss: 0.0863441526889801



 67%|██████▋   | 67205/100000 [1:09:58<34:00, 16.07it/s]
epoch 67200  training loss: 0.08642615377902985




 67%|██████▋   | 67335/100000 [1:10:06<33:51, 16.08it/s]
epoch 67300  training loss: 0.08620147407054901



 67%|██████▋   | 67431/100000 [1:10:12<33:45, 16.08it/s]
epoch 67400  training loss: 0.0861879214644432



 68%|██████▊   | 67527/100000 [1:10:18<33:38, 16.09it/s]
epoch 67500  training loss: 0.08643154054880142



 68%|██████▊   | 67623/100000 [1:10:24<33:34, 16.07it/s]
epoch 67600  training loss: 0.08680570870637894



 68%|██████▊   | 67719/100000 [1:10:30<33:28, 16.07it/s]
epoch 67700  training loss: 0.08649270236492157



 68%|██████▊   | 67817/100000 [1:10:36<33:21, 16.08it/s]
epoch 67800  training loss: 0.08661816269159317



 68%|██████▊   | 67913/100000 [1:10:42<33:17, 16.06it/s]
epoch 67900  training loss: 0.08680102974176407



 68%|██████▊   | 68009/100000 [1:10:48<33:19, 16.00it/s]
epoch 68000  training loss: 0.08691880851984024
epoch 68000  clean testing loss: 0.01183361653238535



 68%|██████▊   | 68105/100000 [1:10:54<33:09, 16.03it/s]
epoch 68100  training loss: 0.0868232399225235




 68%|██████▊   | 68233/100000 [1:11:02<32:56, 16.07it/s]
epoch 68200  training loss: 0.0866471529006958



 68%|██████▊   | 68331/100000 [1:11:08<32:49, 16.08it/s]
epoch 68300  training loss: 0.0868338868021965



 68%|██████▊   | 68427/100000 [1:11:14<32:43, 16.08it/s]
epoch 68400  training loss: 0.08688671886920929



 69%|██████▊   | 68523/100000 [1:11:20<32:38, 16.08it/s]
epoch 68500  training loss: 0.08613637834787369



 69%|██████▊   | 68619/100000 [1:11:26<32:32, 16.07it/s]
epoch 68600  training loss: 0.08667799830436707



 69%|██████▊   | 68715/100000 [1:11:32<32:24, 16.08it/s]
epoch 68700  training loss: 0.08646178245544434



 69%|██████▉   | 68813/100000 [1:11:38<32:20, 16.07it/s]
epoch 68800  training loss: 0.08668063580989838



 69%|██████▉   | 68909/100000 [1:11:44<32:17, 16.05it/s]
epoch 68900  training loss: 0.08638402819633484



 69%|██████▉   | 69005/100000 [1:11:50<32:29, 15.90it/s]
epoch 69000  training loss: 0.08659732341766357
epoch 69000  clean testing loss: 0.011815797537565231




 69%|██████▉   | 69133/100000 [1:11:58<31:59, 16.08it/s]
epoch 69100  training loss: 0.08673805743455887



 69%|██████▉   | 69231/100000 [1:12:04<31:54, 16.08it/s]
epoch 69200  training loss: 0.08665081858634949



 69%|██████▉   | 69327/100000 [1:12:10<31:48, 16.07it/s]
epoch 69300  training loss: 0.08685428649187088



 69%|██████▉   | 69423/100000 [1:12:16<31:48, 16.02it/s]
epoch 69400  training loss: 0.08665811270475388



 70%|██████▉   | 69519/100000 [1:12:22<31:35, 16.08it/s]
epoch 69500  training loss: 0.08635064959526062



 70%|██████▉   | 69615/100000 [1:12:28<31:31, 16.06it/s]
epoch 69600  training loss: 0.08696658909320831



 70%|██████▉   | 69711/100000 [1:12:34<31:25, 16.07it/s]
epoch 69700  training loss: 0.08677629381418228



 70%|██████▉   | 69809/100000 [1:12:40<31:20, 16.05it/s]
epoch 69800  training loss: 0.08658497035503387




 70%|██████▉   | 69937/100000 [1:12:48<31:10, 16.07it/s]
epoch 69900  training loss: 0.0869387611746788



 70%|███████   | 70033/100000 [1:12:54<31:04, 16.07it/s]
epoch 70000  training loss: 0.08673212677240372
epoch 70000  clean testing loss: 0.011677311733365059



 70%|███████   | 70121/100000 [1:13:00<30:58, 16.07it/s]
epoch 70100  training loss: 0.08687453716993332



 70%|███████   | 70217/100000 [1:13:06<30:56, 16.04it/s]
epoch 70200  training loss: 0.08698534965515137



 70%|███████   | 70315/100000 [1:13:12<30:47, 16.07it/s]
epoch 70300  training loss: 0.08666449785232544



 70%|███████   | 70411/100000 [1:13:18<30:45, 16.04it/s]
epoch 70400  training loss: 0.08723530173301697



 71%|███████   | 70507/100000 [1:13:24<30:37, 16.05it/s]
epoch 70500  training loss: 0.0871669352054596



 71%|███████   | 70603/100000 [1:13:30<30:40, 15.97it/s]
epoch 70600  training loss: 0.08688931167125702



 71%|███████   | 70699/100000 [1:13:36<30:24, 16.06it/s]
epoch 70700  training loss: 0.08655500411987305




 71%|███████   | 70829/100000 [1:13:44<30:14, 16.08it/s]
epoch 70800  training loss: 0.08680616319179535



 71%|███████   | 70925/100000 [1:13:50<30:09, 16.07it/s]
epoch 70900  training loss: 0.08705513924360275



 71%|███████   | 71021/100000 [1:13:56<30:08, 16.02it/s]
epoch 71000  training loss: 0.08694078028202057
epoch 71000  clean testing loss: 0.01174989715218544



 71%|███████   | 71117/100000 [1:14:02<29:58, 16.06it/s]
epoch 71100  training loss: 0.08677241951227188



 71%|███████   | 71213/100000 [1:14:08<29:55, 16.03it/s]
epoch 71200  training loss: 0.08689026534557343



 71%|███████▏  | 71311/100000 [1:14:14<29:49, 16.03it/s]
epoch 71300  training loss: 0.08660449087619781



 71%|███████▏  | 71407/100000 [1:14:20<29:45, 16.01it/s]
epoch 71400  training loss: 0.08666623383760452



 72%|███████▏  | 71503/100000 [1:14:26<29:44, 15.97it/s]
epoch 71500  training loss: 0.08664844930171967



 72%|███████▏  | 71599/100000 [1:14:32<29:28, 16.06it/s]
epoch 71600  training loss: 0.08701259642839432




 72%|███████▏  | 71727/100000 [1:14:40<29:21, 16.05it/s]
epoch 71700  training loss: 0.08698766678571701



 72%|███████▏  | 71823/100000 [1:14:46<32:03, 14.65it/s]
epoch 71800  training loss: 0.08706726878881454



 72%|███████▏  | 71921/100000 [1:14:52<29:07, 16.07it/s]
epoch 71900  training loss: 0.0872606709599495



 72%|███████▏  | 72017/100000 [1:14:58<29:08, 16.00it/s]
epoch 72000  training loss: 0.08666712790727615
epoch 72000  clean testing loss: 0.011829753406345844



 72%|███████▏  | 72113/100000 [1:15:04<28:56, 16.06it/s]
epoch 72100  training loss: 0.08727889508008957



 72%|███████▏  | 72209/100000 [1:15:10<28:53, 16.03it/s]
epoch 72200  training loss: 0.08699275553226471



 72%|███████▏  | 72305/100000 [1:15:16<29:49, 15.48it/s]
epoch 72300  training loss: 0.08697233349084854



 72%|███████▏  | 72401/100000 [1:15:22<28:38, 16.06it/s]
epoch 72400  training loss: 0.08703288435935974




 73%|███████▎  | 72531/100000 [1:15:30<28:29, 16.06it/s]
epoch 72500  training loss: 0.08743371069431305



 73%|███████▎  | 72627/100000 [1:15:36<28:22, 16.08it/s]
epoch 72600  training loss: 0.08735571801662445



 73%|███████▎  | 72723/100000 [1:15:42<28:17, 16.06it/s]
epoch 72700  training loss: 0.08715348690748215



 73%|███████▎  | 72819/100000 [1:15:48<28:11, 16.06it/s]
epoch 72800  training loss: 0.08724439889192581



 73%|███████▎  | 72917/100000 [1:15:54<28:06, 16.06it/s]
epoch 72900  training loss: 0.08725185692310333



 73%|███████▎  | 73013/100000 [1:16:00<28:03, 16.03it/s]
epoch 73000  training loss: 0.08703248202800751
epoch 73000  clean testing loss: 0.011813292279839516



 73%|███████▎  | 73109/100000 [1:16:06<27:54, 16.05it/s]
epoch 73100  training loss: 0.08706984668970108



 73%|███████▎  | 73205/100000 [1:16:12<27:52, 16.02it/s]
epoch 73200  training loss: 0.08690281212329865



 73%|███████▎  | 73301/100000 [1:16:18<27:44, 16.04it/s]
epoch 73300  training loss: 0.08740784972906113




 73%|███████▎  | 73429/100000 [1:16:26<27:33, 16.07it/s]
epoch 73400  training loss: 0.08725377917289734



 74%|███████▎  | 73527/100000 [1:16:32<27:27, 16.07it/s]
epoch 73500  training loss: 0.0869312435388565



 74%|███████▎  | 73623/100000 [1:16:38<27:22, 16.06it/s]
epoch 73600  training loss: 0.08668896555900574



 74%|███████▎  | 73719/100000 [1:16:44<27:16, 16.06it/s]
epoch 73700  training loss: 0.08718418329954147



 74%|███████▍  | 73815/100000 [1:16:50<27:11, 16.05it/s]
epoch 73800  training loss: 0.08722759783267975



 74%|███████▍  | 73911/100000 [1:16:56<27:05, 16.05it/s]
epoch 73900  training loss: 0.08700407296419144



 74%|███████▍  | 74009/100000 [1:17:02<27:06, 15.98it/s]
epoch 74000  training loss: 0.08681225031614304
epoch 74000  clean testing loss: 0.011770172975957394



 74%|███████▍  | 74105/100000 [1:17:08<26:55, 16.03it/s]
epoch 74100  training loss: 0.08681562542915344



 74%|███████▍  | 74201/100000 [1:17:14<26:47, 16.05it/s]
epoch 74200  training loss: 0.08716478943824768




 74%|███████▍  | 74329/100000 [1:17:22<26:38, 16.06it/s]
epoch 74300  training loss: 0.08678817003965378



 74%|███████▍  | 74425/100000 [1:17:28<26:31, 16.07it/s]
epoch 74400  training loss: 0.08695507794618607



 75%|███████▍  | 74521/100000 [1:17:34<26:26, 16.06it/s]
epoch 74500  training loss: 0.08739316463470459



 75%|███████▍  | 74619/100000 [1:17:40<26:19, 16.07it/s]
epoch 74600  training loss: 0.08703247457742691



 75%|███████▍  | 74715/100000 [1:17:46<26:13, 16.07it/s]
epoch 74700  training loss: 0.08699344098567963



 75%|███████▍  | 74811/100000 [1:17:52<26:08, 16.05it/s]
epoch 74800  training loss: 0.08677639812231064



 75%|███████▍  | 74907/100000 [1:17:58<26:04, 16.04it/s]
epoch 74900  training loss: 0.0871536061167717



 75%|███████▌  | 75003/100000 [1:18:04<26:14, 15.88it/s]
epoch 75000  training loss: 0.08693280071020126
epoch 75000  clean testing loss: 0.01171582005918026




 75%|███████▌  | 75131/100000 [1:18:12<25:47, 16.07it/s]
epoch 75100  training loss: 0.08709288388490677



 75%|███████▌  | 75227/100000 [1:18:18<25:55, 15.92it/s]
epoch 75200  training loss: 0.08674421161413193



 75%|███████▌  | 75325/100000 [1:18:24<25:41, 16.01it/s]
epoch 75300  training loss: 0.08722671866416931



 75%|███████▌  | 75421/100000 [1:18:30<25:30, 16.06it/s]
epoch 75400  training loss: 0.08704119920730591



 76%|███████▌  | 75517/100000 [1:18:36<25:23, 16.07it/s]
epoch 75500  training loss: 0.0873103216290474



 76%|███████▌  | 75613/100000 [1:18:42<25:19, 16.04it/s]
epoch 75600  training loss: 0.08697524666786194



 76%|███████▌  | 75709/100000 [1:18:48<25:29, 15.88it/s]
epoch 75700  training loss: 0.08723825216293335



 76%|███████▌  | 75807/100000 [1:18:54<25:13, 15.98it/s]
epoch 75800  training loss: 0.0871099978685379



 76%|███████▌  | 75903/100000 [1:19:00<25:06, 15.99it/s]
epoch 75900  training loss: 0.08698778599500656




 76%|███████▌  | 76031/100000 [1:19:08<24:52, 16.06it/s]
epoch 76000  training loss: 0.08710874617099762
epoch 76000  clean testing loss: 0.011686715297400951



 76%|███████▌  | 76127/100000 [1:19:14<24:45, 16.07it/s]
epoch 76100  training loss: 0.08727393299341202



 76%|███████▌  | 76223/100000 [1:19:20<24:40, 16.06it/s]
epoch 76200  training loss: 0.08707955479621887



 76%|███████▋  | 76321/100000 [1:19:26<24:34, 16.06it/s]
epoch 76300  training loss: 0.08721651881933212



 76%|███████▋  | 76417/100000 [1:19:32<24:28, 16.06it/s]
epoch 76400  training loss: 0.0871383398771286



 77%|███████▋  | 76513/100000 [1:19:38<24:23, 16.05it/s]
epoch 76500  training loss: 0.08729083091020584



 77%|███████▋  | 76609/100000 [1:19:44<24:18, 16.04it/s]
epoch 76600  training loss: 0.08707951009273529



 77%|███████▋  | 76705/100000 [1:19:50<24:14, 16.02it/s]
epoch 76700  training loss: 0.08702144771814346



 77%|███████▋  | 76803/100000 [1:19:57<24:10, 15.99it/s]
epoch 76800  training loss: 0.08739928901195526




 77%|███████▋  | 76931/100000 [1:20:04<23:56, 16.06it/s]
epoch 76900  training loss: 0.0873878225684166



 77%|███████▋  | 77027/100000 [1:20:10<23:49, 16.07it/s]
epoch 77000  training loss: 0.08713292330503464
epoch 77000  clean testing loss: 0.011751572601497173



 77%|███████▋  | 77123/100000 [1:20:16<23:45, 16.05it/s]
epoch 77100  training loss: 0.08714832365512848



 77%|███████▋  | 77211/100000 [1:20:22<23:40, 16.04it/s]
epoch 77200  training loss: 0.08700195699930191



 77%|███████▋  | 77309/100000 [1:20:28<23:33, 16.05it/s]
epoch 77300  training loss: 0.08727899938821793



 77%|███████▋  | 77405/100000 [1:20:34<23:31, 16.01it/s]
epoch 77400  training loss: 0.0870877280831337



 78%|███████▊  | 77501/100000 [1:20:40<23:21, 16.05it/s]
epoch 77500  training loss: 0.08728291839361191



 78%|███████▊  | 77597/100000 [1:20:46<23:14, 16.06it/s]
epoch 77600  training loss: 0.08729110658168793



 78%|███████▊  | 77693/100000 [1:20:52<23:10, 16.04it/s]
epoch 77700  training loss: 0.0867704227566719




 78%|███████▊  | 77823/100000 [1:21:00<23:00, 16.07it/s]
epoch 77800  training loss: 0.08698150515556335



 78%|███████▊  | 77919/100000 [1:21:06<22:54, 16.07it/s]
epoch 77900  training loss: 0.08702719211578369



 78%|███████▊  | 78015/100000 [1:21:12<22:50, 16.04it/s]
epoch 78000  training loss: 0.08687283098697662
epoch 78000  clean testing loss: 0.011662040837109089



 78%|███████▊  | 78111/100000 [1:21:18<23:39, 15.42it/s]
epoch 78100  training loss: 0.08722274005413055



 78%|███████▊  | 78207/100000 [1:21:24<22:38, 16.04it/s]
epoch 78200  training loss: 0.08696212619543076



 78%|███████▊  | 78303/100000 [1:21:30<22:35, 16.01it/s]
epoch 78300  training loss: 0.08686801791191101



 78%|███████▊  | 78401/100000 [1:21:36<22:25, 16.05it/s]
epoch 78400  training loss: 0.08710915595293045



 78%|███████▊  | 78497/100000 [1:21:42<22:18, 16.06it/s]
epoch 78500  training loss: 0.08700087666511536



 79%|███████▊  | 78593/100000 [1:21:48<22:13, 16.06it/s]
epoch 78600  training loss: 0.08711248636245728




 79%|███████▊  | 78721/100000 [1:21:56<22:04, 16.07it/s]
epoch 78700  training loss: 0.08709359169006348



 79%|███████▉  | 78817/100000 [1:22:02<21:58, 16.07it/s]
epoch 78800  training loss: 0.08723893761634827



 79%|███████▉  | 78915/100000 [1:22:08<21:53, 16.06it/s]
epoch 78900  training loss: 0.08689791709184647



 79%|███████▉  | 79011/100000 [1:22:14<21:50, 16.01it/s]
epoch 79000  training loss: 0.08739253878593445
epoch 79000  clean testing loss: 0.011613067239522934



 79%|███████▉  | 79107/100000 [1:22:20<21:44, 16.01it/s]
epoch 79100  training loss: 0.08700532466173172



 79%|███████▉  | 79203/100000 [1:22:26<21:39, 16.00it/s]
epoch 79200  training loss: 0.08717138320207596




 79%|███████▉  | 79331/100000 [1:22:34<21:27, 16.06it/s]
epoch 79300  training loss: 0.08706486970186234



 79%|███████▉  | 79427/100000 [1:22:40<21:20, 16.06it/s]
epoch 79400  training loss: 0.08727404475212097



 80%|███████▉  | 79525/100000 [1:22:46<21:15, 16.05it/s]
epoch 79500  training loss: 0.08703973144292831



 80%|███████▉  | 79619/100000 [1:22:52<21:08, 16.06it/s]
epoch 79600  training loss: 0.08714654296636581



 80%|███████▉  | 79717/100000 [1:22:58<21:03, 16.05it/s]
epoch 79700  training loss: 0.08693236112594604



 80%|███████▉  | 79813/100000 [1:23:04<20:58, 16.05it/s]
epoch 79800  training loss: 0.08704957365989685



 80%|███████▉  | 79909/100000 [1:23:10<20:52, 16.04it/s]
epoch 79900  training loss: 0.08684977889060974



 80%|████████  | 80005/100000 [1:23:16<20:56, 15.91it/s]
epoch 80000  training loss: 0.08677505701780319
epoch 80000  clean testing loss: 0.011658960022032261



 80%|████████  | 80101/100000 [1:23:22<20:40, 16.05it/s]
epoch 80100  training loss: 0.08705411851406097




 80%|████████  | 80231/100000 [1:23:30<20:30, 16.06it/s]
epoch 80200  training loss: 0.08700790256261826



 80%|████████  | 80327/100000 [1:23:36<20:25, 16.06it/s]
epoch 80300  training loss: 0.0868343710899353



 80%|████████  | 80423/100000 [1:23:42<20:19, 16.05it/s]
epoch 80400  training loss: 0.08661136776208878



 81%|████████  | 80519/100000 [1:23:48<20:12, 16.07it/s]
epoch 80500  training loss: 0.08715330064296722



 81%|████████  | 80615/100000 [1:23:54<20:16, 15.94it/s]
epoch 80600  training loss: 0.08668505400419235



 81%|████████  | 80711/100000 [1:24:00<20:03, 16.02it/s]
epoch 80700  training loss: 0.08665238320827484



 81%|████████  | 80809/100000 [1:24:07<19:55, 16.05it/s]
epoch 80800  training loss: 0.08691474050283432



 81%|████████  | 80905/100000 [1:24:13<19:51, 16.02it/s]
epoch 80900  training loss: 0.08689138293266296



 81%|████████  | 81001/100000 [1:24:19<20:04, 15.77it/s]
epoch 81000  training loss: 0.08725368976593018
epoch 81000  clean testing loss: 0.011577993631362915




 81%|████████  | 81129/100000 [1:24:27<19:34, 16.06it/s]
epoch 81100  training loss: 0.08671199530363083



 81%|████████  | 81225/100000 [1:24:33<19:28, 16.07it/s]
epoch 81200  training loss: 0.08678416907787323



 81%|████████▏ | 81323/100000 [1:24:39<19:21, 16.08it/s]
epoch 81300  training loss: 0.08712035417556763



 81%|████████▏ | 81419/100000 [1:24:45<19:16, 16.07it/s]
epoch 81400  training loss: 0.0869266614317894



 82%|████████▏ | 81515/100000 [1:24:51<19:21, 15.91it/s]
epoch 81500  training loss: 0.0869772806763649



 82%|████████▏ | 81611/100000 [1:24:57<19:05, 16.05it/s]
epoch 81600  training loss: 0.08687608689069748



 82%|████████▏ | 81707/100000 [1:25:03<19:00, 16.04it/s]
epoch 81700  training loss: 0.08700093626976013



 82%|████████▏ | 81805/100000 [1:25:09<18:55, 16.03it/s]
epoch 81800  training loss: 0.08689235150814056



 82%|████████▏ | 81901/100000 [1:25:15<18:46, 16.06it/s]
epoch 81900  training loss: 0.087076835334301




 82%|████████▏ | 82029/100000 [1:25:23<18:38, 16.06it/s]
epoch 82000  training loss: 0.08659309893846512
epoch 82000  clean testing loss: 0.011586476117372513



 82%|████████▏ | 82125/100000 [1:25:29<18:32, 16.07it/s]
epoch 82100  training loss: 0.08655921369791031



 82%|████████▏ | 82221/100000 [1:25:35<18:27, 16.06it/s]
epoch 82200  training loss: 0.08689259737730026



 82%|████████▏ | 82319/100000 [1:25:41<18:20, 16.07it/s]
epoch 82300  training loss: 0.08661332726478577



 82%|████████▏ | 82415/100000 [1:25:47<18:14, 16.06it/s]
epoch 82400  training loss: 0.08644523471593857



 83%|████████▎ | 82511/100000 [1:25:53<18:09, 16.06it/s]
epoch 82500  training loss: 0.08650971204042435



 83%|████████▎ | 82607/100000 [1:25:59<18:04, 16.04it/s]
epoch 82600  training loss: 0.08691692352294922



 83%|████████▎ | 82703/100000 [1:26:05<18:00, 16.00it/s]
epoch 82700  training loss: 0.08694826811552048



 83%|████████▎ | 82801/100000 [1:26:11<17:51, 16.05it/s]
epoch 82800  training loss: 0.08703458309173584




 83%|████████▎ | 82929/100000 [1:26:19<17:42, 16.07it/s]
epoch 82900  training loss: 0.08684256672859192



 83%|████████▎ | 83025/100000 [1:26:25<17:37, 16.06it/s]
epoch 83000  training loss: 0.08708969503641129
epoch 83000  clean testing loss: 0.01177110243588686



 83%|████████▎ | 83121/100000 [1:26:31<17:31, 16.05it/s]
epoch 83100  training loss: 0.08689894527196884



 83%|████████▎ | 83217/100000 [1:26:37<17:24, 16.06it/s]
epoch 83200  training loss: 0.08687493205070496



 83%|████████▎ | 83313/100000 [1:26:43<17:19, 16.05it/s]
epoch 83300  training loss: 0.08672807365655899



 83%|████████▎ | 83411/100000 [1:26:49<17:13, 16.05it/s]
epoch 83400  training loss: 0.08704112470149994



 84%|████████▎ | 83507/100000 [1:26:55<17:09, 16.01it/s]
epoch 83500  training loss: 0.086819127202034



 84%|████████▎ | 83603/100000 [1:27:01<17:04, 16.00it/s]
epoch 83600  training loss: 0.08714821934700012




 84%|████████▎ | 83731/100000 [1:27:09<16:52, 16.06it/s]
epoch 83700  training loss: 0.08695638924837112



 84%|████████▍ | 83827/100000 [1:27:15<16:46, 16.06it/s]
epoch 83800  training loss: 0.08706328272819519



 84%|████████▍ | 83923/100000 [1:27:21<17:18, 15.48it/s]
epoch 83900  training loss: 0.08725252002477646



 84%|████████▍ | 84021/100000 [1:27:27<16:34, 16.06it/s]
epoch 84000  training loss: 0.08684895932674408
epoch 84000  clean testing loss: 0.011648210696876049



 84%|████████▍ | 84117/100000 [1:27:33<16:28, 16.07it/s]
epoch 84100  training loss: 0.08689828962087631



 84%|████████▍ | 84213/100000 [1:27:39<16:24, 16.04it/s]
epoch 84200  training loss: 0.08682926744222641



 84%|████████▍ | 84301/100000 [1:27:44<16:18, 16.04it/s]
epoch 84300  training loss: 0.08698704838752747



 84%|████████▍ | 84399/100000 [1:27:51<16:10, 16.07it/s]
epoch 84400  training loss: 0.08684761822223663



 84%|████████▍ | 84493/100000 [1:27:56<16:05, 16.06it/s]
epoch 84500  training loss: 0.08724804222583771




 85%|████████▍ | 84623/100000 [1:28:05<15:57, 16.07it/s]
epoch 84600  training loss: 0.08688041567802429



 85%|████████▍ | 84719/100000 [1:28:11<15:52, 16.05it/s]
epoch 84700  training loss: 0.08705193549394608



 85%|████████▍ | 84815/100000 [1:28:17<15:45, 16.06it/s]
epoch 84800  training loss: 0.08678962290287018



 85%|████████▍ | 84911/100000 [1:28:23<15:41, 16.02it/s]
epoch 84900  training loss: 0.08700869977474213



 85%|████████▌ | 85007/100000 [1:28:29<15:39, 15.97it/s]
epoch 85000  training loss: 0.0871230959892273
epoch 85000  clean testing loss: 0.011645988561213017



 85%|████████▌ | 85105/100000 [1:28:35<15:29, 16.02it/s]
epoch 85100  training loss: 0.08711288869380951



 85%|████████▌ | 85201/100000 [1:28:41<15:22, 16.05it/s]
epoch 85200  training loss: 0.08674034476280212



 85%|████████▌ | 85297/100000 [1:28:47<15:14, 16.07it/s]
epoch 85300  training loss: 0.08676398545503616



 85%|████████▌ | 85393/100000 [1:28:53<15:11, 16.03it/s]
epoch 85400  training loss: 0.08673115074634552




 86%|████████▌ | 85521/100000 [1:29:01<15:01, 16.07it/s]
epoch 85500  training loss: 0.0870802253484726



 86%|████████▌ | 85619/100000 [1:29:07<14:55, 16.06it/s]
epoch 85600  training loss: 0.08708594739437103



 86%|████████▌ | 85715/100000 [1:29:13<14:49, 16.06it/s]
epoch 85700  training loss: 0.08710986375808716



 86%|████████▌ | 85811/100000 [1:29:19<14:44, 16.05it/s]
epoch 85800  training loss: 0.08699076622724533



 86%|████████▌ | 85907/100000 [1:29:25<14:38, 16.04it/s]
epoch 85900  training loss: 0.0869569405913353



 86%|████████▌ | 86005/100000 [1:29:31<14:38, 15.93it/s]
epoch 86000  training loss: 0.0869489386677742
epoch 86000  clean testing loss: 0.011674237437546253



 86%|████████▌ | 86101/100000 [1:29:37<14:26, 16.05it/s]
epoch 86100  training loss: 0.08667268604040146




 86%|████████▌ | 86229/100000 [1:29:45<14:16, 16.07it/s]
epoch 86200  training loss: 0.08671249449253082



 86%|████████▋ | 86325/100000 [1:29:51<14:11, 16.07it/s]
epoch 86300  training loss: 0.08691738545894623



 86%|████████▋ | 86421/100000 [1:29:57<14:05, 16.06it/s]
epoch 86400  training loss: 0.08680765330791473



 87%|████████▋ | 86519/100000 [1:30:03<13:59, 16.05it/s]
epoch 86500  training loss: 0.08692292124032974



 87%|████████▋ | 86615/100000 [1:30:09<13:53, 16.07it/s]
epoch 86600  training loss: 0.08675065636634827



 87%|████████▋ | 86711/100000 [1:30:15<13:48, 16.05it/s]
epoch 86700  training loss: 0.08689054846763611



 87%|████████▋ | 86807/100000 [1:30:21<13:42, 16.04it/s]
epoch 86800  training loss: 0.08694340288639069



 87%|████████▋ | 86903/100000 [1:30:27<13:38, 15.99it/s]
epoch 86900  training loss: 0.08673761785030365




 87%|████████▋ | 87031/100000 [1:30:35<13:27, 16.06it/s]
epoch 87000  training loss: 0.08692723512649536
epoch 87000  clean testing loss: 0.011636681854724884



 87%|████████▋ | 87129/100000 [1:30:41<13:21, 16.06it/s]
epoch 87100  training loss: 0.08686179667711258



 87%|████████▋ | 87225/100000 [1:30:47<13:15, 16.06it/s]
epoch 87200  training loss: 0.0871291235089302



 87%|████████▋ | 87321/100000 [1:30:53<13:13, 15.98it/s]
epoch 87300  training loss: 0.08686825633049011



 87%|████████▋ | 87417/100000 [1:30:59<13:03, 16.06it/s]
epoch 87400  training loss: 0.08709592372179031



 88%|████████▊ | 87513/100000 [1:31:05<12:57, 16.05it/s]
epoch 87500  training loss: 0.08715111017227173



 88%|████████▊ | 87611/100000 [1:31:11<12:52, 16.04it/s]
epoch 87600  training loss: 0.08711186796426773



 88%|████████▊ | 87707/100000 [1:31:17<12:47, 16.03it/s]
epoch 87700  training loss: 0.08687017858028412



 88%|████████▊ | 87803/100000 [1:31:23<12:46, 15.91it/s]
epoch 87800  training loss: 0.08721012622117996




 88%|████████▊ | 87931/100000 [1:31:31<12:31, 16.06it/s]
epoch 87900  training loss: 0.08704958111047745



 88%|████████▊ | 88027/100000 [1:31:37<12:25, 16.06it/s]
epoch 88000  training loss: 0.08710827678442001
epoch 88000  clean testing loss: 0.01161673478782177



 88%|████████▊ | 88125/100000 [1:31:43<12:19, 16.06it/s]
epoch 88100  training loss: 0.08692344278097153



 88%|████████▊ | 88221/100000 [1:31:49<12:13, 16.06it/s]
epoch 88200  training loss: 0.08700590580701828



 88%|████████▊ | 88317/100000 [1:31:55<12:07, 16.06it/s]
epoch 88300  training loss: 0.08708672970533371



 88%|████████▊ | 88413/100000 [1:32:01<12:01, 16.06it/s]
epoch 88400  training loss: 0.08697623759508133



 89%|████████▊ | 88509/100000 [1:32:07<11:56, 16.05it/s]
epoch 88500  training loss: 0.08663338422775269



 89%|████████▊ | 88607/100000 [1:32:13<11:50, 16.03it/s]
epoch 88600  training loss: 0.08667726814746857



 89%|████████▊ | 88703/100000 [1:32:19<11:45, 16.01it/s]
epoch 88700  training loss: 0.08664579689502716




 89%|████████▉ | 88831/100000 [1:32:27<11:35, 16.07it/s]
epoch 88800  training loss: 0.08662731200456619



 89%|████████▉ | 88927/100000 [1:32:33<11:29, 16.07it/s]
epoch 88900  training loss: 0.08708377182483673



 89%|████████▉ | 89023/100000 [1:32:39<11:23, 16.05it/s]
epoch 89000  training loss: 0.08710112422704697
epoch 89000  clean testing loss: 0.011599968187510967



 89%|████████▉ | 89119/100000 [1:32:45<11:17, 16.06it/s]
epoch 89100  training loss: 0.08715511113405228



 89%|████████▉ | 89217/100000 [1:32:51<11:11, 16.05it/s]
epoch 89200  training loss: 0.08672870695590973



 89%|████████▉ | 89311/100000 [1:32:57<11:05, 16.05it/s]
epoch 89300  training loss: 0.08672554045915604



 89%|████████▉ | 89409/100000 [1:33:03<11:00, 16.04it/s]
epoch 89400  training loss: 0.0869549810886383



 90%|████████▉ | 89505/100000 [1:33:09<10:54, 16.02it/s]
epoch 89500  training loss: 0.08699556440114975



 90%|████████▉ | 89601/100000 [1:33:15<10:47, 16.06it/s]
epoch 89600  training loss: 0.08681835234165192




 90%|████████▉ | 89729/100000 [1:33:23<11:32, 14.83it/s]
epoch 89700  training loss: 0.08698295801877975



 90%|████████▉ | 89825/100000 [1:33:29<10:32, 16.08it/s]
epoch 89800  training loss: 0.08643299341201782



 90%|████████▉ | 89923/100000 [1:33:35<10:27, 16.07it/s]
epoch 89900  training loss: 0.08663806319236755



 90%|█████████ | 90019/100000 [1:33:41<10:23, 16.02it/s]
epoch 90000  training loss: 0.08678222447633743
epoch 90000  clean testing loss: 0.011641096323728561



 90%|█████████ | 90115/100000 [1:33:47<10:15, 16.07it/s]
epoch 90100  training loss: 0.08655179291963577



 90%|█████████ | 90211/100000 [1:33:53<11:24, 14.30it/s]
epoch 90200  training loss: 0.08714257925748825



 90%|█████████ | 90307/100000 [1:33:59<10:04, 16.04it/s]
epoch 90300  training loss: 0.08646507561206818



 90%|█████████ | 90405/100000 [1:34:05<09:58, 16.02it/s]
epoch 90400  training loss: 0.08643786609172821



 91%|█████████ | 90501/100000 [1:34:11<09:53, 16.00it/s]
epoch 90500  training loss: 0.08685201406478882




 91%|█████████ | 90629/100000 [1:34:19<09:43, 16.06it/s]
epoch 90600  training loss: 0.08651236444711685



 91%|█████████ | 90725/100000 [1:34:25<09:37, 16.05it/s]
epoch 90700  training loss: 0.08673369139432907



 91%|█████████ | 90821/100000 [1:34:31<09:32, 16.04it/s]
epoch 90800  training loss: 0.08652624487876892



 91%|█████████ | 90919/100000 [1:34:37<09:25, 16.06it/s]
epoch 90900  training loss: 0.0866738110780716



 91%|█████████ | 91015/100000 [1:34:43<09:20, 16.04it/s]
epoch 91000  training loss: 0.08690407127141953
epoch 91000  clean testing loss: 0.011658094823360443



 91%|█████████ | 91111/100000 [1:34:49<09:14, 16.03it/s]
epoch 91100  training loss: 0.08677070587873459



 91%|█████████ | 91207/100000 [1:34:55<09:08, 16.02it/s]
epoch 91200  training loss: 0.08677399903535843



 91%|█████████▏| 91303/100000 [1:35:01<09:03, 16.01it/s]
epoch 91300  training loss: 0.08665478974580765




 91%|█████████▏| 91423/100000 [1:35:09<08:54, 16.06it/s]
epoch 91400  training loss: 0.08657798916101456



 92%|█████████▏| 91521/100000 [1:35:15<08:47, 16.06it/s]
epoch 91500  training loss: 0.08703698962926865



 92%|█████████▏| 91617/100000 [1:35:21<08:43, 16.03it/s]
epoch 91600  training loss: 0.0867452397942543



 92%|█████████▏| 91713/100000 [1:35:27<08:35, 16.07it/s]
epoch 91700  training loss: 0.08679062873125076



 92%|█████████▏| 91809/100000 [1:35:33<08:30, 16.06it/s]
epoch 91800  training loss: 0.08683740347623825



 92%|█████████▏| 91905/100000 [1:35:39<08:25, 16.03it/s]
epoch 91900  training loss: 0.08666414767503738



 92%|█████████▏| 92003/100000 [1:35:45<08:23, 15.87it/s]
epoch 92000  training loss: 0.08653813600540161
epoch 92000  clean testing loss: 0.011670168489217758



 92%|█████████▏| 92099/100000 [1:35:51<08:11, 16.07it/s]
epoch 92100  training loss: 0.08682698756456375



 92%|█████████▏| 92195/100000 [1:35:57<08:05, 16.07it/s]
epoch 92200  training loss: 0.0869186744093895




 92%|█████████▏| 92323/100000 [1:36:05<07:57, 16.06it/s]
epoch 92300  training loss: 0.08701174706220627



 92%|█████████▏| 92419/100000 [1:36:11<07:52, 16.03it/s]
epoch 92400  training loss: 0.08646790683269501



 93%|█████████▎| 92517/100000 [1:36:17<07:45, 16.07it/s]
epoch 92500  training loss: 0.08694580942392349



 93%|█████████▎| 92613/100000 [1:36:23<07:40, 16.06it/s]
epoch 92600  training loss: 0.08697379380464554



 93%|█████████▎| 92709/100000 [1:36:29<07:34, 16.05it/s]
epoch 92700  training loss: 0.08696836233139038



 93%|█████████▎| 92805/100000 [1:36:35<07:29, 16.02it/s]
epoch 92800  training loss: 0.08653975278139114



 93%|█████████▎| 92901/100000 [1:36:41<07:22, 16.06it/s]
epoch 92900  training loss: 0.08652807027101517



 93%|█████████▎| 92999/100000 [1:36:47<07:15, 16.06it/s]
epoch 93000  training loss: 0.08683369308710098
epoch 93000  clean testing loss: 0.011705226264894009



 93%|█████████▎| 93095/100000 [1:36:53<07:09, 16.06it/s]
epoch 93100  training loss: 0.0869976133108139




 93%|█████████▎| 93223/100000 [1:37:01<07:01, 16.07it/s]
epoch 93200  training loss: 0.0868101641535759



 93%|█████████▎| 93319/100000 [1:37:07<06:56, 16.06it/s]
epoch 93300  training loss: 0.08651190251111984



 93%|█████████▎| 93415/100000 [1:37:13<06:50, 16.06it/s]
epoch 93400  training loss: 0.08641993254423141



 94%|█████████▎| 93511/100000 [1:37:19<06:44, 16.05it/s]
epoch 93500  training loss: 0.08658310025930405



 94%|█████████▎| 93607/100000 [1:37:25<06:43, 15.84it/s]
epoch 93600  training loss: 0.08689668029546738



 94%|█████████▎| 93703/100000 [1:37:31<06:35, 15.91it/s]
epoch 93700  training loss: 0.0867874026298523



 94%|█████████▍| 93801/100000 [1:37:37<06:25, 16.06it/s]
epoch 93800  training loss: 0.08663147687911987




 94%|█████████▍| 93929/100000 [1:37:45<06:17, 16.06it/s]
epoch 93900  training loss: 0.08672468364238739



 94%|█████████▍| 94025/100000 [1:37:51<06:11, 16.08it/s]
epoch 94000  training loss: 0.08651421964168549
epoch 94000  clean testing loss: 0.011694212444126606



 94%|█████████▍| 94121/100000 [1:37:57<06:05, 16.08it/s]
epoch 94100  training loss: 0.08645863085985184



 94%|█████████▍| 94219/100000 [1:38:03<06:00, 16.06it/s]
epoch 94200  training loss: 0.08675595372915268



 94%|█████████▍| 94315/100000 [1:38:09<05:53, 16.08it/s]
epoch 94300  training loss: 0.0870317816734314



 94%|█████████▍| 94411/100000 [1:38:15<05:48, 16.06it/s]
epoch 94400  training loss: 0.08675939589738846



 95%|█████████▍| 94507/100000 [1:38:21<05:42, 16.05it/s]
epoch 94500  training loss: 0.08676426857709885



 95%|█████████▍| 94603/100000 [1:38:27<05:37, 15.99it/s]
epoch 94600  training loss: 0.08655986189842224



 95%|█████████▍| 94701/100000 [1:38:33<05:29, 16.07it/s]
epoch 94700  training loss: 0.0868912860751152




 95%|█████████▍| 94829/100000 [1:38:41<05:22, 16.05it/s]
epoch 94800  training loss: 0.08689327538013458



 95%|█████████▍| 94925/100000 [1:38:47<05:15, 16.07it/s]
epoch 94900  training loss: 0.0866847112774849



 95%|█████████▌| 95021/100000 [1:38:53<05:10, 16.03it/s]
epoch 95000  training loss: 0.08665219694375992
epoch 95000  clean testing loss: 0.011731591075658798



 95%|█████████▌| 95117/100000 [1:38:59<05:03, 16.06it/s]
epoch 95100  training loss: 0.08658741414546967



 95%|█████████▌| 95215/100000 [1:39:06<04:57, 16.07it/s]
epoch 95200  training loss: 0.08645167201757431



 95%|█████████▌| 95311/100000 [1:39:11<04:51, 16.06it/s]
epoch 95300  training loss: 0.08694655448198318



 95%|█████████▌| 95407/100000 [1:39:17<04:46, 16.03it/s]
epoch 95400  training loss: 0.08677687495946884



 96%|█████████▌| 95503/100000 [1:39:23<04:41, 15.99it/s]
epoch 95500  training loss: 0.08676721155643463




 96%|█████████▌| 95631/100000 [1:39:31<04:32, 16.06it/s]
epoch 95600  training loss: 0.0863444060087204



 96%|█████████▌| 95729/100000 [1:39:38<04:25, 16.06it/s]
epoch 95700  training loss: 0.08684905618429184



 96%|█████████▌| 95825/100000 [1:39:44<04:19, 16.07it/s]
epoch 95800  training loss: 0.08640111237764359



 96%|█████████▌| 95921/100000 [1:39:50<04:13, 16.07it/s]
epoch 95900  training loss: 0.0868096575140953



 96%|█████████▌| 96017/100000 [1:39:56<04:36, 14.42it/s]
epoch 96000  training loss: 0.0864221528172493
epoch 96000  clean testing loss: 0.011726699769496918



 96%|█████████▌| 96113/100000 [1:40:02<04:01, 16.08it/s]
epoch 96100  training loss: 0.08703066408634186



 96%|█████████▌| 96211/100000 [1:40:08<03:56, 16.00it/s]
epoch 96200  training loss: 0.08658880740404129



 96%|█████████▋| 96307/100000 [1:40:14<03:50, 16.01it/s]
epoch 96300  training loss: 0.08690840005874634



 96%|█████████▋| 96403/100000 [1:40:20<03:44, 16.01it/s]
epoch 96400  training loss: 0.08681782335042953




 97%|█████████▋| 96531/100000 [1:40:28<03:36, 16.06it/s]
epoch 96500  training loss: 0.08659147471189499



 97%|█████████▋| 96629/100000 [1:40:34<03:29, 16.08it/s]
epoch 96600  training loss: 0.08693621307611465



 97%|█████████▋| 96725/100000 [1:40:40<03:23, 16.05it/s]
epoch 96700  training loss: 0.08670792728662491



 97%|█████████▋| 96821/100000 [1:40:46<03:17, 16.09it/s]
epoch 96800  training loss: 0.08693993836641312



 97%|█████████▋| 96919/100000 [1:40:52<03:11, 16.07it/s]
epoch 96900  training loss: 0.08639734238386154



 97%|█████████▋| 97015/100000 [1:40:58<03:06, 16.04it/s]
epoch 97000  training loss: 0.08699389547109604
epoch 97000  clean testing loss: 0.011726215481758118



 97%|█████████▋| 97111/100000 [1:41:04<02:59, 16.06it/s]
epoch 97100  training loss: 0.08684694766998291



 97%|█████████▋| 97207/100000 [1:41:10<02:54, 15.97it/s]
epoch 97200  training loss: 0.08644291013479233



 97%|█████████▋| 97303/100000 [1:41:16<02:48, 16.00it/s]
epoch 97300  training loss: 0.08653173595666885



 97%|█████████▋| 97401/100000 [1:41:22<02:41, 16.06it/s]
epoch 97400  training loss: 0.08635211735963821




 98%|█████████▊| 97529/100000 [1:41:30<02:33, 16.07it/s]
epoch 97500  training loss: 0.08661732077598572



 98%|█████████▊| 97625/100000 [1:41:36<02:27, 16.06it/s]
epoch 97600  training loss: 0.08648061007261276



 98%|█████████▊| 97721/100000 [1:41:42<02:21, 16.06it/s]
epoch 97700  training loss: 0.08646989613771439



 98%|█████████▊| 97819/100000 [1:41:48<02:15, 16.06it/s]
epoch 97800  training loss: 0.08654919266700745



 98%|█████████▊| 97915/100000 [1:41:54<02:09, 16.06it/s]
epoch 97900  training loss: 0.08644603937864304



 98%|█████████▊| 98011/100000 [1:42:00<02:04, 16.02it/s]
epoch 98000  training loss: 0.08692169189453125
epoch 98000  clean testing loss: 0.011763380840420723



 98%|█████████▊| 98107/100000 [1:42:06<01:58, 16.03it/s]
epoch 98100  training loss: 0.08701694756746292



 98%|█████████▊| 98203/100000 [1:42:12<01:52, 16.02it/s]
epoch 98200  training loss: 0.08684466034173965



 98%|█████████▊| 98291/100000 [1:42:17<01:46, 16.06it/s]
epoch 98300  training loss: 0.08663427829742432




 98%|█████████▊| 98421/100000 [1:42:25<01:38, 16.07it/s]
epoch 98400  training loss: 0.08695591986179352



 99%|█████████▊| 98517/100000 [1:42:31<01:32, 16.04it/s]
epoch 98500  training loss: 0.08691207319498062



 99%|█████████▊| 98613/100000 [1:42:37<01:26, 16.06it/s]
epoch 98600  training loss: 0.08688703179359436



 99%|█████████▊| 98709/100000 [1:42:43<01:20, 16.05it/s]
epoch 98700  training loss: 0.08661215007305145



 99%|█████████▉| 98805/100000 [1:42:49<01:14, 16.00it/s]
epoch 98800  training loss: 0.0867534726858139



 99%|█████████▉| 98903/100000 [1:42:56<01:08, 16.00it/s]
epoch 98900  training loss: 0.08637025207281113



 99%|█████████▉| 98997/100000 [1:43:01<01:02, 16.07it/s]
epoch 99000  training loss: 0.08642861992120743
epoch 99000  clean testing loss: 0.01178611721843481



 99%|█████████▉| 99095/100000 [1:43:08<00:56, 16.07it/s]
epoch 99100  training loss: 0.08644647896289825




 99%|█████████▉| 99223/100000 [1:43:16<00:48, 16.06it/s]
epoch 99200  training loss: 0.08646146953105927



 99%|█████████▉| 99319/100000 [1:43:21<00:42, 16.06it/s]
epoch 99300  training loss: 0.08652006089687347



 99%|█████████▉| 99415/100000 [1:43:28<00:37, 15.56it/s]
epoch 99400  training loss: 0.08666358143091202



100%|█████████▉| 99511/100000 [1:43:34<00:30, 16.05it/s]
epoch 99500  training loss: 0.08690684288740158



100%|█████████▉| 99607/100000 [1:43:40<00:24, 16.01it/s]
epoch 99600  training loss: 0.08680698275566101



100%|█████████▉| 99705/100000 [1:43:46<00:18, 16.01it/s]
epoch 99700  training loss: 0.08663353323936462



100%|█████████▉| 99801/100000 [1:43:52<00:12, 16.02it/s]
epoch 99800  training loss: 0.0867525264620781



100%|█████████▉| 99897/100000 [1:43:58<00:06, 15.53it/s]
epoch 99900  training loss: 0.08662696182727814



100%|█████████▉| 99993/100000 [1:44:04<00:00, 16.07it/s]

100%|██████████| 100000/100000 [1:44:04<00:00, 16.01it/s]