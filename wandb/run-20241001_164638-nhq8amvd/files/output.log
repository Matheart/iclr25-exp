
  0%|          | 665/300000 [00:01<09:49, 507.63it/s]
epoch 0  training loss: 0.7730321288108826
epoch 0  clean testing loss: 0.5255364179611206
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 100  training loss: 0.408232182264328
epoch 100  clean testing loss: 0.15961341559886932
epoch 200  training loss: 0.3441486060619354
epoch 200  clean testing loss: 0.09720142185688019
epoch 300  training loss: 0.3328268826007843
epoch 300  clean testing loss: 0.08604912459850311
epoch 400  training loss: 0.32074135541915894
epoch 400  clean testing loss: 0.07488799095153809
epoch 500  training loss: 0.30930426716804504
epoch 500  clean testing loss: 0.06650831550359726
epoch 600  training loss: 0.3008752465248108
epoch 600  clean testing loss: 0.06186612695455551
epoch 700  training loss: 0.2949863076210022

  1%|          | 1650/300000 [00:03<11:56, 416.46it/s]
epoch 800  training loss: 0.2901037633419037
epoch 800  clean testing loss: 0.05939978361129761
epoch 900  training loss: 0.28585579991340637
epoch 900  clean testing loss: 0.05879294127225876
epoch 1000  training loss: 0.28185999393463135
epoch 1000  clean testing loss: 0.058327674865722656
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 1100  training loss: 0.2776468098163605
epoch 1100  clean testing loss: 0.05707687884569168
epoch 1200  training loss: 0.2736990451812744
epoch 1200  clean testing loss: 0.05712540075182915
epoch 1300  training loss: 0.26982662081718445
epoch 1300  clean testing loss: 0.05724717676639557
epoch 1400  training loss: 0.266309916973114
epoch 1400  clean testing loss: 0.05708129703998566
epoch 1500  training loss: 0.26300910115242004
epoch 1500  clean testing loss: 0.05750572308897972
epoch 1600  training loss: 0.25990021228790283
epoch 1600  clean testing loss: 0.057919688522815704
epoch 1700  training loss: 0.257016122341156

  1%|          | 2684/300000 [00:05<09:40, 512.34it/s]
epoch 1800  training loss: 0.2544166147708893
epoch 1800  clean testing loss: 0.05995471030473709
epoch 1900  training loss: 0.2517925202846527
epoch 1900  clean testing loss: 0.06016918271780014
epoch 2000  training loss: 0.2495620995759964
epoch 2000  clean testing loss: 0.06015823781490326
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 2100  training loss: 0.24718286097049713
epoch 2100  clean testing loss: 0.06097511574625969
epoch 2200  training loss: 0.24494554102420807
epoch 2200  clean testing loss: 0.0621408186852932
epoch 2300  training loss: 0.2430601865053177
epoch 2300  clean testing loss: 0.06373446434736252
epoch 2400  training loss: 0.24066388607025146
epoch 2400  clean testing loss: 0.06316670030355453
epoch 2500  training loss: 0.23851098120212555
epoch 2500  clean testing loss: 0.0640997365117073
epoch 2600  training loss: 0.23637746274471283
epoch 2600  clean testing loss: 0.06445898115634918
epoch 2700  training loss: 0.23436911404132843

  1%|          | 3253/300000 [00:06<09:46, 505.64it/s]
epoch 2800  training loss: 0.23254090547561646
epoch 2800  clean testing loss: 0.06729020923376083
epoch 2900  training loss: 0.23039478063583374
epoch 2900  clean testing loss: 0.06653006374835968
epoch 3000  training loss: 0.2284226268529892
epoch 3000  clean testing loss: 0.06781578063964844
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 3100  training loss: 0.22683711349964142
epoch 3100  clean testing loss: 0.06883250176906586
epoch 3200  training loss: 0.225412517786026
epoch 3200  clean testing loss: 0.06962549686431885

epoch 3400  clean testing loss: 0.0709928423166275
epoch 3300  clean testing loss: 0.07151385396718979
epoch 3400  training loss: 0.22258692979812622
epoch 3400  clean testing loss: 0.0709928423166275
epoch 3500  training loss: 0.22091321647167206
epoch 3500  clean testing loss: 0.07196102291345596
epoch 3600  training loss: 0.2195129543542862
epoch 3600  clean testing loss: 0.07378628849983215
epoch 3700  training loss: 0.21838216483592987
epoch 3700  clean testing loss: 0.07355034351348877
epoch 3800  training loss: 0.21686603128910065
epoch 3800  clean testing loss: 0.07462728023529053
epoch 3900  training loss: 0.21570542454719543
epoch 3900  clean testing loss: 0.07524852454662323
epoch 4000  training loss: 0.21474744379520416
epoch 4000  clean testing loss: 0.07722768187522888
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 4100  training loss: 0.21343779563903809
epoch 4100  clean testing loss: 0.07731673121452332
epoch 4200  training loss: 0.212225079536438

  2%|▏         | 5164/300000 [00:18<09:39, 508.99it/s]
epoch 4300  training loss: 0.2110692262649536
epoch 4300  clean testing loss: 0.07729987055063248
epoch 4400  training loss: 0.2097194641828537
epoch 4400  clean testing loss: 0.07966523617506027
epoch 4500  training loss: 0.20829744637012482
epoch 4500  clean testing loss: 0.07918106019496918
epoch 4600  training loss: 0.2070995569229126
epoch 4600  clean testing loss: 0.07937406003475189
epoch 4700  training loss: 0.20601873099803925
epoch 4700  clean testing loss: 0.07978381961584091
epoch 4800  training loss: 0.2048802226781845
epoch 4800  clean testing loss: 0.08089122176170349
epoch 4900  training loss: 0.20389893651008606
epoch 4900  clean testing loss: 0.08047255128622055
epoch 5000  training loss: 0.20237895846366882
epoch 5000  clean testing loss: 0.08149714022874832
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 5100  training loss: 0.20157036185264587
epoch 5100  clean testing loss: 0.08301683515310287
epoch 5200  training loss: 0.20008166134357452

  2%|▏         | 6201/300000 [00:20<09:42, 504.71it/s]
epoch 5300  training loss: 0.19919393956661224
epoch 5300  clean testing loss: 0.08254848420619965
epoch 5400  training loss: 0.19809144735336304
epoch 5400  clean testing loss: 0.08331374078989029
epoch 5500  training loss: 0.19709256291389465
epoch 5500  clean testing loss: 0.08581125736236572
epoch 5600  training loss: 0.19552792608737946
epoch 5600  clean testing loss: 0.08505644649267197
epoch 5700  training loss: 0.19438941776752472
epoch 5700  clean testing loss: 0.08507399260997772
epoch 5800  training loss: 0.1933608502149582
epoch 5800  clean testing loss: 0.08533768355846405
epoch 5900  training loss: 0.1922607272863388
epoch 5900  clean testing loss: 0.08613386750221252
epoch 6000  training loss: 0.19143065810203552
epoch 6000  clean testing loss: 0.08664470165967941
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 6100  training loss: 0.1899651139974594
epoch 6100  clean testing loss: 0.08760324865579605
epoch 6200  training loss: 0.18908770382404327

  2%|▏         | 7183/300000 [00:22<09:36, 507.71it/s]
epoch 6300  training loss: 0.18824557960033417
epoch 6300  clean testing loss: 0.0883985310792923
epoch 6400  training loss: 0.18734845519065857
epoch 6400  clean testing loss: 0.08869937807321548
epoch 6500  training loss: 0.18680298328399658
epoch 6500  clean testing loss: 0.09095718711614609
epoch 6600  training loss: 0.18580739200115204
epoch 6600  clean testing loss: 0.08933532983064651
epoch 6700  training loss: 0.18458415567874908
epoch 6700  clean testing loss: 0.0910412073135376
epoch 6800  training loss: 0.18371102213859558
epoch 6800  clean testing loss: 0.09126847982406616
epoch 6900  training loss: 0.1827976107597351
epoch 6900  clean testing loss: 0.09114450216293335
epoch 7000  training loss: 0.18210378289222717
epoch 7000  clean testing loss: 0.0913776159286499
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 7100  training loss: 0.18171708285808563
epoch 7100  clean testing loss: 0.09155803173780441
epoch 7200  training loss: 0.18068741261959076

  3%|▎         | 8160/300000 [00:24<11:06, 438.11it/s]
epoch 7300  training loss: 0.1796066164970398
epoch 7300  clean testing loss: 0.09286348521709442
epoch 7400  training loss: 0.17849262058734894
epoch 7400  clean testing loss: 0.09513267874717712
epoch 7500  training loss: 0.1781618297100067
epoch 7500  clean testing loss: 0.09654737263917923
epoch 7600  training loss: 0.17666563391685486
epoch 7600  clean testing loss: 0.09496372193098068
epoch 7700  training loss: 0.17578642070293427
epoch 7700  clean testing loss: 0.09542784094810486
epoch 7800  training loss: 0.17505455017089844
epoch 7800  clean testing loss: 0.09622467309236526
epoch 7900  training loss: 0.17416740953922272
epoch 7900  clean testing loss: 0.09611108899116516
epoch 8000  training loss: 0.17410889267921448
epoch 8000  clean testing loss: 0.09596575796604156
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 8100  training loss: 0.17341278493404388
epoch 8100  clean testing loss: 0.09658034145832062
epoch 8200  training loss: 0.17210227251052856

  3%|▎         | 9189/300000 [00:26<09:43, 498.70it/s]
epoch 8300  training loss: 0.17112469673156738
epoch 8300  clean testing loss: 0.0972687155008316
epoch 8400  training loss: 0.17016105353832245
epoch 8400  clean testing loss: 0.09905333817005157
epoch 8500  training loss: 0.17009775340557098
epoch 8500  clean testing loss: 0.09823622554540634
epoch 8600  training loss: 0.16884742677211761
epoch 8600  clean testing loss: 0.0993557721376419
epoch 8700  training loss: 0.1681186556816101
epoch 8700  clean testing loss: 0.1018223762512207
epoch 8800  training loss: 0.16756777465343475
epoch 8800  clean testing loss: 0.1024957150220871
epoch 8900  training loss: 0.16640134155750275
epoch 8900  clean testing loss: 0.10171421617269516
epoch 9000  training loss: 0.165827676653862
epoch 9000  clean testing loss: 0.10135878622531891
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 9100  training loss: 0.16489291191101074
epoch 9100  clean testing loss: 0.10238899290561676
epoch 9200  training loss: 0.16427353024482727

  3%|▎         | 10220/300000 [00:28<09:36, 502.57it/s]
epoch 9300  training loss: 0.16362689435482025
epoch 9300  clean testing loss: 0.103874072432518
epoch 9400  training loss: 0.16317300498485565
epoch 9400  clean testing loss: 0.10282713919878006
epoch 9500  training loss: 0.16243857145309448
epoch 9500  clean testing loss: 0.10347487777471542
epoch 9600  training loss: 0.1615084409713745
epoch 9600  clean testing loss: 0.10432831197977066
epoch 9700  training loss: 0.1609167605638504
epoch 9700  clean testing loss: 0.10596957802772522
epoch 9800  training loss: 0.1600552201271057
epoch 9800  clean testing loss: 0.10658758878707886
epoch 9900  training loss: 0.15942491590976715
epoch 9900  clean testing loss: 0.10788893699645996
epoch 10000  training loss: 0.15898442268371582
epoch 10000  clean testing loss: 0.10854580998420715
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 10100  training loss: 0.15840314328670502
epoch 10100  clean testing loss: 0.10926518589258194
epoch 10200  training loss: 0.1577177792787552

  4%|▍         | 12248/300000 [00:32<09:34, 500.93it/s]
epoch 10300  training loss: 0.1567792296409607
epoch 10300  clean testing loss: 0.11010315269231796
epoch 10400  training loss: 0.15590794384479523
epoch 10400  clean testing loss: 0.10933829098939896
epoch 10500  training loss: 0.15539096295833588
epoch 10500  clean testing loss: 0.11113882809877396
epoch 10600  training loss: 0.15488363802433014
epoch 10600  clean testing loss: 0.11211860179901123
epoch 10700  training loss: 0.15451057255268097
epoch 10700  clean testing loss: 0.11328580975532532
epoch 10800  training loss: 0.15379728376865387
epoch 10800  clean testing loss: 0.11348234862089157
epoch 10900  training loss: 0.1527908742427826
epoch 10900  clean testing loss: 0.11242374032735825
epoch 11000  training loss: 0.1521645039319992
epoch 11000  clean testing loss: 0.11275612562894821
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 11100  training loss: 0.151958167552948
epoch 11100  clean testing loss: 0.11453744769096375
epoch 11200  training loss: 0.1508697271347046
epoch 11200  clean testing loss: 0.11336351186037064
epoch 11300  training loss: 0.15079666674137115
epoch 11300  clean testing loss: 0.11567888408899307
epoch 11400  training loss: 0.1496986448764801
epoch 11400  clean testing loss: 0.11404210329055786
epoch 11500  training loss: 0.14928463101387024
epoch 11500  clean testing loss: 0.11355014890432358
epoch 11600  training loss: 0.14879433810710907
epoch 11600  clean testing loss: 0.11718469858169556
epoch 11700  training loss: 0.14829501509666443
epoch 11700  clean testing loss: 0.12236355245113373
epoch 11800  training loss: 0.14623871445655823
epoch 11800  clean testing loss: 0.12122637778520584
epoch 11900  training loss: 0.14562787115573883
epoch 11900  clean testing loss: 0.11980579048395157
epoch 12000  training loss: 0.14496085047721863
epoch 12000  clean testing loss: 0.12114313244819641
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 12100  training loss: 0.14449842274188995
epoch 12100  clean testing loss: 0.12104484438896179
epoch 12200  training loss: 0.14406371116638184
epoch 12200  clean testing loss: 0.12138967216014862
epoch 12300  training loss: 0.14358662068843842

  4%|▍         | 13231/300000 [00:34<09:25, 506.85it/s]
epoch 12400  training loss: 0.14318811893463135
epoch 12400  clean testing loss: 0.12112938612699509
epoch 12500  training loss: 0.14277222752571106
epoch 12500  clean testing loss: 0.12112560123205185
epoch 12600  training loss: 0.14243270456790924
epoch 12600  clean testing loss: 0.12301041185855865
epoch 12700  training loss: 0.14181101322174072
epoch 12700  clean testing loss: 0.1236027255654335
epoch 12800  training loss: 0.14133493602275848
epoch 12800  clean testing loss: 0.12338823825120926
epoch 12900  training loss: 0.14099934697151184
epoch 12900  clean testing loss: 0.12259925156831741
epoch 13000  training loss: 0.14070190489292145
epoch 13000  clean testing loss: 0.12279189378023148
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 13100  training loss: 0.140318363904953
epoch 13100  clean testing loss: 0.12280202656984329
epoch 13200  training loss: 0.13943931460380554
epoch 13200  clean testing loss: 0.12413071095943451
epoch 13300  training loss: 0.13914033770561218


  5%|▍         | 14324/300000 [00:46<10:01, 474.57it/s]
epoch 13400  training loss: 0.13939978182315826
epoch 13400  clean testing loss: 0.12384209036827087
epoch 13500  training loss: 0.13822931051254272
epoch 13500  clean testing loss: 0.12601029872894287
epoch 13600  training loss: 0.1377776861190796
epoch 13600  clean testing loss: 0.12653982639312744
epoch 13700  training loss: 0.13769996166229248
epoch 13700  clean testing loss: 0.12814730405807495
epoch 13800  training loss: 0.13693146407604218
epoch 13800  clean testing loss: 0.1272687017917633
epoch 13900  training loss: 0.13703446090221405
epoch 13900  clean testing loss: 0.1297738403081894
epoch 14000  training loss: 0.13662925362586975
epoch 14000  clean testing loss: 0.1269255131483078
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 14100  training loss: 0.13578352332115173
epoch 14100  clean testing loss: 0.12784430384635925
epoch 14200  training loss: 0.13594746589660645
epoch 14200  clean testing loss: 0.12771306931972504
epoch 14300  training loss: 0.1354718953371048

  5%|▌         | 15304/300000 [00:48<09:25, 503.10it/s]
epoch 14400  training loss: 0.13471464812755585
epoch 14400  clean testing loss: 0.12946045398712158
epoch 14500  training loss: 0.13468849658966064
epoch 14500  clean testing loss: 0.13215404748916626
epoch 14600  training loss: 0.13424469530582428
epoch 14600  clean testing loss: 0.12966705858707428
epoch 14700  training loss: 0.1336275339126587
epoch 14700  clean testing loss: 0.13308000564575195
epoch 14800  training loss: 0.13304737210273743
epoch 14800  clean testing loss: 0.13195303082466125
epoch 14900  training loss: 0.1329987496137619
epoch 14900  clean testing loss: 0.1342054158449173
epoch 15000  training loss: 0.1326301395893097
epoch 15000  clean testing loss: 0.13222689926624298
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 15100  training loss: 0.1319698691368103
epoch 15100  clean testing loss: 0.13302859663963318
epoch 15200  training loss: 0.13168777525424957
epoch 15200  clean testing loss: 0.13398443162441254
epoch 15300  training loss: 0.13146086037158966

  5%|▌         | 16336/300000 [00:50<09:23, 503.37it/s]
epoch 15400  training loss: 0.1311500370502472
epoch 15400  clean testing loss: 0.1341273933649063
epoch 15500  training loss: 0.13116317987442017
epoch 15500  clean testing loss: 0.13356345891952515
epoch 15600  training loss: 0.1306995153427124
epoch 15600  clean testing loss: 0.13449016213417053
epoch 15700  training loss: 0.1302977055311203
epoch 15700  clean testing loss: 0.13714788854122162
epoch 15800  training loss: 0.12987974286079407
epoch 15800  clean testing loss: 0.13728277385234833
epoch 15900  training loss: 0.1295139342546463
epoch 15900  clean testing loss: 0.13674311339855194
epoch 16000  training loss: 0.1294069141149521
epoch 16000  clean testing loss: 0.135904923081398
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 16100  training loss: 0.12889191508293152
epoch 16100  clean testing loss: 0.1377497911453247
epoch 16200  training loss: 0.128626748919487
epoch 16200  clean testing loss: 0.13782288134098053
epoch 16300  training loss: 0.128572016954422
epoch 16300  clean testing loss: 0.13732445240020752
epoch 16400  training loss: 0.12804816663265228

  6%|▌         | 17315/300000 [00:52<09:19, 505.28it/s]
epoch 16500  training loss: 0.12808184325695038
epoch 16500  clean testing loss: 0.13808588683605194
epoch 16600  training loss: 0.12747085094451904
epoch 16600  clean testing loss: 0.13934862613677979
epoch 16700  training loss: 0.12772239744663239
epoch 16700  clean testing loss: 0.138824462890625
epoch 16800  training loss: 0.12692131102085114
epoch 16800  clean testing loss: 0.13975998759269714
epoch 16900  training loss: 0.1267138123512268
epoch 16900  clean testing loss: 0.14099353551864624
epoch 17000  training loss: 0.12678951025009155
epoch 17000  clean testing loss: 0.14293046295642853
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 17100  training loss: 0.12618295848369598
epoch 17100  clean testing loss: 0.14039398729801178
epoch 17200  training loss: 0.12601351737976074
epoch 17200  clean testing loss: 0.14227774739265442
epoch 17300  training loss: 0.12594783306121826
epoch 17300  clean testing loss: 0.14070209860801697
epoch 17400  training loss: 0.12546850740909576

  6%|▌         | 18294/300000 [00:54<11:10, 420.27it/s]
epoch 17500  training loss: 0.12537044286727905
epoch 17500  clean testing loss: 0.14166617393493652
epoch 17600  training loss: 0.12490421533584595
epoch 17600  clean testing loss: 0.1427306979894638
epoch 17700  training loss: 0.12502703070640564
epoch 17700  clean testing loss: 0.14203788340091705
epoch 17800  training loss: 0.1244606301188469
epoch 17800  clean testing loss: 0.1447497308254242
epoch 17900  training loss: 0.12414313852787018
epoch 17900  clean testing loss: 0.14335541427135468
epoch 18000  training loss: 0.12398651987314224
epoch 18000  clean testing loss: 0.14443720877170563
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 18100  training loss: 0.12366601824760437
epoch 18100  clean testing loss: 0.14448221027851105
epoch 18200  training loss: 0.12349945306777954
epoch 18200  clean testing loss: 0.1444108635187149
epoch 18300  training loss: 0.12326883524656296

  6%|▋         | 19319/300000 [00:56<09:15, 505.23it/s]
epoch 18400  training loss: 0.1232939064502716
epoch 18400  clean testing loss: 0.1468203216791153
epoch 18500  training loss: 0.12309557944536209
epoch 18500  clean testing loss: 0.14715605974197388
epoch 18600  training loss: 0.12262163311243057
epoch 18600  clean testing loss: 0.1460018754005432
epoch 18700  training loss: 0.12258342653512955
epoch 18700  clean testing loss: 0.1457740217447281
epoch 18800  training loss: 0.12224742770195007
epoch 18800  clean testing loss: 0.14781449735164642
epoch 18900  training loss: 0.12225227802991867
epoch 18900  clean testing loss: 0.14626792073249817
epoch 19000  training loss: 0.12178181856870651
epoch 19000  clean testing loss: 0.14734531939029694
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 19100  training loss: 0.12202892452478409
epoch 19100  clean testing loss: 0.14668738842010498
epoch 19200  training loss: 0.12137769907712936
epoch 19200  clean testing loss: 0.14839597046375275
epoch 19300  training loss: 0.12129651755094528
epoch 19300  clean testing loss: 0.1494692862033844
epoch 19400  training loss: 0.12114738672971725

  7%|▋         | 20356/300000 [00:58<09:09, 508.69it/s]
epoch 19500  training loss: 0.12096051126718521
epoch 19500  clean testing loss: 0.1485193818807602
epoch 19600  training loss: 0.12058825045824051
epoch 19600  clean testing loss: 0.1505146622657776
epoch 19700  training loss: 0.12037001550197601
epoch 19700  clean testing loss: 0.15011541545391083
epoch 19800  training loss: 0.12054900079965591
epoch 19800  clean testing loss: 0.149346724152565
epoch 19900  training loss: 0.12043669074773788
epoch 19900  clean testing loss: 0.1494024395942688
epoch 20000  training loss: 0.11999266594648361
epoch 20000  clean testing loss: 0.15012921392917633
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 20100  training loss: 0.1197715476155281
epoch 20100  clean testing loss: 0.15245355665683746
epoch 20200  training loss: 0.11962665617465973
epoch 20200  clean testing loss: 0.1508685052394867
epoch 20300  training loss: 0.11924712359905243

  7%|▋         | 21337/300000 [01:00<09:09, 506.97it/s]
epoch 20400  training loss: 0.11925306916236877
epoch 20400  clean testing loss: 0.15425091981887817
epoch 20500  training loss: 0.11882361769676208
epoch 20500  clean testing loss: 0.15320448577404022
epoch 20600  training loss: 0.11870166659355164
epoch 20600  clean testing loss: 0.15360113978385925
epoch 20700  training loss: 0.11873756349086761
epoch 20700  clean testing loss: 0.15511871874332428
epoch 20800  training loss: 0.1182880774140358
epoch 20800  clean testing loss: 0.15341168642044067
epoch 20900  training loss: 0.11824698746204376
epoch 20900  clean testing loss: 0.15512751042842865
epoch 21000  training loss: 0.11827284842729568
epoch 21000  clean testing loss: 0.15348437428474426
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 21100  training loss: 0.11772438883781433
epoch 21100  clean testing loss: 0.15424083173274994
epoch 21200  training loss: 0.11758388578891754
epoch 21200  clean testing loss: 0.15469954907894135
epoch 21300  training loss: 0.11742546409368515
epoch 21300  clean testing loss: 0.15503914654254913
epoch 21400  training loss: 0.1173291802406311

  7%|▋         | 22370/300000 [01:02<09:06, 507.83it/s]
epoch 21500  training loss: 0.11710519343614578
epoch 21500  clean testing loss: 0.15623243153095245
epoch 21600  training loss: 0.1170656606554985
epoch 21600  clean testing loss: 0.15721413493156433
epoch 21700  training loss: 0.11679147928953171
epoch 21700  clean testing loss: 0.15710574388504028
epoch 21800  training loss: 0.11660239100456238
epoch 21800  clean testing loss: 0.15684466063976288
epoch 21900  training loss: 0.11648481339216232
epoch 21900  clean testing loss: 0.15660300850868225
epoch 22000  training loss: 0.11626619845628738
epoch 22000  clean testing loss: 0.15738022327423096
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 22100  training loss: 0.11610960960388184
epoch 22100  clean testing loss: 0.15750595927238464
epoch 22200  training loss: 0.1159883663058281
epoch 22200  clean testing loss: 0.1586553156375885
epoch 22300  training loss: 0.11579575389623642
epoch 22300  clean testing loss: 0.15879206359386444
epoch 22400  training loss: 0.11579430103302002

  8%|▊         | 23401/300000 [01:04<09:08, 504.45it/s]
epoch 22500  training loss: 0.11549404263496399
epoch 22500  clean testing loss: 0.1585087925195694
epoch 22600  training loss: 0.11532332748174667
epoch 22600  clean testing loss: 0.15964069962501526
epoch 22700  training loss: 0.1151963546872139
epoch 22700  clean testing loss: 0.15919022262096405
epoch 22800  training loss: 0.1152288094162941
epoch 22800  clean testing loss: 0.1611107736825943
epoch 22900  training loss: 0.11484957486391068
epoch 22900  clean testing loss: 0.16075092554092407
epoch 23000  training loss: 0.11475417017936707
epoch 23000  clean testing loss: 0.1610817164182663
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 23100  training loss: 0.11461056768894196
epoch 23100  clean testing loss: 0.16140632331371307
epoch 23200  training loss: 0.11458718031644821
epoch 23200  clean testing loss: 0.160207137465477
epoch 23300  training loss: 0.11450212448835373
epoch 23300  clean testing loss: 0.16042672097682953
epoch 23400  training loss: 0.11411106586456299

  8%|▊         | 24385/300000 [01:06<09:02, 508.31it/s]
epoch 23500  training loss: 0.11390792578458786
epoch 23500  clean testing loss: 0.16187022626399994
epoch 23600  training loss: 0.11396602541208267
epoch 23600  clean testing loss: 0.1616053581237793
epoch 23700  training loss: 0.11377733200788498
epoch 23700  clean testing loss: 0.16184550523757935
epoch 23800  training loss: 0.11343894153833389
epoch 23800  clean testing loss: 0.16268737614154816
epoch 23900  training loss: 0.11358275264501572
epoch 23900  clean testing loss: 0.16458021104335785
epoch 24000  training loss: 0.11327236145734787
epoch 24000  clean testing loss: 0.16417783498764038
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 24100  training loss: 0.11300905048847198
epoch 24100  clean testing loss: 0.16398856043815613
epoch 24200  training loss: 0.11288928240537643
epoch 24200  clean testing loss: 0.16383354365825653
epoch 24300  training loss: 0.11274277418851852
epoch 24300  clean testing loss: 0.16422493755817413
epoch 24400  training loss: 0.1126185730099678

  8%|▊         | 25417/300000 [01:08<09:03, 504.75it/s]
epoch 24500  training loss: 0.11265377700328827
epoch 24500  clean testing loss: 0.16583654284477234
epoch 24600  training loss: 0.11234929412603378
epoch 24600  clean testing loss: 0.16481433808803558
epoch 24700  training loss: 0.11236397176980972
epoch 24700  clean testing loss: 0.164678156375885
epoch 24800  training loss: 0.11214665323495865
epoch 24800  clean testing loss: 0.1653972566127777
epoch 24900  training loss: 0.1120414212346077
epoch 24900  clean testing loss: 0.16544151306152344
epoch 25000  training loss: 0.111955925822258
epoch 25000  clean testing loss: 0.16738498210906982
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 25100  training loss: 0.11168495565652847
epoch 25100  clean testing loss: 0.16651147603988647
epoch 25200  training loss: 0.11165627837181091
epoch 25200  clean testing loss: 0.1661643385887146
epoch 25300  training loss: 0.11141791194677353
epoch 25300  clean testing loss: 0.1672603040933609
epoch 25400  training loss: 0.11144459247589111

  9%|▉         | 26453/300000 [01:10<08:58, 507.62it/s]
epoch 25500  training loss: 0.11122290790081024
epoch 25500  clean testing loss: 0.16850237548351288
epoch 25600  training loss: 0.11111048609018326
epoch 25600  clean testing loss: 0.16769720613956451
epoch 25700  training loss: 0.11086191236972809
epoch 25700  clean testing loss: 0.16872090101242065
epoch 25800  training loss: 0.11087732017040253
epoch 25800  clean testing loss: 0.1700502187013626
epoch 25900  training loss: 0.11061017960309982
epoch 25900  clean testing loss: 0.16892603039741516
epoch 26000  training loss: 0.11068840324878693
epoch 26000  clean testing loss: 0.168529212474823
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 26100  training loss: 0.11045641452074051
epoch 26100  clean testing loss: 0.17051194608211517
epoch 26200  training loss: 0.11026822775602341
epoch 26200  clean testing loss: 0.17052243649959564
epoch 26300  training loss: 0.11015861481428146
epoch 26300  clean testing loss: 0.17084626853466034
epoch 26400  training loss: 0.11011820286512375
epoch 26400  clean testing loss: 0.16967037320137024
epoch 26500  training loss: 0.10991046577692032

  9%|▉         | 27436/300000 [01:12<08:58, 506.13it/s]
epoch 26600  training loss: 0.1098162904381752
epoch 26600  clean testing loss: 0.1704377830028534
epoch 26700  training loss: 0.10967087000608444
epoch 26700  clean testing loss: 0.1715194135904312
epoch 26800  training loss: 0.10960227996110916
epoch 26800  clean testing loss: 0.17214053869247437
epoch 26900  training loss: 0.10951801389455795
epoch 26900  clean testing loss: 0.17257650196552277
epoch 27000  training loss: 0.10929898917675018
epoch 27000  clean testing loss: 0.1717425137758255
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 27100  training loss: 0.10916213691234589
epoch 27100  clean testing loss: 0.1720091998577118
epoch 27200  training loss: 0.10905937105417252
epoch 27200  clean testing loss: 0.17219358682632446
epoch 27300  training loss: 0.10895989090204239
epoch 27300  clean testing loss: 0.17217984795570374
epoch 27400  training loss: 0.10886935144662857
epoch 27400  clean testing loss: 0.1722613275051117
epoch 27500  training loss: 0.10876508802175522

  9%|▉         | 28468/300000 [01:14<08:52, 510.28it/s]
epoch 27600  training loss: 0.10864293575286865
epoch 27600  clean testing loss: 0.17298708856105804
epoch 27700  training loss: 0.10852228105068207
epoch 27700  clean testing loss: 0.17304334044456482
epoch 27800  training loss: 0.10851317644119263
epoch 27800  clean testing loss: 0.17476408183574677
epoch 27900  training loss: 0.10828353464603424
epoch 27900  clean testing loss: 0.17419208586215973
epoch 28000  training loss: 0.1081756204366684
epoch 28000  clean testing loss: 0.17402321100234985
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 28100  training loss: 0.10808037966489792
epoch 28100  clean testing loss: 0.17459982633590698
epoch 28200  training loss: 0.10800323635339737
epoch 28200  clean testing loss: 0.17487148940563202
epoch 28300  training loss: 0.10795262455940247
epoch 28300  clean testing loss: 0.17409345507621765
epoch 28400  training loss: 0.10790710896253586
epoch 28400  clean testing loss: 0.17429183423519135
epoch 28500  training loss: 0.10768017917871475

 10%|▉         | 29501/300000 [01:16<08:55, 505.00it/s]
epoch 28600  training loss: 0.1075960099697113
epoch 28600  clean testing loss: 0.17490604519844055
epoch 28700  training loss: 0.1076013445854187
epoch 28700  clean testing loss: 0.17487384378910065
epoch 28800  training loss: 0.10733582079410553
epoch 28800  clean testing loss: 0.17656101286411285
epoch 28900  training loss: 0.10725000500679016
epoch 28900  clean testing loss: 0.17573045194149017
epoch 29000  training loss: 0.10724854469299316
epoch 29000  clean testing loss: 0.17760244011878967
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 29100  training loss: 0.10707440972328186
epoch 29100  clean testing loss: 0.1760825365781784
epoch 29200  training loss: 0.10699991881847382
epoch 29200  clean testing loss: 0.17819763720035553
epoch 29300  training loss: 0.10679423809051514
epoch 29300  clean testing loss: 0.17697562277317047
epoch 29400  training loss: 0.10667846351861954
epoch 29400  clean testing loss: 0.17682763934135437
epoch 29500  training loss: 0.10655038803815842

 10%|█         | 30483/300000 [01:18<08:50, 508.44it/s]
epoch 29600  training loss: 0.10649339109659195
epoch 29600  clean testing loss: 0.17852161824703217
epoch 29700  training loss: 0.10634211450815201
epoch 29700  clean testing loss: 0.17781956493854523
epoch 29800  training loss: 0.10622484236955643
epoch 29800  clean testing loss: 0.17883163690567017
epoch 29900  training loss: 0.10625554621219635
epoch 29900  clean testing loss: 0.17773190140724182
epoch 30000  training loss: 0.10597244650125504
epoch 30000  clean testing loss: 0.17895367741584778
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 30100  training loss: 0.10586761683225632
epoch 30100  clean testing loss: 0.17905281484127045
epoch 30200  training loss: 0.10577686131000519
epoch 30200  clean testing loss: 0.17932960391044617
epoch 30300  training loss: 0.10570314526557922
epoch 30300  clean testing loss: 0.17998914420604706
epoch 30400  training loss: 0.10561675578355789
epoch 30400  clean testing loss: 0.17930133640766144
epoch 30500  training loss: 0.10554864257574081

 11%|█         | 31515/300000 [01:20<08:52, 504.25it/s]
epoch 30600  training loss: 0.10545532405376434
epoch 30600  clean testing loss: 0.17969399690628052
epoch 30700  training loss: 0.1053214892745018
epoch 30700  clean testing loss: 0.17992909252643585
epoch 30800  training loss: 0.10522536188364029
epoch 30800  clean testing loss: 0.18079449236392975
epoch 30900  training loss: 0.1051286980509758
epoch 30900  clean testing loss: 0.18108394742012024
epoch 31000  training loss: 0.10502345860004425
epoch 31000  clean testing loss: 0.18143433332443237
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 31100  training loss: 0.10494821518659592
epoch 31100  clean testing loss: 0.1815660446882248
epoch 31200  training loss: 0.10483600199222565
epoch 31200  clean testing loss: 0.1813390552997589
epoch 31300  training loss: 0.10475906729698181
epoch 31300  clean testing loss: 0.18134796619415283
epoch 31400  training loss: 0.10463034361600876
epoch 31400  clean testing loss: 0.1817854642868042
epoch 31500  training loss: 0.10454590618610382

 11%|█         | 32496/300000 [01:22<08:46, 508.09it/s]
epoch 31600  training loss: 0.1044873371720314
epoch 31600  clean testing loss: 0.18165208399295807
epoch 31700  training loss: 0.10443621128797531
epoch 31700  clean testing loss: 0.18167385458946228
epoch 31800  training loss: 0.10423026233911514
epoch 31800  clean testing loss: 0.18237656354904175
epoch 31900  training loss: 0.10416659712791443
epoch 31900  clean testing loss: 0.1822766661643982
epoch 32000  training loss: 0.10404953360557556
epoch 32000  clean testing loss: 0.18343570828437805
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 32100  training loss: 0.10397236049175262
epoch 32100  clean testing loss: 0.18340860307216644
epoch 32200  training loss: 0.10388806462287903
epoch 32200  clean testing loss: 0.18285411596298218
epoch 32300  training loss: 0.10379800945520401
epoch 32300  clean testing loss: 0.18425299227237701
epoch 32400  training loss: 0.10366536676883698
epoch 32400  clean testing loss: 0.18362697958946228
epoch 32500  training loss: 0.10364802181720734

 11%|█         | 32547/300000 [01:22<08:49, 505.46it/s]
epoch 32600  training loss: 0.10354871302843094
epoch 32600  clean testing loss: 0.1847408264875412
epoch 32700  training loss: 0.10343906283378601
epoch 32700  clean testing loss: 0.18494851887226105
epoch 32800  training loss: 0.10337764769792557
epoch 32800  clean testing loss: 0.18566453456878662
epoch 32900  training loss: 0.10323228687047958
epoch 32900  clean testing loss: 0.18521742522716522
epoch 33000  training loss: 0.1031370460987091
epoch 33000  clean testing loss: 0.1849183887243271
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 33100  training loss: 0.10306213796138763
epoch 33100  clean testing loss: 0.185316801071167
epoch 33200  training loss: 0.10299105197191238
epoch 33200  clean testing loss: 0.1852906346321106
epoch 33300  training loss: 0.10291330516338348
epoch 33300  clean testing loss: 0.18529440462589264
epoch 33400  training loss: 0.10284018516540527

 11%|█         | 33372/300000 [01:28<09:20, 475.46it/s]
epoch 33500  training loss: 0.10278698801994324
epoch 33500  clean testing loss: 0.18646986782550812
epoch 33600  training loss: 0.10269692540168762
epoch 33600  clean testing loss: 0.18645966053009033
epoch 33700  training loss: 0.10261403024196625
epoch 33700  clean testing loss: 0.1869935691356659
epoch 33800  training loss: 0.10250398516654968
epoch 33800  clean testing loss: 0.18711671233177185
epoch 33900  training loss: 0.1023983508348465
epoch 33900  clean testing loss: 0.18738898634910583
epoch 34000  training loss: 0.10232517123222351
epoch 34000  clean testing loss: 0.18783116340637207
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 34100  training loss: 0.10221224278211594
epoch 34100  clean testing loss: 0.1878279447555542
epoch 34200  training loss: 0.10212395340204239
epoch 34200  clean testing loss: 0.18839938938617706
epoch 34300  training loss: 0.10200995206832886
epoch 34300  clean testing loss: 0.18786336481571198
epoch 34400  training loss: 0.10195419192314148

 11%|█▏        | 34354/300000 [01:30<08:55, 496.13it/s]
epoch 34500  training loss: 0.10183876007795334
epoch 34500  clean testing loss: 0.18841621279716492
epoch 34600  training loss: 0.10177282243967056
epoch 34600  clean testing loss: 0.1885066032409668
epoch 34700  training loss: 0.10167505592107773
epoch 34700  clean testing loss: 0.1895018368959427
epoch 34800  training loss: 0.10161581635475159
epoch 34800  clean testing loss: 0.1893002986907959
epoch 34900  training loss: 0.10158339142799377
epoch 34900  clean testing loss: 0.1905444711446762
epoch 35000  training loss: 0.10142771899700165
epoch 35000  clean testing loss: 0.19055986404418945
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 35100  training loss: 0.10138177871704102
epoch 35100  clean testing loss: 0.18994462490081787
epoch 35200  training loss: 0.10127291083335876
epoch 35200  clean testing loss: 0.19011405110359192
epoch 35300  training loss: 0.101188525557518
epoch 35300  clean testing loss: 0.19140741229057312
epoch 35400  training loss: 0.10113119333982468

 12%|█▏        | 35391/300000 [01:32<08:38, 510.72it/s]
epoch 35500  training loss: 0.10102368891239166
epoch 35500  clean testing loss: 0.19113172590732574
epoch 35600  training loss: 0.10099376738071442
epoch 35600  clean testing loss: 0.19242869317531586
epoch 35700  training loss: 0.10091324150562286
epoch 35700  clean testing loss: 0.19253794848918915
epoch 35800  training loss: 0.10078248381614685
epoch 35800  clean testing loss: 0.19163088500499725
epoch 35900  training loss: 0.10076893866062164
epoch 35900  clean testing loss: 0.19176676869392395
epoch 36000  training loss: 0.1006653755903244
epoch 36000  clean testing loss: 0.1920119673013687
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 36100  training loss: 0.10054854303598404
epoch 36100  clean testing loss: 0.192550927400589
epoch 36200  training loss: 0.10048377513885498
epoch 36200  clean testing loss: 0.19273823499679565
epoch 36300  training loss: 0.10043317079544067
epoch 36300  clean testing loss: 0.1927179992198944
epoch 36400  training loss: 0.1003730371594429

 12%|█▏        | 36373/300000 [01:34<08:37, 509.73it/s]
epoch 36500  training loss: 0.10028113424777985
epoch 36500  clean testing loss: 0.192996084690094
epoch 36600  training loss: 0.10020438581705093
epoch 36600  clean testing loss: 0.19361771643161774
epoch 36700  training loss: 0.10013414174318314
epoch 36700  clean testing loss: 0.19340647757053375
epoch 36800  training loss: 0.1000879630446434
epoch 36800  clean testing loss: 0.19353199005126953
epoch 36900  training loss: 0.1000225692987442
epoch 36900  clean testing loss: 0.1934526413679123
epoch 37000  training loss: 0.09992728382349014
epoch 37000  clean testing loss: 0.19445101916790009
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 37100  training loss: 0.09986510872840881
epoch 37100  clean testing loss: 0.1941390484571457
epoch 37200  training loss: 0.09977803379297256
epoch 37200  clean testing loss: 0.19452564418315887
epoch 37300  training loss: 0.0997101217508316
epoch 37300  clean testing loss: 0.19489319622516632
epoch 37400  training loss: 0.09968230128288269
epoch 37400  clean testing loss: 0.19539225101470947
epoch 37500  training loss: 0.09960255026817322

 12%|█▏        | 37402/300000 [01:36<08:40, 504.87it/s]
epoch 37600  training loss: 0.09955385327339172
epoch 37600  clean testing loss: 0.19474992156028748
epoch 37700  training loss: 0.09944052994251251
epoch 37700  clean testing loss: 0.19538314640522003
epoch 37800  training loss: 0.09937331825494766
epoch 37800  clean testing loss: 0.19562745094299316
epoch 37900  training loss: 0.09930296242237091
epoch 37900  clean testing loss: 0.1959846168756485
epoch 38000  training loss: 0.09928169846534729
epoch 38000  clean testing loss: 0.19649836421012878
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 38100  training loss: 0.09917985647916794
epoch 38100  clean testing loss: 0.19630087912082672
epoch 38200  training loss: 0.09908804297447205
epoch 38200  clean testing loss: 0.1959908902645111
epoch 38300  training loss: 0.09901757538318634
epoch 38300  clean testing loss: 0.196319118142128
epoch 38400  training loss: 0.0989590510725975
epoch 38400  clean testing loss: 0.19687139987945557
epoch 38500  training loss: 0.09891629219055176

 13%|█▎        | 38433/300000 [01:38<08:35, 507.41it/s]
epoch 38600  training loss: 0.09884219616651535
epoch 38600  clean testing loss: 0.19654279947280884
epoch 38700  training loss: 0.09879551827907562
epoch 38700  clean testing loss: 0.19763188064098358
epoch 38800  training loss: 0.09868478029966354
epoch 38800  clean testing loss: 0.19720643758773804
epoch 38900  training loss: 0.09864764660596848
epoch 38900  clean testing loss: 0.19709141552448273
epoch 39000  training loss: 0.0985855907201767
epoch 39000  clean testing loss: 0.19725938141345978
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise3.00e-01_invop0 ...
epoch 39100  training loss: 0.0984877198934555
epoch 39100  clean testing loss: 0.19769629836082458
Validation loss variation < 1e-6, trained to interpolation, stop

 13%|█▎        | 39100/300000 [01:39<11:04, 392.90it/s]