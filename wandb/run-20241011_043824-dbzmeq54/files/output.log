epoch 0  training loss: 54.610782623291016
epoch 0  clean testing loss: 49.304237365722656
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
  0%|                                                                               | 0/100000 [00:00<?, ?it/s]
epoch 100  training loss: 17.053260803222656

  0%|                                                                     | 162/100000 [00:02<20:25, 81.44it/s]
epoch 200  training loss: 15.606752395629883
epoch 200  clean testing loss: 15.807065963745117
epoch 300  training loss: 14.475302696228027

  0%|▏                                                                    | 324/100000 [00:04<20:24, 81.40it/s]
epoch 400  training loss: 13.030570983886719

  0%|▎                                                                    | 486/100000 [00:06<20:18, 81.68it/s]
epoch 500  training loss: 10.3029146194458
epoch 500  clean testing loss: 10.478377342224121
epoch 600  training loss: 4.961684703826904

  1%|▍                                                                    | 648/100000 [00:08<20:21, 81.35it/s]
epoch 700  training loss: 1.9392147064208984
epoch 700  clean testing loss: 1.3498715162277222
epoch 800  training loss: 1.3947466611862183

  1%|▌                                                                    | 819/100000 [00:10<20:12, 81.77it/s]
epoch 900  training loss: 1.1081072092056274

  1%|▋                                                                    | 981/100000 [00:12<20:13, 81.58it/s]
epoch 1000  training loss: 0.9774173498153687
epoch 1000  clean testing loss: 0.5538582801818848
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 1100  training loss: 0.8866899013519287

  1%|▊                                                                   | 1134/100000 [00:14<21:00, 78.42it/s]
epoch 1200  training loss: 0.8272470235824585
epoch 1200  clean testing loss: 0.4641839861869812
epoch 1300  training loss: 0.8002619743347168

  1%|▉                                                                   | 1305/100000 [00:16<20:07, 81.70it/s]
epoch 1400  training loss: 0.7712647914886475

  1%|▉                                                                   | 1467/100000 [00:18<19:54, 82.46it/s]
epoch 1500  training loss: 0.7230218052864075
epoch 1500  clean testing loss: 0.41559621691703796
epoch 1600  training loss: 0.6980079412460327

  2%|█                                                                   | 1629/100000 [00:20<20:19, 80.65it/s]
epoch 1700  training loss: 0.6686943769454956

  2%|█▏                                                                  | 1791/100000 [00:22<19:56, 82.06it/s]
epoch 1800  training loss: 0.6589030027389526
epoch 1800  clean testing loss: 0.4619239866733551
epoch 1900  training loss: 0.6537279486656189

  2%|█▎                                                                  | 1953/100000 [00:24<19:54, 82.07it/s]
epoch 2000  training loss: 0.6268323063850403
epoch 2000  clean testing loss: 0.46128222346305847
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 2100  training loss: 0.6394691467285156

  2%|█▍                                                                  | 2124/100000 [00:26<19:51, 82.13it/s]
epoch 2200  training loss: 0.6225212812423706

  2%|█▌                                                                  | 2276/100000 [00:28<20:37, 78.97it/s]
epoch 2300  training loss: 0.6411961317062378
epoch 2300  clean testing loss: 0.47899329662323
epoch 2400  training loss: 0.6353380680084229

  2%|█▋                                                                  | 2437/100000 [00:30<21:24, 75.94it/s]
epoch 2500  training loss: 0.590743899345398

  3%|█▊                                                                  | 2589/100000 [00:32<21:45, 74.63it/s]
epoch 2600  training loss: 0.6065049171447754
epoch 2600  clean testing loss: 0.5611842274665833
epoch 2700  training loss: 0.5764163136482239


  3%|█▉                                                                  | 2893/100000 [00:36<22:24, 72.25it/s]
epoch 2800  training loss: 0.6201925277709961

  3%|██                                                                  | 3020/100000 [00:38<25:01, 64.58it/s]
epoch 2900  training loss: 0.6021614074707031
epoch 2900  clean testing loss: 0.6031058430671692
epoch 3000  training loss: 0.5913691520690918
epoch 3000  clean testing loss: 0.5913265347480774

  3%|██▏                                                                 | 3153/100000 [00:40<24:47, 65.10it/s]
epoch 3100  training loss: 0.5753923654556274

  3%|██▏                                                                 | 3286/100000 [00:42<24:40, 65.33it/s]
epoch 3200  training loss: 0.5730203986167908

  3%|██▎                                                                 | 3412/100000 [00:44<24:39, 65.29it/s]
epoch 3300  training loss: 0.5451334714889526
epoch 3300  clean testing loss: 0.6412014365196228
epoch 3400  training loss: 0.5325087308883667

  4%|██▍                                                                 | 3545/100000 [00:46<24:31, 65.55it/s]
epoch 3500  training loss: 0.5328347682952881

  4%|██▌                                                                 | 3678/100000 [00:48<24:31, 65.46it/s]
epoch 3600  training loss: 0.5538893938064575

  4%|██▌                                                                 | 3804/100000 [00:50<24:31, 65.37it/s]
epoch 3700  training loss: 0.5430262684822083
epoch 3700  clean testing loss: 0.6129212975502014
epoch 3800  training loss: 0.5349417924880981

  4%|██▋                                                                 | 3937/100000 [00:52<24:16, 65.98it/s]
epoch 3900  training loss: 0.5372267365455627

  4%|██▊                                                                 | 4070/100000 [00:54<24:25, 65.47it/s]
epoch 4000  training loss: 0.5291216969490051
epoch 4000  clean testing loss: 0.6362782120704651

  4%|██▊                                                                 | 4196/100000 [00:56<24:26, 65.32it/s]
epoch 4100  training loss: 0.5390040874481201

  4%|██▉                                                                 | 4329/100000 [00:58<24:32, 64.97it/s]
epoch 4200  training loss: 0.5059909224510193
epoch 4200  clean testing loss: 0.6698925495147705
epoch 4300  training loss: 0.5220870971679688

  4%|███                                                                 | 4462/100000 [01:01<24:22, 65.34it/s]
epoch 4400  training loss: 0.5183768272399902

  5%|███                                                                 | 4588/100000 [01:02<24:14, 65.61it/s]
epoch 4500  training loss: 0.4782369136810303
epoch 4500  clean testing loss: 0.7038333415985107
epoch 4600  training loss: 0.5179411768913269
epoch 4600  clean testing loss: 0.7317115068435669
epoch 4700  training loss: 0.48769208788871765


  5%|███▎                                                                | 4854/100000 [01:07<24:14, 65.42it/s]
epoch 4800  training loss: 0.48507028818130493

  5%|███▍                                                                | 4980/100000 [01:08<24:29, 64.65it/s]
epoch 4900  training loss: 0.5829492211341858
epoch 4900  clean testing loss: 0.6582133769989014
epoch 5000  training loss: 0.5442972779273987
epoch 5000  clean testing loss: 0.7030525207519531
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 5100  training loss: 0.5225062370300293


  5%|███▌                                                                | 5246/100000 [01:13<24:10, 65.32it/s]
epoch 5200  training loss: 0.515404224395752
epoch 5200  clean testing loss: 0.7074356079101562
epoch 5300  training loss: 0.4944820702075958


  6%|███▋                                                                | 5505/100000 [01:17<24:34, 64.09it/s]
epoch 5400  training loss: 0.4886898100376129
epoch 5400  clean testing loss: 0.7391035556793213
epoch 5500  training loss: 0.519468367099762
epoch 5500  clean testing loss: 0.7581621408462524
epoch 5600  training loss: 0.5038828253746033

  6%|███▊                                                                | 5631/100000 [01:18<24:01, 65.46it/s]
epoch 5700  training loss: 0.6516706943511963

  6%|███▉                                                                | 5764/100000 [01:21<24:19, 64.59it/s]
epoch 5800  training loss: 0.5904766917228699

  6%|████                                                                | 5897/100000 [01:23<23:46, 65.95it/s]
epoch 5900  training loss: 0.5518710017204285
epoch 5900  clean testing loss: 0.6827415823936462
epoch 6000  training loss: 0.5503876209259033
epoch 6000  clean testing loss: 0.704356849193573

  6%|████                                                                | 6023/100000 [01:25<24:06, 64.98it/s]
epoch 6100  training loss: 0.5145025849342346


  6%|████▎                                                               | 6289/100000 [01:29<24:08, 64.68it/s]
epoch 6200  training loss: 0.5175678133964539

  6%|████▎                                                               | 6415/100000 [01:31<23:48, 65.53it/s]
epoch 6300  training loss: 0.5143013000488281
epoch 6300  clean testing loss: 0.8184290528297424
epoch 6400  training loss: 0.5200525522232056

  7%|████▍                                                               | 6548/100000 [01:33<23:34, 66.09it/s]
epoch 6500  training loss: 0.5001099705696106

  7%|████▌                                                               | 6681/100000 [01:35<23:56, 64.96it/s]
epoch 6600  training loss: 0.5069907903671265

  7%|████▋                                                               | 6807/100000 [01:37<23:53, 65.01it/s]
epoch 6700  training loss: 0.5114394426345825
epoch 6700  clean testing loss: 0.7907100319862366
epoch 6800  training loss: 0.5065842866897583

  7%|████▋                                                               | 6940/100000 [01:39<23:43, 65.36it/s]
epoch 6900  training loss: 0.5246445536613464
epoch 6900  clean testing loss: 0.7723464965820312
epoch 7000  training loss: 0.4946170747280121
epoch 7000  clean testing loss: 0.8297752737998962

  7%|████▊                                                               | 7073/100000 [01:41<23:43, 65.27it/s]
epoch 7100  training loss: 0.49355658888816833

  7%|████▉                                                               | 7199/100000 [01:43<23:36, 65.51it/s]
epoch 7200  training loss: 0.5022215247154236
epoch 7200  clean testing loss: 0.7721556425094604
epoch 7300  training loss: 0.45912304520606995

  7%|████▉                                                               | 7332/100000 [01:45<23:32, 65.61it/s]
epoch 7400  training loss: 0.4526216983795166

  7%|█████                                                               | 7465/100000 [01:47<23:21, 66.03it/s]
epoch 7500  training loss: 0.49028512835502625

  8%|█████▏                                                              | 7598/100000 [01:49<23:33, 65.36it/s]
epoch 7600  training loss: 0.49042099714279175
epoch 7600  clean testing loss: 0.7718018889427185
epoch 7700  training loss: 0.46880415081977844

  8%|█████▎                                                              | 7724/100000 [01:51<23:41, 64.94it/s]
epoch 7800  training loss: 0.5126652121543884

  8%|█████▎                                                              | 7857/100000 [01:53<23:28, 65.40it/s]
epoch 7900  training loss: 0.5093110799789429

  8%|█████▍                                                              | 7990/100000 [01:55<23:38, 64.87it/s]
epoch 8000  training loss: 0.48725637793540955
epoch 8000  clean testing loss: 0.7576262354850769
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 8100  training loss: 0.4898498058319092

  8%|█████▌                                                              | 8116/100000 [01:57<23:40, 64.69it/s]
epoch 8200  training loss: 0.4813947379589081

  8%|█████▌                                                              | 8249/100000 [01:59<23:36, 64.79it/s]
epoch 8300  training loss: 0.4843020737171173

  8%|█████▋                                                              | 8375/100000 [02:01<23:43, 64.39it/s]
epoch 8400  training loss: 0.46239134669303894

  9%|█████▊                                                              | 8508/100000 [02:03<23:12, 65.71it/s]
epoch 8500  training loss: 0.45663654804229736
epoch 8500  clean testing loss: 0.9491310119628906
epoch 8600  training loss: 0.47263380885124207

  9%|█████▉                                                              | 8641/100000 [02:05<23:23, 65.08it/s]
epoch 8700  training loss: 0.4716779887676239

  9%|█████▉                                                              | 8767/100000 [02:07<23:16, 65.33it/s]
epoch 8800  training loss: 0.4688124656677246


  9%|██████▏                                                             | 9033/100000 [02:11<23:13, 65.26it/s]
epoch 8900  training loss: 0.4594708979129791
epoch 8900  clean testing loss: 0.8101925253868103
epoch 9000  training loss: 0.4562890827655792
epoch 9000  clean testing loss: 0.8627587556838989

  9%|██████▏                                                             | 9159/100000 [02:13<23:08, 65.40it/s]
epoch 9100  training loss: 0.4569524824619293

  9%|██████▎                                                             | 9292/100000 [02:15<22:59, 65.77it/s]
epoch 9200  training loss: 0.4400707483291626
epoch 9200  clean testing loss: 0.8660033941268921
epoch 9300  training loss: 0.462049275636673
epoch 9300  clean testing loss: 0.8515647649765015
epoch 9400  training loss: 0.45118096470832825


 10%|██████▍                                                             | 9551/100000 [02:19<23:08, 65.16it/s]
epoch 9500  training loss: 0.45689481496810913

 10%|██████▌                                                             | 9684/100000 [02:21<23:31, 63.99it/s]
epoch 9600  training loss: 0.4404086768627167
epoch 9600  clean testing loss: 0.8550422191619873
epoch 9700  training loss: 0.4612979292869568
epoch 9700  clean testing loss: 0.8390921354293823
epoch 9800  training loss: 0.4672665297985077

 10%|██████▋                                                             | 9810/100000 [02:23<23:23, 64.25it/s]
epoch 9900  training loss: 0.444959819316864


 10%|██████▊                                                            | 10076/100000 [02:27<23:12, 64.56it/s]
epoch 10000  training loss: 0.42514240741729736
epoch 10000  clean testing loss: 0.8798431754112244

 10%|██████▊                                                            | 10202/100000 [02:29<22:48, 65.63it/s]
epoch 10100  training loss: 0.4328416883945465
epoch 10100  clean testing loss: 0.8735528588294983
epoch 10200  training loss: 0.4281182289123535

 10%|██████▉                                                            | 10335/100000 [02:31<22:55, 65.20it/s]
epoch 10300  training loss: 0.43542107939720154

 10%|███████                                                            | 10468/100000 [02:33<22:35, 66.07it/s]
epoch 10400  training loss: 0.4443608522415161

 11%|███████                                                            | 10594/100000 [02:35<22:39, 65.78it/s]
epoch 10500  training loss: 0.41760551929473877
epoch 10500  clean testing loss: 0.8951509594917297
epoch 10600  training loss: 0.4588792026042938

 11%|███████▏                                                           | 10727/100000 [02:37<22:26, 66.30it/s]
epoch 10700  training loss: 0.430614709854126

 11%|███████▎                                                           | 10860/100000 [02:39<22:42, 65.44it/s]
epoch 10800  training loss: 0.46528249979019165

 11%|███████▎                                                           | 10993/100000 [02:41<22:39, 65.46it/s]
epoch 10900  training loss: 0.41694334149360657
epoch 10900  clean testing loss: 0.8625856041908264
epoch 11000  training loss: 0.4407693147659302
epoch 11000  clean testing loss: 0.9070221185684204

 11%|███████▍                                                           | 11119/100000 [02:43<22:33, 65.68it/s]
epoch 11100  training loss: 0.41770365834236145

 11%|███████▌                                                           | 11252/100000 [02:45<22:41, 65.17it/s]
epoch 11200  training loss: 0.42923209071159363

 11%|███████▋                                                           | 11385/100000 [02:47<22:36, 65.33it/s]
epoch 11300  training loss: 0.4251597225666046

 12%|███████▋                                                           | 11511/100000 [02:49<22:53, 64.44it/s]
epoch 11400  training loss: 0.4393768608570099
epoch 11400  clean testing loss: 0.9078277945518494
epoch 11500  training loss: 0.42595815658569336
epoch 11500  clean testing loss: 0.8676789402961731
epoch 11600  training loss: 0.45039817690849304

 12%|███████▊                                                           | 11644/100000 [02:51<22:28, 65.50it/s]
epoch 11700  training loss: 0.45120230317115784

 12%|███████▉                                                           | 11777/100000 [02:53<23:13, 63.29it/s]
epoch 11800  training loss: 0.4336303472518921
epoch 11800  clean testing loss: 0.7877103686332703
epoch 11900  training loss: 0.4373287856578827

 12%|███████▉                                                           | 11903/100000 [02:55<22:20, 65.71it/s]
epoch 12000  training loss: 0.42455899715423584
epoch 12000  clean testing loss: 0.8571453094482422


 12%|████████▏                                                          | 12169/100000 [02:59<22:32, 64.94it/s]
epoch 12100  training loss: 0.43740108609199524

 12%|████████▏                                                          | 12295/100000 [03:01<22:22, 65.33it/s]
epoch 12200  training loss: 0.42116814851760864
epoch 12200  clean testing loss: 0.9226234555244446
epoch 12300  training loss: 0.4165722131729126
epoch 12300  clean testing loss: 0.8863760232925415
epoch 12400  training loss: 0.4037247598171234

 12%|████████▎                                                          | 12428/100000 [03:03<22:34, 64.66it/s]
epoch 12500  training loss: 0.4163338840007782


 13%|████████▌                                                          | 12687/100000 [03:07<22:09, 65.67it/s]
epoch 12600  training loss: 0.40693479776382446
epoch 12600  clean testing loss: 0.8938888311386108
epoch 12700  training loss: 0.4419917166233063

 13%|████████▌                                                          | 12820/100000 [03:09<22:21, 64.98it/s]
epoch 12800  training loss: 0.4321974217891693
epoch 12800  clean testing loss: 0.9648204445838928
epoch 12900  training loss: 0.4034493863582611

 13%|████████▋                                                          | 12953/100000 [03:11<22:06, 65.62it/s]
epoch 13000  training loss: 0.4232063591480255
epoch 13000  clean testing loss: 0.9798321723937988

 13%|████████▊                                                          | 13079/100000 [03:13<22:00, 65.85it/s]
epoch 13100  training loss: 0.43909719586372375
epoch 13100  clean testing loss: 0.9659087657928467
epoch 13200  training loss: 0.3970039188861847


 13%|████████▉                                                          | 13345/100000 [03:17<21:56, 65.81it/s]
epoch 13300  training loss: 0.42630481719970703

 13%|█████████                                                          | 13471/100000 [03:19<21:58, 65.64it/s]
epoch 13400  training loss: 0.4299828112125397

 14%|█████████                                                          | 13604/100000 [03:21<22:09, 64.97it/s]
epoch 13500  training loss: 0.3969641327857971
epoch 13500  clean testing loss: 0.9452662467956543
epoch 13600  training loss: 0.42736464738845825
epoch 13600  clean testing loss: 0.9198607802391052
epoch 13700  training loss: 0.4340011775493622

 14%|█████████▏                                                         | 13737/100000 [03:23<22:00, 65.32it/s]
epoch 13800  training loss: 0.4027191400527954

 14%|█████████▎                                                         | 13863/100000 [03:25<21:53, 65.59it/s]
epoch 13900  training loss: 0.425536185503006
epoch 13900  clean testing loss: 0.907596230506897
epoch 14000  training loss: 0.428580105304718
epoch 14000  clean testing loss: 0.8879488706588745

 14%|█████████▍                                                         | 13996/100000 [03:27<21:58, 65.24it/s]
epoch 14100  training loss: 0.4178276062011719

 14%|█████████▍                                                         | 14129/100000 [03:29<21:48, 65.63it/s]
epoch 14200  training loss: 0.42023298144340515


 14%|█████████▋                                                         | 14388/100000 [03:33<21:52, 65.25it/s]
epoch 14300  training loss: 0.41190335154533386

 15%|█████████▋                                                         | 14521/100000 [03:35<21:58, 64.82it/s]
epoch 14400  training loss: 0.4301656484603882
epoch 14400  clean testing loss: 0.8501232862472534
epoch 14500  training loss: 0.41486042737960815

 15%|█████████▊                                                         | 14654/100000 [03:37<21:58, 64.73it/s]
epoch 14600  training loss: 0.4240547716617584

 15%|█████████▉                                                         | 14787/100000 [03:39<21:42, 65.43it/s]
epoch 14700  training loss: 0.4149780571460724

 15%|█████████▉                                                         | 14913/100000 [03:41<21:46, 65.11it/s]
epoch 14800  training loss: 0.40540701150894165
epoch 14800  clean testing loss: 0.906143844127655
epoch 14900  training loss: 0.4181324243545532

 15%|██████████                                                         | 15046/100000 [03:43<21:54, 64.61it/s]
epoch 15000  training loss: 0.4053384065628052
epoch 15000  clean testing loss: 0.8934596180915833

 15%|██████████▏                                                        | 15179/100000 [03:45<21:37, 65.39it/s]
epoch 15100  training loss: 0.40236371755599976
epoch 15100  clean testing loss: 0.9179760813713074
epoch 15200  training loss: 0.40940603613853455
epoch 15200  clean testing loss: 0.9350728988647461
epoch 15300  training loss: 0.4469204545021057

 15%|██████████▎                                                        | 15305/100000 [03:47<21:35, 65.36it/s]
epoch 15400  training loss: 0.41497281193733215


 16%|██████████▍                                                        | 15571/100000 [03:51<21:25, 65.69it/s]
epoch 15500  training loss: 0.40811970829963684
epoch 15500  clean testing loss: 0.8486977815628052
epoch 15600  training loss: 0.4174897372722626
epoch 15600  clean testing loss: 0.886833906173706
epoch 15700  training loss: 0.40641292929649353

 16%|██████████▌                                                        | 15697/100000 [03:53<21:32, 65.22it/s]
epoch 15800  training loss: 0.38296499848365784

 16%|██████████▌                                                        | 15830/100000 [03:55<21:18, 65.85it/s]
epoch 15900  training loss: 0.40462496876716614

 16%|██████████▋                                                        | 15963/100000 [03:57<21:13, 66.00it/s]
epoch 16000  training loss: 0.4169982969760895
epoch 16000  clean testing loss: 0.9008257389068604

 16%|██████████▊                                                        | 16089/100000 [03:59<21:32, 64.90it/s]
epoch 16100  training loss: 0.3820076584815979
epoch 16100  clean testing loss: 0.9265240430831909
epoch 16200  training loss: 0.40238791704177856

 16%|██████████▊                                                        | 16222/100000 [04:01<21:29, 64.97it/s]
epoch 16300  training loss: 0.4214983880519867


 16%|███████████                                                        | 16481/100000 [04:05<21:09, 65.80it/s]
epoch 16400  training loss: 0.43157926201820374
epoch 16400  clean testing loss: 0.887245774269104
epoch 16500  training loss: 0.42706355452537537
epoch 16500  clean testing loss: 0.8966831564903259
epoch 16600  training loss: 0.414057195186615


 17%|███████████▏                                                       | 16747/100000 [04:09<21:11, 65.46it/s]
epoch 16700  training loss: 0.41794121265411377
epoch 16700  clean testing loss: 0.959132194519043
epoch 16800  training loss: 0.4271077513694763


 17%|███████████▍                                                       | 17006/100000 [04:13<21:19, 64.85it/s]
epoch 16900  training loss: 0.40965700149536133
epoch 16900  clean testing loss: 0.859460711479187
epoch 17000  training loss: 0.3835160732269287
epoch 17000  clean testing loss: 0.9223107099533081
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 17100  training loss: 0.4152439534664154

 17%|███████████▍                                                       | 17139/100000 [04:15<20:59, 65.80it/s]
epoch 17200  training loss: 0.4137575626373291

 17%|███████████▌                                                       | 17272/100000 [04:17<21:04, 65.43it/s]
epoch 17300  training loss: 0.4104078710079193
epoch 17300  clean testing loss: 0.8864980936050415
epoch 17400  training loss: 0.4007074534893036


 18%|███████████▋                                                       | 17531/100000 [04:21<20:57, 65.59it/s]
epoch 17500  training loss: 0.4270586371421814

 18%|███████████▊                                                       | 17664/100000 [04:23<21:02, 65.23it/s]
epoch 17600  training loss: 0.4097185730934143

 18%|███████████▉                                                       | 17790/100000 [04:25<20:53, 65.60it/s]
epoch 17700  training loss: 0.38940346240997314

 18%|████████████                                                       | 17923/100000 [04:27<20:52, 65.53it/s]
epoch 17800  training loss: 0.36775484681129456
epoch 17800  clean testing loss: 0.9038754105567932
epoch 17900  training loss: 0.40018579363822937

 18%|████████████                                                       | 18056/100000 [04:29<20:44, 65.86it/s]
epoch 18000  training loss: 0.37634772062301636
epoch 18000  clean testing loss: 0.9073721766471863

 18%|████████████▏                                                      | 18182/100000 [04:31<20:34, 66.30it/s]
epoch 18100  training loss: 0.4101950228214264

 18%|████████████▏                                                      | 18280/100000 [04:33<20:54, 65.12it/s]
epoch 18200  training loss: 0.39659279584884644
epoch 18200  clean testing loss: 0.8662289381027222
epoch 18300  training loss: 0.39493152499198914

 18%|████████████▎                                                      | 18413/100000 [04:35<20:41, 65.72it/s]
epoch 18400  training loss: 0.3918019235134125

 19%|████████████▍                                                      | 18546/100000 [04:37<20:50, 65.16it/s]
epoch 18500  training loss: 0.4332297444343567

 19%|████████████▌                                                      | 18672/100000 [04:39<21:10, 64.03it/s]
epoch 18600  training loss: 0.41488251090049744
epoch 18600  clean testing loss: 0.8879742622375488
epoch 18700  training loss: 0.39778369665145874

 19%|████████████▌                                                      | 18805/100000 [04:41<20:49, 64.96it/s]
epoch 18800  training loss: 0.3777633607387543

 19%|████████████▋                                                      | 18938/100000 [04:43<20:52, 64.72it/s]
epoch 18900  training loss: 0.41287922859191895

 19%|████████████▊                                                      | 19064/100000 [04:45<20:47, 64.85it/s]
epoch 19000  training loss: 0.41825827956199646
epoch 19000  clean testing loss: 0.8392590880393982

 19%|████████████▊                                                      | 19197/100000 [04:47<20:32, 65.59it/s]
epoch 19100  training loss: 0.42516234517097473
epoch 19100  clean testing loss: 0.934592068195343
epoch 19200  training loss: 0.38388898968696594

 19%|████████████▉                                                      | 19323/100000 [04:49<21:04, 63.79it/s]
epoch 19300  training loss: 0.4111521244049072

 19%|█████████████                                                      | 19456/100000 [04:51<20:33, 65.32it/s]
epoch 19400  training loss: 0.3791843056678772

 20%|█████████████                                                      | 19589/100000 [04:53<20:28, 65.45it/s]
epoch 19500  training loss: 0.3715932071208954
epoch 19500  clean testing loss: 0.9043342471122742
epoch 19600  training loss: 0.3687407970428467

 20%|█████████████▏                                                     | 19722/100000 [04:55<20:37, 64.87it/s]
epoch 19700  training loss: 0.3840016722679138

 20%|█████████████▎                                                     | 19848/100000 [04:57<20:29, 65.20it/s]
epoch 19800  training loss: 0.349874347448349

 20%|█████████████▍                                                     | 19981/100000 [04:59<20:22, 65.46it/s]
epoch 19900  training loss: 0.3733985126018524
epoch 19900  clean testing loss: 0.9923341870307922
epoch 20000  training loss: 0.3568120300769806
epoch 20000  clean testing loss: 0.9991146922111511

 20%|█████████████▍                                                     | 20114/100000 [05:01<20:24, 65.23it/s]
epoch 20100  training loss: 0.354265034198761

 20%|█████████████▌                                                     | 20240/100000 [05:03<20:17, 65.50it/s]
epoch 20200  training loss: 0.37485426664352417

 20%|█████████████▋                                                     | 20373/100000 [05:05<20:14, 65.57it/s]
epoch 20300  training loss: 0.3982047736644745
epoch 20300  clean testing loss: 0.9668905735015869
epoch 20400  training loss: 0.3752790689468384

 21%|█████████████▋                                                     | 20506/100000 [05:07<20:18, 65.24it/s]
epoch 20500  training loss: 0.3673146069049835

 21%|█████████████▊                                                     | 20632/100000 [05:09<20:24, 64.82it/s]
epoch 20600  training loss: 0.3697863817214966

 21%|█████████████▉                                                     | 20765/100000 [05:11<20:18, 65.02it/s]
epoch 20700  training loss: 0.3556584119796753

 21%|██████████████                                                     | 20898/100000 [05:13<20:19, 64.84it/s]
epoch 20800  training loss: 0.3741430938243866
epoch 20800  clean testing loss: 0.9468041658401489
epoch 20900  training loss: 0.38014015555381775

 21%|██████████████                                                     | 21024/100000 [05:15<20:24, 64.50it/s]
epoch 21000  training loss: 0.3814484775066376
epoch 21000  clean testing loss: 0.9526073336601257

 21%|██████████████▏                                                    | 21157/100000 [05:17<20:08, 65.24it/s]
epoch 21100  training loss: 0.37064918875694275

 21%|██████████████▎                                                    | 21290/100000 [05:19<19:58, 65.69it/s]
epoch 21200  training loss: 0.38818106055259705
epoch 21200  clean testing loss: 0.9973022937774658
epoch 21300  training loss: 0.35214903950691223

 21%|██████████████▎                                                    | 21416/100000 [05:21<20:21, 64.33it/s]
epoch 21400  training loss: 0.36389631032943726

 22%|██████████████▍                                                    | 21549/100000 [05:23<20:05, 65.07it/s]
epoch 21500  training loss: 0.37590718269348145

 22%|██████████████▌                                                    | 21682/100000 [05:25<20:03, 65.09it/s]
epoch 21600  training loss: 0.39261460304260254
epoch 21600  clean testing loss: 0.9850779175758362
epoch 21700  training loss: 0.359244167804718

 22%|██████████████▌                                                    | 21815/100000 [05:27<19:44, 66.00it/s]
epoch 21800  training loss: 0.4082390069961548

 22%|██████████████▋                                                    | 21941/100000 [05:29<19:56, 65.24it/s]
epoch 21900  training loss: 0.34070253372192383

 22%|██████████████▊                                                    | 22074/100000 [05:31<19:51, 65.39it/s]
epoch 22000  training loss: 0.37679606676101685
epoch 22000  clean testing loss: 0.9540866017341614

 22%|██████████████▊                                                    | 22200/100000 [05:33<19:41, 65.86it/s]
epoch 22100  training loss: 0.3578808903694153
epoch 22100  clean testing loss: 0.9787302017211914
epoch 22200  training loss: 0.352311909198761

 22%|██████████████▉                                                    | 22333/100000 [05:35<19:42, 65.69it/s]
epoch 22300  training loss: 0.3650415241718292

 22%|███████████████                                                    | 22466/100000 [05:37<19:48, 65.23it/s]
epoch 22400  training loss: 0.3716046214103699

 23%|███████████████▏                                                   | 22592/100000 [05:39<19:56, 64.69it/s]
epoch 22500  training loss: 0.3634868860244751
epoch 22500  clean testing loss: 0.9496288299560547
epoch 22600  training loss: 0.33785727620124817

 23%|███████████████▏                                                   | 22725/100000 [05:41<19:44, 65.26it/s]
epoch 22700  training loss: 0.3433813154697418

 23%|███████████████▎                                                   | 22858/100000 [05:43<19:33, 65.74it/s]
epoch 22800  training loss: 0.3907666802406311

 23%|███████████████▍                                                   | 22984/100000 [05:45<19:39, 65.31it/s]
epoch 22900  training loss: 0.3797074854373932
epoch 22900  clean testing loss: 0.9762071967124939
epoch 23000  training loss: 0.36690273880958557
epoch 23000  clean testing loss: 0.9904605150222778

 23%|███████████████▍                                                   | 23117/100000 [05:47<19:43, 64.97it/s]
epoch 23100  training loss: 0.35587555170059204

 23%|███████████████▌                                                   | 23243/100000 [05:49<19:47, 64.64it/s]
epoch 23200  training loss: 0.37810468673706055

 23%|███████████████▋                                                   | 23376/100000 [05:51<19:46, 64.55it/s]
epoch 23300  training loss: 0.3757997751235962

 24%|███████████████▊                                                   | 23509/100000 [05:53<19:27, 65.51it/s]
epoch 23400  training loss: 0.38608720898628235
epoch 23400  clean testing loss: 0.9764725565910339
epoch 23500  training loss: 0.37962275743484497

 24%|███████████████▊                                                   | 23635/100000 [05:55<19:22, 65.68it/s]
epoch 23600  training loss: 0.3507262170314789

 24%|███████████████▉                                                   | 23768/100000 [05:57<19:26, 65.36it/s]
epoch 23700  training loss: 0.34592193365097046

 24%|████████████████                                                   | 23901/100000 [05:59<19:32, 64.90it/s]
epoch 23800  training loss: 0.36187803745269775
epoch 23800  clean testing loss: 0.9790061116218567
epoch 23900  training loss: 0.3434261083602905

 24%|████████████████                                                   | 24027/100000 [06:01<19:29, 64.98it/s]
epoch 24000  training loss: 0.35298866033554077
epoch 24000  clean testing loss: 0.9709987044334412

 24%|████████████████▏                                                  | 24160/100000 [06:03<19:11, 65.84it/s]
epoch 24100  training loss: 0.363569974899292

 24%|████████████████▎                                                  | 24293/100000 [06:05<19:13, 65.64it/s]
epoch 24200  training loss: 0.3591650724411011
epoch 24200  clean testing loss: 0.9371407628059387
epoch 24300  training loss: 0.3508138060569763

 24%|████████████████▎                                                  | 24426/100000 [06:07<19:21, 65.09it/s]
epoch 24400  training loss: 0.3200424909591675

 25%|████████████████▍                                                  | 24552/100000 [06:09<19:16, 65.25it/s]
epoch 24500  training loss: 0.34762364625930786

 25%|████████████████▌                                                  | 24685/100000 [06:11<19:12, 65.32it/s]
epoch 24600  training loss: 0.3592644929885864
epoch 24600  clean testing loss: 0.9859107732772827
epoch 24700  training loss: 0.3604668080806732

 25%|████████████████▋                                                  | 24818/100000 [06:13<19:02, 65.81it/s]
epoch 24800  training loss: 0.34615498781204224

 25%|████████████████▋                                                  | 24944/100000 [06:15<19:00, 65.84it/s]
epoch 24900  training loss: 0.3656952381134033

 25%|████████████████▊                                                  | 25077/100000 [06:17<18:55, 65.95it/s]
epoch 25000  training loss: 0.3464031517505646
epoch 25000  clean testing loss: 0.962256133556366

 25%|████████████████▉                                                  | 25210/100000 [06:19<18:57, 65.73it/s]
epoch 25100  training loss: 0.3310301601886749
epoch 25100  clean testing loss: 0.9928076267242432
epoch 25200  training loss: 0.37597328424453735

 25%|████████████████▉                                                  | 25336/100000 [06:21<19:07, 65.07it/s]
epoch 25300  training loss: 0.3538725972175598

 25%|█████████████████                                                  | 25469/100000 [06:23<19:08, 64.87it/s]
epoch 25400  training loss: 0.3626388609409332

 26%|█████████████████▏                                                 | 25595/100000 [06:25<19:00, 65.24it/s]
epoch 25500  training loss: 0.37976038455963135
epoch 25500  clean testing loss: 1.0098079442977905
epoch 25600  training loss: 0.3289075791835785

 26%|█████████████████▏                                                 | 25728/100000 [06:27<18:47, 65.87it/s]
epoch 25700  training loss: 0.31124287843704224

 26%|█████████████████▎                                                 | 25861/100000 [06:29<18:57, 65.20it/s]
epoch 25800  training loss: 0.35729366540908813

 26%|█████████████████▍                                                 | 25994/100000 [06:31<18:50, 65.48it/s]
epoch 25900  training loss: 0.3399854898452759
epoch 25900  clean testing loss: 1.0212047100067139
epoch 26000  training loss: 0.34571510553359985
epoch 26000  clean testing loss: 1.0158566236495972

 26%|█████████████████▌                                                 | 26120/100000 [06:33<18:58, 64.91it/s]
epoch 26100  training loss: 0.3584912419319153

 26%|█████████████████▌                                                 | 26246/100000 [06:35<19:02, 64.54it/s]
epoch 26200  training loss: 0.3943149149417877

 26%|█████████████████▋                                                 | 26379/100000 [06:37<18:46, 65.33it/s]
epoch 26300  training loss: 0.35633039474487305

 27%|█████████████████▊                                                 | 26512/100000 [06:39<19:01, 64.40it/s]
epoch 26400  training loss: 0.3502950966358185
epoch 26400  clean testing loss: 1.014237403869629
epoch 26500  training loss: 0.33944013714790344

 27%|█████████████████▊                                                 | 26638/100000 [06:41<18:48, 65.03it/s]
epoch 26600  training loss: 0.3604671061038971

 27%|█████████████████▉                                                 | 26771/100000 [06:43<18:51, 64.73it/s]
epoch 26700  training loss: 0.34590691328048706

 27%|██████████████████                                                 | 26904/100000 [06:45<18:38, 65.34it/s]
epoch 26800  training loss: 0.3459233045578003
epoch 26800  clean testing loss: 1.0435670614242554
epoch 26900  training loss: 0.3401716947555542

 27%|██████████████████                                                 | 27037/100000 [06:47<18:40, 65.10it/s]
epoch 27000  training loss: 0.3595331013202667
epoch 27000  clean testing loss: 1.0004138946533203

 27%|██████████████████▏                                                | 27163/100000 [06:49<18:46, 64.68it/s]
epoch 27100  training loss: 0.3475525677204132

 27%|██████████████████▎                                                | 27296/100000 [06:51<18:41, 64.84it/s]
epoch 27200  training loss: 0.34166139364242554
epoch 27200  clean testing loss: 0.9761407971382141
epoch 27300  training loss: 0.3394709527492523

 27%|██████████████████▍                                                | 27429/100000 [06:53<18:38, 64.90it/s]
epoch 27400  training loss: 0.3118322193622589

 28%|██████████████████▍                                                | 27555/100000 [06:55<18:51, 64.01it/s]
epoch 27500  training loss: 0.33096471428871155

 28%|██████████████████▌                                                | 27688/100000 [06:57<18:17, 65.88it/s]
epoch 27600  training loss: 0.3720454275608063
epoch 27600  clean testing loss: 0.997003972530365
epoch 27700  training loss: 0.34403130412101746

 28%|██████████████████▋                                                | 27821/100000 [06:59<18:17, 65.78it/s]
epoch 27800  training loss: 0.3296273350715637

 28%|██████████████████▋                                                | 27954/100000 [07:01<18:13, 65.87it/s]
epoch 27900  training loss: 0.3609694242477417

 28%|██████████████████▊                                                | 28080/100000 [07:03<18:30, 64.76it/s]
epoch 28000  training loss: 0.3216061592102051
epoch 28000  clean testing loss: 1.006872296333313

 28%|██████████████████▉                                                | 28213/100000 [07:05<18:21, 65.19it/s]
epoch 28100  training loss: 0.35619670152664185
epoch 28100  clean testing loss: 1.0334868431091309
epoch 28200  training loss: 0.3199416995048523

 28%|██████████████████▉                                                | 28346/100000 [07:07<18:22, 65.02it/s]
epoch 28300  training loss: 0.3302512764930725

 28%|███████████████████                                                | 28479/100000 [07:09<18:03, 65.99it/s]
epoch 28400  training loss: 0.3335624933242798

 29%|███████████████████▏                                               | 28605/100000 [07:11<18:04, 65.86it/s]
epoch 28500  training loss: 0.3052483797073364
epoch 28500  clean testing loss: 1.024667501449585
epoch 28600  training loss: 0.33306068181991577

 29%|███████████████████▎                                               | 28738/100000 [07:13<18:07, 65.54it/s]
epoch 28700  training loss: 0.33698374032974243

 29%|███████████████████▎                                               | 28871/100000 [07:15<18:11, 65.19it/s]
epoch 28800  training loss: 0.3212432265281677

 29%|███████████████████▍                                               | 29004/100000 [07:17<18:18, 64.65it/s]
epoch 28900  training loss: 0.34633246064186096
epoch 28900  clean testing loss: 1.0201199054718018
epoch 29000  training loss: 0.324153333902359
epoch 29000  clean testing loss: 1.0383765697479248

 29%|███████████████████▌                                               | 29130/100000 [07:19<18:06, 65.21it/s]
epoch 29100  training loss: 0.345662921667099

 29%|███████████████████▌                                               | 29263/100000 [07:21<18:02, 65.32it/s]
epoch 29200  training loss: 0.3192816376686096

 29%|███████████████████▋                                               | 29396/100000 [07:23<18:06, 64.97it/s]
epoch 29300  training loss: 0.3313400447368622
epoch 29300  clean testing loss: 1.0322734117507935
epoch 29400  training loss: 0.3176199495792389
epoch 29400  clean testing loss: 1.0140031576156616
epoch 29500  training loss: 0.3313308358192444

 30%|███████████████████▊                                               | 29522/100000 [07:25<18:08, 64.75it/s]
epoch 29600  training loss: 0.32325848937034607

 30%|███████████████████▊                                               | 29655/100000 [07:27<18:07, 64.70it/s]
epoch 29700  training loss: 0.36087214946746826

 30%|███████████████████▉                                               | 29788/100000 [07:29<17:52, 65.48it/s]
epoch 29800  training loss: 0.3364909887313843
epoch 29800  clean testing loss: 1.093884825706482
epoch 29900  training loss: 0.34396740794181824

 30%|████████████████████                                               | 29914/100000 [07:31<17:50, 65.46it/s]
epoch 30000  training loss: 0.32520437240600586
epoch 30000  clean testing loss: 1.0572317838668823

 30%|████████████████████▏                                              | 30047/100000 [07:33<18:05, 64.44it/s]
epoch 30100  training loss: 0.31775838136672974

 30%|████████████████████▏                                              | 30173/100000 [07:35<18:01, 64.55it/s]
epoch 30200  training loss: 0.3168400526046753
epoch 30200  clean testing loss: 1.0676181316375732
epoch 30300  training loss: 0.31430044770240784

 30%|████████████████████▎                                              | 30306/100000 [07:37<17:49, 65.18it/s]
epoch 30400  training loss: 0.31733644008636475

 30%|████████████████████▍                                              | 30439/100000 [07:39<17:43, 65.40it/s]
epoch 30500  training loss: 0.3068285584449768

 31%|████████████████████▍                                              | 30572/100000 [07:41<17:38, 65.59it/s]
epoch 30600  training loss: 0.30292806029319763
epoch 30600  clean testing loss: 1.067307472229004
epoch 30700  training loss: 0.30527710914611816

 31%|████████████████████▌                                              | 30698/100000 [07:43<17:35, 65.64it/s]
epoch 30800  training loss: 0.30809637904167175

 31%|████████████████████▋                                              | 30831/100000 [07:45<17:29, 65.89it/s]
epoch 30900  training loss: 0.30643874406814575

 31%|████████████████████▋                                              | 30964/100000 [07:47<17:36, 65.37it/s]
epoch 31000  training loss: 0.3414815664291382
epoch 31000  clean testing loss: 1.0869510173797607


 31%|████████████████████▉                                              | 31223/100000 [07:51<17:39, 64.94it/s]
epoch 31100  training loss: 0.29232263565063477
epoch 31100  clean testing loss: 1.0903199911117554
epoch 31200  training loss: 0.3014765977859497

 31%|█████████████████████                                              | 31356/100000 [07:53<17:29, 65.41it/s]
epoch 31300  training loss: 0.30892693996429443

 31%|█████████████████████                                              | 31482/100000 [07:55<17:29, 65.26it/s]
epoch 31400  training loss: 0.3250720500946045

 32%|█████████████████████▏                                             | 31615/100000 [07:57<17:28, 65.20it/s]
epoch 31500  training loss: 0.3242166340351105
epoch 31500  clean testing loss: 1.125069499015808
epoch 31600  training loss: 0.33102649450302124

 32%|█████████████████████▎                                             | 31748/100000 [07:59<17:17, 65.78it/s]
epoch 31700  training loss: 0.3036973476409912
epoch 31700  clean testing loss: 1.1125867366790771
epoch 31800  training loss: 0.32476991415023804

 32%|█████████████████████▎                                             | 31874/100000 [08:01<17:26, 65.08it/s]
epoch 31900  training loss: 0.30923962593078613
epoch 31900  clean testing loss: 1.1123734712600708
epoch 32000  training loss: 0.3060091435909271
epoch 32000  clean testing loss: 1.1476191282272339

 32%|█████████████████████▍                                             | 32007/100000 [08:03<17:35, 64.39it/s]
epoch 32100  training loss: 0.30075931549072266

 32%|█████████████████████▌                                             | 32133/100000 [08:05<17:25, 64.90it/s]
epoch 32200  training loss: 0.3032517731189728

 32%|█████████████████████▌                                             | 32266/100000 [08:07<16:59, 66.46it/s]
epoch 32300  training loss: 0.29561200737953186
epoch 32300  clean testing loss: 1.1577332019805908
epoch 32400  training loss: 0.3316114842891693

 32%|█████████████████████▋                                             | 32399/100000 [08:09<17:16, 65.20it/s]
epoch 32500  training loss: 0.28032025694847107

 33%|█████████████████████▊                                             | 32532/100000 [08:11<17:05, 65.81it/s]
epoch 32600  training loss: 0.31643587350845337

 33%|█████████████████████▉                                             | 32658/100000 [08:13<17:01, 65.90it/s]
epoch 32700  training loss: 0.3078894317150116

 33%|█████████████████████▉                                             | 32791/100000 [08:15<17:11, 65.13it/s]
epoch 32800  training loss: 0.3283196985721588
epoch 32800  clean testing loss: 1.0885339975357056
epoch 32900  training loss: 0.30832937359809875

 33%|██████████████████████                                             | 32924/100000 [08:17<17:13, 64.89it/s]
epoch 33000  training loss: 0.35471925139427185
epoch 33000  clean testing loss: 1.0857505798339844

 33%|██████████████████████▏                                            | 33050/100000 [08:19<17:14, 64.71it/s]
epoch 33100  training loss: 0.32458820939064026

 33%|██████████████████████▏                                            | 33183/100000 [08:21<16:59, 65.51it/s]
epoch 33200  training loss: 0.3132137656211853
epoch 33200  clean testing loss: 1.0595612525939941
epoch 33300  training loss: 0.33187347650527954

 33%|██████████████████████▎                                            | 33316/100000 [08:23<17:06, 64.94it/s]
epoch 33400  training loss: 0.3283079266548157

 33%|██████████████████████▍                                            | 33442/100000 [08:25<17:00, 65.23it/s]
epoch 33500  training loss: 0.32250460982322693

 34%|██████████████████████▍                                            | 33575/100000 [08:27<17:06, 64.73it/s]
epoch 33600  training loss: 0.31155911087989807
epoch 33600  clean testing loss: 1.0752613544464111
epoch 33700  training loss: 0.3030160665512085

 34%|██████████████████████▌                                            | 33708/100000 [08:29<16:54, 65.32it/s]
epoch 33800  training loss: 0.3090028762817383

 34%|██████████████████████▋                                            | 33834/100000 [08:31<17:11, 64.12it/s]
epoch 33900  training loss: 0.29873672127723694

 34%|██████████████████████▊                                            | 33967/100000 [08:33<16:44, 65.73it/s]
epoch 34000  training loss: 0.28068986535072327
epoch 34000  clean testing loss: 1.049027681350708

 34%|██████████████████████▊                                            | 34093/100000 [08:35<16:48, 65.33it/s]
epoch 34100  training loss: 0.30377593636512756
epoch 34100  clean testing loss: 1.0600208044052124
epoch 34200  training loss: 0.2944395840167999

 34%|██████████████████████▉                                            | 34226/100000 [08:37<16:46, 65.34it/s]
epoch 34300  training loss: 0.26983484625816345

 34%|███████████████████████                                            | 34359/100000 [08:39<16:35, 65.93it/s]
epoch 34400  training loss: 0.3000503182411194

 34%|███████████████████████                                            | 34457/100000 [08:41<16:43, 65.34it/s]
epoch 34500  training loss: 0.3013659715652466
epoch 34500  clean testing loss: 1.0615265369415283
epoch 34600  training loss: 0.30770865082740784

 35%|███████████████████████▏                                           | 34590/100000 [08:43<16:48, 64.84it/s]
epoch 34700  training loss: 0.2860562205314636

 35%|███████████████████████▎                                           | 34716/100000 [08:45<16:53, 64.41it/s]
epoch 34800  training loss: 0.33157578110694885


 35%|███████████████████████▍                                           | 34982/100000 [08:49<16:34, 65.39it/s]
epoch 34900  training loss: 0.29780322313308716
epoch 34900  clean testing loss: 1.05166494846344
epoch 35000  training loss: 0.3066912889480591
epoch 35000  clean testing loss: 1.0627878904342651
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 35100  training loss: 0.3115222156047821

 35%|███████████████████████▌                                           | 35108/100000 [08:51<16:39, 64.92it/s]
epoch 35200  training loss: 0.3116529583930969

 35%|███████████████████████▌                                           | 35241/100000 [08:53<16:36, 64.97it/s]
epoch 35300  training loss: 0.29651951789855957
epoch 35300  clean testing loss: 1.0721640586853027
epoch 35400  training loss: 0.3047631084918976

 35%|███████████████████████▋                                           | 35367/100000 [08:55<16:38, 64.71it/s]
epoch 35500  training loss: 0.29745185375213623

 36%|███████████████████████▊                                           | 35500/100000 [08:57<16:38, 64.62it/s]
epoch 35600  training loss: 0.3047773540019989

 36%|███████████████████████▊                                           | 35633/100000 [08:59<16:21, 65.60it/s]
epoch 35700  training loss: 0.3222934305667877

 36%|███████████████████████▉                                           | 35759/100000 [09:01<16:23, 65.30it/s]
epoch 35800  training loss: 0.30223435163497925
epoch 35800  clean testing loss: 1.0940170288085938
epoch 35900  training loss: 0.32057246565818787

 36%|████████████████████████                                           | 35892/100000 [09:03<16:25, 65.03it/s]
epoch 36000  training loss: 0.2991628646850586
epoch 36000  clean testing loss: 1.1228561401367188

 36%|████████████████████████▏                                          | 36025/100000 [09:05<16:29, 64.65it/s]
epoch 36100  training loss: 0.32639461755752563

 36%|████████████████████████▏                                          | 36151/100000 [09:07<16:26, 64.72it/s]
epoch 36200  training loss: 0.2882503569126129
epoch 36200  clean testing loss: 1.1444395780563354
epoch 36300  training loss: 0.29801496863365173

 36%|████████████████████████▎                                          | 36284/100000 [09:09<16:19, 65.08it/s]
epoch 36400  training loss: 0.28654229640960693

 36%|████████████████████████▍                                          | 36417/100000 [09:11<16:16, 65.08it/s]
epoch 36500  training loss: 0.29338204860687256

 37%|████████████████████████▍                                          | 36543/100000 [09:13<16:10, 65.36it/s]
epoch 36600  training loss: 0.30309510231018066
epoch 36600  clean testing loss: 1.1206750869750977
epoch 36700  training loss: 0.31665149331092834

 37%|████████████████████████▌                                          | 36676/100000 [09:15<16:07, 65.46it/s]
epoch 36800  training loss: 0.2825130820274353

 37%|████████████████████████▋                                          | 36802/100000 [09:17<16:20, 64.46it/s]
epoch 36900  training loss: 0.3149738311767578

 37%|████████████████████████▋                                          | 36935/100000 [09:19<16:10, 64.99it/s]
epoch 37000  training loss: 0.3090357184410095
epoch 37000  clean testing loss: 1.137426495552063

 37%|████████████████████████▊                                          | 37061/100000 [09:21<16:04, 65.27it/s]
epoch 37100  training loss: 0.28905975818634033
epoch 37100  clean testing loss: 1.142194151878357
epoch 37200  training loss: 0.2984626293182373

 37%|████████████████████████▉                                          | 37194/100000 [09:23<16:01, 65.29it/s]
epoch 37300  training loss: 0.30083000659942627

 37%|█████████████████████████                                          | 37327/100000 [09:25<15:51, 65.88it/s]
epoch 37400  training loss: 0.2963866591453552

 37%|█████████████████████████                                          | 37460/100000 [09:27<15:59, 65.15it/s]
epoch 37500  training loss: 0.2718016803264618
epoch 37500  clean testing loss: 1.1607110500335693
epoch 37600  training loss: 0.2980269193649292

 38%|█████████████████████████▏                                         | 37586/100000 [09:29<15:57, 65.18it/s]
epoch 37700  training loss: 0.3120717406272888

 38%|█████████████████████████▎                                         | 37719/100000 [09:31<15:57, 65.07it/s]
epoch 37800  training loss: 0.32631921768188477

 38%|█████████████████████████▎                                         | 37852/100000 [09:33<15:43, 65.89it/s]
epoch 37900  training loss: 0.32292094826698303
epoch 37900  clean testing loss: 1.1928961277008057
epoch 38000  training loss: 0.29782313108444214
epoch 38000  clean testing loss: 1.1854995489120483

 38%|█████████████████████████▍                                         | 37978/100000 [09:35<15:55, 64.92it/s]
epoch 38100  training loss: 0.3090532422065735

 38%|█████████████████████████▌                                         | 38111/100000 [09:37<15:54, 64.87it/s]
epoch 38200  training loss: 0.3099338412284851

 38%|█████████████████████████▌                                         | 38237/100000 [09:39<15:54, 64.74it/s]
epoch 38300  training loss: 0.29765182733535767

 38%|█████████████████████████▋                                         | 38370/100000 [09:41<16:03, 63.99it/s]
epoch 38400  training loss: 0.31676363945007324
epoch 38400  clean testing loss: 1.1989123821258545
epoch 38500  training loss: 0.2858794629573822

 38%|█████████████████████████▊                                         | 38496/100000 [09:43<15:39, 65.47it/s]
epoch 38600  training loss: 0.2740519642829895

 39%|█████████████████████████▉                                         | 38629/100000 [09:45<15:45, 64.89it/s]
epoch 38700  training loss: 0.29022127389907837

 39%|█████████████████████████▉                                         | 38762/100000 [09:47<15:38, 65.25it/s]
epoch 38800  training loss: 0.27421343326568604
epoch 38800  clean testing loss: 1.175418734550476
epoch 38900  training loss: 0.27983859181404114


 39%|██████████████████████████▏                                        | 39021/100000 [09:51<15:37, 65.03it/s]
epoch 39000  training loss: 0.27218443155288696
epoch 39000  clean testing loss: 1.1635037660598755

 39%|██████████████████████████▏                                        | 39154/100000 [09:53<15:21, 66.04it/s]
epoch 39100  training loss: 0.3031856417655945

 39%|██████████████████████████▎                                        | 39280/100000 [09:55<15:50, 63.85it/s]
epoch 39200  training loss: 0.3216605484485626
epoch 39200  clean testing loss: 1.1521580219268799
epoch 39300  training loss: 0.2869948148727417

 39%|██████████████████████████▍                                        | 39413/100000 [09:57<15:38, 64.54it/s]
epoch 39400  training loss: 0.3153051435947418
epoch 39400  clean testing loss: 1.147871732711792
epoch 39500  training loss: 0.3291071355342865


 40%|██████████████████████████▌                                        | 39672/100000 [10:01<15:20, 65.51it/s]
epoch 39600  training loss: 0.30590304732322693

 40%|██████████████████████████▋                                        | 39805/100000 [10:03<15:27, 64.89it/s]
epoch 39700  training loss: 0.2934858798980713
epoch 39700  clean testing loss: 1.1379107236862183
epoch 39800  training loss: 0.2928954064846039

 40%|██████████████████████████▊                                        | 39938/100000 [10:05<15:28, 64.68it/s]
epoch 39900  training loss: 0.26568225026130676

 40%|██████████████████████████▊                                        | 40064/100000 [10:07<15:10, 65.83it/s]
epoch 40000  training loss: 0.2698589563369751
epoch 40000  clean testing loss: 1.149469256401062

 40%|██████████████████████████▉                                        | 40197/100000 [10:09<15:25, 64.59it/s]
epoch 40100  training loss: 0.2771042585372925
epoch 40100  clean testing loss: 1.1620522737503052
epoch 40200  training loss: 0.2824978530406952

 40%|███████████████████████████                                        | 40323/100000 [10:11<15:14, 65.26it/s]
epoch 40300  training loss: 0.2763327658176422

 40%|███████████████████████████                                        | 40456/100000 [10:13<15:18, 64.84it/s]
epoch 40400  training loss: 0.2665538191795349

 41%|███████████████████████████▏                                       | 40589/100000 [10:15<15:06, 65.54it/s]
epoch 40500  training loss: 0.28915637731552124
epoch 40500  clean testing loss: 1.157767653465271
epoch 40600  training loss: 0.2942665219306946

 41%|███████████████████████████▎                                       | 40722/100000 [10:17<15:03, 65.64it/s]
epoch 40700  training loss: 0.2851875126361847

 41%|███████████████████████████▎                                       | 40848/100000 [10:19<15:11, 64.91it/s]
epoch 40800  training loss: 0.29172763228416443

 41%|███████████████████████████▍                                       | 40981/100000 [10:21<15:01, 65.47it/s]
epoch 40900  training loss: 0.27246516942977905

 41%|███████████████████████████▌                                       | 41107/100000 [10:23<15:04, 65.13it/s]
epoch 41000  training loss: 0.2745918333530426
epoch 41000  clean testing loss: 1.1445144414901733
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 41100  training loss: 0.28525635600090027

 41%|███████████████████████████▋                                       | 41240/100000 [10:25<14:58, 65.39it/s]
epoch 41200  training loss: 0.28470760583877563

 41%|███████████████████████████▋                                       | 41373/100000 [10:27<14:55, 65.47it/s]
epoch 41300  training loss: 0.2497006356716156

 41%|███████████████████████████▊                                       | 41499/100000 [10:29<14:56, 65.28it/s]
epoch 41400  training loss: 0.28567254543304443
epoch 41400  clean testing loss: 1.1517738103866577
epoch 41500  training loss: 0.27064961194992065

 42%|███████████████████████████▉                                       | 41632/100000 [10:31<14:59, 64.91it/s]
epoch 41600  training loss: 0.257363885641098

 42%|███████████████████████████▉                                       | 41765/100000 [10:33<14:50, 65.43it/s]
epoch 41700  training loss: 0.279247522354126

 42%|████████████████████████████                                       | 41891/100000 [10:35<14:58, 64.70it/s]
epoch 41800  training loss: 0.2716447710990906
epoch 41800  clean testing loss: 1.1558310985565186
epoch 41900  training loss: 0.28440576791763306

 42%|████████████████████████████▏                                      | 42024/100000 [10:37<15:05, 64.06it/s]
epoch 42000  training loss: 0.25963327288627625
epoch 42000  clean testing loss: 1.1678636074066162

 42%|████████████████████████████▏                                      | 42157/100000 [10:39<14:48, 65.09it/s]
epoch 42100  training loss: 0.2688160836696625

 42%|████████████████████████████▎                                      | 42283/100000 [10:41<14:47, 65.04it/s]
epoch 42200  training loss: 0.2809653580188751
epoch 42200  clean testing loss: 1.164202332496643
epoch 42300  training loss: 0.27702662348747253

 42%|████████████████████████████▍                                      | 42416/100000 [10:43<14:44, 65.10it/s]
epoch 42400  training loss: 0.2898588478565216

 43%|████████████████████████████▌                                      | 42549/100000 [10:45<14:35, 65.63it/s]
epoch 42500  training loss: 0.2667311728000641

 43%|████████████████████████████▌                                      | 42675/100000 [10:47<14:48, 64.49it/s]
epoch 42600  training loss: 0.3127988576889038

 43%|████████████████████████████▋                                      | 42808/100000 [10:49<14:37, 65.17it/s]
epoch 42700  training loss: 0.2580619752407074
epoch 42700  clean testing loss: 1.165496826171875
epoch 42800  training loss: 0.28124257922172546
epoch 42800  clean testing loss: 1.1540583372116089
epoch 42900  training loss: 0.2957194745540619

 43%|████████████████████████████▊                                      | 42941/100000 [10:51<14:42, 64.65it/s]
epoch 43000  training loss: 0.2926749587059021
epoch 43000  clean testing loss: 1.159011721611023

 43%|████████████████████████████▊                                      | 43067/100000 [10:53<14:34, 65.10it/s]
epoch 43100  training loss: 0.25418663024902344
epoch 43100  clean testing loss: 1.1736632585525513
epoch 43200  training loss: 0.2843557298183441

 43%|████████████████████████████▉                                      | 43193/100000 [10:55<14:36, 64.78it/s]
epoch 43300  training loss: 0.2903438210487366

 43%|█████████████████████████████                                      | 43326/100000 [10:57<14:28, 65.25it/s]
epoch 43400  training loss: 0.2532716393470764

 43%|█████████████████████████████                                      | 43459/100000 [10:59<14:29, 65.02it/s]
epoch 43500  training loss: 0.2933313250541687

 44%|█████████████████████████████▏                                     | 43585/100000 [11:01<14:27, 65.00it/s]
epoch 43600  training loss: 0.28163477778434753
epoch 43600  clean testing loss: 1.1890336275100708
epoch 43700  training loss: 0.27030137181282043

 44%|█████████████████████████████▎                                     | 43697/100000 [11:03<16:54, 55.49it/s]
epoch 43800  training loss: 0.2668997347354889


 44%|█████████████████████████████▍                                     | 43913/100000 [11:07<16:39, 56.09it/s]
epoch 43900  training loss: 0.27283337712287903
epoch 43900  clean testing loss: 1.1801838874816895
epoch 44000  training loss: 0.2483145296573639
epoch 44000  clean testing loss: 1.157461404800415

 44%|█████████████████████████████▍                                     | 44021/100000 [11:09<17:02, 54.72it/s]
epoch 44100  training loss: 0.2578137218952179

 44%|█████████████████████████████▌                                     | 44129/100000 [11:11<17:24, 53.48it/s]
epoch 44200  training loss: 0.2619771957397461


 44%|█████████████████████████████▋                                     | 44351/100000 [11:15<16:55, 54.81it/s]
epoch 44300  training loss: 0.29951417446136475

 44%|█████████████████████████████▊                                     | 44459/100000 [11:17<17:11, 53.86it/s]
epoch 44400  training loss: 0.2739538848400116
epoch 44400  clean testing loss: 1.1605132818222046
epoch 44500  training loss: 0.2790829539299011

 45%|█████████████████████████████▊                                     | 44567/100000 [11:19<17:50, 51.79it/s]
epoch 44600  training loss: 0.30379506945610046

 45%|█████████████████████████████▉                                     | 44675/100000 [11:21<17:00, 54.20it/s]
epoch 44700  training loss: 0.2980645000934601

 45%|██████████████████████████████                                     | 44783/100000 [11:23<17:02, 53.99it/s]
epoch 44800  training loss: 0.3108333349227905


 45%|██████████████████████████████▏                                    | 44999/100000 [11:27<16:56, 54.13it/s]
epoch 44900  training loss: 0.28830286860466003
epoch 44900  clean testing loss: 1.141217589378357
epoch 45000  training loss: 0.3085818588733673
epoch 45000  clean testing loss: 1.133491039276123

 45%|██████████████████████████████▏                                    | 45107/100000 [11:29<16:49, 54.40it/s]
epoch 45100  training loss: 0.2916361093521118

 45%|██████████████████████████████▎                                    | 45215/100000 [11:31<17:18, 52.75it/s]
epoch 45200  training loss: 0.31998056173324585
epoch 45200  clean testing loss: 1.1316665410995483
epoch 45300  training loss: 0.2987949252128601

 45%|██████████████████████████████▎                                    | 45323/100000 [11:34<17:11, 53.01it/s]
epoch 45400  training loss: 0.2807393968105316

 45%|██████████████████████████████▍                                    | 45431/100000 [11:36<17:17, 52.60it/s]
epoch 45500  training loss: 0.3208739161491394

 46%|██████████████████████████████▌                                    | 45544/100000 [11:38<14:28, 62.69it/s]
epoch 45600  training loss: 0.2808603346347809

 46%|██████████████████████████████▌                                    | 45670/100000 [11:39<13:51, 65.35it/s]
epoch 45700  training loss: 0.2655237317085266
epoch 45700  clean testing loss: 1.1588630676269531
epoch 45800  training loss: 0.29921695590019226


 46%|██████████████████████████████▊                                    | 45936/100000 [11:44<13:50, 65.11it/s]
epoch 45900  training loss: 0.27581435441970825
epoch 45900  clean testing loss: 1.137049913406372
epoch 46000  training loss: 0.2950827479362488
epoch 46000  clean testing loss: 1.1684768199920654


 46%|██████████████████████████████▉                                    | 46188/100000 [11:48<13:52, 64.68it/s]
epoch 46100  training loss: 0.3008057773113251

 46%|███████████████████████████████                                    | 46321/100000 [11:50<13:40, 65.39it/s]
epoch 46200  training loss: 0.3147719204425812
epoch 46200  clean testing loss: 1.144220232963562
epoch 46300  training loss: 0.29196637868881226
epoch 46300  clean testing loss: 1.1334367990493774
epoch 46400  training loss: 0.2905696630477905

 46%|███████████████████████████████                                    | 46447/100000 [11:52<13:49, 64.59it/s]
epoch 46500  training loss: 0.2920544743537903


 47%|███████████████████████████████▎                                   | 46682/100000 [11:56<16:00, 55.51it/s]
epoch 46600  training loss: 0.25304386019706726

 47%|███████████████████████████████▎                                   | 46794/100000 [11:58<14:19, 61.87it/s]
epoch 46700  training loss: 0.3199887275695801

 47%|███████████████████████████████▍                                   | 46927/100000 [12:00<13:31, 65.42it/s]
epoch 46800  training loss: 0.2699449062347412
epoch 46800  clean testing loss: 1.1221321821212769
epoch 46900  training loss: 0.3041130602359772

 47%|███████████████████████████████▌                                   | 47053/100000 [12:02<13:37, 64.73it/s]
epoch 47000  training loss: 0.28375086188316345
epoch 47000  clean testing loss: 1.1334304809570312

 47%|███████████████████████████████▌                                   | 47186/100000 [12:04<13:27, 65.37it/s]
epoch 47100  training loss: 0.24378912150859833

 47%|███████████████████████████████▋                                   | 47312/100000 [12:06<13:23, 65.55it/s]
epoch 47200  training loss: 0.27843785285949707
epoch 47200  clean testing loss: 1.127055048942566
epoch 47300  training loss: 0.2734570801258087

 47%|███████████████████████████████▊                                   | 47445/100000 [12:08<13:32, 64.70it/s]
epoch 47400  training loss: 0.27807411551475525

 48%|███████████████████████████████▉                                   | 47578/100000 [12:10<13:24, 65.14it/s]
epoch 47500  training loss: 0.2674761414527893

 48%|███████████████████████████████▉                                   | 47704/100000 [12:12<13:24, 64.97it/s]
epoch 47600  training loss: 0.3090564012527466
epoch 47600  clean testing loss: 1.1310105323791504
epoch 47700  training loss: 0.2918931245803833

 48%|████████████████████████████████                                   | 47837/100000 [12:14<13:25, 64.79it/s]
epoch 47800  training loss: 0.3046155869960785
epoch 47800  clean testing loss: 1.1422486305236816
epoch 47900  training loss: 0.24384382367134094

 48%|████████████████████████████████▏                                  | 47970/100000 [12:16<13:22, 64.85it/s]
epoch 48000  training loss: 0.29659730195999146
epoch 48000  clean testing loss: 1.1207473278045654
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 48100  training loss: 0.2664833962917328


 48%|████████████████████████████████▎                                  | 48229/100000 [12:20<13:17, 64.94it/s]
epoch 48200  training loss: 0.3093237280845642

 48%|████████████████████████████████▍                                  | 48362/100000 [12:22<13:12, 65.15it/s]
epoch 48300  training loss: 0.28672724962234497

 48%|████████████████████████████████▍                                  | 48488/100000 [12:24<13:19, 64.43it/s]
epoch 48400  training loss: 0.25498491525650024

 49%|████████████████████████████████▌                                  | 48621/100000 [12:26<13:06, 65.32it/s]
epoch 48500  training loss: 0.27206888794898987
epoch 48500  clean testing loss: 1.1024616956710815
epoch 48600  training loss: 0.29369011521339417

 49%|████████████████████████████████▋                                  | 48747/100000 [12:28<13:03, 65.40it/s]
epoch 48700  training loss: 0.27912142872810364

 49%|████████████████████████████████▋                                  | 48880/100000 [12:30<13:13, 64.43it/s]
epoch 48800  training loss: 0.25853395462036133

 49%|████████████████████████████████▊                                  | 49013/100000 [12:32<13:02, 65.19it/s]
epoch 48900  training loss: 0.26779595017433167
epoch 48900  clean testing loss: 1.127029299736023
epoch 49000  training loss: 0.2839867174625397
epoch 49000  clean testing loss: 1.1285269260406494
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 49100  training loss: 0.24551717936992645

 49%|████████████████████████████████▉                                  | 49139/100000 [12:34<12:52, 65.86it/s]
epoch 49200  training loss: 0.27792108058929443


 49%|█████████████████████████████████                                  | 49405/100000 [12:38<12:58, 65.03it/s]
epoch 49300  training loss: 0.2574843764305115
epoch 49300  clean testing loss: 1.1374403238296509
epoch 49400  training loss: 0.2407108098268509

 50%|█████████████████████████████████▏                                 | 49538/100000 [12:40<12:51, 65.40it/s]
epoch 49500  training loss: 0.2528478503227234

 50%|█████████████████████████████████▎                                 | 49664/100000 [12:42<12:50, 65.37it/s]
epoch 49600  training loss: 0.2979377806186676

 50%|█████████████████████████████████▎                                 | 49797/100000 [12:44<12:56, 64.66it/s]
epoch 49700  training loss: 0.2767368257045746

 50%|█████████████████████████████████▍                                 | 49923/100000 [12:46<12:58, 64.35it/s]
epoch 49800  training loss: 0.2780083119869232
epoch 49800  clean testing loss: 1.1379865407943726
epoch 49900  training loss: 0.3015908896923065

 50%|█████████████████████████████████▌                                 | 50056/100000 [12:48<12:37, 65.93it/s]
epoch 50000  training loss: 0.2783192992210388
epoch 50000  clean testing loss: 1.1220427751541138

 50%|█████████████████████████████████▋                                 | 50189/100000 [12:50<12:49, 64.77it/s]
epoch 50100  training loss: 0.26894909143447876

 50%|█████████████████████████████████▋                                 | 50315/100000 [12:52<12:47, 64.71it/s]
epoch 50200  training loss: 0.2858523726463318
epoch 50200  clean testing loss: 1.1279263496398926
epoch 50300  training loss: 0.285232812166214

 50%|█████████████████████████████████▊                                 | 50448/100000 [12:54<12:43, 64.91it/s]
epoch 50400  training loss: 0.2953442633152008
epoch 50400  clean testing loss: 1.1146317720413208
epoch 50500  training loss: 0.2652280032634735

 51%|█████████████████████████████████▉                                 | 50574/100000 [12:56<12:33, 65.59it/s]
epoch 50600  training loss: 0.2800302803516388
epoch 50600  clean testing loss: 1.0948081016540527
epoch 50700  training loss: 0.2851400077342987

 51%|█████████████████████████████████▉                                 | 50707/100000 [12:58<12:37, 65.05it/s]
epoch 50800  training loss: 0.29166898131370544

 51%|██████████████████████████████████                                 | 50805/100000 [12:59<12:41, 64.62it/s]
epoch 50900  training loss: 0.2566663324832916

 51%|██████████████████████████████████▏                                | 50938/100000 [13:01<12:33, 65.12it/s]
epoch 51000  training loss: 0.2517608404159546
epoch 51000  clean testing loss: 1.0812206268310547

 51%|██████████████████████████████████▏                                | 51064/100000 [13:03<12:32, 65.04it/s]
epoch 51100  training loss: 0.27625933289527893
epoch 51100  clean testing loss: 1.080020785331726
epoch 51200  training loss: 0.2805315852165222

 51%|██████████████████████████████████▎                                | 51197/100000 [13:05<12:22, 65.74it/s]
epoch 51300  training loss: 0.2658700942993164


 51%|██████████████████████████████████▍                                | 51456/100000 [13:09<12:30, 64.69it/s]
epoch 51400  training loss: 0.2904614806175232
epoch 51400  clean testing loss: 1.0915875434875488
epoch 51500  training loss: 0.31192225217819214
epoch 51500  clean testing loss: 1.0867629051208496
epoch 51600  training loss: 0.2607499957084656


 52%|██████████████████████████████████▋                                | 51715/100000 [13:13<12:25, 64.76it/s]
epoch 51700  training loss: 0.26295241713523865

 52%|██████████████████████████████████▋                                | 51841/100000 [13:15<12:27, 64.44it/s]
epoch 51800  training loss: 0.25805407762527466
epoch 51800  clean testing loss: 1.0831247568130493
epoch 51900  training loss: 0.2951142191886902
epoch 51900  clean testing loss: 1.0992445945739746
epoch 52000  training loss: 0.26978403329849243
epoch 52000  clean testing loss: 1.0923391580581665

 52%|██████████████████████████████████▊                                | 51974/100000 [13:17<12:16, 65.18it/s]
epoch 52100  training loss: 0.281186044216156

 52%|██████████████████████████████████▉                                | 52107/100000 [13:19<12:12, 65.37it/s]
epoch 52200  training loss: 0.26189419627189636

 52%|██████████████████████████████████▉                                | 52233/100000 [13:21<12:11, 65.27it/s]
epoch 52300  training loss: 0.2781814634799957

 52%|███████████████████████████████████                                | 52366/100000 [13:23<12:16, 64.65it/s]
epoch 52400  training loss: 0.24347274005413055
epoch 52400  clean testing loss: 1.0904234647750854
epoch 52500  training loss: 0.2819281816482544

 52%|███████████████████████████████████▏                               | 52499/100000 [13:25<12:04, 65.56it/s]
epoch 52600  training loss: 0.26845356822013855

 53%|███████████████████████████████████▎                               | 52625/100000 [13:27<12:08, 65.05it/s]
epoch 52700  training loss: 0.2770048975944519

 53%|███████████████████████████████████▎                               | 52758/100000 [13:29<12:05, 65.08it/s]
epoch 52800  training loss: 0.27552682161331177
epoch 52800  clean testing loss: 1.0927876234054565
epoch 52900  training loss: 0.27495917677879333

 53%|███████████████████████████████████▍                               | 52891/100000 [13:31<12:08, 64.63it/s]
epoch 53000  training loss: 0.2675739526748657
epoch 53000  clean testing loss: 1.0966284275054932

 53%|███████████████████████████████████▌                               | 53017/100000 [13:33<11:55, 65.67it/s]
epoch 53100  training loss: 0.2822561264038086

 53%|███████████████████████████████████▌                               | 53150/100000 [13:35<11:56, 65.35it/s]
epoch 53200  training loss: 0.25927841663360596
epoch 53200  clean testing loss: 1.0991806983947754
epoch 53300  training loss: 0.27245765924453735

 53%|███████████████████████████████████▋                               | 53276/100000 [13:37<11:58, 65.03it/s]
epoch 53400  training loss: 0.2414410561323166

 53%|███████████████████████████████████▊                               | 53409/100000 [13:39<11:45, 66.04it/s]
epoch 53500  training loss: 0.2906531095504761

 54%|███████████████████████████████████▊                               | 53542/100000 [13:41<11:45, 65.82it/s]
epoch 53600  training loss: 0.28632572293281555
epoch 53600  clean testing loss: 1.1029571294784546
epoch 53700  training loss: 0.2782847583293915

 54%|███████████████████████████████████▉                               | 53675/100000 [13:43<11:51, 65.10it/s]
epoch 53800  training loss: 0.2602519094944

 54%|████████████████████████████████████                               | 53801/100000 [13:45<11:55, 64.58it/s]
epoch 53900  training loss: 0.2906872630119324

 54%|████████████████████████████████████▏                              | 53934/100000 [13:47<11:45, 65.31it/s]
epoch 54000  training loss: 0.28680604696273804
epoch 54000  clean testing loss: 1.1201307773590088

 54%|████████████████████████████████████▏                              | 54067/100000 [13:49<11:36, 65.97it/s]
epoch 54100  training loss: 0.27741944789886475
epoch 54100  clean testing loss: 1.1057504415512085
epoch 54200  training loss: 0.2954166531562805


 54%|████████████████████████████████████▍                              | 54326/100000 [13:53<11:40, 65.22it/s]
epoch 54300  training loss: 0.26359108090400696

 54%|████████████████████████████████████▍                              | 54459/100000 [13:56<11:34, 65.53it/s]
epoch 54400  training loss: 0.26373976469039917

 55%|████████████████████████████████████▌                              | 54585/100000 [13:57<11:36, 65.18it/s]
epoch 54500  training loss: 0.27710264921188354
epoch 54500  clean testing loss: 1.1471575498580933
epoch 54600  training loss: 0.2896938621997833

 55%|████████████████████████████████████▋                              | 54718/100000 [13:59<11:33, 65.27it/s]
epoch 54700  training loss: 0.28310051560401917

 55%|████████████████████████████████████▋                              | 54844/100000 [14:01<11:35, 64.94it/s]
epoch 54800  training loss: 0.25426185131073

 55%|████████████████████████████████████▊                              | 54977/100000 [14:03<11:30, 65.18it/s]
epoch 54900  training loss: 0.23826032876968384
epoch 54900  clean testing loss: 1.1415845155715942
epoch 55000  training loss: 0.2913624346256256
epoch 55000  clean testing loss: 1.141767144203186

 55%|████████████████████████████████████▉                              | 55110/100000 [14:06<11:22, 65.80it/s]
epoch 55100  training loss: 0.2669614851474762

 55%|█████████████████████████████████████                              | 55236/100000 [14:07<11:30, 64.82it/s]
epoch 55200  training loss: 0.2624085247516632

 55%|█████████████████████████████████████                              | 55369/100000 [14:09<11:23, 65.26it/s]
epoch 55300  training loss: 0.26805782318115234

 56%|█████████████████████████████████████▏                             | 55502/100000 [14:12<11:27, 64.72it/s]
epoch 55400  training loss: 0.27053603529930115
epoch 55400  clean testing loss: 1.133658528327942
epoch 55500  training loss: 0.2896532118320465
epoch 55500  clean testing loss: 1.13196861743927
epoch 55600  training loss: 0.2605476379394531

 56%|█████████████████████████████████████▎                             | 55628/100000 [14:13<11:22, 64.98it/s]
epoch 55700  training loss: 0.24241942167282104

 56%|█████████████████████████████████████▎                             | 55761/100000 [14:15<11:15, 65.53it/s]
epoch 55800  training loss: 0.2743505537509918
epoch 55800  clean testing loss: 1.1405457258224487
epoch 55900  training loss: 0.2462800294160843

 56%|█████████████████████████████████████▍                             | 55894/100000 [14:18<11:15, 65.34it/s]
epoch 56000  training loss: 0.25000715255737305
epoch 56000  clean testing loss: 1.1455254554748535

 56%|█████████████████████████████████████▌                             | 56027/100000 [14:20<11:15, 65.11it/s]
epoch 56100  training loss: 0.2532898187637329

 56%|█████████████████████████████████████▌                             | 56153/100000 [14:21<11:10, 65.42it/s]
epoch 56200  training loss: 0.26901471614837646
epoch 56200  clean testing loss: 1.1481964588165283
epoch 56300  training loss: 0.2600055932998657


 56%|█████████████████████████████████████▊                             | 56412/100000 [14:26<11:17, 64.32it/s]
epoch 56400  training loss: 0.28286024928092957

 57%|█████████████████████████████████████▉                             | 56545/100000 [14:28<11:08, 65.03it/s]
epoch 56500  training loss: 0.2769189476966858

 57%|█████████████████████████████████████▉                             | 56678/100000 [14:30<11:07, 64.87it/s]
epoch 56600  training loss: 0.2530171871185303
epoch 56600  clean testing loss: 1.1640379428863525
epoch 56700  training loss: 0.2614046037197113
epoch 56700  clean testing loss: 1.1561566591262817
epoch 56800  training loss: 0.29835420846939087

 57%|██████████████████████████████████████                             | 56804/100000 [14:32<11:05, 64.94it/s]
epoch 56900  training loss: 0.2724592983722687


 57%|██████████████████████████████████████▏                            | 57063/100000 [14:36<11:03, 64.71it/s]
epoch 57000  training loss: 0.2796640694141388
epoch 57000  clean testing loss: 1.1318223476409912

 57%|██████████████████████████████████████▎                            | 57196/100000 [14:38<10:56, 65.22it/s]
epoch 57100  training loss: 0.2660791575908661
epoch 57100  clean testing loss: 1.1471834182739258
epoch 57200  training loss: 0.2651911675930023
epoch 57200  clean testing loss: 1.133310317993164
epoch 57300  training loss: 0.3205793499946594


 57%|██████████████████████████████████████▍                            | 57455/100000 [14:42<10:46, 65.84it/s]
epoch 57400  training loss: 0.3074575662612915

 58%|██████████████████████████████████████▌                            | 57588/100000 [14:44<10:51, 65.14it/s]
epoch 57500  training loss: 0.2937700152397156
epoch 57500  clean testing loss: 1.1389493942260742
epoch 57600  training loss: 0.2843147814273834
epoch 57600  clean testing loss: 1.1468055248260498
epoch 57700  training loss: 0.28129008412361145

 58%|██████████████████████████████████████▋                            | 57721/100000 [14:46<10:51, 64.91it/s]
epoch 57800  training loss: 0.3044571578502655

 58%|██████████████████████████████████████▊                            | 57847/100000 [14:48<10:44, 65.41it/s]
epoch 57900  training loss: 0.25475218892097473

 58%|██████████████████████████████████████▊                            | 57980/100000 [14:50<10:43, 65.28it/s]
epoch 58000  training loss: 0.2687329053878784
epoch 58000  clean testing loss: 1.1346627473831177
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 58100  training loss: 0.3119478225708008

 58%|██████████████████████████████████████▉                            | 58113/100000 [14:52<10:31, 66.31it/s]
epoch 58200  training loss: 0.29630860686302185


 58%|███████████████████████████████████████                            | 58372/100000 [14:56<10:40, 65.02it/s]
epoch 58300  training loss: 0.279908150434494

 59%|███████████████████████████████████████▏                           | 58505/100000 [14:58<10:31, 65.66it/s]
epoch 58400  training loss: 0.3136160969734192
epoch 58400  clean testing loss: 1.1226327419281006
epoch 58500  training loss: 0.2680702209472656

 59%|███████████████████████████████████████▎                           | 58638/100000 [15:00<10:42, 64.40it/s]
epoch 58600  training loss: 0.3052917420864105

 59%|███████████████████████████████████████▎                           | 58764/100000 [15:02<10:35, 64.92it/s]
epoch 58700  training loss: 0.30365094542503357

 59%|███████████████████████████████████████▍                           | 58897/100000 [15:04<10:31, 65.13it/s]
epoch 58800  training loss: 0.28878673911094666
epoch 58800  clean testing loss: 1.1169768571853638
epoch 58900  training loss: 0.2949194014072418

 59%|███████████████████████████████████████▌                           | 59030/100000 [15:06<10:34, 64.55it/s]
epoch 59000  training loss: 0.2636040151119232
epoch 59000  clean testing loss: 1.1145458221435547

 59%|███████████████████████████████████████▋                           | 59156/100000 [15:08<10:25, 65.28it/s]
epoch 59100  training loss: 0.27602076530456543

 59%|███████████████████████████████████████▋                           | 59289/100000 [15:10<10:22, 65.44it/s]
epoch 59200  training loss: 0.27641457319259644
epoch 59200  clean testing loss: 1.128631353378296
epoch 59300  training loss: 0.32783445715904236
epoch 59300  clean testing loss: 1.1350075006484985
epoch 59400  training loss: 0.27794399857521057

 59%|███████████████████████████████████████▊                           | 59422/100000 [15:12<10:20, 65.36it/s]
epoch 59500  training loss: 0.2961500883102417

 60%|███████████████████████████████████████▉                           | 59548/100000 [15:14<10:24, 64.78it/s]
epoch 59600  training loss: 0.28462570905685425

 60%|███████████████████████████████████████▉                           | 59681/100000 [15:16<10:19, 65.08it/s]
epoch 59700  training loss: 0.285213440656662
epoch 59700  clean testing loss: 1.1352893114089966
epoch 59800  training loss: 0.24181947112083435

 60%|████████████████████████████████████████                           | 59814/100000 [15:18<10:19, 64.88it/s]
epoch 59900  training loss: 0.26395711302757263

 60%|████████████████████████████████████████▏                          | 59940/100000 [15:20<10:12, 65.40it/s]
epoch 60000  training loss: 0.25690075755119324
epoch 60000  clean testing loss: 1.1333808898925781

 60%|████████████████████████████████████████▏                          | 60073/100000 [15:22<10:08, 65.63it/s]
epoch 60100  training loss: 0.3055824041366577
epoch 60100  clean testing loss: 1.13545823097229
epoch 60200  training loss: 0.2835806906223297

 60%|████████████████████████████████████████▎                          | 60206/100000 [15:24<10:15, 64.70it/s]
epoch 60300  training loss: 0.2668769657611847


 60%|████████████████████████████████████████▌                          | 60465/100000 [15:28<10:06, 65.14it/s]
epoch 60400  training loss: 0.2536560297012329

 61%|████████████████████████████████████████▌                          | 60598/100000 [15:30<10:00, 65.61it/s]
epoch 60500  training loss: 0.2592720687389374
epoch 60500  clean testing loss: 1.1252236366271973
epoch 60600  training loss: 0.25060129165649414

 61%|████████████████████████████████████████▋                          | 60724/100000 [15:32<10:01, 65.25it/s]
epoch 60700  training loss: 0.2750469446182251

 61%|████████████████████████████████████████▊                          | 60857/100000 [15:34<09:59, 65.32it/s]
epoch 60800  training loss: 0.2955114245414734

 61%|████████████████████████████████████████▊                          | 60990/100000 [15:36<09:56, 65.40it/s]
epoch 60900  training loss: 0.287166029214859
epoch 60900  clean testing loss: 1.1522722244262695
epoch 61000  training loss: 0.2512873709201813
epoch 61000  clean testing loss: 1.1321817636489868
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 61100  training loss: 0.290172815322876

 61%|████████████████████████████████████████▉                          | 61116/100000 [15:38<09:59, 64.81it/s]
epoch 61200  training loss: 0.26787298917770386

 61%|█████████████████████████████████████████                          | 61249/100000 [15:40<09:53, 65.26it/s]
epoch 61300  training loss: 0.24757465720176697


 62%|█████████████████████████████████████████▏                         | 61508/100000 [15:44<09:45, 65.75it/s]
epoch 61400  training loss: 0.25625213980674744
epoch 61400  clean testing loss: 1.1246111392974854
epoch 61500  training loss: 0.29975569248199463

 62%|█████████████████████████████████████████▎                         | 61641/100000 [15:46<09:51, 64.90it/s]
epoch 61600  training loss: 0.28490135073661804
epoch 61600  clean testing loss: 1.1387007236480713
epoch 61700  training loss: 0.2312179058790207


 62%|█████████████████████████████████████████▍                         | 61900/100000 [15:50<09:41, 65.54it/s]
epoch 61800  training loss: 0.23884981870651245
epoch 61800  clean testing loss: 1.1222180128097534
epoch 61900  training loss: 0.2856101095676422

 62%|█████████████████████████████████████████▌                         | 62033/100000 [15:52<09:51, 64.17it/s]
epoch 62000  training loss: 0.24037303030490875
epoch 62000  clean testing loss: 1.1341099739074707
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 62100  training loss: 0.2544448673725128

 62%|█████████████████████████████████████████▋                         | 62159/100000 [15:54<09:40, 65.21it/s]
epoch 62200  training loss: 0.28348615765571594
epoch 62200  clean testing loss: 1.1380459070205688
epoch 62300  training loss: 0.2451372742652893

 62%|█████████████████████████████████████████▋                         | 62292/100000 [15:56<09:46, 64.30it/s]
epoch 62400  training loss: 0.24095997214317322


 63%|█████████████████████████████████████████▉                         | 62551/100000 [16:00<09:37, 64.89it/s]
epoch 62500  training loss: 0.2465689778327942

 63%|█████████████████████████████████████████▉                         | 62684/100000 [16:02<09:38, 64.51it/s]
epoch 62600  training loss: 0.29647889733314514
epoch 62600  clean testing loss: 1.150754451751709
epoch 62700  training loss: 0.2750292420387268
epoch 62700  clean testing loss: 1.1430615186691284
epoch 62800  training loss: 0.24459052085876465

 63%|██████████████████████████████████████████                         | 62817/100000 [16:04<09:32, 64.97it/s]
epoch 62900  training loss: 0.2695014476776123

 63%|██████████████████████████████████████████▏                        | 62943/100000 [16:06<09:27, 65.35it/s]
epoch 63000  training loss: 0.2526669204235077
epoch 63000  clean testing loss: 1.1470656394958496


 63%|██████████████████████████████████████████▎                        | 63209/100000 [16:10<09:25, 65.06it/s]
epoch 63100  training loss: 0.25027433037757874
epoch 63100  clean testing loss: 1.1510233879089355
epoch 63200  training loss: 0.2526644766330719
epoch 63200  clean testing loss: 1.144616961479187
epoch 63300  training loss: 0.2555740475654602

 63%|██████████████████████████████████████████▍                        | 63335/100000 [16:12<09:24, 64.92it/s]
epoch 63400  training loss: 0.27037447690963745

 63%|██████████████████████████████████████████▌                        | 63468/100000 [16:14<09:17, 65.58it/s]
epoch 63500  training loss: 0.2522967755794525
epoch 63500  clean testing loss: 1.1476880311965942
epoch 63600  training loss: 0.24289211630821228


 64%|██████████████████████████████████████████▋                        | 63727/100000 [16:18<09:20, 64.76it/s]
epoch 63700  training loss: 0.2586515247821808

 64%|██████████████████████████████████████████▊                        | 63860/100000 [16:20<09:13, 65.26it/s]
epoch 63800  training loss: 0.25128111243247986

 64%|██████████████████████████████████████████▊                        | 63986/100000 [16:22<09:13, 65.01it/s]
epoch 63900  training loss: 0.24992632865905762
epoch 63900  clean testing loss: 1.1500122547149658
epoch 64000  training loss: 0.2701435685157776
epoch 64000  clean testing loss: 1.162837266921997
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 64100  training loss: 0.25759831070899963


 64%|███████████████████████████████████████████                        | 64245/100000 [16:26<09:04, 65.67it/s]
epoch 64200  training loss: 0.25951430201530457

 64%|███████████████████████████████████████████▏                       | 64378/100000 [16:28<09:02, 65.72it/s]
epoch 64300  training loss: 0.2401810884475708

 65%|███████████████████████████████████████████▏                       | 64511/100000 [16:30<09:03, 65.30it/s]
epoch 64400  training loss: 0.23859639465808868
epoch 64400  clean testing loss: 1.156568169593811
epoch 64500  training loss: 0.2649316191673279

 65%|███████████████████████████████████████████▎                       | 64637/100000 [16:32<09:02, 65.17it/s]
epoch 64600  training loss: 0.27827778458595276
epoch 64600  clean testing loss: 1.1470760107040405
epoch 64700  training loss: 0.2702696919441223

 65%|███████████████████████████████████████████▍                       | 64770/100000 [16:34<09:10, 64.05it/s]
epoch 64800  training loss: 0.23327629268169403
epoch 64800  clean testing loss: 1.1533797979354858
epoch 64900  training loss: 0.2829851806163788

 65%|███████████████████████████████████████████▍                       | 64903/100000 [16:36<09:00, 64.92it/s]
epoch 65000  training loss: 0.2613937556743622
epoch 65000  clean testing loss: 1.1460847854614258

 65%|███████████████████████████████████████████▌                       | 65029/100000 [16:38<08:56, 65.17it/s]
epoch 65100  training loss: 0.24327397346496582

 65%|███████████████████████████████████████████▋                       | 65162/100000 [16:40<08:56, 64.99it/s]
epoch 65200  training loss: 0.2867712676525116

 65%|███████████████████████████████████████████▋                       | 65295/100000 [16:42<08:56, 64.64it/s]
epoch 65300  training loss: 0.2556021213531494
epoch 65300  clean testing loss: 1.158173680305481
epoch 65400  training loss: 0.25577351450920105

 65%|███████████████████████████████████████████▊                       | 65421/100000 [16:44<08:53, 64.82it/s]
epoch 65500  training loss: 0.2735113203525543

 66%|███████████████████████████████████████████▉                       | 65554/100000 [16:46<08:47, 65.26it/s]
epoch 65600  training loss: 0.2911088168621063

 66%|████████████████████████████████████████████                       | 65687/100000 [16:48<08:39, 66.01it/s]
epoch 65700  training loss: 0.27777570486068726
epoch 65700  clean testing loss: 1.1665902137756348
epoch 65800  training loss: 0.25904127955436707

 66%|████████████████████████████████████████████                       | 65813/100000 [16:50<08:48, 64.69it/s]
epoch 65900  training loss: 0.23905886709690094

 66%|████████████████████████████████████████████▏                      | 65946/100000 [16:52<08:40, 65.45it/s]
epoch 66000  training loss: 0.2552220821380615
epoch 66000  clean testing loss: 1.1447410583496094

 66%|████████████████████████████████████████████▎                      | 66079/100000 [16:54<08:42, 64.94it/s]
epoch 66100  training loss: 0.2421887367963791
epoch 66100  clean testing loss: 1.1509405374526978
epoch 66200  training loss: 0.22798798978328705

 66%|████████████████████████████████████████████▎                      | 66205/100000 [16:56<08:38, 65.24it/s]
epoch 66300  training loss: 0.22359661757946014

 66%|████████████████████████████████████████████▍                      | 66338/100000 [16:58<08:33, 65.51it/s]
epoch 66400  training loss: 0.23848474025726318

 66%|████████████████████████████████████████████▌                      | 66471/100000 [17:00<08:42, 64.17it/s]
epoch 66500  training loss: 0.2663090229034424
epoch 66500  clean testing loss: 1.1614875793457031
epoch 66600  training loss: 0.2458212971687317

 67%|████████████████████████████████████████████▌                      | 66604/100000 [17:02<08:29, 65.50it/s]
epoch 66700  training loss: 0.28753089904785156

 67%|████████████████████████████████████████████▋                      | 66730/100000 [17:04<08:35, 64.52it/s]
epoch 66800  training loss: 0.2529076039791107

 67%|████████████████████████████████████████████▊                      | 66863/100000 [17:06<08:23, 65.86it/s]
epoch 66900  training loss: 0.2503226399421692

 67%|████████████████████████████████████████████▉                      | 66989/100000 [17:08<08:27, 65.09it/s]
epoch 67000  training loss: 0.24007700383663177
epoch 67000  clean testing loss: 1.1442803144454956
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 67100  training loss: 0.28873297572135925

 67%|████████████████████████████████████████████▉                      | 67122/100000 [17:10<08:21, 65.53it/s]
epoch 67200  training loss: 0.2812396287918091

 67%|█████████████████████████████████████████████                      | 67255/100000 [17:12<08:17, 65.79it/s]
epoch 67300  training loss: 0.23705220222473145

 67%|█████████████████████████████████████████████▏                     | 67381/100000 [17:14<08:16, 65.75it/s]
epoch 67400  training loss: 0.27103427052497864
epoch 67400  clean testing loss: 1.1420960426330566
epoch 67500  training loss: 0.23816636204719543

 68%|█████████████████████████████████████████████▏                     | 67514/100000 [17:16<08:16, 65.42it/s]
epoch 67600  training loss: 0.25186866521835327

 68%|█████████████████████████████████████████████▎                     | 67647/100000 [17:18<08:16, 65.12it/s]
epoch 67700  training loss: 0.2807381749153137

 68%|█████████████████████████████████████████████▍                     | 67780/100000 [17:20<08:11, 65.56it/s]
epoch 67800  training loss: 0.2377588003873825
epoch 67800  clean testing loss: 1.1353816986083984
epoch 67900  training loss: 0.2879488468170166


 68%|█████████████████████████████████████████████▌                     | 68039/100000 [17:24<08:17, 64.20it/s]
epoch 68000  training loss: 0.2305922657251358
epoch 68000  clean testing loss: 1.140652060508728

 68%|█████████████████████████████████████████████▋                     | 68137/100000 [17:26<08:04, 65.76it/s]
epoch 68100  training loss: 0.2766517996788025

 68%|█████████████████████████████████████████████▋                     | 68263/100000 [17:28<08:10, 64.65it/s]
epoch 68200  training loss: 0.22879745066165924

 68%|█████████████████████████████████████████████▊                     | 68396/100000 [17:30<08:00, 65.80it/s]
epoch 68300  training loss: 0.2853182852268219
epoch 68300  clean testing loss: 1.146094799041748
epoch 68400  training loss: 0.28836724162101746

 69%|█████████████████████████████████████████████▉                     | 68529/100000 [17:32<08:04, 65.02it/s]
epoch 68500  training loss: 0.26406052708625793

 69%|█████████████████████████████████████████████▉                     | 68655/100000 [17:34<08:04, 64.69it/s]
epoch 68600  training loss: 0.27982693910598755

 69%|██████████████████████████████████████████████                     | 68788/100000 [17:36<07:57, 65.31it/s]
epoch 68700  training loss: 0.28286096453666687
epoch 68700  clean testing loss: 1.1384594440460205
epoch 68800  training loss: 0.2377285659313202
epoch 68800  clean testing loss: 1.1287171840667725
epoch 68900  training loss: 0.2546454668045044

 69%|██████████████████████████████████████████████▏                    | 68914/100000 [17:38<08:00, 64.68it/s]
epoch 69000  training loss: 0.27290844917297363
epoch 69000  clean testing loss: 1.1156100034713745

 69%|██████████████████████████████████████████████▎                    | 69047/100000 [17:40<07:55, 65.11it/s]
epoch 69100  training loss: 0.27342119812965393
epoch 69100  clean testing loss: 1.1292822360992432
epoch 69200  training loss: 0.2531278431415558

 69%|██████████████████████████████████████████████▎                    | 69180/100000 [17:42<07:47, 65.94it/s]
epoch 69300  training loss: 0.29567262530326843

 69%|██████████████████████████████████████████████▍                    | 69306/100000 [17:44<07:54, 64.72it/s]
epoch 69400  training loss: 0.25785955786705017

 69%|██████████████████████████████████████████████▌                    | 69439/100000 [17:46<07:45, 65.59it/s]
epoch 69500  training loss: 0.26459479331970215

 70%|██████████████████████████████████████████████▌                    | 69572/100000 [17:48<07:47, 65.12it/s]
epoch 69600  training loss: 0.2499629110097885
epoch 69600  clean testing loss: 1.1350938081741333
epoch 69700  training loss: 0.2721812427043915

 70%|██████████████████████████████████████████████▋                    | 69698/100000 [17:50<07:47, 64.84it/s]
epoch 69800  training loss: 0.25449374318122864

 70%|██████████████████████████████████████████████▊                    | 69831/100000 [17:52<07:41, 65.38it/s]
epoch 69900  training loss: 0.25909894704818726

 70%|██████████████████████████████████████████████▉                    | 69964/100000 [17:54<07:45, 64.46it/s]
epoch 70000  training loss: 0.2484142780303955
epoch 70000  clean testing loss: 1.1139376163482666
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 70100  training loss: 0.21666203439235687

 70%|██████████████████████████████████████████████▉                    | 70090/100000 [17:56<07:40, 64.95it/s]
epoch 70200  training loss: 0.2731127142906189

 70%|███████████████████████████████████████████████                    | 70223/100000 [17:58<07:38, 65.01it/s]
epoch 70300  training loss: 0.24383951723575592

 70%|███████████████████████████████████████████████▏                   | 70349/100000 [18:00<07:36, 64.93it/s]
epoch 70400  training loss: 0.2650327980518341
epoch 70400  clean testing loss: 1.1129602193832397
epoch 70500  training loss: 0.24598723649978638

 70%|███████████████████████████████████████████████▏                   | 70482/100000 [18:02<07:35, 64.78it/s]
epoch 70600  training loss: 0.26658064126968384

 71%|███████████████████████████████████████████████▎                   | 70615/100000 [18:04<07:34, 64.71it/s]
epoch 70700  training loss: 0.24779708683490753

 71%|███████████████████████████████████████████████▍                   | 70741/100000 [18:06<07:30, 64.89it/s]
epoch 70800  training loss: 0.2737978994846344

 71%|███████████████████████████████████████████████▍                   | 70874/100000 [18:08<07:32, 64.40it/s]
epoch 70900  training loss: 0.25211045145988464
epoch 70900  clean testing loss: 1.1057049036026
epoch 71000  training loss: 0.2854065001010895
epoch 71000  clean testing loss: 1.1139346361160278

 71%|███████████████████████████████████████████████▌                   | 71007/100000 [18:10<07:31, 64.25it/s]
epoch 71100  training loss: 0.22732658684253693


 71%|███████████████████████████████████████████████▋                   | 71266/100000 [18:14<07:19, 65.38it/s]
epoch 71200  training loss: 0.2655649781227112

 71%|███████████████████████████████████████████████▊                   | 71399/100000 [18:16<07:17, 65.43it/s]
epoch 71300  training loss: 0.24329695105552673
epoch 71300  clean testing loss: 1.1082454919815063
epoch 71400  training loss: 0.26427772641181946

 72%|███████████████████████████████████████████████▉                   | 71525/100000 [18:18<07:16, 65.25it/s]
epoch 71500  training loss: 0.2530597746372223

 72%|████████████████████████████████████████████████                   | 71658/100000 [18:20<07:15, 65.08it/s]
epoch 71600  training loss: 0.2589704096317291
epoch 71600  clean testing loss: 1.129480242729187
epoch 71700  training loss: 0.2457927167415619
epoch 71700  clean testing loss: 1.1243234872817993
epoch 71800  training loss: 0.25133076310157776


 72%|████████████████████████████████████████████████▏                  | 71917/100000 [18:24<07:10, 65.24it/s]
epoch 71900  training loss: 0.27714747190475464

 72%|████████████████████████████████████████████████▎                  | 72050/100000 [18:26<07:17, 63.81it/s]
epoch 72000  training loss: 0.25324416160583496
epoch 72000  clean testing loss: 1.1210142374038696
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 72100  training loss: 0.2624273896217346
epoch 72100  clean testing loss: 1.1326985359191895
epoch 72200  training loss: 0.278446227312088


 72%|████████████████████████████████████████████████▍                  | 72309/100000 [18:30<07:00, 65.80it/s]
epoch 72300  training loss: 0.24044056236743927

 72%|████████████████████████████████████████████████▌                  | 72442/100000 [18:32<07:03, 65.09it/s]
epoch 72400  training loss: 0.2701427638530731

 73%|████████████████████████████████████████████████▌                  | 72568/100000 [18:34<07:04, 64.65it/s]
epoch 72500  training loss: 0.23737454414367676

 73%|████████████████████████████████████████████████▋                  | 72701/100000 [18:36<06:57, 65.38it/s]
epoch 72600  training loss: 0.22634947299957275
epoch 72600  clean testing loss: 1.1237295866012573
epoch 72700  training loss: 0.2336096316576004

 73%|████████████████████████████████████████████████▊                  | 72834/100000 [18:38<06:59, 64.70it/s]
epoch 72800  training loss: 0.2410506308078766
epoch 72800  clean testing loss: 1.119022011756897
epoch 72900  training loss: 0.22816944122314453

 73%|████████████████████████████████████████████████▉                  | 72960/100000 [18:40<06:51, 65.72it/s]
epoch 73000  training loss: 0.25446027517318726
epoch 73000  clean testing loss: 1.1041285991668701
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 73100  training loss: 0.23110553622245789

 73%|████████████████████████████████████████████████▉                  | 73093/100000 [18:42<06:51, 65.45it/s]
epoch 73200  training loss: 0.28300532698631287


 73%|█████████████████████████████████████████████████▏                 | 73352/100000 [18:46<06:44, 65.87it/s]
epoch 73300  training loss: 0.2599257230758667

 73%|█████████████████████████████████████████████████▏                 | 73485/100000 [18:48<06:47, 65.11it/s]
epoch 73400  training loss: 0.28033342957496643
epoch 73400  clean testing loss: 1.1242502927780151
epoch 73500  training loss: 0.2498183399438858

 74%|█████████████████████████████████████████████████▎                 | 73618/100000 [18:50<06:43, 65.33it/s]
epoch 73600  training loss: 0.2376498281955719

 74%|█████████████████████████████████████████████████▍                 | 73744/100000 [18:52<06:42, 65.27it/s]
epoch 73700  training loss: 0.2381804883480072

 74%|█████████████████████████████████████████████████▍                 | 73877/100000 [18:54<06:41, 65.05it/s]
epoch 73800  training loss: 0.2663998305797577

 74%|█████████████████████████████████████████████████▌                 | 74010/100000 [18:56<06:45, 64.02it/s]
epoch 73900  training loss: 0.25953832268714905
epoch 73900  clean testing loss: 1.1016130447387695
epoch 74000  training loss: 0.26561325788497925
epoch 74000  clean testing loss: 1.1128360033035278

 74%|█████████████████████████████████████████████████▋                 | 74136/100000 [18:58<06:40, 64.51it/s]
epoch 74100  training loss: 0.2673189342021942

 74%|█████████████████████████████████████████████████▊                 | 74269/100000 [19:00<06:34, 65.20it/s]
epoch 74200  training loss: 0.2986085116863251

 74%|█████████████████████████████████████████████████▊                 | 74402/100000 [19:02<06:33, 65.09it/s]
epoch 74300  training loss: 0.26143166422843933
epoch 74300  clean testing loss: 1.1104494333267212
epoch 74400  training loss: 0.2984766960144043

 75%|█████████████████████████████████████████████████▉                 | 74528/100000 [19:04<06:32, 64.95it/s]
epoch 74500  training loss: 0.25466811656951904

 75%|██████████████████████████████████████████████████                 | 74661/100000 [19:06<06:30, 64.97it/s]
epoch 74600  training loss: 0.26712945103645325

 75%|██████████████████████████████████████████████████                 | 74794/100000 [19:08<06:30, 64.57it/s]
epoch 74700  training loss: 0.24291379749774933
epoch 74700  clean testing loss: 1.1061724424362183
epoch 74800  training loss: 0.22706346213817596

 75%|██████████████████████████████████████████████████▏                | 74920/100000 [19:10<06:24, 65.22it/s]
epoch 74900  training loss: 0.25567173957824707

 75%|██████████████████████████████████████████████████▎                | 75053/100000 [19:12<06:26, 64.59it/s]
epoch 75000  training loss: 0.26691707968711853
epoch 75000  clean testing loss: 1.1143624782562256

 75%|██████████████████████████████████████████████████▎                | 75186/100000 [19:14<06:23, 64.76it/s]
epoch 75100  training loss: 0.2749984562397003

 75%|██████████████████████████████████████████████████▍                | 75312/100000 [19:16<06:13, 66.08it/s]
epoch 75200  training loss: 0.26491254568099976
epoch 75200  clean testing loss: 1.0997569561004639
epoch 75300  training loss: 0.2726139724254608

 75%|██████████████████████████████████████████████████▌                | 75445/100000 [19:18<06:15, 65.38it/s]
epoch 75400  training loss: 0.2592848539352417

 76%|██████████████████████████████████████████████████▋                | 75578/100000 [19:20<06:12, 65.50it/s]
epoch 75500  training loss: 0.2883147597312927

 76%|██████████████████████████████████████████████████▋                | 75711/100000 [19:22<06:09, 65.78it/s]
epoch 75600  training loss: 0.2732730805873871
epoch 75600  clean testing loss: 1.0979909896850586
epoch 75700  training loss: 0.23549887537956238

 76%|██████████████████████████████████████████████████▊                | 75837/100000 [19:24<06:10, 65.29it/s]
epoch 75800  training loss: 0.24775217473506927

 76%|██████████████████████████████████████████████████▉                | 75970/100000 [19:26<06:08, 65.27it/s]
epoch 75900  training loss: 0.2777341902256012

 76%|██████████████████████████████████████████████████▉                | 76103/100000 [19:28<06:05, 65.42it/s]
epoch 76000  training loss: 0.252777099609375
epoch 76000  clean testing loss: 1.1052297353744507
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 76100  training loss: 0.24292515218257904

 76%|███████████████████████████████████████████████████                | 76229/100000 [19:30<06:07, 64.67it/s]
epoch 76200  training loss: 0.2463383674621582

 76%|███████████████████████████████████████████████████▏               | 76362/100000 [19:32<06:02, 65.15it/s]
epoch 76300  training loss: 0.24732452630996704

 76%|███████████████████████████████████████████████████▎               | 76496/100000 [19:34<05:47, 67.67it/s]
epoch 76400  training loss: 0.2796413004398346
epoch 76400  clean testing loss: 1.1090071201324463
epoch 76500  training loss: 0.25730788707733154

 77%|███████████████████████████████████████████████████▎               | 76648/100000 [19:36<05:10, 75.10it/s]
epoch 76600  training loss: 0.2454640120267868

 77%|███████████████████████████████████████████████████▍               | 76792/100000 [19:38<05:12, 74.23it/s]
epoch 76700  training loss: 0.2615431547164917
epoch 76700  clean testing loss: 1.0880049467086792
epoch 76800  training loss: 0.25717929005622864
epoch 76800  clean testing loss: 1.104825496673584
epoch 76900  training loss: 0.27395856380462646

 77%|███████████████████████████████████████████████████▌               | 76944/100000 [19:40<05:06, 75.34it/s]
epoch 77000  training loss: 0.27298980951309204
epoch 77000  clean testing loss: 1.0988754034042358
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 77100  training loss: 0.2704320549964905

 77%|███████████████████████████████████████████████████▋               | 77096/100000 [19:42<05:03, 75.43it/s]
epoch 77200  training loss: 0.25383129715919495

 77%|███████████████████████████████████████████████████▊               | 77248/100000 [19:44<05:00, 75.61it/s]
epoch 77300  training loss: 0.2625109553337097
epoch 77300  clean testing loss: 1.0916155576705933
epoch 77400  training loss: 0.243101567029953

 77%|███████████████████████████████████████████████████▊               | 77400/100000 [19:46<04:57, 75.91it/s]
epoch 77500  training loss: 0.2673162519931793

 78%|███████████████████████████████████████████████████▉               | 77552/100000 [19:48<04:55, 75.85it/s]
epoch 77600  training loss: 0.2510102391242981
epoch 77600  clean testing loss: 1.1024129390716553
epoch 77700  training loss: 0.2719494104385376

 78%|████████████████████████████████████████████████████               | 77704/100000 [19:50<04:55, 75.40it/s]
epoch 77800  training loss: 0.247061625123024

 78%|████████████████████████████████████████████████████▏              | 77856/100000 [19:52<04:54, 75.28it/s]
epoch 77900  training loss: 0.25234901905059814
epoch 77900  clean testing loss: 1.1029404401779175
epoch 78000  training loss: 0.27194786071777344
epoch 78000  clean testing loss: 1.110857367515564

 78%|████████████████████████████████████████████████████▎              | 78000/100000 [19:54<04:50, 75.63it/s]
epoch 78100  training loss: 0.2528436481952667

 78%|████████████████████████████████████████████████████▎              | 78152/100000 [19:56<04:50, 75.17it/s]
epoch 78200  training loss: 0.2829575538635254
epoch 78200  clean testing loss: 1.1024621725082397
epoch 78300  training loss: 0.2419116348028183

 78%|████████████████████████████████████████████████████▍              | 78304/100000 [19:58<04:48, 75.14it/s]
epoch 78400  training loss: 0.25630512833595276

 78%|████████████████████████████████████████████████████▌              | 78456/100000 [20:00<04:46, 75.19it/s]
epoch 78500  training loss: 0.28642675280570984
epoch 78500  clean testing loss: 1.1124773025512695
epoch 78600  training loss: 0.2723698318004608

 79%|████████████████████████████████████████████████████▋              | 78608/100000 [20:02<04:43, 75.49it/s]
epoch 78700  training loss: 0.2574601471424103


 79%|████████████████████████████████████████████████████▊              | 78912/100000 [20:06<04:40, 75.10it/s]
epoch 78800  training loss: 0.24703651666641235
epoch 78800  clean testing loss: 1.1180801391601562
epoch 78900  training loss: 0.23406727612018585

 79%|████████████████████████████████████████████████████▉              | 79056/100000 [20:08<04:38, 75.21it/s]
epoch 79000  training loss: 0.2935998737812042
epoch 79000  clean testing loss: 1.1213774681091309

 79%|█████████████████████████████████████████████████████              | 79208/100000 [20:10<04:36, 75.31it/s]
epoch 79100  training loss: 0.24287858605384827
epoch 79100  clean testing loss: 1.1197148561477661
epoch 79200  training loss: 0.2678641080856323

 79%|█████████████████████████████████████████████████████▏             | 79360/100000 [20:12<04:33, 75.52it/s]
epoch 79300  training loss: 0.25909188389778137

 80%|█████████████████████████████████████████████████████▎             | 79512/100000 [20:14<04:28, 76.28it/s]
epoch 79400  training loss: 0.26203158497810364
epoch 79400  clean testing loss: 1.120279312133789
epoch 79500  training loss: 0.23888829350471497

 80%|█████████████████████████████████████████████████████▎             | 79664/100000 [20:16<04:28, 75.78it/s]
epoch 79600  training loss: 0.2517632246017456

 80%|█████████████████████████████████████████████████████▍             | 79816/100000 [20:18<04:27, 75.58it/s]
epoch 79700  training loss: 0.2576410174369812
epoch 79700  clean testing loss: 1.1071478128433228
epoch 79800  training loss: 0.2976795732975006

 80%|█████████████████████████████████████████████████████▌             | 79968/100000 [20:20<04:25, 75.56it/s]
epoch 79900  training loss: 0.24492572247982025

 80%|█████████████████████████████████████████████████████▋             | 80120/100000 [20:22<04:21, 76.03it/s]
epoch 80000  training loss: 0.26899805665016174
epoch 80000  clean testing loss: 1.1073116064071655
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 80100  training loss: 0.2599777579307556

 80%|█████████████████████████████████████████████████████▊             | 80272/100000 [20:24<04:23, 74.99it/s]
epoch 80200  training loss: 0.28029540181159973

 80%|█████████████████████████████████████████████████████▉             | 80424/100000 [20:26<04:21, 74.97it/s]
epoch 80300  training loss: 0.23052555322647095
epoch 80300  clean testing loss: 1.1269561052322388
epoch 80400  training loss: 0.23036982119083405

 81%|█████████████████████████████████████████████████████▉             | 80576/100000 [20:28<04:17, 75.37it/s]
epoch 80500  training loss: 0.2702048718929291

 81%|██████████████████████████████████████████████████████             | 80728/100000 [20:30<04:16, 75.20it/s]
epoch 80600  training loss: 0.2665632367134094
epoch 80600  clean testing loss: 1.1176979541778564
epoch 80700  training loss: 0.23109953105449677

 81%|██████████████████████████████████████████████████████▏            | 80872/100000 [20:32<04:14, 75.12it/s]
epoch 80800  training loss: 0.2427138239145279
epoch 80800  clean testing loss: 1.1137988567352295
epoch 80900  training loss: 0.25145602226257324
epoch 80900  clean testing loss: 1.107265830039978
epoch 81000  training loss: 0.27714478969573975
epoch 81000  clean testing loss: 1.1169209480285645

 81%|██████████████████████████████████████████████████████▎            | 81024/100000 [20:34<04:14, 74.49it/s]
epoch 81100  training loss: 0.24169950187206268

 81%|██████████████████████████████████████████████████████▍            | 81176/100000 [20:36<04:10, 75.07it/s]
epoch 81200  training loss: 0.26370394229888916
epoch 81200  clean testing loss: 1.1170166730880737
epoch 81300  training loss: 0.27293381094932556

 81%|██████████████████████████████████████████████████████▍            | 81328/100000 [20:38<04:08, 75.11it/s]
epoch 81400  training loss: 0.26785537600517273

 81%|██████████████████████████████████████████████████████▌            | 81480/100000 [20:40<04:03, 75.93it/s]
epoch 81500  training loss: 0.26451215147972107
epoch 81500  clean testing loss: 1.1182725429534912
epoch 81600  training loss: 0.2907872796058655

 82%|██████████████████████████████████████████████████████▋            | 81632/100000 [20:42<04:03, 75.38it/s]
epoch 81700  training loss: 0.2801804840564728

 82%|██████████████████████████████████████████████████████▊            | 81776/100000 [20:44<04:01, 75.51it/s]
epoch 81800  training loss: 0.24194644391536713
epoch 81800  clean testing loss: 1.114880084991455
epoch 81900  training loss: 0.23735667765140533

 82%|██████████████████████████████████████████████████████▉            | 81928/100000 [20:46<03:59, 75.48it/s]
epoch 82000  training loss: 0.26003310084342957
epoch 82000  clean testing loss: 1.1121753454208374

 82%|██████████████████████████████████████████████████████▉            | 82080/100000 [20:48<03:57, 75.50it/s]
epoch 82100  training loss: 0.2815021574497223
epoch 82100  clean testing loss: 1.1113238334655762
epoch 82200  training loss: 0.2585459053516388

 82%|███████████████████████████████████████████████████████            | 82232/100000 [20:50<03:55, 75.54it/s]
epoch 82300  training loss: 0.25215181708335876

 82%|███████████████████████████████████████████████████████▏           | 82384/100000 [20:52<03:53, 75.40it/s]
epoch 82400  training loss: 0.2868957817554474
epoch 82400  clean testing loss: 1.1162668466567993
epoch 82500  training loss: 0.2680457830429077


 83%|███████████████████████████████████████████████████████▍           | 82688/100000 [20:56<03:48, 75.62it/s]
epoch 82600  training loss: 0.2846548855304718

 83%|███████████████████████████████████████████████████████▌           | 82840/100000 [20:58<03:47, 75.28it/s]
epoch 82700  training loss: 0.2584516108036041
epoch 82700  clean testing loss: 1.1212430000305176
epoch 82800  training loss: 0.23898804187774658

 83%|███████████████████████████████████████████████████████▌           | 82992/100000 [21:00<03:44, 75.66it/s]
epoch 82900  training loss: 0.24108177423477173

 83%|███████████████████████████████████████████████████████▋           | 83136/100000 [21:02<03:44, 75.24it/s]
epoch 83000  training loss: 0.24820385873317719
epoch 83000  clean testing loss: 1.1183797121047974
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 83100  training loss: 0.24950218200683594

 83%|███████████████████████████████████████████████████████▊           | 83288/100000 [21:04<03:41, 75.46it/s]
epoch 83200  training loss: 0.25268030166625977

 83%|███████████████████████████████████████████████████████▉           | 83440/100000 [21:06<03:39, 75.35it/s]
epoch 83300  training loss: 0.29246410727500916
epoch 83300  clean testing loss: 1.110581636428833
epoch 83400  training loss: 0.25968921184539795
epoch 83400  clean testing loss: 1.1147022247314453
epoch 83500  training loss: 0.2569252848625183

 84%|████████████████████████████████████████████████████████           | 83592/100000 [21:08<03:37, 75.46it/s]
epoch 83600  training loss: 0.2954083979129791
epoch 83600  clean testing loss: 1.1224136352539062
epoch 83700  training loss: 0.2490290403366089


 84%|████████████████████████████████████████████████████████▏          | 83896/100000 [21:12<03:33, 75.45it/s]
epoch 83800  training loss: 0.24289795756340027

 84%|████████████████████████████████████████████████████████▎          | 84048/100000 [21:14<03:32, 75.10it/s]
epoch 83900  training loss: 0.24213843047618866
epoch 83900  clean testing loss: 1.1146782636642456
epoch 84000  training loss: 0.28212398290634155
epoch 84000  clean testing loss: 1.1098759174346924

 84%|████████████████████████████████████████████████████████▍          | 84200/100000 [21:16<03:30, 75.13it/s]
epoch 84100  training loss: 0.2538797855377197

 84%|████████████████████████████████████████████████████████▌          | 84344/100000 [21:18<03:29, 74.84it/s]
epoch 84200  training loss: 0.2616117596626282
epoch 84200  clean testing loss: 1.1117730140686035
epoch 84300  training loss: 0.2744671702384949

 84%|████████████████████████████████████████████████████████▌          | 84496/100000 [21:20<03:24, 75.73it/s]
epoch 84400  training loss: 0.2616701126098633

 85%|████████████████████████████████████████████████████████▋          | 84648/100000 [21:22<03:22, 75.69it/s]
epoch 84500  training loss: 0.2618567943572998
epoch 84500  clean testing loss: 1.111426591873169
epoch 84600  training loss: 0.2630159258842468

 85%|████████████████████████████████████████████████████████▊          | 84800/100000 [21:24<03:23, 74.86it/s]
epoch 84700  training loss: 0.26257410645484924
epoch 84700  clean testing loss: 1.1171971559524536
epoch 84800  training loss: 0.27311310172080994

 85%|████████████████████████████████████████████████████████▉          | 84952/100000 [21:26<03:20, 75.24it/s]
epoch 84900  training loss: 0.2815113067626953

 85%|█████████████████████████████████████████████████████████          | 85104/100000 [21:28<03:16, 75.79it/s]
epoch 85000  training loss: 0.2563275098800659
epoch 85000  clean testing loss: 1.1147974729537964
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 85100  training loss: 0.27521151304244995

 85%|█████████████████████████████████████████████████████████          | 85256/100000 [21:30<03:15, 75.60it/s]
epoch 85200  training loss: 0.26001831889152527

 85%|█████████████████████████████████████████████████████████▏         | 85408/100000 [21:32<03:12, 75.65it/s]
epoch 85300  training loss: 0.2688104510307312
epoch 85300  clean testing loss: 1.1105151176452637
epoch 85400  training loss: 0.2824013829231262

 86%|█████████████████████████████████████████████████████████▎         | 85560/100000 [21:34<03:10, 75.68it/s]
epoch 85500  training loss: 0.2826961278915405

 86%|█████████████████████████████████████████████████████████▍         | 85712/100000 [21:36<03:09, 75.22it/s]
epoch 85600  training loss: 0.2632913589477539
epoch 85600  clean testing loss: 1.1171455383300781
epoch 85700  training loss: 0.24575871229171753

 86%|█████████████████████████████████████████████████████████▌         | 85864/100000 [21:38<03:07, 75.40it/s]
epoch 85800  training loss: 0.2724229395389557

 86%|█████████████████████████████████████████████████████████▋         | 86016/100000 [21:40<03:08, 74.22it/s]
epoch 85900  training loss: 0.26614734530448914
epoch 85900  clean testing loss: 1.1211979389190674
epoch 86000  training loss: 0.2544540762901306
epoch 86000  clean testing loss: 1.1200305223464966

 86%|█████████████████████████████████████████████████████████▋         | 86128/100000 [21:42<03:04, 75.00it/s]
epoch 86100  training loss: 0.2747022211551666

 86%|█████████████████████████████████████████████████████████▊         | 86280/100000 [21:44<03:01, 75.52it/s]
epoch 86200  training loss: 0.2627033293247223
epoch 86200  clean testing loss: 1.1252810955047607
epoch 86300  training loss: 0.25709953904151917

 86%|█████████████████████████████████████████████████████████▉         | 86432/100000 [21:46<03:00, 75.27it/s]
epoch 86400  training loss: 0.2686401903629303

 87%|██████████████████████████████████████████████████████████         | 86576/100000 [21:48<02:58, 75.11it/s]
epoch 86500  training loss: 0.26142987608909607
epoch 86500  clean testing loss: 1.1326043605804443
epoch 86600  training loss: 0.2711966037750244

 87%|██████████████████████████████████████████████████████████         | 86728/100000 [21:50<02:57, 74.85it/s]
epoch 86700  training loss: 0.2511555850505829

 87%|██████████████████████████████████████████████████████████▏        | 86880/100000 [21:52<02:54, 75.17it/s]
epoch 86800  training loss: 0.2488391101360321
epoch 86800  clean testing loss: 1.1329041719436646
epoch 86900  training loss: 0.24889764189720154

 87%|██████████████████████████████████████████████████████████▎        | 87032/100000 [21:54<02:52, 75.12it/s]
epoch 87000  training loss: 0.25168952345848083
epoch 87000  clean testing loss: 1.1320747137069702

 87%|██████████████████████████████████████████████████████████▍        | 87184/100000 [21:56<02:50, 75.31it/s]
epoch 87100  training loss: 0.27327248454093933
epoch 87100  clean testing loss: 1.1335293054580688
epoch 87200  training loss: 0.255273699760437

 87%|██████████████████████████████████████████████████████████▌        | 87336/100000 [21:58<02:47, 75.47it/s]
epoch 87300  training loss: 0.24517002701759338

 87%|██████████████████████████████████████████████████████████▌        | 87480/100000 [22:00<02:47, 74.80it/s]
epoch 87400  training loss: 0.26970455050468445
epoch 87400  clean testing loss: 1.1307010650634766
epoch 87500  training loss: 0.26139965653419495

 88%|██████████████████████████████████████████████████████████▋        | 87632/100000 [22:02<02:43, 75.64it/s]
epoch 87600  training loss: 0.26345959305763245

 88%|██████████████████████████████████████████████████████████▊        | 87784/100000 [22:04<02:42, 75.31it/s]
epoch 87700  training loss: 0.2681485116481781
epoch 87700  clean testing loss: 1.1242402791976929
epoch 87800  training loss: 0.2805950939655304

 88%|██████████████████████████████████████████████████████████▉        | 87936/100000 [22:06<02:40, 75.10it/s]
epoch 87900  training loss: 0.2802366018295288

 88%|███████████████████████████████████████████████████████████        | 88088/100000 [22:08<02:38, 75.13it/s]
epoch 88000  training loss: 0.253534734249115
epoch 88000  clean testing loss: 1.1242060661315918
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 88100  training loss: 0.24613302946090698

 88%|███████████████████████████████████████████████████████████        | 88240/100000 [22:10<02:35, 75.40it/s]
epoch 88200  training loss: 0.25080469250679016

 88%|███████████████████████████████████████████████████████████▏       | 88392/100000 [22:12<02:33, 75.47it/s]
epoch 88300  training loss: 0.25649988651275635
epoch 88300  clean testing loss: 1.1346089839935303
epoch 88400  training loss: 0.2795765697956085

 89%|███████████████████████████████████████████████████████████▎       | 88536/100000 [22:14<02:32, 75.22it/s]
epoch 88500  training loss: 0.2631883919239044

 89%|███████████████████████████████████████████████████████████▍       | 88688/100000 [22:16<02:29, 75.67it/s]
epoch 88600  training loss: 0.2888604700565338
epoch 88600  clean testing loss: 1.1139856576919556
epoch 88700  training loss: 0.2718086838722229

 89%|███████████████████████████████████████████████████████████▌       | 88840/100000 [22:18<02:27, 75.51it/s]
epoch 88800  training loss: 0.26615235209465027

 89%|███████████████████████████████████████████████████████████▌       | 88992/100000 [22:20<02:24, 76.12it/s]
epoch 88900  training loss: 0.2797556221485138
epoch 88900  clean testing loss: 1.1134732961654663
epoch 89000  training loss: 0.2611513137817383
epoch 89000  clean testing loss: 1.1127419471740723

 89%|███████████████████████████████████████████████████████████▋       | 89144/100000 [22:22<02:24, 75.36it/s]
epoch 89100  training loss: 0.24551457166671753

 89%|███████████████████████████████████████████████████████████▊       | 89296/100000 [22:24<02:21, 75.61it/s]
epoch 89200  training loss: 0.24109598994255066
epoch 89200  clean testing loss: 1.1219687461853027
epoch 89300  training loss: 0.279533714056015

 89%|███████████████████████████████████████████████████████████▉       | 89448/100000 [22:26<02:19, 75.67it/s]
epoch 89400  training loss: 0.2609986960887909

 90%|████████████████████████████████████████████████████████████       | 89600/100000 [22:28<02:17, 75.46it/s]
epoch 89500  training loss: 0.2664370834827423
epoch 89500  clean testing loss: 1.1183310747146606
epoch 89600  training loss: 0.27855947613716125

 90%|████████████████████████████████████████████████████████████▏      | 89752/100000 [22:30<02:16, 75.34it/s]
epoch 89700  training loss: 0.2553962171077728

 90%|████████████████████████████████████████████████████████████▏      | 89904/100000 [22:32<02:14, 75.28it/s]
epoch 89800  training loss: 0.2468811571598053
epoch 89800  clean testing loss: 1.127404808998108
epoch 89900  training loss: 0.25250697135925293

 90%|████████████████████████████████████████████████████████████▎      | 90056/100000 [22:34<02:11, 75.39it/s]
epoch 90000  training loss: 0.23201002180576324
epoch 90000  clean testing loss: 1.1222163438796997

 90%|████████████████████████████████████████████████████████████▍      | 90200/100000 [22:36<02:09, 75.59it/s]
epoch 90100  training loss: 0.26171261072158813
epoch 90100  clean testing loss: 1.1201446056365967
epoch 90200  training loss: 0.26348981261253357

 90%|████████████████████████████████████████████████████████████▌      | 90352/100000 [22:38<02:07, 75.75it/s]
epoch 90300  training loss: 0.2596805691719055

 91%|████████████████████████████████████████████████████████████▋      | 90504/100000 [22:40<02:05, 75.56it/s]
epoch 90400  training loss: 0.2396433800458908
epoch 90400  clean testing loss: 1.1293648481369019
epoch 90500  training loss: 0.238528773188591

 91%|████████████████████████████████████████████████████████████▋      | 90656/100000 [22:42<02:04, 75.27it/s]
epoch 90600  training loss: 0.26448699831962585

 91%|████████████████████████████████████████████████████████████▊      | 90808/100000 [22:44<02:02, 75.08it/s]
epoch 90700  training loss: 0.25864678621292114
epoch 90700  clean testing loss: 1.1238763332366943
epoch 90800  training loss: 0.25352707505226135

 91%|████████████████████████████████████████████████████████████▉      | 90960/100000 [22:46<01:59, 75.54it/s]
epoch 90900  training loss: 0.25474536418914795

 91%|█████████████████████████████████████████████████████████████      | 91112/100000 [22:48<01:57, 75.65it/s]
epoch 91000  training loss: 0.24442394077777863
epoch 91000  clean testing loss: 1.126590609550476
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 91100  training loss: 0.257429301738739

 91%|█████████████████████████████████████████████████████████████▏     | 91264/100000 [22:50<01:55, 75.87it/s]
epoch 91200  training loss: 0.2873561978340149

 91%|█████████████████████████████████████████████████████████████▏     | 91416/100000 [22:52<01:53, 75.56it/s]
epoch 91300  training loss: 0.24158795177936554
epoch 91300  clean testing loss: 1.1303584575653076
epoch 91400  training loss: 0.2689498960971832

 92%|█████████████████████████████████████████████████████████████▎     | 91568/100000 [22:54<01:51, 75.66it/s]
epoch 91500  training loss: 0.24557361006736755

 92%|█████████████████████████████████████████████████████████████▍     | 91720/100000 [22:56<01:50, 74.98it/s]
epoch 91600  training loss: 0.2514224350452423
epoch 91600  clean testing loss: 1.1269046068191528
epoch 91700  training loss: 0.2830214202404022

 92%|█████████████████████████████████████████████████████████████▌     | 91872/100000 [22:58<01:48, 75.26it/s]
epoch 91800  training loss: 0.2883360683917999

 92%|█████████████████████████████████████████████████████████████▋     | 92016/100000 [23:00<01:47, 74.57it/s]
epoch 91900  training loss: 0.28212404251098633
epoch 91900  clean testing loss: 1.1273083686828613
epoch 92000  training loss: 0.2537374496459961
epoch 92000  clean testing loss: 1.121768593788147

 92%|█████████████████████████████████████████████████████████████▊     | 92168/100000 [23:02<01:43, 75.34it/s]
epoch 92100  training loss: 0.2647165358066559

 92%|█████████████████████████████████████████████████████████████▊     | 92320/100000 [23:04<01:42, 75.11it/s]
epoch 92200  training loss: 0.26014330983161926
epoch 92200  clean testing loss: 1.1184827089309692
epoch 92300  training loss: 0.2455865889787674

 92%|█████████████████████████████████████████████████████████████▉     | 92472/100000 [23:06<01:40, 74.94it/s]
epoch 92400  training loss: 0.23093897104263306

 93%|██████████████████████████████████████████████████████████████     | 92624/100000 [23:08<01:38, 75.03it/s]
epoch 92500  training loss: 0.27958670258522034
epoch 92500  clean testing loss: 1.1239800453186035
epoch 92600  training loss: 0.27318745851516724

 93%|██████████████████████████████████████████████████████████████▏    | 92776/100000 [23:10<01:35, 75.58it/s]
epoch 92700  training loss: 0.2678956687450409

 93%|██████████████████████████████████████████████████████████████▎    | 92928/100000 [23:12<01:33, 75.72it/s]
epoch 92800  training loss: 0.2699406147003174
epoch 92800  clean testing loss: 1.1167089939117432
epoch 92900  training loss: 0.26553913950920105

 93%|██████████████████████████████████████████████████████████████▎    | 93080/100000 [23:14<01:32, 74.98it/s]
epoch 93000  training loss: 0.25117921829223633
epoch 93000  clean testing loss: 1.1188325881958008

 93%|██████████████████████████████████████████████████████████████▍    | 93224/100000 [23:16<01:30, 75.13it/s]
epoch 93100  training loss: 0.2627183496952057
epoch 93100  clean testing loss: 1.1157582998275757
epoch 93200  training loss: 0.2624911069869995

 93%|██████████████████████████████████████████████████████████████▌    | 93376/100000 [23:18<01:28, 75.04it/s]
epoch 93300  training loss: 0.2488185614347458

 94%|██████████████████████████████████████████████████████████████▋    | 93528/100000 [23:20<01:25, 75.27it/s]
epoch 93400  training loss: 0.2725452184677124
epoch 93400  clean testing loss: 1.1167261600494385
epoch 93500  training loss: 0.2415817826986313

 94%|██████████████████████████████████████████████████████████████▊    | 93680/100000 [23:22<01:23, 75.77it/s]
epoch 93600  training loss: 0.27143847942352295

 94%|██████████████████████████████████████████████████████████████▊    | 93832/100000 [23:24<01:22, 75.05it/s]
epoch 93700  training loss: 0.2626212537288666
epoch 93700  clean testing loss: 1.122115969657898
epoch 93800  training loss: 0.246236190199852

 94%|██████████████████████████████████████████████████████████████▉    | 93984/100000 [23:26<01:19, 75.74it/s]
epoch 93900  training loss: 0.2600041627883911

 94%|███████████████████████████████████████████████████████████████    | 94136/100000 [23:28<01:17, 75.50it/s]
epoch 94000  training loss: 0.2517779469490051
epoch 94000  clean testing loss: 1.1160188913345337
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 94100  training loss: 0.2633168697357178

 94%|███████████████████████████████████████████████████████████████▏   | 94288/100000 [23:30<01:15, 75.54it/s]
epoch 94200  training loss: 0.2768988311290741
epoch 94200  clean testing loss: 1.1056255102157593
epoch 94300  training loss: 0.23684176802635193

 94%|███████████████████████████████████████████████████████████████▎   | 94432/100000 [23:32<01:13, 75.32it/s]
epoch 94400  training loss: 0.27111876010894775

 95%|███████████████████████████████████████████████████████████████▎   | 94584/100000 [23:34<01:12, 75.12it/s]
epoch 94500  training loss: 0.25379884243011475
epoch 94500  clean testing loss: 1.116801381111145
epoch 94600  training loss: 0.2593468725681305

 95%|███████████████████████████████████████████████████████████████▍   | 94736/100000 [23:36<01:09, 75.69it/s]
epoch 94700  training loss: 0.280924916267395

 95%|███████████████████████████████████████████████████████████████▌   | 94888/100000 [23:38<01:07, 75.55it/s]
epoch 94800  training loss: 0.28985166549682617
epoch 94800  clean testing loss: 1.112474799156189
epoch 94900  training loss: 0.26959627866744995

 95%|███████████████████████████████████████████████████████████████▋   | 95040/100000 [23:40<01:05, 75.40it/s]
epoch 95000  training loss: 0.24034647643566132
epoch 95000  clean testing loss: 1.1089918613433838

 95%|███████████████████████████████████████████████████████████████▊   | 95192/100000 [23:42<01:03, 75.41it/s]
epoch 95100  training loss: 0.272176593542099
epoch 95100  clean testing loss: 1.1127229928970337
epoch 95200  training loss: 0.2691393792629242

 95%|███████████████████████████████████████████████████████████████▉   | 95344/100000 [23:44<01:01, 75.20it/s]
epoch 95300  training loss: 0.28640517592430115

 95%|███████████████████████████████████████████████████████████████▉   | 95488/100000 [23:46<01:00, 74.83it/s]
epoch 95400  training loss: 0.2704217731952667
epoch 95400  clean testing loss: 1.1208293437957764
epoch 95500  training loss: 0.2592920660972595

 96%|████████████████████████████████████████████████████████████████   | 95640/100000 [23:48<00:57, 75.24it/s]
epoch 95600  training loss: 0.26738476753234863

 96%|████████████████████████████████████████████████████████████████▏  | 95792/100000 [23:50<00:55, 75.22it/s]
epoch 95700  training loss: 0.2457757443189621
epoch 95700  clean testing loss: 1.118892788887024
epoch 95800  training loss: 0.22856636345386505

 96%|████████████████████████████████████████████████████████████████▎  | 95944/100000 [23:52<00:54, 75.05it/s]
epoch 95900  training loss: 0.22989733517169952

 96%|████████████████████████████████████████████████████████████████▍  | 96096/100000 [23:54<00:51, 75.19it/s]
epoch 96000  training loss: 0.23012296855449677
epoch 96000  clean testing loss: 1.1144825220108032
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 96100  training loss: 0.23543593287467957

 96%|████████████████████████████████████████████████████████████████▍  | 96248/100000 [23:56<00:49, 75.62it/s]
epoch 96200  training loss: 0.24563050270080566

 96%|████████████████████████████████████████████████████████████████▌  | 96392/100000 [23:58<00:47, 75.77it/s]
epoch 96300  training loss: 0.2578696310520172
epoch 96300  clean testing loss: 1.1134560108184814
epoch 96400  training loss: 0.25344160199165344

 97%|████████████████████████████████████████████████████████████████▋  | 96544/100000 [24:00<00:45, 75.46it/s]
epoch 96500  training loss: 0.25229278206825256

 97%|████████████████████████████████████████████████████████████████▊  | 96696/100000 [24:02<00:43, 75.33it/s]
epoch 96600  training loss: 0.2363198846578598
epoch 96600  clean testing loss: 1.1202689409255981
epoch 96700  training loss: 0.27413421869277954

 97%|████████████████████████████████████████████████████████████████▉  | 96848/100000 [24:04<00:42, 75.03it/s]
epoch 96800  training loss: 0.2577337622642517

 97%|████████████████████████████████████████████████████████████████▉  | 97000/100000 [24:06<00:39, 75.02it/s]
epoch 96900  training loss: 0.26072487235069275
epoch 96900  clean testing loss: 1.1213406324386597
epoch 97000  training loss: 0.24018774926662445
epoch 97000  clean testing loss: 1.1205896139144897

 97%|█████████████████████████████████████████████████████████████████  | 97152/100000 [24:08<00:37, 75.21it/s]
epoch 97100  training loss: 0.23322731256484985

 97%|█████████████████████████████████████████████████████████████████▏ | 97304/100000 [24:10<00:35, 75.16it/s]
epoch 97200  training loss: 0.2507528066635132
epoch 97200  clean testing loss: 1.1191685199737549
epoch 97300  training loss: 0.26125043630599976

 97%|█████████████████████████████████████████████████████████████████▎ | 97448/100000 [24:12<00:33, 75.07it/s]
epoch 97400  training loss: 0.23954999446868896

 98%|█████████████████████████████████████████████████████████████████▍ | 97600/100000 [24:14<00:32, 74.93it/s]
epoch 97500  training loss: 0.2424791306257248
epoch 97500  clean testing loss: 1.1194350719451904
epoch 97600  training loss: 0.2849012315273285

 98%|█████████████████████████████████████████████████████████████████▍ | 97752/100000 [24:16<00:29, 75.64it/s]
epoch 97700  training loss: 0.2417016625404358

 98%|█████████████████████████████████████████████████████████████████▌ | 97904/100000 [24:18<00:27, 75.75it/s]
epoch 97800  training loss: 0.26379308104515076
epoch 97800  clean testing loss: 1.1176133155822754
epoch 97900  training loss: 0.24773825705051422

 98%|█████████████████████████████████████████████████████████████████▋ | 98056/100000 [24:20<00:25, 75.92it/s]
epoch 98000  training loss: 0.2591400444507599
epoch 98000  clean testing loss: 1.119016408920288

 98%|█████████████████████████████████████████████████████████████████▊ | 98208/100000 [24:22<00:23, 75.82it/s]
epoch 98100  training loss: 0.2534390389919281
epoch 98100  clean testing loss: 1.117471694946289
epoch 98200  training loss: 0.25796908140182495

 98%|█████████████████████████████████████████████████████████████████▉ | 98360/100000 [24:25<00:21, 75.19it/s]
epoch 98300  training loss: 0.24007658660411835

 99%|██████████████████████████████████████████████████████████████████ | 98512/100000 [24:27<00:19, 75.77it/s]
epoch 98400  training loss: 0.2571779191493988
epoch 98400  clean testing loss: 1.1193121671676636
epoch 98500  training loss: 0.2646718919277191

 99%|██████████████████████████████████████████████████████████████████ | 98664/100000 [24:29<00:17, 75.76it/s]
epoch 98600  training loss: 0.24226288497447968

 99%|██████████████████████████████████████████████████████████████████▏| 98816/100000 [24:31<00:15, 75.71it/s]
epoch 98700  training loss: 0.2589398920536041
epoch 98700  clean testing loss: 1.1186199188232422
epoch 98800  training loss: 0.26156917214393616

 99%|██████████████████████████████████████████████████████████████████▎| 98968/100000 [24:33<00:13, 75.27it/s]
epoch 98900  training loss: 0.23986022174358368

 99%|██████████████████████████████████████████████████████████████████▍| 99112/100000 [24:34<00:11, 75.49it/s]
epoch 99000  training loss: 0.2600170373916626
epoch 99000  clean testing loss: 1.1153100728988647
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...
epoch 99100  training loss: 0.2571864724159241

 99%|██████████████████████████████████████████████████████████████████▌| 99264/100000 [24:36<00:09, 75.49it/s]
epoch 99200  training loss: 0.2422110140323639

 99%|██████████████████████████████████████████████████████████████████▌| 99416/100000 [24:39<00:07, 75.35it/s]
epoch 99300  training loss: 0.24404276907444
epoch 99300  clean testing loss: 1.1120474338531494
epoch 99400  training loss: 0.2638300359249115

100%|██████████████████████████████████████████████████████████████████▋| 99568/100000 [24:41<00:05, 75.42it/s]
epoch 99500  training loss: 0.24423381686210632

100%|██████████████████████████████████████████████████████████████████▊| 99720/100000 [24:43<00:03, 75.29it/s]
epoch 99600  training loss: 0.25910139083862305
epoch 99600  clean testing loss: 1.111038327217102
epoch 99700  training loss: 0.2710110545158386

100%|██████████████████████████████████████████████████████████████████▉| 99872/100000 [24:45<00:01, 75.02it/s]
epoch 99800  training loss: 0.23335589468479156

100%|██████████████████████████████████████████████████████████████████| 100000/100000 [24:46<00:00, 67.26it/s]
epoch 99900  training loss: 0.2734817564487457
epoch 99900  clean testing loss: 1.1068501472473145
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise1.00e+00_invop1_lr5e-05 ...