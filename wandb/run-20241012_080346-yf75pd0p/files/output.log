
  0%|          | 65/100000 [00:02<47:17, 35.22it/s]
epoch 0  training loss: 44.57735824584961
epoch 0  clean testing loss: 40.70396041870117

  0%|          | 133/100000 [00:03<47:14, 35.23it/s]
epoch 100  training loss: 17.914152145385742

  0%|          | 205/100000 [00:05<47:18, 35.16it/s]
epoch 200  training loss: 16.654644012451172


  0%|          | 329/100000 [00:09<47:06, 35.27it/s]
epoch 300  training loss: 15.300752639770508


  0%|          | 445/100000 [00:13<48:15, 34.38it/s]
epoch 400  training loss: 11.408817291259766

  0%|          | 497/100000 [00:15<52:20, 31.68it/s]
epoch 500  training loss: 4.492988109588623


  1%|          | 637/100000 [00:19<46:57, 35.26it/s]
epoch 600  training loss: 1.3283025026321411

  1%|          | 709/100000 [00:21<47:04, 35.16it/s]
epoch 700  training loss: 0.8591257333755493

  1%|          | 777/100000 [00:23<46:54, 35.25it/s]
epoch 800  training loss: 0.5891051888465881


  1%|          | 917/100000 [00:27<46:57, 35.16it/s]
epoch 900  training loss: 0.4246037006378174

  1%|          | 989/100000 [00:29<46:51, 35.22it/s]
epoch 1000  training loss: 0.34135690331459045
epoch 1000  clean testing loss: 0.260638564825058


  1%|          | 1125/100000 [00:33<46:52, 35.16it/s]
epoch 1100  training loss: 0.2809116244316101

  1%|          | 1197/100000 [00:35<46:45, 35.21it/s]
epoch 1200  training loss: 0.2304951548576355


  1%|▏         | 1337/100000 [00:39<46:45, 35.17it/s]
epoch 1300  training loss: 0.20953217148780823

  1%|▏         | 1409/100000 [00:41<46:55, 35.02it/s]
epoch 1400  training loss: 0.18767157196998596


  2%|▏         | 1549/100000 [00:45<46:41, 35.15it/s]
epoch 1500  training loss: 0.16653291881084442

  2%|▏         | 1617/100000 [00:47<46:53, 34.96it/s]
epoch 1600  training loss: 0.15508417785167694

  2%|▏         | 1689/100000 [00:49<46:37, 35.14it/s]
epoch 1700  training loss: 0.15109233558177948


  2%|▏         | 1829/100000 [00:53<46:37, 35.09it/s]
epoch 1800  training loss: 0.1470215767621994

  2%|▏         | 1897/100000 [00:55<47:13, 34.62it/s]
epoch 1900  training loss: 0.14323541522026062


  2%|▏         | 2037/100000 [00:59<46:36, 35.03it/s]
epoch 2000  training loss: 0.13904431462287903
epoch 2000  clean testing loss: 0.06364332884550095

  2%|▏         | 2109/100000 [01:01<46:40, 34.95it/s]
epoch 2100  training loss: 0.13695554435253143


  2%|▏         | 2249/100000 [01:05<46:27, 35.07it/s]
epoch 2200  training loss: 0.12895622849464417

  2%|▏         | 2317/100000 [01:07<46:28, 35.03it/s]
epoch 2300  training loss: 0.1247265487909317

  2%|▏         | 2389/100000 [01:09<46:24, 35.05it/s]
epoch 2400  training loss: 0.12157723307609558


  3%|▎         | 2525/100000 [01:13<46:23, 35.02it/s]
epoch 2500  training loss: 0.12032576650381088

  3%|▎         | 2597/100000 [01:15<46:19, 35.04it/s]
epoch 2600  training loss: 0.12579792737960815


  3%|▎         | 2737/100000 [01:19<46:17, 35.02it/s]
epoch 2700  training loss: 0.1198524609208107

  3%|▎         | 2809/100000 [01:21<46:26, 34.88it/s]
epoch 2800  training loss: 0.1185351014137268


  3%|▎         | 2945/100000 [01:25<47:17, 34.21it/s]
epoch 2900  training loss: 0.11597752571105957

  3%|▎         | 3017/100000 [01:27<46:31, 34.75it/s]
epoch 3000  training loss: 0.11475085467100143
epoch 3000  clean testing loss: 0.036729149520397186

  3%|▎         | 3085/100000 [01:29<46:08, 35.00it/s]
epoch 3100  training loss: 0.11254585534334183


  3%|▎         | 3225/100000 [01:33<46:11, 34.92it/s]
epoch 3200  training loss: 0.11071620881557465

  3%|▎         | 3297/100000 [01:35<46:05, 34.96it/s]
epoch 3300  training loss: 0.10897726565599442


  3%|▎         | 3437/100000 [01:39<46:02, 34.96it/s]
epoch 3400  training loss: 0.10859686136245728

  4%|▎         | 3505/100000 [01:41<46:11, 34.82it/s]
epoch 3500  training loss: 0.11019494384527206


  4%|▎         | 3645/100000 [01:45<45:59, 34.92it/s]
epoch 3600  training loss: 0.11052658408880234

  4%|▎         | 3717/100000 [01:47<46:01, 34.86it/s]
epoch 3700  training loss: 0.10791166871786118

  4%|▍         | 3785/100000 [01:49<45:55, 34.91it/s]
epoch 3800  training loss: 0.10818292945623398


  4%|▍         | 3925/100000 [01:53<45:56, 34.86it/s]
epoch 3900  training loss: 0.10653351992368698

  4%|▍         | 3993/100000 [01:55<47:13, 33.88it/s]
epoch 4000  training loss: 0.10617385059595108
epoch 4000  clean testing loss: 0.02959711290895939


  4%|▍         | 4133/100000 [01:59<45:47, 34.89it/s]
epoch 4100  training loss: 0.10489938408136368

  4%|▍         | 4201/100000 [02:01<45:49, 34.84it/s]
epoch 4200  training loss: 0.10359438508749008


  4%|▍         | 4341/100000 [02:05<45:41, 34.89it/s]
epoch 4300  training loss: 0.10589120537042618

  4%|▍         | 4409/100000 [02:07<45:46, 34.80it/s]
epoch 4400  training loss: 0.10514210909605026


  5%|▍         | 4549/100000 [02:11<45:38, 34.86it/s]
epoch 4500  training loss: 0.10431835800409317

  5%|▍         | 4621/100000 [02:13<45:48, 34.71it/s]
epoch 4600  training loss: 0.10204433649778366

  5%|▍         | 4689/100000 [02:15<45:33, 34.86it/s]
epoch 4700  training loss: 0.10312953591346741


  5%|▍         | 4829/100000 [02:19<45:31, 34.84it/s]
epoch 4800  training loss: 0.10054168105125427

  5%|▍         | 4901/100000 [02:21<45:30, 34.82it/s]
epoch 4900  training loss: 0.09938045591115952


  5%|▌         | 5037/100000 [02:25<46:59, 33.68it/s]
epoch 5000  training loss: 0.09901934862136841
epoch 5000  clean testing loss: 0.023224318400025368

  5%|▌         | 5105/100000 [02:27<45:38, 34.65it/s]
epoch 5100  training loss: 0.09851746261119843


  5%|▌         | 5245/100000 [02:31<45:19, 34.84it/s]
epoch 5200  training loss: 0.09772041440010071

  5%|▌         | 5317/100000 [02:33<45:21, 34.79it/s]
epoch 5300  training loss: 0.09675966203212738

  5%|▌         | 5385/100000 [02:35<45:14, 34.86it/s]
epoch 5400  training loss: 0.09758897125720978


  6%|▌         | 5525/100000 [02:39<45:12, 34.83it/s]
epoch 5500  training loss: 0.09736484289169312

  6%|▌         | 5593/100000 [02:41<45:12, 34.80it/s]
epoch 5600  training loss: 0.09641296416521072


  6%|▌         | 5733/100000 [02:45<45:05, 34.85it/s]
epoch 5700  training loss: 0.10047143697738647

  6%|▌         | 5805/100000 [02:47<45:15, 34.69it/s]
epoch 5800  training loss: 0.0962849110364914


  6%|▌         | 5941/100000 [02:51<45:01, 34.81it/s]
epoch 5900  training loss: 0.0962287113070488

  6%|▌         | 6013/100000 [02:53<45:17, 34.59it/s]
epoch 6000  training loss: 0.09774750471115112
epoch 6000  clean testing loss: 0.022905828431248665


  6%|▌         | 6149/100000 [02:57<44:57, 34.79it/s]
epoch 6100  training loss: 0.09543251991271973

  6%|▌         | 6221/100000 [02:59<44:54, 34.80it/s]
epoch 6200  training loss: 0.09490038454532623

  6%|▋         | 6289/100000 [03:01<44:50, 34.83it/s]
epoch 6300  training loss: 0.09434261173009872


  6%|▋         | 6429/100000 [03:05<44:50, 34.78it/s]
epoch 6400  training loss: 0.09511510282754898

  6%|▋         | 6497/100000 [03:07<44:47, 34.79it/s]
epoch 6500  training loss: 0.09403462707996368


  7%|▋         | 6637/100000 [03:11<44:45, 34.76it/s]
epoch 6600  training loss: 0.09437362104654312

  7%|▋         | 6709/100000 [03:13<44:51, 34.66it/s]
epoch 6700  training loss: 0.09624788910150528


  7%|▋         | 6845/100000 [03:17<44:36, 34.80it/s]
epoch 6800  training loss: 0.09433796256780624

  7%|▋         | 6917/100000 [03:19<44:38, 34.75it/s]
epoch 6900  training loss: 0.09512123465538025

  7%|▋         | 6985/100000 [03:21<44:31, 34.81it/s]
epoch 7000  training loss: 0.09452816843986511
epoch 7000  clean testing loss: 0.020021064206957817


  7%|▋         | 7121/100000 [03:25<48:13, 32.10it/s]
epoch 7100  training loss: 0.09619233012199402

  7%|▋         | 7193/100000 [03:27<44:23, 34.85it/s]
epoch 7200  training loss: 0.09388133138418198


  7%|▋         | 7333/100000 [03:31<44:23, 34.79it/s]
epoch 7300  training loss: 0.09654685854911804

  7%|▋         | 7401/100000 [03:33<44:23, 34.77it/s]
epoch 7400  training loss: 0.0932912677526474


  8%|▊         | 7541/100000 [03:37<44:18, 34.78it/s]
epoch 7500  training loss: 0.09365615993738174

  8%|▊         | 7609/100000 [03:39<44:25, 34.66it/s]
epoch 7600  training loss: 0.09287615865468979


  8%|▊         | 7749/100000 [03:43<44:18, 34.70it/s]
epoch 7700  training loss: 0.09284105151891708

  8%|▊         | 7821/100000 [03:46<44:12, 34.76it/s]
epoch 7800  training loss: 0.09295544028282166

  8%|▊         | 7889/100000 [03:47<44:07, 34.80it/s]
epoch 7900  training loss: 0.09372492134571075


  8%|▊         | 8029/100000 [03:51<44:06, 34.75it/s]
epoch 8000  training loss: 0.0926491767168045
epoch 8000  clean testing loss: 0.01959780417382717

  8%|▊         | 8097/100000 [03:53<44:00, 34.80it/s]
epoch 8100  training loss: 0.09237880259752274


  8%|▊         | 8233/100000 [03:57<44:01, 34.74it/s]
epoch 8200  training loss: 0.09292848408222198

  8%|▊         | 8305/100000 [04:00<43:59, 34.74it/s]
epoch 8300  training loss: 0.09216377884149551


  8%|▊         | 8445/100000 [04:04<43:46, 34.86it/s]
epoch 8400  training loss: 0.09326691925525665

  9%|▊         | 8513/100000 [04:05<43:46, 34.83it/s]
epoch 8500  training loss: 0.09184423089027405

  9%|▊         | 8585/100000 [04:08<43:40, 34.89it/s]
epoch 8600  training loss: 0.09198654443025589


  9%|▊         | 8725/100000 [04:12<43:40, 34.84it/s]
epoch 8700  training loss: 0.09225527197122574

  9%|▉         | 8793/100000 [04:14<43:33, 34.90it/s]
epoch 8800  training loss: 0.09215313196182251


  9%|▉         | 8933/100000 [04:18<43:31, 34.87it/s]
epoch 8900  training loss: 0.09228655695915222

  9%|▉         | 9001/100000 [04:19<44:18, 34.23it/s]
epoch 9000  training loss: 0.09182905405759811
epoch 9000  clean testing loss: 0.018264934420585632


  9%|▉         | 9141/100000 [04:24<43:25, 34.87it/s]
epoch 9100  training loss: 0.0914439707994461

  9%|▉         | 9209/100000 [04:26<48:29, 31.20it/s]
epoch 9200  training loss: 0.09185292571783066


  9%|▉         | 9349/100000 [04:30<43:18, 34.89it/s]
epoch 9300  training loss: 0.09242486953735352

  9%|▉         | 9421/100000 [04:32<43:18, 34.86it/s]
epoch 9400  training loss: 0.09202752262353897

  9%|▉         | 9489/100000 [04:34<43:40, 34.54it/s]
epoch 9500  training loss: 0.09248210489749908


 10%|▉         | 9629/100000 [04:38<43:12, 34.86it/s]
epoch 9600  training loss: 0.09578900039196014

 10%|▉         | 9697/100000 [04:40<43:30, 34.60it/s]
epoch 9700  training loss: 0.09563912451267242


 10%|▉         | 9837/100000 [04:44<43:07, 34.85it/s]
epoch 9800  training loss: 0.09707307815551758

 10%|▉         | 9909/100000 [04:46<43:08, 34.81it/s]
epoch 9900  training loss: 0.09856333583593369


 10%|█         | 10049/100000 [04:50<43:04, 34.81it/s]
epoch 10000  training loss: 0.09926804155111313
epoch 10000  clean testing loss: 0.02000240422785282

 10%|█         | 10117/100000 [04:52<43:01, 34.82it/s]
epoch 10100  training loss: 0.09889862686395645

 10%|█         | 10189/100000 [04:54<42:54, 34.89it/s]
epoch 10200  training loss: 0.0982135459780693


 10%|█         | 10325/100000 [04:58<43:00, 34.75it/s]
epoch 10300  training loss: 0.09946517646312714

 10%|█         | 10393/100000 [05:00<42:53, 34.82it/s]
epoch 10400  training loss: 0.10039953142404556


 11%|█         | 10533/100000 [05:04<42:46, 34.85it/s]
epoch 10500  training loss: 0.1011253297328949

 11%|█         | 10605/100000 [05:06<42:56, 34.69it/s]
epoch 10600  training loss: 0.10071266442537308


 11%|█         | 10745/100000 [05:10<42:46, 34.78it/s]
epoch 10700  training loss: 0.10190584510564804

 11%|█         | 10813/100000 [05:12<42:38, 34.86it/s]
epoch 10800  training loss: 0.10253889113664627

 11%|█         | 10885/100000 [05:14<42:40, 34.80it/s]
epoch 10900  training loss: 0.09935229271650314


 11%|█         | 11025/100000 [05:18<42:37, 34.79it/s]
epoch 11000  training loss: 0.09930431842803955
epoch 11000  clean testing loss: 0.019705260172486305

 11%|█         | 11093/100000 [05:20<42:35, 34.79it/s]
epoch 11100  training loss: 0.09917961806058884


 11%|█         | 11233/100000 [05:24<42:23, 34.90it/s]
epoch 11200  training loss: 0.09953176975250244

 11%|█▏        | 11301/100000 [05:26<47:05, 31.40it/s]
epoch 11300  training loss: 0.09845231473445892


 11%|█▏        | 11441/100000 [05:30<42:16, 34.92it/s]
epoch 11400  training loss: 0.09775600582361221

 12%|█▏        | 11509/100000 [05:32<42:21, 34.82it/s]
epoch 11500  training loss: 0.09748934954404831


 12%|█▏        | 11649/100000 [05:36<42:10, 34.91it/s]
epoch 11600  training loss: 0.09800274670124054

 12%|█▏        | 11721/100000 [05:38<42:12, 34.85it/s]
epoch 11700  training loss: 0.09650075435638428

 12%|█▏        | 11789/100000 [05:40<42:20, 34.72it/s]
epoch 11800  training loss: 0.0968354344367981


 12%|█▏        | 11929/100000 [05:44<42:09, 34.82it/s]
epoch 11900  training loss: 0.09642819315195084

 12%|█▏        | 11997/100000 [05:46<41:59, 34.92it/s]
epoch 12000  training loss: 0.09572930634021759
epoch 12000  clean testing loss: 0.016471782699227333


 12%|█▏        | 12137/100000 [05:50<41:57, 34.90it/s]
epoch 12100  training loss: 0.09565582126379013

 12%|█▏        | 12209/100000 [05:52<42:02, 34.80it/s]
epoch 12200  training loss: 0.09503347426652908


 12%|█▏        | 12349/100000 [05:56<41:51, 34.89it/s]
epoch 12300  training loss: 0.09588903933763504

 12%|█▏        | 12417/100000 [05:58<41:55, 34.82it/s]
epoch 12400  training loss: 0.0956183597445488

 12%|█▏        | 12485/100000 [06:00<41:45, 34.93it/s]
epoch 12500  training loss: 0.09498616307973862


 13%|█▎        | 12625/100000 [06:04<41:44, 34.89it/s]
epoch 12600  training loss: 0.09535869210958481

 13%|█▎        | 12693/100000 [06:06<41:38, 34.95it/s]
epoch 12700  training loss: 0.09548415243625641


 13%|█▎        | 12833/100000 [06:10<41:39, 34.87it/s]
epoch 12800  training loss: 0.09419805556535721

 13%|█▎        | 12905/100000 [06:12<41:42, 34.81it/s]
epoch 12900  training loss: 0.09425212442874908


 13%|█▎        | 13045/100000 [06:16<41:28, 34.94it/s]
epoch 13000  training loss: 0.11169258505105972
epoch 13000  clean testing loss: 0.02805522456765175

 13%|█▎        | 13113/100000 [06:18<41:32, 34.86it/s]
epoch 13100  training loss: 0.09389010816812515

 13%|█▎        | 13185/100000 [06:20<41:24, 34.95it/s]
epoch 13200  training loss: 0.09282059967517853


 13%|█▎        | 13325/100000 [06:24<41:21, 34.93it/s]
epoch 13300  training loss: 0.0926429033279419

 13%|█▎        | 13393/100000 [06:26<41:16, 34.97it/s]
epoch 13400  training loss: 0.09247884154319763


 14%|█▎        | 13533/100000 [06:30<41:15, 34.93it/s]
epoch 13500  training loss: 0.09244362264871597

 14%|█▎        | 13601/100000 [06:32<41:14, 34.92it/s]
epoch 13600  training loss: 0.09118399769067764


 14%|█▎        | 13741/100000 [06:36<41:08, 34.95it/s]
epoch 13700  training loss: 0.09245206415653229

 14%|█▍        | 13813/100000 [06:38<41:10, 34.89it/s]
epoch 13800  training loss: 0.0920025035738945


 14%|█▍        | 13949/100000 [06:42<41:00, 34.97it/s]
epoch 13900  training loss: 0.09150153398513794

 14%|█▍        | 14021/100000 [06:44<41:08, 34.83it/s]
epoch 14000  training loss: 0.091771200299263
epoch 14000  clean testing loss: 0.015537240542471409

 14%|█▍        | 14089/100000 [06:46<40:57, 34.96it/s]
epoch 14100  training loss: 0.0925530269742012


 14%|█▍        | 14229/100000 [06:50<40:54, 34.94it/s]
epoch 14200  training loss: 0.09200594574213028

 14%|█▍        | 14301/100000 [06:52<40:56, 34.89it/s]
epoch 14300  training loss: 0.0915725901722908


 14%|█▍        | 14441/100000 [06:56<40:49, 34.94it/s]
epoch 14400  training loss: 0.0912703275680542

 15%|█▍        | 14509/100000 [06:58<40:59, 34.76it/s]
epoch 14500  training loss: 0.09089043736457825


 15%|█▍        | 14649/100000 [07:02<40:42, 34.95it/s]
epoch 14600  training loss: 0.09211722016334534

 15%|█▍        | 14717/100000 [07:04<40:44, 34.88it/s]
epoch 14700  training loss: 0.09329307824373245

 15%|█▍        | 14789/100000 [07:06<40:48, 34.80it/s]
epoch 14800  training loss: 0.09370497614145279


 15%|█▍        | 14929/100000 [07:10<40:48, 34.74it/s]
epoch 14900  training loss: 0.09294960647821426

 15%|█▍        | 14997/100000 [07:12<40:30, 34.97it/s]
epoch 15000  training loss: 0.09233323484659195
epoch 15000  clean testing loss: 0.015153484418988228


 15%|█▌        | 15137/100000 [07:16<40:29, 34.93it/s]
epoch 15100  training loss: 0.09180464595556259

 15%|█▌        | 15205/100000 [07:18<40:34, 34.83it/s]
epoch 15200  training loss: 0.09167133271694183


 15%|█▌        | 15345/100000 [07:22<40:23, 34.92it/s]
epoch 15300  training loss: 0.09139663726091385

 15%|█▌        | 15417/100000 [07:24<40:39, 34.67it/s]
epoch 15400  training loss: 0.09142890572547913

 15%|█▌        | 15469/100000 [07:25<40:20, 34.92it/s]
epoch 15500  training loss: 0.09034851938486099


 16%|█▌        | 15605/100000 [07:29<40:27, 34.77it/s]
epoch 15600  training loss: 0.09028788655996323

 16%|█▌        | 15677/100000 [07:31<40:17, 34.88it/s]
epoch 15700  training loss: 0.09078125655651093


 16%|█▌        | 15817/100000 [07:35<40:17, 34.82it/s]
epoch 15800  training loss: 0.09082187712192535

 16%|█▌        | 15885/100000 [07:37<40:13, 34.85it/s]
epoch 15900  training loss: 0.09043251723051071


 16%|█▌        | 16025/100000 [07:41<40:08, 34.86it/s]
epoch 16000  training loss: 0.08999012410640717
epoch 16000  clean testing loss: 0.015095556154847145

 16%|█▌        | 16097/100000 [07:44<40:06, 34.86it/s]
epoch 16100  training loss: 0.09019017219543457

 16%|█▌        | 16165/100000 [07:45<40:00, 34.92it/s]
epoch 16200  training loss: 0.0898013785481453


 16%|█▋        | 16305/100000 [07:49<40:08, 34.74it/s]
epoch 16300  training loss: 0.08975449949502945

 16%|█▋        | 16373/100000 [07:51<39:58, 34.87it/s]
epoch 16400  training loss: 0.08978015184402466


 17%|█▋        | 16513/100000 [07:55<39:58, 34.81it/s]
epoch 16500  training loss: 0.09033649414777756

 17%|█▋        | 16581/100000 [07:57<40:43, 34.14it/s]
epoch 16600  training loss: 0.08934430032968521


 17%|█▋        | 16721/100000 [08:01<39:49, 34.85it/s]
epoch 16700  training loss: 0.0891663208603859

 17%|█▋        | 16793/100000 [08:04<39:46, 34.87it/s]
epoch 16800  training loss: 0.08931466937065125


 17%|█▋        | 16933/100000 [08:08<39:44, 34.84it/s]
epoch 16900  training loss: 0.08917047828435898

 17%|█▋        | 17001/100000 [08:10<40:45, 33.93it/s]
epoch 17000  training loss: 0.09001701325178146
epoch 17000  clean testing loss: 0.015459493733942509

 17%|█▋        | 17069/100000 [08:11<39:36, 34.89it/s]
epoch 17100  training loss: 0.08924936503171921


 17%|█▋        | 17209/100000 [08:16<39:42, 34.76it/s]
epoch 17200  training loss: 0.08881128579378128


 17%|█▋        | 17349/100000 [08:20<39:31, 34.86it/s]
epoch 17300  training loss: 0.08955729752779007

 17%|█▋        | 17421/100000 [08:22<39:27, 34.88it/s]
epoch 17400  training loss: 0.08976577967405319

 17%|█▋        | 17489/100000 [08:24<39:24, 34.89it/s]
epoch 17500  training loss: 0.08818641304969788


 18%|█▊        | 17629/100000 [08:28<40:22, 34.01it/s]
epoch 17600  training loss: 0.08754649758338928

 18%|█▊        | 17697/100000 [08:30<39:18, 34.89it/s]
epoch 17700  training loss: 0.08764311671257019


 18%|█▊        | 17837/100000 [08:34<39:16, 34.87it/s]
epoch 17800  training loss: 0.08718722313642502

 18%|█▊        | 17905/100000 [08:36<39:26, 34.69it/s]
epoch 17900  training loss: 0.08808824419975281


 18%|█▊        | 18045/100000 [08:40<39:31, 34.55it/s]
epoch 18000  training loss: 0.08781247586011887
epoch 18000  clean testing loss: 0.01610296033322811

 18%|█▊        | 18117/100000 [08:42<39:11, 34.82it/s]
epoch 18100  training loss: 0.08711172640323639

 18%|█▊        | 18185/100000 [08:44<39:07, 34.85it/s]
epoch 18200  training loss: 0.08716656267642975


 18%|█▊        | 18325/100000 [08:48<39:04, 34.83it/s]
epoch 18300  training loss: 0.08768495917320251

 18%|█▊        | 18393/100000 [08:50<39:00, 34.87it/s]
epoch 18400  training loss: 0.08712755888700485


 19%|█▊        | 18533/100000 [08:54<38:56, 34.86it/s]
epoch 18500  training loss: 0.0867510735988617

 19%|█▊        | 18605/100000 [08:56<39:01, 34.76it/s]
epoch 18600  training loss: 0.0872693732380867


 19%|█▊        | 18741/100000 [09:00<38:52, 34.83it/s]
epoch 18700  training loss: 0.08683454245328903

 19%|█▉        | 18813/100000 [09:02<38:51, 34.82it/s]
epoch 18800  training loss: 0.08612993359565735


 19%|█▉        | 18949/100000 [09:06<38:44, 34.87it/s]
epoch 18900  training loss: 0.08662917464971542

 19%|█▉        | 19021/100000 [09:08<38:59, 34.62it/s]
epoch 19000  training loss: 0.08754265308380127
epoch 19000  clean testing loss: 0.01636093482375145

 19%|█▉        | 19089/100000 [09:10<38:39, 34.88it/s]
epoch 19100  training loss: 0.08914270997047424


 19%|█▉        | 19229/100000 [09:14<38:41, 34.79it/s]
epoch 19200  training loss: 0.08944064378738403

 19%|█▉        | 19301/100000 [09:16<38:36, 34.84it/s]
epoch 19300  training loss: 0.08857647329568863


 19%|█▉        | 19441/100000 [09:20<38:30, 34.86it/s]
epoch 19400  training loss: 0.0884317010641098

 20%|█▉        | 19509/100000 [09:22<38:36, 34.75it/s]
epoch 19500  training loss: 0.08759164810180664


 20%|█▉        | 19649/100000 [09:26<38:25, 34.85it/s]
epoch 19600  training loss: 0.08782362937927246

 20%|█▉        | 19717/100000 [09:28<39:58, 33.47it/s]
epoch 19700  training loss: 0.08763553202152252

 20%|█▉        | 19785/100000 [09:30<38:21, 34.86it/s]
epoch 19800  training loss: 0.08724281936883926


 20%|█▉        | 19925/100000 [09:34<38:18, 34.84it/s]
epoch 19900  training loss: 0.08697796612977982

 20%|█▉        | 19997/100000 [09:36<38:12, 34.89it/s]
epoch 20000  training loss: 0.08703393489122391
epoch 20000  clean testing loss: 0.016244715079665184


 20%|██        | 20133/100000 [09:40<38:21, 34.70it/s]
epoch 20100  training loss: 0.08718305826187134

 20%|██        | 20205/100000 [09:42<38:25, 34.61it/s]
epoch 20200  training loss: 0.08617798238992691


 20%|██        | 20345/100000 [09:46<38:03, 34.88it/s]
epoch 20300  training loss: 0.08608931303024292

 20%|██        | 20413/100000 [09:48<38:07, 34.79it/s]
epoch 20400  training loss: 0.08666667342185974

 20%|██        | 20485/100000 [09:50<37:59, 34.88it/s]
epoch 20500  training loss: 0.08710406720638275


 21%|██        | 20625/100000 [09:54<38:05, 34.73it/s]
epoch 20600  training loss: 0.08683197945356369

 21%|██        | 20693/100000 [09:56<37:53, 34.88it/s]
epoch 20700  training loss: 0.08630634844303131


 21%|██        | 20829/100000 [10:00<37:53, 34.83it/s]
epoch 20800  training loss: 0.08582961559295654

 21%|██        | 20901/100000 [10:02<37:55, 34.76it/s]
epoch 20900  training loss: 0.08693956583738327


 21%|██        | 21041/100000 [10:06<37:47, 34.82it/s]
epoch 21000  training loss: 0.08753518015146255
epoch 21000  clean testing loss: 0.017410503700375557

 21%|██        | 21109/100000 [10:08<37:48, 34.77it/s]
epoch 21100  training loss: 0.08685270696878433


 21%|██        | 21249/100000 [10:12<37:37, 34.88it/s]
epoch 21200  training loss: 0.08702420443296432

 21%|██▏       | 21317/100000 [10:14<37:37, 34.86it/s]
epoch 21300  training loss: 0.08668600022792816

 21%|██▏       | 21389/100000 [10:16<37:30, 34.92it/s]
epoch 21400  training loss: 0.08632659912109375


 22%|██▏       | 21529/100000 [10:20<37:30, 34.86it/s]
epoch 21500  training loss: 0.08635544776916504

 22%|██▏       | 21597/100000 [10:22<37:26, 34.90it/s]
epoch 21600  training loss: 0.08579818904399872


 22%|██▏       | 21737/100000 [10:26<37:24, 34.87it/s]
epoch 21700  training loss: 0.08585870265960693

 22%|██▏       | 21805/100000 [10:28<40:56, 31.83it/s]
epoch 21800  training loss: 0.08603395521640778


 22%|██▏       | 21945/100000 [10:32<37:18, 34.86it/s]
epoch 21900  training loss: 0.08635452389717102

 22%|██▏       | 22017/100000 [10:34<37:21, 34.78it/s]
epoch 22000  training loss: 0.08576188236474991
epoch 22000  clean testing loss: 0.019930221140384674

 22%|██▏       | 22085/100000 [10:36<37:11, 34.92it/s]
epoch 22100  training loss: 0.08499877899885178


 22%|██▏       | 22225/100000 [10:40<37:08, 34.90it/s]
epoch 22200  training loss: 0.08527061343193054

 22%|██▏       | 22293/100000 [10:42<37:09, 34.85it/s]
epoch 22300  training loss: 0.08527135848999023


 22%|██▏       | 22433/100000 [10:46<37:02, 34.91it/s]
epoch 22400  training loss: 0.08551947772502899

 23%|██▎       | 22505/100000 [10:48<37:07, 34.78it/s]
epoch 22500  training loss: 0.08564145117998123


 23%|██▎       | 22645/100000 [10:52<37:01, 34.82it/s]
epoch 22600  training loss: 0.08524820953607559

 23%|██▎       | 22713/100000 [10:54<37:00, 34.81it/s]
epoch 22700  training loss: 0.08555853366851807

 23%|██▎       | 22785/100000 [10:56<36:52, 34.90it/s]
epoch 22800  training loss: 0.08589638769626617


 23%|██▎       | 22921/100000 [11:00<36:52, 34.84it/s]
epoch 22900  training loss: 0.08462300896644592

 23%|██▎       | 22993/100000 [11:02<36:45, 34.92it/s]
epoch 23000  training loss: 0.0856165960431099
epoch 23000  clean testing loss: 0.017606953158974648


 23%|██▎       | 23129/100000 [11:06<36:44, 34.86it/s]
epoch 23100  training loss: 0.08612290024757385

 23%|██▎       | 23201/100000 [11:08<36:44, 34.84it/s]
epoch 23200  training loss: 0.08454948663711548


 23%|██▎       | 23341/100000 [11:12<36:37, 34.89it/s]
epoch 23300  training loss: 0.08476869016885757

 23%|██▎       | 23409/100000 [11:14<36:40, 34.80it/s]
epoch 23400  training loss: 0.08387387543916702


 24%|██▎       | 23549/100000 [11:18<36:30, 34.90it/s]
epoch 23500  training loss: 0.0843973457813263

 24%|██▎       | 23621/100000 [11:20<36:29, 34.88it/s]
epoch 23600  training loss: 0.08450295031070709

 24%|██▎       | 23689/100000 [11:22<36:26, 34.90it/s]
epoch 23700  training loss: 0.08465411514043808


 24%|██▍       | 23829/100000 [11:26<36:24, 34.87it/s]
epoch 23800  training loss: 0.08469394594430923

 24%|██▍       | 23897/100000 [11:28<36:18, 34.93it/s]
epoch 23900  training loss: 0.08375099301338196


 24%|██▍       | 24037/100000 [11:32<36:18, 34.87it/s]
epoch 24000  training loss: 0.08489640802145004
epoch 24000  clean testing loss: 0.018488088622689247

 24%|██▍       | 24105/100000 [11:34<36:23, 34.76it/s]
epoch 24100  training loss: 0.08489745855331421


 24%|██▍       | 24245/100000 [11:38<36:11, 34.89it/s]
epoch 24200  training loss: 0.08384425193071365

 24%|██▍       | 24317/100000 [11:40<36:18, 34.74it/s]
epoch 24300  training loss: 0.08459500223398209

 24%|██▍       | 24385/100000 [11:42<36:06, 34.91it/s]
epoch 24400  training loss: 0.08372359722852707


 25%|██▍       | 24525/100000 [11:46<36:04, 34.87it/s]
epoch 24500  training loss: 0.08371805399656296

 25%|██▍       | 24593/100000 [11:48<36:00, 34.91it/s]
epoch 24600  training loss: 0.08420880883932114


 25%|██▍       | 24733/100000 [11:52<35:58, 34.87it/s]
epoch 24700  training loss: 0.08373526483774185

 25%|██▍       | 24805/100000 [11:54<36:13, 34.60it/s]
epoch 24800  training loss: 0.08662592619657516


 25%|██▍       | 24945/100000 [11:58<35:59, 34.76it/s]
epoch 24900  training loss: 0.08599535375833511

 25%|██▌       | 25013/100000 [12:00<36:04, 34.65it/s]
epoch 25000  training loss: 0.08555293828248978
epoch 25000  clean testing loss: 0.017172744497656822


 25%|██▌       | 25153/100000 [12:04<35:50, 34.80it/s]
epoch 25100  training loss: 0.08571341633796692

 25%|██▌       | 25221/100000 [12:06<35:45, 34.86it/s]
epoch 25200  training loss: 0.08518503606319427

 25%|██▌       | 25289/100000 [12:08<35:43, 34.86it/s]
epoch 25300  training loss: 0.08536612242460251


 25%|██▌       | 25429/100000 [12:12<35:38, 34.87it/s]
epoch 25400  training loss: 0.08557794988155365

 26%|██▌       | 25501/100000 [12:14<35:36, 34.86it/s]
epoch 25500  training loss: 0.08464844524860382


 26%|██▌       | 25641/100000 [12:18<35:39, 34.76it/s]
epoch 25600  training loss: 0.08513429760932922

 26%|██▌       | 25709/100000 [12:20<35:35, 34.79it/s]
epoch 25700  training loss: 0.0848848894238472


 26%|██▌       | 25849/100000 [12:24<35:34, 34.74it/s]
epoch 25800  training loss: 0.08473620563745499

 26%|██▌       | 25921/100000 [12:26<35:23, 34.88it/s]
epoch 25900  training loss: 0.08544538170099258

 26%|██▌       | 25989/100000 [12:28<35:28, 34.77it/s]
epoch 26000  training loss: 0.0849703699350357
epoch 26000  clean testing loss: 0.01771656982600689


 26%|██▌       | 26125/100000 [12:32<35:19, 34.85it/s]
epoch 26100  training loss: 0.08521433919668198

 26%|██▌       | 26197/100000 [12:34<35:21, 34.79it/s]
epoch 26200  training loss: 0.0847766250371933


 26%|██▋       | 26337/100000 [12:38<35:17, 34.79it/s]
epoch 26300  training loss: 0.08507968485355377

 26%|██▋       | 26405/100000 [12:40<35:18, 34.75it/s]
epoch 26400  training loss: 0.08519715070724487


 27%|██▋       | 26545/100000 [12:44<35:09, 34.82it/s]
epoch 26500  training loss: 0.08550044149160385

 27%|██▋       | 26613/100000 [12:46<35:15, 34.70it/s]
epoch 26600  training loss: 0.08589652925729752

 27%|██▋       | 26685/100000 [12:48<35:01, 34.89it/s]
epoch 26700  training loss: 0.08525629341602325


 27%|██▋       | 26825/100000 [12:52<35:03, 34.80it/s]
epoch 26800  training loss: 0.08515185117721558

 27%|██▋       | 26893/100000 [12:54<34:55, 34.88it/s]
epoch 26900  training loss: 0.08570793271064758


 27%|██▋       | 27029/100000 [12:58<34:56, 34.81it/s]
epoch 27000  training loss: 0.08663086593151093
epoch 27000  clean testing loss: 0.017461339011788368

 27%|██▋       | 27101/100000 [13:00<35:01, 34.70it/s]
epoch 27100  training loss: 0.08524947613477707


 27%|██▋       | 27241/100000 [13:04<34:45, 34.89it/s]
epoch 27200  training loss: 0.08476284146308899

 27%|██▋       | 27309/100000 [13:06<34:48, 34.81it/s]
epoch 27300  training loss: 0.08483634144067764


 27%|██▋       | 27449/100000 [13:10<34:40, 34.88it/s]
epoch 27400  training loss: 0.0853661596775055

 28%|██▊       | 27521/100000 [13:12<34:43, 34.79it/s]
epoch 27500  training loss: 0.08483023941516876

 28%|██▊       | 27589/100000 [13:14<34:40, 34.80it/s]
epoch 27600  training loss: 0.08473057299852371


 28%|██▊       | 27729/100000 [13:18<34:33, 34.86it/s]
epoch 27700  training loss: 0.08468692749738693

 28%|██▊       | 27797/100000 [13:20<34:30, 34.87it/s]
epoch 27800  training loss: 0.08475922048091888


 28%|██▊       | 27937/100000 [13:24<34:29, 34.83it/s]
epoch 27900  training loss: 0.08431361615657806

 28%|██▊       | 28009/100000 [13:26<34:49, 34.45it/s]
epoch 28000  training loss: 0.08407194912433624
epoch 28000  clean testing loss: 0.017790408805012703


 28%|██▊       | 28145/100000 [13:30<34:23, 34.82it/s]
epoch 28100  training loss: 0.08389857411384583

 28%|██▊       | 28217/100000 [13:32<34:17, 34.88it/s]
epoch 28200  training loss: 0.08467519283294678

 28%|██▊       | 28285/100000 [13:34<34:21, 34.79it/s]
epoch 28300  training loss: 0.08383185416460037


 28%|██▊       | 28425/100000 [13:38<34:11, 34.90it/s]
epoch 28400  training loss: 0.08382192254066467

 28%|██▊       | 28493/100000 [13:40<34:12, 34.85it/s]
epoch 28500  training loss: 0.08408293128013611


 29%|██▊       | 28633/100000 [13:44<34:12, 34.77it/s]
epoch 28600  training loss: 0.08370509743690491

 29%|██▊       | 28705/100000 [13:46<34:13, 34.72it/s]
epoch 28700  training loss: 0.08454172313213348


 29%|██▉       | 28845/100000 [13:50<34:03, 34.83it/s]
epoch 28800  training loss: 0.08450571447610855

 29%|██▉       | 28913/100000 [13:52<34:02, 34.81it/s]
epoch 28900  training loss: 0.0833902433514595

 29%|██▉       | 28985/100000 [13:54<33:55, 34.89it/s]
epoch 29000  training loss: 0.0834500789642334
epoch 29000  clean testing loss: 0.01836036704480648


 29%|██▉       | 29125/100000 [13:58<33:59, 34.74it/s]
epoch 29100  training loss: 0.08379348367452621

 29%|██▉       | 29189/100000 [14:00<33:56, 34.77it/s]
epoch 29200  training loss: 0.08358219265937805


 29%|██▉       | 29329/100000 [14:04<33:46, 34.87it/s]
epoch 29300  training loss: 0.08408432453870773

 29%|██▉       | 29401/100000 [14:06<33:45, 34.85it/s]
epoch 29400  training loss: 0.08359269797801971


 30%|██▉       | 29541/100000 [14:10<33:39, 34.90it/s]
epoch 29500  training loss: 0.08381079137325287

 30%|██▉       | 29609/100000 [14:12<33:43, 34.79it/s]
epoch 29600  training loss: 0.08352359384298325


 30%|██▉       | 29749/100000 [14:16<33:38, 34.81it/s]
epoch 29700  training loss: 0.08380915224552155

 30%|██▉       | 29821/100000 [14:18<33:36, 34.80it/s]
epoch 29800  training loss: 0.083650141954422

 30%|██▉       | 29889/100000 [14:20<33:28, 34.90it/s]
epoch 29900  training loss: 0.08362292498350143


 30%|███       | 30029/100000 [14:24<33:32, 34.77it/s]
epoch 30000  training loss: 0.08345811814069748
epoch 30000  clean testing loss: 0.017978530377149582

 30%|███       | 30097/100000 [14:26<33:22, 34.91it/s]
epoch 30100  training loss: 0.08324440568685532


 30%|███       | 30237/100000 [14:30<33:26, 34.77it/s]
epoch 30200  training loss: 0.0836230218410492

 30%|███       | 30305/100000 [14:32<33:24, 34.77it/s]
epoch 30300  training loss: 0.08319759368896484


 30%|███       | 30445/100000 [14:36<33:16, 34.84it/s]
epoch 30400  training loss: 0.08316278457641602

 31%|███       | 30517/100000 [14:38<33:14, 34.84it/s]
epoch 30500  training loss: 0.08311330527067184

 31%|███       | 30585/100000 [14:40<33:13, 34.82it/s]
epoch 30600  training loss: 0.08269252628087997


 31%|███       | 30725/100000 [14:44<33:06, 34.87it/s]
epoch 30700  training loss: 0.08263242989778519

 31%|███       | 30777/100000 [14:46<33:02, 34.92it/s]
epoch 30800  training loss: 0.08240877091884613


 31%|███       | 30917/100000 [14:50<33:02, 34.85it/s]
epoch 30900  training loss: 0.0831136628985405

 31%|███       | 30985/100000 [14:52<32:59, 34.86it/s]
epoch 31000  training loss: 0.08299385756254196
epoch 31000  clean testing loss: 0.01841956377029419


 31%|███       | 31125/100000 [14:56<32:55, 34.87it/s]
epoch 31100  training loss: 0.08283612877130508

 31%|███       | 31197/100000 [14:58<32:53, 34.87it/s]
epoch 31200  training loss: 0.08280932158231735


 31%|███▏      | 31333/100000 [15:02<32:50, 34.85it/s]
epoch 31300  training loss: 0.08308898657560349

 31%|███▏      | 31405/100000 [15:04<32:52, 34.77it/s]
epoch 31400  training loss: 0.08258771896362305

 31%|███▏      | 31473/100000 [15:06<32:42, 34.91it/s]
epoch 31500  training loss: 0.08271109312772751


 32%|███▏      | 31613/100000 [15:10<32:51, 34.70it/s]
epoch 31600  training loss: 0.08243532478809357

 32%|███▏      | 31681/100000 [15:12<32:36, 34.92it/s]
epoch 31700  training loss: 0.08204413205385208


 32%|███▏      | 31821/100000 [15:16<32:36, 34.86it/s]
epoch 31800  training loss: 0.08307108283042908

 32%|███▏      | 31893/100000 [15:18<32:31, 34.91it/s]
epoch 31900  training loss: 0.08267764747142792


 32%|███▏      | 32033/100000 [15:22<32:30, 34.85it/s]
epoch 32000  training loss: 0.08236479014158249
epoch 32000  clean testing loss: 0.01892821677029133

 32%|███▏      | 32101/100000 [15:24<32:29, 34.83it/s]
epoch 32100  training loss: 0.0824047401547432

 32%|███▏      | 32173/100000 [15:26<32:23, 34.90it/s]
epoch 32200  training loss: 0.08249705284833908


 32%|███▏      | 32309/100000 [15:30<33:24, 33.77it/s]
epoch 32300  training loss: 0.08236879855394363

 32%|███▏      | 32377/100000 [15:32<32:20, 34.85it/s]
epoch 32400  training loss: 0.08254309743642807


 33%|███▎      | 32517/100000 [15:36<32:17, 34.83it/s]
epoch 32500  training loss: 0.08256212621927261

 33%|███▎      | 32589/100000 [15:38<32:13, 34.86it/s]
epoch 32600  training loss: 0.08282535523176193


 33%|███▎      | 32729/100000 [15:42<32:08, 34.87it/s]
epoch 32700  training loss: 0.08270850777626038

 33%|███▎      | 32797/100000 [15:44<32:05, 34.90it/s]
epoch 32800  training loss: 0.0831499993801117


 33%|███▎      | 32937/100000 [15:48<32:00, 34.92it/s]
epoch 32900  training loss: 0.08252447098493576

 33%|███▎      | 33009/100000 [15:50<32:17, 34.57it/s]
epoch 33000  training loss: 0.08252294361591339
epoch 33000  clean testing loss: 0.01969495788216591


 33%|███▎      | 33145/100000 [15:54<31:53, 34.93it/s]
epoch 33100  training loss: 0.08265356719493866

 33%|███▎      | 33217/100000 [15:56<31:52, 34.92it/s]
epoch 33200  training loss: 0.08216455578804016

 33%|███▎      | 33285/100000 [15:58<31:47, 34.97it/s]
epoch 33300  training loss: 0.08229083567857742


 33%|███▎      | 33425/100000 [16:02<31:45, 34.94it/s]
epoch 33400  training loss: 0.08203161507844925

 33%|███▎      | 33493/100000 [16:04<31:43, 34.95it/s]
epoch 33500  training loss: 0.08197136223316193


 34%|███▎      | 33633/100000 [16:08<31:38, 34.95it/s]
epoch 33600  training loss: 0.08218447864055634

 34%|███▎      | 33705/100000 [16:10<31:47, 34.76it/s]
epoch 33700  training loss: 0.08195573836565018


 34%|███▍      | 33845/100000 [16:14<31:33, 34.94it/s]
epoch 33800  training loss: 0.08188707381486893

 34%|███▍      | 33913/100000 [16:16<31:34, 34.88it/s]
epoch 33900  training loss: 0.08244448155164719

 34%|███▍      | 33985/100000 [16:18<31:27, 34.98it/s]
epoch 34000  training loss: 0.08153500407934189
epoch 34000  clean testing loss: 0.01951073482632637


 34%|███▍      | 34125/100000 [16:22<31:24, 34.95it/s]
epoch 34100  training loss: 0.08239112049341202

 34%|███▍      | 34193/100000 [16:24<31:23, 34.93it/s]
epoch 34200  training loss: 0.08218833804130554


 34%|███▍      | 34333/100000 [16:28<31:20, 34.91it/s]
epoch 34300  training loss: 0.08136554062366486

 34%|███▍      | 34401/100000 [16:30<32:39, 33.48it/s]
epoch 34400  training loss: 0.0818430557847023


 35%|███▍      | 34541/100000 [16:34<31:12, 34.95it/s]
epoch 34500  training loss: 0.0824270099401474

 35%|███▍      | 34613/100000 [16:36<31:18, 34.80it/s]
epoch 34600  training loss: 0.08202991634607315

 35%|███▍      | 34681/100000 [16:38<31:09, 34.95it/s]
epoch 34700  training loss: 0.08190541714429855


 35%|███▍      | 34821/100000 [16:42<31:07, 34.89it/s]
epoch 34800  training loss: 0.08143144845962524

 35%|███▍      | 34893/100000 [16:44<31:11, 34.78it/s]
epoch 34900  training loss: 0.08140269666910172


 35%|███▌      | 35033/100000 [16:48<31:00, 34.92it/s]
epoch 35000  training loss: 0.08186697959899902
epoch 35000  clean testing loss: 0.02013186365365982

 35%|███▌      | 35101/100000 [16:50<30:58, 34.92it/s]
epoch 35100  training loss: 0.081818588078022


 35%|███▌      | 35241/100000 [16:54<30:53, 34.93it/s]
epoch 35200  training loss: 0.0818038135766983

 35%|███▌      | 35313/100000 [16:56<30:59, 34.79it/s]
epoch 35300  training loss: 0.08277855813503265

 35%|███▌      | 35381/100000 [16:58<30:47, 34.97it/s]
epoch 35400  training loss: 0.08155114948749542


 36%|███▌      | 35521/100000 [17:02<30:50, 34.84it/s]
epoch 35500  training loss: 0.08151380717754364

 36%|███▌      | 35589/100000 [17:04<30:47, 34.87it/s]
epoch 35600  training loss: 0.08132398873567581


 36%|███▌      | 35729/100000 [17:08<30:48, 34.76it/s]
epoch 35700  training loss: 0.08112826943397522

 36%|███▌      | 35801/100000 [17:10<30:40, 34.88it/s]
epoch 35800  training loss: 0.08192218840122223


 36%|███▌      | 35941/100000 [17:14<30:35, 34.91it/s]
epoch 35900  training loss: 0.08195137977600098

 36%|███▌      | 36009/100000 [17:16<30:53, 34.53it/s]
epoch 36000  training loss: 0.08125173300504684
epoch 36000  clean testing loss: 0.020728712901473045


 36%|███▌      | 36149/100000 [17:20<30:26, 34.96it/s]
epoch 36100  training loss: 0.08122571557760239

 36%|███▌      | 36217/100000 [17:22<30:27, 34.90it/s]
epoch 36200  training loss: 0.08280113339424133

 36%|███▋      | 36289/100000 [17:24<30:29, 34.82it/s]
epoch 36300  training loss: 0.0824250802397728


 36%|███▋      | 36429/100000 [17:28<30:26, 34.80it/s]
epoch 36400  training loss: 0.08216457068920135

 36%|███▋      | 36497/100000 [17:30<33:05, 31.98it/s]
epoch 36500  training loss: 0.08244526386260986


 37%|███▋      | 36637/100000 [17:34<30:16, 34.88it/s]
epoch 36600  training loss: 0.08215147256851196

 37%|███▋      | 36705/100000 [17:36<30:19, 34.78it/s]
epoch 36700  training loss: 0.08170385658740997


 37%|███▋      | 36845/100000 [17:40<30:13, 34.83it/s]
epoch 36800  training loss: 0.0819673165678978

 37%|███▋      | 36917/100000 [17:42<30:05, 34.93it/s]
epoch 36900  training loss: 0.08141472190618515

 37%|███▋      | 36985/100000 [17:44<30:05, 34.91it/s]
epoch 37000  training loss: 0.08155499398708344
epoch 37000  clean testing loss: 0.020113317295908928


 37%|███▋      | 37125/100000 [17:48<30:00, 34.91it/s]
epoch 37100  training loss: 0.0810343399643898

 37%|███▋      | 37197/100000 [17:50<30:00, 34.88it/s]
epoch 37200  training loss: 0.08090287446975708


 37%|███▋      | 37337/100000 [17:54<29:55, 34.90it/s]
epoch 37300  training loss: 0.0809440165758133

 37%|███▋      | 37405/100000 [17:56<30:03, 34.72it/s]
epoch 37400  training loss: 0.08124957233667374


 38%|███▊      | 37545/100000 [18:00<32:47, 31.75it/s]
epoch 37500  training loss: 0.08118347078561783

 38%|███▊      | 37613/100000 [18:02<29:52, 34.80it/s]
epoch 37600  training loss: 0.08166708052158356

 38%|███▊      | 37685/100000 [18:04<29:48, 34.84it/s]
epoch 37700  training loss: 0.08177661150693893


 38%|███▊      | 37821/100000 [18:08<29:40, 34.92it/s]
epoch 37800  training loss: 0.08162741363048553

 38%|███▊      | 37893/100000 [18:10<29:42, 34.84it/s]
epoch 37900  training loss: 0.08115343749523163


 38%|███▊      | 38033/100000 [18:14<29:35, 34.89it/s]
epoch 38000  training loss: 0.08132621645927429
epoch 38000  clean testing loss: 0.020189007744193077

 38%|███▊      | 38101/100000 [18:16<29:41, 34.74it/s]
epoch 38100  training loss: 0.08239010721445084


 38%|███▊      | 38241/100000 [18:20<29:26, 34.96it/s]
epoch 38200  training loss: 0.0819658562541008

 38%|███▊      | 38313/100000 [18:22<29:36, 34.72it/s]
epoch 38300  training loss: 0.08205840736627579

 38%|███▊      | 38381/100000 [18:24<29:30, 34.81it/s]
epoch 38400  training loss: 0.08188453316688538


 39%|███▊      | 38521/100000 [18:28<29:30, 34.72it/s]
epoch 38500  training loss: 0.08150936663150787

 39%|███▊      | 38589/100000 [18:30<34:31, 29.64it/s]
epoch 38600  training loss: 0.08208468556404114


 39%|███▊      | 38729/100000 [18:34<29:10, 34.99it/s]
epoch 38700  training loss: 0.08171208202838898

 39%|███▉      | 38801/100000 [18:36<29:12, 34.92it/s]
epoch 38800  training loss: 0.08161541819572449


 39%|███▉      | 38941/100000 [18:40<29:13, 34.81it/s]
epoch 38900  training loss: 0.08119087666273117

 39%|███▉      | 39009/100000 [18:42<29:19, 34.66it/s]
epoch 39000  training loss: 0.08121723681688309
epoch 39000  clean testing loss: 0.02064228430390358


 39%|███▉      | 39149/100000 [18:46<29:04, 34.88it/s]
epoch 39100  training loss: 0.08138386905193329

 39%|███▉      | 39221/100000 [18:48<29:04, 34.85it/s]
epoch 39200  training loss: 0.08128896355628967

 39%|███▉      | 39289/100000 [18:50<28:55, 34.97it/s]
epoch 39300  training loss: 0.08147300779819489


 39%|███▉      | 39429/100000 [18:54<28:55, 34.90it/s]
epoch 39400  training loss: 0.08084744215011597

 40%|███▉      | 39501/100000 [18:56<28:54, 34.87it/s]
epoch 39500  training loss: 0.0806490108370781


 40%|███▉      | 39637/100000 [19:00<29:39, 33.92it/s]
epoch 39600  training loss: 0.08154299110174179

 40%|███▉      | 39709/100000 [19:02<28:51, 34.82it/s]
epoch 39700  training loss: 0.08032302558422089


 40%|███▉      | 39849/100000 [19:06<28:41, 34.94it/s]
epoch 39800  training loss: 0.08053072541952133

 40%|███▉      | 39917/100000 [19:08<28:39, 34.95it/s]
epoch 39900  training loss: 0.08031846582889557

 40%|███▉      | 39989/100000 [19:10<28:37, 34.95it/s]
epoch 40000  training loss: 0.0802055299282074
epoch 40000  clean testing loss: 0.02080736681818962


 40%|████      | 40129/100000 [19:14<28:34, 34.91it/s]
epoch 40100  training loss: 0.08034684509038925

 40%|████      | 40197/100000 [19:16<28:32, 34.91it/s]
epoch 40200  training loss: 0.08094935119152069


 40%|████      | 40337/100000 [19:20<28:24, 35.01it/s]
epoch 40300  training loss: 0.08105882257223129

 40%|████      | 40409/100000 [19:23<28:26, 34.93it/s]
epoch 40400  training loss: 0.0809512659907341


 41%|████      | 40549/100000 [19:27<28:27, 34.82it/s]
epoch 40500  training loss: 0.08095728605985641

 41%|████      | 40617/100000 [19:28<28:20, 34.92it/s]
epoch 40600  training loss: 0.0805383175611496

 41%|████      | 40689/100000 [19:31<30:26, 32.47it/s]
epoch 40700  training loss: 0.08087768405675888


 41%|████      | 40825/100000 [19:34<28:15, 34.90it/s]
epoch 40800  training loss: 0.08143386244773865

 41%|████      | 40897/100000 [19:37<28:09, 34.98it/s]
epoch 40900  training loss: 0.0812910720705986


 41%|████      | 41037/100000 [19:41<28:06, 34.96it/s]
epoch 41000  training loss: 0.0820496454834938
epoch 41000  clean testing loss: 0.021080676466226578

 41%|████      | 41105/100000 [19:42<28:10, 34.84it/s]
epoch 41100  training loss: 0.08059408515691757


 41%|████      | 41245/100000 [19:46<27:59, 34.98it/s]
epoch 41200  training loss: 0.08061102777719498

 41%|████▏     | 41317/100000 [19:49<28:03, 34.87it/s]
epoch 41300  training loss: 0.08091847598552704

 41%|████▏     | 41385/100000 [19:51<27:58, 34.93it/s]
epoch 41400  training loss: 0.08070886880159378


 42%|████▏     | 41525/100000 [19:55<27:56, 34.87it/s]
epoch 41500  training loss: 0.08067582547664642

 42%|████▏     | 41597/100000 [19:57<27:50, 34.97it/s]
epoch 41600  training loss: 0.08095048367977142


 42%|████▏     | 41737/100000 [20:01<27:48, 34.93it/s]
epoch 41700  training loss: 0.08135294169187546

 42%|████▏     | 41805/100000 [20:03<27:52, 34.79it/s]
epoch 41800  training loss: 0.08124060928821564


 42%|████▏     | 41945/100000 [20:07<27:43, 34.91it/s]
epoch 41900  training loss: 0.0821869894862175

 42%|████▏     | 42013/100000 [20:09<27:49, 34.73it/s]
epoch 42000  training loss: 0.08032724261283875
epoch 42000  clean testing loss: 0.020926063880324364

 42%|████▏     | 42085/100000 [20:11<27:35, 34.99it/s]
epoch 42100  training loss: 0.08128529787063599


 42%|████▏     | 42225/100000 [20:15<27:33, 34.94it/s]
epoch 42200  training loss: 0.08094781637191772

 42%|████▏     | 42293/100000 [20:17<27:29, 34.99it/s]
epoch 42300  training loss: 0.08054562658071518


 42%|████▏     | 42433/100000 [20:21<27:26, 34.96it/s]
epoch 42400  training loss: 0.08146125078201294

 43%|████▎     | 42505/100000 [20:23<27:30, 34.83it/s]
epoch 42500  training loss: 0.08057393878698349


 43%|████▎     | 42645/100000 [20:27<27:18, 35.01it/s]
epoch 42600  training loss: 0.0803677961230278

 43%|████▎     | 42713/100000 [20:29<27:22, 34.88it/s]
epoch 42700  training loss: 0.08101186156272888

 43%|████▎     | 42785/100000 [20:31<27:17, 34.95it/s]
epoch 42800  training loss: 0.08133810758590698


 43%|████▎     | 42921/100000 [20:35<27:13, 34.94it/s]
epoch 42900  training loss: 0.08061907440423965

 43%|████▎     | 42993/100000 [20:37<27:10, 34.96it/s]
epoch 43000  training loss: 0.0802614763379097
epoch 43000  clean testing loss: 0.02118133194744587


 43%|████▎     | 43133/100000 [20:41<27:06, 34.96it/s]
epoch 43100  training loss: 0.0805509090423584

 43%|████▎     | 43201/100000 [20:43<27:05, 34.93it/s]
epoch 43200  training loss: 0.08046673238277435


 43%|████▎     | 43341/100000 [20:47<27:01, 34.94it/s]
epoch 43300  training loss: 0.08094245195388794

 43%|████▎     | 43413/100000 [20:49<27:03, 34.86it/s]
epoch 43400  training loss: 0.08015533536672592


 44%|████▎     | 43553/100000 [20:53<26:55, 34.93it/s]
epoch 43500  training loss: 0.08146163821220398

 44%|████▎     | 43621/100000 [20:55<26:52, 34.97it/s]
epoch 43600  training loss: 0.08044856041669846

 44%|████▎     | 43693/100000 [20:57<26:51, 34.94it/s]
epoch 43700  training loss: 0.07994130998849869


 44%|████▍     | 43833/100000 [21:01<26:47, 34.94it/s]
epoch 43800  training loss: 0.08020474016666412

 44%|████▍     | 43901/100000 [21:03<26:46, 34.92it/s]
epoch 43900  training loss: 0.07975924760103226


 44%|████▍     | 44041/100000 [21:07<26:42, 34.91it/s]
epoch 44000  training loss: 0.08075179159641266
epoch 44000  clean testing loss: 0.021358080208301544

 44%|████▍     | 44109/100000 [21:09<26:45, 34.82it/s]
epoch 44100  training loss: 0.08068674057722092


 44%|████▍     | 44249/100000 [21:13<26:33, 34.98it/s]
epoch 44200  training loss: 0.0802672728896141

 44%|████▍     | 44317/100000 [21:15<26:33, 34.93it/s]
epoch 44300  training loss: 0.0808393657207489

 44%|████▍     | 44389/100000 [21:17<26:30, 34.97it/s]
epoch 44400  training loss: 0.08024393022060394


 45%|████▍     | 44529/100000 [21:21<26:26, 34.95it/s]
epoch 44500  training loss: 0.08048507571220398

 45%|████▍     | 44597/100000 [21:23<26:23, 34.98it/s]
epoch 44600  training loss: 0.08019549399614334


 45%|████▍     | 44737/100000 [21:27<26:20, 34.98it/s]
epoch 44700  training loss: 0.081633061170578

 45%|████▍     | 44809/100000 [21:29<26:24, 34.84it/s]
epoch 44800  training loss: 0.0811060443520546


 45%|████▍     | 44945/100000 [21:33<26:17, 34.91it/s]
epoch 44900  training loss: 0.0800049751996994

 45%|████▌     | 45017/100000 [21:35<26:19, 34.81it/s]
epoch 45000  training loss: 0.08045244216918945
epoch 45000  clean testing loss: 0.02127547189593315

 45%|████▌     | 45085/100000 [21:37<26:09, 34.98it/s]
epoch 45100  training loss: 0.08007937669754028


 45%|████▌     | 45225/100000 [21:41<26:09, 34.90it/s]
epoch 45200  training loss: 0.0806756541132927

 45%|████▌     | 45297/100000 [21:43<26:04, 34.96it/s]
epoch 45300  training loss: 0.08060555160045624


 45%|████▌     | 45437/100000 [21:47<26:01, 34.95it/s]
epoch 45400  training loss: 0.08039359003305435

 46%|████▌     | 45505/100000 [21:49<26:06, 34.79it/s]
epoch 45500  training loss: 0.0804632157087326


 46%|████▌     | 45645/100000 [21:53<25:54, 34.98it/s]
epoch 45600  training loss: 0.08103203773498535

 46%|████▌     | 45717/100000 [21:55<25:55, 34.89it/s]
epoch 45700  training loss: 0.08157727122306824

 46%|████▌     | 45785/100000 [21:57<25:50, 34.96it/s]
epoch 45800  training loss: 0.08099003881216049


 46%|████▌     | 45909/100000 [22:00<25:51, 34.87it/s]
epoch 45900  training loss: 0.08103428781032562

 46%|████▌     | 45977/100000 [22:02<25:56, 34.71it/s]
epoch 46000  training loss: 0.08043967187404633
epoch 46000  clean testing loss: 0.02176845073699951


 46%|████▌     | 46117/100000 [22:06<25:51, 34.72it/s]
epoch 46100  training loss: 0.08075642585754395

 46%|████▌     | 46189/100000 [22:08<25:40, 34.94it/s]
epoch 46200  training loss: 0.07953276485204697


 46%|████▋     | 46329/100000 [22:12<25:35, 34.94it/s]
epoch 46300  training loss: 0.07966955751180649

 46%|████▋     | 46397/100000 [22:14<25:38, 34.84it/s]
epoch 46400  training loss: 0.08110155910253525

 46%|████▋     | 46469/100000 [22:16<25:31, 34.96it/s]
epoch 46500  training loss: 0.08081028610467911


 47%|████▋     | 46609/100000 [22:20<25:30, 34.88it/s]
epoch 46600  training loss: 0.0805218517780304

 47%|████▋     | 46677/100000 [22:22<25:25, 34.96it/s]
epoch 46700  training loss: 0.08022134006023407


 47%|████▋     | 46817/100000 [22:26<25:30, 34.75it/s]
epoch 46800  training loss: 0.08021937310695648

 47%|████▋     | 46889/100000 [22:28<25:20, 34.93it/s]
epoch 46900  training loss: 0.08009635657072067


 47%|████▋     | 47025/100000 [22:32<25:35, 34.49it/s]
epoch 47000  training loss: 0.0808100625872612
epoch 47000  clean testing loss: 0.021828988566994667

 47%|████▋     | 47093/100000 [22:34<25:12, 34.97it/s]
epoch 47100  training loss: 0.08022475242614746

 47%|████▋     | 47165/100000 [22:36<25:12, 34.93it/s]
epoch 47200  training loss: 0.08064878731966019


 47%|████▋     | 47305/100000 [22:40<25:15, 34.77it/s]
epoch 47300  training loss: 0.08104782551527023

 47%|████▋     | 47373/100000 [22:42<25:06, 34.94it/s]
epoch 47400  training loss: 0.08065811544656754


 48%|████▊     | 47513/100000 [22:46<25:04, 34.88it/s]
epoch 47500  training loss: 0.0811648741364479

 48%|████▊     | 47585/100000 [22:48<24:58, 34.97it/s]
epoch 47600  training loss: 0.0808878242969513


 48%|████▊     | 47725/100000 [22:52<25:00, 34.84it/s]
epoch 47700  training loss: 0.07953023165464401

 48%|████▊     | 47797/100000 [22:55<24:54, 34.93it/s]
epoch 47800  training loss: 0.08009501546621323


 48%|████▊     | 47933/100000 [22:58<24:55, 34.81it/s]
epoch 47900  training loss: 0.08040906488895416

 48%|████▊     | 48005/100000 [23:00<25:09, 34.43it/s]
epoch 48000  training loss: 0.0812910720705986
epoch 48000  clean testing loss: 0.021631695330142975


 48%|████▊     | 48141/100000 [23:04<24:48, 34.84it/s]
epoch 48100  training loss: 0.08076928555965424

 48%|████▊     | 48213/100000 [23:07<24:45, 34.86it/s]
epoch 48200  training loss: 0.08005215972661972

 48%|████▊     | 48281/100000 [23:08<24:43, 34.86it/s]
epoch 48300  training loss: 0.08104769885540009


 48%|████▊     | 48421/100000 [23:12<24:36, 34.93it/s]
epoch 48400  training loss: 0.08055561035871506

 48%|████▊     | 48493/100000 [23:15<24:33, 34.96it/s]
epoch 48500  training loss: 0.08034533262252808


 49%|████▊     | 48633/100000 [23:19<24:33, 34.86it/s]
epoch 48600  training loss: 0.08068740367889404

 49%|████▊     | 48701/100000 [23:20<24:31, 34.85it/s]
epoch 48700  training loss: 0.08000816404819489


 49%|████▉     | 48841/100000 [23:24<24:26, 34.89it/s]
epoch 48800  training loss: 0.08014733344316483

 49%|████▉     | 48913/100000 [23:27<24:24, 34.89it/s]
epoch 48900  training loss: 0.08068834245204926

 49%|████▉     | 48981/100000 [23:28<24:22, 34.89it/s]
epoch 49000  training loss: 0.08024459332227707
epoch 49000  clean testing loss: 0.02153935097157955


 49%|████▉     | 49121/100000 [23:33<24:41, 34.35it/s]
epoch 49100  training loss: 0.08026891946792603

 49%|████▉     | 49189/100000 [23:35<24:17, 34.87it/s]
epoch 49200  training loss: 0.08027798682451248


 49%|████▉     | 49329/100000 [23:39<24:10, 34.94it/s]
epoch 49300  training loss: 0.08073760569095612

 49%|████▉     | 49401/100000 [23:41<24:11, 34.87it/s]
epoch 49400  training loss: 0.08045495301485062


 50%|████▉     | 49541/100000 [23:45<24:06, 34.88it/s]
epoch 49500  training loss: 0.08052605390548706

 50%|████▉     | 49609/100000 [23:47<24:04, 34.88it/s]
epoch 49600  training loss: 0.08029399067163467


 50%|████▉     | 49749/100000 [23:51<23:57, 34.95it/s]
epoch 49700  training loss: 0.08018001168966293

 50%|████▉     | 49821/100000 [23:53<23:58, 34.89it/s]
epoch 49800  training loss: 0.08048436045646667

 50%|████▉     | 49889/100000 [23:55<23:56, 34.87it/s]
epoch 49900  training loss: 0.08099216967821121


 50%|█████     | 50029/100000 [23:59<23:55, 34.81it/s]
epoch 50000  training loss: 0.07977671921253204
epoch 50000  clean testing loss: 0.021433226764202118

 50%|█████     | 50101/100000 [24:01<23:48, 34.92it/s]
epoch 50100  training loss: 0.0804143026471138


 50%|█████     | 50237/100000 [24:05<23:44, 34.94it/s]
epoch 50200  training loss: 0.08054155111312866

 50%|█████     | 50309/100000 [24:07<23:44, 34.87it/s]
epoch 50300  training loss: 0.08027517795562744


 50%|█████     | 50449/100000 [24:11<23:38, 34.93it/s]
epoch 50400  training loss: 0.08007319271564484

 51%|█████     | 50517/100000 [24:13<23:40, 34.83it/s]
epoch 50500  training loss: 0.0803903266787529

 51%|█████     | 50589/100000 [24:15<23:34, 34.93it/s]
epoch 50600  training loss: 0.08083207905292511


 51%|█████     | 50729/100000 [24:19<23:29, 34.95it/s]
epoch 50700  training loss: 0.08072729408740997

 51%|█████     | 50797/100000 [24:21<23:26, 34.98it/s]
epoch 50800  training loss: 0.0802721455693245


 51%|█████     | 50937/100000 [24:25<23:25, 34.92it/s]
epoch 50900  training loss: 0.0804547369480133

 51%|█████     | 51009/100000 [24:27<23:34, 34.63it/s]
epoch 51000  training loss: 0.07987343519926071
epoch 51000  clean testing loss: 0.021485062316060066


 51%|█████     | 51149/100000 [24:31<23:19, 34.90it/s]
epoch 51100  training loss: 0.08070209622383118

 51%|█████     | 51213/100000 [24:33<24:25, 33.30it/s]
epoch 51200  training loss: 0.08060728758573532

 51%|█████▏    | 51285/100000 [24:35<23:14, 34.93it/s]
epoch 51300  training loss: 0.08089975267648697


 51%|█████▏    | 51425/100000 [24:39<23:09, 34.96it/s]
epoch 51400  training loss: 0.08011307567358017

 51%|█████▏    | 51493/100000 [24:41<23:10, 34.89it/s]
epoch 51500  training loss: 0.0799226313829422


 52%|█████▏    | 51633/100000 [24:45<23:05, 34.91it/s]
epoch 51600  training loss: 0.08055023849010468

 52%|█████▏    | 51705/100000 [24:47<23:05, 34.85it/s]
epoch 51700  training loss: 0.07984796166419983


 52%|█████▏    | 51845/100000 [24:51<22:56, 34.99it/s]
epoch 51800  training loss: 0.07936254888772964

 52%|█████▏    | 51913/100000 [24:53<22:59, 34.87it/s]
epoch 51900  training loss: 0.08007623255252838

 52%|█████▏    | 51985/100000 [24:55<22:55, 34.91it/s]
epoch 52000  training loss: 0.07984711974859238
epoch 52000  clean testing loss: 0.021503621712327003


 52%|█████▏    | 52125/100000 [24:59<22:52, 34.88it/s]
epoch 52100  training loss: 0.08032775670289993

 52%|█████▏    | 52193/100000 [25:01<22:47, 34.96it/s]
epoch 52200  training loss: 0.08003311604261398


 52%|█████▏    | 52333/100000 [25:05<22:44, 34.93it/s]
epoch 52300  training loss: 0.07996983081102371

 52%|█████▏    | 52401/100000 [25:07<22:43, 34.90it/s]
epoch 52400  training loss: 0.08003221452236176


 53%|█████▎    | 52541/100000 [25:11<22:38, 34.93it/s]
epoch 52500  training loss: 0.08078408241271973

 53%|█████▎    | 52613/100000 [25:13<22:38, 34.89it/s]
epoch 52600  training loss: 0.08013994246721268

 53%|█████▎    | 52681/100000 [25:15<22:33, 34.96it/s]
epoch 52700  training loss: 0.08067397028207779


 53%|█████▎    | 52821/100000 [25:19<22:33, 34.86it/s]
epoch 52800  training loss: 0.080701544880867

 53%|█████▎    | 52893/100000 [25:21<22:28, 34.93it/s]
epoch 52900  training loss: 0.08048566430807114


 53%|█████▎    | 53033/100000 [25:25<22:24, 34.93it/s]
epoch 53000  training loss: 0.07963327318429947
epoch 53000  clean testing loss: 0.02165193296968937

 53%|█████▎    | 53101/100000 [25:27<22:22, 34.94it/s]
epoch 53100  training loss: 0.07947617769241333


 53%|█████▎    | 53241/100000 [25:31<22:16, 34.97it/s]
epoch 53200  training loss: 0.07964500039815903

 53%|█████▎    | 53309/100000 [25:33<24:05, 32.31it/s]
epoch 53300  training loss: 0.07959483563899994


 53%|█████▎    | 53449/100000 [25:37<22:11, 34.96it/s]
epoch 53400  training loss: 0.08083601295948029

 54%|█████▎    | 53521/100000 [25:39<22:11, 34.91it/s]
epoch 53500  training loss: 0.08059541136026382

 54%|█████▎    | 53589/100000 [25:41<22:10, 34.89it/s]
epoch 53600  training loss: 0.08023716509342194


 54%|█████▎    | 53729/100000 [25:45<22:06, 34.87it/s]
epoch 53700  training loss: 0.08044242113828659

 54%|█████▍    | 53801/100000 [25:47<22:03, 34.91it/s]
epoch 53800  training loss: 0.08051078766584396


 54%|█████▍    | 53941/100000 [25:51<21:56, 34.98it/s]
epoch 53900  training loss: 0.08042420446872711

 54%|█████▍    | 54009/100000 [25:53<22:05, 34.70it/s]
epoch 54000  training loss: 0.0810055285692215
epoch 54000  clean testing loss: 0.021488318219780922


 54%|█████▍    | 54149/100000 [25:57<21:54, 34.89it/s]
epoch 54100  training loss: 0.08029064536094666

 54%|█████▍    | 54221/100000 [25:59<21:49, 34.96it/s]
epoch 54200  training loss: 0.08073931932449341

 54%|█████▍    | 54289/100000 [26:01<21:47, 34.97it/s]
epoch 54300  training loss: 0.08014998584985733


 54%|█████▍    | 54429/100000 [26:05<21:46, 34.88it/s]
epoch 54400  training loss: 0.08014652132987976

 54%|█████▍    | 54497/100000 [26:07<21:42, 34.94it/s]
epoch 54500  training loss: 0.08075935393571854


 55%|█████▍    | 54637/100000 [26:11<21:38, 34.93it/s]
epoch 54600  training loss: 0.07995521277189255

 55%|█████▍    | 54705/100000 [26:13<21:41, 34.81it/s]
epoch 54700  training loss: 0.08047044277191162


 55%|█████▍    | 54845/100000 [26:17<21:34, 34.89it/s]
epoch 54800  training loss: 0.08042947947978973

 55%|█████▍    | 54917/100000 [26:19<21:29, 34.95it/s]
epoch 54900  training loss: 0.08093017339706421

 55%|█████▍    | 54989/100000 [26:21<21:26, 34.99it/s]
epoch 55000  training loss: 0.0802934467792511
epoch 55000  clean testing loss: 0.021633276715874672


 55%|█████▌    | 55125/100000 [26:25<21:22, 34.99it/s]
epoch 55100  training loss: 0.08029294013977051

 55%|█████▌    | 55197/100000 [26:27<21:19, 35.03it/s]
epoch 55200  training loss: 0.07998733967542648


 55%|█████▌    | 55337/100000 [26:31<21:17, 34.95it/s]
epoch 55300  training loss: 0.07986298948526382

 55%|█████▌    | 55405/100000 [26:33<23:43, 31.33it/s]
epoch 55400  training loss: 0.08059556037187576


 56%|█████▌    | 55545/100000 [26:37<21:14, 34.88it/s]
epoch 55500  training loss: 0.08057093620300293

 56%|█████▌    | 55617/100000 [26:39<21:10, 34.94it/s]
epoch 55600  training loss: 0.08004843443632126

 56%|█████▌    | 55685/100000 [26:41<21:08, 34.93it/s]
epoch 55700  training loss: 0.07986661791801453


 56%|█████▌    | 55825/100000 [26:45<21:03, 34.97it/s]
epoch 55800  training loss: 0.08077582716941833

 56%|█████▌    | 55897/100000 [26:47<21:01, 34.97it/s]
epoch 55900  training loss: 0.08002328127622604


 56%|█████▌    | 56037/100000 [26:51<20:58, 34.94it/s]
epoch 56000  training loss: 0.07972084730863571
epoch 56000  clean testing loss: 0.021786533296108246

 56%|█████▌    | 56105/100000 [26:53<20:58, 34.88it/s]
epoch 56100  training loss: 0.07941532135009766


 56%|█████▌    | 56245/100000 [26:57<20:49, 35.00it/s]
epoch 56200  training loss: 0.0799141600728035

 56%|█████▋    | 56317/100000 [26:59<20:49, 34.96it/s]
epoch 56300  training loss: 0.08072615414857864

 56%|█████▋    | 56385/100000 [27:01<20:46, 35.00it/s]
epoch 56400  training loss: 0.07950125634670258


 57%|█████▋    | 56525/100000 [27:05<20:42, 34.98it/s]
epoch 56500  training loss: 0.07966269552707672

 57%|█████▋    | 56593/100000 [27:07<20:39, 35.03it/s]
epoch 56600  training loss: 0.08080808818340302


 57%|█████▋    | 56733/100000 [27:11<20:36, 34.99it/s]
epoch 56700  training loss: 0.08028635382652283

 57%|█████▋    | 56805/100000 [27:13<20:56, 34.37it/s]
epoch 56800  training loss: 0.08000196516513824


 57%|█████▋    | 56945/100000 [27:17<20:33, 34.90it/s]
epoch 56900  training loss: 0.08049334585666656

 57%|█████▋    | 57013/100000 [27:19<20:38, 34.72it/s]
epoch 57000  training loss: 0.07985029369592667
epoch 57000  clean testing loss: 0.021809259429574013

 57%|█████▋    | 57085/100000 [27:21<20:28, 34.92it/s]
epoch 57100  training loss: 0.07968376576900482


 57%|█████▋    | 57225/100000 [27:25<20:24, 34.93it/s]
epoch 57200  training loss: 0.08002863824367523

 57%|█████▋    | 57293/100000 [27:27<20:20, 34.99it/s]
epoch 57300  training loss: 0.07992564141750336


 57%|█████▋    | 57433/100000 [27:31<20:23, 34.81it/s]
epoch 57400  training loss: 0.07937569916248322

 58%|█████▊    | 57501/100000 [27:33<20:15, 34.96it/s]
epoch 57500  training loss: 0.08014050126075745


 58%|█████▊    | 57641/100000 [27:37<20:11, 34.96it/s]
epoch 57600  training loss: 0.08028298616409302

 58%|█████▊    | 57713/100000 [27:39<20:12, 34.88it/s]
epoch 57700  training loss: 0.07930715382099152

 58%|█████▊    | 57781/100000 [27:41<20:07, 34.98it/s]
epoch 57800  training loss: 0.07991411536931992


 58%|█████▊    | 57921/100000 [27:45<20:02, 34.98it/s]
epoch 57900  training loss: 0.0798439159989357

 58%|█████▊    | 57993/100000 [27:47<20:00, 35.00it/s]
epoch 58000  training loss: 0.07946740835905075
epoch 58000  clean testing loss: 0.02215055748820305


 58%|█████▊    | 58133/100000 [27:51<19:57, 34.98it/s]
epoch 58100  training loss: 0.07989020645618439

 58%|█████▊    | 58201/100000 [27:53<19:57, 34.91it/s]
epoch 58200  training loss: 0.07922623306512833


 58%|█████▊    | 58341/100000 [27:57<19:50, 34.99it/s]
epoch 58300  training loss: 0.07926281541585922

 58%|█████▊    | 58413/100000 [27:59<19:50, 34.92it/s]
epoch 58400  training loss: 0.07946866750717163

 58%|█████▊    | 58481/100000 [28:01<19:46, 35.00it/s]
epoch 58500  training loss: 0.07942487299442291


 59%|█████▊    | 58621/100000 [28:05<19:44, 34.94it/s]
epoch 58600  training loss: 0.08037353307008743

 59%|█████▊    | 58689/100000 [28:07<19:41, 34.98it/s]
epoch 58700  training loss: 0.08033661544322968


 59%|█████▉    | 58829/100000 [28:11<19:37, 34.97it/s]
epoch 58800  training loss: 0.07933509349822998

 59%|█████▉    | 58897/100000 [28:13<19:36, 34.95it/s]
epoch 58900  training loss: 0.08021490275859833


 59%|█████▉    | 59041/100000 [28:17<19:32, 34.94it/s]
epoch 59000  training loss: 0.07987847924232483
epoch 59000  clean testing loss: 0.022131668403744698

 59%|█████▉    | 59109/100000 [28:19<19:31, 34.91it/s]
epoch 59100  training loss: 0.07985332608222961


 59%|█████▉    | 59249/100000 [28:23<19:24, 35.00it/s]
epoch 59200  training loss: 0.08039828389883041

 59%|█████▉    | 59321/100000 [28:25<19:23, 34.95it/s]
epoch 59300  training loss: 0.08066669851541519

 59%|█████▉    | 59389/100000 [28:27<19:20, 34.99it/s]
epoch 59400  training loss: 0.07924028486013412


 60%|█████▉    | 59529/100000 [28:31<19:19, 34.90it/s]
epoch 59500  training loss: 0.08007712662220001

 60%|█████▉    | 59601/100000 [28:33<19:16, 34.94it/s]
epoch 59600  training loss: 0.0791369155049324


 60%|█████▉    | 59737/100000 [28:37<19:12, 34.95it/s]
epoch 59700  training loss: 0.07950559258460999

 60%|█████▉    | 59809/100000 [28:39<19:11, 34.90it/s]
epoch 59800  training loss: 0.07971476763486862


 60%|█████▉    | 59949/100000 [28:43<19:08, 34.87it/s]
epoch 59900  training loss: 0.07913665473461151

 60%|██████    | 60017/100000 [28:45<19:09, 34.79it/s]
epoch 60000  training loss: 0.07903782278299332
epoch 60000  clean testing loss: 0.022363055497407913

 60%|██████    | 60089/100000 [28:47<19:01, 34.97it/s]
epoch 60100  training loss: 0.07932797074317932


 60%|██████    | 60229/100000 [28:51<18:58, 34.94it/s]
epoch 60200  training loss: 0.08012771606445312

 60%|██████    | 60297/100000 [28:53<18:56, 34.94it/s]
epoch 60300  training loss: 0.07929243892431259


 60%|██████    | 60437/100000 [28:57<18:51, 34.97it/s]
epoch 60400  training loss: 0.07955428212881088

 61%|██████    | 60509/100000 [28:59<18:52, 34.87it/s]
epoch 60500  training loss: 0.0800221785902977


 61%|██████    | 60629/100000 [29:03<18:48, 34.89it/s]
epoch 60600  training loss: 0.07964704185724258

 61%|██████    | 60697/100000 [29:05<18:49, 34.79it/s]
epoch 60700  training loss: 0.08023112267255783

 61%|██████    | 60769/100000 [29:07<18:41, 34.99it/s]
epoch 60800  training loss: 0.08034829795360565


 61%|██████    | 60909/100000 [29:11<18:40, 34.89it/s]
epoch 60900  training loss: 0.08064699918031693

 61%|██████    | 60977/100000 [29:13<18:38, 34.90it/s]
epoch 61000  training loss: 0.0794386938214302
epoch 61000  clean testing loss: 0.02260497957468033


 61%|██████    | 61117/100000 [29:17<18:32, 34.96it/s]
epoch 61100  training loss: 0.08039825409650803

 61%|██████    | 61189/100000 [29:19<18:28, 35.02it/s]
epoch 61200  training loss: 0.079605832695961


 61%|██████▏   | 61329/100000 [29:23<18:25, 34.97it/s]
epoch 61300  training loss: 0.07885739207267761

 61%|██████▏   | 61397/100000 [29:25<18:26, 34.90it/s]
epoch 61400  training loss: 0.07951632142066956

 61%|██████▏   | 61469/100000 [29:27<18:21, 34.97it/s]
epoch 61500  training loss: 0.07890794426202774


 62%|██████▏   | 61609/100000 [29:31<18:21, 34.86it/s]
epoch 61600  training loss: 0.079086072742939

 62%|██████▏   | 61677/100000 [29:33<18:16, 34.94it/s]
epoch 61700  training loss: 0.08004991710186005


 62%|██████▏   | 61817/100000 [29:37<18:13, 34.92it/s]
epoch 61800  training loss: 0.07946217805147171

 62%|██████▏   | 61885/100000 [29:39<18:10, 34.95it/s]
epoch 61900  training loss: 0.07951496541500092


 62%|██████▏   | 62025/100000 [29:43<18:09, 34.85it/s]
epoch 62000  training loss: 0.0796302855014801
epoch 62000  clean testing loss: 0.0228201262652874

 62%|██████▏   | 62097/100000 [29:45<18:03, 34.97it/s]
epoch 62100  training loss: 0.07983213663101196

 62%|██████▏   | 62165/100000 [29:47<18:01, 34.99it/s]
epoch 62200  training loss: 0.07991430163383484


 62%|██████▏   | 62305/100000 [29:51<18:01, 34.86it/s]
epoch 62300  training loss: 0.07942426204681396

 62%|██████▏   | 62377/100000 [29:53<17:55, 34.99it/s]
epoch 62400  training loss: 0.07992986589670181


 63%|██████▎   | 62517/100000 [29:57<17:53, 34.93it/s]
epoch 62500  training loss: 0.07929186522960663

 63%|██████▎   | 62585/100000 [29:59<17:51, 34.93it/s]
epoch 62600  training loss: 0.07956261932849884


 63%|██████▎   | 62725/100000 [30:03<17:45, 34.98it/s]
epoch 62700  training loss: 0.08000548183917999

 63%|██████▎   | 62793/100000 [30:05<17:52, 34.68it/s]
epoch 62800  training loss: 0.07931012660264969


 63%|██████▎   | 62933/100000 [30:09<17:39, 34.98it/s]
epoch 62900  training loss: 0.07960384339094162

 63%|██████▎   | 63005/100000 [30:11<17:51, 34.54it/s]
epoch 63000  training loss: 0.07964875549077988
epoch 63000  clean testing loss: 0.023229025304317474


 63%|██████▎   | 63145/100000 [30:15<17:32, 35.00it/s]
epoch 63100  training loss: 0.08019111305475235

 63%|██████▎   | 63213/100000 [30:17<17:33, 34.91it/s]
epoch 63200  training loss: 0.0801541656255722

 63%|██████▎   | 63285/100000 [30:19<17:30, 34.94it/s]
epoch 63300  training loss: 0.07967893034219742


 63%|██████▎   | 63425/100000 [30:23<17:26, 34.96it/s]
epoch 63400  training loss: 0.0793648287653923

 63%|██████▎   | 63493/100000 [30:25<17:24, 34.96it/s]
epoch 63500  training loss: 0.07975752651691437


 64%|██████▎   | 63633/100000 [30:29<17:21, 34.92it/s]
epoch 63600  training loss: 0.07976837456226349

 64%|██████▎   | 63705/100000 [30:31<17:21, 34.84it/s]
epoch 63700  training loss: 0.07996198534965515


 64%|██████▍   | 63841/100000 [30:35<17:24, 34.61it/s]
epoch 63800  training loss: 0.0795200914144516

 64%|██████▍   | 63913/100000 [30:37<17:13, 34.93it/s]
epoch 63900  training loss: 0.07909698039293289

 64%|██████▍   | 63981/100000 [30:39<17:08, 35.00it/s]
epoch 64000  training loss: 0.07965119928121567
epoch 64000  clean testing loss: 0.02307954989373684


 64%|██████▍   | 64121/100000 [30:43<17:07, 34.91it/s]
epoch 64100  training loss: 0.07903972268104553

 64%|██████▍   | 64193/100000 [30:45<17:04, 34.94it/s]
epoch 64200  training loss: 0.07883404195308685


 64%|██████▍   | 64333/100000 [30:49<17:00, 34.94it/s]
epoch 64300  training loss: 0.07948584109544754

 64%|██████▍   | 64401/100000 [30:51<17:00, 34.88it/s]
epoch 64400  training loss: 0.07892625778913498


 65%|██████▍   | 64541/100000 [30:55<16:53, 34.97it/s]
epoch 64500  training loss: 0.0791625827550888

 65%|██████▍   | 64613/100000 [30:57<16:54, 34.90it/s]
epoch 64600  training loss: 0.0792776346206665

 65%|██████▍   | 64681/100000 [30:59<16:50, 34.95it/s]
epoch 64700  training loss: 0.079072006046772


 65%|██████▍   | 64821/100000 [31:03<16:47, 34.92it/s]
epoch 64800  training loss: 0.07910335808992386

 65%|██████▍   | 64889/100000 [31:05<16:57, 34.50it/s]
epoch 64900  training loss: 0.0790431872010231


 65%|██████▌   | 65029/100000 [31:09<16:43, 34.85it/s]
epoch 65000  training loss: 0.0796012207865715
epoch 65000  clean testing loss: 0.02302653342485428

 65%|██████▌   | 65097/100000 [31:11<16:38, 34.96it/s]
epoch 65100  training loss: 0.07958841323852539


 65%|██████▌   | 65241/100000 [31:15<16:34, 34.97it/s]
epoch 65200  training loss: 0.07902446389198303

 65%|██████▌   | 65309/100000 [31:17<16:34, 34.88it/s]
epoch 65300  training loss: 0.07919925451278687


 65%|██████▌   | 65449/100000 [31:21<16:28, 34.96it/s]
epoch 65400  training loss: 0.07919452339410782

 66%|██████▌   | 65521/100000 [31:23<16:26, 34.93it/s]
epoch 65500  training loss: 0.07908198982477188

 66%|██████▌   | 65589/100000 [31:25<16:26, 34.90it/s]
epoch 65600  training loss: 0.0798407569527626


 66%|██████▌   | 65729/100000 [31:29<16:20, 34.94it/s]
epoch 65700  training loss: 0.07892297208309174

 66%|██████▌   | 65797/100000 [31:31<16:19, 34.92it/s]
epoch 65800  training loss: 0.07914897054433823


 66%|██████▌   | 65937/100000 [31:35<16:33, 34.27it/s]
epoch 65900  training loss: 0.0789143517613411

 66%|██████▌   | 66005/100000 [31:37<16:23, 34.55it/s]
epoch 66000  training loss: 0.07934001088142395
epoch 66000  clean testing loss: 0.02301947958767414


 66%|██████▌   | 66145/100000 [31:41<16:08, 34.94it/s]
epoch 66100  training loss: 0.07900933921337128

 66%|██████▌   | 66217/100000 [31:43<16:07, 34.91it/s]
epoch 66200  training loss: 0.07820155471563339

 66%|██████▋   | 66285/100000 [31:45<16:03, 34.98it/s]
epoch 66300  training loss: 0.07957065105438232


 66%|██████▋   | 66425/100000 [31:49<16:01, 34.91it/s]
epoch 66400  training loss: 0.07999349385499954

 66%|██████▋   | 66497/100000 [31:51<15:57, 34.98it/s]
epoch 66500  training loss: 0.08015000075101852


 67%|██████▋   | 66637/100000 [31:55<15:54, 34.94it/s]
epoch 66600  training loss: 0.07906085252761841

 67%|██████▋   | 66705/100000 [31:57<15:55, 34.83it/s]
epoch 66700  training loss: 0.07866691797971725


 67%|██████▋   | 66845/100000 [32:01<15:48, 34.94it/s]
epoch 66800  training loss: 0.080052949488163

 67%|██████▋   | 66917/100000 [32:03<15:47, 34.93it/s]
epoch 66900  training loss: 0.07895620167255402

 67%|██████▋   | 66985/100000 [32:05<16:07, 34.13it/s]
epoch 67000  training loss: 0.0796237364411354
epoch 67000  clean testing loss: 0.022920379415154457


 67%|██████▋   | 67125/100000 [32:09<15:40, 34.94it/s]
epoch 67100  training loss: 0.07945384085178375

 67%|██████▋   | 67193/100000 [32:11<15:38, 34.96it/s]
epoch 67200  training loss: 0.07893665879964828


 67%|██████▋   | 67333/100000 [32:15<15:34, 34.96it/s]
epoch 67300  training loss: 0.07942171394824982

 67%|██████▋   | 67405/100000 [32:17<15:36, 34.82it/s]
epoch 67400  training loss: 0.07885657995939255


 68%|██████▊   | 67545/100000 [32:21<15:27, 34.98it/s]
epoch 67500  training loss: 0.07995427399873734

 68%|██████▊   | 67613/100000 [32:23<15:28, 34.89it/s]
epoch 67600  training loss: 0.07887562364339828

 68%|██████▊   | 67685/100000 [32:25<15:24, 34.96it/s]
epoch 67700  training loss: 0.07967986166477203


 68%|██████▊   | 67825/100000 [32:29<15:20, 34.96it/s]
epoch 67800  training loss: 0.07925964146852493

 68%|██████▊   | 67893/100000 [32:31<15:18, 34.97it/s]
epoch 67900  training loss: 0.07969586551189423


 68%|██████▊   | 68033/100000 [32:35<15:41, 33.96it/s]
epoch 68000  training loss: 0.07933836430311203
epoch 68000  clean testing loss: 0.02266448177397251

 68%|██████▊   | 68101/100000 [32:37<15:12, 34.94it/s]
epoch 68100  training loss: 0.07930253446102142


 68%|██████▊   | 68241/100000 [32:41<15:07, 35.00it/s]
epoch 68200  training loss: 0.0799395889043808

 68%|██████▊   | 68313/100000 [32:43<15:10, 34.81it/s]
epoch 68300  training loss: 0.07872958481311798

 68%|██████▊   | 68381/100000 [32:45<15:03, 34.98it/s]
epoch 68400  training loss: 0.07941460609436035


 69%|██████▊   | 68521/100000 [32:49<15:01, 34.91it/s]
epoch 68500  training loss: 0.07938433438539505

 69%|██████▊   | 68593/100000 [32:51<14:57, 34.98it/s]
epoch 68600  training loss: 0.07869763672351837


 69%|██████▊   | 68733/100000 [32:55<14:53, 34.98it/s]
epoch 68700  training loss: 0.07996499538421631

 69%|██████▉   | 68801/100000 [32:57<14:52, 34.95it/s]
epoch 68800  training loss: 0.07919169217348099


 69%|██████▉   | 68941/100000 [33:01<14:48, 34.95it/s]
epoch 68900  training loss: 0.07918227463960648

 69%|██████▉   | 69013/100000 [33:03<14:51, 34.77it/s]
epoch 69000  training loss: 0.07923361659049988
epoch 69000  clean testing loss: 0.022800538688898087


 69%|██████▉   | 69149/100000 [33:07<14:42, 34.97it/s]
epoch 69100  training loss: 0.08041089028120041

 69%|██████▉   | 69221/100000 [33:09<14:41, 34.93it/s]
epoch 69200  training loss: 0.07933775335550308

 69%|██████▉   | 69289/100000 [33:11<14:38, 34.95it/s]
epoch 69300  training loss: 0.0789906233549118


 69%|██████▉   | 69429/100000 [33:15<14:34, 34.94it/s]
epoch 69400  training loss: 0.08027209341526031

 70%|██████▉   | 69501/100000 [33:17<14:32, 34.94it/s]
epoch 69500  training loss: 0.07915090024471283


 70%|██████▉   | 69641/100000 [33:21<14:27, 34.98it/s]
epoch 69600  training loss: 0.0799826979637146

 70%|██████▉   | 69709/100000 [33:23<14:28, 34.87it/s]
epoch 69700  training loss: 0.0793914869427681


 70%|██████▉   | 69849/100000 [33:27<14:21, 34.99it/s]
epoch 69800  training loss: 0.07915554195642471

 70%|██████▉   | 69921/100000 [33:29<14:24, 34.79it/s]
epoch 69900  training loss: 0.07881073653697968

 70%|██████▉   | 69989/100000 [33:31<14:19, 34.91it/s]
epoch 70000  training loss: 0.07967931032180786
epoch 70000  clean testing loss: 0.02286902256309986


 70%|███████   | 70129/100000 [33:35<15:01, 33.14it/s]
epoch 70100  training loss: 0.07955554872751236

 70%|███████   | 70197/100000 [33:37<14:13, 34.92it/s]
epoch 70200  training loss: 0.07899434864521027


 70%|███████   | 70337/100000 [33:41<14:09, 34.94it/s]
epoch 70300  training loss: 0.07908128201961517

 70%|███████   | 70405/100000 [33:43<14:12, 34.73it/s]
epoch 70400  training loss: 0.07958055287599564


 71%|███████   | 70545/100000 [33:47<14:02, 34.98it/s]
epoch 70500  training loss: 0.07992221415042877

 71%|███████   | 70617/100000 [33:49<14:02, 34.89it/s]
epoch 70600  training loss: 0.07928300648927689

 71%|███████   | 70685/100000 [33:51<13:58, 34.97it/s]
epoch 70700  training loss: 0.07926250994205475


 71%|███████   | 70825/100000 [33:55<13:56, 34.89it/s]
epoch 70800  training loss: 0.07874909043312073

 71%|███████   | 70897/100000 [33:57<13:52, 34.95it/s]
epoch 70900  training loss: 0.07968352735042572


 71%|███████   | 71037/100000 [34:01<13:49, 34.90it/s]
epoch 71000  training loss: 0.07921683043241501
epoch 71000  clean testing loss: 0.02266238071024418

 71%|███████   | 71105/100000 [34:03<13:50, 34.79it/s]
epoch 71100  training loss: 0.07915523648262024


 71%|███████   | 71245/100000 [34:07<13:43, 34.93it/s]
epoch 71200  training loss: 0.08012884110212326

 71%|███████▏  | 71313/100000 [34:09<13:42, 34.88it/s]
epoch 71300  training loss: 0.07919726520776749

 71%|███████▏  | 71385/100000 [34:11<13:37, 34.98it/s]
epoch 71400  training loss: 0.0793503001332283


 72%|███████▏  | 71525/100000 [34:15<13:33, 34.98it/s]
epoch 71500  training loss: 0.0795699954032898

 72%|███████▏  | 71593/100000 [34:17<13:31, 34.99it/s]
epoch 71600  training loss: 0.07957623898983002


 72%|███████▏  | 71733/100000 [34:21<13:30, 34.89it/s]
epoch 71700  training loss: 0.08011071383953094

 72%|███████▏  | 71805/100000 [34:23<13:30, 34.78it/s]
epoch 71800  training loss: 0.07884871959686279


 72%|███████▏  | 71945/100000 [34:28<13:23, 34.92it/s]
epoch 71900  training loss: 0.07877795398235321

 72%|███████▏  | 72013/100000 [34:29<13:25, 34.76it/s]
epoch 72000  training loss: 0.07901651412248611
epoch 72000  clean testing loss: 0.022546853870153427

 72%|███████▏  | 72085/100000 [34:32<13:18, 34.95it/s]
epoch 72100  training loss: 0.07935958355665207


 72%|███████▏  | 72221/100000 [34:35<14:41, 31.50it/s]
epoch 72200  training loss: 0.08001293241977692

 72%|███████▏  | 72293/100000 [34:38<13:12, 34.95it/s]
epoch 72300  training loss: 0.07965172082185745


 72%|███████▏  | 72433/100000 [34:42<13:08, 34.95it/s]
epoch 72400  training loss: 0.0794672816991806

 73%|███████▎  | 72501/100000 [34:43<13:08, 34.86it/s]
epoch 72500  training loss: 0.07952716946601868


 73%|███████▎  | 72641/100000 [34:48<13:03, 34.91it/s]
epoch 72600  training loss: 0.0797187015414238

 73%|███████▎  | 72713/100000 [34:50<13:03, 34.84it/s]
epoch 72700  training loss: 0.07906784117221832

 73%|███████▎  | 72781/100000 [34:52<13:00, 34.88it/s]
epoch 72800  training loss: 0.07881268858909607


 73%|███████▎  | 72921/100000 [34:56<12:54, 34.96it/s]
epoch 72900  training loss: 0.07906881719827652

 73%|███████▎  | 72993/100000 [34:58<12:51, 35.00it/s]
epoch 73000  training loss: 0.07898641377687454
epoch 73000  clean testing loss: 0.022578176110982895


 73%|███████▎  | 73133/100000 [35:02<12:48, 34.94it/s]
epoch 73100  training loss: 0.07926859706640244

 73%|███████▎  | 73201/100000 [35:04<12:48, 34.86it/s]
epoch 73200  training loss: 0.07988506555557251


 73%|███████▎  | 73337/100000 [35:08<12:44, 34.87it/s]
epoch 73300  training loss: 0.07955169677734375

 73%|███████▎  | 73409/100000 [35:10<12:45, 34.72it/s]
epoch 73400  training loss: 0.07863900810480118


 74%|███████▎  | 73549/100000 [35:14<12:36, 34.98it/s]
epoch 73500  training loss: 0.07916831970214844

 74%|███████▎  | 73621/100000 [35:16<12:34, 34.96it/s]
epoch 73600  training loss: 0.07853110134601593

 74%|███████▎  | 73689/100000 [35:18<12:34, 34.87it/s]
epoch 73700  training loss: 0.07923265546560287


 74%|███████▍  | 73829/100000 [35:22<12:28, 34.96it/s]
epoch 73800  training loss: 0.07897410541772842

 74%|███████▍  | 73897/100000 [35:24<12:26, 34.98it/s]
epoch 73900  training loss: 0.07948117703199387


 74%|███████▍  | 74037/100000 [35:28<12:25, 34.84it/s]
epoch 74000  training loss: 0.07988830655813217
epoch 74000  clean testing loss: 0.022653691470623016

 74%|███████▍  | 74109/100000 [35:30<12:23, 34.83it/s]
epoch 74100  training loss: 0.07874366641044617


 74%|███████▍  | 74249/100000 [35:34<12:16, 34.98it/s]
epoch 74200  training loss: 0.07856664806604385

 74%|███████▍  | 74317/100000 [35:36<14:31, 29.47it/s]
epoch 74300  training loss: 0.07959571480751038

 74%|███████▍  | 74385/100000 [35:38<12:12, 34.97it/s]
epoch 74400  training loss: 0.0796462669968605


 75%|███████▍  | 74525/100000 [35:42<12:09, 34.91it/s]
epoch 74500  training loss: 0.07900572568178177

 75%|███████▍  | 74597/100000 [35:44<12:07, 34.93it/s]
epoch 74600  training loss: 0.0790206789970398


 75%|███████▍  | 74733/100000 [35:48<12:03, 34.90it/s]
epoch 74700  training loss: 0.07868567854166031

 75%|███████▍  | 74805/100000 [35:50<12:02, 34.86it/s]
epoch 74800  training loss: 0.0785842314362526


 75%|███████▍  | 74945/100000 [35:54<11:56, 34.97it/s]
epoch 74900  training loss: 0.0791950523853302

 75%|███████▌  | 75013/100000 [35:56<11:59, 34.74it/s]
epoch 75000  training loss: 0.0794236809015274
epoch 75000  clean testing loss: 0.022603889927268028

 75%|███████▌  | 75085/100000 [35:58<11:52, 34.98it/s]
epoch 75100  training loss: 0.07943878322839737


 75%|███████▌  | 75225/100000 [36:02<11:48, 34.95it/s]
epoch 75200  training loss: 0.07995687425136566

 75%|███████▌  | 75293/100000 [36:04<11:45, 35.00it/s]
epoch 75300  training loss: 0.07920100539922714


 75%|███████▌  | 75413/100000 [36:07<11:58, 34.22it/s]
epoch 75400  training loss: 0.07976780086755753

 75%|███████▌  | 75485/100000 [36:09<11:40, 34.97it/s]
epoch 75500  training loss: 0.07893048971891403


 76%|███████▌  | 75621/100000 [36:13<11:37, 34.97it/s]
epoch 75600  training loss: 0.07921160757541656

 76%|███████▌  | 75693/100000 [36:15<11:34, 34.99it/s]
epoch 75700  training loss: 0.07879258692264557

 76%|███████▌  | 75765/100000 [36:17<11:33, 34.93it/s]
epoch 75800  training loss: 0.07951594144105911


 76%|███████▌  | 75905/100000 [36:21<11:32, 34.81it/s]
epoch 75900  training loss: 0.07931238412857056

 76%|███████▌  | 75973/100000 [36:23<11:26, 35.00it/s]
epoch 76000  training loss: 0.0795290470123291
epoch 76000  clean testing loss: 0.022679870948195457


 76%|███████▌  | 76113/100000 [36:27<11:24, 34.88it/s]
epoch 76100  training loss: 0.08020389825105667

 76%|███████▌  | 76185/100000 [36:29<11:21, 34.97it/s]
epoch 76200  training loss: 0.07892484962940216


 76%|███████▋  | 76325/100000 [36:33<11:17, 34.96it/s]
epoch 76300  training loss: 0.07999181747436523

 76%|███████▋  | 76393/100000 [36:35<11:15, 34.95it/s]
epoch 76400  training loss: 0.08008747547864914


 77%|███████▋  | 76533/100000 [36:39<11:10, 34.98it/s]
epoch 76500  training loss: 0.07850829511880875

 77%|███████▋  | 76601/100000 [36:41<11:09, 34.93it/s]
epoch 76600  training loss: 0.0796726644039154

 77%|███████▋  | 76673/100000 [36:43<11:08, 34.89it/s]
epoch 76700  training loss: 0.07889926433563232


 77%|███████▋  | 76813/100000 [36:47<11:04, 34.90it/s]
epoch 76800  training loss: 0.07962161302566528

 77%|███████▋  | 76881/100000 [36:49<11:01, 34.94it/s]
epoch 76900  training loss: 0.07994603365659714


 77%|███████▋  | 77021/100000 [36:53<10:59, 34.87it/s]
epoch 77000  training loss: 0.07928832620382309
epoch 77000  clean testing loss: 0.022832201793789864

 77%|███████▋  | 77093/100000 [36:55<10:55, 34.97it/s]
epoch 77100  training loss: 0.0782819464802742


 77%|███████▋  | 77233/100000 [36:59<10:51, 34.96it/s]
epoch 77200  training loss: 0.0789053812623024

 77%|███████▋  | 77301/100000 [37:01<10:49, 34.94it/s]
epoch 77300  training loss: 0.07873325049877167

 77%|███████▋  | 77373/100000 [37:03<10:46, 35.00it/s]
epoch 77400  training loss: 0.0795464962720871


 78%|███████▊  | 77509/100000 [37:07<11:04, 33.84it/s]
epoch 77500  training loss: 0.07996418327093124

 78%|███████▊  | 77581/100000 [37:09<10:41, 34.96it/s]
epoch 77600  training loss: 0.07842274755239487


 78%|███████▊  | 77721/100000 [37:13<10:39, 34.86it/s]
epoch 77700  training loss: 0.07952345907688141

 78%|███████▊  | 77789/100000 [37:15<10:35, 34.96it/s]
epoch 77800  training loss: 0.07942619174718857


 78%|███████▊  | 77929/100000 [37:19<10:31, 34.96it/s]
epoch 77900  training loss: 0.07948874682188034

 78%|███████▊  | 78001/100000 [37:21<10:39, 34.38it/s]
epoch 78000  training loss: 0.07986342906951904
epoch 78000  clean testing loss: 0.02292647399008274


 78%|███████▊  | 78141/100000 [37:25<10:25, 34.92it/s]
epoch 78100  training loss: 0.0785522311925888

 78%|███████▊  | 78209/100000 [37:27<10:25, 34.86it/s]
epoch 78200  training loss: 0.07850998640060425


 78%|███████▊  | 78349/100000 [37:31<10:19, 34.92it/s]
epoch 78300  training loss: 0.07894588261842728

 78%|███████▊  | 78421/100000 [37:33<10:17, 34.92it/s]
epoch 78400  training loss: 0.07891345024108887

 78%|███████▊  | 78489/100000 [37:35<10:15, 34.95it/s]
epoch 78500  training loss: 0.07853591442108154


 79%|███████▊  | 78629/100000 [37:39<10:10, 34.98it/s]
epoch 78600  training loss: 0.07848251610994339

 79%|███████▊  | 78697/100000 [37:41<10:08, 34.98it/s]
epoch 78700  training loss: 0.07969047874212265


 79%|███████▉  | 78837/100000 [37:45<10:05, 34.95it/s]
epoch 78800  training loss: 0.07943439483642578

 79%|███████▉  | 78909/100000 [37:47<10:04, 34.89it/s]
epoch 78900  training loss: 0.07906757295131683


 79%|███████▉  | 79045/100000 [37:51<10:00, 34.91it/s]
epoch 79000  training loss: 0.07925144582986832
epoch 79000  clean testing loss: 0.022872621193528175

 79%|███████▉  | 79117/100000 [37:53<09:58, 34.89it/s]
epoch 79100  training loss: 0.0788160040974617

 79%|███████▉  | 79185/100000 [37:55<09:55, 34.97it/s]
epoch 79200  training loss: 0.07903823256492615


 79%|███████▉  | 79325/100000 [37:59<09:51, 34.93it/s]
epoch 79300  training loss: 0.07838904857635498

 79%|███████▉  | 79397/100000 [38:01<09:49, 34.93it/s]
epoch 79400  training loss: 0.07961180061101913


 80%|███████▉  | 79537/100000 [38:05<09:45, 34.96it/s]
epoch 79500  training loss: 0.07940453290939331

 80%|███████▉  | 79605/100000 [38:07<10:11, 33.35it/s]
epoch 79600  training loss: 0.07973457127809525


 80%|███████▉  | 79745/100000 [38:11<09:39, 34.96it/s]
epoch 79700  training loss: 0.07952263206243515

 80%|███████▉  | 79813/100000 [38:13<09:39, 34.85it/s]
epoch 79800  training loss: 0.07997611165046692

 80%|███████▉  | 79885/100000 [38:15<09:34, 35.00it/s]
epoch 79900  training loss: 0.0794479250907898


 80%|████████  | 80025/100000 [38:20<09:32, 34.90it/s]
epoch 80000  training loss: 0.0784946009516716
epoch 80000  clean testing loss: 0.022985534742474556

 80%|████████  | 80093/100000 [38:21<09:29, 34.93it/s]
epoch 80100  training loss: 0.07889267802238464


 80%|████████  | 80233/100000 [38:25<09:26, 34.89it/s]
epoch 80200  training loss: 0.07886151224374771

 80%|████████  | 80305/100000 [38:28<09:25, 34.82it/s]
epoch 80300  training loss: 0.07946957647800446


 80%|████████  | 80445/100000 [38:32<09:19, 34.95it/s]
epoch 80400  training loss: 0.0788087397813797

 81%|████████  | 80513/100000 [38:33<09:18, 34.88it/s]
epoch 80500  training loss: 0.07866762578487396

 81%|████████  | 80585/100000 [38:36<09:14, 35.00it/s]
epoch 80600  training loss: 0.0796080082654953


 81%|████████  | 80721/100000 [38:40<09:18, 34.52it/s]
epoch 80700  training loss: 0.07919704169034958

 81%|████████  | 80793/100000 [38:42<09:08, 35.00it/s]
epoch 80800  training loss: 0.07871729880571365


 81%|████████  | 80933/100000 [38:46<09:06, 34.91it/s]
epoch 80900  training loss: 0.07864530384540558

 81%|████████  | 81001/100000 [38:48<09:13, 34.30it/s]
epoch 81000  training loss: 0.07997705042362213
epoch 81000  clean testing loss: 0.02291778288781643


 81%|████████  | 81141/100000 [38:52<08:59, 34.96it/s]
epoch 81100  training loss: 0.07949745655059814

 81%|████████  | 81209/100000 [38:53<08:59, 34.83it/s]
epoch 81200  training loss: 0.07972497493028641


 81%|████████▏ | 81349/100000 [38:58<08:53, 34.94it/s]
epoch 81300  training loss: 0.079693503677845

 81%|████████▏ | 81421/100000 [39:00<08:52, 34.90it/s]
epoch 81400  training loss: 0.07981741428375244

 81%|████████▏ | 81489/100000 [39:02<08:50, 34.92it/s]
epoch 81500  training loss: 0.07891428470611572


 82%|████████▏ | 81629/100000 [39:06<08:46, 34.93it/s]
epoch 81600  training loss: 0.07922366261482239

 82%|████████▏ | 81697/100000 [39:08<09:33, 31.92it/s]
epoch 81700  training loss: 0.07959040254354477


 82%|████████▏ | 81837/100000 [39:12<08:39, 34.98it/s]
epoch 81800  training loss: 0.07893912494182587

 82%|████████▏ | 81909/100000 [39:14<08:38, 34.91it/s]
epoch 81900  training loss: 0.07906237989664078


 82%|████████▏ | 82049/100000 [39:18<08:33, 34.97it/s]
epoch 82000  training loss: 0.07894404232501984
epoch 82000  clean testing loss: 0.022902745753526688

 82%|████████▏ | 82117/100000 [39:20<08:33, 34.86it/s]
epoch 82100  training loss: 0.0794036015868187

 82%|████████▏ | 82189/100000 [39:22<08:30, 34.91it/s]
epoch 82200  training loss: 0.07866804301738739


 82%|████████▏ | 82329/100000 [39:26<08:25, 34.98it/s]
epoch 82300  training loss: 0.07933753728866577

 82%|████████▏ | 82397/100000 [39:28<08:23, 34.97it/s]
epoch 82400  training loss: 0.07886484265327454


 83%|████████▎ | 82537/100000 [39:32<08:19, 34.95it/s]
epoch 82500  training loss: 0.07883200794458389

 83%|████████▎ | 82609/100000 [39:34<08:19, 34.84it/s]
epoch 82600  training loss: 0.07948723435401917


 83%|████████▎ | 82745/100000 [39:38<09:14, 31.11it/s]
epoch 82700  training loss: 0.07971281558275223

 83%|████████▎ | 82817/100000 [39:40<08:13, 34.80it/s]
epoch 82800  training loss: 0.08006064593791962

 83%|████████▎ | 82885/100000 [39:42<08:10, 34.89it/s]
epoch 82900  training loss: 0.07981344312429428


 83%|████████▎ | 83025/100000 [39:46<08:06, 34.87it/s]
epoch 83000  training loss: 0.07947574555873871
epoch 83000  clean testing loss: 0.02292264997959137

 83%|████████▎ | 83097/100000 [39:48<08:03, 34.97it/s]
epoch 83100  training loss: 0.07977548986673355


 83%|████████▎ | 83237/100000 [39:52<08:00, 34.92it/s]
epoch 83200  training loss: 0.07917451858520508

 83%|████████▎ | 83305/100000 [39:54<08:00, 34.72it/s]
epoch 83300  training loss: 0.07876241207122803


 83%|████████▎ | 83445/100000 [39:58<07:53, 34.93it/s]
epoch 83400  training loss: 0.07949948310852051

 84%|████████▎ | 83517/100000 [40:00<07:51, 34.93it/s]
epoch 83500  training loss: 0.07980890572071075

 84%|████████▎ | 83585/100000 [40:02<07:49, 35.00it/s]
epoch 83600  training loss: 0.07878667116165161


 84%|████████▎ | 83725/100000 [40:06<07:46, 34.86it/s]
epoch 83700  training loss: 0.07877614349126816

 84%|████████▍ | 83793/100000 [40:08<08:51, 30.51it/s]
epoch 83800  training loss: 0.07917993515729904


 84%|████████▍ | 83933/100000 [40:12<07:39, 34.96it/s]
epoch 83900  training loss: 0.07850237935781479

 84%|████████▍ | 84005/100000 [40:14<07:43, 34.54it/s]
epoch 84000  training loss: 0.07960324734449387
epoch 84000  clean testing loss: 0.023037169128656387


 84%|████████▍ | 84141/100000 [40:18<07:35, 34.85it/s]
epoch 84100  training loss: 0.07890766113996506

 84%|████████▍ | 84213/100000 [40:20<07:33, 34.80it/s]
epoch 84200  training loss: 0.07848197966814041

 84%|████████▍ | 84285/100000 [40:22<07:29, 34.97it/s]
epoch 84300  training loss: 0.07910808175802231


 84%|████████▍ | 84421/100000 [40:26<07:27, 34.82it/s]
epoch 84400  training loss: 0.07868438214063644

 84%|████████▍ | 84493/100000 [40:28<07:24, 34.90it/s]
epoch 84500  training loss: 0.0790724903345108


 85%|████████▍ | 84633/100000 [40:32<07:20, 34.90it/s]
epoch 84600  training loss: 0.07904036343097687

 85%|████████▍ | 84701/100000 [40:34<07:19, 34.84it/s]
epoch 84700  training loss: 0.07978226244449615


 85%|████████▍ | 84841/100000 [40:38<08:00, 31.54it/s]
epoch 84800  training loss: 0.07924771308898926

 85%|████████▍ | 84909/100000 [40:40<07:15, 34.64it/s]
epoch 84900  training loss: 0.07992582768201828


 85%|████████▌ | 85049/100000 [40:44<07:07, 34.93it/s]
epoch 85000  training loss: 0.07881702482700348
epoch 85000  clean testing loss: 0.023003563284873962

 85%|████████▌ | 85121/100000 [40:46<07:06, 34.91it/s]
epoch 85100  training loss: 0.07989083975553513

 85%|████████▌ | 85189/100000 [40:48<07:03, 34.99it/s]
epoch 85200  training loss: 0.07926099747419357


 85%|████████▌ | 85329/100000 [40:52<07:00, 34.93it/s]
epoch 85300  training loss: 0.07948511093854904

 85%|████████▌ | 85401/100000 [40:54<06:58, 34.91it/s]
epoch 85400  training loss: 0.0789027214050293


 86%|████████▌ | 85541/100000 [40:58<06:53, 35.00it/s]
epoch 85500  training loss: 0.07836457341909409

 86%|████████▌ | 85609/100000 [41:00<06:53, 34.81it/s]
epoch 85600  training loss: 0.0783771499991417


 86%|████████▌ | 85749/100000 [41:04<06:47, 34.96it/s]
epoch 85700  training loss: 0.0794612392783165

 86%|████████▌ | 85821/100000 [41:06<06:45, 34.93it/s]
epoch 85800  training loss: 0.07925645262002945

 86%|████████▌ | 85889/100000 [41:08<06:43, 34.99it/s]
epoch 85900  training loss: 0.07828222960233688


 86%|████████▌ | 86025/100000 [41:12<06:40, 34.90it/s]
epoch 86000  training loss: 0.0793512836098671
epoch 86000  clean testing loss: 0.0230292696505785

 86%|████████▌ | 86097/100000 [41:14<06:37, 34.95it/s]
epoch 86100  training loss: 0.07859732955694199


 86%|████████▌ | 86237/100000 [41:18<06:33, 34.96it/s]
epoch 86200  training loss: 0.07930291444063187

 86%|████████▋ | 86305/100000 [41:20<06:33, 34.83it/s]
epoch 86300  training loss: 0.07913870364427567


 86%|████████▋ | 86445/100000 [41:24<06:27, 35.00it/s]
epoch 86400  training loss: 0.07957345247268677

 87%|████████▋ | 86517/100000 [41:26<06:25, 34.95it/s]
epoch 86500  training loss: 0.07953695952892303

 87%|████████▋ | 86585/100000 [41:28<06:23, 34.97it/s]
epoch 86600  training loss: 0.07918014377355576


 87%|████████▋ | 86725/100000 [41:32<06:20, 34.93it/s]
epoch 86700  training loss: 0.07888398319482803

 87%|████████▋ | 86797/100000 [41:34<06:17, 34.98it/s]
epoch 86800  training loss: 0.07868728041648865


 87%|████████▋ | 86937/100000 [41:38<06:13, 34.96it/s]
epoch 86900  training loss: 0.07852412760257721

 87%|████████▋ | 87005/100000 [41:40<06:18, 34.31it/s]
epoch 87000  training loss: 0.07932236790657043
epoch 87000  clean testing loss: 0.02299521118402481


 87%|████████▋ | 87145/100000 [41:44<06:07, 34.98it/s]
epoch 87100  training loss: 0.07895109057426453

 87%|████████▋ | 87213/100000 [41:46<06:06, 34.87it/s]
epoch 87200  training loss: 0.07953999936580658

 87%|████████▋ | 87285/100000 [41:48<06:03, 34.97it/s]
epoch 87300  training loss: 0.07884588092565536


 87%|████████▋ | 87425/100000 [41:52<06:00, 34.88it/s]
epoch 87400  training loss: 0.07847362011671066

 87%|████████▋ | 87493/100000 [41:54<05:57, 34.98it/s]
epoch 87500  training loss: 0.07923923432826996


 88%|████████▊ | 87633/100000 [41:58<05:53, 34.94it/s]
epoch 87600  training loss: 0.07901564985513687

 88%|████████▊ | 87705/100000 [42:00<05:52, 34.84it/s]
epoch 87700  training loss: 0.07929132133722305


 88%|████████▊ | 87845/100000 [42:04<05:47, 34.99it/s]
epoch 87800  training loss: 0.07882162928581238

 88%|████████▊ | 87913/100000 [42:06<05:46, 34.89it/s]
epoch 87900  training loss: 0.07902159541845322

 88%|████████▊ | 87985/100000 [42:08<05:44, 34.93it/s]
epoch 88000  training loss: 0.07832346111536026
epoch 88000  clean testing loss: 0.022991176694631577


 88%|████████▊ | 88121/100000 [42:12<05:39, 34.94it/s]
epoch 88100  training loss: 0.07946671545505524

 88%|████████▊ | 88189/100000 [42:14<05:37, 35.01it/s]
epoch 88200  training loss: 0.07910414785146713


 88%|████████▊ | 88329/100000 [42:18<05:33, 34.95it/s]
epoch 88300  training loss: 0.07901353389024734

 88%|████████▊ | 88401/100000 [42:20<05:31, 34.94it/s]
epoch 88400  training loss: 0.07834061980247498


 89%|████████▊ | 88541/100000 [42:24<05:29, 34.79it/s]
epoch 88500  training loss: 0.0791843980550766

 89%|████████▊ | 88609/100000 [42:26<05:26, 34.84it/s]
epoch 88600  training loss: 0.07891160994768143


 89%|████████▊ | 88749/100000 [42:30<05:21, 34.97it/s]
epoch 88700  training loss: 0.07814706861972809

 89%|████████▉ | 88821/100000 [42:32<05:19, 34.95it/s]
epoch 88800  training loss: 0.07893640547990799

 89%|████████▉ | 88889/100000 [42:34<05:17, 35.00it/s]
epoch 88900  training loss: 0.0791143923997879


 89%|████████▉ | 89029/100000 [42:38<05:14, 34.86it/s]
epoch 89000  training loss: 0.07892905175685883
epoch 89000  clean testing loss: 0.023008381947875023

 89%|████████▉ | 89097/100000 [42:40<05:13, 34.76it/s]
epoch 89100  training loss: 0.07855582982301712


 89%|████████▉ | 89237/100000 [42:44<05:07, 34.96it/s]
epoch 89200  training loss: 0.0793139785528183

 89%|████████▉ | 89309/100000 [42:46<05:06, 34.87it/s]
epoch 89300  training loss: 0.07948924601078033


 89%|████████▉ | 89449/100000 [42:50<05:01, 35.00it/s]
epoch 89400  training loss: 0.07878640294075012

 90%|████████▉ | 89517/100000 [42:52<04:59, 34.95it/s]
epoch 89500  training loss: 0.07836709916591644

 90%|████████▉ | 89589/100000 [42:54<04:58, 34.87it/s]
epoch 89600  training loss: 0.07922238111495972


 90%|████████▉ | 89729/100000 [42:58<04:53, 34.95it/s]
epoch 89700  training loss: 0.07897020876407623

 90%|████████▉ | 89797/100000 [43:00<04:51, 35.02it/s]
epoch 89800  training loss: 0.07874998450279236


 90%|████████▉ | 89937/100000 [43:04<04:47, 34.97it/s]
epoch 89900  training loss: 0.07886335253715515

 90%|█████████ | 90009/100000 [43:06<04:48, 34.61it/s]
epoch 90000  training loss: 0.07938285917043686
epoch 90000  clean testing loss: 0.022984495386481285


 90%|█████████ | 90145/100000 [43:10<04:43, 34.76it/s]
epoch 90100  training loss: 0.07953322678804398

 90%|█████████ | 90217/100000 [43:12<04:40, 34.91it/s]
epoch 90200  training loss: 0.07851117849349976

 90%|█████████ | 90285/100000 [43:14<04:37, 34.98it/s]
epoch 90300  training loss: 0.07949022948741913


 90%|█████████ | 90425/100000 [43:18<04:34, 34.92it/s]
epoch 90400  training loss: 0.07882841676473618

 90%|█████████ | 90497/100000 [43:20<04:31, 34.97it/s]
epoch 90500  training loss: 0.07822101563215256


 91%|█████████ | 90637/100000 [43:24<04:27, 34.95it/s]
epoch 90600  training loss: 0.07926774770021439

 91%|█████████ | 90705/100000 [43:26<04:27, 34.80it/s]
epoch 90700  training loss: 0.0784817636013031


 91%|█████████ | 90845/100000 [43:30<04:21, 34.99it/s]
epoch 90800  training loss: 0.07850313186645508

 91%|█████████ | 90917/100000 [43:32<04:19, 34.94it/s]
epoch 90900  training loss: 0.07933519035577774

 91%|█████████ | 90985/100000 [43:34<04:17, 34.95it/s]
epoch 91000  training loss: 0.0794370248913765
epoch 91000  clean testing loss: 0.022931674495339394


 91%|█████████ | 91125/100000 [43:38<04:13, 34.97it/s]
epoch 91100  training loss: 0.0785767212510109

 91%|█████████ | 91177/100000 [43:40<04:22, 33.59it/s]
epoch 91200  training loss: 0.07841917872428894


 91%|█████████▏| 91317/100000 [43:44<04:08, 34.92it/s]
epoch 91300  training loss: 0.0790930986404419

 91%|█████████▏| 91385/100000 [43:46<04:06, 34.98it/s]
epoch 91400  training loss: 0.07963508367538452


 92%|█████████▏| 91525/100000 [43:50<04:02, 34.93it/s]
epoch 91500  training loss: 0.0790950208902359

 92%|█████████▏| 91597/100000 [43:52<04:00, 34.99it/s]
epoch 91600  training loss: 0.0787225216627121

 92%|█████████▏| 91665/100000 [43:54<03:58, 34.96it/s]
epoch 91700  training loss: 0.07973618805408478


 92%|█████████▏| 91805/100000 [43:58<03:55, 34.86it/s]
epoch 91800  training loss: 0.07946322858333588

 92%|█████████▏| 91877/100000 [44:00<03:52, 34.96it/s]
epoch 91900  training loss: 0.07857854664325714


 92%|█████████▏| 92017/100000 [44:04<03:49, 34.82it/s]
epoch 92000  training loss: 0.07962530851364136
epoch 92000  clean testing loss: 0.022953545674681664

 92%|█████████▏| 92085/100000 [44:06<03:46, 34.94it/s]
epoch 92100  training loss: 0.07888432592153549


 92%|█████████▏| 92225/100000 [44:10<03:53, 33.35it/s]
epoch 92200  training loss: 0.07862912118434906

 92%|█████████▏| 92293/100000 [44:12<03:40, 34.92it/s]
epoch 92300  training loss: 0.07950945943593979


 92%|█████████▏| 92433/100000 [44:16<03:36, 34.92it/s]
epoch 92400  training loss: 0.07942789047956467

 93%|█████████▎| 92505/100000 [44:18<03:35, 34.79it/s]
epoch 92500  training loss: 0.07828257232904434

 93%|█████████▎| 92573/100000 [44:20<03:32, 34.90it/s]
epoch 92600  training loss: 0.07884882390499115


 93%|█████████▎| 92713/100000 [44:24<03:29, 34.80it/s]
epoch 92700  training loss: 0.07869089394807816

 93%|█████████▎| 92785/100000 [44:26<03:26, 34.97it/s]
epoch 92800  training loss: 0.07976331561803818


 93%|█████████▎| 92921/100000 [44:30<03:22, 34.89it/s]
epoch 92900  training loss: 0.07923950999975204

 93%|█████████▎| 92993/100000 [44:32<03:20, 34.95it/s]
epoch 93000  training loss: 0.0798201858997345
epoch 93000  clean testing loss: 0.023025410249829292


 93%|█████████▎| 93133/100000 [44:36<03:16, 34.95it/s]
epoch 93100  training loss: 0.07906214147806168

 93%|█████████▎| 93201/100000 [44:38<03:14, 34.93it/s]
epoch 93200  training loss: 0.07925281673669815

 93%|█████████▎| 93269/100000 [44:40<03:32, 31.73it/s]
epoch 93300  training loss: 0.07850535959005356


 93%|█████████▎| 93409/100000 [44:44<03:09, 34.80it/s]
epoch 93400  training loss: 0.07862824946641922

 93%|█████████▎| 93481/100000 [44:46<03:06, 34.98it/s]
epoch 93500  training loss: 0.07984910905361176


 94%|█████████▎| 93621/100000 [44:50<03:02, 34.89it/s]
epoch 93600  training loss: 0.07948411256074905

 94%|█████████▎| 93689/100000 [44:52<03:00, 34.93it/s]
epoch 93700  training loss: 0.07885310053825378


 94%|█████████▍| 93829/100000 [44:56<02:56, 34.99it/s]
epoch 93800  training loss: 0.07918885350227356

 94%|█████████▍| 93901/100000 [44:58<02:54, 34.93it/s]
epoch 93900  training loss: 0.07939353585243225


 94%|█████████▍| 94041/100000 [45:02<02:50, 34.91it/s]
epoch 94000  training loss: 0.07897619158029556
epoch 94000  clean testing loss: 0.02296053059399128

 94%|█████████▍| 94109/100000 [45:04<02:49, 34.85it/s]
epoch 94100  training loss: 0.07874663174152374


 94%|█████████▍| 94249/100000 [45:08<02:44, 34.93it/s]
epoch 94200  training loss: 0.07946374267339706

 94%|█████████▍| 94317/100000 [45:10<03:00, 31.45it/s]
epoch 94300  training loss: 0.07984569668769836

 94%|█████████▍| 94389/100000 [45:12<02:40, 34.95it/s]
epoch 94400  training loss: 0.07937058806419373


 95%|█████████▍| 94529/100000 [45:16<02:36, 34.89it/s]
epoch 94500  training loss: 0.0792946144938469

 95%|█████████▍| 94597/100000 [45:18<02:34, 34.90it/s]
epoch 94600  training loss: 0.07931080460548401


 95%|█████████▍| 94737/100000 [45:22<02:31, 34.83it/s]
epoch 94700  training loss: 0.07816053926944733

 95%|█████████▍| 94809/100000 [45:24<02:29, 34.71it/s]
epoch 94800  training loss: 0.07880675047636032


 95%|█████████▍| 94949/100000 [45:28<02:24, 34.95it/s]
epoch 94900  training loss: 0.07941651344299316

 95%|█████████▌| 95017/100000 [45:30<02:22, 34.85it/s]
epoch 95000  training loss: 0.07877419888973236
epoch 95000  clean testing loss: 0.022937005385756493

 95%|█████████▌| 95089/100000 [45:32<02:20, 34.97it/s]
epoch 95100  training loss: 0.07840234041213989


 95%|█████████▌| 95229/100000 [45:36<02:16, 35.01it/s]
epoch 95200  training loss: 0.07873577624559402

 95%|█████████▌| 95297/100000 [45:38<02:14, 35.02it/s]
epoch 95300  training loss: 0.07921301573514938


 95%|█████████▌| 95437/100000 [45:42<02:10, 34.94it/s]
epoch 95400  training loss: 0.07916278392076492

 96%|█████████▌| 95505/100000 [45:44<02:09, 34.71it/s]
epoch 95500  training loss: 0.07815971225500107


 96%|█████████▌| 95645/100000 [45:48<02:04, 34.97it/s]
epoch 95600  training loss: 0.07904016226530075

 96%|█████████▌| 95713/100000 [45:50<02:02, 34.92it/s]
epoch 95700  training loss: 0.07795000821352005

 96%|█████████▌| 95785/100000 [45:52<02:00, 34.98it/s]
epoch 95800  training loss: 0.0785556510090828


 96%|█████████▌| 95925/100000 [45:56<01:56, 34.86it/s]
epoch 95900  training loss: 0.07824432849884033

 96%|█████████▌| 95993/100000 [45:58<01:54, 34.95it/s]
epoch 96000  training loss: 0.07930565625429153
epoch 96000  clean testing loss: 0.02286113053560257


 96%|█████████▌| 96133/100000 [46:02<01:50, 34.96it/s]
epoch 96100  training loss: 0.0776391550898552

 96%|█████████▌| 96205/100000 [46:04<01:49, 34.81it/s]
epoch 96200  training loss: 0.07929297536611557


 96%|█████████▋| 96345/100000 [46:08<01:44, 34.94it/s]
epoch 96300  training loss: 0.07931992411613464

 96%|█████████▋| 96413/100000 [46:10<01:43, 34.79it/s]
epoch 96400  training loss: 0.07831422239542007

 96%|█████████▋| 96481/100000 [46:12<01:40, 34.92it/s]
epoch 96500  training loss: 0.07941043376922607


 97%|█████████▋| 96621/100000 [46:16<01:36, 34.97it/s]
epoch 96600  training loss: 0.07923965901136398

 97%|█████████▋| 96693/100000 [46:18<01:34, 34.98it/s]
epoch 96700  training loss: 0.07831329107284546


 97%|█████████▋| 96833/100000 [46:22<01:30, 34.96it/s]
epoch 96800  training loss: 0.0792832225561142

 97%|█████████▋| 96901/100000 [46:24<01:28, 34.90it/s]
epoch 96900  training loss: 0.07933508604764938


 97%|█████████▋| 97041/100000 [46:28<01:24, 34.96it/s]
epoch 97000  training loss: 0.0787908062338829
epoch 97000  clean testing loss: 0.022833092138171196

 97%|█████████▋| 97113/100000 [46:30<01:22, 34.87it/s]
epoch 97100  training loss: 0.07942596077919006

 97%|█████████▋| 97181/100000 [46:32<01:20, 34.97it/s]
epoch 97200  training loss: 0.07872962951660156


 97%|█████████▋| 97321/100000 [46:36<01:16, 34.91it/s]
epoch 97300  training loss: 0.07899484783411026

 97%|█████████▋| 97393/100000 [46:38<01:14, 34.98it/s]
epoch 97400  training loss: 0.07811572402715683


 98%|█████████▊| 97529/100000 [46:42<01:10, 34.88it/s]
epoch 97500  training loss: 0.07931087166070938

 98%|█████████▊| 97601/100000 [46:44<01:08, 34.95it/s]
epoch 97600  training loss: 0.07821498811244965


 98%|█████████▊| 97741/100000 [46:48<01:04, 34.93it/s]
epoch 97700  training loss: 0.07865557819604874

 98%|█████████▊| 97809/100000 [46:50<01:02, 34.86it/s]
epoch 97800  training loss: 0.0792679414153099


 98%|█████████▊| 97949/100000 [46:54<00:58, 34.90it/s]
epoch 97900  training loss: 0.07828101515769958

 98%|█████████▊| 98021/100000 [46:56<00:56, 34.85it/s]
epoch 98000  training loss: 0.07864350080490112
epoch 98000  clean testing loss: 0.022868460044264793

 98%|█████████▊| 98089/100000 [46:58<00:54, 34.96it/s]
epoch 98100  training loss: 0.07906435430049896


 98%|█████████▊| 98229/100000 [47:02<00:50, 34.92it/s]
epoch 98200  training loss: 0.07831260561943054

 98%|█████████▊| 98301/100000 [47:04<00:48, 34.95it/s]
epoch 98300  training loss: 0.07818695902824402


 98%|█████████▊| 98441/100000 [47:08<00:44, 34.95it/s]
epoch 98400  training loss: 0.07919760793447495

 99%|█████████▊| 98509/100000 [47:10<00:42, 34.82it/s]
epoch 98500  training loss: 0.07873179763555527


 99%|█████████▊| 98649/100000 [47:14<00:38, 34.95it/s]
epoch 98600  training loss: 0.07892278581857681

 99%|█████████▊| 98717/100000 [47:16<00:36, 34.90it/s]
epoch 98700  training loss: 0.07919880002737045

 99%|█████████▉| 98789/100000 [47:18<00:34, 34.96it/s]
epoch 98800  training loss: 0.07909546047449112


 99%|█████████▉| 98929/100000 [47:22<00:30, 34.96it/s]
epoch 98900  training loss: 0.07865004986524582

 99%|█████████▉| 98997/100000 [47:24<00:28, 35.00it/s]
epoch 99000  training loss: 0.07864535599946976
epoch 99000  clean testing loss: 0.022944731637835503


 99%|█████████▉| 99137/100000 [47:28<00:24, 34.96it/s]
epoch 99100  training loss: 0.07854374498128891

 99%|█████████▉| 99209/100000 [47:30<00:22, 34.89it/s]
epoch 99200  training loss: 0.07868596911430359


 99%|█████████▉| 99349/100000 [47:34<00:18, 35.00it/s]
epoch 99300  training loss: 0.07823389768600464

 99%|█████████▉| 99417/100000 [47:36<00:16, 34.89it/s]
epoch 99400  training loss: 0.07923304289579391

 99%|█████████▉| 99489/100000 [47:38<00:14, 34.98it/s]
epoch 99500  training loss: 0.07860685139894485


100%|█████████▉| 99625/100000 [47:42<00:10, 34.84it/s]
epoch 99600  training loss: 0.07934433221817017

100%|█████████▉| 99697/100000 [47:44<00:08, 34.96it/s]
epoch 99700  training loss: 0.07778658717870712


100%|█████████▉| 99837/100000 [47:48<00:04, 34.96it/s]
epoch 99800  training loss: 0.07894574105739594

100%|█████████▉| 99905/100000 [47:50<00:02, 34.82it/s]
epoch 99900  training loss: 0.07830115407705307


100%|██████████| 100000/100000 [47:53<00:00, 34.80it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop1_lr5e-05 ...