
  0%|▎                                                                                 | 319/100000 [00:01<06:33, 253.07it/s]
epoch 0  training loss: 0.6105605959892273
epoch 0  clean testing loss: 3.7066900730133057
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 100  training loss: 0.13405734300613403
epoch 100  clean testing loss: 0.0559706836938858
epoch 200  training loss: 0.14008547365665436
epoch 200  clean testing loss: 0.054312653839588165
epoch 300  training loss: 0.13015776872634888

  1%|▋                                                                                 | 827/100000 [00:03<06:28, 255.07it/s]
epoch 400  training loss: 0.12046866118907928
epoch 400  clean testing loss: 0.0517461821436882
epoch 500  training loss: 0.10232524573802948
epoch 500  clean testing loss: 0.03432824835181236
epoch 600  training loss: 0.10423398017883301
epoch 600  clean testing loss: 0.058196377009153366
epoch 700  training loss: 0.10634386539459229
epoch 700  clean testing loss: 0.03723924607038498
epoch 800  training loss: 0.10145209729671478
epoch 800  clean testing loss: 0.034305278211832047
epoch 900  training loss: 0.12069161236286163

  1%|█                                                                                | 1340/100000 [00:05<06:17, 261.20it/s]
epoch 1000  training loss: 0.10072147101163864
epoch 1000  clean testing loss: 0.032908182591199875
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 1100  training loss: 0.12116347253322601
epoch 1100  clean testing loss: 0.04781964048743248
epoch 1200  training loss: 0.11234688013792038
epoch 1200  clean testing loss: 0.0403730571269989
epoch 1300  training loss: 0.11074712872505188
epoch 1300  clean testing loss: 0.042757127434015274
epoch 1400  training loss: 0.16915039718151093

  2%|█▌                                                                               | 1870/100000 [00:07<06:18, 259.30it/s]
epoch 1500  training loss: 0.1138978973031044
epoch 1500  clean testing loss: 0.04552807658910751
epoch 1600  training loss: 0.09178406000137329
epoch 1600  clean testing loss: 0.03113441914319992
epoch 1700  training loss: 0.11326796561479568
epoch 1700  clean testing loss: 0.04315017908811569
epoch 1800  training loss: 0.09525112807750702
epoch 1800  clean testing loss: 0.02967589907348156
epoch 1900  training loss: 0.0915866270661354

  2%|█▉                                                                               | 2360/100000 [00:09<07:18, 222.44it/s]
epoch 2000  training loss: 0.09137772023677826
epoch 2000  clean testing loss: 0.028625285252928734
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 2100  training loss: 0.12299142777919769
epoch 2100  clean testing loss: 0.05242890492081642
epoch 2200  training loss: 0.08672770857810974
epoch 2200  clean testing loss: 0.02982565388083458
epoch 2300  training loss: 0.0900517925620079
epoch 2300  clean testing loss: 0.03257015720009804
epoch 2400  training loss: 0.12507770955562592

  3%|██▎                                                                              | 2795/100000 [00:11<07:31, 215.47it/s]
epoch 2500  training loss: 0.10157044231891632
epoch 2500  clean testing loss: 0.04053753986954689
epoch 2600  training loss: 0.10725599527359009
epoch 2600  clean testing loss: 0.03565021604299545
epoch 2700  training loss: 0.09028393030166626
epoch 2700  clean testing loss: 0.02634696289896965
epoch 2800  training loss: 0.08492513746023178

  3%|██▌                                                                              | 3203/100000 [00:13<07:25, 217.38it/s]
epoch 2900  training loss: 0.08414149284362793
epoch 2900  clean testing loss: 0.03270198777318001
epoch 3000  training loss: 0.11376732587814331
epoch 3000  clean testing loss: 0.04258463904261589
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 3100  training loss: 0.09606589376926422
epoch 3100  clean testing loss: 0.035061247646808624
epoch 3200  training loss: 0.10981470346450806

  4%|██▉                                                                              | 3655/100000 [00:15<07:36, 210.88it/s]
epoch 3300  training loss: 0.08733963221311569
epoch 3300  clean testing loss: 0.03096161223948002
epoch 3400  training loss: 0.08514673262834549
epoch 3400  clean testing loss: 0.03362950310111046
epoch 3500  training loss: 0.0834403708577156
epoch 3500  clean testing loss: 0.030763249844312668
epoch 3600  training loss: 0.0970725566148758
epoch 3600  clean testing loss: 0.041643962264060974
epoch 3700  training loss: 0.08050999045372009

  4%|███▎                                                                             | 4086/100000 [00:17<07:25, 215.52it/s]
epoch 3800  training loss: 0.08506810665130615
epoch 3800  clean testing loss: 0.04751782491803169
epoch 3900  training loss: 0.07972520589828491
epoch 3900  clean testing loss: 0.030813897028565407
epoch 4000  training loss: 0.1213909238576889
epoch 4000  clean testing loss: 0.04452820122241974
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 4100  training loss: 0.09480749070644379

  4%|███▌                                                                             | 4440/100000 [00:19<09:06, 174.91it/s]
epoch 4200  training loss: 0.10536296665668488
epoch 4200  clean testing loss: 0.03937629982829094
epoch 4300  training loss: 0.07805633544921875
epoch 4300  clean testing loss: 0.030361395329236984
epoch 4400  training loss: 0.08003707975149155

  5%|███▉                                                                             | 4795/100000 [00:21<08:56, 177.54it/s]
epoch 4500  training loss: 0.07760047912597656
epoch 4500  clean testing loss: 0.030359001830220222
epoch 4600  training loss: 0.07806553691625595
epoch 4600  clean testing loss: 0.029514191672205925
epoch 4700  training loss: 0.07603448629379272
epoch 4700  clean testing loss: 0.031060906127095222
epoch 4800  training loss: 0.09202629327774048

  5%|████▏                                                                            | 5152/100000 [00:23<08:47, 179.93it/s]
epoch 4900  training loss: 0.0881410539150238
epoch 4900  clean testing loss: 0.03364177048206329
epoch 5000  training loss: 0.07936183363199234
epoch 5000  clean testing loss: 0.03224625065922737
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 5100  training loss: 0.0747658908367157

  6%|████▍                                                                            | 5506/100000 [00:25<08:45, 179.74it/s]
epoch 5200  training loss: 0.08767972141504288
epoch 5200  clean testing loss: 0.03275435045361519
epoch 5300  training loss: 0.07579535245895386
epoch 5300  clean testing loss: 0.03166323900222778
epoch 5400  training loss: 0.07455651462078094
epoch 5400  clean testing loss: 0.03318987786769867
epoch 5500  training loss: 0.07297126203775406

  6%|████▋                                                                            | 5862/100000 [00:27<09:02, 173.59it/s]
epoch 5600  training loss: 0.07561851292848587
epoch 5600  clean testing loss: 0.030918210744857788
epoch 5700  training loss: 0.07353972643613815
epoch 5700  clean testing loss: 0.03306199982762337
epoch 5800  training loss: 0.07424195855855942
epoch 5800  clean testing loss: 0.032367512583732605
epoch 5900  training loss: 0.08342068642377853

  6%|█████                                                                            | 6215/100000 [00:29<08:51, 176.54it/s]
epoch 6000  training loss: 0.07346279919147491
epoch 6000  clean testing loss: 0.030793286859989166
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 6100  training loss: 0.07139374315738678
epoch 6100  clean testing loss: 0.033375877887010574
epoch 6200  training loss: 0.07089432328939438

  7%|█████▎                                                                           | 6568/100000 [00:31<08:43, 178.58it/s]
epoch 6300  training loss: 0.07047772407531738
epoch 6300  clean testing loss: 0.034532949328422546
epoch 6400  training loss: 0.07004310190677643
epoch 6400  clean testing loss: 0.03656408190727234
epoch 6500  training loss: 0.07762376219034195
epoch 6500  clean testing loss: 0.03157955780625343
epoch 6600  training loss: 0.06962724775075912

  7%|█████▌                                                                           | 6939/100000 [00:33<08:41, 178.61it/s]
epoch 6700  training loss: 0.07125546783208847
epoch 6700  clean testing loss: 0.03537101671099663
epoch 6800  training loss: 0.07088301330804825
epoch 6800  clean testing loss: 0.0425097718834877
epoch 6900  training loss: 0.0756792202591896

  7%|█████▉                                                                           | 7291/100000 [00:35<08:53, 173.78it/s]
epoch 7000  training loss: 0.07332673668861389
epoch 7000  clean testing loss: 0.033849649131298065
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 7100  training loss: 0.07102000713348389
epoch 7100  clean testing loss: 0.03615982085466385
epoch 7200  training loss: 0.06697919219732285
epoch 7200  clean testing loss: 0.03806539252400398
epoch 7300  training loss: 0.07012598216533661

  8%|██████▏                                                                          | 7645/100000 [00:37<08:42, 176.67it/s]
epoch 7400  training loss: 0.06839572638273239
epoch 7400  clean testing loss: 0.03518030419945717
epoch 7500  training loss: 0.06982983648777008
epoch 7500  clean testing loss: 0.03442907705903053
epoch 7600  training loss: 0.06718938797712326

  8%|██████▍                                                                          | 7998/100000 [00:39<08:34, 178.87it/s]
epoch 7700  training loss: 0.0677158460021019
epoch 7700  clean testing loss: 0.040320608764886856
epoch 7800  training loss: 0.06492521613836288
epoch 7800  clean testing loss: 0.037680305540561676
epoch 7900  training loss: 0.06449861079454422
epoch 7900  clean testing loss: 0.038033679127693176
epoch 8000  training loss: 0.0654744803905487
epoch 8000  clean testing loss: 0.03839848190546036

  8%|██████▊                                                                          | 8348/100000 [00:41<08:47, 173.91it/s]
epoch 8100  training loss: 0.0671699270606041
epoch 8100  clean testing loss: 0.03863370791077614
epoch 8200  training loss: 0.0644737258553505
epoch 8200  clean testing loss: 0.04104528948664665
epoch 8300  training loss: 0.06989073753356934
epoch 8300  clean testing loss: 0.04901594668626785
epoch 8400  training loss: 0.06286092102527618

  9%|███████                                                                          | 8683/100000 [00:43<08:29, 179.32it/s]
epoch 8500  training loss: 0.06265198439359665
epoch 8500  clean testing loss: 0.04158443957567215
epoch 8600  training loss: 0.06322336941957474
epoch 8600  clean testing loss: 0.04096627235412598
epoch 8700  training loss: 0.06295289844274521
epoch 8700  clean testing loss: 0.04188890382647514
epoch 8800  training loss: 0.062367770820856094

  9%|███████▎                                                                         | 9054/100000 [00:45<08:27, 179.26it/s]
epoch 8900  training loss: 0.0629994347691536
epoch 8900  clean testing loss: 0.04125221446156502
epoch 9000  training loss: 0.061987001448869705
epoch 9000  clean testing loss: 0.04131166636943817

  9%|███████▌                                                                         | 9405/100000 [00:47<08:39, 174.53it/s]
epoch 9100  training loss: 0.06072583422064781
epoch 9100  clean testing loss: 0.04145647957921028
epoch 9200  training loss: 0.060320280492305756
epoch 9200  clean testing loss: 0.04228702187538147
epoch 9300  training loss: 0.060418710112571716
epoch 9300  clean testing loss: 0.04036669060587883
epoch 9400  training loss: 0.06170334666967392

 10%|███████▉                                                                         | 9758/100000 [00:49<08:26, 178.11it/s]
epoch 9500  training loss: 0.06163540109992027
epoch 9500  clean testing loss: 0.043771807104349136
epoch 9600  training loss: 0.059728674590587616
epoch 9600  clean testing loss: 0.04287245497107506
epoch 9700  training loss: 0.05933960899710655
epoch 9700  clean testing loss: 0.04221838712692261
epoch 9800  training loss: 0.06117825582623482

 10%|████████                                                                        | 10112/100000 [00:51<08:21, 179.06it/s]
epoch 9900  training loss: 0.06158176809549332
epoch 9900  clean testing loss: 0.045179568231105804
epoch 10000  training loss: 0.06116020306944847
epoch 10000  clean testing loss: 0.04121657460927963
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 10100  training loss: 0.05868489295244217

 10%|████████▍                                                                       | 10484/100000 [00:53<08:19, 179.32it/s]
epoch 10200  training loss: 0.0591539703309536
epoch 10200  clean testing loss: 0.04515606164932251
epoch 10300  training loss: 0.0582130067050457
epoch 10300  clean testing loss: 0.04313141852617264
epoch 10400  training loss: 0.06320606917142868
epoch 10400  clean testing loss: 0.04804636910557747
epoch 10500  training loss: 0.057714514434337616

 11%|████████▋                                                                       | 10835/100000 [00:55<08:30, 174.73it/s]
epoch 10600  training loss: 0.06112198159098625
epoch 10600  clean testing loss: 0.046935778111219406
epoch 10700  training loss: 0.06390812993049622
epoch 10700  clean testing loss: 0.050592318177223206
epoch 10800  training loss: 0.057181764394044876

 11%|████████▉                                                                       | 11190/100000 [00:57<08:21, 177.09it/s]
epoch 10900  training loss: 0.056688740849494934
epoch 10900  clean testing loss: 0.04327511414885521
epoch 11000  training loss: 0.05734976381063461
epoch 11000  clean testing loss: 0.04570012539625168
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 11100  training loss: 0.056860439479351044
epoch 11100  clean testing loss: 0.044376734644174576
epoch 11200  training loss: 0.05838799104094505
 11%|█████████                                                                       | 11320/100000 [00:58<08:29, 174.04it/s][34m[1mwandb[39m[22m: 429 encountered (Filestream rate limit exceeded, retrying in 2.4 seconds.), retrying request
 12%|█████████▏                                                                      | 11543/100000 [00:59<08:13, 179.29it/s]
epoch 11300  training loss: 0.05657189339399338
epoch 11300  clean testing loss: 0.04428235813975334
epoch 11400  training loss: 0.05598890408873558
epoch 11400  clean testing loss: 0.046878647059202194
epoch 11500  training loss: 0.057165082544088364

 12%|█████████▌                                                                      | 11894/100000 [01:01<08:25, 174.45it/s]
epoch 11600  training loss: 0.05922078341245651
epoch 11600  clean testing loss: 0.04655146226286888
epoch 11700  training loss: 0.07306493818759918
epoch 11700  clean testing loss: 0.045752063393592834
epoch 11800  training loss: 0.05558395758271217
epoch 11800  clean testing loss: 0.045396849513053894
epoch 11900  training loss: 0.05569193884730339

 12%|█████████▊                                                                      | 12247/100000 [01:03<08:13, 177.85it/s]
epoch 12000  training loss: 0.05865893140435219
epoch 12000  clean testing loss: 0.044005442410707474
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 12100  training loss: 0.0547616071999073
epoch 12100  clean testing loss: 0.04585709422826767
epoch 12200  training loss: 0.05439493805170059

 13%|██████████                                                                      | 12600/100000 [01:05<08:07, 179.19it/s]
epoch 12300  training loss: 0.05453738942742348
epoch 12300  clean testing loss: 0.04685011878609657
epoch 12400  training loss: 0.05409836024045944
epoch 12400  clean testing loss: 0.04632164537906647
epoch 12500  training loss: 0.055757541209459305
epoch 12500  clean testing loss: 0.04652281478047371
epoch 12600  training loss: 0.05413705110549927

 13%|██████████▎                                                                     | 12952/100000 [01:07<08:15, 175.74it/s]
epoch 12700  training loss: 0.0547148659825325
epoch 12700  clean testing loss: 0.051830217242240906
epoch 12800  training loss: 0.0545201413333416
epoch 12800  clean testing loss: 0.04753180593252182
epoch 12900  training loss: 0.05403142794966698

 13%|██████████▋                                                                     | 13306/100000 [01:09<08:05, 178.68it/s]
epoch 13000  training loss: 0.054093074053525925
epoch 13000  clean testing loss: 0.04874661564826965
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 13100  training loss: 0.05430454760789871
epoch 13100  clean testing loss: 0.050222087651491165
epoch 13200  training loss: 0.05370785668492317
epoch 13200  clean testing loss: 0.047507114708423615
epoch 13300  training loss: 0.05304295942187309

 14%|██████████▉                                                                     | 13660/100000 [01:11<08:02, 179.09it/s]
epoch 13400  training loss: 0.05324640870094299
epoch 13400  clean testing loss: 0.049751244485378265
epoch 13500  training loss: 0.05287818983197212
epoch 13500  clean testing loss: 0.04885111004114151
epoch 13600  training loss: 0.05447922274470329

 14%|███████████▏                                                                    | 14012/100000 [01:13<08:16, 173.31it/s]
epoch 13700  training loss: 0.05376196280121803
epoch 13700  clean testing loss: 0.050875335931777954
epoch 13800  training loss: 0.05403657257556915
epoch 13800  clean testing loss: 0.04832219332456589
epoch 13900  training loss: 0.053211625665426254
epoch 13900  clean testing loss: 0.04931408166885376
epoch 14000  training loss: 0.05694650858640671
epoch 14000  clean testing loss: 0.05556665360927582

 14%|███████████▍                                                                    | 14366/100000 [01:15<08:01, 177.96it/s]
epoch 14100  training loss: 0.05358738452196121
epoch 14100  clean testing loss: 0.04873082786798477
epoch 14200  training loss: 0.05331309884786606
epoch 14200  clean testing loss: 0.0493394136428833
epoch 14300  training loss: 0.05215330794453621
epoch 14300  clean testing loss: 0.048627350479364395
epoch 14400  training loss: 0.053260087966918945

 15%|███████████▊                                                                    | 14737/100000 [01:17<07:59, 177.89it/s]
epoch 14500  training loss: 0.05327576771378517
epoch 14500  clean testing loss: 0.04890067130327225
epoch 14600  training loss: 0.05189324542880058
epoch 14600  clean testing loss: 0.04966405779123306
epoch 14700  training loss: 0.05151406303048134

 15%|████████████                                                                    | 15090/100000 [01:19<07:53, 179.23it/s]
epoch 14800  training loss: 0.05223732069134712
epoch 14800  clean testing loss: 0.05061626061797142
epoch 14900  training loss: 0.05180560424923897
epoch 14900  clean testing loss: 0.05085952207446098
epoch 15000  training loss: 0.05222431570291519
epoch 15000  clean testing loss: 0.05057736113667488
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 15100  training loss: 0.050766490399837494

 15%|████████████▎                                                                   | 15441/100000 [01:21<08:03, 174.77it/s]
epoch 15200  training loss: 0.050753410905599594
epoch 15200  clean testing loss: 0.04990328475832939
epoch 15300  training loss: 0.05073198303580284
epoch 15300  clean testing loss: 0.051800891757011414
epoch 15400  training loss: 0.050869785249233246

 16%|████████████▋                                                                   | 15801/100000 [01:23<07:56, 176.75it/s]
epoch 15500  training loss: 0.05022425577044487
epoch 15500  clean testing loss: 0.05099773406982422
epoch 15600  training loss: 0.050497088581323624
epoch 15600  clean testing loss: 0.050570048391819
epoch 15700  training loss: 0.05051327869296074
epoch 15700  clean testing loss: 0.050266847014427185
epoch 15800  training loss: 0.05320720747113228

 16%|████████████▉                                                                   | 16154/100000 [01:25<07:49, 178.77it/s]
epoch 15900  training loss: 0.050118058919906616
epoch 15900  clean testing loss: 0.05182179808616638
epoch 16000  training loss: 0.05006929859519005
epoch 16000  clean testing loss: 0.05315292626619339
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 16100  training loss: 0.050995100289583206

 17%|█████████████▏                                                                  | 16506/100000 [01:27<07:58, 174.48it/s]
epoch 16200  training loss: 0.050209201872348785
epoch 16200  clean testing loss: 0.052794985473155975
epoch 16300  training loss: 0.04939472675323486
epoch 16300  clean testing loss: 0.051018983125686646
epoch 16400  training loss: 0.04919859394431114
epoch 16400  clean testing loss: 0.051617685705423355
epoch 16500  training loss: 0.05029663071036339

 17%|█████████████▍                                                                  | 16859/100000 [01:29<07:48, 177.29it/s]
epoch 16600  training loss: 0.04897642880678177
epoch 16600  clean testing loss: 0.05208281800150871
epoch 16700  training loss: 0.06909198313951492
epoch 16700  clean testing loss: 0.06083086133003235
epoch 16800  training loss: 0.04913759231567383

 17%|█████████████▊                                                                  | 17212/100000 [01:31<07:44, 178.28it/s]
epoch 16900  training loss: 0.04892345517873764
epoch 16900  clean testing loss: 0.05373965948820114
epoch 17000  training loss: 0.04866151511669159
epoch 17000  clean testing loss: 0.051729775965213776
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 17100  training loss: 0.04868290573358536
epoch 17100  clean testing loss: 0.05312294885516167
epoch 17200  training loss: 0.04878094419836998

 18%|██████████████                                                                  | 17564/100000 [01:33<07:54, 173.67it/s]
epoch 17300  training loss: 0.051342643797397614
epoch 17300  clean testing loss: 0.056063465774059296
epoch 17400  training loss: 0.04942695051431656
epoch 17400  clean testing loss: 0.053075190633535385
epoch 17500  training loss: 0.05435118451714516

 18%|██████████████▎                                                                 | 17918/100000 [01:35<07:44, 176.61it/s]
epoch 17600  training loss: 0.048158466815948486
epoch 17600  clean testing loss: 0.05294420197606087
epoch 17700  training loss: 0.047907400876283646
epoch 17700  clean testing loss: 0.05396999418735504
epoch 17800  training loss: 0.06441366672515869
epoch 17800  clean testing loss: 0.05764655023813248
epoch 17900  training loss: 0.04976625367999077

 18%|██████████████▌                                                                 | 18271/100000 [01:37<07:35, 179.62it/s]
epoch 18000  training loss: 0.05006832256913185
epoch 18000  clean testing loss: 0.0538589283823967
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 18100  training loss: 0.047572407871484756
epoch 18100  clean testing loss: 0.05233772471547127
epoch 18200  training loss: 0.04746299982070923

 19%|██████████████▉                                                                 | 18642/100000 [01:39<07:35, 178.52it/s]
epoch 18300  training loss: 0.04748468101024628
epoch 18300  clean testing loss: 0.05278805270791054
epoch 18400  training loss: 0.04759863391518593
epoch 18400  clean testing loss: 0.053213976323604584
epoch 18500  training loss: 0.047212861478328705
epoch 18500  clean testing loss: 0.0539463572204113
epoch 18600  training loss: 0.04726780578494072

 19%|███████████████▏                                                                | 18993/100000 [01:41<07:45, 173.85it/s]
epoch 18700  training loss: 0.04892275109887123
epoch 18700  clean testing loss: 0.05388560891151428
epoch 18800  training loss: 0.0469023697078228
epoch 18800  clean testing loss: 0.054940737783908844
epoch 18900  training loss: 0.04748629406094551
epoch 18900  clean testing loss: 0.05373356118798256
epoch 19000  training loss: 0.04888187721371651
epoch 19000  clean testing loss: 0.055762454867362976

 19%|███████████████▍                                                                | 19345/100000 [01:43<07:36, 176.56it/s]
epoch 19100  training loss: 0.04751690477132797
epoch 19100  clean testing loss: 0.057494718581438065
epoch 19200  training loss: 0.04623033106327057
epoch 19200  clean testing loss: 0.05403859168291092
epoch 19300  training loss: 0.04651365801692009

 20%|███████████████▊                                                                | 19698/100000 [01:45<07:29, 178.72it/s]
epoch 19400  training loss: 0.045948293060064316
epoch 19400  clean testing loss: 0.05475194752216339
epoch 19500  training loss: 0.04663214460015297
epoch 19500  clean testing loss: 0.05556640774011612
epoch 19600  training loss: 0.04586503282189369
epoch 19600  clean testing loss: 0.054868120700120926
epoch 19700  training loss: 0.04589611291885376

 20%|████████████████                                                                | 20048/100000 [01:47<07:43, 172.66it/s]
epoch 19800  training loss: 0.04697289317846298
epoch 19800  clean testing loss: 0.05446987226605415
epoch 19900  training loss: 0.04570664092898369
epoch 19900  clean testing loss: 0.055673666298389435
epoch 20000  training loss: 0.04791654273867607
epoch 20000  clean testing loss: 0.05682097375392914

 20%|████████████████▎                                                               | 20401/100000 [01:49<07:30, 176.56it/s]
epoch 20100  training loss: 0.04606352746486664
epoch 20100  clean testing loss: 0.05588396266102791
epoch 20200  training loss: 0.0454905740916729
epoch 20200  clean testing loss: 0.05604798346757889
epoch 20300  training loss: 0.045865144580602646
epoch 20300  clean testing loss: 0.05480373650789261
epoch 20400  training loss: 0.04566504806280136

 21%|████████████████▌                                                               | 20772/100000 [01:51<07:27, 177.02it/s]
epoch 20500  training loss: 0.04670824110507965
epoch 20500  clean testing loss: 0.05605272203683853
epoch 20600  training loss: 0.04522603005170822
epoch 20600  clean testing loss: 0.05570072680711746
epoch 20700  training loss: 0.04539145156741142

 21%|████████████████▉                                                               | 21124/100000 [01:53<07:20, 179.15it/s]
epoch 20800  training loss: 0.050213273614645004
epoch 20800  clean testing loss: 0.0637645348906517
epoch 20900  training loss: 0.04506131261587143
epoch 20900  clean testing loss: 0.05547697842121124
epoch 21000  training loss: 0.04934913292527199
epoch 21000  clean testing loss: 0.05519360676407814
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 21100  training loss: 0.04462350532412529

 21%|█████████████████▏                                                              | 21475/100000 [01:55<07:30, 174.19it/s]
epoch 21200  training loss: 0.04442237317562103
epoch 21200  clean testing loss: 0.0555918924510479
epoch 21300  training loss: 0.04475347697734833
epoch 21300  clean testing loss: 0.05563491955399513
epoch 21400  training loss: 0.04433685168623924

 22%|█████████████████▍                                                              | 21828/100000 [01:57<07:21, 177.21it/s]
epoch 21500  training loss: 0.04437322914600372
epoch 21500  clean testing loss: 0.05602638050913811
epoch 21600  training loss: 0.044393278658390045
epoch 21600  clean testing loss: 0.05652758851647377
epoch 21700  training loss: 0.043960437178611755
epoch 21700  clean testing loss: 0.05678962916135788
epoch 21800  training loss: 0.045117978006601334

 22%|█████████████████▋                                                              | 22182/100000 [01:59<07:13, 179.59it/s]
epoch 21900  training loss: 0.04405674338340759
epoch 21900  clean testing loss: 0.05613837018609047
epoch 22000  training loss: 0.043746598064899445
epoch 22000  clean testing loss: 0.05701325461268425
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 22100  training loss: 0.04407911002635956

 23%|██████████████████                                                              | 22534/100000 [02:01<07:24, 174.17it/s]
epoch 22200  training loss: 0.0444859117269516
epoch 22200  clean testing loss: 0.059138089418411255
epoch 22300  training loss: 0.0447678342461586
epoch 22300  clean testing loss: 0.058170996606349945
epoch 22400  training loss: 0.04366553574800491
epoch 22400  clean testing loss: 0.058293841779232025
epoch 22500  training loss: 0.04348321631550789

 23%|██████████████████▎                                                             | 22888/100000 [02:03<07:15, 177.03it/s]
epoch 22600  training loss: 0.043340615928173065
epoch 22600  clean testing loss: 0.057452913373708725
epoch 22700  training loss: 0.04344959184527397
epoch 22700  clean testing loss: 0.057453662157058716
epoch 22800  training loss: 0.04331498593091965
epoch 22800  clean testing loss: 0.05934567376971245
epoch 22900  training loss: 0.04621827229857445

 23%|██████████████████▌                                                             | 23241/100000 [02:05<07:06, 179.88it/s]
epoch 23000  training loss: 0.04335121437907219
epoch 23000  clean testing loss: 0.057553209364414215
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 23100  training loss: 0.04303784668445587
epoch 23100  clean testing loss: 0.05768434330821037
epoch 23200  training loss: 0.04310613498091698

 24%|██████████████████▉                                                             | 23612/100000 [02:07<07:05, 179.70it/s]
epoch 23300  training loss: 0.04312311112880707
epoch 23300  clean testing loss: 0.060048479586839676
epoch 23400  training loss: 0.043424367904663086
epoch 23400  clean testing loss: 0.05782931670546532
epoch 23500  training loss: 0.04339649900794029
epoch 23500  clean testing loss: 0.05791137367486954
epoch 23600  training loss: 0.043245989829301834

 24%|███████████████████▏                                                            | 23963/100000 [02:09<07:14, 174.91it/s]
epoch 23700  training loss: 0.04269743710756302
epoch 23700  clean testing loss: 0.05815304443240166
epoch 23800  training loss: 0.042885422706604004
epoch 23800  clean testing loss: 0.05928376317024231
epoch 23900  training loss: 0.042863935232162476

 24%|███████████████████▍                                                            | 24318/100000 [02:11<07:05, 177.66it/s]
epoch 24000  training loss: 0.042911890894174576
epoch 24000  clean testing loss: 0.0589359812438488
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 24100  training loss: 0.04227059334516525
epoch 24100  clean testing loss: 0.05815977230668068
epoch 24200  training loss: 0.042210835963487625
epoch 24200  clean testing loss: 0.058549653738737106
epoch 24300  training loss: 0.04201893508434296

 25%|███████████████████▋                                                            | 24671/100000 [02:13<07:02, 178.30it/s]
epoch 24400  training loss: 0.0420924536883831
epoch 24400  clean testing loss: 0.058253515511751175
epoch 24500  training loss: 0.04211331531405449
epoch 24500  clean testing loss: 0.05931771546602249
epoch 24600  training loss: 0.04230687767267227

 25%|████████████████████                                                            | 25023/100000 [02:15<07:14, 172.47it/s]
epoch 24700  training loss: 0.04246894270181656
epoch 24700  clean testing loss: 0.05836204066872597
epoch 24800  training loss: 0.04188741743564606
epoch 24800  clean testing loss: 0.05841366946697235
epoch 24900  training loss: 0.04167209193110466
epoch 24900  clean testing loss: 0.059709642082452774
epoch 25000  training loss: 0.041743792593479156
epoch 25000  clean testing loss: 0.05882095545530319

 25%|████████████████████▎                                                           | 25376/100000 [02:17<07:00, 177.36it/s]
epoch 25100  training loss: 0.04184373840689659
epoch 25100  clean testing loss: 0.06093133985996246
epoch 25200  training loss: 0.04138326644897461
epoch 25200  clean testing loss: 0.058906447142362595
epoch 25300  training loss: 0.041706353425979614

 26%|████████████████████▌                                                           | 25729/100000 [02:19<06:51, 180.53it/s]
epoch 25400  training loss: 0.041234880685806274
epoch 25400  clean testing loss: 0.058841198682785034
epoch 25500  training loss: 0.04486032947897911
epoch 25500  clean testing loss: 0.05918991193175316
epoch 25600  training loss: 0.04109597206115723
epoch 25600  clean testing loss: 0.059010256081819534
epoch 25700  training loss: 0.04120578616857529

 26%|████████████████████▊                                                           | 26088/100000 [02:21<06:52, 179.11it/s]
epoch 25800  training loss: 0.043886687606573105
epoch 25800  clean testing loss: 0.06510117650032043
epoch 25900  training loss: 0.04347116872668266
epoch 25900  clean testing loss: 0.059849683195352554
epoch 26000  training loss: 0.041512712836265564
epoch 26000  clean testing loss: 0.06077006831765175

 26%|█████████████████████▏                                                          | 26439/100000 [02:23<07:01, 174.32it/s]
epoch 26100  training loss: 0.040700748562812805
epoch 26100  clean testing loss: 0.05938958376646042
epoch 26200  training loss: 0.04074661433696747
epoch 26200  clean testing loss: 0.059105034917593
epoch 26300  training loss: 0.04049751162528992
epoch 26300  clean testing loss: 0.05960056185722351
epoch 26400  training loss: 0.04044868052005768

 27%|█████████████████████▍                                                          | 26793/100000 [02:25<06:52, 177.37it/s]
epoch 26500  training loss: 0.04074392467737198
epoch 26500  clean testing loss: 0.05987117066979408
epoch 26600  training loss: 0.04046332836151123
epoch 26600  clean testing loss: 0.059825073927640915
epoch 26700  training loss: 0.04092533886432648
epoch 26700  clean testing loss: 0.05988585576415062
epoch 26800  training loss: 0.04176609218120575

 27%|█████████████████████▋                                                          | 27147/100000 [02:27<06:47, 178.96it/s]
epoch 26900  training loss: 0.04125375300645828
epoch 26900  clean testing loss: 0.059855081140995026
epoch 27000  training loss: 0.040002062916755676
epoch 27000  clean testing loss: 0.06038745492696762
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 27100  training loss: 0.039805974811315536

 28%|██████████████████████                                                          | 27567/100000 [02:30<05:45, 209.51it/s]
epoch 27200  training loss: 0.0400439016520977
epoch 27200  clean testing loss: 0.06036427989602089
epoch 27300  training loss: 0.03964868560433388
epoch 27300  clean testing loss: 0.06048223003745079
epoch 27400  training loss: 0.03955293819308281
epoch 27400  clean testing loss: 0.060354046523571014
epoch 27500  training loss: 0.04075222834944725

 28%|██████████████████████▍                                                         | 27978/100000 [02:32<05:55, 202.80it/s]
epoch 27600  training loss: 0.0395408570766449
epoch 27600  clean testing loss: 0.06058625504374504
epoch 27700  training loss: 0.03942231833934784
epoch 27700  clean testing loss: 0.06060322746634483
epoch 27800  training loss: 0.03971800580620766
epoch 27800  clean testing loss: 0.061232417821884155
epoch 27900  training loss: 0.03920239582657814

 28%|██████████████████████▋                                                         | 28391/100000 [02:34<05:48, 205.50it/s]
epoch 28000  training loss: 0.03927743062376976
epoch 28000  clean testing loss: 0.06080878525972366
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 28100  training loss: 0.04196725785732269
epoch 28100  clean testing loss: 0.06253845989704132
epoch 28200  training loss: 0.03979465365409851
epoch 28200  clean testing loss: 0.06278644502162933
epoch 28300  training loss: 0.038924217224121094

 29%|███████████████████████                                                         | 28805/100000 [02:36<05:44, 206.37it/s]
epoch 28400  training loss: 0.038709454238414764
epoch 28400  clean testing loss: 0.0611257366836071
epoch 28500  training loss: 0.039225902408361435
epoch 28500  clean testing loss: 0.06265487521886826
epoch 28600  training loss: 0.038887932896614075
epoch 28600  clean testing loss: 0.06194440647959709
epoch 28700  training loss: 0.03852442279458046

 29%|███████████████████████▎                                                        | 29217/100000 [02:38<05:40, 207.59it/s]
epoch 28800  training loss: 0.0389421321451664
epoch 28800  clean testing loss: 0.06179707124829292
epoch 28900  training loss: 0.04094618558883667
epoch 28900  clean testing loss: 0.06276436895132065
epoch 29000  training loss: 0.038809437304735184
epoch 29000  clean testing loss: 0.061603009700775146
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 29100  training loss: 0.038322433829307556
epoch 29100  clean testing loss: 0.06169668957591057
epoch 29200  training loss: 0.03806314989924431

 30%|███████████████████████▋                                                        | 29630/100000 [02:40<05:35, 209.68it/s]
epoch 29300  training loss: 0.03794616833329201
epoch 29300  clean testing loss: 0.062274493277072906
epoch 29400  training loss: 0.037784356623888016
epoch 29400  clean testing loss: 0.062015268951654434
epoch 29500  training loss: 0.038000233471393585
epoch 29500  clean testing loss: 0.06315713375806808
epoch 29600  training loss: 0.03801342844963074

 30%|████████████████████████                                                        | 30041/100000 [02:42<05:47, 201.17it/s]
epoch 29700  training loss: 0.037473712116479874
epoch 29700  clean testing loss: 0.06249026954174042
epoch 29800  training loss: 0.037719957530498505
epoch 29800  clean testing loss: 0.062996044754982
epoch 29900  training loss: 0.03850619122385979
epoch 29900  clean testing loss: 0.06223506107926369
epoch 30000  training loss: 0.03734004497528076
epoch 30000  clean testing loss: 0.06270002573728561

 30%|████████████████████████▎                                                       | 30454/100000 [02:44<05:38, 205.33it/s]
epoch 30100  training loss: 0.0370907187461853
epoch 30100  clean testing loss: 0.06298656016588211
epoch 30200  training loss: 0.0370120070874691
epoch 30200  clean testing loss: 0.06269564479589462
epoch 30300  training loss: 0.0371314138174057
epoch 30300  clean testing loss: 0.06269877403974533
epoch 30400  training loss: 0.03685671463608742

 31%|████████████████████████▋                                                       | 30867/100000 [02:46<05:34, 206.90it/s]
epoch 30500  training loss: 0.03683068975806236
epoch 30500  clean testing loss: 0.06361743062734604
epoch 30600  training loss: 0.03665977716445923
epoch 30600  clean testing loss: 0.06298001110553741
epoch 30700  training loss: 0.03657755255699158
epoch 30700  clean testing loss: 0.06298983842134476
epoch 30800  training loss: 0.03741929680109024

 31%|█████████████████████████                                                       | 31279/100000 [02:48<05:29, 208.35it/s]
epoch 30900  training loss: 0.03641996160149574
epoch 30900  clean testing loss: 0.0635429099202156
epoch 31000  training loss: 0.03638502210378647
epoch 31000  clean testing loss: 0.06431549042463303
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 31100  training loss: 0.036455366760492325
epoch 31100  clean testing loss: 0.06503758579492569
epoch 31200  training loss: 0.03614016994833946

 32%|█████████████████████████▎                                                      | 31693/100000 [02:50<05:25, 209.69it/s]
epoch 31300  training loss: 0.0366196408867836
epoch 31300  clean testing loss: 0.06572068482637405
epoch 31400  training loss: 0.036042843014001846
epoch 31400  clean testing loss: 0.0643458217382431
epoch 31500  training loss: 0.035993095487356186
epoch 31500  clean testing loss: 0.06384359300136566
epoch 31600  training loss: 0.038281626999378204

 32%|█████████████████████████▋                                                      | 32103/100000 [02:52<05:35, 202.36it/s]
epoch 31700  training loss: 0.03680827096104622
epoch 31700  clean testing loss: 0.06429306417703629
epoch 31800  training loss: 0.03580671548843384
epoch 31800  clean testing loss: 0.06450840830802917
epoch 31900  training loss: 0.035843245685100555
epoch 31900  clean testing loss: 0.06449536979198456
epoch 32000  training loss: 0.035331983119249344
epoch 32000  clean testing loss: 0.06485763192176819

 33%|██████████████████████████                                                      | 32517/100000 [02:54<05:28, 205.42it/s]
epoch 32100  training loss: 0.035926204174757004
epoch 32100  clean testing loss: 0.06581587344408035
epoch 32200  training loss: 0.03563926741480827
epoch 32200  clean testing loss: 0.06516604870557785
epoch 32300  training loss: 0.035307250916957855
epoch 32300  clean testing loss: 0.06520461291074753
epoch 32400  training loss: 0.03534470498561859
epoch 32400  clean testing loss: 0.06536322832107544
epoch 32500  training loss: 0.03541027382016182

 33%|██████████████████████████▎                                                     | 32930/100000 [02:56<05:23, 207.03it/s]
epoch 32600  training loss: 0.03616354987025261
epoch 32600  clean testing loss: 0.0656156986951828
epoch 32700  training loss: 0.034778837114572525
epoch 32700  clean testing loss: 0.06547053903341293
epoch 32800  training loss: 0.03469565883278847
epoch 32800  clean testing loss: 0.06549795717000961
epoch 32900  training loss: 0.035897258669137955

 33%|██████████████████████████▋                                                     | 33342/100000 [02:58<05:19, 208.44it/s]
epoch 33000  training loss: 0.03451567888259888
epoch 33000  clean testing loss: 0.06583517789840698
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 33100  training loss: 0.034376222640275955
epoch 33100  clean testing loss: 0.06592592597007751
epoch 33200  training loss: 0.03451461344957352
epoch 33200  clean testing loss: 0.06608787924051285
epoch 33300  training loss: 0.03426402434706688

 34%|███████████████████████████                                                     | 33757/100000 [03:00<05:15, 209.82it/s]
epoch 33400  training loss: 0.034262292087078094
epoch 33400  clean testing loss: 0.0662560760974884
epoch 33500  training loss: 0.03459462150931358
epoch 33500  clean testing loss: 0.06649383902549744
epoch 33600  training loss: 0.03414753079414368
epoch 33600  clean testing loss: 0.06632845848798752
epoch 33700  training loss: 0.034019581973552704

 34%|███████████████████████████▎                                                    | 34170/100000 [03:02<05:24, 202.61it/s]
epoch 33800  training loss: 0.033958353102207184
epoch 33800  clean testing loss: 0.06688003987073898
epoch 33900  training loss: 0.03398822993040085
epoch 33900  clean testing loss: 0.06677310168743134
epoch 34000  training loss: 0.03474447876214981
epoch 34000  clean testing loss: 0.06719065457582474
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 34100  training loss: 0.034638047218322754

 35%|███████████████████████████▋                                                    | 34585/100000 [03:04<05:19, 204.98it/s]
epoch 34200  training loss: 0.033968474715948105
epoch 34200  clean testing loss: 0.06713277101516724
epoch 34300  training loss: 0.035234905779361725
epoch 34300  clean testing loss: 0.06760893762111664
epoch 34400  training loss: 0.034288130700588226
epoch 34400  clean testing loss: 0.06744537502527237
epoch 34500  training loss: 0.03348575904965401

 35%|███████████████████████████▉                                                    | 34999/100000 [03:06<05:15, 206.08it/s]
epoch 34600  training loss: 0.03388139605522156
epoch 34600  clean testing loss: 0.06766395270824432
epoch 34700  training loss: 0.0336468368768692
epoch 34700  clean testing loss: 0.0682172030210495
epoch 34800  training loss: 0.03372129052877426
epoch 34800  clean testing loss: 0.06783522665500641
epoch 34900  training loss: 0.033232416957616806

 35%|████████████████████████████▎                                                   | 35413/100000 [03:08<05:08, 209.18it/s]
epoch 35000  training loss: 0.033150892704725266
epoch 35000  clean testing loss: 0.06764241307973862
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 35100  training loss: 0.033206503838300705
epoch 35100  clean testing loss: 0.06801921874284744
epoch 35200  training loss: 0.033665720373392105
epoch 35200  clean testing loss: 0.07004585862159729
epoch 35300  training loss: 0.032909464091062546
epoch 35300  clean testing loss: 0.06855946034193039
epoch 35400  training loss: 0.03286600857973099

 36%|████████████████████████████▋                                                   | 35849/100000 [03:10<04:59, 214.08it/s]
epoch 35500  training loss: 0.03290170431137085
epoch 35500  clean testing loss: 0.06845951825380325
epoch 35600  training loss: 0.03278423473238945
epoch 35600  clean testing loss: 0.06891205161809921
epoch 35700  training loss: 0.032994192093610764
epoch 35700  clean testing loss: 0.06908132135868073
epoch 35800  training loss: 0.03292689844965935

 36%|█████████████████████████████                                                   | 36264/100000 [03:12<05:08, 206.35it/s]
epoch 35900  training loss: 0.032929178327322006
epoch 35900  clean testing loss: 0.06866654008626938
epoch 36000  training loss: 0.03274044394493103
epoch 36000  clean testing loss: 0.06910663098096848
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 36100  training loss: 0.03247569501399994
epoch 36100  clean testing loss: 0.06863417476415634
epoch 36200  training loss: 0.03246335685253143

 37%|█████████████████████████████▎                                                  | 36677/100000 [03:14<05:04, 208.13it/s]
epoch 36300  training loss: 0.032394591718912125
epoch 36300  clean testing loss: 0.06877479702234268
epoch 36400  training loss: 0.032297227531671524
epoch 36400  clean testing loss: 0.0690784603357315
epoch 36500  training loss: 0.032253555953502655
epoch 36500  clean testing loss: 0.06963550299406052
epoch 36600  training loss: 0.032522592693567276

 37%|█████████████████████████████▋                                                  | 37090/100000 [03:16<05:02, 207.98it/s]
epoch 36700  training loss: 0.03219706192612648
epoch 36700  clean testing loss: 0.0699659138917923
epoch 36800  training loss: 0.03206552565097809
epoch 36800  clean testing loss: 0.06969156116247177
epoch 36900  training loss: 0.032389603555202484
epoch 36900  clean testing loss: 0.07073433697223663
epoch 37000  training loss: 0.03199438750743866
epoch 37000  clean testing loss: 0.06963621079921722

 38%|██████████████████████████████                                                  | 37502/100000 [03:18<05:04, 205.05it/s]
epoch 37100  training loss: 0.03230153024196625
epoch 37100  clean testing loss: 0.06976956874132156
epoch 37200  training loss: 0.032241158187389374
epoch 37200  clean testing loss: 0.06975220143795013
epoch 37300  training loss: 0.03186728432774544
epoch 37300  clean testing loss: 0.07040990889072418
epoch 37400  training loss: 0.03182774782180786

 38%|██████████████████████████████▎                                                 | 37915/100000 [03:20<05:04, 203.70it/s]
epoch 37500  training loss: 0.031814686954021454
epoch 37500  clean testing loss: 0.070452019572258
epoch 37600  training loss: 0.03182920813560486
epoch 37600  clean testing loss: 0.07067029923200607
epoch 37700  training loss: 0.031634990125894547
epoch 37700  clean testing loss: 0.0705493912100792
epoch 37800  training loss: 0.03153932839632034

 38%|██████████████████████████████▋                                                 | 38328/100000 [03:22<04:59, 205.84it/s]
epoch 37900  training loss: 0.031511638313531876
epoch 37900  clean testing loss: 0.07027978450059891
epoch 38000  training loss: 0.03143564611673355
epoch 38000  clean testing loss: 0.07069501280784607
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 38100  training loss: 0.03178153559565544
epoch 38100  clean testing loss: 0.07064642757177353
epoch 38200  training loss: 0.03203178569674492
epoch 38200  clean testing loss: 0.07104369252920151
epoch 38300  training loss: 0.03132406994700432

 39%|██████████████████████████████▉                                                 | 38741/100000 [03:24<04:53, 208.52it/s]
epoch 38400  training loss: 0.03125891461968422
epoch 38400  clean testing loss: 0.07121007889509201
epoch 38500  training loss: 0.0314524881541729
epoch 38500  clean testing loss: 0.07170947641134262
epoch 38600  training loss: 0.031157979741692543
epoch 38600  clean testing loss: 0.07153265178203583
epoch 38700  training loss: 0.031175393611192703

 39%|███████████████████████████████▎                                                | 39154/100000 [03:26<04:51, 208.62it/s]
epoch 38800  training loss: 0.03131876140832901
epoch 38800  clean testing loss: 0.07159972190856934
epoch 38900  training loss: 0.031073259189724922
epoch 38900  clean testing loss: 0.0711393877863884
epoch 39000  training loss: 0.03098408319056034
epoch 39000  clean testing loss: 0.0716780349612236
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 39100  training loss: 0.030896000564098358

 40%|███████████████████████████████▋                                                | 39565/100000 [03:28<04:57, 202.89it/s]
epoch 39200  training loss: 0.030872412025928497
epoch 39200  clean testing loss: 0.07179673761129379
epoch 39300  training loss: 0.030845168977975845
epoch 39300  clean testing loss: 0.07199349999427795
epoch 39400  training loss: 0.030781066045165062
epoch 39400  clean testing loss: 0.07223644107580185
epoch 39500  training loss: 0.03081631101667881

 40%|███████████████████████████████▉                                                | 39978/100000 [03:30<04:54, 203.98it/s]
epoch 39600  training loss: 0.03096415475010872
epoch 39600  clean testing loss: 0.07272558659315109
epoch 39700  training loss: 0.030789509415626526
epoch 39700  clean testing loss: 0.07280146330595016
epoch 39800  training loss: 0.030766233801841736
epoch 39800  clean testing loss: 0.07218614220619202
epoch 39900  training loss: 0.03065640851855278

 40%|████████████████████████████████▎                                               | 40392/100000 [03:32<04:50, 205.54it/s]
epoch 40000  training loss: 0.030550969764590263
epoch 40000  clean testing loss: 0.0721319392323494
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 40100  training loss: 0.03058793395757675
epoch 40100  clean testing loss: 0.07289297878742218
epoch 40200  training loss: 0.030630065128207207
epoch 40200  clean testing loss: 0.07308531552553177
epoch 40300  training loss: 0.030355095863342285

 41%|████████████████████████████████▋                                               | 40805/100000 [03:34<04:44, 208.40it/s]
epoch 40400  training loss: 0.030447760596871376
epoch 40400  clean testing loss: 0.07277148216962814
epoch 40500  training loss: 0.030378075316548347
epoch 40500  clean testing loss: 0.0726822093129158
epoch 40600  training loss: 0.03031105175614357
epoch 40600  clean testing loss: 0.0729595199227333
epoch 40700  training loss: 0.030677029862999916

 41%|████████████████████████████████▉                                               | 41218/100000 [03:36<04:41, 208.50it/s]
epoch 40800  training loss: 0.030262088403105736
epoch 40800  clean testing loss: 0.07284073531627655
epoch 40900  training loss: 0.03023211844265461
epoch 40900  clean testing loss: 0.073157899081707
epoch 41000  training loss: 0.030354950577020645
epoch 41000  clean testing loss: 0.07361319661140442
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 41100  training loss: 0.030110586434602737

 42%|█████████████████████████████████▏                                              | 41520/100000 [03:37<04:49, 201.68it/s]
epoch 41200  training loss: 0.03010241873562336
epoch 41200  clean testing loss: 0.07309035211801529
epoch 41300  training loss: 0.02998499944806099
epoch 41300  clean testing loss: 0.07341690361499786
epoch 41400  training loss: 0.030234580859541893
epoch 41400  clean testing loss: 0.07372549176216125
epoch 41500  training loss: 0.030065443366765976

 42%|█████████████████████████████████▌                                              | 41933/100000 [03:39<04:43, 204.51it/s]
epoch 41600  training loss: 0.029852695763111115
epoch 41600  clean testing loss: 0.0735359862446785
epoch 41700  training loss: 0.02982211485505104
epoch 41700  clean testing loss: 0.07394909113645554
epoch 41800  training loss: 0.029816487804055214
epoch 41800  clean testing loss: 0.07348375022411346
epoch 41900  training loss: 0.02997257001698017
epoch 41900  clean testing loss: 0.07441199570894241
epoch 42000  training loss: 0.02989097312092781
epoch 42000  clean testing loss: 0.07356680929660797

 42%|█████████████████████████████████▉                                              | 42345/100000 [03:41<04:39, 206.06it/s]
epoch 42100  training loss: 0.029669025912880898
epoch 42100  clean testing loss: 0.07401864230632782
epoch 42200  training loss: 0.029629504308104515
epoch 42200  clean testing loss: 0.07391166687011719
epoch 42300  training loss: 0.029649797827005386
epoch 42300  clean testing loss: 0.07423343509435654
epoch 42400  training loss: 0.029648475348949432

 43%|██████████████████████████████████▏                                             | 42758/100000 [03:43<04:36, 207.28it/s]
epoch 42500  training loss: 0.029631424695253372
epoch 42500  clean testing loss: 0.07442174106836319
epoch 42600  training loss: 0.02951633930206299
epoch 42600  clean testing loss: 0.07430154085159302
epoch 42700  training loss: 0.029471365734934807
epoch 42700  clean testing loss: 0.07442457973957062
epoch 42800  training loss: 0.029456879943609238

 43%|██████████████████████████████████▌                                             | 43169/100000 [03:45<04:32, 208.18it/s]
epoch 42900  training loss: 0.02954888343811035
epoch 42900  clean testing loss: 0.07479173690080643
epoch 43000  training loss: 0.029441632330417633
epoch 43000  clean testing loss: 0.07406870275735855
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 43100  training loss: 0.02935120277106762
epoch 43100  clean testing loss: 0.07456672191619873
epoch 43200  training loss: 0.02996639721095562

 44%|██████████████████████████████████▊                                             | 43581/100000 [03:47<04:38, 202.75it/s]
epoch 43300  training loss: 0.029324812814593315
epoch 43300  clean testing loss: 0.07465953379869461
epoch 43400  training loss: 0.02926749736070633
epoch 43400  clean testing loss: 0.07464076578617096
epoch 43500  training loss: 0.02920718491077423
epoch 43500  clean testing loss: 0.07452574372291565
epoch 43600  training loss: 0.029347149655222893

 44%|███████████████████████████████████▏                                            | 43995/100000 [03:49<04:33, 204.73it/s]
epoch 43700  training loss: 0.029163779690861702
epoch 43700  clean testing loss: 0.07500316947698593
epoch 43800  training loss: 0.029127269983291626
epoch 43800  clean testing loss: 0.07508929818868637
epoch 43900  training loss: 0.029072606936097145
epoch 43900  clean testing loss: 0.07505687326192856
epoch 44000  training loss: 0.029044250026345253
epoch 44000  clean testing loss: 0.07507528364658356

 44%|███████████████████████████████████▌                                            | 44407/100000 [03:51<04:28, 207.31it/s]
epoch 44100  training loss: 0.02904629334807396
epoch 44100  clean testing loss: 0.07475029677152634
epoch 44200  training loss: 0.029168909415602684
epoch 44200  clean testing loss: 0.07560429722070694
epoch 44300  training loss: 0.02896888367831707
epoch 44300  clean testing loss: 0.07525614649057388
epoch 44400  training loss: 0.029121961444616318

 45%|███████████████████████████████████▊                                            | 44821/100000 [03:53<04:25, 208.11it/s]
epoch 44500  training loss: 0.028910420835018158
epoch 44500  clean testing loss: 0.07521890848875046
epoch 44600  training loss: 0.028896890580654144
epoch 44600  clean testing loss: 0.0750652626156807
epoch 44700  training loss: 0.029045792296528816
epoch 44700  clean testing loss: 0.0752195343375206
epoch 44800  training loss: 0.028876401484012604

 45%|████████████████████████████████████▏                                           | 45232/100000 [03:55<04:25, 206.14it/s]
epoch 44900  training loss: 0.02879958786070347
epoch 44900  clean testing loss: 0.07530707865953445
epoch 45000  training loss: 0.02876370958983898
epoch 45000  clean testing loss: 0.07584580034017563
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 45100  training loss: 0.028684787452220917
epoch 45100  clean testing loss: 0.07558920979499817
epoch 45200  training loss: 0.028680315241217613
epoch 45200  clean testing loss: 0.07552357017993927
epoch 45300  training loss: 0.028659189119935036

 46%|████████████████████████████████████▌                                           | 45645/100000 [03:57<04:27, 203.38it/s]
epoch 45400  training loss: 0.028641317039728165
epoch 45400  clean testing loss: 0.07569944858551025
epoch 45500  training loss: 0.02858436107635498
epoch 45500  clean testing loss: 0.07581230252981186
epoch 45600  training loss: 0.028589559718966484
epoch 45600  clean testing loss: 0.07564862072467804
epoch 45700  training loss: 0.028535062447190285

 46%|████████████████████████████████████▊                                           | 46060/100000 [03:59<04:25, 203.05it/s]
epoch 45800  training loss: 0.02867916226387024
epoch 45800  clean testing loss: 0.07589958608150482
epoch 45900  training loss: 0.02847985550761223
epoch 45900  clean testing loss: 0.07587996125221252
epoch 46000  training loss: 0.02844719961285591
epoch 46000  clean testing loss: 0.0760694146156311
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 46100  training loss: 0.02862006612122059

 46%|█████████████████████████████████████▏                                          | 46475/100000 [04:01<04:20, 205.11it/s]
epoch 46200  training loss: 0.02856755442917347
epoch 46200  clean testing loss: 0.07581663876771927
epoch 46300  training loss: 0.028402600437402725
epoch 46300  clean testing loss: 0.07637280970811844
epoch 46400  training loss: 0.02840683050453663
epoch 46400  clean testing loss: 0.07611409574747086
epoch 46500  training loss: 0.028496313840150833

 47%|█████████████████████████████████████▌                                          | 46888/100000 [04:03<04:16, 206.75it/s]
epoch 46600  training loss: 0.028312038630247116
epoch 46600  clean testing loss: 0.07624121010303497
epoch 46700  training loss: 0.028305253013968468
epoch 46700  clean testing loss: 0.07647435367107391
epoch 46800  training loss: 0.028243133798241615
epoch 46800  clean testing loss: 0.07631680369377136
epoch 46900  training loss: 0.028278280049562454

 47%|█████████████████████████████████████▊                                          | 47301/100000 [04:05<04:13, 208.23it/s]
epoch 47000  training loss: 0.028352990746498108
epoch 47000  clean testing loss: 0.07633455097675323
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 47100  training loss: 0.028160840272903442
epoch 47100  clean testing loss: 0.07649959623813629
epoch 47200  training loss: 0.028301136568188667
epoch 47200  clean testing loss: 0.07653442025184631
epoch 47300  training loss: 0.028147565200924873

 48%|██████████████████████████████████████▏                                         | 47714/100000 [04:07<04:10, 208.93it/s]
epoch 47400  training loss: 0.028335915878415108
epoch 47400  clean testing loss: 0.07644035667181015
epoch 47500  training loss: 0.02804526500403881
epoch 47500  clean testing loss: 0.07662643492221832
epoch 47600  training loss: 0.02811000496149063
epoch 47600  clean testing loss: 0.07668758183717728
epoch 47700  training loss: 0.02825302630662918

 48%|██████████████████████████████████████▌                                         | 48126/100000 [04:09<04:15, 203.02it/s]
epoch 47800  training loss: 0.027942750602960587
epoch 47800  clean testing loss: 0.0767151489853859
epoch 47900  training loss: 0.027930043637752533
epoch 47900  clean testing loss: 0.07704602926969528
epoch 48000  training loss: 0.028033258393406868
epoch 48000  clean testing loss: 0.07686556130647659
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 48100  training loss: 0.027883652597665787

 49%|██████████████████████████████████████▊                                         | 48563/100000 [04:11<04:05, 209.84it/s]
epoch 48200  training loss: 0.027846790850162506
epoch 48200  clean testing loss: 0.07689398527145386
epoch 48300  training loss: 0.027829226106405258
epoch 48300  clean testing loss: 0.07674131542444229
epoch 48400  training loss: 0.027833258733153343
epoch 48400  clean testing loss: 0.0766940787434578
epoch 48500  training loss: 0.02777395211160183
epoch 48500  clean testing loss: 0.07700487971305847
epoch 48600  training loss: 0.027724379673600197

 49%|███████████████████████████████████████▏                                        | 48957/100000 [04:13<04:07, 206.41it/s]
epoch 48700  training loss: 0.02781590446829796
epoch 48700  clean testing loss: 0.077300064265728
epoch 48800  training loss: 0.02784191630780697
epoch 48800  clean testing loss: 0.0775163471698761
epoch 48900  training loss: 0.027751123532652855
epoch 48900  clean testing loss: 0.07765945792198181
epoch 49000  training loss: 0.02771434374153614
epoch 49000  clean testing loss: 0.07760884612798691

 49%|███████████████████████████████████████▍                                        | 49369/100000 [04:15<04:03, 208.27it/s]
epoch 49100  training loss: 0.02759326621890068
epoch 49100  clean testing loss: 0.07732167094945908
epoch 49200  training loss: 0.027694428339600563
epoch 49200  clean testing loss: 0.07723355293273926
epoch 49300  training loss: 0.027606550604104996
epoch 49300  clean testing loss: 0.07740428298711777
epoch 49400  training loss: 0.02758902497589588

 50%|███████████████████████████████████████▊                                        | 49783/100000 [04:17<04:00, 208.72it/s]
epoch 49500  training loss: 0.027479669079184532
epoch 49500  clean testing loss: 0.07742837071418762
epoch 49600  training loss: 0.027632130309939384
epoch 49600  clean testing loss: 0.07789264619350433
epoch 49700  training loss: 0.02747296169400215
epoch 49700  clean testing loss: 0.07787594944238663
epoch 49800  training loss: 0.027451423928141594

 50%|████████████████████████████████████████▏                                       | 50216/100000 [04:19<03:58, 208.95it/s]
epoch 49900  training loss: 0.027493447065353394
epoch 49900  clean testing loss: 0.07792778313159943
epoch 50000  training loss: 0.027355359867215157
epoch 50000  clean testing loss: 0.07768232375383377
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 50100  training loss: 0.027334751561284065
epoch 50100  clean testing loss: 0.07774553447961807
epoch 50200  training loss: 0.02748987264931202

 51%|████████████████████████████████████████▌                                       | 50631/100000 [04:21<03:56, 208.81it/s]
epoch 50300  training loss: 0.0274277925491333
epoch 50300  clean testing loss: 0.07797018438577652
epoch 50400  training loss: 0.027275411412119865
epoch 50400  clean testing loss: 0.07806622982025146
epoch 50500  training loss: 0.02723062038421631
epoch 50500  clean testing loss: 0.07789598405361176
epoch 50600  training loss: 0.02734396420419216

 51%|████████████████████████████████████████▊                                       | 51043/100000 [04:23<03:58, 205.58it/s]
epoch 50700  training loss: 0.027228690683841705
epoch 50700  clean testing loss: 0.07819023728370667
epoch 50800  training loss: 0.027193937450647354
epoch 50800  clean testing loss: 0.07804570347070694
epoch 50900  training loss: 0.02714156173169613
epoch 50900  clean testing loss: 0.0783347636461258
epoch 51000  training loss: 0.027139130979776382
epoch 51000  clean testing loss: 0.07828325033187866

 51%|█████████████████████████████████████████▏                                      | 51457/100000 [04:25<03:58, 203.57it/s]
epoch 51100  training loss: 0.0270902831107378
epoch 51100  clean testing loss: 0.07819032669067383
epoch 51200  training loss: 0.027073530480265617
epoch 51200  clean testing loss: 0.07833839952945709
epoch 51300  training loss: 0.027051683515310287
epoch 51300  clean testing loss: 0.07838696986436844
epoch 51400  training loss: 0.027035364881157875
epoch 51400  clean testing loss: 0.07836554199457169
epoch 51500  training loss: 0.027075722813606262

 52%|█████████████████████████████████████████▍                                      | 51872/100000 [04:27<03:54, 205.46it/s]
epoch 51600  training loss: 0.026991959661245346
epoch 51600  clean testing loss: 0.07857498526573181
epoch 51700  training loss: 0.027124539017677307
epoch 51700  clean testing loss: 0.07900894433259964
epoch 51800  training loss: 0.027050279080867767
epoch 51800  clean testing loss: 0.07850033789873123
epoch 51900  training loss: 0.02694006823003292

 52%|█████████████████████████████████████████▊                                      | 52286/100000 [04:29<03:50, 207.31it/s]
epoch 52000  training loss: 0.026895027607679367
epoch 52000  clean testing loss: 0.07880637794733047
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 52100  training loss: 0.02689088135957718
epoch 52100  clean testing loss: 0.07874558120965958
epoch 52200  training loss: 0.02688603289425373
epoch 52200  clean testing loss: 0.07876554876565933
epoch 52300  training loss: 0.026985006406903267

 53%|██████████████████████████████████████████▏                                     | 52699/100000 [04:31<03:47, 208.16it/s]
epoch 52400  training loss: 0.026861675083637238
epoch 52400  clean testing loss: 0.07876668125391006
epoch 52500  training loss: 0.026827415451407433
epoch 52500  clean testing loss: 0.0790436640381813
epoch 52600  training loss: 0.026778334751725197
epoch 52600  clean testing loss: 0.07892739027738571
epoch 52700  training loss: 0.026777436956763268

 53%|██████████████████████████████████████████▍                                     | 53113/100000 [04:33<03:44, 208.94it/s]
epoch 52800  training loss: 0.02675876021385193
epoch 52800  clean testing loss: 0.07900894433259964
epoch 52900  training loss: 0.02672566846013069
epoch 52900  clean testing loss: 0.07921162992715836
epoch 53000  training loss: 0.026835288852453232
epoch 53000  clean testing loss: 0.07960791140794754
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 53100  training loss: 0.02668374963104725

 54%|██████████████████████████████████████████▊                                     | 53525/100000 [04:35<03:49, 202.62it/s]
epoch 53200  training loss: 0.02672969549894333
epoch 53200  clean testing loss: 0.07901093363761902
epoch 53300  training loss: 0.02664620243012905
epoch 53300  clean testing loss: 0.0791696086525917
epoch 53400  training loss: 0.026649968698620796
epoch 53400  clean testing loss: 0.0791807621717453
epoch 53500  training loss: 0.02663283795118332

 54%|███████████████████████████████████████████▏                                    | 53940/100000 [04:37<03:44, 205.07it/s]
epoch 53600  training loss: 0.026737354695796967
epoch 53600  clean testing loss: 0.07983385026454926
epoch 53700  training loss: 0.02663038671016693
epoch 53700  clean testing loss: 0.07963046431541443
epoch 53800  training loss: 0.02662271074950695
epoch 53800  clean testing loss: 0.07935791462659836
epoch 53900  training loss: 0.026601100340485573

 54%|███████████████████████████████████████████▍                                    | 54354/100000 [04:39<03:41, 206.38it/s]
epoch 54000  training loss: 0.026505926623940468
epoch 54000  clean testing loss: 0.0795440748333931
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 54100  training loss: 0.026475731283426285
epoch 54100  clean testing loss: 0.07968628406524658
epoch 54200  training loss: 0.026455888524651527
epoch 54200  clean testing loss: 0.07961244881153107
epoch 54300  training loss: 0.02643788978457451

 55%|███████████████████████████████████████████▊                                    | 54768/100000 [04:41<03:35, 209.49it/s]
epoch 54400  training loss: 0.026469560340046883
epoch 54400  clean testing loss: 0.07965853065252304
epoch 54500  training loss: 0.02643064223229885
epoch 54500  clean testing loss: 0.07980810105800629
epoch 54600  training loss: 0.02644103392958641
epoch 54600  clean testing loss: 0.07982301712036133
epoch 54700  training loss: 0.02644362486898899
epoch 54700  clean testing loss: 0.07961098849773407
epoch 54800  training loss: 0.026350950822234154

 55%|████████████████████████████████████████████▏                                   | 55181/100000 [04:43<03:35, 208.34it/s]
epoch 54900  training loss: 0.0263641607016325
epoch 54900  clean testing loss: 0.07978060096502304
epoch 55000  training loss: 0.026385778561234474
epoch 55000  clean testing loss: 0.08003299683332443
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 55100  training loss: 0.026324249804019928
epoch 55100  clean testing loss: 0.07977759093046188
epoch 55200  training loss: 0.026288745924830437

 56%|████████████████████████████████████████████▍                                   | 55594/100000 [04:45<03:34, 206.92it/s]
epoch 55300  training loss: 0.02627287432551384
epoch 55300  clean testing loss: 0.07989755272865295
epoch 55400  training loss: 0.02629854343831539
epoch 55400  clean testing loss: 0.08005902916193008
epoch 55500  training loss: 0.026279877871274948
epoch 55500  clean testing loss: 0.08023029565811157
epoch 55600  training loss: 0.026225728914141655

 56%|████████████████████████████████████████████▊                                   | 56008/100000 [04:47<03:33, 206.04it/s]
epoch 55700  training loss: 0.02631179243326187
epoch 55700  clean testing loss: 0.08041822910308838
epoch 55800  training loss: 0.026180069893598557
epoch 55800  clean testing loss: 0.08014978468418121
epoch 55900  training loss: 0.02619240991771221
epoch 55900  clean testing loss: 0.08013512194156647
epoch 56000  training loss: 0.026143647730350494
epoch 56000  clean testing loss: 0.0801273062825203

 56%|█████████████████████████████████████████████▏                                  | 56426/100000 [04:49<03:34, 202.70it/s]
epoch 56100  training loss: 0.026150478050112724
epoch 56100  clean testing loss: 0.08021721988916397
epoch 56200  training loss: 0.026103666052222252
epoch 56200  clean testing loss: 0.08044491708278656
epoch 56300  training loss: 0.02613091841340065
epoch 56300  clean testing loss: 0.08011224865913391
epoch 56400  training loss: 0.026134861633181572

 57%|█████████████████████████████████████████████▍                                  | 56840/100000 [04:51<03:30, 205.04it/s]
epoch 56500  training loss: 0.026057977229356766
epoch 56500  clean testing loss: 0.08025955408811569
epoch 56600  training loss: 0.02608843334019184
epoch 56600  clean testing loss: 0.08020856231451035
epoch 56700  training loss: 0.026081357151269913
epoch 56700  clean testing loss: 0.08030284196138382
epoch 56800  training loss: 0.0260830819606781

 57%|█████████████████████████████████████████████▊                                  | 57252/100000 [04:53<03:27, 206.04it/s]
epoch 56900  training loss: 0.026076262816786766
epoch 56900  clean testing loss: 0.08077945560216904
epoch 57000  training loss: 0.02604750171303749
epoch 57000  clean testing loss: 0.08040878176689148
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 57100  training loss: 0.025958549231290817
epoch 57100  clean testing loss: 0.08043649792671204
epoch 57200  training loss: 0.025964077562093735

 58%|██████████████████████████████████████████████▏                                 | 57667/100000 [04:55<03:22, 209.24it/s]
epoch 57300  training loss: 0.0259193517267704
epoch 57300  clean testing loss: 0.08049767464399338
epoch 57400  training loss: 0.025924691930413246
epoch 57400  clean testing loss: 0.08073471486568451
epoch 57500  training loss: 0.025922609493136406
epoch 57500  clean testing loss: 0.08064445853233337
epoch 57600  training loss: 0.025899358093738556
epoch 57600  clean testing loss: 0.08065182715654373
epoch 57700  training loss: 0.02586549147963524

 58%|██████████████████████████████████████████████▍                                 | 58081/100000 [04:57<03:21, 207.97it/s]
epoch 57800  training loss: 0.025852147489786148
epoch 57800  clean testing loss: 0.08081847429275513
epoch 57900  training loss: 0.025892408564686775
epoch 57900  clean testing loss: 0.08086853474378586
epoch 58000  training loss: 0.02584949880838394
epoch 58000  clean testing loss: 0.08078261464834213
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 58100  training loss: 0.025830045342445374

 58%|██████████████████████████████████████████████▊                                 | 58494/100000 [04:59<03:20, 207.10it/s]
epoch 58200  training loss: 0.02581297792494297
epoch 58200  clean testing loss: 0.08093057572841644
epoch 58300  training loss: 0.025768570601940155
epoch 58300  clean testing loss: 0.08098199963569641
epoch 58400  training loss: 0.02576020546257496
epoch 58400  clean testing loss: 0.08068796247243881
epoch 58500  training loss: 0.025751419365406036

 59%|███████████████████████████████████████████████▏                                | 58908/100000 [05:01<03:21, 203.65it/s]
epoch 58600  training loss: 0.025762265548110008
epoch 58600  clean testing loss: 0.08106900751590729
epoch 58700  training loss: 0.02576407417654991
epoch 58700  clean testing loss: 0.08113683015108109
epoch 58800  training loss: 0.025696195662021637
epoch 58800  clean testing loss: 0.08095119148492813
epoch 58900  training loss: 0.025717491284012794

 59%|███████████████████████████████████████████████▍                                | 59322/100000 [05:03<03:17, 205.93it/s]
epoch 59000  training loss: 0.025711553171277046
epoch 59000  clean testing loss: 0.08097074925899506
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 59100  training loss: 0.025701476261019707
epoch 59100  clean testing loss: 0.0811915472149849
epoch 59200  training loss: 0.025636091828346252
epoch 59200  clean testing loss: 0.08104372024536133
epoch 59300  training loss: 0.025633519515395164

 60%|███████████████████████████████████████████████▊                                | 59738/100000 [05:06<03:14, 206.54it/s]
epoch 59400  training loss: 0.025693368166685104
epoch 59400  clean testing loss: 0.08074068278074265
epoch 59500  training loss: 0.025621308013796806
epoch 59500  clean testing loss: 0.08098354190587997
epoch 59600  training loss: 0.02559356763958931
epoch 59600  clean testing loss: 0.08112822473049164
epoch 59700  training loss: 0.025636015459895134

 60%|████████████████████████████████████████████████                                | 60153/100000 [05:08<03:11, 208.43it/s]
epoch 59800  training loss: 0.025578059256076813
epoch 59800  clean testing loss: 0.08115753531455994
epoch 59900  training loss: 0.025546498596668243
epoch 59900  clean testing loss: 0.08126135915517807
epoch 60000  training loss: 0.025539306923747063
epoch 60000  clean testing loss: 0.0811542272567749
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 60100  training loss: 0.02550790086388588

 61%|████████████████████████████████████████████████▍                               | 60567/100000 [05:10<03:08, 209.64it/s]
epoch 60200  training loss: 0.02550327405333519
epoch 60200  clean testing loss: 0.08128848671913147
epoch 60300  training loss: 0.025482194498181343
epoch 60300  clean testing loss: 0.08124297112226486
epoch 60400  training loss: 0.025475868955254555
epoch 60400  clean testing loss: 0.08120670914649963
epoch 60500  training loss: 0.02545962668955326
epoch 60500  clean testing loss: 0.08138685673475266
epoch 60600  training loss: 0.025462644174695015

 61%|████████████████████████████████████████████████▊                               | 60980/100000 [05:12<03:11, 203.41it/s]
epoch 60700  training loss: 0.02544255182147026
epoch 60700  clean testing loss: 0.08140675723552704
epoch 60800  training loss: 0.025435680523514748
epoch 60800  clean testing loss: 0.08132424205541611
epoch 60900  training loss: 0.025424068793654442
epoch 60900  clean testing loss: 0.08146640658378601
epoch 61000  training loss: 0.02538992278277874
epoch 61000  clean testing loss: 0.08146081864833832

 61%|█████████████████████████████████████████████████                               | 61394/100000 [05:14<03:09, 204.18it/s]
epoch 61100  training loss: 0.025384539738297462
epoch 61100  clean testing loss: 0.08147616684436798
epoch 61200  training loss: 0.025376038625836372
epoch 61200  clean testing loss: 0.08156930655241013
epoch 61300  training loss: 0.025386827066540718
epoch 61300  clean testing loss: 0.08154957741498947
epoch 61400  training loss: 0.025364762172102928

 62%|█████████████████████████████████████████████████▍                              | 61809/100000 [05:16<03:05, 205.92it/s]
epoch 61500  training loss: 0.025331325829029083
epoch 61500  clean testing loss: 0.08151325583457947
epoch 61600  training loss: 0.025313420221209526
epoch 61600  clean testing loss: 0.08156679570674896
epoch 61700  training loss: 0.02534494921565056
epoch 61700  clean testing loss: 0.08154240250587463
epoch 61800  training loss: 0.025295525789260864

 62%|█████████████████████████████████████████████████▊                              | 62221/100000 [05:18<03:01, 208.63it/s]
epoch 61900  training loss: 0.025279037654399872
epoch 61900  clean testing loss: 0.08175473660230637
epoch 62000  training loss: 0.02529277093708515
epoch 62000  clean testing loss: 0.08171601593494415
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 62100  training loss: 0.025262966752052307
epoch 62100  clean testing loss: 0.08186446875333786
epoch 62200  training loss: 0.02527243085205555

 63%|██████████████████████████████████████████████████                              | 62636/100000 [05:20<02:58, 209.11it/s]
epoch 62300  training loss: 0.025220539420843124
epoch 62300  clean testing loss: 0.0816696360707283
epoch 62400  training loss: 0.02523758076131344
epoch 62400  clean testing loss: 0.08169817179441452
epoch 62500  training loss: 0.025193223729729652
epoch 62500  clean testing loss: 0.08196113258600235
epoch 62600  training loss: 0.025191091001033783

 63%|██████████████████████████████████████████████████▍                             | 63069/100000 [05:22<02:58, 207.21it/s]
epoch 62700  training loss: 0.02516944706439972
epoch 62700  clean testing loss: 0.08191371709108353
epoch 62800  training loss: 0.02515583299100399
epoch 62800  clean testing loss: 0.08204144984483719
epoch 62900  training loss: 0.02514878660440445
epoch 62900  clean testing loss: 0.08211614191532135
epoch 63000  training loss: 0.025132127106189728
epoch 63000  clean testing loss: 0.08200455456972122

 63%|██████████████████████████████████████████████████▊                             | 63484/100000 [05:24<02:54, 208.68it/s]
epoch 63100  training loss: 0.025118688121438026
epoch 63100  clean testing loss: 0.08199168741703033
epoch 63200  training loss: 0.025104766711592674
epoch 63200  clean testing loss: 0.08197671920061111
epoch 63300  training loss: 0.025091372430324554
epoch 63300  clean testing loss: 0.08216215670108795
epoch 63400  training loss: 0.02509024180471897
epoch 63400  clean testing loss: 0.08201993256807327
epoch 63500  training loss: 0.025085018947720528

 64%|███████████████████████████████████████████████████                             | 63899/100000 [05:26<02:51, 210.10it/s]
epoch 63600  training loss: 0.025073712691664696
epoch 63600  clean testing loss: 0.08217483013868332
epoch 63700  training loss: 0.025058843195438385
epoch 63700  clean testing loss: 0.08225801587104797
epoch 63800  training loss: 0.02504074200987816
epoch 63800  clean testing loss: 0.08216414600610733
epoch 63900  training loss: 0.025028564035892487

 64%|███████████████████████████████████████████████████▍                            | 64309/100000 [05:28<02:56, 201.98it/s]
epoch 64000  training loss: 0.025033937767148018
epoch 64000  clean testing loss: 0.08232545852661133
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 64100  training loss: 0.02500399574637413
epoch 64100  clean testing loss: 0.08221950381994247
epoch 64200  training loss: 0.024996675550937653
epoch 64200  clean testing loss: 0.08220834285020828
epoch 64300  training loss: 0.024988973513245583

 65%|███████████████████████████████████████████████████▊                            | 64722/100000 [05:30<02:57, 198.41it/s]
epoch 64400  training loss: 0.024993080645799637
epoch 64400  clean testing loss: 0.08227855712175369
epoch 64500  training loss: 0.02499215491116047
epoch 64500  clean testing loss: 0.08231525123119354
epoch 64600  training loss: 0.02496338076889515
epoch 64600  clean testing loss: 0.08254764974117279
epoch 64700  training loss: 0.024939347058534622

 65%|████████████████████████████████████████████████████                            | 65134/100000 [05:32<02:48, 206.71it/s]
epoch 64800  training loss: 0.024942463263869286
epoch 64800  clean testing loss: 0.08249491453170776
epoch 64900  training loss: 0.024942545220255852
epoch 64900  clean testing loss: 0.08255057781934738
epoch 65000  training loss: 0.024903293699026108
epoch 65000  clean testing loss: 0.08243492245674133
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 65100  training loss: 0.02489754930138588

 66%|████████████████████████████████████████████████████▍                           | 65550/100000 [05:34<02:44, 209.38it/s]
epoch 65200  training loss: 0.024888070300221443
epoch 65200  clean testing loss: 0.08248161524534225
epoch 65300  training loss: 0.024877404794096947
epoch 65300  clean testing loss: 0.08268273621797562
epoch 65400  training loss: 0.024869265034794807
epoch 65400  clean testing loss: 0.08253133296966553
epoch 65500  training loss: 0.02486184425652027

 66%|████████████████████████████████████████████████████▊                           | 65965/100000 [05:36<02:42, 209.82it/s]
epoch 65600  training loss: 0.024834569543600082
epoch 65600  clean testing loss: 0.0825687125325203
epoch 65700  training loss: 0.02485787309706211
epoch 65700  clean testing loss: 0.08261235803365707
epoch 65800  training loss: 0.024837849661707878
epoch 65800  clean testing loss: 0.08270629495382309
epoch 65900  training loss: 0.024843478575348854

 66%|█████████████████████████████████████████████████████                           | 66386/100000 [05:38<02:41, 208.61it/s]
epoch 66000  training loss: 0.024805953726172447
epoch 66000  clean testing loss: 0.0826236754655838
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 66100  training loss: 0.024780692532658577
epoch 66100  clean testing loss: 0.08266156911849976
epoch 66200  training loss: 0.024770772084593773
epoch 66200  clean testing loss: 0.08258933573961258
epoch 66300  training loss: 0.02477000094950199
epoch 66300  clean testing loss: 0.08255220204591751
epoch 66400  training loss: 0.024753987789154053

 67%|█████████████████████████████████████████████████████▍                          | 66801/100000 [05:40<02:38, 209.30it/s]
epoch 66500  training loss: 0.024746352806687355
epoch 66500  clean testing loss: 0.08273491263389587
epoch 66600  training loss: 0.0247320719063282
epoch 66600  clean testing loss: 0.08261915296316147
epoch 66700  training loss: 0.024723902344703674
epoch 66700  clean testing loss: 0.08265949785709381
epoch 66800  training loss: 0.02471473440527916

 67%|█████████████████████████████████████████████████████▊                          | 67211/100000 [05:42<02:41, 203.36it/s]
epoch 66900  training loss: 0.024721402674913406
epoch 66900  clean testing loss: 0.08258679509162903
epoch 67000  training loss: 0.024698860943317413
epoch 67000  clean testing loss: 0.08285344392061234
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 67100  training loss: 0.02468717284500599
epoch 67100  clean testing loss: 0.08254090696573257
epoch 67200  training loss: 0.02467603050172329

 68%|██████████████████████████████████████████████████████                          | 67629/100000 [05:44<02:39, 203.39it/s]
epoch 67300  training loss: 0.02466047741472721
epoch 67300  clean testing loss: 0.08277209848165512
epoch 67400  training loss: 0.024661334231495857
epoch 67400  clean testing loss: 0.08274134248495102
epoch 67500  training loss: 0.02464449033141136
epoch 67500  clean testing loss: 0.08287673443555832
epoch 67600  training loss: 0.0246345866471529

 68%|██████████████████████████████████████████████████████▍                         | 68042/100000 [05:46<02:36, 204.12it/s]
epoch 67700  training loss: 0.0246173944324255
epoch 67700  clean testing loss: 0.08288956433534622
epoch 67800  training loss: 0.02461094781756401
epoch 67800  clean testing loss: 0.08288100361824036
epoch 67900  training loss: 0.024594994261860847
epoch 67900  clean testing loss: 0.08295401185750961
epoch 68000  training loss: 0.024595238268375397
epoch 68000  clean testing loss: 0.08290881663560867

 68%|██████████████████████████████████████████████████████▊                         | 68457/100000 [05:48<02:32, 206.70it/s]
epoch 68100  training loss: 0.024573037400841713
epoch 68100  clean testing loss: 0.08293602615594864
epoch 68200  training loss: 0.024568889290094376
epoch 68200  clean testing loss: 0.08300188183784485
epoch 68300  training loss: 0.02455638162791729
epoch 68300  clean testing loss: 0.08300042897462845
epoch 68400  training loss: 0.024556118994951248

 69%|███████████████████████████████████████████████████████                         | 68872/100000 [05:50<02:29, 208.28it/s]
epoch 68500  training loss: 0.024536127224564552
epoch 68500  clean testing loss: 0.08304814994335175
epoch 68600  training loss: 0.024525543674826622
epoch 68600  clean testing loss: 0.08305230736732483
epoch 68700  training loss: 0.02452724613249302
epoch 68700  clean testing loss: 0.08312945812940598
epoch 68800  training loss: 0.02450459636747837

 69%|███████████████████████████████████████████████████████▍                        | 69287/100000 [05:52<02:26, 210.09it/s]
epoch 68900  training loss: 0.024501251056790352
epoch 68900  clean testing loss: 0.08307666331529617
epoch 69000  training loss: 0.024502387270331383
epoch 69000  clean testing loss: 0.08303564041852951
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 69100  training loss: 0.02448032796382904
epoch 69100  clean testing loss: 0.08314622938632965
epoch 69200  training loss: 0.02447168156504631

 70%|███████████████████████████████████████████████████████▊                        | 69700/100000 [05:54<02:28, 204.67it/s]
epoch 69300  training loss: 0.02446199581027031
epoch 69300  clean testing loss: 0.08310144394636154
epoch 69400  training loss: 0.02445780113339424
epoch 69400  clean testing loss: 0.08310986310243607
epoch 69500  training loss: 0.024449806660413742
epoch 69500  clean testing loss: 0.08320480585098267
epoch 69600  training loss: 0.024449052289128304
epoch 69600  clean testing loss: 0.08321208506822586
epoch 69700  training loss: 0.024438174441456795

 70%|████████████████████████████████████████████████████████                        | 70114/100000 [05:56<02:26, 203.98it/s]
epoch 69800  training loss: 0.024430515244603157
epoch 69800  clean testing loss: 0.08330678939819336
epoch 69900  training loss: 0.024416467174887657
epoch 69900  clean testing loss: 0.08323630690574646
epoch 70000  training loss: 0.024404730647802353
epoch 70000  clean testing loss: 0.08324261009693146
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 70100  training loss: 0.02440052479505539

 71%|████████████████████████████████████████████████████████▍                       | 70529/100000 [05:58<02:22, 206.14it/s]
epoch 70200  training loss: 0.024381674826145172
epoch 70200  clean testing loss: 0.08328007161617279
epoch 70300  training loss: 0.024374349042773247
epoch 70300  clean testing loss: 0.08333519101142883
epoch 70400  training loss: 0.024365440011024475
epoch 70400  clean testing loss: 0.0833510309457779
epoch 70500  training loss: 0.024355165660381317

 71%|████████████████████████████████████████████████████████▊                       | 70943/100000 [06:00<02:20, 207.40it/s]
epoch 70600  training loss: 0.024356022477149963
epoch 70600  clean testing loss: 0.08337827771902084
epoch 70700  training loss: 0.024340298026800156
epoch 70700  clean testing loss: 0.08330713212490082
epoch 70800  training loss: 0.0243301410228014
epoch 70800  clean testing loss: 0.0834263488650322
epoch 70900  training loss: 0.024320164695382118

 71%|█████████████████████████████████████████████████████████                       | 71357/100000 [06:02<02:17, 208.51it/s]
epoch 71000  training loss: 0.02431868202984333
epoch 71000  clean testing loss: 0.08352091908454895
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 71100  training loss: 0.024302499368786812
epoch 71100  clean testing loss: 0.08353513479232788
epoch 71200  training loss: 0.024294229224324226
epoch 71200  clean testing loss: 0.08355999737977982
epoch 71300  training loss: 0.02428908832371235

 72%|█████████████████████████████████████████████████████████▍                      | 71770/100000 [06:04<02:14, 209.77it/s]
epoch 71400  training loss: 0.024281684309244156
epoch 71400  clean testing loss: 0.08358704298734665
epoch 71500  training loss: 0.02426549233496189
epoch 71500  clean testing loss: 0.08369877189397812
epoch 71600  training loss: 0.024263210594654083
epoch 71600  clean testing loss: 0.08368056267499924
epoch 71700  training loss: 0.02424715831875801

 72%|█████████████████████████████████████████████████████████▋                      | 72183/100000 [06:06<02:17, 202.72it/s]
epoch 71800  training loss: 0.024261189624667168
epoch 71800  clean testing loss: 0.08365004509687424
epoch 71900  training loss: 0.02423281967639923
epoch 71900  clean testing loss: 0.0837230384349823
epoch 72000  training loss: 0.02423415519297123
epoch 72000  clean testing loss: 0.0838279128074646
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 72100  training loss: 0.024213895201683044

 73%|██████████████████████████████████████████████████████████                      | 72597/100000 [06:08<02:13, 205.44it/s]
epoch 72200  training loss: 0.024202706292271614
epoch 72200  clean testing loss: 0.08385390043258667
epoch 72300  training loss: 0.02419995702803135
epoch 72300  clean testing loss: 0.08375074714422226
epoch 72400  training loss: 0.024190600961446762
epoch 72400  clean testing loss: 0.08384712785482407
epoch 72500  training loss: 0.02418428286910057
epoch 72500  clean testing loss: 0.08378801494836807
epoch 72600  training loss: 0.02417888678610325

 73%|██████████████████████████████████████████████████████████▍                     | 73012/100000 [06:10<02:11, 204.68it/s]
epoch 72700  training loss: 0.02417103946208954
epoch 72700  clean testing loss: 0.08395984768867493
epoch 72800  training loss: 0.0241609588265419
epoch 72800  clean testing loss: 0.08388520032167435
epoch 72900  training loss: 0.02415567822754383
epoch 72900  clean testing loss: 0.08400069177150726
epoch 73000  training loss: 0.024138791486620903
epoch 73000  clean testing loss: 0.0839623510837555

 73%|██████████████████████████████████████████████████████████▋                     | 73427/100000 [06:12<02:07, 208.57it/s]
epoch 73100  training loss: 0.02412930503487587
epoch 73100  clean testing loss: 0.08394943922758102
epoch 73200  training loss: 0.024129312485456467
epoch 73200  clean testing loss: 0.08407044410705566
epoch 73300  training loss: 0.024114035069942474
epoch 73300  clean testing loss: 0.08394580334424973
epoch 73400  training loss: 0.02410457842051983

 74%|███████████████████████████████████████████████████████████                     | 73842/100000 [06:14<02:05, 209.12it/s]
epoch 73500  training loss: 0.024102021008729935
epoch 73500  clean testing loss: 0.08401776105165482
epoch 73600  training loss: 0.02409074455499649
epoch 73600  clean testing loss: 0.08405117690563202
epoch 73700  training loss: 0.02408229187130928
epoch 73700  clean testing loss: 0.08409062027931213
epoch 73800  training loss: 0.024080296978354454

 74%|███████████████████████████████████████████████████████████▍                    | 74256/100000 [06:16<02:01, 211.57it/s]
epoch 73900  training loss: 0.024066384881734848
epoch 73900  clean testing loss: 0.08408325910568237
epoch 74000  training loss: 0.024058910086750984
epoch 74000  clean testing loss: 0.08415164798498154
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 74100  training loss: 0.02405739761888981
epoch 74100  clean testing loss: 0.08412408083677292
epoch 74200  training loss: 0.0240413099527359

 75%|███████████████████████████████████████████████████████████▋                    | 74671/100000 [06:18<02:04, 202.89it/s]
epoch 74300  training loss: 0.02404456026852131
epoch 74300  clean testing loss: 0.08409149199724197
epoch 74400  training loss: 0.02402658574283123
epoch 74400  clean testing loss: 0.08420425653457642
epoch 74500  training loss: 0.02402377873659134
epoch 74500  clean testing loss: 0.0842045471072197
epoch 74600  training loss: 0.024017037823796272

 75%|████████████████████████████████████████████████████████████                    | 75087/100000 [06:20<02:02, 203.86it/s]
epoch 74700  training loss: 0.024006394669413567
epoch 74700  clean testing loss: 0.08424843102693558
epoch 74800  training loss: 0.02399911917746067
epoch 74800  clean testing loss: 0.08427221328020096
epoch 74900  training loss: 0.02399461530148983
epoch 74900  clean testing loss: 0.08424029499292374
epoch 75000  training loss: 0.023980412632226944
epoch 75000  clean testing loss: 0.08425257354974747
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...

epoch 75100  training loss: 0.02397332526743412
epoch 75100  clean testing loss: 0.08426918834447861
epoch 75200  training loss: 0.02396450750529766
epoch 75200  clean testing loss: 0.0843006819486618
epoch 75300  training loss: 0.02396504394710064
epoch 75300  clean testing loss: 0.08429794758558273
epoch 75400  training loss: 0.023959213867783546
epoch 75400  clean testing loss: 0.08421959728002548
epoch 75500  training loss: 0.02395050600171089

 76%|████████████████████████████████████████████████████████████▋                   | 75917/100000 [06:24<01:55, 208.38it/s]
epoch 75600  training loss: 0.02394193224608898
epoch 75600  clean testing loss: 0.08433270454406738
epoch 75700  training loss: 0.023933885619044304
epoch 75700  clean testing loss: 0.08431924134492874
epoch 75800  training loss: 0.02392958104610443
epoch 75800  clean testing loss: 0.08431355655193329
epoch 75900  training loss: 0.023922409862279892

 76%|█████████████████████████████████████████████████████████████                   | 76333/100000 [06:26<01:53, 208.26it/s]
epoch 76000  training loss: 0.023918146267533302
epoch 76000  clean testing loss: 0.0843154788017273
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 76100  training loss: 0.02390546165406704
epoch 76100  clean testing loss: 0.08441358059644699
epoch 76200  training loss: 0.023896710947155952
epoch 76200  clean testing loss: 0.08437846601009369
epoch 76300  training loss: 0.023903051391243935

 77%|█████████████████████████████████████████████████████████████▍                  | 76750/100000 [06:28<01:51, 208.60it/s]
epoch 76400  training loss: 0.023884695023298264
epoch 76400  clean testing loss: 0.08442666381597519
epoch 76500  training loss: 0.02387825958430767
epoch 76500  clean testing loss: 0.08440624177455902
epoch 76600  training loss: 0.02387004904448986
epoch 76600  clean testing loss: 0.08443421125411987
epoch 76700  training loss: 0.02386477403342724

 77%|█████████████████████████████████████████████████████████████▋                  | 77164/100000 [06:30<01:49, 209.26it/s]
epoch 76800  training loss: 0.023861898109316826
epoch 76800  clean testing loss: 0.08440051972866058
epoch 76900  training loss: 0.02384786680340767
epoch 76900  clean testing loss: 0.08445394039154053
epoch 77000  training loss: 0.02384040132164955
epoch 77000  clean testing loss: 0.08448570221662521
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 77100  training loss: 0.023834018036723137

 78%|██████████████████████████████████████████████████████████████                  | 77578/100000 [06:32<01:47, 209.54it/s]
epoch 77200  training loss: 0.023825200274586678
epoch 77200  clean testing loss: 0.084470734000206
epoch 77300  training loss: 0.023820573464035988
epoch 77300  clean testing loss: 0.08450601994991302
epoch 77400  training loss: 0.023812463507056236
epoch 77400  clean testing loss: 0.08451791852712631
epoch 77500  training loss: 0.023809272795915604

 78%|██████████████████████████████████████████████████████████████▍                 | 77991/100000 [06:34<01:48, 203.36it/s]
epoch 77600  training loss: 0.023798592388629913
epoch 77600  clean testing loss: 0.0844762846827507
epoch 77700  training loss: 0.023791683837771416
epoch 77700  clean testing loss: 0.08460025489330292
epoch 77800  training loss: 0.0237949900329113
epoch 77800  clean testing loss: 0.08457063883543015
epoch 77900  training loss: 0.023785607889294624
epoch 77900  clean testing loss: 0.08457314968109131
epoch 78000  training loss: 0.02377268299460411
epoch 78000  clean testing loss: 0.08459929376840591

 78%|██████████████████████████████████████████████████████████████▋                 | 78404/100000 [06:36<01:44, 205.72it/s]
epoch 78100  training loss: 0.02376757562160492
epoch 78100  clean testing loss: 0.08465486764907837
epoch 78200  training loss: 0.02375839278101921
epoch 78200  clean testing loss: 0.0846090316772461
epoch 78300  training loss: 0.023754898458719254
epoch 78300  clean testing loss: 0.08462997525930405
epoch 78400  training loss: 0.02375059761106968

 79%|███████████████████████████████████████████████████████████████                 | 78820/100000 [06:38<01:42, 206.76it/s]
epoch 78500  training loss: 0.02374226041138172
epoch 78500  clean testing loss: 0.08465652167797089
epoch 78600  training loss: 0.023737460374832153
epoch 78600  clean testing loss: 0.08466663211584091
epoch 78700  training loss: 0.023730900138616562
epoch 78700  clean testing loss: 0.08461064845323563
epoch 78800  training loss: 0.023729505017399788

 79%|███████████████████████████████████████████████████████████████▍                | 79254/100000 [06:40<01:40, 205.73it/s]
epoch 78900  training loss: 0.02371816895902157
epoch 78900  clean testing loss: 0.08470036834478378
epoch 79000  training loss: 0.023712366819381714
epoch 79000  clean testing loss: 0.08465249836444855
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 79100  training loss: 0.02370685525238514
epoch 79100  clean testing loss: 0.084689199924469
epoch 79200  training loss: 0.023704856634140015

 80%|███████████████████████████████████████████████████████████████▋                | 79648/100000 [06:42<01:36, 209.83it/s]
epoch 79300  training loss: 0.023692505434155464
epoch 79300  clean testing loss: 0.08464639633893967
epoch 79400  training loss: 0.02368883602321148
epoch 79400  clean testing loss: 0.08473730832338333
epoch 79500  training loss: 0.0236810315400362
epoch 79500  clean testing loss: 0.0847039669752121
epoch 79600  training loss: 0.02367708645761013

 80%|████████████████████████████████████████████████████████████████                | 80082/100000 [06:44<01:35, 208.54it/s]
epoch 79700  training loss: 0.02367030270397663
epoch 79700  clean testing loss: 0.08473756909370422
epoch 79800  training loss: 0.023668985813856125
epoch 79800  clean testing loss: 0.08470073342323303
epoch 79900  training loss: 0.023661702871322632
epoch 79900  clean testing loss: 0.0847502052783966
epoch 80000  training loss: 0.02365264669060707
epoch 80000  clean testing loss: 0.08477465808391571

 80%|████████████████████████████████████████████████████████████████▍               | 80500/100000 [06:46<01:33, 208.38it/s]
epoch 80100  training loss: 0.02364281751215458
epoch 80100  clean testing loss: 0.08470692485570908
epoch 80200  training loss: 0.02364385314285755
epoch 80200  clean testing loss: 0.08467576652765274
epoch 80300  training loss: 0.0236298106610775
epoch 80300  clean testing loss: 0.08477447926998138
epoch 80400  training loss: 0.023626290261745453

 81%|████████████████████████████████████████████████████████████████▋               | 80915/100000 [06:48<01:30, 210.25it/s]
epoch 80500  training loss: 0.023618139326572418
epoch 80500  clean testing loss: 0.08475880324840546
epoch 80600  training loss: 0.023611638695001602
epoch 80600  clean testing loss: 0.08472521603107452
epoch 80700  training loss: 0.023607471957802773
epoch 80700  clean testing loss: 0.08475230634212494
epoch 80800  training loss: 0.023599863052368164
epoch 80800  clean testing loss: 0.08477191627025604
epoch 80900  training loss: 0.023591311648488045

 81%|█████████████████████████████████████████████████████████████████               | 81328/100000 [06:50<01:31, 202.98it/s]
epoch 81000  training loss: 0.02358683943748474
epoch 81000  clean testing loss: 0.08479204028844833
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 81100  training loss: 0.02357766032218933
epoch 81100  clean testing loss: 0.08481276780366898
epoch 81200  training loss: 0.023572485893964767
epoch 81200  clean testing loss: 0.08479020744562149
epoch 81300  training loss: 0.023569732904434204

 82%|█████████████████████████████████████████████████████████████████▍              | 81743/100000 [06:52<01:29, 205.10it/s]
epoch 81400  training loss: 0.023564087226986885
epoch 81400  clean testing loss: 0.08481981605291367
epoch 81500  training loss: 0.023557547479867935
epoch 81500  clean testing loss: 0.0848095640540123
epoch 81600  training loss: 0.023551398888230324
epoch 81600  clean testing loss: 0.08485513925552368
epoch 81700  training loss: 0.023547478020191193

 82%|█████████████████████████████████████████████████████████████████▋              | 82157/100000 [06:54<01:26, 206.54it/s]
epoch 81800  training loss: 0.023542622104287148
epoch 81800  clean testing loss: 0.08483725786209106
epoch 81900  training loss: 0.023534616455435753
epoch 81900  clean testing loss: 0.08487124741077423
epoch 82000  training loss: 0.023530393838882446
epoch 82000  clean testing loss: 0.08489160239696503
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 82100  training loss: 0.023524289950728416

 83%|██████████████████████████████████████████████████████████████████              | 82573/100000 [06:56<01:23, 208.34it/s]
epoch 82200  training loss: 0.023518918082118034
epoch 82200  clean testing loss: 0.08494937419891357
epoch 82300  training loss: 0.023512303829193115
epoch 82300  clean testing loss: 0.08492499589920044
epoch 82400  training loss: 0.02350686304271221
epoch 82400  clean testing loss: 0.08495419472455978
epoch 82500  training loss: 0.023500757291913033

 83%|██████████████████████████████████████████████████████████████████▍             | 82988/100000 [06:58<01:21, 208.85it/s]
epoch 82600  training loss: 0.023496050387620926
epoch 82600  clean testing loss: 0.08493625372648239
epoch 82700  training loss: 0.02349333092570305
epoch 82700  clean testing loss: 0.08498430997133255
epoch 82800  training loss: 0.023484645411372185
epoch 82800  clean testing loss: 0.08500515669584274
epoch 82900  training loss: 0.02348066121339798

 83%|██████████████████████████████████████████████████████████████████▋             | 83403/100000 [07:00<01:18, 210.20it/s]
epoch 83000  training loss: 0.02347303181886673
epoch 83000  clean testing loss: 0.08494593948125839
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 83100  training loss: 0.023469505831599236
epoch 83100  clean testing loss: 0.08500538766384125
epoch 83200  training loss: 0.023463550955057144
epoch 83200  clean testing loss: 0.08503163605928421
epoch 83300  training loss: 0.023460227996110916

 84%|███████████████████████████████████████████████████████████████████             | 83817/100000 [07:02<01:19, 202.71it/s]
epoch 83400  training loss: 0.023451760411262512
epoch 83400  clean testing loss: 0.08504504710435867
epoch 83500  training loss: 0.023446720093488693
epoch 83500  clean testing loss: 0.08506020903587341
epoch 83600  training loss: 0.023444250226020813
epoch 83600  clean testing loss: 0.08499141782522202
epoch 83700  training loss: 0.023440320044755936
epoch 83700  clean testing loss: 0.08500248938798904
epoch 83800  training loss: 0.02343081124126911

 84%|███████████████████████████████████████████████████████████████████▍            | 84233/100000 [07:04<01:17, 204.63it/s]
epoch 83900  training loss: 0.02342676743865013
epoch 83900  clean testing loss: 0.08506185561418533
epoch 84000  training loss: 0.02342245914041996
epoch 84000  clean testing loss: 0.0850750207901001
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 84100  training loss: 0.02341333031654358
epoch 84100  clean testing loss: 0.08504864573478699
epoch 84200  training loss: 0.02341129444539547

 85%|███████████████████████████████████████████████████████████████████▋            | 84649/100000 [07:06<01:14, 206.17it/s]
epoch 84300  training loss: 0.023406198248267174
epoch 84300  clean testing loss: 0.08509910851716995
epoch 84400  training loss: 0.023404469713568687
epoch 84400  clean testing loss: 0.08505627512931824
epoch 84500  training loss: 0.02339574135839939
epoch 84500  clean testing loss: 0.08510764688253403
epoch 84600  training loss: 0.023390894755721092

 85%|████████████████████████████████████████████████████████████████████            | 85064/100000 [07:08<01:12, 205.53it/s]
epoch 84700  training loss: 0.02338695153594017
epoch 84700  clean testing loss: 0.08519014716148376
epoch 84800  training loss: 0.02338292822241783
epoch 84800  clean testing loss: 0.08509636670351028
epoch 84900  training loss: 0.023377565667033195
epoch 84900  clean testing loss: 0.08512624353170395
epoch 85000  training loss: 0.02337128110229969
epoch 85000  clean testing loss: 0.0851278081536293

 85%|████████████████████████████████████████████████████████████████████▎           | 85369/100000 [07:09<01:10, 208.73it/s]
epoch 85100  training loss: 0.02336997725069523
epoch 85100  clean testing loss: 0.08515069633722305
epoch 85200  training loss: 0.023362454026937485
epoch 85200  clean testing loss: 0.08515165746212006
epoch 85300  training loss: 0.023358361795544624
epoch 85300  clean testing loss: 0.08518017828464508
epoch 85400  training loss: 0.02335279807448387

 86%|████████████████████████████████████████████████████████████████████▋           | 85784/100000 [07:11<01:07, 210.52it/s]
epoch 85500  training loss: 0.023349644616246223
epoch 85500  clean testing loss: 0.08518310636281967
epoch 85600  training loss: 0.023342441767454147
epoch 85600  clean testing loss: 0.08517114818096161
epoch 85700  training loss: 0.023341184481978416
epoch 85700  clean testing loss: 0.08519506454467773
epoch 85800  training loss: 0.023336635902523994

 86%|████████████████████████████████████████████████████████████████████▉           | 86197/100000 [07:13<01:08, 202.80it/s]
epoch 85900  training loss: 0.023329269140958786
epoch 85900  clean testing loss: 0.08525188267230988
epoch 86000  training loss: 0.02332526072859764
epoch 86000  clean testing loss: 0.08525964617729187
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 86100  training loss: 0.023322423920035362
epoch 86100  clean testing loss: 0.08520769327878952
epoch 86200  training loss: 0.023314539343118668

 87%|█████████████████████████████████████████████████████████████████████▎          | 86617/100000 [07:15<01:04, 206.18it/s]
epoch 86300  training loss: 0.023312045261263847
epoch 86300  clean testing loss: 0.08524959534406662
epoch 86400  training loss: 0.02330591343343258
epoch 86400  clean testing loss: 0.08526147902011871
epoch 86500  training loss: 0.023303041234612465
epoch 86500  clean testing loss: 0.08530602604150772
epoch 86600  training loss: 0.023297084495425224
epoch 86600  clean testing loss: 0.08525168150663376
epoch 86700  training loss: 0.023292500525712967

 87%|█████████████████████████████████████████████████████████████████████▌          | 87030/100000 [07:17<01:04, 202.61it/s]
epoch 86800  training loss: 0.023288274183869362
epoch 86800  clean testing loss: 0.0852847471833229
epoch 86900  training loss: 0.023285623639822006
epoch 86900  clean testing loss: 0.08528424799442291
epoch 87000  training loss: 0.02328181266784668
epoch 87000  clean testing loss: 0.08530740439891815
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 87100  training loss: 0.023275425657629967

 87%|█████████████████████████████████████████████████████████████████████▉          | 87444/100000 [07:19<01:00, 206.18it/s]
epoch 87200  training loss: 0.023270336911082268
epoch 87200  clean testing loss: 0.08531270176172256
epoch 87300  training loss: 0.023266511037945747
epoch 87300  clean testing loss: 0.08534257113933563
epoch 87400  training loss: 0.023262696340680122
epoch 87400  clean testing loss: 0.08535399287939072
epoch 87500  training loss: 0.023259958252310753

 88%|██████████████████████████████████████████████████████████████████████▎         | 87858/100000 [07:21<00:58, 207.56it/s]
epoch 87600  training loss: 0.023256497457623482
epoch 87600  clean testing loss: 0.08533930778503418
epoch 87700  training loss: 0.02325054630637169
epoch 87700  clean testing loss: 0.0853508710861206
epoch 87800  training loss: 0.023246636614203453
epoch 87800  clean testing loss: 0.0853298157453537
epoch 87900  training loss: 0.02324388176202774

 88%|██████████████████████████████████████████████████████████████████████▌         | 88272/100000 [07:23<00:56, 208.91it/s]
epoch 88000  training loss: 0.02323889546096325
epoch 88000  clean testing loss: 0.08534123748540878
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 88100  training loss: 0.023235715925693512
epoch 88100  clean testing loss: 0.08540552854537964
epoch 88200  training loss: 0.023231778293848038
epoch 88200  clean testing loss: 0.0854068323969841
epoch 88300  training loss: 0.02322746440768242

 89%|██████████████████████████████████████████████████████████████████████▉         | 88687/100000 [07:25<00:53, 210.25it/s]
epoch 88400  training loss: 0.023222604766488075
epoch 88400  clean testing loss: 0.08538065105676651
epoch 88500  training loss: 0.023219726979732513
epoch 88500  clean testing loss: 0.08543504774570465
epoch 88600  training loss: 0.02321523055434227
epoch 88600  clean testing loss: 0.08545949310064316
epoch 88700  training loss: 0.02321077324450016

 89%|███████████████████████████████████████████████████████████████████████▎        | 89098/100000 [07:27<00:54, 201.87it/s]
epoch 88800  training loss: 0.023206833750009537
epoch 88800  clean testing loss: 0.0854702815413475
epoch 88900  training loss: 0.023202156648039818
epoch 88900  clean testing loss: 0.08543192595243454
epoch 89000  training loss: 0.023197190836071968
epoch 89000  clean testing loss: 0.08544638007879257
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 89100  training loss: 0.02319289930164814

 90%|███████████████████████████████████████████████████████████████████████▌        | 89514/100000 [07:30<00:51, 205.19it/s]
epoch 89200  training loss: 0.023189065977931023
epoch 89200  clean testing loss: 0.08546571433544159
epoch 89300  training loss: 0.02318587712943554
epoch 89300  clean testing loss: 0.08545521646738052
epoch 89400  training loss: 0.02318020723760128
epoch 89400  clean testing loss: 0.08549106121063232
epoch 89500  training loss: 0.02317674830555916
epoch 89500  clean testing loss: 0.08547035604715347
epoch 89600  training loss: 0.02317257970571518

 90%|███████████████████████████████████████████████████████████████████████▉        | 89929/100000 [07:32<00:48, 206.47it/s]
epoch 89700  training loss: 0.02316851168870926
epoch 89700  clean testing loss: 0.08550171554088593
epoch 89800  training loss: 0.0231644157320261
epoch 89800  clean testing loss: 0.08553615212440491
epoch 89900  training loss: 0.023159721866250038
epoch 89900  clean testing loss: 0.08551950752735138
epoch 90000  training loss: 0.023156926035881042
epoch 90000  clean testing loss: 0.08556775748729706

 90%|████████████████████████████████████████████████████████████████████████▎       | 90342/100000 [07:34<00:46, 208.87it/s]
epoch 90100  training loss: 0.02315264195203781
epoch 90100  clean testing loss: 0.08554266393184662
epoch 90200  training loss: 0.023149685934185982
epoch 90200  clean testing loss: 0.0855453684926033
epoch 90300  training loss: 0.02314751408994198
epoch 90300  clean testing loss: 0.08553549647331238
epoch 90400  training loss: 0.02314290963113308

 91%|████████████████████████████████████████████████████████████████████████▌       | 90757/100000 [07:36<00:44, 209.41it/s]
epoch 90500  training loss: 0.023141132667660713
epoch 90500  clean testing loss: 0.08555851131677628
epoch 90600  training loss: 0.023136600852012634
epoch 90600  clean testing loss: 0.08555535972118378
epoch 90700  training loss: 0.0231326911598444
epoch 90700  clean testing loss: 0.08558328449726105
epoch 90800  training loss: 0.02312973327934742

 91%|████████████████████████████████████████████████████████████████████████▉       | 91172/100000 [07:38<00:41, 210.92it/s]
epoch 90900  training loss: 0.02312592789530754
epoch 90900  clean testing loss: 0.08558719605207443
epoch 91000  training loss: 0.02312275394797325
epoch 91000  clean testing loss: 0.08562348037958145
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 91100  training loss: 0.023118633776903152
epoch 91100  clean testing loss: 0.08562898635864258
epoch 91200  training loss: 0.023115476593375206

 92%|█████████████████████████████████████████████████████████████████████████▎      | 91588/100000 [07:40<00:41, 203.01it/s]
epoch 91300  training loss: 0.023111818358302116
epoch 91300  clean testing loss: 0.08563878387212753
epoch 91400  training loss: 0.023108169436454773
epoch 91400  clean testing loss: 0.08562296628952026
epoch 91500  training loss: 0.023105725646018982
epoch 91500  clean testing loss: 0.08564823120832443
epoch 91600  training loss: 0.023102914914488792

 92%|█████████████████████████████████████████████████████████████████████████▌      | 92005/100000 [07:42<00:39, 202.01it/s]
epoch 91700  training loss: 0.02309892699122429
epoch 91700  clean testing loss: 0.08565739542245865
epoch 91800  training loss: 0.023094628006219864
epoch 91800  clean testing loss: 0.08567684888839722
epoch 91900  training loss: 0.023091213777661324
epoch 91900  clean testing loss: 0.08564934134483337
epoch 92000  training loss: 0.02308753691613674
epoch 92000  clean testing loss: 0.08567941933870316

 92%|█████████████████████████████████████████████████████████████████████████▉      | 92422/100000 [07:44<00:36, 205.99it/s]
epoch 92100  training loss: 0.023084798827767372
epoch 92100  clean testing loss: 0.08568906784057617
epoch 92200  training loss: 0.023080872371792793
epoch 92200  clean testing loss: 0.0857359915971756
epoch 92300  training loss: 0.023076482117176056
epoch 92300  clean testing loss: 0.08571743220090866
epoch 92400  training loss: 0.023073675110936165
epoch 92400  clean testing loss: 0.08569718897342682
epoch 92500  training loss: 0.02307061105966568

 93%|██████████████████████████████████████████████████████████████████████████▎     | 92843/100000 [07:46<00:34, 206.56it/s]
epoch 92600  training loss: 0.023066580295562744
epoch 92600  clean testing loss: 0.08569008111953735
epoch 92700  training loss: 0.023063192144036293
epoch 92700  clean testing loss: 0.08572793751955032
epoch 92800  training loss: 0.023059673607349396
epoch 92800  clean testing loss: 0.08575650304555893
epoch 92900  training loss: 0.023057516664266586

 93%|██████████████████████████████████████████████████████████████████████████▌     | 93259/100000 [07:48<00:32, 207.62it/s]
epoch 93000  training loss: 0.023053107783198357
epoch 93000  clean testing loss: 0.08576605468988419
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 93100  training loss: 0.02305055968463421
epoch 93100  clean testing loss: 0.08575461059808731
epoch 93200  training loss: 0.023047057911753654
epoch 93200  clean testing loss: 0.08576589077711105
epoch 93300  training loss: 0.023043913766741753

 94%|██████████████████████████████████████████████████████████████████████████▉     | 93676/100000 [07:50<00:30, 209.02it/s]
epoch 93400  training loss: 0.0230410173535347
epoch 93400  clean testing loss: 0.08575794100761414
epoch 93500  training loss: 0.023038189858198166
epoch 93500  clean testing loss: 0.0857585221529007
epoch 93600  training loss: 0.023034626618027687
epoch 93600  clean testing loss: 0.08580447733402252
epoch 93700  training loss: 0.02303152158856392

 94%|███████████████████████████████████████████████████████████████████████████▎    | 94091/100000 [07:52<00:28, 208.53it/s]
epoch 93800  training loss: 0.023029835894703865
epoch 93800  clean testing loss: 0.08580384403467178
epoch 93900  training loss: 0.023027315735816956
epoch 93900  clean testing loss: 0.08578745275735855
epoch 94000  training loss: 0.0230228491127491
epoch 94000  clean testing loss: 0.0858292281627655
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 94100  training loss: 0.02302057482302189

 95%|███████████████████████████████████████████████████████████████████████████▌    | 94508/100000 [07:54<00:26, 210.36it/s]
epoch 94200  training loss: 0.023016994819045067
epoch 94200  clean testing loss: 0.08584655076265335
epoch 94300  training loss: 0.023013951256871223
epoch 94300  clean testing loss: 0.08585997670888901
epoch 94400  training loss: 0.023009704425930977
epoch 94400  clean testing loss: 0.08583161979913712
epoch 94500  training loss: 0.023005660623311996

 95%|███████████████████████████████████████████████████████████████████████████▉    | 94924/100000 [07:56<00:24, 205.03it/s]
epoch 94600  training loss: 0.023002132773399353
epoch 94600  clean testing loss: 0.08585135638713837
epoch 94700  training loss: 0.022998973727226257
epoch 94700  clean testing loss: 0.08584920316934586
epoch 94800  training loss: 0.022996796295046806
epoch 94800  clean testing loss: 0.08586642891168594
epoch 94900  training loss: 0.022993169724941254

 95%|████████████████████████████████████████████████████████████████████████████▎   | 95341/100000 [07:58<00:22, 203.68it/s]
epoch 95000  training loss: 0.022989314049482346
epoch 95000  clean testing loss: 0.08588273078203201
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 95100  training loss: 0.022986672818660736
epoch 95100  clean testing loss: 0.08589154481887817
epoch 95200  training loss: 0.022983968257904053
epoch 95200  clean testing loss: 0.08589541167020798
epoch 95300  training loss: 0.02298017591238022
epoch 95300  clean testing loss: 0.08590301126241684
epoch 95400  training loss: 0.02297767624258995

 96%|████████████████████████████████████████████████████████████████████████████▌   | 95761/100000 [08:00<00:20, 204.87it/s]
epoch 95500  training loss: 0.022975759580731392
epoch 95500  clean testing loss: 0.08594199270009995
epoch 95600  training loss: 0.022970125079154968
epoch 95600  clean testing loss: 0.08590373396873474
epoch 95700  training loss: 0.022967251017689705
epoch 95700  clean testing loss: 0.08593323081731796
epoch 95800  training loss: 0.022963838651776314

 96%|████████████████████████████████████████████████████████████████████████████▉   | 96176/100000 [08:02<00:18, 206.36it/s]
epoch 95900  training loss: 0.022961320355534554
epoch 95900  clean testing loss: 0.08595636487007141
epoch 96000  training loss: 0.022959286347031593
epoch 96000  clean testing loss: 0.08595433086156845
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 96100  training loss: 0.022955691441893578
epoch 96100  clean testing loss: 0.08596230298280716
epoch 96200  training loss: 0.022952955216169357

 97%|█████████████████████████████████████████████████████████████████████████████▎  | 96596/100000 [08:04<00:16, 206.56it/s]
epoch 96300  training loss: 0.022950291633605957
epoch 96300  clean testing loss: 0.08594339340925217
epoch 96400  training loss: 0.022948842495679855
epoch 96400  clean testing loss: 0.08596719801425934
epoch 96500  training loss: 0.02294628694653511
epoch 96500  clean testing loss: 0.08598654717206955
epoch 96600  training loss: 0.022943047806620598

 97%|█████████████████████████████████████████████████████████████████████████████▌  | 97011/100000 [08:06<00:14, 204.20it/s]
epoch 96700  training loss: 0.022941838949918747
epoch 96700  clean testing loss: 0.08597702533006668
epoch 96800  training loss: 0.022938575595617294
epoch 96800  clean testing loss: 0.08598599582910538
epoch 96900  training loss: 0.02293570153415203
epoch 96900  clean testing loss: 0.08599211275577545
epoch 97000  training loss: 0.02293318137526512
epoch 97000  clean testing loss: 0.08599507808685303

 97%|█████████████████████████████████████████████████████████████████████████████▉  | 97425/100000 [08:08<00:12, 208.88it/s]
epoch 97100  training loss: 0.022930799052119255
epoch 97100  clean testing loss: 0.08601422607898712
epoch 97200  training loss: 0.02292742021381855
epoch 97200  clean testing loss: 0.08601263910531998
epoch 97300  training loss: 0.02292548678815365
epoch 97300  clean testing loss: 0.08601105213165283
epoch 97400  training loss: 0.02292311191558838

 98%|██████████████████████████████████████████████████████████████████████████████▎ | 97840/100000 [08:10<00:10, 209.20it/s]
epoch 97500  training loss: 0.02292053773999214
epoch 97500  clean testing loss: 0.08603348582983017
epoch 97600  training loss: 0.02291717194020748
epoch 97600  clean testing loss: 0.0860285609960556
epoch 97700  training loss: 0.022915543988347054
epoch 97700  clean testing loss: 0.08604564517736435
epoch 97800  training loss: 0.022913407534360886
epoch 97800  clean testing loss: 0.08604840934276581
epoch 97900  training loss: 0.022909868508577347

 98%|██████████████████████████████████████████████████████████████████████████████▌ | 98254/100000 [08:12<00:08, 211.83it/s]
epoch 98000  training loss: 0.022908136248588562
epoch 98000  clean testing loss: 0.08605417609214783
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 98100  training loss: 0.022904464974999428
epoch 98100  clean testing loss: 0.08606944978237152
epoch 98200  training loss: 0.022902779281139374
epoch 98200  clean testing loss: 0.08608418703079224
epoch 98300  training loss: 0.02289973944425583

 99%|██████████████████████████████████████████████████████████████████████████████▉ | 98673/100000 [08:14<00:06, 205.01it/s]
epoch 98400  training loss: 0.022897347807884216
epoch 98400  clean testing loss: 0.08609406650066376
epoch 98500  training loss: 0.022895311936736107
epoch 98500  clean testing loss: 0.08611056953668594
epoch 98600  training loss: 0.022893395274877548
epoch 98600  clean testing loss: 0.08610237389802933
epoch 98700  training loss: 0.02288924530148506

 99%|███████████████████████████████████████████████████████████████████████████████▎| 99087/100000 [08:16<00:04, 204.22it/s]
epoch 98800  training loss: 0.02288774587213993
epoch 98800  clean testing loss: 0.08610036224126816
epoch 98900  training loss: 0.022884590551257133
epoch 98900  clean testing loss: 0.08610790222883224
epoch 99000  training loss: 0.02288161963224411
epoch 99000  clean testing loss: 0.08611419796943665
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 99100  training loss: 0.022879518568515778

 99%|███████████████████████████████████████████████████████████████████████████████▌| 99487/100000 [08:18<00:02, 208.78it/s]
epoch 99200  training loss: 0.022877760231494904
epoch 99200  clean testing loss: 0.08613025397062302
epoch 99300  training loss: 0.022875161841511726
epoch 99300  clean testing loss: 0.08613055944442749
epoch 99400  training loss: 0.022873790934681892
epoch 99400  clean testing loss: 0.08614154905080795
epoch 99500  training loss: 0.022870825603604317

100%|███████████████████████████████████████████████████████████████████████████████▉| 99904/100000 [08:20<00:00, 209.72it/s]
epoch 99600  training loss: 0.022868996486067772
epoch 99600  clean testing loss: 0.08616197109222412
epoch 99700  training loss: 0.022867152467370033
epoch 99700  clean testing loss: 0.08617179095745087
epoch 99800  training loss: 0.02286459133028984
epoch 99800  clean testing loss: 0.0861467495560646
epoch 99900  training loss: 0.022862976416945457

100%|███████████████████████████████████████████████████████████████████████████████| 100000/100000 [08:20<00:00, 199.75it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...