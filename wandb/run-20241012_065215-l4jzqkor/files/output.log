
  1%|          | 520/100000 [00:01<05:53, 281.77it/s]
epoch 0  training loss: 0.5975368618965149
epoch 0  clean testing loss: 1.8171237707138062
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 100  training loss: 0.15191957354545593
epoch 100  clean testing loss: 0.05133819952607155
epoch 200  training loss: 0.13037988543510437
epoch 200  clean testing loss: 0.04122130200266838
epoch 300  training loss: 0.12440653890371323
epoch 300  clean testing loss: 0.0275105070322752
epoch 400  training loss: 0.16843566298484802
epoch 400  clean testing loss: 0.0771082267165184
epoch 500  training loss: 0.12528054416179657

  1%|          | 1071/100000 [00:03<05:53, 280.16it/s]
epoch 600  training loss: 0.12138434499502182
epoch 600  clean testing loss: 0.024990981444716454
epoch 700  training loss: 0.11993341892957687
epoch 700  clean testing loss: 0.023228663951158524
epoch 800  training loss: 0.13147565722465515
epoch 800  clean testing loss: 0.03465915471315384
epoch 900  training loss: 0.12104510515928268

  2%|▏         | 1506/100000 [00:05<05:53, 278.83it/s]
epoch 1000  training loss: 0.12007013708353043
epoch 1000  clean testing loss: 0.02255602739751339
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 1100  training loss: 0.12073726207017899
epoch 1100  clean testing loss: 0.023035412654280663
epoch 1200  training loss: 0.11994211375713348
epoch 1200  clean testing loss: 0.0225396566092968
epoch 1300  training loss: 0.11891945451498032
epoch 1300  clean testing loss: 0.02163015305995941
epoch 1400  training loss: 0.11869852244853973
epoch 1400  clean testing loss: 0.021416589617729187
epoch 1500  training loss: 0.11880982667207718

  2%|▏         | 2056/100000 [00:07<05:53, 277.35it/s]
epoch 1600  training loss: 0.1204291507601738
epoch 1600  clean testing loss: 0.02238045632839203
epoch 1700  training loss: 0.12780065834522247
epoch 1700  clean testing loss: 0.028617937117815018
epoch 1800  training loss: 0.13237102329730988
epoch 1800  clean testing loss: 0.03702601045370102
epoch 1900  training loss: 0.12159516662359238
epoch 1900  clean testing loss: 0.02408275194466114
epoch 2000  training loss: 0.1212603747844696
epoch 2000  clean testing loss: 0.024563098326325417
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 2100  training loss: 0.12010405212640762

  3%|▎         | 2635/100000 [00:09<05:46, 280.88it/s]
epoch 2200  training loss: 0.1200212836265564
epoch 2200  clean testing loss: 0.022236846387386322
epoch 2300  training loss: 0.12018566578626633
epoch 2300  clean testing loss: 0.022269606590270996
epoch 2400  training loss: 0.1466425657272339
epoch 2400  clean testing loss: 0.05102875456213951
epoch 2500  training loss: 0.12344337999820709
epoch 2500  clean testing loss: 0.025955919176340103
epoch 2600  training loss: 0.12012127041816711

  3%|▎         | 3183/100000 [00:11<05:47, 278.80it/s]
epoch 2700  training loss: 0.11973623931407928
epoch 2700  clean testing loss: 0.021920576691627502
epoch 2800  training loss: 0.12043710798025131
epoch 2800  clean testing loss: 0.022052425891160965
epoch 2900  training loss: 0.11948499083518982
epoch 2900  clean testing loss: 0.021574445068836212
epoch 3000  training loss: 0.11943169683218002
epoch 3000  clean testing loss: 0.021477019414305687
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 3100  training loss: 0.11928939819335938
epoch 3100  clean testing loss: 0.02143874391913414
epoch 3200  training loss: 0.11928679049015045

  4%|▍         | 3758/100000 [00:13<05:42, 281.06it/s]
epoch 3300  training loss: 0.11942780762910843
epoch 3300  clean testing loss: 0.02152409218251705
epoch 3400  training loss: 0.11939870566129684
epoch 3400  clean testing loss: 0.021483635529875755
epoch 3500  training loss: 0.11940068006515503
epoch 3500  clean testing loss: 0.021490944549441338
epoch 3600  training loss: 0.11960197240114212
epoch 3600  clean testing loss: 0.021780917420983315
epoch 3700  training loss: 0.12059306353330612

  4%|▍         | 4306/100000 [00:15<05:43, 278.92it/s]
epoch 3800  training loss: 0.12548603117465973
epoch 3800  clean testing loss: 0.02317298762500286
epoch 3900  training loss: 0.11982265114784241
epoch 3900  clean testing loss: 0.025087060406804085
epoch 4000  training loss: 0.11948312819004059
epoch 4000  clean testing loss: 0.021560994908213615
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 4100  training loss: 0.11945588141679764
epoch 4100  clean testing loss: 0.02164878323674202
epoch 4200  training loss: 0.11944489181041718
epoch 4200  clean testing loss: 0.021549947559833527
epoch 4300  training loss: 0.11947721987962723

  5%|▍         | 4853/100000 [00:17<05:40, 279.44it/s]
epoch 4400  training loss: 0.1199103519320488
epoch 4400  clean testing loss: 0.022169139236211777
epoch 4500  training loss: 0.11996077746152878
epoch 4500  clean testing loss: 0.021947525441646576
epoch 4600  training loss: 0.11960986256599426
epoch 4600  clean testing loss: 0.02174861915409565
epoch 4700  training loss: 0.11961281299591064
epoch 4700  clean testing loss: 0.02174081839621067
epoch 4800  training loss: 0.11960200220346451
epoch 4800  clean testing loss: 0.0217195525765419
epoch 4900  training loss: 0.11965493857860565

  5%|▌         | 5426/100000 [00:19<05:41, 276.69it/s]
epoch 5000  training loss: 0.11962856352329254
epoch 5000  clean testing loss: 0.022217141464352608
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 5100  training loss: 0.13577452301979065
epoch 5100  clean testing loss: 0.03365270793437958
epoch 5200  training loss: 0.11995226889848709
epoch 5200  clean testing loss: 0.022113649174571037
epoch 5300  training loss: 0.1197221428155899
epoch 5300  clean testing loss: 0.02190493792295456
epoch 5400  training loss: 0.11967501789331436

  6%|▌         | 5974/100000 [00:21<05:33, 281.57it/s]
epoch 5500  training loss: 0.11968627572059631
epoch 5500  clean testing loss: 0.021872373297810555
epoch 5600  training loss: 0.11967065185308456
epoch 5600  clean testing loss: 0.02178015373647213
epoch 5700  training loss: 0.1204289048910141
epoch 5700  clean testing loss: 0.022978171706199646
epoch 5800  training loss: 0.12096692621707916
epoch 5800  clean testing loss: 0.022588104009628296
epoch 5900  training loss: 0.12092232704162598
epoch 5900  clean testing loss: 0.02256719395518303
epoch 6000  training loss: 0.11977110058069229
epoch 6000  clean testing loss: 0.02199487015604973

  7%|▋         | 6541/100000 [00:23<05:35, 278.30it/s]
epoch 6100  training loss: 0.11967673897743225
epoch 6100  clean testing loss: 0.021902740001678467
epoch 6200  training loss: 0.11967302113771439
epoch 6200  clean testing loss: 0.021911034360527992
epoch 6300  training loss: 0.11966831982135773
epoch 6300  clean testing loss: 0.02192242629826069
epoch 6400  training loss: 0.1196625605225563
epoch 6400  clean testing loss: 0.02191750518977642
epoch 6500  training loss: 0.11967279762029648

  7%|▋         | 7084/100000 [00:25<05:34, 277.48it/s]
epoch 6600  training loss: 0.11971761286258698
epoch 6600  clean testing loss: 0.021874383091926575
epoch 6700  training loss: 0.11964008212089539
epoch 6700  clean testing loss: 0.02185385301709175
epoch 6800  training loss: 0.11970491707324982
epoch 6800  clean testing loss: 0.02188018709421158
epoch 6900  training loss: 0.1199115589261055
epoch 6900  clean testing loss: 0.02186754159629345
epoch 7000  training loss: 0.11980551481246948
epoch 7000  clean testing loss: 0.021947186440229416
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 7100  training loss: 0.1200748011469841

  8%|▊         | 7624/100000 [00:27<05:32, 277.43it/s]
epoch 7200  training loss: 0.1203407570719719
epoch 7200  clean testing loss: 0.023374533280730247
epoch 7300  training loss: 0.11969169974327087
epoch 7300  clean testing loss: 0.02193949744105339
epoch 7400  training loss: 0.11964881420135498
epoch 7400  clean testing loss: 0.021922286599874496
epoch 7500  training loss: 0.1196371540427208
epoch 7500  clean testing loss: 0.021944353356957436
epoch 7600  training loss: 0.11962711066007614

  8%|▊         | 8194/100000 [00:29<05:32, 276.33it/s]
epoch 7700  training loss: 0.11962015181779861
epoch 7700  clean testing loss: 0.021863747388124466
epoch 7800  training loss: 0.12010064721107483
epoch 7800  clean testing loss: 0.02270488254725933
epoch 7900  training loss: 0.11974922567605972
epoch 7900  clean testing loss: 0.022055843845009804
epoch 8000  training loss: 0.11960656195878983
epoch 8000  clean testing loss: 0.021830778568983078
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 8100  training loss: 0.1195882260799408
epoch 8100  clean testing loss: 0.021845070645213127
epoch 8200  training loss: 0.119599848985672

  9%|▊         | 8736/100000 [00:31<05:30, 275.95it/s]
epoch 8300  training loss: 0.11960209906101227
epoch 8300  clean testing loss: 0.02184351161122322
epoch 8400  training loss: 0.11969330906867981
epoch 8400  clean testing loss: 0.021852431818842888
epoch 8500  training loss: 0.12140348553657532
epoch 8500  clean testing loss: 0.023569796234369278
epoch 8600  training loss: 0.1195969209074974
epoch 8600  clean testing loss: 0.021873291581869125
epoch 8700  training loss: 0.11956597864627838

  9%|▉         | 9298/100000 [00:33<05:27, 276.64it/s]
epoch 8800  training loss: 0.11957842856645584
epoch 8800  clean testing loss: 0.021771196275949478
epoch 8900  training loss: 0.1195579469203949
epoch 8900  clean testing loss: 0.021814320236444473
epoch 9000  training loss: 0.12065060436725616
epoch 9000  clean testing loss: 0.022380318492650986
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 9100  training loss: 0.11953841149806976
epoch 9100  clean testing loss: 0.021810870617628098
epoch 9200  training loss: 0.11953691393136978
epoch 9200  clean testing loss: 0.021783780306577682
epoch 9300  training loss: 0.11953290551900864

 10%|▉         | 9871/100000 [00:35<05:20, 280.81it/s]
epoch 9400  training loss: 0.11952820420265198
epoch 9400  clean testing loss: 0.021826881915330887
epoch 9500  training loss: 0.11971624195575714
epoch 9500  clean testing loss: 0.021838536486029625
epoch 9600  training loss: 0.119557224214077
epoch 9600  clean testing loss: 0.021972712129354477
epoch 9700  training loss: 0.11998441815376282
epoch 9700  clean testing loss: 0.02313588745892048
epoch 9800  training loss: 0.12008804827928543

 10%|█         | 10414/100000 [00:37<05:19, 280.53it/s]
epoch 9900  training loss: 0.11951947957277298
epoch 9900  clean testing loss: 0.02181982807815075
epoch 10000  training loss: 0.11949987709522247
epoch 10000  clean testing loss: 0.021756824105978012
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 10100  training loss: 0.11948879063129425
epoch 10100  clean testing loss: 0.021764537319540977
epoch 10200  training loss: 0.11953598260879517
epoch 10200  clean testing loss: 0.021991997957229614
epoch 10300  training loss: 0.11970202624797821
epoch 10300  clean testing loss: 0.022069891914725304
epoch 10400  training loss: 0.11999116092920303

 11%|█         | 10982/100000 [00:39<05:17, 280.65it/s]
epoch 10500  training loss: 0.11949098855257034
epoch 10500  clean testing loss: 0.021786659955978394
epoch 10600  training loss: 0.11946777999401093
epoch 10600  clean testing loss: 0.02173972688615322
epoch 10700  training loss: 0.11945565044879913
epoch 10700  clean testing loss: 0.02170909009873867
epoch 10800  training loss: 0.11946658790111542
epoch 10800  clean testing loss: 0.021699221804738045
epoch 10900  training loss: 0.11945056170225143
epoch 10900  clean testing loss: 0.021704038605093956
epoch 11000  training loss: 0.1195835992693901
epoch 11000  clean testing loss: 0.021849744021892548

 12%|█▏        | 11523/100000 [00:41<05:20, 276.11it/s]
epoch 11100  training loss: 0.12179543077945709
epoch 11100  clean testing loss: 0.02183103747665882
epoch 11200  training loss: 0.11944572627544403
epoch 11200  clean testing loss: 0.02175477147102356
epoch 11300  training loss: 0.11941023916006088
epoch 11300  clean testing loss: 0.0216810442507267
epoch 11400  training loss: 0.11941022425889969
epoch 11400  clean testing loss: 0.02170506864786148
epoch 11500  training loss: 0.1193833202123642

 12%|█▏        | 12072/100000 [00:43<05:16, 277.59it/s]
epoch 11600  training loss: 0.11940867453813553
epoch 11600  clean testing loss: 0.021653832867741585
epoch 11700  training loss: 0.11949948221445084
epoch 11700  clean testing loss: 0.021776461973786354
epoch 11800  training loss: 0.11969954520463943
epoch 11800  clean testing loss: 0.021794766187667847
epoch 11900  training loss: 0.11952365189790726
epoch 11900  clean testing loss: 0.021755101159214973
epoch 12000  training loss: 0.11941166967153549
epoch 12000  clean testing loss: 0.022522928193211555
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 12100  training loss: 0.11932492256164551
 12%|█▏        | 12128/100000 [00:43<05:20, 273.88it/s]wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3 seconds.), retrying request
 13%|█▎        | 12638/100000 [00:45<05:13, 278.79it/s]
epoch 12200  training loss: 0.11931298673152924
epoch 12200  clean testing loss: 0.021562088280916214
epoch 12300  training loss: 0.11929573863744736
epoch 12300  clean testing loss: 0.02153150364756584
epoch 12400  training loss: 0.11928208917379379
epoch 12400  clean testing loss: 0.021501539275050163
epoch 12500  training loss: 0.11925983428955078
epoch 12500  clean testing loss: 0.021513119339942932
epoch 12600  training loss: 0.11924166977405548

 13%|█▎        | 13186/100000 [00:47<05:11, 278.53it/s]
epoch 12700  training loss: 0.11934013664722443
epoch 12700  clean testing loss: 0.0216689333319664
epoch 12800  training loss: 0.11939215660095215
epoch 12800  clean testing loss: 0.02145000547170639
epoch 12900  training loss: 0.11957668513059616
epoch 12900  clean testing loss: 0.022068969905376434
epoch 13000  training loss: 0.11918925493955612
epoch 13000  clean testing loss: 0.02143860049545765
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 13100  training loss: 0.11915348470211029
epoch 13100  clean testing loss: 0.021380633115768433
epoch 13200  training loss: 0.1191328912973404

 14%|█▍        | 13759/100000 [00:49<05:08, 279.99it/s]
epoch 13300  training loss: 0.1191500723361969
epoch 13300  clean testing loss: 0.021350065246224403
epoch 13400  training loss: 0.1198195070028305
epoch 13400  clean testing loss: 0.021892357617616653
epoch 13500  training loss: 0.11911162734031677
epoch 13500  clean testing loss: 0.021352779120206833
epoch 13600  training loss: 0.11909157782793045
epoch 13600  clean testing loss: 0.021304946392774582
epoch 13700  training loss: 0.11907389760017395

 14%|█▍        | 14309/100000 [00:51<05:06, 279.42it/s]
epoch 13800  training loss: 0.11906500905752182
epoch 13800  clean testing loss: 0.02126259170472622
epoch 13900  training loss: 0.11909957975149155
epoch 13900  clean testing loss: 0.021225474774837494
epoch 14000  training loss: 0.11901926249265671
epoch 14000  clean testing loss: 0.02125375159084797
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 14100  training loss: 0.11915937066078186
epoch 14100  clean testing loss: 0.02140761911869049
epoch 14200  training loss: 0.11923107504844666
epoch 14200  clean testing loss: 0.021714283153414726
epoch 14300  training loss: 0.1189848855137825

 15%|█▍        | 14884/100000 [00:53<05:01, 282.26it/s]
epoch 14400  training loss: 0.11895900219678879
epoch 14400  clean testing loss: 0.02114596590399742
epoch 14500  training loss: 0.11893803626298904
epoch 14500  clean testing loss: 0.021109722554683685
epoch 14600  training loss: 0.11893264204263687
epoch 14600  clean testing loss: 0.021122850477695465
epoch 14700  training loss: 0.11898183077573776
epoch 14700  clean testing loss: 0.022481201216578484
epoch 14800  training loss: 0.11893753707408905
epoch 14800  clean testing loss: 0.021088793873786926
epoch 14900  training loss: 0.11887440830469131

 15%|█▌        | 15423/100000 [00:55<05:05, 276.70it/s]
epoch 15000  training loss: 0.11900031566619873
epoch 15000  clean testing loss: 0.02101515792310238
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 15100  training loss: 0.11884064972400665
epoch 15100  clean testing loss: 0.021013176068663597
epoch 15200  training loss: 0.11882199347019196
epoch 15200  clean testing loss: 0.020978517830371857
epoch 15300  training loss: 0.11882170289754868
epoch 15300  clean testing loss: 0.0209344569593668
epoch 15400  training loss: 0.11881082504987717

 16%|█▌        | 15974/100000 [00:57<04:56, 283.51it/s]
epoch 15500  training loss: 0.11885245144367218
epoch 15500  clean testing loss: 0.0209443811327219
epoch 15600  training loss: 0.11886025220155716
epoch 15600  clean testing loss: 0.02114645577967167
epoch 15700  training loss: 0.11876598745584488
epoch 15700  clean testing loss: 0.02090510167181492
epoch 15800  training loss: 0.11879625916481018
epoch 15800  clean testing loss: 0.020875105634331703
epoch 15900  training loss: 0.11881166696548462
epoch 15900  clean testing loss: 0.020976128056645393
epoch 16000  training loss: 0.11874325573444366
epoch 16000  clean testing loss: 0.02083323337137699

 17%|█▋        | 16554/100000 [00:59<04:56, 281.39it/s]
epoch 16100  training loss: 0.11875446140766144
epoch 16100  clean testing loss: 0.020808085799217224
epoch 16200  training loss: 0.11905328929424286
epoch 16200  clean testing loss: 0.020985377952456474
epoch 16300  training loss: 0.11870387941598892
epoch 16300  clean testing loss: 0.02083263173699379
epoch 16400  training loss: 0.11869916319847107
epoch 16400  clean testing loss: 0.020796194672584534
epoch 16500  training loss: 0.11870280653238297

 17%|█▋        | 17105/100000 [01:01<04:56, 280.01it/s]
epoch 16600  training loss: 0.11893825232982635
epoch 16600  clean testing loss: 0.021135862916707993
epoch 16700  training loss: 0.11874418705701828
epoch 16700  clean testing loss: 0.0208034198731184
epoch 16800  training loss: 0.11863970756530762
epoch 16800  clean testing loss: 0.02077707089483738
epoch 16900  training loss: 0.11881987005472183
epoch 16900  clean testing loss: 0.020809227600693703
epoch 17000  training loss: 0.11864680796861649
epoch 17000  clean testing loss: 0.02071595937013626
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 17100  training loss: 0.11861701309680939

 18%|█▊        | 17685/100000 [01:03<04:49, 284.37it/s]
epoch 17200  training loss: 0.11859533190727234
epoch 17200  clean testing loss: 0.02067730575799942
epoch 17300  training loss: 0.11863613873720169
epoch 17300  clean testing loss: 0.020751789212226868
epoch 17400  training loss: 0.11872317641973495
epoch 17400  clean testing loss: 0.02088616043329239
epoch 17500  training loss: 0.11858925223350525
epoch 17500  clean testing loss: 0.020718887448310852
epoch 17600  training loss: 0.11856845766305923
epoch 17600  clean testing loss: 0.020710241049528122
epoch 17700  training loss: 0.11855559796094894

 18%|█▊        | 18236/100000 [01:05<04:52, 279.82it/s]
epoch 17800  training loss: 0.11866091936826706
epoch 17800  clean testing loss: 0.020736467093229294
epoch 17900  training loss: 0.11853513866662979
epoch 17900  clean testing loss: 0.020707083866000175
epoch 18000  training loss: 0.1187451034784317
epoch 18000  clean testing loss: 0.020627843216061592
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 18100  training loss: 0.11848743259906769
epoch 18100  clean testing loss: 0.020564638078212738
epoch 18200  training loss: 0.11847987771034241

 19%|█▉        | 18816/100000 [01:07<04:47, 282.54it/s]
epoch 18300  training loss: 0.11845895648002625
epoch 18300  clean testing loss: 0.020529549568891525
epoch 18400  training loss: 0.11844637244939804
epoch 18400  clean testing loss: 0.0204936396330595
epoch 18500  training loss: 0.1184341311454773
epoch 18500  clean testing loss: 0.020503483712673187
epoch 18600  training loss: 0.11841107159852982
epoch 18600  clean testing loss: 0.02049938589334488
epoch 18700  training loss: 0.11840032786130905
epoch 18700  clean testing loss: 0.020497765392065048
epoch 18800  training loss: 0.11855492740869522

 19%|█▉        | 19367/100000 [01:09<04:43, 283.96it/s]
epoch 18900  training loss: 0.11843040585517883
epoch 18900  clean testing loss: 0.02037651091814041
epoch 19000  training loss: 0.11854290217161179
epoch 19000  clean testing loss: 0.02055671624839306
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 19100  training loss: 0.11833400279283524
epoch 19100  clean testing loss: 0.020345360040664673
epoch 19200  training loss: 0.11832720786333084
epoch 19200  clean testing loss: 0.020354552194476128
epoch 19300  training loss: 0.1183711364865303
epoch 19300  clean testing loss: 0.020433804020285606
epoch 19400  training loss: 0.11830399185419083

 20%|█▉        | 19947/100000 [01:11<04:42, 283.15it/s]
epoch 19500  training loss: 0.11834242939949036
epoch 19500  clean testing loss: 0.020498501136898994
epoch 19600  training loss: 0.11836186051368713
epoch 19600  clean testing loss: 0.020349867641925812
epoch 19700  training loss: 0.11825986951589584
epoch 19700  clean testing loss: 0.020286476239562035
epoch 19800  training loss: 0.11828024685382843
epoch 19800  clean testing loss: 0.020300259813666344
epoch 19900  training loss: 0.11822858452796936

 20%|██        | 20498/100000 [01:13<04:39, 284.91it/s]
epoch 20000  training loss: 0.11823859810829163
epoch 20000  clean testing loss: 0.020341375842690468
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 20100  training loss: 0.11823009699583054
epoch 20100  clean testing loss: 0.020255446434020996
epoch 20200  training loss: 0.11823812872171402
epoch 20200  clean testing loss: 0.02028125524520874
epoch 20300  training loss: 0.11825747787952423
epoch 20300  clean testing loss: 0.0202591922134161
epoch 20400  training loss: 0.11827202141284943
epoch 20400  clean testing loss: 0.020254317671060562
epoch 20500  training loss: 0.1182546615600586

 21%|██        | 21078/100000 [01:15<04:40, 280.89it/s]
epoch 20600  training loss: 0.11826227605342865
epoch 20600  clean testing loss: 0.020230937749147415
epoch 20700  training loss: 0.11822093278169632
epoch 20700  clean testing loss: 0.020179949700832367
epoch 20800  training loss: 0.11823014914989471
epoch 20800  clean testing loss: 0.020344549790024757
epoch 20900  training loss: 0.11827309429645538
epoch 20900  clean testing loss: 0.020355720072984695
epoch 21000  training loss: 0.11819025874137878
epoch 21000  clean testing loss: 0.020064396783709526
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 21100  training loss: 0.11807416379451752

 22%|██▏       | 21628/100000 [01:17<04:37, 282.70it/s]
epoch 21200  training loss: 0.11805373430252075
epoch 21200  clean testing loss: 0.020033761858940125
epoch 21300  training loss: 0.11804792284965515
epoch 21300  clean testing loss: 0.019985318183898926
epoch 21400  training loss: 0.11802621930837631
epoch 21400  clean testing loss: 0.019967826083302498
epoch 21500  training loss: 0.11804977804422379
epoch 21500  clean testing loss: 0.02006925828754902
epoch 21600  training loss: 0.11800988763570786

 22%|██▏       | 22208/100000 [01:19<04:35, 282.02it/s]
epoch 21700  training loss: 0.11798439919948578
epoch 21700  clean testing loss: 0.019938182085752487
epoch 21800  training loss: 0.11796441674232483
epoch 21800  clean testing loss: 0.01990126445889473
epoch 21900  training loss: 0.11831574141979218
epoch 21900  clean testing loss: 0.02002355083823204
epoch 22000  training loss: 0.11793617904186249
epoch 22000  clean testing loss: 0.0199205931276083
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 22100  training loss: 0.11781466752290726
epoch 22100  clean testing loss: 0.019789982587099075
epoch 22200  training loss: 0.11799535900354385

 23%|██▎       | 22759/100000 [01:21<04:31, 284.76it/s]
epoch 22300  training loss: 0.11778566241264343
epoch 22300  clean testing loss: 0.019798124209046364
epoch 22400  training loss: 0.11778175085783005
epoch 22400  clean testing loss: 0.019770510494709015
epoch 22500  training loss: 0.11776219308376312
epoch 22500  clean testing loss: 0.01977340690791607
epoch 22600  training loss: 0.1177748590707779
epoch 22600  clean testing loss: 0.01974259503185749
epoch 22700  training loss: 0.1179153323173523
epoch 22700  clean testing loss: 0.019993092864751816
epoch 22800  training loss: 0.1177203580737114

 23%|██▎       | 23339/100000 [01:23<04:31, 282.82it/s]
epoch 22900  training loss: 0.11770182847976685
epoch 22900  clean testing loss: 0.019699016585946083
epoch 23000  training loss: 0.11768391728401184
epoch 23000  clean testing loss: 0.019739944487810135
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 23100  training loss: 0.117951899766922
epoch 23100  clean testing loss: 0.019736826419830322
epoch 23200  training loss: 0.11761259287595749
epoch 23200  clean testing loss: 0.019631633535027504
epoch 23300  training loss: 0.11760541796684265

 24%|██▍       | 23885/100000 [01:25<04:29, 282.23it/s]
epoch 23400  training loss: 0.11761938035488129
epoch 23400  clean testing loss: 0.019615674391388893
epoch 23500  training loss: 0.11759557574987411
epoch 23500  clean testing loss: 0.019669020548462868
epoch 23600  training loss: 0.11760222166776657
epoch 23600  clean testing loss: 0.019604073837399483
epoch 23700  training loss: 0.11754027754068375
epoch 23700  clean testing loss: 0.019591400399804115
epoch 23800  training loss: 0.1176583468914032
epoch 23800  clean testing loss: 0.019582288339734077
epoch 23900  training loss: 0.11746367067098618

 24%|██▍       | 24465/100000 [01:27<04:25, 285.00it/s]
epoch 24000  training loss: 0.11745091527700424
epoch 24000  clean testing loss: 0.019497642293572426
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 24100  training loss: 0.1174384281039238
epoch 24100  clean testing loss: 0.01950472965836525
epoch 24200  training loss: 0.11742579191923141
epoch 24200  clean testing loss: 0.019488632678985596
epoch 24300  training loss: 0.11741969734430313
epoch 24300  clean testing loss: 0.019503561779856682
epoch 24400  training loss: 0.11742831766605377

 25%|██▌       | 25016/100000 [01:29<04:29, 278.39it/s]
epoch 24500  training loss: 0.11740308254957199
epoch 24500  clean testing loss: 0.019468894228339195
epoch 24600  training loss: 0.11745956540107727
epoch 24600  clean testing loss: 0.019461190328001976
epoch 24700  training loss: 0.11738105118274689
epoch 24700  clean testing loss: 0.019445087760686874
epoch 24800  training loss: 0.11747922003269196
epoch 24800  clean testing loss: 0.019496656954288483
epoch 24900  training loss: 0.11738479882478714
epoch 24900  clean testing loss: 0.019480591639876366
epoch 25000  training loss: 0.1173778772354126
epoch 25000  clean testing loss: 0.019512386992573738

 26%|██▌       | 25596/100000 [01:31<04:20, 286.01it/s]
epoch 25100  training loss: 0.11734477430582047
epoch 25100  clean testing loss: 0.019411319866776466
epoch 25200  training loss: 0.1173529401421547
epoch 25200  clean testing loss: 0.019394556060433388
epoch 25300  training loss: 0.11732722818851471
epoch 25300  clean testing loss: 0.01939062774181366
epoch 25400  training loss: 0.11738046258687973
epoch 25400  clean testing loss: 0.0194249227643013
epoch 25500  training loss: 0.11740007251501083
epoch 25500  clean testing loss: 0.019435664638876915
epoch 25600  training loss: 0.11730416864156723

 26%|██▌       | 26147/100000 [01:33<04:20, 283.94it/s]
epoch 25700  training loss: 0.1173672080039978
epoch 25700  clean testing loss: 0.01937219873070717
epoch 25800  training loss: 0.11736831068992615
epoch 25800  clean testing loss: 0.019465599209070206
epoch 25900  training loss: 0.11728151887655258
epoch 25900  clean testing loss: 0.019366372376680374
epoch 26000  training loss: 0.11728359013795853
epoch 26000  clean testing loss: 0.01940321922302246
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 26100  training loss: 0.11726284772157669

 27%|██▋       | 26727/100000 [01:35<04:18, 283.82it/s]
epoch 26200  training loss: 0.11726608872413635
epoch 26200  clean testing loss: 0.01937149651348591
epoch 26300  training loss: 0.11723161488771439
epoch 26300  clean testing loss: 0.019310293719172478
epoch 26400  training loss: 0.11727318912744522
epoch 26400  clean testing loss: 0.019380778074264526
epoch 26500  training loss: 0.11722328513860703
epoch 26500  clean testing loss: 0.019307078793644905
epoch 26600  training loss: 0.1172059029340744
epoch 26600  clean testing loss: 0.0192861407995224
epoch 26700  training loss: 0.11720750480890274

 27%|██▋       | 27307/100000 [01:37<04:17, 282.61it/s]
epoch 26800  training loss: 0.11719462275505066
epoch 26800  clean testing loss: 0.019286567345261574
epoch 26900  training loss: 0.1171964555978775
epoch 26900  clean testing loss: 0.019310133531689644
epoch 27000  training loss: 0.1171877533197403
epoch 27000  clean testing loss: 0.019277412444353104
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 27100  training loss: 0.11717409640550613
epoch 27100  clean testing loss: 0.0192478746175766
epoch 27200  training loss: 0.11716591566801071
epoch 27200  clean testing loss: 0.01925565116107464
epoch 27300  training loss: 0.11716809868812561

 28%|██▊       | 27858/100000 [01:39<04:12, 285.72it/s]
epoch 27400  training loss: 0.11715683341026306
epoch 27400  clean testing loss: 0.019220519810914993
epoch 27500  training loss: 0.11716721951961517
epoch 27500  clean testing loss: 0.019270483404397964
epoch 27600  training loss: 0.11716427654027939
epoch 27600  clean testing loss: 0.019217802211642265
epoch 27700  training loss: 0.117158904671669
epoch 27700  clean testing loss: 0.019207093864679337
epoch 27800  training loss: 0.11714386940002441
epoch 27800  clean testing loss: 0.019203322008252144
epoch 27900  training loss: 0.11715321987867355

 28%|██▊       | 28438/100000 [01:41<04:10, 285.94it/s]
epoch 28000  training loss: 0.11713962256908417
epoch 28000  clean testing loss: 0.01920221373438835
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 28100  training loss: 0.1171288788318634
epoch 28100  clean testing loss: 0.019236315041780472
epoch 28200  training loss: 0.1171787828207016
epoch 28200  clean testing loss: 0.019216686487197876
epoch 28300  training loss: 0.11719240248203278
epoch 28300  clean testing loss: 0.01921899989247322
epoch 28400  training loss: 0.11716143786907196

 29%|██▉       | 28989/100000 [01:43<04:07, 286.66it/s]
epoch 28500  training loss: 0.11711709946393967
epoch 28500  clean testing loss: 0.019200453534722328
epoch 28600  training loss: 0.11711254715919495
epoch 28600  clean testing loss: 0.019211264327168465
epoch 28700  training loss: 0.11712947487831116
epoch 28700  clean testing loss: 0.019175369292497635
epoch 28800  training loss: 0.11711694300174713
epoch 28800  clean testing loss: 0.019204653799533844
epoch 28900  training loss: 0.11709723621606827
epoch 28900  clean testing loss: 0.01917489618062973
epoch 29000  training loss: 0.11710254848003387
epoch 29000  clean testing loss: 0.01917695626616478

 30%|██▉       | 29569/100000 [01:45<04:06, 286.24it/s]
epoch 29100  training loss: 0.11709821224212646
epoch 29100  clean testing loss: 0.019204257056117058
epoch 29200  training loss: 0.11711049824953079
epoch 29200  clean testing loss: 0.019226055592298508
epoch 29300  training loss: 0.11710617691278458
epoch 29300  clean testing loss: 0.019162960350513458
epoch 29400  training loss: 0.11708288639783859
epoch 29400  clean testing loss: 0.019149592146277428
epoch 29500  training loss: 0.11708351969718933
epoch 29500  clean testing loss: 0.01918652653694153
epoch 29600  training loss: 0.11711698025465012

 30%|███       | 30149/100000 [01:47<04:05, 284.24it/s]
epoch 29700  training loss: 0.11709123104810715
epoch 29700  clean testing loss: 0.01914185658097267
epoch 29800  training loss: 0.1171412542462349
epoch 29800  clean testing loss: 0.019304851070046425
epoch 29900  training loss: 0.11709010601043701
epoch 29900  clean testing loss: 0.01920156553387642
epoch 30000  training loss: 0.11719462275505066
epoch 30000  clean testing loss: 0.01925000175833702
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 30100  training loss: 0.11706501245498657

 31%|███       | 30729/100000 [01:49<04:02, 285.14it/s]
epoch 30200  training loss: 0.1170630231499672
epoch 30200  clean testing loss: 0.019144034013152122
epoch 30300  training loss: 0.11706459522247314
epoch 30300  clean testing loss: 0.01914847642183304
epoch 30400  training loss: 0.11706393957138062
epoch 30400  clean testing loss: 0.019184637814760208
epoch 30500  training loss: 0.1170676127076149
epoch 30500  clean testing loss: 0.01912763901054859
epoch 30600  training loss: 0.11705807596445084
epoch 30600  clean testing loss: 0.019160814583301544
epoch 30700  training loss: 0.11705241352319717

 31%|███▏      | 31280/100000 [01:51<03:59, 286.50it/s]
epoch 30800  training loss: 0.11705577373504639
epoch 30800  clean testing loss: 0.019136665388941765
epoch 30900  training loss: 0.11710067838430405
epoch 30900  clean testing loss: 0.01912408322095871
epoch 31000  training loss: 0.1170634999871254
epoch 31000  clean testing loss: 0.01916605420410633
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 31100  training loss: 0.11709278076887131
epoch 31100  clean testing loss: 0.01912790909409523
epoch 31200  training loss: 0.1170528307557106
epoch 31200  clean testing loss: 0.01911351829767227
epoch 31300  training loss: 0.11707116663455963

 32%|███▏      | 31860/100000 [01:53<03:57, 286.50it/s]
epoch 31400  training loss: 0.11704126000404358
epoch 31400  clean testing loss: 0.0191456601023674
epoch 31500  training loss: 0.11705219745635986
epoch 31500  clean testing loss: 0.019115187227725983
epoch 31600  training loss: 0.11706331372261047
epoch 31600  clean testing loss: 0.019115548580884933
epoch 31700  training loss: 0.11703919619321823
epoch 31700  clean testing loss: 0.019109319895505905
epoch 31800  training loss: 0.1170421838760376

 32%|███▏      | 32407/100000 [01:55<04:00, 280.73it/s]
epoch 31900  training loss: 0.11706206947565079
epoch 31900  clean testing loss: 0.019115576520562172
epoch 32000  training loss: 0.11703120172023773
epoch 32000  clean testing loss: 0.019137460738420486
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 32100  training loss: 0.11705610156059265
epoch 32100  clean testing loss: 0.01911482773721218
epoch 32200  training loss: 0.11704684793949127
epoch 32200  clean testing loss: 0.01910422556102276
epoch 32300  training loss: 0.11702580004930496
epoch 32300  clean testing loss: 0.01910392753779888
epoch 32400  training loss: 0.11702457070350647

 33%|███▎      | 32987/100000 [01:57<03:53, 286.70it/s]
epoch 32500  training loss: 0.11705246567726135
epoch 32500  clean testing loss: 0.019191084429621696
epoch 32600  training loss: 0.11705251038074493
epoch 32600  clean testing loss: 0.019107626751065254
epoch 32700  training loss: 0.11702172458171844
epoch 32700  clean testing loss: 0.01909451000392437
epoch 32800  training loss: 0.11701785773038864
epoch 32800  clean testing loss: 0.019096991047263145
epoch 32900  training loss: 0.11703568696975708
epoch 32900  clean testing loss: 0.01908758282661438
epoch 33000  training loss: 0.11703293025493622
epoch 33000  clean testing loss: 0.019088784232735634

 34%|███▎      | 33567/100000 [01:59<03:51, 286.46it/s]
epoch 33100  training loss: 0.11700765043497086
epoch 33100  clean testing loss: 0.01909574866294861
epoch 33200  training loss: 0.11700654029846191
epoch 33200  clean testing loss: 0.019105128943920135
epoch 33300  training loss: 0.11700773984193802
epoch 33300  clean testing loss: 0.01909397542476654
epoch 33400  training loss: 0.11700709909200668
epoch 33400  clean testing loss: 0.019089708104729652
epoch 33500  training loss: 0.11700763553380966

 34%|███▍      | 34118/100000 [02:01<03:52, 283.81it/s]
epoch 33600  training loss: 0.1170029491186142
epoch 33600  clean testing loss: 0.019089601933956146
epoch 33700  training loss: 0.11700412631034851
epoch 33700  clean testing loss: 0.019086046144366264
epoch 33800  training loss: 0.11704447865486145
epoch 33800  clean testing loss: 0.019094262272119522
epoch 33900  training loss: 0.11700243502855301
epoch 33900  clean testing loss: 0.019080089405179024
epoch 34000  training loss: 0.11701241135597229
epoch 34000  clean testing loss: 0.019145235419273376
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 34100  training loss: 0.11699990928173065

 35%|███▍      | 34698/100000 [02:03<03:47, 287.15it/s]
epoch 34200  training loss: 0.1169988363981247
epoch 34200  clean testing loss: 0.01907583884894848
epoch 34300  training loss: 0.11701736599206924
epoch 34300  clean testing loss: 0.019124941900372505
epoch 34400  training loss: 0.11700031161308289
epoch 34400  clean testing loss: 0.019075460731983185
epoch 34500  training loss: 0.11699210852384567
epoch 34500  clean testing loss: 0.01908738724887371
epoch 34600  training loss: 0.11699472367763519
epoch 34600  clean testing loss: 0.0190697330981493
epoch 34700  training loss: 0.1169959306716919

 35%|███▌      | 35278/100000 [02:05<03:46, 286.22it/s]
epoch 34800  training loss: 0.11699982732534409
epoch 34800  clean testing loss: 0.019093768671154976
epoch 34900  training loss: 0.11699055135250092
epoch 34900  clean testing loss: 0.019097240641713142
epoch 35000  training loss: 0.11698862165212631
epoch 35000  clean testing loss: 0.019088171422481537
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 35100  training loss: 0.11702173948287964
epoch 35100  clean testing loss: 0.019132614135742188
epoch 35200  training loss: 0.11700503528118134
epoch 35200  clean testing loss: 0.0190729983150959
epoch 35300  training loss: 0.11698742210865021

 36%|███▌      | 35829/100000 [02:07<03:45, 284.30it/s]
epoch 35400  training loss: 0.11698493361473083
epoch 35400  clean testing loss: 0.01906672865152359
epoch 35500  training loss: 0.11698399484157562
epoch 35500  clean testing loss: 0.019065845757722855
epoch 35600  training loss: 0.11701560020446777
epoch 35600  clean testing loss: 0.019075140357017517
epoch 35700  training loss: 0.11698903143405914
epoch 35700  clean testing loss: 0.019110798835754395
epoch 35800  training loss: 0.11698166280984879

 36%|███▋      | 36409/100000 [02:09<03:44, 283.70it/s]
epoch 35900  training loss: 0.11698213964700699
epoch 35900  clean testing loss: 0.01906852051615715
epoch 36000  training loss: 0.1169828325510025
epoch 36000  clean testing loss: 0.019084908068180084
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 36100  training loss: 0.1169724315404892
epoch 36100  clean testing loss: 0.01907598040997982
epoch 36200  training loss: 0.11697321385145187
epoch 36200  clean testing loss: 0.01907932013273239
epoch 36300  training loss: 0.11697138100862503
epoch 36300  clean testing loss: 0.01905767433345318
epoch 36400  training loss: 0.11697438359260559

 37%|███▋      | 36989/100000 [02:11<03:40, 286.04it/s]
epoch 36500  training loss: 0.1169806644320488
epoch 36500  clean testing loss: 0.019092585891485214
epoch 36600  training loss: 0.11697250604629517
epoch 36600  clean testing loss: 0.019094012677669525
epoch 36700  training loss: 0.11696857959032059
epoch 36700  clean testing loss: 0.019066737964749336
epoch 36800  training loss: 0.11697877943515778
epoch 36800  clean testing loss: 0.019054682925343513
epoch 36900  training loss: 0.11697866022586823
epoch 36900  clean testing loss: 0.01906956359744072
epoch 37000  training loss: 0.11696376651525497
epoch 37000  clean testing loss: 0.019058506935834885

 38%|███▊      | 37540/100000 [02:13<03:40, 283.55it/s]
epoch 37100  training loss: 0.1169646605849266
epoch 37100  clean testing loss: 0.019071130082011223
epoch 37200  training loss: 0.11696986109018326
epoch 37200  clean testing loss: 0.019097603857517242
epoch 37300  training loss: 0.11696554720401764
epoch 37300  clean testing loss: 0.019080545753240585
epoch 37400  training loss: 0.11696697771549225
epoch 37400  clean testing loss: 0.019060278311371803
epoch 37500  training loss: 0.11696653813123703

 38%|███▊      | 38120/100000 [02:15<03:38, 282.81it/s]
epoch 37600  training loss: 0.1169634610414505
epoch 37600  clean testing loss: 0.019074415788054466
epoch 37700  training loss: 0.11695915460586548
epoch 37700  clean testing loss: 0.01907886564731598
epoch 37800  training loss: 0.1169665977358818
epoch 37800  clean testing loss: 0.01905136927962303
epoch 37900  training loss: 0.11695827543735504
epoch 37900  clean testing loss: 0.01907109096646309
epoch 38000  training loss: 0.11695802956819534
epoch 38000  clean testing loss: 0.01905500702559948
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 38100  training loss: 0.11695673316717148

 39%|███▊      | 38700/100000 [02:17<03:33, 286.65it/s]
epoch 38200  training loss: 0.11695902794599533
epoch 38200  clean testing loss: 0.01908191852271557
epoch 38300  training loss: 0.11696047335863113
epoch 38300  clean testing loss: 0.01905127242207527
epoch 38400  training loss: 0.11695409566164017
epoch 38400  clean testing loss: 0.01905934512615204
epoch 38500  training loss: 0.1169533059000969
epoch 38500  clean testing loss: 0.019064810127019882
epoch 38600  training loss: 0.11695175617933273
epoch 38600  clean testing loss: 0.019061902537941933
epoch 38700  training loss: 0.11695949733257294

 39%|███▉      | 39251/100000 [02:19<03:33, 284.86it/s]
epoch 38800  training loss: 0.11695126444101334
epoch 38800  clean testing loss: 0.019045474007725716
epoch 38900  training loss: 0.11694959551095963
epoch 38900  clean testing loss: 0.01905614510178566
epoch 39000  training loss: 0.11696100980043411
epoch 39000  clean testing loss: 0.019081924110651016
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 39100  training loss: 0.11694621294736862
epoch 39100  clean testing loss: 0.019057992845773697
epoch 39200  training loss: 0.11694531887769699

 40%|███▉      | 39831/100000 [02:21<03:31, 284.92it/s]
epoch 39300  training loss: 0.11694325506687164
epoch 39300  clean testing loss: 0.019056258723139763
epoch 39400  training loss: 0.11694224923849106
epoch 39400  clean testing loss: 0.019052177667617798
epoch 39500  training loss: 0.11694233119487762
epoch 39500  clean testing loss: 0.019050737842917442
epoch 39600  training loss: 0.11695148795843124
epoch 39600  clean testing loss: 0.019049590453505516
epoch 39700  training loss: 0.11696145683526993
epoch 39700  clean testing loss: 0.01909126527607441
epoch 39800  training loss: 0.11694198846817017

 40%|████      | 40411/100000 [02:23<03:29, 284.26it/s]
epoch 39900  training loss: 0.11694164574146271
epoch 39900  clean testing loss: 0.019054360687732697
epoch 40000  training loss: 0.11694041639566422
epoch 40000  clean testing loss: 0.019065143540501595
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 40100  training loss: 0.11694265902042389
epoch 40100  clean testing loss: 0.019064800813794136
epoch 40200  training loss: 0.11694545298814774
epoch 40200  clean testing loss: 0.0190434530377388
epoch 40300  training loss: 0.11694221198558807
epoch 40300  clean testing loss: 0.019069097936153412
epoch 40400  training loss: 0.11694416403770447

 41%|████      | 40960/100000 [02:25<03:29, 282.05it/s]
epoch 40500  training loss: 0.11693859845399857
epoch 40500  clean testing loss: 0.019043436273932457
epoch 40600  training loss: 0.11694114655256271
epoch 40600  clean testing loss: 0.01904596947133541
epoch 40700  training loss: 0.11693459004163742
epoch 40700  clean testing loss: 0.019055495038628578
epoch 40800  training loss: 0.11694049835205078
epoch 40800  clean testing loss: 0.0190765168517828
epoch 40900  training loss: 0.11693564057350159

 42%|████▏     | 41511/100000 [02:27<03:26, 283.27it/s]
epoch 41000  training loss: 0.11693529039621353
epoch 41000  clean testing loss: 0.01904323324561119
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 41100  training loss: 0.11693405359983444
epoch 41100  clean testing loss: 0.01905892603099346
epoch 41200  training loss: 0.11693158000707626
epoch 41200  clean testing loss: 0.019053233787417412
epoch 41300  training loss: 0.11692986637353897
epoch 41300  clean testing loss: 0.019044697284698486
epoch 41400  training loss: 0.11692802608013153
epoch 41400  clean testing loss: 0.019049206748604774
epoch 41500  training loss: 0.11693571507930756

 42%|████▏     | 42091/100000 [02:29<03:23, 284.62it/s]
epoch 41600  training loss: 0.11692623049020767
epoch 41600  clean testing loss: 0.019048988819122314
epoch 41700  training loss: 0.1169280856847763
epoch 41700  clean testing loss: 0.019066885113716125
epoch 41800  training loss: 0.11692638695240021
epoch 41800  clean testing loss: 0.0190537478774786
epoch 41900  training loss: 0.11693266034126282
epoch 41900  clean testing loss: 0.019086459651589394
epoch 42000  training loss: 0.11693248897790909
epoch 42000  clean testing loss: 0.019051888957619667
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 42100  training loss: 0.11692117899656296

 43%|████▎     | 42671/100000 [02:31<03:20, 286.50it/s]
epoch 42200  training loss: 0.11692094802856445
epoch 42200  clean testing loss: 0.019039848819375038
epoch 42300  training loss: 0.11691994220018387
epoch 42300  clean testing loss: 0.01904410310089588
epoch 42400  training loss: 0.11692079901695251
epoch 42400  clean testing loss: 0.019057029858231544
epoch 42500  training loss: 0.11691977083683014
epoch 42500  clean testing loss: 0.019054114818572998
epoch 42600  training loss: 0.11692535132169724

 43%|████▎     | 43222/100000 [02:33<03:20, 283.80it/s]
epoch 42700  training loss: 0.11691760271787643
epoch 42700  clean testing loss: 0.019048267975449562
epoch 42800  training loss: 0.11691813915967941
epoch 42800  clean testing loss: 0.019044730812311172
epoch 42900  training loss: 0.11691892147064209
epoch 42900  clean testing loss: 0.019044481217861176
epoch 43000  training loss: 0.11691978573799133
epoch 43000  clean testing loss: 0.019062697887420654
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 43100  training loss: 0.11691520363092422
epoch 43100  clean testing loss: 0.0190399382263422
epoch 43200  training loss: 0.11691364645957947

 44%|████▍     | 43802/100000 [02:35<03:17, 284.85it/s]
epoch 43300  training loss: 0.1169176697731018
epoch 43300  clean testing loss: 0.019058754667639732
epoch 43400  training loss: 0.11691800504922867
epoch 43400  clean testing loss: 0.019035479053854942
epoch 43500  training loss: 0.11691762506961823
epoch 43500  clean testing loss: 0.01905946619808674
epoch 43600  training loss: 0.11691407114267349
epoch 43600  clean testing loss: 0.019054489210247993
epoch 43700  training loss: 0.1169118657708168
epoch 43700  clean testing loss: 0.01905081979930401
epoch 43800  training loss: 0.11691301316022873

 44%|████▍     | 44383/100000 [02:37<03:13, 287.84it/s]
epoch 43900  training loss: 0.1169225424528122
epoch 43900  clean testing loss: 0.01902714930474758
epoch 44000  training loss: 0.11691397428512573
epoch 44000  clean testing loss: 0.01905178464949131
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 44100  training loss: 0.11691171675920486
epoch 44100  clean testing loss: 0.019039828330278397
epoch 44200  training loss: 0.11690942198038101
epoch 44200  clean testing loss: 0.019041668623685837
epoch 44300  training loss: 0.11690854281187057
epoch 44300  clean testing loss: 0.01904049888253212
epoch 44400  training loss: 0.11691288650035858

 45%|████▍     | 44963/100000 [02:39<03:12, 285.92it/s]
epoch 44500  training loss: 0.11690963804721832
epoch 44500  clean testing loss: 0.019041266292333603
epoch 44600  training loss: 0.11691351234912872
epoch 44600  clean testing loss: 0.019026245921850204
epoch 44700  training loss: 0.11692091822624207
epoch 44700  clean testing loss: 0.019028132781386375
epoch 44800  training loss: 0.1169147789478302
epoch 44800  clean testing loss: 0.019054753705859184
epoch 44900  training loss: 0.11690659821033478

 46%|████▌     | 45516/100000 [02:41<03:10, 286.16it/s]
epoch 45000  training loss: 0.1169041097164154
epoch 45000  clean testing loss: 0.01904297061264515
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 45100  training loss: 0.11690311878919601
epoch 45100  clean testing loss: 0.01903463713824749
epoch 45200  training loss: 0.11690361052751541
epoch 45200  clean testing loss: 0.019044268876314163
epoch 45300  training loss: 0.11690273135900497
epoch 45300  clean testing loss: 0.019036123529076576
epoch 45400  training loss: 0.11690326780080795
epoch 45400  clean testing loss: 0.019043026491999626
epoch 45500  training loss: 0.11690632253885269

 46%|████▌     | 46100/100000 [02:43<03:08, 285.32it/s]
epoch 45600  training loss: 0.11690236628055573
epoch 45600  clean testing loss: 0.01904069446027279
epoch 45700  training loss: 0.11690055578947067
epoch 45700  clean testing loss: 0.019043490290641785
epoch 45800  training loss: 0.11690273135900497
epoch 45800  clean testing loss: 0.01902959495782852
epoch 45900  training loss: 0.11690653860569
epoch 45900  clean testing loss: 0.01902616396546364
epoch 46000  training loss: 0.11690005660057068
epoch 46000  clean testing loss: 0.01902778632938862
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 46100  training loss: 0.11690031737089157

 47%|████▋     | 46684/100000 [02:45<03:05, 288.09it/s]
epoch 46200  training loss: 0.11689869314432144
epoch 46200  clean testing loss: 0.019042814150452614
epoch 46300  training loss: 0.11689670383930206
epoch 46300  clean testing loss: 0.01904292032122612
epoch 46400  training loss: 0.11689728498458862
epoch 46400  clean testing loss: 0.019036419689655304
epoch 46500  training loss: 0.11689770221710205
epoch 46500  clean testing loss: 0.019054165109992027
epoch 46600  training loss: 0.11689704656600952

 47%|████▋     | 47238/100000 [02:47<03:04, 286.63it/s]
epoch 46700  training loss: 0.11689534783363342
epoch 46700  clean testing loss: 0.01904028281569481
epoch 46800  training loss: 0.11689656972885132
epoch 46800  clean testing loss: 0.019047703593969345
epoch 46900  training loss: 0.11688703298568726
epoch 46900  clean testing loss: 0.019033366814255714
epoch 47000  training loss: 0.11688884347677231
epoch 47000  clean testing loss: 0.019030187278985977
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 47100  training loss: 0.11688654124736786
epoch 47100  clean testing loss: 0.01902918703854084
epoch 47200  training loss: 0.11688987910747528

 48%|████▊     | 47823/100000 [02:49<03:02, 286.27it/s]
epoch 47300  training loss: 0.11688688397407532
epoch 47300  clean testing loss: 0.01902979426085949
epoch 47400  training loss: 0.11688647419214249
epoch 47400  clean testing loss: 0.019043713808059692
epoch 47500  training loss: 0.11688495427370071
epoch 47500  clean testing loss: 0.019038768485188484
epoch 47600  training loss: 0.1168886199593544
epoch 47600  clean testing loss: 0.0190191101282835
epoch 47700  training loss: 0.11688412725925446
epoch 47700  clean testing loss: 0.01903381384909153
epoch 47800  training loss: 0.11688105016946793

 48%|████▊     | 48405/100000 [02:51<03:00, 286.02it/s]
epoch 47900  training loss: 0.11688100546598434
epoch 47900  clean testing loss: 0.019025828689336777
epoch 48000  training loss: 0.11688349395990372
epoch 48000  clean testing loss: 0.019028816372156143
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 48100  training loss: 0.11688017100095749
epoch 48100  clean testing loss: 0.019030485302209854
epoch 48200  training loss: 0.1168796569108963
epoch 48200  clean testing loss: 0.019028136506676674
epoch 48300  training loss: 0.11687751114368439
epoch 48300  clean testing loss: 0.019019989296793938
epoch 48400  training loss: 0.11687792837619781

 49%|████▉     | 48968/100000 [02:53<02:57, 288.24it/s]
epoch 48500  training loss: 0.1168786808848381
epoch 48500  clean testing loss: 0.01902361772954464
epoch 48600  training loss: 0.11687670648097992
epoch 48600  clean testing loss: 0.019029241055250168
epoch 48700  training loss: 0.11687839031219482
epoch 48700  clean testing loss: 0.019043724983930588
epoch 48800  training loss: 0.11687986552715302
epoch 48800  clean testing loss: 0.019021812826395035
epoch 48900  training loss: 0.11687658727169037

 50%|████▉     | 49528/100000 [02:55<03:00, 280.07it/s]
epoch 49000  training loss: 0.11687557399272919
epoch 49000  clean testing loss: 0.019027890637516975
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 49100  training loss: 0.11687550693750381
epoch 49100  clean testing loss: 0.01901928335428238
epoch 49200  training loss: 0.11687853932380676
epoch 49200  clean testing loss: 0.019016137346625328
epoch 49300  training loss: 0.11687443405389786
epoch 49300  clean testing loss: 0.019025325775146484
epoch 49400  training loss: 0.11687609553337097
epoch 49400  clean testing loss: 0.019039969891309738
epoch 49500  training loss: 0.11687760800123215

 50%|█████     | 50088/100000 [02:57<02:54, 285.39it/s]
epoch 49600  training loss: 0.11687418818473816
epoch 49600  clean testing loss: 0.01903465762734413
epoch 49700  training loss: 0.11687148362398148
epoch 49700  clean testing loss: 0.01902375929057598
epoch 49800  training loss: 0.11687294393777847
epoch 49800  clean testing loss: 0.019032761454582214
epoch 49900  training loss: 0.11687207967042923
epoch 49900  clean testing loss: 0.019021930173039436
epoch 50000  training loss: 0.11686991900205612
epoch 50000  clean testing loss: 0.019019899889826775
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 50100  training loss: 0.11687354743480682

 51%|█████     | 50671/100000 [02:59<02:51, 287.75it/s]
epoch 50200  training loss: 0.11687275022268295
epoch 50200  clean testing loss: 0.01903579756617546
epoch 50300  training loss: 0.11686974763870239
epoch 50300  clean testing loss: 0.019019732251763344
epoch 50400  training loss: 0.11687023937702179
epoch 50400  clean testing loss: 0.019034307450056076
epoch 50500  training loss: 0.1168702095746994
epoch 50500  clean testing loss: 0.019015535712242126
epoch 50600  training loss: 0.11686702817678452

 51%|█████▏    | 51254/100000 [03:01<02:50, 286.49it/s]
epoch 50700  training loss: 0.11686879396438599
epoch 50700  clean testing loss: 0.019013896584510803
epoch 50800  training loss: 0.11686769872903824
epoch 50800  clean testing loss: 0.01901969499886036
epoch 50900  training loss: 0.11686725914478302
epoch 50900  clean testing loss: 0.01901317946612835
epoch 51000  training loss: 0.1168687492609024
epoch 51000  clean testing loss: 0.01902160607278347
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 51100  training loss: 0.11686673015356064
epoch 51100  clean testing loss: 0.019019966945052147
epoch 51200  training loss: 0.11686582863330841

 52%|█████▏    | 51807/100000 [03:03<02:48, 286.13it/s]
epoch 51300  training loss: 0.11686640232801437
epoch 51300  clean testing loss: 0.01902230829000473
epoch 51400  training loss: 0.11686552315950394
epoch 51400  clean testing loss: 0.019013848155736923
epoch 51500  training loss: 0.11686477810144424
epoch 51500  clean testing loss: 0.01901804842054844
epoch 51600  training loss: 0.11686456948518753
epoch 51600  clean testing loss: 0.019018907099962234
epoch 51700  training loss: 0.11686354875564575
epoch 51700  clean testing loss: 0.019016826525330544
epoch 51800  training loss: 0.11686860024929047

 52%|█████▏    | 52394/100000 [03:05<02:45, 288.50it/s]
epoch 51900  training loss: 0.11686454713344574
epoch 51900  clean testing loss: 0.019019141793251038
epoch 52000  training loss: 0.11686410754919052
epoch 52000  clean testing loss: 0.019021261483430862
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 52100  training loss: 0.11686288565397263
epoch 52100  clean testing loss: 0.01901855506002903
epoch 52200  training loss: 0.11686475574970245
epoch 52200  clean testing loss: 0.0190084520727396
epoch 52300  training loss: 0.11686254292726517
epoch 52300  clean testing loss: 0.019022801890969276
epoch 52400  training loss: 0.11686179041862488

 53%|█████▎    | 52952/100000 [03:07<02:43, 287.53it/s]
epoch 52500  training loss: 0.11686322838068008
epoch 52500  clean testing loss: 0.019009772688150406
epoch 52600  training loss: 0.11686230450868607
epoch 52600  clean testing loss: 0.019017938524484634
epoch 52700  training loss: 0.11686059087514877
epoch 52700  clean testing loss: 0.019010987132787704
epoch 52800  training loss: 0.11686103045940399
epoch 52800  clean testing loss: 0.019020596519112587
epoch 52900  training loss: 0.11686213314533234

 54%|█████▎    | 53542/100000 [03:09<02:41, 287.24it/s]
epoch 53000  training loss: 0.11686066538095474
epoch 53000  clean testing loss: 0.019023407250642776
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 53100  training loss: 0.11685974150896072
epoch 53100  clean testing loss: 0.019021587446331978
epoch 53200  training loss: 0.11686379462480545
epoch 53200  clean testing loss: 0.01901409775018692
epoch 53300  training loss: 0.11686234921216965
epoch 53300  clean testing loss: 0.019027527421712875
epoch 53400  training loss: 0.11686043441295624
epoch 53400  clean testing loss: 0.01901353895664215
epoch 53500  training loss: 0.11685936897993088

 54%|█████▍    | 54099/100000 [03:11<02:41, 284.28it/s]
epoch 53600  training loss: 0.11685919016599655
epoch 53600  clean testing loss: 0.01901952549815178
epoch 53700  training loss: 0.1168573796749115
epoch 53700  clean testing loss: 0.01901349425315857
epoch 53800  training loss: 0.11686215549707413
epoch 53800  clean testing loss: 0.019030092284083366
epoch 53900  training loss: 0.11685702949762344
epoch 53900  clean testing loss: 0.019020309671759605
epoch 54000  training loss: 0.11685924977064133
epoch 54000  clean testing loss: 0.019010933116078377
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 54100  training loss: 0.11685661226511002

 55%|█████▍    | 54687/100000 [03:13<02:37, 287.95it/s]
epoch 54200  training loss: 0.11685600131750107
epoch 54200  clean testing loss: 0.01900964230298996
epoch 54300  training loss: 0.11685644090175629
epoch 54300  clean testing loss: 0.019014956429600716
epoch 54400  training loss: 0.1168554425239563
epoch 54400  clean testing loss: 0.019020861014723778
epoch 54500  training loss: 0.11685565859079361
epoch 54500  clean testing loss: 0.019012896344065666
epoch 54600  training loss: 0.11685531586408615
epoch 54600  clean testing loss: 0.019016485661268234
epoch 54700  training loss: 0.11685436964035034

 55%|█████▌    | 55273/100000 [03:15<02:35, 287.57it/s]
epoch 54800  training loss: 0.11685556173324585
epoch 54800  clean testing loss: 0.01900648884475231
epoch 54900  training loss: 0.11685676872730255
epoch 54900  clean testing loss: 0.019019147381186485
epoch 55000  training loss: 0.1168549656867981
epoch 55000  clean testing loss: 0.019019445404410362
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 55100  training loss: 0.11685487627983093
epoch 55100  clean testing loss: 0.019012408331036568
epoch 55200  training loss: 0.11685370653867722

 56%|█████▌    | 55830/100000 [03:17<02:33, 287.41it/s]
epoch 55300  training loss: 0.11685340106487274
epoch 55300  clean testing loss: 0.019010288640856743
epoch 55400  training loss: 0.11685341596603394
epoch 55400  clean testing loss: 0.019018108025193214
epoch 55500  training loss: 0.11685194820165634
epoch 55500  clean testing loss: 0.019013144075870514
epoch 55600  training loss: 0.11685370653867722
epoch 55600  clean testing loss: 0.01901995576918125
epoch 55700  training loss: 0.11685299128293991
epoch 55700  clean testing loss: 0.019008005037903786
epoch 55800  training loss: 0.11685270816087723

 56%|█████▋    | 56417/100000 [03:19<02:32, 286.04it/s]
epoch 55900  training loss: 0.116852767765522
epoch 55900  clean testing loss: 0.019007474184036255
epoch 56000  training loss: 0.1168522909283638
epoch 56000  clean testing loss: 0.019020292907953262
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 56100  training loss: 0.11685153841972351
epoch 56100  clean testing loss: 0.0190103929489851
epoch 56200  training loss: 0.11685207486152649
epoch 56200  clean testing loss: 0.019021859392523766
epoch 56300  training loss: 0.11685099452733994
epoch 56300  clean testing loss: 0.019007427617907524
epoch 56400  training loss: 0.1168542429804802

 57%|█████▋    | 56972/100000 [03:21<02:29, 288.06it/s]
epoch 56500  training loss: 0.11685094982385635
epoch 56500  clean testing loss: 0.019011519849300385
epoch 56600  training loss: 0.11685136705636978
epoch 56600  clean testing loss: 0.01901680789887905
epoch 56700  training loss: 0.11685045808553696
epoch 56700  clean testing loss: 0.019011516124010086
epoch 56800  training loss: 0.11684936285018921
epoch 56800  clean testing loss: 0.01901010423898697
epoch 56900  training loss: 0.11685098707675934
epoch 56900  clean testing loss: 0.01902100071310997
epoch 57000  training loss: 0.11684855818748474
epoch 57000  clean testing loss: 0.019009185954928398

 58%|█████▊    | 57557/100000 [03:23<02:27, 287.53it/s]
epoch 57100  training loss: 0.11684907972812653
epoch 57100  clean testing loss: 0.019016137346625328
epoch 57200  training loss: 0.116848424077034
epoch 57200  clean testing loss: 0.01901223696768284
epoch 57300  training loss: 0.11684715002775192
epoch 57300  clean testing loss: 0.019011467695236206
epoch 57400  training loss: 0.11684932559728622
epoch 57400  clean testing loss: 0.019013255834579468
epoch 57500  training loss: 0.11684855818748474

 58%|█████▊    | 58112/100000 [03:25<02:32, 275.02it/s]
epoch 57600  training loss: 0.1168467253446579
epoch 57600  clean testing loss: 0.01900913566350937
epoch 57700  training loss: 0.11684836447238922
epoch 57700  clean testing loss: 0.01901569589972496
epoch 57800  training loss: 0.11684750765562057
epoch 57800  clean testing loss: 0.01900574378669262
epoch 57900  training loss: 0.11684758216142654
epoch 57900  clean testing loss: 0.019007904455065727
epoch 58000  training loss: 0.1168467104434967
epoch 58000  clean testing loss: 0.019014723598957062
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 58100  training loss: 0.1168462261557579

 59%|█████▊    | 58699/100000 [03:27<02:23, 288.55it/s]
epoch 58200  training loss: 0.11684572696685791
epoch 58200  clean testing loss: 0.01901017315685749
epoch 58300  training loss: 0.11684660613536835
epoch 58300  clean testing loss: 0.01901288516819477
epoch 58400  training loss: 0.11684560030698776
epoch 58400  clean testing loss: 0.01900888979434967
epoch 58500  training loss: 0.1168459951877594
epoch 58500  clean testing loss: 0.019005823880434036
epoch 58600  training loss: 0.11684645712375641
epoch 58600  clean testing loss: 0.01900652050971985
epoch 58700  training loss: 0.11684609204530716

 59%|█████▉    | 59254/100000 [03:29<02:21, 287.38it/s]
epoch 58800  training loss: 0.11684521287679672
epoch 58800  clean testing loss: 0.019012732431292534
epoch 58900  training loss: 0.1168445497751236
epoch 58900  clean testing loss: 0.019007490947842598
epoch 59000  training loss: 0.11684423685073853
epoch 59000  clean testing loss: 0.019007012248039246
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 59100  training loss: 0.11684367060661316
epoch 59100  clean testing loss: 0.01901276223361492
epoch 59200  training loss: 0.1168440505862236

 60%|█████▉    | 59839/100000 [03:31<02:19, 287.26it/s]
epoch 59300  training loss: 0.11684389412403107
epoch 59300  clean testing loss: 0.01900770142674446
epoch 59400  training loss: 0.11684508621692657
epoch 59400  clean testing loss: 0.019012536853551865
epoch 59500  training loss: 0.11684370040893555
epoch 59500  clean testing loss: 0.019004128873348236
epoch 59600  training loss: 0.11684393137693405
epoch 59600  clean testing loss: 0.019010841846466064
epoch 59700  training loss: 0.11684434860944748
epoch 59700  clean testing loss: 0.019016049802303314
epoch 59800  training loss: 0.11684338003396988

 60%|██████    | 60396/100000 [03:33<02:17, 288.44it/s]
epoch 59900  training loss: 0.1168430894613266
epoch 59900  clean testing loss: 0.01900535449385643
epoch 60000  training loss: 0.11684355139732361
epoch 60000  clean testing loss: 0.0190091822296381
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 60100  training loss: 0.11684183031320572
epoch 60100  clean testing loss: 0.019005559384822845
epoch 60200  training loss: 0.11684161424636841
epoch 60200  clean testing loss: 0.019008584320545197
epoch 60300  training loss: 0.11684096604585648
epoch 60300  clean testing loss: 0.019008539617061615
epoch 60400  training loss: 0.11684274673461914

 61%|██████    | 60986/100000 [03:35<02:15, 288.56it/s]
epoch 60500  training loss: 0.11684076488018036
epoch 60500  clean testing loss: 0.019009536132216454
epoch 60600  training loss: 0.11684072017669678
epoch 60600  clean testing loss: 0.019008876755833626
epoch 60700  training loss: 0.11684045195579529
epoch 60700  clean testing loss: 0.019005050882697105
epoch 60800  training loss: 0.11683976650238037
epoch 60800  clean testing loss: 0.01900566928088665
epoch 60900  training loss: 0.11684010922908783
epoch 60900  clean testing loss: 0.0190125685185194
epoch 61000  training loss: 0.11684068292379379
epoch 61000  clean testing loss: 0.019008992239832878

 62%|██████▏   | 61543/100000 [03:37<02:13, 287.02it/s]
epoch 61100  training loss: 0.11684022843837738
epoch 61100  clean testing loss: 0.01900370605289936
epoch 61200  training loss: 0.11684034019708633
epoch 61200  clean testing loss: 0.019008418545126915
epoch 61300  training loss: 0.11683966964483261
epoch 61300  clean testing loss: 0.01900448650121689
epoch 61400  training loss: 0.11683936417102814
epoch 61400  clean testing loss: 0.0190074872225523
epoch 61500  training loss: 0.11683874577283859

 62%|██████▏   | 62131/100000 [03:39<02:12, 285.59it/s]
epoch 61600  training loss: 0.11683952063322067
epoch 61600  clean testing loss: 0.01901053823530674
epoch 61700  training loss: 0.11683905869722366
epoch 61700  clean testing loss: 0.01901266910135746
epoch 61800  training loss: 0.11683817952871323
epoch 61800  clean testing loss: 0.01900738850235939
epoch 61900  training loss: 0.11683788895606995
epoch 61900  clean testing loss: 0.019005075097084045
epoch 62000  training loss: 0.11683886498212814
epoch 62000  clean testing loss: 0.019008804112672806
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 62100  training loss: 0.1168384701013565

 63%|██████▎   | 62717/100000 [03:41<02:10, 285.14it/s]
epoch 62200  training loss: 0.11683817952871323
epoch 62200  clean testing loss: 0.01901398040354252
epoch 62300  training loss: 0.11683785170316696
epoch 62300  clean testing loss: 0.019006989896297455
epoch 62400  training loss: 0.11683846265077591
epoch 62400  clean testing loss: 0.01901085115969181
epoch 62500  training loss: 0.1168384850025177
epoch 62500  clean testing loss: 0.01899907737970352
epoch 62600  training loss: 0.11683714389801025
epoch 62600  clean testing loss: 0.019005684182047844
epoch 62700  training loss: 0.11683698743581772

 63%|██████▎   | 63274/100000 [03:43<02:08, 286.87it/s]
epoch 62800  training loss: 0.11683803051710129
epoch 62800  clean testing loss: 0.019010039046406746
epoch 62900  training loss: 0.11683748662471771
epoch 62900  clean testing loss: 0.019005276262760162
epoch 63000  training loss: 0.11683715879917145
epoch 63000  clean testing loss: 0.019003480672836304
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 63100  training loss: 0.11683566868305206
epoch 63100  clean testing loss: 0.019006695598363876
epoch 63200  training loss: 0.1168355941772461
epoch 63200  clean testing loss: 0.019003013148903847
epoch 63300  training loss: 0.11683569103479385

 64%|██████▍   | 63863/100000 [03:45<02:05, 288.30it/s]
epoch 63400  training loss: 0.11683700978755951
epoch 63400  clean testing loss: 0.019004974514245987
epoch 63500  training loss: 0.1168350800871849
epoch 63500  clean testing loss: 0.019006796181201935
epoch 63600  training loss: 0.11683554202318192
epoch 63600  clean testing loss: 0.01900653727352619
epoch 63700  training loss: 0.11683526635169983
epoch 63700  clean testing loss: 0.019003767520189285
epoch 63800  training loss: 0.11683609336614609

 64%|██████▍   | 64419/100000 [03:47<02:04, 286.02it/s]
epoch 63900  training loss: 0.11683537065982819
epoch 63900  clean testing loss: 0.0190021563321352
epoch 64000  training loss: 0.11683488637208939
epoch 64000  clean testing loss: 0.01900588907301426
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 64100  training loss: 0.11683464050292969
epoch 64100  clean testing loss: 0.019003067165613174
epoch 64200  training loss: 0.11683505773544312
epoch 64200  clean testing loss: 0.01899847760796547
epoch 64300  training loss: 0.11683396995067596
epoch 64300  clean testing loss: 0.019001541659235954
epoch 64400  training loss: 0.11683368682861328

 65%|██████▌   | 65001/100000 [03:49<02:04, 280.39it/s]
epoch 64500  training loss: 0.11683394759893417
epoch 64500  clean testing loss: 0.01900457963347435
epoch 64600  training loss: 0.11683341860771179
epoch 64600  clean testing loss: 0.019002752378582954
epoch 64700  training loss: 0.11683434993028641
epoch 64700  clean testing loss: 0.019006166607141495
epoch 64800  training loss: 0.11683354526758194
epoch 64800  clean testing loss: 0.019003452733159065
epoch 64900  training loss: 0.11683350801467896
epoch 64900  clean testing loss: 0.019002940505743027
epoch 65000  training loss: 0.11683440953493118
epoch 65000  clean testing loss: 0.019002730026841164

 66%|██████▌   | 65586/100000 [03:51<01:59, 287.37it/s]
epoch 65100  training loss: 0.11683391034603119
epoch 65100  clean testing loss: 0.019006015732884407
epoch 65200  training loss: 0.11683288216590881
epoch 65200  clean testing loss: 0.019004857167601585
epoch 65300  training loss: 0.1168329045176506
epoch 65300  clean testing loss: 0.019007185474038124
epoch 65400  training loss: 0.11683271080255508
epoch 65400  clean testing loss: 0.01900305785238743
epoch 65500  training loss: 0.1168321967124939

 66%|██████▌   | 66146/100000 [03:53<01:58, 286.07it/s]
epoch 65600  training loss: 0.11683247983455658
epoch 65600  clean testing loss: 0.019004778936505318
epoch 65700  training loss: 0.1168324425816536
epoch 65700  clean testing loss: 0.019002599641680717
epoch 65800  training loss: 0.11683224886655807
epoch 65800  clean testing loss: 0.019000789150595665
epoch 65900  training loss: 0.11683183163404465
epoch 65900  clean testing loss: 0.01900593191385269
epoch 66000  training loss: 0.11683162301778793
epoch 66000  clean testing loss: 0.019004372879862785
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 66100  training loss: 0.11683107912540436

 67%|██████▋   | 66700/100000 [03:55<02:01, 274.88it/s]
epoch 66200  training loss: 0.11683081835508347
epoch 66200  clean testing loss: 0.01900087483227253
epoch 66300  training loss: 0.11683111637830734
epoch 66300  clean testing loss: 0.019004616886377335
epoch 66400  training loss: 0.11683139204978943
epoch 66400  clean testing loss: 0.01900237426161766
epoch 66500  training loss: 0.11683062463998795
epoch 66500  clean testing loss: 0.01900188811123371
epoch 66600  training loss: 0.1168309673666954
epoch 66600  clean testing loss: 0.0190044604241848
epoch 66700  training loss: 0.11683148890733719

 67%|██████▋   | 67286/100000 [03:57<01:53, 287.87it/s]
epoch 66800  training loss: 0.11683077365159988
epoch 66800  clean testing loss: 0.01900358498096466
epoch 66900  training loss: 0.11683037132024765
epoch 66900  clean testing loss: 0.019004030153155327
epoch 67000  training loss: 0.11683022230863571
epoch 67000  clean testing loss: 0.019001031294465065
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 67100  training loss: 0.11682942509651184
epoch 67100  clean testing loss: 0.019003786146640778
epoch 67200  training loss: 0.11683006584644318

 68%|██████▊   | 67841/100000 [03:59<01:52, 287.11it/s]
epoch 67300  training loss: 0.11683017015457153
epoch 67300  clean testing loss: 0.019003717228770256
epoch 67400  training loss: 0.11683034151792526
epoch 67400  clean testing loss: 0.019000185653567314
epoch 67500  training loss: 0.11682981997728348
epoch 67500  clean testing loss: 0.01900072582066059
epoch 67600  training loss: 0.11682946234941483
epoch 67600  clean testing loss: 0.01900053396821022
epoch 67700  training loss: 0.11682987958192825
epoch 67700  clean testing loss: 0.01899847947061062
epoch 67800  training loss: 0.1168297678232193

 68%|██████▊   | 68426/100000 [04:01<01:50, 286.22it/s]
epoch 67900  training loss: 0.11682932078838348
epoch 67900  clean testing loss: 0.019001485779881477
epoch 68000  training loss: 0.11682901531457901
epoch 68000  clean testing loss: 0.019001897424459457
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 68100  training loss: 0.11682923138141632
epoch 68100  clean testing loss: 0.01900484226644039
epoch 68200  training loss: 0.11682802438735962
epoch 68200  clean testing loss: 0.019001146778464317
epoch 68300  training loss: 0.11682869493961334
epoch 68300  clean testing loss: 0.01900184340775013
epoch 68400  training loss: 0.11682851612567902

 69%|██████▉   | 69013/100000 [04:04<01:50, 280.57it/s]
epoch 68500  training loss: 0.1168287843465805
epoch 68500  clean testing loss: 0.019001074135303497
epoch 68600  training loss: 0.11682861298322678
epoch 68600  clean testing loss: 0.019003605470061302
epoch 68700  training loss: 0.11682794988155365
epoch 68700  clean testing loss: 0.019000492990016937
epoch 68800  training loss: 0.11682762205600739
epoch 68800  clean testing loss: 0.019002459943294525
epoch 68900  training loss: 0.11682789027690887
epoch 68900  clean testing loss: 0.01900085061788559
epoch 69000  training loss: 0.11682780832052231
epoch 69000  clean testing loss: 0.019000815227627754

 70%|██████▉   | 69572/100000 [04:05<01:45, 288.15it/s]
epoch 69100  training loss: 0.11682743579149246
epoch 69100  clean testing loss: 0.019001033157110214
epoch 69200  training loss: 0.11682752519845963
epoch 69200  clean testing loss: 0.01900021918118
epoch 69300  training loss: 0.11682748794555664
epoch 69300  clean testing loss: 0.01900235190987587
epoch 69400  training loss: 0.11682689189910889
epoch 69400  clean testing loss: 0.018999841064214706
epoch 69500  training loss: 0.11682726442813873

 70%|███████   | 70160/100000 [04:08<01:43, 287.26it/s]
epoch 69600  training loss: 0.11682668328285217
epoch 69600  clean testing loss: 0.01900174655020237
epoch 69700  training loss: 0.11682704836130142
epoch 69700  clean testing loss: 0.019000733271241188
epoch 69800  training loss: 0.11682723462581635
epoch 69800  clean testing loss: 0.019000545144081116
epoch 69900  training loss: 0.11682658642530441
epoch 69900  clean testing loss: 0.018999099731445312
epoch 70000  training loss: 0.11682714521884918
epoch 70000  clean testing loss: 0.01900126039981842
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 70100  training loss: 0.11682721972465515

 71%|███████   | 70716/100000 [04:09<01:42, 285.56it/s]
epoch 70200  training loss: 0.11682726442813873
epoch 70200  clean testing loss: 0.01899964176118374
epoch 70300  training loss: 0.11682653427124023
epoch 70300  clean testing loss: 0.019000817090272903
epoch 70400  training loss: 0.116826631128788
epoch 70400  clean testing loss: 0.019003497436642647
epoch 70500  training loss: 0.11682645976543427
epoch 70500  clean testing loss: 0.018998444080352783
epoch 70600  training loss: 0.11682641506195068
epoch 70600  clean testing loss: 0.018998634070158005
epoch 70700  training loss: 0.11682603508234024

 71%|███████▏  | 71301/100000 [04:12<01:40, 284.60it/s]
epoch 70800  training loss: 0.11682572960853577
epoch 70800  clean testing loss: 0.01899966411292553
epoch 70900  training loss: 0.11682628840208054
epoch 70900  clean testing loss: 0.01899995282292366
epoch 71000  training loss: 0.11682604998350143
epoch 71000  clean testing loss: 0.019002722576260567
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 71100  training loss: 0.1168254017829895
epoch 71100  clean testing loss: 0.019000815227627754
epoch 71200  training loss: 0.11682601273059845
epoch 71200  clean testing loss: 0.01899927295744419
epoch 71300  training loss: 0.11682521551847458

 72%|███████▏  | 71884/100000 [04:14<01:37, 287.90it/s]
epoch 71400  training loss: 0.11682520806789398
epoch 71400  clean testing loss: 0.019002502784132957
epoch 71500  training loss: 0.11682529002428055
epoch 71500  clean testing loss: 0.019000710919499397
epoch 71600  training loss: 0.11682548373937607
epoch 71600  clean testing loss: 0.019000807777047157
epoch 71700  training loss: 0.11682549864053726
epoch 71700  clean testing loss: 0.019001085311174393
epoch 71800  training loss: 0.11682476848363876

 72%|███████▏  | 72436/100000 [04:15<01:35, 287.17it/s]
epoch 71900  training loss: 0.11682487279176712
epoch 71900  clean testing loss: 0.019000906497240067
epoch 72000  training loss: 0.11682525277137756
epoch 72000  clean testing loss: 0.019000165164470673
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 72100  training loss: 0.11682465672492981
epoch 72100  clean testing loss: 0.018999790772795677
epoch 72200  training loss: 0.11682448536157608
epoch 72200  clean testing loss: 0.01899983547627926
epoch 72300  training loss: 0.11682425439357758
epoch 72300  clean testing loss: 0.018997378647327423
epoch 72400  training loss: 0.11682441085577011

 73%|███████▎  | 73021/100000 [04:18<01:36, 280.57it/s]
epoch 72500  training loss: 0.11682471632957458
epoch 72500  clean testing loss: 0.019001664593815804
epoch 72600  training loss: 0.11682421714067459
epoch 72600  clean testing loss: 0.019001785665750504
epoch 72700  training loss: 0.11682409048080444
epoch 72700  clean testing loss: 0.018999194726347923
epoch 72800  training loss: 0.11682399362325668
epoch 72800  clean testing loss: 0.018998941406607628
epoch 72900  training loss: 0.11682422459125519
epoch 72900  clean testing loss: 0.019000353291630745
epoch 73000  training loss: 0.11682377755641937
epoch 73000  clean testing loss: 0.01899838261306286

 74%|███████▎  | 73606/100000 [04:20<01:32, 286.30it/s]
epoch 73100  training loss: 0.11682398617267609
epoch 73100  clean testing loss: 0.018998440355062485
epoch 73200  training loss: 0.11682379990816116
epoch 73200  clean testing loss: 0.019000902771949768
epoch 73300  training loss: 0.11682391166687012
epoch 73300  clean testing loss: 0.01900090090930462
epoch 73400  training loss: 0.11682355403900146
epoch 73400  clean testing loss: 0.018999245017766953
epoch 73500  training loss: 0.11682400852441788
epoch 73500  clean testing loss: 0.018999574705958366
epoch 73600  training loss: 0.11682355403900146

 74%|███████▍  | 74160/100000 [04:22<01:30, 286.69it/s]
epoch 73700  training loss: 0.11682355403900146
epoch 73700  clean testing loss: 0.018998797982931137
epoch 73800  training loss: 0.11682318896055222
epoch 73800  clean testing loss: 0.01899772509932518
epoch 73900  training loss: 0.11682312935590744
epoch 73900  clean testing loss: 0.01900104247033596
epoch 74000  training loss: 0.11682314425706863
epoch 74000  clean testing loss: 0.019000133499503136
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 74100  training loss: 0.11682332307100296

 75%|███████▍  | 74749/100000 [04:24<01:27, 287.97it/s]
epoch 74200  training loss: 0.11682350933551788
epoch 74200  clean testing loss: 0.01899818144738674
epoch 74300  training loss: 0.11682338267564774
epoch 74300  clean testing loss: 0.018997561186552048
epoch 74400  training loss: 0.11682307720184326
epoch 74400  clean testing loss: 0.019000304862856865
epoch 74500  training loss: 0.11682316660881042
epoch 74500  clean testing loss: 0.018997397273778915
epoch 74600  training loss: 0.11682310700416565
epoch 74600  clean testing loss: 0.0189988911151886
epoch 74700  training loss: 0.11682238429784775

 75%|███████▌  | 75305/100000 [04:26<01:30, 273.09it/s]
epoch 74800  training loss: 0.11682257801294327
epoch 74800  clean testing loss: 0.019000694155693054
epoch 74900  training loss: 0.11682314425706863
epoch 74900  clean testing loss: 0.018998317420482635
epoch 75000  training loss: 0.11682263761758804
epoch 75000  clean testing loss: 0.01899869181215763
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 75100  training loss: 0.11682277172803879
epoch 75100  clean testing loss: 0.018998360261321068
epoch 75200  training loss: 0.11682238429784775
epoch 75200  clean testing loss: 0.01899842731654644
epoch 75300  training loss: 0.11682233959436417

 76%|███████▌  | 75861/100000 [04:28<01:23, 287.86it/s]
epoch 75400  training loss: 0.11682219803333282
epoch 75400  clean testing loss: 0.018998105078935623
epoch 75500  training loss: 0.11682204157114029
epoch 75500  clean testing loss: 0.018998492509126663
epoch 75600  training loss: 0.11682247370481491
epoch 75600  clean testing loss: 0.019000552594661713
epoch 75700  training loss: 0.11682184785604477
epoch 75700  clean testing loss: 0.018997948616743088
epoch 75800  training loss: 0.11682190001010895

 76%|███████▋  | 76448/100000 [04:30<01:21, 287.51it/s]
epoch 75900  training loss: 0.11682245880365372
epoch 75900  clean testing loss: 0.018998611718416214
epoch 76000  training loss: 0.11682206392288208
epoch 76000  clean testing loss: 0.01899784989655018
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 76100  training loss: 0.11682137101888657
epoch 76100  clean testing loss: 0.018999557942152023
epoch 76200  training loss: 0.1168217658996582
epoch 76200  clean testing loss: 0.018998529762029648
epoch 76300  training loss: 0.1168212965130806
epoch 76300  clean testing loss: 0.018997598439455032
epoch 76400  training loss: 0.11682108789682388

 77%|███████▋  | 77006/100000 [04:32<01:22, 280.21it/s]
epoch 76500  training loss: 0.11682138592004776
epoch 76500  clean testing loss: 0.018999679014086723
epoch 76600  training loss: 0.11682108789682388
epoch 76600  clean testing loss: 0.01899789087474346
epoch 76700  training loss: 0.11682150512933731
epoch 76700  clean testing loss: 0.01899690181016922
epoch 76800  training loss: 0.11682155728340149
epoch 76800  clean testing loss: 0.018998442217707634
epoch 76900  training loss: 0.11682114005088806
epoch 76900  clean testing loss: 0.01899607852101326
epoch 77000  training loss: 0.1168212890625
epoch 77000  clean testing loss: 0.018999071791768074

 78%|███████▊  | 77594/100000 [04:34<01:17, 288.91it/s]
epoch 77100  training loss: 0.1168210506439209
epoch 77100  clean testing loss: 0.018997499719262123
epoch 77200  training loss: 0.11682133376598358
epoch 77200  clean testing loss: 0.01899852231144905
epoch 77300  training loss: 0.11682118475437164
epoch 77300  clean testing loss: 0.01899765059351921
epoch 77400  training loss: 0.1168208196759224
epoch 77400  clean testing loss: 0.018998362123966217
epoch 77500  training loss: 0.11682043224573135
epoch 77500  clean testing loss: 0.018997177481651306
epoch 77600  training loss: 0.11682064086198807

 78%|███████▊  | 78152/100000 [04:35<01:16, 286.51it/s]
epoch 77700  training loss: 0.11682062596082687
epoch 77700  clean testing loss: 0.01899798773229122
epoch 77800  training loss: 0.11682020127773285
epoch 77800  clean testing loss: 0.01899593137204647
epoch 77900  training loss: 0.11682068556547165
epoch 77900  clean testing loss: 0.018996847793459892
epoch 78000  training loss: 0.11682058125734329
epoch 78000  clean testing loss: 0.01899789832532406
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 78100  training loss: 0.11682014167308807

 79%|███████▊  | 78737/100000 [04:38<01:14, 286.05it/s]
epoch 78200  training loss: 0.11682020872831345
epoch 78200  clean testing loss: 0.018996652215719223
epoch 78300  training loss: 0.11682028323411942
epoch 78300  clean testing loss: 0.01899753138422966
epoch 78400  training loss: 0.11682011187076569
epoch 78400  clean testing loss: 0.018996570259332657
epoch 78500  training loss: 0.11681997030973434
epoch 78500  clean testing loss: 0.01899767853319645
epoch 78600  training loss: 0.11681987345218658
epoch 78600  clean testing loss: 0.018997326493263245
epoch 78700  training loss: 0.11681994050741196

 79%|███████▉  | 79320/100000 [04:40<01:12, 285.78it/s]
epoch 78800  training loss: 0.11681976914405823
epoch 78800  clean testing loss: 0.018997671082615852
epoch 78900  training loss: 0.11682043224573135
epoch 78900  clean testing loss: 0.01899760775268078
epoch 79000  training loss: 0.11681976914405823
epoch 79000  clean testing loss: 0.0189983993768692
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 79100  training loss: 0.11681951582431793
epoch 79100  clean testing loss: 0.018996840342879295
epoch 79200  training loss: 0.11681976914405823
epoch 79200  clean testing loss: 0.01899672858417034
epoch 79300  training loss: 0.1168196052312851

 80%|███████▉  | 79872/100000 [04:42<01:10, 285.33it/s]
epoch 79400  training loss: 0.11681990325450897
epoch 79400  clean testing loss: 0.01899595931172371
epoch 79500  training loss: 0.11681944131851196
epoch 79500  clean testing loss: 0.018996920436620712
epoch 79600  training loss: 0.11681953072547913
epoch 79600  clean testing loss: 0.018996840342879295
epoch 79700  training loss: 0.11681947857141495
epoch 79700  clean testing loss: 0.018997298553586006
epoch 79800  training loss: 0.11681930720806122
epoch 79800  clean testing loss: 0.018998004496097565
epoch 79900  training loss: 0.11681947857141495

 80%|████████  | 80453/100000 [04:44<01:07, 288.02it/s]
epoch 80000  training loss: 0.11681926995515823
epoch 80000  clean testing loss: 0.018995841965079308
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 80100  training loss: 0.11681945621967316
epoch 80100  clean testing loss: 0.018996920436620712
epoch 80200  training loss: 0.11681932955980301
epoch 80200  clean testing loss: 0.01899692416191101
epoch 80300  training loss: 0.11681907624006271
epoch 80300  clean testing loss: 0.018996931612491608
epoch 80400  training loss: 0.11681877076625824

 81%|████████  | 81037/100000 [04:46<01:06, 283.44it/s]
epoch 80500  training loss: 0.11681923270225525
epoch 80500  clean testing loss: 0.018996840342879295
epoch 80600  training loss: 0.11681895703077316
epoch 80600  clean testing loss: 0.018996644765138626
epoch 80700  training loss: 0.11681944131851196
epoch 80700  clean testing loss: 0.018998293206095695
epoch 80800  training loss: 0.1168191134929657
epoch 80800  clean testing loss: 0.01899690367281437
epoch 80900  training loss: 0.11681868880987167
epoch 80900  clean testing loss: 0.018996549770236015
epoch 81000  training loss: 0.11681896448135376
epoch 81000  clean testing loss: 0.018996842205524445

 82%|████████▏ | 81596/100000 [04:48<01:03, 288.84it/s]
epoch 81100  training loss: 0.11681869626045227
epoch 81100  clean testing loss: 0.018996411934494972
epoch 81200  training loss: 0.11681848019361496
epoch 81200  clean testing loss: 0.018997179344296455
epoch 81300  training loss: 0.11681874841451645
epoch 81300  clean testing loss: 0.018998095765709877
epoch 81400  training loss: 0.11681848764419556
epoch 81400  clean testing loss: 0.01899489387869835
epoch 81500  training loss: 0.11681823432445526
epoch 81500  clean testing loss: 0.018996797502040863
epoch 81600  training loss: 0.11681817471981049

 82%|████████▏ | 82182/100000 [04:50<01:01, 287.59it/s]
epoch 81700  training loss: 0.1168181374669075
epoch 81700  clean testing loss: 0.01899545267224312
epoch 81800  training loss: 0.1168183833360672
epoch 81800  clean testing loss: 0.01899760402739048
epoch 81900  training loss: 0.11681852489709854
epoch 81900  clean testing loss: 0.018997246399521828
epoch 82000  training loss: 0.11681810021400452
epoch 82000  clean testing loss: 0.018997110426425934
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 82100  training loss: 0.11681815981864929
epoch 82100  clean testing loss: 0.018996400758624077
epoch 82200  training loss: 0.11681835353374481

 83%|████████▎ | 82771/100000 [04:52<00:59, 288.41it/s]
epoch 82300  training loss: 0.11681834608316422
epoch 82300  clean testing loss: 0.018996328115463257
epoch 82400  training loss: 0.11681804060935974
epoch 82400  clean testing loss: 0.018996374681591988
epoch 82500  training loss: 0.11681779474020004
epoch 82500  clean testing loss: 0.018995434045791626
epoch 82600  training loss: 0.1168178915977478
epoch 82600  clean testing loss: 0.01899542473256588
epoch 82700  training loss: 0.11681760847568512

 83%|████████▎ | 83327/100000 [04:54<00:58, 284.97it/s]
epoch 82800  training loss: 0.11681767553091049
epoch 82800  clean testing loss: 0.018995383754372597
epoch 82900  training loss: 0.11681798845529556
epoch 82900  clean testing loss: 0.018996279686689377
epoch 83000  training loss: 0.1168178915977478
epoch 83000  clean testing loss: 0.018997283652424812
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 83100  training loss: 0.11681762337684631
epoch 83100  clean testing loss: 0.018995920196175575
epoch 83200  training loss: 0.11681798100471497
epoch 83200  clean testing loss: 0.018997134640812874
epoch 83300  training loss: 0.11681754142045975

 84%|████████▍ | 83880/100000 [04:56<01:00, 266.66it/s]
epoch 83400  training loss: 0.11681774258613586
epoch 83400  clean testing loss: 0.01899711787700653
epoch 83500  training loss: 0.11681777238845825
epoch 83500  clean testing loss: 0.018997250124812126
epoch 83600  training loss: 0.11681757867336273
epoch 83600  clean testing loss: 0.01899552159011364
epoch 83700  training loss: 0.11681772023439407
epoch 83700  clean testing loss: 0.01899602636694908
epoch 83800  training loss: 0.11681737750768661
epoch 83800  clean testing loss: 0.01899549551308155
epoch 83900  training loss: 0.11681725829839706

 84%|████████▍ | 84463/100000 [04:58<00:53, 288.01it/s]
epoch 84000  training loss: 0.11681737005710602
epoch 84000  clean testing loss: 0.018995340913534164
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 84100  training loss: 0.11681769788265228
epoch 84100  clean testing loss: 0.01899639517068863
epoch 84200  training loss: 0.11681724339723587
epoch 84200  clean testing loss: 0.018995946273207664
epoch 84300  training loss: 0.11681710928678513
epoch 84300  clean testing loss: 0.018995337188243866
epoch 84400  training loss: 0.11681714653968811

 85%|████████▌ | 85047/100000 [05:00<00:52, 283.39it/s]
epoch 84500  training loss: 0.11681713908910751
epoch 84500  clean testing loss: 0.018996484577655792
epoch 84600  training loss: 0.11681696772575378
epoch 84600  clean testing loss: 0.018995191901922226
epoch 84700  training loss: 0.11681720614433289
epoch 84700  clean testing loss: 0.018996814265847206
epoch 84800  training loss: 0.11681713908910751
epoch 84800  clean testing loss: 0.018995346501469612
epoch 84900  training loss: 0.11681696772575378
epoch 84900  clean testing loss: 0.01899510808289051
epoch 85000  training loss: 0.11681697517633438
epoch 85000  clean testing loss: 0.018995994701981544

 86%|████████▌ | 85602/100000 [05:02<00:50, 285.68it/s]
epoch 85100  training loss: 0.11681683361530304
epoch 85100  clean testing loss: 0.018994921818375587
epoch 85200  training loss: 0.11681689321994781
epoch 85200  clean testing loss: 0.01899644359946251
epoch 85300  training loss: 0.11681687086820602
epoch 85300  clean testing loss: 0.018994702026247978
epoch 85400  training loss: 0.11681703478097916
epoch 85400  clean testing loss: 0.018996188417077065
epoch 85500  training loss: 0.11681664735078812
epoch 85500  clean testing loss: 0.018995920196175575
epoch 85600  training loss: 0.11681676656007767

 86%|████████▌ | 86188/100000 [05:04<00:48, 287.50it/s]
epoch 85700  training loss: 0.11681683361530304
epoch 85700  clean testing loss: 0.018996015191078186
epoch 85800  training loss: 0.11681649833917618
epoch 85800  clean testing loss: 0.0189946461468935
epoch 85900  training loss: 0.11681672185659409
epoch 85900  clean testing loss: 0.018996035680174828
epoch 86000  training loss: 0.11681658774614334
epoch 86000  clean testing loss: 0.018996046856045723
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 86100  training loss: 0.1168164610862732

 87%|████████▋ | 86771/100000 [05:06<00:45, 288.05it/s]
epoch 86200  training loss: 0.11681640148162842
epoch 86200  clean testing loss: 0.018995419144630432
epoch 86300  training loss: 0.11681634187698364
epoch 86300  clean testing loss: 0.018996194005012512
epoch 86400  training loss: 0.11681647598743439
epoch 86400  clean testing loss: 0.01899617910385132
epoch 86500  training loss: 0.11681628972291946
epoch 86500  clean testing loss: 0.018994973972439766
epoch 86600  training loss: 0.1168164312839508
epoch 86600  clean testing loss: 0.01899578981101513
epoch 86700  training loss: 0.11681635677814484

 87%|████████▋ | 87328/100000 [05:08<00:44, 285.71it/s]
epoch 86800  training loss: 0.11681625992059708
epoch 86800  clean testing loss: 0.01899457722902298
epoch 86900  training loss: 0.11681630462408066
epoch 86900  clean testing loss: 0.018994729965925217
epoch 87000  training loss: 0.11681625992059708
epoch 87000  clean testing loss: 0.018995461985468864
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 87100  training loss: 0.11681613326072693
epoch 87100  clean testing loss: 0.018995024263858795
epoch 87200  training loss: 0.11681618541479111
epoch 87200  clean testing loss: 0.018994243815541267
epoch 87300  training loss: 0.1168159618973732

 88%|████████▊ | 87914/100000 [05:10<00:42, 286.27it/s]
epoch 87400  training loss: 0.11681611090898514
epoch 87400  clean testing loss: 0.01899476908147335
epoch 87500  training loss: 0.11681599915027618
epoch 87500  clean testing loss: 0.018995748832821846
epoch 87600  training loss: 0.11681593954563141
epoch 87600  clean testing loss: 0.01899516023695469
epoch 87700  training loss: 0.1168159544467926
epoch 87700  clean testing loss: 0.018995698541402817
epoch 87800  training loss: 0.11681592464447021
epoch 87800  clean testing loss: 0.018995016813278198
epoch 87900  training loss: 0.11681578308343887

 88%|████████▊ | 88470/100000 [05:12<00:40, 285.81it/s]
epoch 88000  training loss: 0.11681605875492096
epoch 88000  clean testing loss: 0.018994055688381195
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 88100  training loss: 0.11681576818227768
epoch 88100  clean testing loss: 0.018995486199855804
epoch 88200  training loss: 0.11681576818227768
epoch 88200  clean testing loss: 0.018995046615600586
epoch 88300  training loss: 0.11681564897298813
epoch 88300  clean testing loss: 0.018995100632309914
epoch 88400  training loss: 0.11681574583053589

 89%|████████▉ | 89054/100000 [05:14<00:38, 283.40it/s]
epoch 88500  training loss: 0.11681569367647171
epoch 88500  clean testing loss: 0.018995800986886024
epoch 88600  training loss: 0.11681561917066574
epoch 88600  clean testing loss: 0.018995145335793495
epoch 88700  training loss: 0.11681575328111649
epoch 88700  clean testing loss: 0.018995167687535286
epoch 88800  training loss: 0.11681569367647171
epoch 88800  clean testing loss: 0.018995923921465874
epoch 88900  training loss: 0.11681559681892395
epoch 88900  clean testing loss: 0.018994329497218132
epoch 89000  training loss: 0.11681587994098663
epoch 89000  clean testing loss: 0.01899460330605507

 90%|████████▉ | 89639/100000 [05:16<00:36, 286.82it/s]
epoch 89100  training loss: 0.11681557446718216
epoch 89100  clean testing loss: 0.018994832411408424
epoch 89200  training loss: 0.11681569367647171
epoch 89200  clean testing loss: 0.018994662910699844
epoch 89300  training loss: 0.11681553721427917
epoch 89300  clean testing loss: 0.018995122984051704
epoch 89400  training loss: 0.11681561917066574
epoch 89400  clean testing loss: 0.018993889912962914
epoch 89500  training loss: 0.11681544780731201
epoch 89500  clean testing loss: 0.01899409480392933
epoch 89600  training loss: 0.11681542545557022

 90%|█████████ | 90195/100000 [05:18<00:34, 287.41it/s]
epoch 89700  training loss: 0.11681555211544037
epoch 89700  clean testing loss: 0.01899496093392372
epoch 89800  training loss: 0.11681538075208664
epoch 89800  clean testing loss: 0.01899450086057186
epoch 89900  training loss: 0.11681528389453888
epoch 89900  clean testing loss: 0.018995730206370354
epoch 90000  training loss: 0.11681525409221649
epoch 90000  clean testing loss: 0.018994171172380447
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 90100  training loss: 0.11681532859802246
epoch 90100  clean testing loss: 0.018994798883795738
epoch 90200  training loss: 0.11681521683931351

 91%|█████████ | 90781/100000 [05:20<00:31, 288.22it/s]
epoch 90300  training loss: 0.11681534349918365
epoch 90300  clean testing loss: 0.01899445429444313
epoch 90400  training loss: 0.11681528389453888
epoch 90400  clean testing loss: 0.018994685262441635
epoch 90500  training loss: 0.11681520938873291
epoch 90500  clean testing loss: 0.018994513899087906
epoch 90600  training loss: 0.11681517958641052
epoch 90600  clean testing loss: 0.018995041027665138
epoch 90700  training loss: 0.11681525409221649

 91%|█████████▏| 91337/100000 [05:22<00:30, 287.19it/s]
epoch 90800  training loss: 0.11681506037712097
epoch 90800  clean testing loss: 0.01899438165128231
epoch 90900  training loss: 0.11681513488292694
epoch 90900  clean testing loss: 0.018994325771927834
epoch 91000  training loss: 0.11681517958641052
epoch 91000  clean testing loss: 0.01899489015340805
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 91100  training loss: 0.11681507527828217
epoch 91100  clean testing loss: 0.018994532525539398
epoch 91200  training loss: 0.11681513488292694
epoch 91200  clean testing loss: 0.018995245918631554
epoch 91300  training loss: 0.11681486666202545

 92%|█████████▏| 91923/100000 [05:24<00:28, 286.37it/s]
epoch 91400  training loss: 0.1168149784207344
epoch 91400  clean testing loss: 0.01899426244199276
epoch 91500  training loss: 0.11681502312421799
epoch 91500  clean testing loss: 0.01899447664618492
epoch 91600  training loss: 0.116814985871315
epoch 91600  clean testing loss: 0.01899535395205021
epoch 91700  training loss: 0.1168150082230568
epoch 91700  clean testing loss: 0.018994983285665512
epoch 91800  training loss: 0.11681486666202545
epoch 91800  clean testing loss: 0.018994860351085663
epoch 91900  training loss: 0.11681484431028366

 92%|█████████▏| 92474/100000 [05:26<00:29, 258.61it/s]
epoch 92000  training loss: 0.1168149784207344
epoch 92000  clean testing loss: 0.01899474859237671
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 92100  training loss: 0.11681486666202545
epoch 92100  clean testing loss: 0.01899399608373642
epoch 92200  training loss: 0.11681476980447769
epoch 92200  clean testing loss: 0.01899414137005806
epoch 92300  training loss: 0.11681481450796127
epoch 92300  clean testing loss: 0.018994493409991264
epoch 92400  training loss: 0.11681479215621948

 93%|█████████▎| 93056/100000 [05:28<00:24, 282.70it/s]
epoch 92500  training loss: 0.11681486666202545
epoch 92500  clean testing loss: 0.018994644284248352
epoch 92600  training loss: 0.11681491136550903
epoch 92600  clean testing loss: 0.01899479329586029
epoch 92700  training loss: 0.11681486666202545
epoch 92700  clean testing loss: 0.018994156271219254
epoch 92800  training loss: 0.1168147400021553
epoch 92800  clean testing loss: 0.018995177000761032
epoch 92900  training loss: 0.11681464314460754
epoch 92900  clean testing loss: 0.018994273617863655
epoch 93000  training loss: 0.11681476980447769
epoch 93000  clean testing loss: 0.01899413950741291

 94%|█████████▎| 93611/100000 [05:30<00:22, 285.85it/s]
epoch 93100  training loss: 0.11681476980447769
epoch 93100  clean testing loss: 0.018994232639670372
epoch 93200  training loss: 0.11681456863880157
epoch 93200  clean testing loss: 0.01899418979883194
epoch 93300  training loss: 0.11681454628705978
epoch 93300  clean testing loss: 0.01899450086057186
epoch 93400  training loss: 0.11681462079286575
epoch 93400  clean testing loss: 0.018994104117155075
epoch 93500  training loss: 0.11681456863880157
epoch 93500  clean testing loss: 0.018994422629475594
epoch 93600  training loss: 0.11681467294692993

 94%|█████████▍| 94191/100000 [05:32<00:20, 286.83it/s]
epoch 93700  training loss: 0.11681456863880157
epoch 93700  clean testing loss: 0.018994281068444252
epoch 93800  training loss: 0.11681459844112396
epoch 93800  clean testing loss: 0.018994227051734924
epoch 93900  training loss: 0.1168145015835762
epoch 93900  clean testing loss: 0.01899404264986515
epoch 94000  training loss: 0.11681454628705978
epoch 94000  clean testing loss: 0.018994474783539772
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 94100  training loss: 0.11681442707777023
epoch 94100  clean testing loss: 0.018994061276316643
epoch 94200  training loss: 0.11681462079286575

 95%|█████████▍| 94777/100000 [05:34<00:18, 287.68it/s]
epoch 94300  training loss: 0.11681444942951202
epoch 94300  clean testing loss: 0.018993789330124855
epoch 94400  training loss: 0.11681454628705978
epoch 94400  clean testing loss: 0.018994051963090897
epoch 94500  training loss: 0.11681454628705978
epoch 94500  clean testing loss: 0.018994467332959175
epoch 94600  training loss: 0.1168145015835762
epoch 94600  clean testing loss: 0.01899448223412037
epoch 94700  training loss: 0.11681438982486725

 95%|█████████▌| 95335/100000 [05:36<00:16, 286.37it/s]
epoch 94800  training loss: 0.11681442707777023
epoch 94800  clean testing loss: 0.018994400277733803
epoch 94900  training loss: 0.11681446433067322
epoch 94900  clean testing loss: 0.018994616344571114
epoch 95000  training loss: 0.11681436747312546
epoch 95000  clean testing loss: 0.018993962556123734
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 95100  training loss: 0.11681435257196426
epoch 95100  clean testing loss: 0.01899377629160881
epoch 95200  training loss: 0.11681430041790009
epoch 95200  clean testing loss: 0.01899377815425396
epoch 95300  training loss: 0.11681433022022247

 96%|█████████▌| 95923/100000 [05:38<00:14, 286.46it/s]
epoch 95400  training loss: 0.11681435257196426
epoch 95400  clean testing loss: 0.018994411453604698
epoch 95500  training loss: 0.1168142780661583
epoch 95500  clean testing loss: 0.018994173035025597
epoch 95600  training loss: 0.11681431531906128
epoch 95600  clean testing loss: 0.01899370737373829
epoch 95700  training loss: 0.11681441217660904
epoch 95700  clean testing loss: 0.018994612619280815
epoch 95800  training loss: 0.11681430041790009
epoch 95800  clean testing loss: 0.018994299694895744
epoch 95900  training loss: 0.11681429296731949

 96%|█████████▋| 96480/100000 [05:40<00:12, 287.82it/s]
epoch 96000  training loss: 0.11681423336267471
epoch 96000  clean testing loss: 0.018993880599737167
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 96100  training loss: 0.11681423336267471
epoch 96100  clean testing loss: 0.018993766978383064
epoch 96200  training loss: 0.11681415885686874
epoch 96200  clean testing loss: 0.018994295969605446
epoch 96300  training loss: 0.11681415885686874
epoch 96300  clean testing loss: 0.018994025886058807
epoch 96400  training loss: 0.11681415885686874
epoch 96400  clean testing loss: 0.018993953242897987
epoch 96500  training loss: 0.11681424081325531

 97%|█████████▋| 97066/100000 [05:42<00:10, 284.54it/s]
epoch 96600  training loss: 0.11681420356035233
epoch 96600  clean testing loss: 0.01899433322250843
epoch 96700  training loss: 0.11681418120861053
epoch 96700  clean testing loss: 0.018993981182575226
epoch 96800  training loss: 0.11681413650512695
epoch 96800  clean testing loss: 0.01899448037147522
epoch 96900  training loss: 0.11681415885686874
epoch 96900  clean testing loss: 0.01899375207722187
epoch 97000  training loss: 0.11681413650512695
epoch 97000  clean testing loss: 0.018993809819221497

 98%|█████████▊| 97651/100000 [05:44<00:08, 286.91it/s]
epoch 97100  training loss: 0.11681412160396576
epoch 97100  clean testing loss: 0.018993984907865524
epoch 97200  training loss: 0.11681404709815979
epoch 97200  clean testing loss: 0.018993929028511047
epoch 97300  training loss: 0.11681406944990158
epoch 97300  clean testing loss: 0.01899433694779873
epoch 97400  training loss: 0.11681408435106277
epoch 97400  clean testing loss: 0.0189935602247715
epoch 97500  training loss: 0.11681398749351501
epoch 97500  clean testing loss: 0.018993502482771873
epoch 97600  training loss: 0.11681404709815979

 98%|█████████▊| 98207/100000 [05:46<00:06, 285.24it/s]
epoch 97700  training loss: 0.11681398749351501
epoch 97700  clean testing loss: 0.018994003534317017
epoch 97800  training loss: 0.1168140321969986
epoch 97800  clean testing loss: 0.0189936775714159
epoch 97900  training loss: 0.116814024746418
epoch 97900  clean testing loss: 0.01899365894496441
epoch 98000  training loss: 0.11681389808654785
epoch 98000  clean testing loss: 0.018993983045220375
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 98100  training loss: 0.11681389808654785
epoch 98100  clean testing loss: 0.018993794918060303
epoch 98200  training loss: 0.11681395024061203

 99%|█████████▉| 98793/100000 [05:48<00:04, 288.54it/s]
epoch 98300  training loss: 0.11681389808654785
epoch 98300  clean testing loss: 0.018993888050317764
epoch 98400  training loss: 0.1168140321969986
epoch 98400  clean testing loss: 0.018994146957993507
epoch 98500  training loss: 0.11681391298770905
epoch 98500  clean testing loss: 0.018993442878127098
epoch 98600  training loss: 0.1168140098452568
epoch 98600  clean testing loss: 0.018994171172380447
epoch 98700  training loss: 0.11681398749351501
epoch 98700  clean testing loss: 0.018993740901350975
epoch 98800  training loss: 0.11681385338306427

 99%|█████████▉| 99349/100000 [05:50<00:02, 286.85it/s]
epoch 98900  training loss: 0.11681386083364487
epoch 98900  clean testing loss: 0.018993664532899857
epoch 99000  training loss: 0.11681383848190308
epoch 99000  clean testing loss: 0.018993539735674858
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...
epoch 99100  training loss: 0.1168137937784195
epoch 99100  clean testing loss: 0.018993830308318138
epoch 99200  training loss: 0.11681381613016129
epoch 99200  clean testing loss: 0.01899409480392933
epoch 99300  training loss: 0.11681381613016129

100%|█████████▉| 99932/100000 [05:52<00:00, 286.30it/s]
epoch 99400  training loss: 0.11681381613016129
epoch 99400  clean testing loss: 0.01899404078722
epoch 99500  training loss: 0.1168137937784195
epoch 99500  clean testing loss: 0.018993614241480827
epoch 99600  training loss: 0.11681383103132248
epoch 99600  clean testing loss: 0.01899382658302784
epoch 99700  training loss: 0.1168137639760971
epoch 99700  clean testing loss: 0.018993567675352097
epoch 99800  training loss: 0.1168137788772583
epoch 99800  clean testing loss: 0.018993455916643143
epoch 99900  training loss: 0.1168137937784195

100%|██████████| 100000/100000 [05:52<00:00, 283.74it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size5000_noise1.00e-01_invop0_lr0.005 ...