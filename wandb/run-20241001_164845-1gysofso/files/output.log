
  0%|          | 668/300000 [00:01<09:46, 510.40it/s]
epoch 0  training loss: 0.9441112279891968
epoch 0  clean testing loss: 0.5003780722618103
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-01_invop0 ...
epoch 100  training loss: 0.6491478085517883
epoch 100  clean testing loss: 0.15424948930740356
epoch 200  training loss: 0.589629590511322
epoch 200  clean testing loss: 0.09512262046337128
epoch 300  training loss: 0.5571102499961853
epoch 300  clean testing loss: 0.0801306739449501
epoch 400  training loss: 0.5328588485717773
epoch 400  clean testing loss: 0.07519108802080154
epoch 500  training loss: 0.5209676027297974
epoch 500  clean testing loss: 0.07534937560558319
epoch 600  training loss: 0.5141452550888062
epoch 600  clean testing loss: 0.07465103268623352
epoch 700  training loss: 0.5088512301445007

  1%|          | 1658/300000 [00:03<11:15, 441.39it/s]
epoch 800  training loss: 0.5041573643684387
epoch 800  clean testing loss: 0.07530699670314789
epoch 900  training loss: 0.4998036026954651
epoch 900  clean testing loss: 0.07623951882123947
epoch 1000  training loss: 0.4955950677394867
epoch 1000  clean testing loss: 0.07713297009468079
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-01_invop0 ...
epoch 1100  training loss: 0.49132126569747925
epoch 1100  clean testing loss: 0.07842560112476349
epoch 1200  training loss: 0.48699814081192017
epoch 1200  clean testing loss: 0.07924717664718628
epoch 1300  training loss: 0.4826172888278961
epoch 1300  clean testing loss: 0.08020856231451035
epoch 1400  training loss: 0.47829753160476685
epoch 1400  clean testing loss: 0.08033118396997452
epoch 1500  training loss: 0.47404977679252625
epoch 1500  clean testing loss: 0.08158514648675919
epoch 1600  training loss: 0.4700918197631836
epoch 1600  clean testing loss: 0.0848051980137825
epoch 1700  training loss: 0.4658576250076294

  1%|          | 2694/300000 [00:05<09:36, 515.32it/s]
epoch 1800  training loss: 0.46138009428977966
epoch 1800  clean testing loss: 0.08671624958515167
epoch 1900  training loss: 0.4568578898906708
epoch 1900  clean testing loss: 0.08671572804450989
epoch 2000  training loss: 0.45240968465805054
epoch 2000  clean testing loss: 0.09047383815050125
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-01_invop0 ...
epoch 2100  training loss: 0.4477074146270752
epoch 2100  clean testing loss: 0.09007782489061356
epoch 2200  training loss: 0.4425577223300934
epoch 2200  clean testing loss: 0.09179898351430893
epoch 2300  training loss: 0.4380747973918915
epoch 2300  clean testing loss: 0.0950125977396965
epoch 2400  training loss: 0.43290475010871887
epoch 2400  clean testing loss: 0.09773692488670349
epoch 2500  training loss: 0.42828142642974854
epoch 2500  clean testing loss: 0.09741661697626114
epoch 2600  training loss: 0.4234621822834015
epoch 2600  clean testing loss: 0.0996313989162445
epoch 2700  training loss: 0.4196901321411133

  1%|          | 3687/300000 [00:07<09:36, 514.21it/s]
epoch 2800  training loss: 0.4149532914161682
epoch 2800  clean testing loss: 0.10383290797472
epoch 2900  training loss: 0.4108588993549347
epoch 2900  clean testing loss: 0.10836922377347946
epoch 3000  training loss: 0.4073048233985901
epoch 3000  clean testing loss: 0.11024414747953415
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-01_invop0 ...
epoch 3100  training loss: 0.40303486585617065
epoch 3100  clean testing loss: 0.11161274462938309
epoch 3200  training loss: 0.3997558653354645
epoch 3200  clean testing loss: 0.11401959508657455
epoch 3300  training loss: 0.396838515996933
epoch 3300  clean testing loss: 0.1172778382897377
epoch 3400  training loss: 0.3933011591434479
epoch 3400  clean testing loss: 0.11903499811887741
epoch 3500  training loss: 0.3905990421772003
epoch 3500  clean testing loss: 0.1203608512878418
epoch 3600  training loss: 0.38736531138420105
epoch 3600  clean testing loss: 0.1223730817437172
epoch 3700  training loss: 0.38486939668655396

  1%|▏         | 3897/300000 [00:07<09:33, 515.97it/s]
epoch 3800  training loss: 0.38126465678215027
epoch 3800  clean testing loss: 0.1264665722846985
epoch 3900  training loss: 0.3781501054763794

  2%|▏         | 4726/300000 [00:16<10:57, 448.83it/s]
epoch 4000  training loss: 0.37509170174598694
epoch 4000  clean testing loss: 0.1302223652601242
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-01_invop0 ...
epoch 4100  training loss: 0.37246066331863403
epoch 4100  clean testing loss: 0.13188770413398743
epoch 4200  training loss: 0.36935457587242126
epoch 4200  clean testing loss: 0.13320791721343994
epoch 4300  training loss: 0.36620283126831055
epoch 4300  clean testing loss: 0.1351436972618103
epoch 4400  training loss: 0.36359941959381104
epoch 4400  clean testing loss: 0.13652676343917847
epoch 4500  training loss: 0.35952523350715637
epoch 4500  clean testing loss: 0.1384168118238449
epoch 4600  training loss: 0.3577398359775543
epoch 4600  clean testing loss: 0.14016397297382355
epoch 4700  training loss: 0.3540200889110565
epoch 4700  clean testing loss: 0.1424199342727661
epoch 4800  training loss: 0.3506896495819092

  2%|▏         | 5768/300000 [00:18<09:32, 514.31it/s]
epoch 4900  training loss: 0.3481394350528717
epoch 4900  clean testing loss: 0.14521196484565735
epoch 5000  training loss: 0.3445415496826172
epoch 5000  clean testing loss: 0.14749692380428314
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-01_invop0 ...
epoch 5100  training loss: 0.3430270850658417
epoch 5100  clean testing loss: 0.1501949578523636
epoch 5200  training loss: 0.3391689360141754
epoch 5200  clean testing loss: 0.15144000947475433
epoch 5300  training loss: 0.33608850836753845
epoch 5300  clean testing loss: 0.15216559171676636
epoch 5400  training loss: 0.33215615153312683
epoch 5400  clean testing loss: 0.15357606112957
epoch 5500  training loss: 0.32926031947135925
epoch 5500  clean testing loss: 0.15604816377162933
epoch 5600  training loss: 0.3262351155281067
epoch 5600  clean testing loss: 0.15736514329910278
epoch 5700  training loss: 0.3236405551433563
epoch 5700  clean testing loss: 0.15952850878238678
epoch 5800  training loss: 0.32172396779060364
epoch 5800  clean testing loss: 0.1626342087984085
epoch 5900  training loss: 0.3186571002006531
epoch 5900  clean testing loss: 0.16411054134368896
epoch 6000  training loss: 0.31655755639076233
epoch 6000  clean testing loss: 0.1655096858739853
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size500_noise5.00e-01_invop0 ...
epoch 6100  training loss: 0.3129585087299347
epoch 6100  clean testing loss: 0.16659343242645264
Validation loss variation < 1e-6, trained to interpolation, stop

  2%|▏         | 6100/300000 [00:19<15:23, 318.25it/s]