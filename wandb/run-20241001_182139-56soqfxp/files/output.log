
  0%|                                                                                | 63/100000 [00:01<33:42, 49.41it/s]
epoch 0  training loss: 49.87559509277344
epoch 0  clean testing loss: 45.33860397338867

  0%|▏                                                                              | 165/100000 [00:03<33:29, 49.67it/s]
epoch 100  training loss: 0.28736743330955505

  0%|▏                                                                              | 265/100000 [00:05<33:29, 49.64it/s]
epoch 200  training loss: 0.2631683945655823

  0%|▎                                                                              | 362/100000 [00:07<33:42, 49.27it/s]
epoch 300  training loss: 0.259079247713089

  0%|▎                                                                              | 460/100000 [00:09<33:27, 49.58it/s]
epoch 400  training loss: 0.25657859444618225

  1%|▍                                                                              | 560/100000 [00:11<33:28, 49.51it/s]
epoch 500  training loss: 0.2547234296798706

  1%|▌                                                                              | 657/100000 [00:13<33:38, 49.22it/s]
epoch 600  training loss: 0.2532867193222046

  1%|▌                                                                              | 758/100000 [00:15<33:14, 49.76it/s]
epoch 700  training loss: 0.25213927030563354

  1%|▋                                                                              | 858/100000 [00:17<33:20, 49.55it/s]
epoch 800  training loss: 0.2511909306049347

  1%|▊                                                                              | 959/100000 [00:19<33:15, 49.64it/s]
epoch 900  training loss: 0.250385046005249

  1%|▊                                                                             | 1057/100000 [00:21<33:05, 49.84it/s]
epoch 1000  training loss: 0.24968157708644867
epoch 1000  clean testing loss: 0.01478345412760973

  1%|▊                                                                             | 1097/100000 [00:22<34:59, 47.12it/s]
epoch 1100  training loss: 0.24905359745025635

  1%|█                                                                             | 1329/100000 [00:27<32:56, 49.92it/s]
epoch 1200  training loss: 0.24848201870918274
epoch 1200  clean testing loss: 0.015476768836379051
epoch 1300  training loss: 0.2479502111673355

  1%|█                                                                             | 1427/100000 [00:29<33:07, 49.60it/s]
epoch 1400  training loss: 0.24744343757629395

  2%|█▏                                                                            | 1529/100000 [00:31<33:07, 49.55it/s]
epoch 1500  training loss: 0.2469472736120224

  2%|█▎                                                                            | 1624/100000 [00:33<33:08, 49.48it/s]
epoch 1600  training loss: 0.24644815921783447

  2%|█▎                                                                            | 1729/100000 [00:35<32:58, 49.67it/s]
epoch 1700  training loss: 0.24593181908130646

  2%|█▍                                                                            | 1826/100000 [00:37<33:01, 49.55it/s]
epoch 1800  training loss: 0.2453818917274475
epoch 1800  clean testing loss: 0.018285170197486877
epoch 1900  training loss: 0.24477744102478027

  2%|█▌                                                                            | 1926/100000 [00:39<32:57, 49.59it/s]
epoch 2000  training loss: 0.2440902590751648
epoch 2000  clean testing loss: 0.019513161852955818

  2%|█▌                                                                            | 2027/100000 [00:41<33:19, 48.99it/s]
epoch 2100  training loss: 0.2432813197374344

  2%|█▋                                                                            | 2122/100000 [00:43<32:59, 49.45it/s]
epoch 2200  training loss: 0.2423039674758911

  2%|█▋                                                                            | 2225/100000 [00:45<32:45, 49.74it/s]
epoch 2300  training loss: 0.24112214148044586

  2%|█▊                                                                            | 2325/100000 [00:47<32:50, 49.57it/s]
epoch 2400  training loss: 0.23978431522846222

  2%|█▉                                                                            | 2421/100000 [00:49<33:26, 48.63it/s]
epoch 2500  training loss: 0.23845109343528748

  3%|█▉                                                                            | 2522/100000 [00:51<32:46, 49.57it/s]
epoch 2600  training loss: 0.23718424141407013

  3%|██                                                                            | 2618/100000 [00:53<32:36, 49.76it/s]
epoch 2700  training loss: 0.2358863353729248

  3%|██                                                                            | 2722/100000 [00:55<32:42, 49.56it/s]
epoch 2800  training loss: 0.23447971045970917

  3%|██▏                                                                           | 2818/100000 [00:57<32:41, 49.54it/s]
epoch 2900  training loss: 0.23291748762130737

  3%|██▎                                                                           | 2919/100000 [00:59<32:42, 49.48it/s]
epoch 3000  training loss: 0.23116053640842438
epoch 3000  clean testing loss: 0.03307995945215225

  3%|██▎                                                                           | 3020/100000 [01:01<33:10, 48.73it/s]
epoch 3100  training loss: 0.22963286936283112

  3%|██▍                                                                           | 3116/100000 [01:03<32:40, 49.41it/s]
epoch 3200  training loss: 0.2281554639339447

  3%|██▌                                                                           | 3217/100000 [01:05<32:34, 49.52it/s]
epoch 3300  training loss: 0.2268698513507843

  3%|██▌                                                                           | 3317/100000 [01:07<32:27, 49.64it/s]
epoch 3400  training loss: 0.2256719321012497

  3%|██▋                                                                           | 3418/100000 [01:09<32:24, 49.68it/s]
epoch 3500  training loss: 0.22441399097442627

  4%|██▋                                                                           | 3514/100000 [01:11<32:25, 49.60it/s]
epoch 3600  training loss: 0.22302457690238953

  4%|██▊                                                                           | 3614/100000 [01:13<32:27, 49.50it/s]
epoch 3700  training loss: 0.22150123119354248


  4%|██▉                                                                           | 3815/100000 [01:17<33:43, 47.54it/s]
epoch 3800  training loss: 0.2198910415172577
epoch 3800  clean testing loss: 0.0528758279979229
epoch 3900  training loss: 0.2181941568851471

  4%|███                                                                           | 3910/100000 [01:19<32:20, 49.51it/s]
epoch 4000  training loss: 0.21634449064731598
epoch 4000  clean testing loss: 0.0580255463719368

  4%|███▏                                                                          | 4010/100000 [01:21<33:27, 47.80it/s]
epoch 4100  training loss: 0.21445493400096893

  4%|███▏                                                                          | 4110/100000 [01:23<32:21, 49.40it/s]
epoch 4200  training loss: 0.21293549239635468

  4%|███▎                                                                          | 4211/100000 [01:25<32:16, 49.48it/s]
epoch 4300  training loss: 0.21150490641593933

  4%|███▎                                                                          | 4307/100000 [01:27<31:49, 50.11it/s]
epoch 4400  training loss: 0.2101382464170456

  4%|███▍                                                                          | 4410/100000 [01:29<31:56, 49.87it/s]
epoch 4500  training loss: 0.20863379538059235

  5%|███▌                                                                          | 4507/100000 [01:31<32:03, 49.65it/s]
epoch 4600  training loss: 0.20698127150535583

  5%|███▌                                                                          | 4607/100000 [01:33<32:08, 49.47it/s]
epoch 4700  training loss: 0.20515091717243195

  5%|███▋                                                                          | 4707/100000 [01:35<32:02, 49.56it/s]
epoch 4800  training loss: 0.20341932773590088

  5%|███▋                                                                          | 4807/100000 [01:37<32:01, 49.55it/s]
epoch 4900  training loss: 0.20188850164413452


  5%|███▉                                                                          | 5004/100000 [01:41<33:22, 47.45it/s]
epoch 5000  training loss: 0.20142309367656708
epoch 5000  clean testing loss: 0.091849185526371

  5%|███▉                                                                          | 5104/100000 [01:43<31:58, 49.47it/s]
epoch 5100  training loss: 0.19898779690265656

  5%|████                                                                          | 5204/100000 [01:45<31:57, 49.45it/s]
epoch 5200  training loss: 0.19739088416099548


  5%|████▏                                                                         | 5404/100000 [01:49<31:43, 49.69it/s]
epoch 5300  training loss: 0.19564035534858704

  6%|████▎                                                                         | 5500/100000 [01:51<31:48, 49.53it/s]
epoch 5400  training loss: 0.19366469979286194

  6%|████▎                                                                         | 5600/100000 [01:53<31:46, 49.51it/s]
epoch 5500  training loss: 0.19174592196941376
epoch 5500  clean testing loss: 0.11352115869522095
epoch 5600  training loss: 0.1906006634235382

  6%|████▍                                                                         | 5699/100000 [01:55<31:47, 49.45it/s]
epoch 5700  training loss: 0.18841367959976196

  6%|████▌                                                                         | 5801/100000 [01:57<31:41, 49.53it/s]
epoch 5800  training loss: 0.1865987628698349

  6%|████▌                                                                         | 5901/100000 [01:59<31:44, 49.40it/s]
epoch 5900  training loss: 0.1844414621591568

  6%|████▋                                                                         | 6001/100000 [02:01<31:56, 49.04it/s]
epoch 6000  training loss: 0.18202057480812073
epoch 6000  clean testing loss: 0.15285025537014008

  6%|████▊                                                                         | 6097/100000 [02:03<31:34, 49.56it/s]
epoch 6100  training loss: 0.17976468801498413


  6%|████▉                                                                         | 6298/100000 [02:07<31:29, 49.59it/s]
epoch 6200  training loss: 0.17742590606212616

  6%|████▉                                                                         | 6394/100000 [02:09<31:28, 49.56it/s]
epoch 6300  training loss: 0.1750406175851822

  6%|█████                                                                         | 6496/100000 [02:11<31:24, 49.61it/s]
epoch 6400  training loss: 0.17275992035865784

  7%|█████▏                                                                        | 6593/100000 [02:13<31:19, 49.69it/s]
epoch 6500  training loss: 0.1707329899072647

  7%|█████▏                                                                        | 6693/100000 [02:15<31:22, 49.57it/s]
epoch 6600  training loss: 0.16842927038669586

  7%|█████▎                                                                        | 6793/100000 [02:17<31:18, 49.63it/s]
epoch 6700  training loss: 0.16589397192001343

  7%|█████▍                                                                        | 6893/100000 [02:19<31:19, 49.54it/s]
epoch 6800  training loss: 0.1634208858013153

  7%|█████▍                                                                        | 6993/100000 [02:21<31:13, 49.65it/s]
epoch 6900  training loss: 0.16073305904865265

  7%|█████▎                                                                      | 7023/100000 [02:23<1:03:25, 24.43it/s]
epoch 7000  training loss: 0.15770410001277924
epoch 7000  clean testing loss: 0.26987868547439575

  7%|█████▌                                                                        | 7118/100000 [02:25<31:17, 49.46it/s]
epoch 7100  training loss: 0.15473572909832

  7%|█████▋                                                                        | 7218/100000 [02:27<31:14, 49.51it/s]
epoch 7200  training loss: 0.15210868418216705

  7%|█████▋                                                                        | 7320/100000 [02:29<31:01, 49.80it/s]
epoch 7300  training loss: 0.15204235911369324

  7%|█████▊                                                                        | 7391/100000 [02:30<31:09, 49.55it/s]
epoch 7400  training loss: 0.14733511209487915

  7%|█████▊                                                                        | 7492/100000 [02:32<30:54, 49.88it/s]
epoch 7500  training loss: 0.14496146142482758

  8%|█████▉                                                                        | 7594/100000 [02:35<30:55, 49.81it/s]
epoch 7600  training loss: 0.14680804312229156

  8%|██████                                                                        | 7694/100000 [02:37<30:59, 49.65it/s]
epoch 7700  training loss: 0.13936178386211395

  8%|██████                                                                        | 7794/100000 [02:39<30:58, 49.61it/s]
epoch 7800  training loss: 0.13612894713878632

  8%|██████▏                                                                       | 7889/100000 [02:40<30:57, 49.59it/s]
epoch 7900  training loss: 0.1323917657136917

  8%|██████▏                                                                       | 7989/100000 [02:42<30:58, 49.50it/s]
epoch 8000  training loss: 0.1288018822669983
epoch 8000  clean testing loss: 0.40425917506217957

  8%|██████▎                                                                       | 8091/100000 [02:45<30:46, 49.76it/s]
epoch 8100  training loss: 0.12527301907539368

  8%|██████▍                                                                       | 8191/100000 [02:47<30:52, 49.55it/s]
epoch 8200  training loss: 0.12220549583435059

  8%|██████▍                                                                       | 8291/100000 [02:49<30:58, 49.34it/s]
epoch 8300  training loss: 0.11919689178466797

  8%|██████▌                                                                       | 8387/100000 [02:51<32:17, 47.28it/s]
epoch 8400  training loss: 0.11662479490041733

  8%|██████▌                                                                       | 8488/100000 [02:53<30:44, 49.61it/s]
epoch 8500  training loss: 0.1144832968711853

  9%|██████▋                                                                       | 8589/100000 [02:55<30:40, 49.67it/s]
epoch 8600  training loss: 0.11188895255327225


  9%|██████▊                                                                       | 8788/100000 [02:59<30:41, 49.53it/s]
epoch 8700  training loss: 0.10934403538703918

  9%|██████▉                                                                       | 8884/100000 [03:01<30:40, 49.52it/s]
epoch 8800  training loss: 0.10708379745483398

  9%|███████                                                                       | 8984/100000 [03:03<30:44, 49.34it/s]
epoch 8900  training loss: 0.10485124588012695

  9%|███████                                                                       | 9084/100000 [03:05<30:34, 49.55it/s]
epoch 9000  training loss: 0.10458417236804962
epoch 9000  clean testing loss: 0.5697170495986938

  9%|███████▏                                                                      | 9185/100000 [03:07<30:33, 49.54it/s]
epoch 9100  training loss: 0.10091182589530945

  9%|███████▏                                                                      | 9281/100000 [03:09<30:20, 49.84it/s]
epoch 9200  training loss: 0.09912537038326263

  9%|███████▎                                                                      | 9382/100000 [03:11<30:29, 49.52it/s]
epoch 9300  training loss: 0.09726583957672119

  9%|███████▍                                                                      | 9482/100000 [03:13<30:28, 49.49it/s]
epoch 9400  training loss: 0.09531775116920471

 10%|███████▍                                                                      | 9583/100000 [03:15<30:22, 49.62it/s]
epoch 9500  training loss: 0.09351162612438202

 10%|███████▌                                                                      | 9683/100000 [03:17<30:20, 49.60it/s]
epoch 9600  training loss: 0.09141877293586731

 10%|███████▋                                                                      | 9778/100000 [03:19<30:19, 49.59it/s]
epoch 9700  training loss: 0.08954257518053055

 10%|███████▋                                                                      | 9878/100000 [03:21<30:19, 49.53it/s]
epoch 9800  training loss: 0.08770465850830078

 10%|███████▊                                                                      | 9978/100000 [03:23<31:10, 48.14it/s]
epoch 9900  training loss: 0.08591197431087494

 10%|███████▊                                                                     | 10078/100000 [03:25<30:36, 48.96it/s]
epoch 10000  training loss: 0.08432392030954361
epoch 10000  clean testing loss: 0.8321171402931213
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 10100  training loss: 0.08439178019762039

 10%|███████▊                                                                     | 10175/100000 [03:27<30:05, 49.75it/s]
epoch 10200  training loss: 0.08098333328962326

 10%|███████▉                                                                     | 10276/100000 [03:29<29:53, 50.03it/s]
epoch 10300  training loss: 0.08163020759820938

 10%|███████▉                                                                     | 10377/100000 [03:31<30:08, 49.56it/s]
epoch 10400  training loss: 0.07812361419200897

 10%|████████                                                                     | 10473/100000 [03:33<30:02, 49.66it/s]
epoch 10500  training loss: 0.07639501988887787

 11%|████████▏                                                                    | 10573/100000 [03:35<29:49, 49.96it/s]
epoch 10600  training loss: 0.07864014059305191

 11%|████████▏                                                                    | 10673/100000 [03:37<30:01, 49.57it/s]
epoch 10700  training loss: 0.07374037802219391

 11%|████████▎                                                                    | 10773/100000 [03:39<30:02, 49.51it/s]
epoch 10800  training loss: 0.07245976477861404

 11%|████████▎                                                                    | 10871/100000 [03:41<29:55, 49.64it/s]
epoch 10900  training loss: 0.07244312763214111

 11%|████████▍                                                                    | 10971/100000 [03:43<29:58, 49.49it/s]
epoch 11000  training loss: 0.07038027048110962
epoch 11000  clean testing loss: 1.3939588069915771

 11%|████████▌                                                                    | 11073/100000 [03:45<29:52, 49.62it/s]
epoch 11100  training loss: 0.06904084980487823

 11%|████████▌                                                                    | 11169/100000 [03:47<29:54, 49.50it/s]
epoch 11200  training loss: 0.06803174316883087

 11%|████████▋                                                                    | 11270/100000 [03:49<29:52, 49.50it/s]
epoch 11300  training loss: 0.07320917397737503

 11%|████████▊                                                                    | 11372/100000 [03:51<29:46, 49.61it/s]
epoch 11400  training loss: 0.06610653549432755

 11%|████████▊                                                                    | 11467/100000 [03:53<29:49, 49.48it/s]
epoch 11500  training loss: 0.06526978313922882

 12%|████████▉                                                                    | 11567/100000 [03:55<29:26, 50.06it/s]
epoch 11600  training loss: 0.06430954486131668

 12%|████████▉                                                                    | 11669/100000 [03:57<29:33, 49.80it/s]
epoch 11700  training loss: 0.06346480548381805

 12%|█████████                                                                    | 11770/100000 [03:59<29:43, 49.47it/s]
epoch 11800  training loss: 0.06255452334880829

 12%|█████████▏                                                                   | 11865/100000 [04:01<29:39, 49.54it/s]
epoch 11900  training loss: 0.061689600348472595


 12%|█████████▎                                                                   | 12069/100000 [04:05<29:32, 49.61it/s]
epoch 12000  training loss: 0.060948148369789124
epoch 12000  clean testing loss: 1.7934517860412598
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 12100  training loss: 0.06008305773139

 12%|█████████▎                                                                   | 12164/100000 [04:07<29:32, 49.56it/s]
epoch 12200  training loss: 0.05933021754026413

 12%|█████████▍                                                                   | 12265/100000 [04:09<29:32, 49.50it/s]
epoch 12300  training loss: 0.058531541377305984

 12%|█████████▌                                                                   | 12366/100000 [04:11<29:27, 49.58it/s]
epoch 12400  training loss: 0.0632471889257431


 13%|█████████▋                                                                   | 12565/100000 [04:15<29:14, 49.84it/s]
epoch 12500  training loss: 0.05686306208372116

 13%|█████████▊                                                                   | 12666/100000 [04:17<29:19, 49.63it/s]
epoch 12600  training loss: 0.05699005350470543

 13%|█████████▊                                                                   | 12761/100000 [04:19<29:25, 49.41it/s]
epoch 12700  training loss: 0.055131107568740845

 13%|█████████▉                                                                   | 12861/100000 [04:21<29:20, 49.50it/s]
epoch 12800  training loss: 0.05428824946284294

 13%|█████████▉                                                                   | 12961/100000 [04:23<29:23, 49.36it/s]
epoch 12900  training loss: 0.05412950739264488

 13%|██████████                                                                   | 13059/100000 [04:25<29:16, 49.49it/s]
epoch 13000  training loss: 0.05255575850605965
epoch 13000  clean testing loss: 2.0194666385650635

 13%|██████████▏                                                                  | 13159/100000 [04:27<29:13, 49.53it/s]
epoch 13100  training loss: 0.05163112282752991

 13%|██████████▏                                                                  | 13260/100000 [04:29<29:11, 49.52it/s]
epoch 13200  training loss: 0.05078321322798729

 13%|██████████▎                                                                  | 13368/100000 [04:31<25:53, 55.76it/s]
epoch 13300  training loss: 0.05000364035367966

 13%|██████████▎                                                                  | 13467/100000 [04:33<29:09, 49.46it/s]
epoch 13400  training loss: 0.05380958691239357
epoch 13400  clean testing loss: 2.134812593460083
epoch 13500  training loss: 0.048218805342912674

 14%|██████████▍                                                                  | 13566/100000 [04:35<28:48, 50.02it/s]
epoch 13600  training loss: 0.04741242527961731

 14%|██████████▌                                                                  | 13662/100000 [04:37<29:04, 49.50it/s]
epoch 13700  training loss: 0.04829207807779312

 14%|██████████▌                                                                  | 13762/100000 [04:39<28:57, 49.62it/s]
epoch 13800  training loss: 0.04591036215424538

 14%|██████████▋                                                                  | 13862/100000 [04:41<28:57, 49.57it/s]
epoch 13900  training loss: 0.04512413218617439

 14%|██████████▊                                                                  | 13963/100000 [04:43<28:57, 49.52it/s]
epoch 14000  training loss: 0.04450124874711037
epoch 14000  clean testing loss: 2.3184456825256348


 14%|██████████▉                                                                  | 14160/100000 [04:47<28:52, 49.53it/s]
epoch 14100  training loss: 0.04471016302704811

 14%|██████████▉                                                                  | 14260/100000 [04:49<28:51, 49.50it/s]
epoch 14200  training loss: 0.04311271011829376

 14%|███████████                                                                  | 14360/100000 [04:51<28:48, 49.55it/s]
epoch 14300  training loss: 0.042393848299980164

 14%|███████████▏                                                                 | 14456/100000 [04:53<28:47, 49.50it/s]
epoch 14400  training loss: 0.04174734279513359
epoch 14400  clean testing loss: 2.4598867893218994
epoch 14500  training loss: 0.041205890476703644

 15%|███████████▏                                                                 | 14559/100000 [04:55<28:12, 50.47it/s]
epoch 14600  training loss: 0.04128267988562584

 15%|███████████▎                                                                 | 14656/100000 [04:57<28:39, 49.63it/s]
epoch 14700  training loss: 0.04013770818710327

 15%|███████████▎                                                                 | 14757/100000 [04:59<28:44, 49.44it/s]
epoch 14800  training loss: 0.039609599858522415

 15%|███████████▍                                                                 | 14857/100000 [05:01<28:37, 49.57it/s]
epoch 14900  training loss: 0.039269596338272095

 15%|███████████▌                                                                 | 14953/100000 [05:03<28:35, 49.57it/s]
epoch 15000  training loss: 0.04063394293189049
epoch 15000  clean testing loss: 2.6983766555786133

 15%|███████████▌                                                                 | 15054/100000 [05:05<28:34, 49.56it/s]
epoch 15100  training loss: 0.03825679421424866

 15%|███████████▋                                                                 | 15155/100000 [05:07<28:24, 49.78it/s]
epoch 15200  training loss: 0.037892092019319534

 15%|███████████▋                                                                 | 15251/100000 [05:09<28:44, 49.13it/s]
epoch 15300  training loss: 0.03751925751566887

 15%|███████████▊                                                                 | 15351/100000 [05:11<28:28, 49.54it/s]
epoch 15400  training loss: 0.0371372252702713

 15%|███████████▉                                                                 | 15448/100000 [05:13<28:22, 49.66it/s]
epoch 15500  training loss: 0.03675677627325058

 16%|███████████▉                                                                 | 15550/100000 [05:15<27:59, 50.29it/s]
epoch 15600  training loss: 0.03637705370783806

 16%|████████████                                                                 | 15649/100000 [05:17<28:41, 48.99it/s]
epoch 15700  training loss: 0.036021653562784195

 16%|████████████▏                                                                | 15750/100000 [05:19<28:31, 49.23it/s]
epoch 15800  training loss: 0.035791367292404175

 16%|████████████▏                                                                | 15845/100000 [05:21<28:18, 49.55it/s]
epoch 15900  training loss: 0.03536761552095413

 16%|████████████▎                                                                | 15946/100000 [05:23<28:08, 49.77it/s]
epoch 16000  training loss: 0.0349801667034626
epoch 16000  clean testing loss: 3.1425862312316895

 16%|████████████▎                                                                | 16046/100000 [05:25<28:20, 49.38it/s]
epoch 16100  training loss: 0.034633830189704895

 16%|████████████▍                                                                | 16147/100000 [05:27<28:14, 49.49it/s]
epoch 16200  training loss: 0.03453035280108452

 16%|████████████▍                                                                | 16207/100000 [05:28<28:10, 49.58it/s]
epoch 16300  training loss: 0.03400220721960068

 16%|████████████▌                                                                | 16299/100000 [05:30<28:09, 49.54it/s]
epoch 16400  training loss: 0.03392898663878441

 16%|████████████▋                                                                | 16448/100000 [05:33<28:01, 49.68it/s]
epoch 16500  training loss: 0.03339993208646774

 17%|████████████▋                                                                | 16543/100000 [05:35<28:21, 49.06it/s]
epoch 16600  training loss: 0.03307165205478668


 17%|████████████▉                                                                | 16744/100000 [05:39<28:01, 49.51it/s]
epoch 16700  training loss: 0.032959260046482086

 17%|████████████▉                                                                | 16844/100000 [05:41<27:59, 49.51it/s]
epoch 16800  training loss: 0.032550327479839325

 17%|█████████████                                                                | 16940/100000 [05:43<27:54, 49.59it/s]
epoch 16900  training loss: 0.03221321105957031

 17%|█████████████                                                                | 17040/100000 [05:45<28:00, 49.37it/s]
epoch 17000  training loss: 0.033767908811569214
epoch 17000  clean testing loss: 3.6446027755737305

 17%|█████████████▏                                                               | 17142/100000 [05:47<27:50, 49.61it/s]
epoch 17100  training loss: 0.0317516103386879

 17%|█████████████▎                                                               | 17238/100000 [05:49<27:43, 49.74it/s]
epoch 17200  training loss: 0.03187599405646324

 17%|█████████████▎                                                               | 17342/100000 [05:51<27:46, 49.59it/s]
epoch 17300  training loss: 0.03294258564710617

 17%|█████████████▍                                                               | 17441/100000 [05:53<27:45, 49.56it/s]
epoch 17400  training loss: 0.03096301108598709

 18%|█████████████▌                                                               | 17536/100000 [05:55<27:45, 49.53it/s]
epoch 17500  training loss: 0.030662713572382927

 18%|█████████████▌                                                               | 17641/100000 [05:57<27:44, 49.49it/s]
epoch 17600  training loss: 0.03043193928897381

 18%|█████████████▋                                                               | 17740/100000 [05:59<27:28, 49.89it/s]
epoch 17700  training loss: 0.030154531821608543

 18%|█████████████▋                                                               | 17836/100000 [06:01<27:36, 49.60it/s]
epoch 17800  training loss: 0.02991371974349022

 18%|█████████████▊                                                               | 17936/100000 [06:03<27:33, 49.64it/s]
epoch 17900  training loss: 0.031048525124788284

 18%|█████████████▉                                                               | 18036/100000 [06:05<27:44, 49.23it/s]
epoch 18000  training loss: 0.03001122549176216
epoch 18000  clean testing loss: 4.193731784820557

 18%|█████████████▉                                                               | 18137/100000 [06:07<27:31, 49.57it/s]
epoch 18100  training loss: 0.02924356423318386

 18%|██████████████                                                               | 18237/100000 [06:09<27:31, 49.51it/s]
epoch 18200  training loss: 0.029041219502687454

 18%|██████████████                                                               | 18308/100000 [06:11<27:29, 49.52it/s]
epoch 18300  training loss: 0.028830107301473618

 18%|██████████████▏                                                              | 18405/100000 [06:13<27:33, 49.35it/s]
epoch 18400  training loss: 0.028609437867999077

 19%|██████████████▏                                                              | 18506/100000 [06:15<27:19, 49.71it/s]
epoch 18500  training loss: 0.028391189873218536

 19%|██████████████▎                                                              | 18607/100000 [06:17<27:17, 49.70it/s]
epoch 18600  training loss: 0.028170034289360046

 19%|██████████████▍                                                              | 18707/100000 [06:19<27:23, 49.47it/s]
epoch 18700  training loss: 0.02795298397541046

 19%|██████████████▍                                                              | 18807/100000 [06:21<27:16, 49.61it/s]
epoch 18800  training loss: 0.02774309366941452

 19%|██████████████▌                                                              | 18903/100000 [06:23<27:18, 49.49it/s]
epoch 18900  training loss: 0.02758307196199894

 19%|██████████████▋                                                              | 19004/100000 [06:25<28:24, 47.51it/s]
epoch 19000  training loss: 0.02733948640525341
epoch 19000  clean testing loss: 4.762433052062988

 19%|██████████████▋                                                              | 19105/100000 [06:27<27:12, 49.56it/s]
epoch 19100  training loss: 0.027176782488822937

 19%|██████████████▊                                                              | 19203/100000 [06:29<27:01, 49.84it/s]
epoch 19200  training loss: 0.026884637773036957

 19%|██████████████▊                                                              | 19298/100000 [06:31<27:09, 49.51it/s]
epoch 19300  training loss: 0.02683129906654358

 19%|██████████████▉                                                              | 19404/100000 [06:33<26:59, 49.76it/s]
epoch 19400  training loss: 0.02646573819220066

 20%|███████████████                                                              | 19504/100000 [06:35<27:04, 49.55it/s]
epoch 19500  training loss: 0.026268362998962402

 20%|███████████████                                                              | 19600/100000 [06:37<27:00, 49.63it/s]
epoch 19600  training loss: 0.026252763345837593

 20%|███████████████▏                                                             | 19700/100000 [06:39<28:03, 47.71it/s]
epoch 19700  training loss: 0.026075489819049835
epoch 19700  clean testing loss: 5.193153381347656
epoch 19800  training loss: 0.02570527233183384

 20%|███████████████▏                                                             | 19800/100000 [06:41<26:57, 49.57it/s]
epoch 19900  training loss: 0.025444185361266136

 20%|███████████████▎                                                             | 19901/100000 [06:43<26:56, 49.56it/s]
epoch 20000  training loss: 0.02524448186159134
epoch 20000  clean testing loss: 5.384474277496338

 20%|███████████████▍                                                             | 19997/100000 [06:45<26:55, 49.53it/s]
epoch 20100  training loss: 0.025746529921889305

 20%|███████████████▍                                                             | 20097/100000 [06:47<26:49, 49.64it/s]
epoch 20200  training loss: 0.024841712787747383

 20%|███████████████▌                                                             | 20197/100000 [06:49<26:52, 49.50it/s]
epoch 20300  training loss: 0.02463211491703987

 20%|███████████████▋                                                             | 20293/100000 [06:51<26:54, 49.38it/s]
epoch 20400  training loss: 0.024436956271529198


 20%|███████████████▊                                                             | 20495/100000 [06:55<26:41, 49.64it/s]
epoch 20500  training loss: 0.024232376366853714

 21%|███████████████▊                                                             | 20595/100000 [06:57<26:38, 49.68it/s]
epoch 20600  training loss: 0.024334760382771492

 21%|███████████████▉                                                             | 20692/100000 [06:59<26:46, 49.37it/s]
epoch 20700  training loss: 0.02389250509440899


 21%|████████████████                                                             | 20888/100000 [07:03<26:32, 49.69it/s]
epoch 20800  training loss: 0.023637555539608

 21%|████████████████▏                                                            | 20989/100000 [07:05<26:33, 49.59it/s]
epoch 20900  training loss: 0.023470746353268623

 21%|████████████████▏                                                            | 21089/100000 [07:07<26:33, 49.52it/s]
epoch 21000  training loss: 0.02324756234884262
epoch 21000  clean testing loss: 6.017147541046143

 21%|████████████████▎                                                            | 21190/100000 [07:09<26:29, 49.59it/s]
epoch 21100  training loss: 0.02308041788637638

 21%|████████████████▍                                                            | 21285/100000 [07:11<26:25, 49.64it/s]
epoch 21200  training loss: 0.02291039749979973

 21%|████████████████▍                                                            | 21386/100000 [07:13<26:13, 49.96it/s]
epoch 21300  training loss: 0.02273254096508026

 21%|████████████████▌                                                            | 21486/100000 [07:15<26:27, 49.45it/s]
epoch 21400  training loss: 0.022545140236616135

 22%|████████████████▌                                                            | 21586/100000 [07:17<26:17, 49.69it/s]
epoch 21500  training loss: 0.02237711101770401

 22%|████████████████▋                                                            | 21686/100000 [07:19<26:18, 49.62it/s]
epoch 21600  training loss: 0.022161228582262993

 22%|████████████████▊                                                            | 21787/100000 [07:21<26:17, 49.57it/s]
epoch 21700  training loss: 0.022031612694263458

 22%|████████████████▊                                                            | 21883/100000 [07:23<26:17, 49.51it/s]
epoch 21800  training loss: 0.021977221593260765

 22%|████████████████▉                                                            | 21984/100000 [07:25<26:08, 49.74it/s]
epoch 21900  training loss: 0.021607110276818275

 22%|█████████████████                                                            | 22081/100000 [07:27<26:14, 49.50it/s]
epoch 22000  training loss: 0.021401388570666313
epoch 22000  clean testing loss: 6.635616779327393

 22%|█████████████████                                                            | 22182/100000 [07:29<26:15, 49.38it/s]
epoch 22100  training loss: 0.02132081612944603

 22%|█████████████████▏                                                           | 22278/100000 [07:31<26:06, 49.63it/s]
epoch 22200  training loss: 0.021181205287575722

 22%|█████████████████▏                                                           | 22379/100000 [07:33<26:03, 49.63it/s]
epoch 22300  training loss: 0.020886322483420372

 22%|█████████████████▎                                                           | 22481/100000 [07:35<26:06, 49.49it/s]
epoch 22400  training loss: 0.020644748583436012

 23%|█████████████████▍                                                           | 22578/100000 [07:37<25:53, 49.83it/s]
epoch 22500  training loss: 0.020456358790397644

 23%|█████████████████▍                                                           | 22679/100000 [07:39<26:00, 49.54it/s]
epoch 22600  training loss: 0.02027180977165699

 23%|█████████████████▌                                                           | 22779/100000 [07:41<25:55, 49.65it/s]
epoch 22700  training loss: 0.020094146952033043

 23%|█████████████████▌                                                           | 22875/100000 [07:43<25:53, 49.63it/s]
epoch 22800  training loss: 0.01990417391061783

 23%|█████████████████▋                                                           | 22975/100000 [07:45<25:55, 49.51it/s]
epoch 22900  training loss: 0.019721779972314835

 23%|█████████████████▊                                                           | 23075/100000 [07:47<27:11, 47.16it/s]
epoch 23000  training loss: 0.01972297765314579
epoch 23000  clean testing loss: 7.299933910369873

 23%|█████████████████▊                                                           | 23171/100000 [07:49<25:51, 49.52it/s]
epoch 23100  training loss: 0.019487254321575165

 23%|█████████████████▉                                                           | 23271/100000 [07:51<25:46, 49.61it/s]
epoch 23200  training loss: 0.01918015070259571

 23%|█████████████████▉                                                           | 23371/100000 [07:53<25:47, 49.53it/s]
epoch 23300  training loss: 0.01900338940322399

 23%|██████████████████                                                           | 23472/100000 [07:55<25:43, 49.57it/s]
epoch 23400  training loss: 0.018970739096403122

 24%|██████████████████▏                                                          | 23573/100000 [07:57<25:31, 49.89it/s]
epoch 23500  training loss: 0.018699826672673225

 24%|██████████████████▏                                                          | 23673/100000 [07:59<25:41, 49.51it/s]
epoch 23600  training loss: 0.018501942977309227

 24%|██████████████████▎                                                          | 23769/100000 [08:01<25:39, 49.53it/s]
epoch 23700  training loss: 0.01829000934958458

 24%|██████████████████▍                                                          | 23869/100000 [08:03<25:38, 49.50it/s]
epoch 23800  training loss: 0.018168676644563675

 24%|██████████████████▍                                                          | 23969/100000 [08:05<25:35, 49.52it/s]
epoch 23900  training loss: 0.018002532422542572

 24%|██████████████████▌                                                          | 24065/100000 [08:07<25:31, 49.57it/s]
epoch 24000  training loss: 0.017801398411393166
epoch 24000  clean testing loss: 8.036009788513184

 24%|██████████████████▌                                                          | 24165/100000 [08:09<25:35, 49.39it/s]
epoch 24100  training loss: 0.017625467851758003

 24%|██████████████████▋                                                          | 24265/100000 [08:11<25:29, 49.50it/s]
epoch 24200  training loss: 0.017477553337812424

 24%|██████████████████▊                                                          | 24365/100000 [08:13<25:29, 49.46it/s]
epoch 24300  training loss: 0.017323100939393044

 24%|██████████████████▊                                                          | 24464/100000 [08:15<25:25, 49.52it/s]
epoch 24400  training loss: 0.017161350697278976

 25%|██████████████████▉                                                          | 24564/100000 [08:17<25:01, 50.25it/s]
epoch 24500  training loss: 0.01706039160490036

 25%|██████████████████▉                                                          | 24662/100000 [08:19<25:20, 49.56it/s]
epoch 24600  training loss: 0.01683238334953785

 25%|███████████████████                                                          | 24762/100000 [08:21<26:13, 47.82it/s]
epoch 24700  training loss: 0.01715528592467308

 25%|███████████████████▏                                                         | 24862/100000 [08:23<25:16, 49.56it/s]
epoch 24800  training loss: 0.01685260608792305

 25%|███████████████████▏                                                         | 24962/100000 [08:25<25:14, 49.55it/s]
epoch 24900  training loss: 0.016360217705368996
epoch 24900  clean testing loss: 8.716968536376953
epoch 25000  training loss: 0.016176171600818634
epoch 25000  clean testing loss: 8.798293113708496


 25%|███████████████████▎                                                         | 25158/100000 [08:29<25:11, 49.51it/s]
epoch 25100  training loss: 0.016008011996746063
epoch 25100  clean testing loss: 8.882158279418945
epoch 25200  training loss: 0.015858449041843414

 25%|███████████████████▍                                                         | 25258/100000 [08:31<25:08, 49.54it/s]
epoch 25300  training loss: 0.015686962753534317


 25%|███████████████████▌                                                         | 25454/100000 [08:35<25:09, 49.38it/s]
epoch 25400  training loss: 0.015582569874823093

 26%|███████████████████▋                                                         | 25552/100000 [08:37<24:43, 50.17it/s]
epoch 25500  training loss: 0.015348355285823345

 26%|███████████████████▊                                                         | 25657/100000 [08:39<25:00, 49.53it/s]
epoch 25600  training loss: 0.015234997496008873

 26%|███████████████████▊                                                         | 25723/100000 [08:41<24:51, 49.80it/s]
epoch 25700  training loss: 0.015031864866614342

 26%|███████████████████▉                                                         | 25954/100000 [08:45<24:52, 49.61it/s]
epoch 25800  training loss: 0.014856264926493168
epoch 25800  clean testing loss: 9.501260757446289
epoch 25900  training loss: 0.014691815711557865

 26%|████████████████████                                                         | 26054/100000 [08:47<24:54, 49.48it/s]
epoch 26000  training loss: 0.014523590914905071
epoch 26000  clean testing loss: 9.688041687011719

 26%|████████████████████                                                         | 26099/100000 [08:48<24:52, 49.51it/s]
epoch 26100  training loss: 0.014365474693477154

 26%|████████████████████▎                                                        | 26336/100000 [08:55<29:39, 41.41it/s]
epoch 26200  training loss: 0.014193257316946983
epoch 26200  clean testing loss: 9.877918243408203
epoch 26300  training loss: 0.014029271900653839

 26%|████████████████████▎                                                        | 26432/100000 [08:57<24:45, 49.52it/s]
epoch 26400  training loss: 0.013861316256225109

 27%|████████████████████▍                                                        | 26532/100000 [08:59<24:43, 49.53it/s]
epoch 26500  training loss: 0.013697086833417416

 27%|████████████████████▌                                                        | 26634/100000 [09:01<24:36, 49.70it/s]
epoch 26600  training loss: 0.013531235046684742

 27%|████████████████████▌                                                        | 26730/100000 [09:03<24:36, 49.62it/s]
epoch 26700  training loss: 0.013368463143706322
epoch 26700  clean testing loss: 10.36977767944336
epoch 26800  training loss: 0.013206344097852707

 27%|████████████████████▋                                                        | 26830/100000 [09:05<24:38, 49.47it/s]
epoch 26900  training loss: 0.013059128075838089

 27%|████████████████████▋                                                        | 26930/100000 [09:07<24:34, 49.57it/s]
epoch 27000  training loss: 0.012871867045760155
epoch 27000  clean testing loss: 10.677526473999023

 27%|████████████████████▊                                                        | 27030/100000 [09:09<24:44, 49.17it/s]
epoch 27100  training loss: 0.012729489244520664

 27%|████████████████████▉                                                        | 27125/100000 [09:11<24:28, 49.61it/s]
epoch 27200  training loss: 0.012585894204676151

 27%|████████████████████▉                                                        | 27225/100000 [09:13<24:27, 49.58it/s]
epoch 27300  training loss: 0.012436673045158386

 27%|█████████████████████                                                        | 27325/100000 [09:15<24:23, 49.67it/s]
epoch 27400  training loss: 0.012279936112463474

 27%|█████████████████████                                                        | 27426/100000 [09:17<25:20, 47.74it/s]
epoch 27500  training loss: 0.012131860479712486

 28%|█████████████████████▏                                                       | 27526/100000 [09:19<24:19, 49.67it/s]
epoch 27600  training loss: 0.011998867616057396

 28%|█████████████████████▎                                                       | 27623/100000 [09:21<24:20, 49.57it/s]
epoch 27700  training loss: 0.012678561732172966

 28%|█████████████████████▎                                                       | 27723/100000 [09:23<24:19, 49.51it/s]
epoch 27800  training loss: 0.011646178551018238

 28%|█████████████████████▍                                                       | 27823/100000 [09:25<24:15, 49.60it/s]
epoch 27900  training loss: 0.011497383937239647

 28%|█████████████████████▌                                                       | 27924/100000 [09:27<24:05, 49.88it/s]
epoch 28000  training loss: 0.011331863701343536
epoch 28000  clean testing loss: 11.67606258392334

 28%|█████████████████████▌                                                       | 28020/100000 [09:29<24:36, 48.75it/s]
epoch 28100  training loss: 0.011179606430232525

 28%|█████████████████████▋                                                       | 28121/100000 [09:31<24:09, 49.58it/s]
epoch 28200  training loss: 0.011059933342039585

 28%|█████████████████████▋                                                       | 28216/100000 [09:33<24:08, 49.55it/s]
epoch 28300  training loss: 0.011101902462542057

 28%|█████████████████████▊                                                       | 28317/100000 [09:35<24:09, 49.46it/s]
epoch 28400  training loss: 0.010730902664363384

 28%|█████████████████████▉                                                       | 28414/100000 [09:37<23:59, 49.73it/s]
epoch 28500  training loss: 0.01085406169295311

 29%|█████████████████████▉                                                       | 28517/100000 [09:39<24:10, 49.28it/s]
epoch 28600  training loss: 0.01060599647462368

 29%|██████████████████████                                                       | 28617/100000 [09:41<23:57, 49.66it/s]
epoch 28700  training loss: 0.010593750514090061

 29%|██████████████████████                                                       | 28715/100000 [09:43<23:49, 49.86it/s]
epoch 28800  training loss: 0.01016739010810852

 29%|██████████████████████▏                                                      | 28790/100000 [09:45<23:56, 49.58it/s]
epoch 28900  training loss: 0.01004426833242178

 29%|██████████████████████▏                                                      | 28891/100000 [09:47<23:52, 49.63it/s]
epoch 29000  training loss: 0.01010688953101635
epoch 29000  clean testing loss: 12.707395553588867

 29%|██████████████████████▎                                                      | 28987/100000 [09:49<23:53, 49.55it/s]
epoch 29100  training loss: 0.009774232283234596

 29%|██████████████████████▍                                                      | 29087/100000 [09:51<23:50, 49.58it/s]
epoch 29200  training loss: 0.010281396098434925


 29%|██████████████████████▌                                                      | 29282/100000 [09:55<23:52, 49.38it/s]
epoch 29300  training loss: 0.009512573480606079

 29%|██████████████████████▋                                                      | 29384/100000 [09:57<23:40, 49.71it/s]
epoch 29400  training loss: 0.00939110666513443

 29%|██████████████████████▋                                                      | 29484/100000 [09:59<23:42, 49.57it/s]
epoch 29500  training loss: 0.009273684583604336

 30%|██████████████████████▊                                                      | 29583/100000 [10:01<23:36, 49.70it/s]
epoch 29600  training loss: 0.009179194457828999

 30%|██████████████████████▊                                                      | 29680/100000 [10:03<23:40, 49.50it/s]
epoch 29700  training loss: 0.009085243567824364

 30%|██████████████████████▉                                                      | 29780/100000 [10:05<23:35, 49.62it/s]
epoch 29800  training loss: 0.008937218226492405

 30%|███████████████████████                                                      | 29881/100000 [10:07<23:37, 49.46it/s]
epoch 29900  training loss: 0.0088290274143219

 30%|███████████████████████                                                      | 29982/100000 [10:09<23:30, 49.64it/s]
epoch 30000  training loss: 0.00873218011111021
epoch 30000  clean testing loss: 13.596792221069336

 30%|███████████████████████▏                                                     | 30077/100000 [10:11<23:30, 49.57it/s]
epoch 30100  training loss: 0.008640341460704803

 30%|███████████████████████▏                                                     | 30179/100000 [10:13<23:28, 49.58it/s]
epoch 30200  training loss: 0.008554179221391678

 30%|███████████████████████▎                                                     | 30279/100000 [10:15<23:28, 49.50it/s]
epoch 30300  training loss: 0.00846539530903101

 30%|███████████████████████▍                                                     | 30382/100000 [10:17<20:00, 57.97it/s]
epoch 30400  training loss: 0.00837397575378418
epoch 30400  clean testing loss: 13.880765914916992
epoch 30500  training loss: 0.008285172283649445

 31%|███████████████████████▍                                                     | 30502/100000 [10:19<19:34, 59.15it/s]
epoch 30600  training loss: 0.008210224099457264

 31%|███████████████████████▌                                                     | 30619/100000 [10:21<19:34, 59.05it/s]
epoch 30700  training loss: 0.008297152817249298

 31%|███████████████████████▋                                                     | 30739/100000 [10:23<19:34, 58.96it/s]
epoch 30800  training loss: 0.00802495889365673

 31%|███████████████████████▊                                                     | 30859/100000 [10:25<19:32, 58.98it/s]
epoch 30900  training loss: 0.007988215424120426

 31%|███████████████████████▊                                                     | 30975/100000 [10:27<19:30, 58.95it/s]
epoch 31000  training loss: 0.007867326959967613
epoch 31000  clean testing loss: 14.30074405670166
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 31100  training loss: 0.007953229360282421

 31%|███████████████████████▉                                                     | 31095/100000 [10:29<19:29, 58.92it/s]
epoch 31200  training loss: 0.007707708049565554

 31%|████████████████████████                                                     | 31215/100000 [10:31<19:26, 58.98it/s]
epoch 31300  training loss: 0.007633701898157597

 31%|████████████████████████                                                     | 31330/100000 [10:33<19:24, 58.97it/s]
epoch 31400  training loss: 0.007561905309557915

 31%|████████████████████████▏                                                    | 31451/100000 [10:35<19:24, 58.86it/s]
epoch 31500  training loss: 0.007545683532953262

 32%|████████████████████████▎                                                    | 31568/100000 [10:37<19:14, 59.25it/s]
epoch 31600  training loss: 0.007422746624797583

 32%|████████████████████████▍                                                    | 31688/100000 [10:39<19:16, 59.07it/s]
epoch 31700  training loss: 0.0073522962629795074
epoch 31700  clean testing loss: 14.723788261413574
epoch 31800  training loss: 0.007286492735147476

 32%|████████████████████████▍                                                    | 31808/100000 [10:41<19:14, 59.09it/s]
epoch 31900  training loss: 0.007220055907964706

 32%|████████████████████████▌                                                    | 31922/100000 [10:43<19:14, 58.98it/s]
epoch 32000  training loss: 0.00717914616689086
epoch 32000  clean testing loss: 14.888070106506348

 32%|████████████████████████▋                                                    | 32043/100000 [10:45<19:18, 58.67it/s]
epoch 32100  training loss: 0.007092953193932772

 32%|████████████████████████▊                                                    | 32163/100000 [10:47<19:13, 58.79it/s]
epoch 32200  training loss: 0.007032295688986778

 32%|████████████████████████▊                                                    | 32277/100000 [10:49<19:09, 58.93it/s]
epoch 32300  training loss: 0.006975120399147272
epoch 32300  clean testing loss: 15.039600372314453
epoch 32400  training loss: 0.006916049402207136

 32%|████████████████████████▉                                                    | 32398/100000 [10:51<19:04, 59.06it/s]
epoch 32500  training loss: 0.006859293207526207

 33%|█████████████████████████                                                    | 32518/100000 [10:53<19:01, 59.10it/s]
epoch 32600  training loss: 0.0068090250715613365

 33%|█████████████████████████▏                                                   | 32633/100000 [10:55<19:04, 58.85it/s]
epoch 32700  training loss: 0.007207724265754223

 33%|█████████████████████████▏                                                   | 32753/100000 [10:57<18:59, 59.03it/s]
epoch 32800  training loss: 0.006697056349366903

 33%|█████████████████████████▎                                                   | 32868/100000 [10:59<18:57, 59.02it/s]
epoch 32900  training loss: 0.006650425493717194

 33%|█████████████████████████▍                                                   | 32989/100000 [11:01<18:56, 58.98it/s]
epoch 33000  training loss: 0.006592361256480217
epoch 33000  clean testing loss: 15.353328704833984
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 33100  training loss: 0.006550184916704893

 33%|█████████████████████████▍                                                   | 33109/100000 [11:03<18:54, 58.98it/s]
epoch 33200  training loss: 0.0065071359276771545

 33%|█████████████████████████▌                                                   | 33223/100000 [11:05<18:54, 58.85it/s]
epoch 33300  training loss: 0.006462032441049814

 33%|█████████████████████████▋                                                   | 33343/100000 [11:07<18:48, 59.05it/s]
epoch 33400  training loss: 0.006416101939976215

 33%|█████████████████████████▊                                                   | 33464/100000 [11:09<18:51, 58.82it/s]
epoch 33500  training loss: 0.006370415911078453

 34%|█████████████████████████▊                                                   | 33580/100000 [11:11<18:44, 59.09it/s]
epoch 33600  training loss: 0.006323339883238077
epoch 33600  clean testing loss: 15.574962615966797
epoch 33700  training loss: 0.006281776819378138

 34%|█████████████████████████▉                                                   | 33700/100000 [11:13<18:42, 59.05it/s]
epoch 33800  training loss: 0.006280907895416021

 34%|██████████████████████████                                                   | 33821/100000 [11:15<18:43, 58.90it/s]
epoch 33900  training loss: 0.006192822940647602

 34%|██████████████████████████▏                                                  | 33935/100000 [11:17<18:42, 58.86it/s]
epoch 34000  training loss: 0.0061673917807638645
epoch 34000  clean testing loss: 15.72216510772705

 34%|██████████████████████████▏                                                  | 34055/100000 [11:19<18:38, 58.93it/s]
epoch 34100  training loss: 0.006104601081460714

 34%|██████████████████████████▎                                                  | 34176/100000 [11:21<18:35, 59.00it/s]
epoch 34200  training loss: 0.006104845553636551

 34%|██████████████████████████▍                                                  | 34290/100000 [11:23<18:31, 59.14it/s]
epoch 34300  training loss: 0.00608967337757349
epoch 34300  clean testing loss: 15.81849479675293
epoch 34400  training loss: 0.006227988284081221

 34%|██████████████████████████▍                                                  | 34412/100000 [11:25<18:32, 58.95it/s]
epoch 34500  training loss: 0.005952966399490833

 35%|██████████████████████████▌                                                  | 34526/100000 [11:27<18:31, 58.90it/s]
epoch 34600  training loss: 0.0059147365391254425

 35%|██████████████████████████▋                                                  | 34648/100000 [11:29<18:28, 58.98it/s]
epoch 34700  training loss: 0.005885789170861244

 35%|██████████████████████████▊                                                  | 34769/100000 [11:31<18:27, 58.92it/s]
epoch 34800  training loss: 0.0058292206376791

 35%|██████████████████████████▊                                                  | 34883/100000 [11:33<18:40, 58.13it/s]
epoch 34900  training loss: 0.005792603828012943
epoch 34900  clean testing loss: 16.00391387939453
epoch 35000  training loss: 0.0057761166244745255
epoch 35000  clean testing loss: 16.033735275268555

 35%|██████████████████████████▉                                                  | 35003/100000 [11:35<18:58, 57.10it/s]
epoch 35100  training loss: 0.0057245055213570595

 35%|███████████████████████████                                                  | 35117/100000 [11:37<18:22, 58.86it/s]
epoch 35200  training loss: 0.005770509131252766

 35%|███████████████████████████▏                                                 | 35237/100000 [11:39<18:19, 58.89it/s]
epoch 35300  training loss: 0.005648214835673571

 35%|███████████████████████████▏                                                 | 35357/100000 [11:41<18:19, 58.82it/s]
epoch 35400  training loss: 0.005614703521132469

 35%|███████████████████████████▎                                                 | 35472/100000 [11:43<18:15, 58.92it/s]
epoch 35500  training loss: 0.0055813961662352085

 36%|███████████████████████████▍                                                 | 35595/100000 [11:45<18:12, 58.93it/s]
epoch 35600  training loss: 0.005869821645319462
epoch 35600  clean testing loss: 16.2008056640625
epoch 35700  training loss: 0.005689652170985937

 36%|███████████████████████████▍                                                 | 35709/100000 [11:47<18:13, 58.77it/s]
epoch 35800  training loss: 0.005519360303878784

 36%|███████████████████████████▌                                                 | 35829/100000 [11:49<18:07, 59.00it/s]
epoch 35900  training loss: 0.005453124176710844

 36%|███████████████████████████▋                                                 | 35949/100000 [11:51<18:07, 58.89it/s]
epoch 36000  training loss: 0.005422691814601421
epoch 36000  clean testing loss: 16.303213119506836

 36%|███████████████████████████▊                                                 | 36063/100000 [11:53<18:09, 58.66it/s]
epoch 36100  training loss: 0.0053961253724992275

 36%|███████████████████████████▊                                                 | 36183/100000 [11:55<18:02, 58.94it/s]
epoch 36200  training loss: 0.005369610618799925
epoch 36200  clean testing loss: 16.346723556518555
epoch 36300  training loss: 0.005342187825590372

 36%|███████████████████████████▉                                                 | 36303/100000 [11:57<18:03, 58.77it/s]
epoch 36400  training loss: 0.00531349191442132

 36%|████████████████████████████                                                 | 36418/100000 [11:59<17:58, 58.93it/s]
epoch 36500  training loss: 0.005286706145852804

 37%|████████████████████████████▏                                                | 36541/100000 [12:01<17:26, 60.63it/s]
epoch 36600  training loss: 0.005255545023828745

 37%|████████████████████████████▏                                                | 36657/100000 [12:03<17:52, 59.03it/s]
epoch 36700  training loss: 0.005227211397141218

 37%|████████████████████████████▎                                                | 36777/100000 [12:05<17:56, 58.72it/s]
epoch 36800  training loss: 0.00534158805385232

 37%|████████████████████████████▍                                                | 36897/100000 [12:08<17:49, 58.99it/s]
epoch 36900  training loss: 0.005276995711028576
epoch 36900  clean testing loss: 16.510469436645508
epoch 37000  training loss: 0.005187713075429201
epoch 37000  clean testing loss: 16.53272819519043

 37%|████████████████████████████▍                                                | 37011/100000 [12:09<18:15, 57.49it/s]
epoch 37100  training loss: 0.005136942490935326

 37%|████████████████████████████▌                                                | 37131/100000 [12:11<17:49, 58.77it/s]
epoch 37200  training loss: 0.005100604612380266

 37%|████████████████████████████▋                                                | 37252/100000 [12:14<17:44, 58.94it/s]
epoch 37300  training loss: 0.005064505618065596

 37%|████████████████████████████▊                                                | 37368/100000 [12:16<17:38, 59.18it/s]
epoch 37400  training loss: 0.005040954798460007

 37%|████████████████████████████▊                                                | 37489/100000 [12:18<17:33, 59.33it/s]
epoch 37500  training loss: 0.005013162270188332
epoch 37500  clean testing loss: 16.644105911254883
epoch 37600  training loss: 0.00498748617246747

 38%|████████████████████████████▉                                                | 37605/100000 [12:20<17:36, 59.04it/s]
epoch 37700  training loss: 0.00496253278106451

 38%|█████████████████████████████                                                | 37725/100000 [12:22<17:35, 58.98it/s]
epoch 37800  training loss: 0.004958578385412693

 38%|█████████████████████████████▏                                               | 37845/100000 [12:24<17:33, 59.01it/s]
epoch 37900  training loss: 0.004913243465125561

 38%|█████████████████████████████▏                                               | 37959/100000 [12:26<17:33, 58.91it/s]
epoch 38000  training loss: 0.004889410454779863
epoch 38000  clean testing loss: 16.751197814941406

 38%|█████████████████████████████▎                                               | 38079/100000 [12:28<17:31, 58.87it/s]
epoch 38100  training loss: 0.00486522214487195

 38%|█████████████████████████████▍                                               | 38199/100000 [12:30<17:28, 58.97it/s]
epoch 38200  training loss: 0.004841795191168785
epoch 38200  clean testing loss: 16.79222297668457
epoch 38300  training loss: 0.004819254856556654

 38%|█████████████████████████████▌                                               | 38313/100000 [12:32<17:24, 59.09it/s]
epoch 38400  training loss: 0.00479622557759285

 38%|█████████████████████████████▌                                               | 38436/100000 [12:34<16:21, 62.75it/s]
epoch 38500  training loss: 0.004773438908159733

 39%|█████████████████████████████▋                                               | 38580/100000 [12:36<14:04, 72.74it/s]
epoch 38600  training loss: 0.004768652375787497
epoch 38600  clean testing loss: 16.874813079833984
epoch 38700  training loss: 0.004733954556286335

 39%|█████████████████████████████▊                                               | 38724/100000 [12:38<14:03, 72.62it/s]
epoch 38800  training loss: 0.004805276170372963

 39%|█████████████████████████████▉                                               | 38868/100000 [12:40<14:04, 72.42it/s]
epoch 38900  training loss: 0.004690719768404961
epoch 38900  clean testing loss: 16.933698654174805
epoch 39000  training loss: 0.004692216869443655
epoch 39000  clean testing loss: 16.95682716369629

 39%|██████████████████████████████                                               | 39020/100000 [12:42<14:17, 71.10it/s]
epoch 39100  training loss: 0.004644204396754503

 39%|██████████████████████████████▏                                              | 39164/100000 [12:44<13:56, 72.71it/s]
epoch 39200  training loss: 0.0046255458146333694
epoch 39200  clean testing loss: 16.988136291503906
epoch 39300  training loss: 0.004606098867952824

 39%|██████████████████████████████▎                                              | 39308/100000 [12:46<13:56, 72.52it/s]
epoch 39400  training loss: 0.00458591990172863

 39%|██████████████████████████████▍                                              | 39452/100000 [12:48<13:53, 72.61it/s]
epoch 39500  training loss: 0.004570092540234327

 40%|██████████████████████████████▍                                              | 39604/100000 [12:50<13:53, 72.42it/s]
epoch 39600  training loss: 0.0045653944835066795
epoch 39600  clean testing loss: 17.06439208984375
epoch 39700  training loss: 0.0045342640951275826

 40%|██████████████████████████████▌                                              | 39748/100000 [12:52<13:52, 72.40it/s]
epoch 39800  training loss: 0.004537210334092379

 40%|██████████████████████████████▋                                              | 39892/100000 [12:54<13:45, 72.80it/s]
epoch 39900  training loss: 0.004614923615008593
epoch 39900  clean testing loss: 17.11984634399414
epoch 40000  training loss: 0.004468927625566721
epoch 40000  clean testing loss: 17.1378173828125

 40%|██████████████████████████████▊                                              | 40036/100000 [12:56<13:51, 72.15it/s]
epoch 40100  training loss: 0.004485183861106634

 40%|██████████████████████████████▉                                              | 40180/100000 [12:58<13:43, 72.66it/s]
epoch 40200  training loss: 0.00443143118172884
epoch 40200  clean testing loss: 17.175052642822266
epoch 40300  training loss: 0.004432260524481535

 40%|███████████████████████████████                                              | 40332/100000 [13:00<13:39, 72.79it/s]
epoch 40400  training loss: 0.004399031866341829

 40%|███████████████████████████████▏                                             | 40498/100000 [13:02<11:30, 86.21it/s]
epoch 40500  training loss: 0.004374403040856123
epoch 40500  clean testing loss: 17.229942321777344
epoch 40600  training loss: 0.004358129110187292

 41%|███████████████████████████████▎                                             | 40669/100000 [13:04<11:34, 85.48it/s]
epoch 40700  training loss: 0.0043381513096392155
epoch 40700  clean testing loss: 17.266332626342773
epoch 40800  training loss: 0.004320256877690554

 41%|███████████████████████████████▍                                             | 40840/100000 [13:06<11:25, 86.35it/s]
epoch 40900  training loss: 0.0043030958622694016
epoch 40900  clean testing loss: 17.30091094970703
epoch 41000  training loss: 0.004299298394471407
epoch 41000  clean testing loss: 17.3194580078125

 41%|███████████████████████████████▌                                             | 41011/100000 [13:08<11:29, 85.55it/s]
epoch 41100  training loss: 0.004277858883142471

 41%|███████████████████████████████▋                                             | 41182/100000 [13:10<11:19, 86.58it/s]
epoch 41200  training loss: 0.004251966252923012
epoch 41200  clean testing loss: 17.354894638061523
epoch 41300  training loss: 0.004233979620039463

 41%|███████████████████████████████▊                                             | 41353/100000 [13:12<11:19, 86.37it/s]
epoch 41400  training loss: 0.004217478446662426
epoch 41400  clean testing loss: 17.389883041381836
epoch 41500  training loss: 0.004199712071567774

 42%|███████████████████████████████▉                                             | 41533/100000 [13:14<11:19, 86.07it/s]
epoch 41600  training loss: 0.0041833133436739445

 42%|████████████████████████████████                                             | 41659/100000 [13:15<11:16, 86.30it/s]
epoch 41700  training loss: 0.004167189821600914
epoch 41700  clean testing loss: 17.44141960144043
epoch 41800  training loss: 0.004151373170316219

 42%|████████████████████████████████▏                                            | 41830/100000 [13:17<11:16, 86.00it/s]
epoch 41900  training loss: 0.004134675487875938
epoch 41900  clean testing loss: 17.47596549987793
epoch 42000  training loss: 0.00411982974037528
epoch 42000  clean testing loss: 17.492525100708008

 42%|████████████████████████████████▎                                            | 42001/100000 [13:19<11:16, 85.75it/s]
epoch 42100  training loss: 0.004105680156499147
epoch 42100  clean testing loss: 17.506567001342773
epoch 42200  training loss: 0.004092174116522074

 42%|████████████████████████████████▍                                            | 42181/100000 [13:21<11:15, 85.56it/s]
epoch 42300  training loss: 0.0040782359428703785

 42%|████████████████████████████████▌                                            | 42352/100000 [13:23<11:13, 85.61it/s]
epoch 42400  training loss: 0.00406360998749733
epoch 42400  clean testing loss: 17.55223846435547
epoch 42500  training loss: 0.004048425704240799

 43%|████████████████████████████████▋                                            | 42523/100000 [13:25<11:14, 85.27it/s]
epoch 42600  training loss: 0.004048466682434082
epoch 42600  clean testing loss: 17.586509704589844
epoch 42700  training loss: 0.004032909404486418

 43%|████████████████████████████████▊                                            | 42694/100000 [13:27<11:01, 86.70it/s]
epoch 42800  training loss: 0.004037636797875166

 43%|█████████████████████████████████                                            | 42865/100000 [13:29<11:03, 86.17it/s]
epoch 42900  training loss: 0.003989049699157476
epoch 42900  clean testing loss: 17.634798049926758
epoch 43000  training loss: 0.003974528051912785
epoch 43000  clean testing loss: 17.65192222595215

 43%|█████████████████████████████████▏                                           | 43036/100000 [13:31<10:59, 86.33it/s]
epoch 43100  training loss: 0.003960643894970417
epoch 43100  clean testing loss: 17.669038772583008
epoch 43200  training loss: 0.004015738610178232

 43%|█████████████████████████████████▎                                           | 43216/100000 [13:33<10:56, 86.43it/s]
epoch 43300  training loss: 0.003928993362933397
epoch 43300  clean testing loss: 17.701631546020508
epoch 43400  training loss: 0.00391459371894598

 43%|█████████████████████████████████▍                                           | 43387/100000 [13:35<10:55, 86.41it/s]
epoch 43500  training loss: 0.0039005044382065535

 44%|█████████████████████████████████▌                                           | 43558/100000 [13:37<10:55, 86.13it/s]
epoch 43600  training loss: 0.00388639816083014
epoch 43600  clean testing loss: 17.74917984008789
epoch 43700  training loss: 0.00387267186306417

 44%|█████████████████████████████████▋                                           | 43738/100000 [13:39<10:53, 86.08it/s]
epoch 43800  training loss: 0.00385904754512012
epoch 43800  clean testing loss: 17.780672073364258
epoch 43900  training loss: 0.0038456933107227087

 44%|█████████████████████████████████▊                                           | 43909/100000 [13:41<10:47, 86.65it/s]
epoch 44000  training loss: 0.0038320100866258144
epoch 44000  clean testing loss: 17.81182289123535
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 44100  training loss: 0.003817920573055744

 44%|█████████████████████████████████▉                                           | 44080/100000 [13:43<10:52, 85.66it/s]
epoch 44200  training loss: 0.003804318141192198

 44%|██████████████████████████████████                                           | 44251/100000 [13:45<10:51, 85.58it/s]
epoch 44300  training loss: 0.003791171358898282
epoch 44300  clean testing loss: 17.858585357666016
epoch 44400  training loss: 0.003777238307520747

 44%|██████████████████████████████████▏                                          | 44422/100000 [13:47<10:41, 86.58it/s]
epoch 44500  training loss: 0.003763583954423666
epoch 44500  clean testing loss: 17.889463424682617
epoch 44600  training loss: 0.0037506206426769495

 45%|██████████████████████████████████▎                                          | 44593/100000 [13:49<10:46, 85.66it/s]
epoch 44700  training loss: 0.0037372910883277655

 45%|██████████████████████████████████▍                                          | 44773/100000 [13:51<10:40, 86.26it/s]
epoch 44800  training loss: 0.003728060517460108
epoch 44800  clean testing loss: 17.934871673583984
epoch 44900  training loss: 0.003711230820044875

 45%|██████████████████████████████████▌                                          | 44944/100000 [13:53<10:36, 86.54it/s]
epoch 45000  training loss: 0.003698349231854081
epoch 45000  clean testing loss: 17.965227127075195
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 45100  training loss: 0.0036878150422126055

 45%|██████████████████████████████████▋                                          | 45115/100000 [13:55<10:40, 85.69it/s]
epoch 45200  training loss: 0.0036768349818885326
epoch 45200  clean testing loss: 17.9904727935791
epoch 45300  training loss: 0.0036653229035437107

 45%|██████████████████████████████████▊                                          | 45286/100000 [13:57<10:32, 86.53it/s]
epoch 45400  training loss: 0.003653324209153652

 45%|███████████████████████████████████                                          | 45457/100000 [13:59<10:29, 86.67it/s]
epoch 45500  training loss: 0.0036416160874068737
epoch 45500  clean testing loss: 18.033035278320312
epoch 45600  training loss: 0.0036314360331743956

 46%|███████████████████████████████████▏                                         | 45637/100000 [14:01<10:29, 86.40it/s]
epoch 45700  training loss: 0.003715295111760497
epoch 45700  clean testing loss: 18.060863494873047
epoch 45800  training loss: 0.003604267491027713

 46%|███████████████████████████████████▎                                         | 45808/100000 [14:03<10:27, 86.29it/s]
epoch 45900  training loss: 0.003591914428398013
epoch 45900  clean testing loss: 18.090673446655273
epoch 46000  training loss: 0.003579647745937109
epoch 46000  clean testing loss: 18.105758666992188

 46%|███████████████████████████████████▍                                         | 45979/100000 [14:05<10:28, 86.02it/s]
epoch 46100  training loss: 0.0035797387827187777

 46%|███████████████████████████████████▌                                         | 46150/100000 [14:07<10:25, 86.04it/s]
epoch 46200  training loss: 0.003561536781489849
epoch 46200  clean testing loss: 18.13545799255371
epoch 46300  training loss: 0.003544086590409279

 46%|███████████████████████████████████▋                                         | 46321/100000 [14:09<10:19, 86.60it/s]
epoch 46400  training loss: 0.003538113320246339
epoch 46400  clean testing loss: 18.164445877075195
epoch 46500  training loss: 0.003520742291584611

 47%|███████████████████████████████████▊                                         | 46501/100000 [14:11<10:18, 86.56it/s]
epoch 46600  training loss: 0.0035151371266692877

 47%|███████████████████████████████████▉                                         | 46663/100000 [14:13<10:23, 85.50it/s]
epoch 46700  training loss: 0.0035167394671589136
epoch 46700  clean testing loss: 18.205669403076172
epoch 46800  training loss: 0.0034841764718294144

 47%|████████████████████████████████████                                         | 46843/100000 [14:15<10:11, 86.87it/s]
epoch 46900  training loss: 0.0034728930331766605
epoch 46900  clean testing loss: 18.23318862915039
epoch 47000  training loss: 0.003461698768660426
epoch 47000  clean testing loss: 18.246652603149414

 47%|████████████████████████████████████▏                                        | 47014/100000 [14:17<10:25, 84.75it/s]
epoch 47100  training loss: 0.003458907827734947
epoch 47100  clean testing loss: 18.26112174987793
epoch 47200  training loss: 0.0034374541137367487

 47%|████████████████████████████████████▎                                        | 47185/100000 [14:19<10:10, 86.50it/s]
epoch 47300  training loss: 0.0034316545352339745

 47%|████████████████████████████████████▍                                        | 47365/100000 [14:21<10:08, 86.49it/s]
epoch 47400  training loss: 0.0034147126134485006
epoch 47400  clean testing loss: 18.3018798828125
epoch 47500  training loss: 0.0034076168667525053

 48%|████████████████████████████████████▌                                        | 47536/100000 [14:23<10:05, 86.62it/s]
epoch 47600  training loss: 0.0033966104965656996
epoch 47600  clean testing loss: 18.328445434570312
epoch 47700  training loss: 0.0033821321558207273

 48%|████████████████████████████████████▋                                        | 47707/100000 [14:25<10:08, 85.98it/s]
epoch 47800  training loss: 0.003369657788425684

 48%|████████████████████████████████████▊                                        | 47878/100000 [14:27<10:02, 86.45it/s]
epoch 47900  training loss: 0.003358574118465185
epoch 47900  clean testing loss: 18.369163513183594
epoch 48000  training loss: 0.0033535968977957964
epoch 48000  clean testing loss: 18.383197784423828

 48%|████████████████████████████████████▉                                        | 48049/100000 [14:29<10:03, 86.14it/s]
epoch 48100  training loss: 0.0033382733818143606
epoch 48100  clean testing loss: 18.39350700378418
epoch 48200  training loss: 0.0033287974074482918

 48%|█████████████████████████████████████▏                                       | 48229/100000 [14:31<09:57, 86.58it/s]
epoch 48300  training loss: 0.0033188755623996258
epoch 48300  clean testing loss: 18.416934967041016
epoch 48400  training loss: 0.0033084643073379993

 48%|█████████████████████████████████████▎                                       | 48400/100000 [14:33<09:55, 86.60it/s]
epoch 48500  training loss: 0.0032978830859065056

 49%|█████████████████████████████████████▍                                       | 48571/100000 [14:35<09:59, 85.78it/s]
epoch 48600  training loss: 0.003286987077444792
epoch 48600  clean testing loss: 18.45553970336914
epoch 48700  training loss: 0.003276045899838209

 49%|█████████████████████████████████████▌                                       | 48751/100000 [14:38<09:52, 86.53it/s]
epoch 48800  training loss: 0.003265152219682932
epoch 48800  clean testing loss: 18.48169708251953
epoch 48900  training loss: 0.0032755774445831776

 49%|█████████████████████████████████████▋                                       | 48922/100000 [14:40<09:50, 86.46it/s]
epoch 49000  training loss: 0.0032537919469177723
epoch 49000  clean testing loss: 18.50737953186035
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 49100  training loss: 0.00323309819214046

 49%|█████████████████████████████████████▊                                       | 49093/100000 [14:42<09:47, 86.61it/s]
epoch 49200  training loss: 0.003224956104531884


 49%|██████████████████████████████████████                                       | 49444/100000 [14:46<09:46, 86.13it/s]
epoch 49300  training loss: 0.003215655917301774
epoch 49300  clean testing loss: 18.546083450317383
epoch 49400  training loss: 0.0032020090147852898

 50%|██████████████████████████████████████▏                                      | 49615/100000 [14:48<09:42, 86.43it/s]
epoch 49500  training loss: 0.003195565426722169
epoch 49500  clean testing loss: 18.572763442993164
epoch 49600  training loss: 0.0031802107114344835

 50%|██████████████████████████████████████▎                                      | 49786/100000 [14:50<09:39, 86.59it/s]
epoch 49700  training loss: 0.0031768768094480038
epoch 49700  clean testing loss: 18.5976505279541
epoch 49800  training loss: 0.003159503685310483
epoch 49800  clean testing loss: 18.60968017578125
epoch 49900  training loss: 0.003148864721879363

 50%|██████████████████████████████████████▍                                      | 49957/100000 [14:52<09:43, 85.80it/s]
epoch 50000  training loss: 0.003140677697956562
epoch 50000  clean testing loss: 18.63530921936035
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 50100  training loss: 0.0031338646076619625

 50%|██████████████████████████████████████▌                                      | 50128/100000 [14:54<09:37, 86.42it/s]
epoch 50200  training loss: 0.0031182027887552977
epoch 50200  clean testing loss: 18.659976959228516
epoch 50300  training loss: 0.0031082332134246826

 50%|██████████████████████████████████████▋                                      | 50308/100000 [14:56<09:36, 86.17it/s]
epoch 50400  training loss: 0.0030997549183666706

 50%|██████████████████████████████████████▊                                      | 50479/100000 [14:58<09:34, 86.23it/s]
epoch 50500  training loss: 0.003088152501732111
epoch 50500  clean testing loss: 18.69649887084961
epoch 50600  training loss: 0.00307804299518466


 51%|███████████████████████████████████████▏                                     | 50821/100000 [15:02<09:29, 86.38it/s]
epoch 50700  training loss: 0.0030682480428367853
epoch 50700  clean testing loss: 18.721019744873047
epoch 50800  training loss: 0.0030720382928848267

 51%|███████████████████████████████████████▎                                     | 51001/100000 [15:04<09:33, 85.49it/s]
epoch 50900  training loss: 0.003053093096241355
epoch 50900  clean testing loss: 18.745840072631836
epoch 51000  training loss: 0.0030381891410797834
epoch 51000  clean testing loss: 18.757667541503906

 51%|███████████████████████████████████████▍                                     | 51172/100000 [15:06<09:26, 86.15it/s]
epoch 51100  training loss: 0.0030298468191176653

 51%|███████████████████████████████████████▌                                     | 51343/100000 [15:08<09:24, 86.14it/s]
epoch 51200  training loss: 0.0030211021658033133
epoch 51200  clean testing loss: 18.778467178344727
epoch 51300  training loss: 0.003012103959918022

 52%|███████████████████████████████████████▋                                     | 51514/100000 [15:10<09:19, 86.65it/s]
epoch 51400  training loss: 0.0030025322921574116
epoch 51400  clean testing loss: 18.801427841186523
epoch 51500  training loss: 0.0029934325721114874

 52%|███████████████████████████████████████▊                                     | 51694/100000 [15:12<09:22, 85.92it/s]
epoch 51600  training loss: 0.0029835267923772335

 52%|███████████████████████████████████████▉                                     | 51865/100000 [15:14<09:17, 86.30it/s]
epoch 51700  training loss: 0.002977132797241211
epoch 51700  clean testing loss: 18.83824348449707
epoch 51800  training loss: 0.002963957143947482

 52%|████████████████████████████████████████                                     | 52036/100000 [15:16<09:18, 85.92it/s]
epoch 51900  training loss: 0.0029542616102844477
epoch 51900  clean testing loss: 18.86155128479004
epoch 52000  training loss: 0.0029444594401866198
epoch 52000  clean testing loss: 18.87370491027832

 52%|████████████████████████████████████████▏                                    | 52207/100000 [15:18<09:17, 85.75it/s]
epoch 52100  training loss: 0.0029348914977163076
epoch 52100  clean testing loss: 18.88547706604004
epoch 52200  training loss: 0.0029260441660881042

 52%|████████████████████████████████████████▎                                    | 52378/100000 [15:20<09:10, 86.49it/s]
epoch 52300  training loss: 0.0029196087270975113

 53%|████████████████████████████████████████▍                                    | 52558/100000 [15:22<09:10, 86.10it/s]
epoch 52400  training loss: 0.0029086132999509573
epoch 52400  clean testing loss: 18.920969009399414
epoch 52500  training loss: 0.0028977415058761835

 53%|████████████████████████████████████████▌                                    | 52729/100000 [15:24<09:06, 86.48it/s]
epoch 52600  training loss: 0.002887468785047531
epoch 52600  clean testing loss: 18.94489097595215
epoch 52700  training loss: 0.0028776447288691998
epoch 52700  clean testing loss: 18.956321716308594
epoch 52800  training loss: 0.002868560841307044
epoch 52800  clean testing loss: 18.968048095703125
epoch 52900  training loss: 0.002863165456801653

 53%|████████████████████████████████████████▋                                    | 52900/100000 [15:26<09:04, 86.50it/s]
epoch 53000  training loss: 0.0028495751321315765
epoch 53000  clean testing loss: 18.99136734008789

 53%|████████████████████████████████████████▊                                    | 53071/100000 [15:28<09:08, 85.55it/s]
epoch 53100  training loss: 0.00284129218198359
epoch 53100  clean testing loss: 19.00337028503418
epoch 53200  training loss: 0.0028321868740022182

 53%|████████████████████████████████████████▉                                    | 53242/100000 [15:30<09:07, 85.35it/s]
epoch 53300  training loss: 0.0028214987833052874
epoch 53300  clean testing loss: 19.026296615600586
epoch 53400  training loss: 0.0028122225776314735

 53%|█████████████████████████████████████████▏                                   | 53422/100000 [15:32<08:58, 86.46it/s]
epoch 53500  training loss: 0.0028033792041242123
epoch 53500  clean testing loss: 19.04970359802246
epoch 53600  training loss: 0.0028016725555062294


 54%|█████████████████████████████████████████▍                                   | 53801/100000 [15:36<08:02, 95.85it/s]
epoch 53700  training loss: 0.0027847657911479473
epoch 53700  clean testing loss: 19.072481155395508
epoch 53800  training loss: 0.002784806303679943

 54%|█████████████████████████████████████████▌                                   | 53991/100000 [15:38<07:57, 96.45it/s]
epoch 53900  training loss: 0.002767010824754834

 54%|█████████████████████████████████████████▋                                   | 54191/100000 [15:40<07:51, 97.19it/s]
epoch 54000  training loss: 0.0027650606352835894
epoch 54000  clean testing loss: 19.107105255126953
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 54100  training loss: 0.002750139217823744

 54%|█████████████████████████████████████████▊                                   | 54381/100000 [15:42<07:49, 97.14it/s]
epoch 54200  training loss: 0.002742332173511386
epoch 54200  clean testing loss: 19.125934600830078
epoch 54300  training loss: 0.0027342410758137703

 55%|██████████████████████████████████████████                                   | 54581/100000 [15:44<07:52, 96.14it/s]
epoch 54400  training loss: 0.002725756261497736
epoch 54400  clean testing loss: 19.147310256958008
epoch 54500  training loss: 0.0027174113783985376

 55%|██████████████████████████████████████████▏                                  | 54771/100000 [15:46<07:47, 96.75it/s]
epoch 54600  training loss: 0.002708142390474677
epoch 54600  clean testing loss: 19.16984748840332
epoch 54700  training loss: 0.0026996121741831303

 55%|██████████████████████████████████████████▎                                  | 54961/100000 [15:48<07:45, 96.77it/s]
epoch 54800  training loss: 0.0026906977873295546
epoch 54800  clean testing loss: 19.192602157592773
epoch 54900  training loss: 0.002681852551177144

 55%|██████████████████████████████████████████▍                                  | 55161/100000 [15:50<07:44, 96.59it/s]
epoch 55000  training loss: 0.002678011078387499
epoch 55000  clean testing loss: 19.214954376220703
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 55100  training loss: 0.002664413768798113

 55%|██████████████████████████████████████████▌                                  | 55351/100000 [15:52<07:41, 96.65it/s]
epoch 55200  training loss: 0.002655650256201625
epoch 55200  clean testing loss: 19.237804412841797
epoch 55300  training loss: 0.0026474539190530777

 56%|██████████████████████████████████████████▊                                  | 55541/100000 [15:54<07:39, 96.72it/s]
epoch 55400  training loss: 0.0026383129879832268
epoch 55400  clean testing loss: 19.26005744934082
epoch 55500  training loss: 0.0026296323630958796
epoch 55500  clean testing loss: 19.271387100219727
epoch 55600  training loss: 0.0026208865456283092
epoch 55600  clean testing loss: 19.282546997070312
epoch 55700  training loss: 0.0026128103490918875

 56%|██████████████████████████████████████████▉                                  | 55741/100000 [15:56<07:38, 96.48it/s]
epoch 55800  training loss: 0.0026041651144623756
epoch 55800  clean testing loss: 19.30499267578125
epoch 55900  training loss: 0.0025952598080039024

 56%|███████████████████████████████████████████                                  | 55931/100000 [15:58<07:36, 96.45it/s]
epoch 56000  training loss: 0.002595976460725069
epoch 56000  clean testing loss: 19.327281951904297
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 56100  training loss: 0.002583777531981468

 56%|███████████████████████████████████████████▏                                 | 56121/100000 [16:00<07:36, 96.11it/s]
epoch 56200  training loss: 0.0025699820835143328
epoch 56200  clean testing loss: 19.34893798828125
epoch 56300  training loss: 0.0025617757346481085

 56%|███████████████████████████████████████████▎                                 | 56321/100000 [16:02<07:34, 96.12it/s]
epoch 56400  training loss: 0.0025538241025060415
epoch 56400  clean testing loss: 19.371047973632812
epoch 56500  training loss: 0.002545031253248453

 57%|███████████████████████████████████████████▌                                 | 56511/100000 [16:04<07:32, 96.19it/s]
epoch 56600  training loss: 0.0025375275872647762
epoch 56600  clean testing loss: 19.392656326293945
epoch 56700  training loss: 0.00252841436304152

 57%|███████████████████████████████████████████▋                                 | 56701/100000 [16:06<07:30, 96.21it/s]
epoch 56800  training loss: 0.002520231297239661

 57%|███████████████████████████████████████████▊                                 | 56901/100000 [16:08<07:27, 96.33it/s]
epoch 56900  training loss: 0.002511990023776889
epoch 56900  clean testing loss: 19.42531394958496
epoch 57000  training loss: 0.0025038074236363173
epoch 57000  clean testing loss: 19.43613624572754

 57%|███████████████████████████████████████████▉                                 | 57091/100000 [16:10<07:23, 96.79it/s]
epoch 57100  training loss: 0.0024970732629299164
epoch 57100  clean testing loss: 19.445068359375
epoch 57200  training loss: 0.0024901076685637236

 57%|████████████████████████████████████████████                                 | 57281/100000 [16:12<07:20, 96.98it/s]
epoch 57300  training loss: 0.0024827339220792055
epoch 57300  clean testing loss: 19.464317321777344
epoch 57400  training loss: 0.0024750949814915657

 57%|████████████████████████████████████████████▎                                | 57481/100000 [16:14<07:18, 96.93it/s]
epoch 57500  training loss: 0.0024680444039404392
epoch 57500  clean testing loss: 19.48517608642578
epoch 57600  training loss: 0.002459279727190733

 58%|████████████████████████████████████████████▍                                | 57671/100000 [16:16<07:19, 96.33it/s]
epoch 57700  training loss: 0.002452531363815069
epoch 57700  clean testing loss: 19.50627326965332
epoch 57800  training loss: 0.0024445115122944117

 58%|████████████████████████████████████████████▌                                | 57871/100000 [16:18<07:15, 96.83it/s]
epoch 57900  training loss: 0.002435853937640786
epoch 57900  clean testing loss: 19.528005599975586
epoch 58000  training loss: 0.002433693502098322
epoch 58000  clean testing loss: 19.53809356689453

 58%|████████████████████████████████████████████▋                                | 58061/100000 [16:20<07:17, 95.88it/s]
epoch 58100  training loss: 0.0024205443914979696
epoch 58100  clean testing loss: 19.548906326293945
epoch 58200  training loss: 0.0024213744327425957

 58%|████████████████████████████████████████████▊                                | 58251/100000 [16:22<07:13, 96.35it/s]
epoch 58300  training loss: 0.002404684666544199
epoch 58300  clean testing loss: 19.569852828979492
epoch 58400  training loss: 0.002397055272012949

 58%|█████████████████████████████████████████████                                | 58451/100000 [16:24<07:09, 96.79it/s]
epoch 58500  training loss: 0.0023894126061350107
epoch 58500  clean testing loss: 19.590482711791992
epoch 58600  training loss: 0.002381799276918173

 59%|█████████████████████████████████████████████▏                               | 58641/100000 [16:26<07:10, 96.08it/s]
epoch 58700  training loss: 0.002374229021370411
epoch 58700  clean testing loss: 19.611286163330078
epoch 58800  training loss: 0.002366670174524188

 59%|█████████████████████████████████████████████▎                               | 58831/100000 [16:28<07:05, 96.67it/s]
epoch 58900  training loss: 0.002359071746468544
epoch 58900  clean testing loss: 19.632015228271484
epoch 59000  training loss: 0.0023515401408076286
epoch 59000  clean testing loss: 19.642410278320312


 59%|█████████████████████████████████████████████▌                               | 59221/100000 [16:32<07:01, 96.66it/s]
epoch 59100  training loss: 0.0023439908400177956
epoch 59100  clean testing loss: 19.652755737304688
epoch 59200  training loss: 0.002339464845135808

 59%|█████████████████████████████████████████████▊                               | 59421/100000 [16:34<07:00, 96.51it/s]
epoch 59300  training loss: 0.0023290738463401794
epoch 59300  clean testing loss: 19.67351722717285
epoch 59400  training loss: 0.0023214269895106554

 60%|█████████████████████████████████████████████▉                               | 59611/100000 [16:36<06:57, 96.70it/s]
epoch 59500  training loss: 0.0023140800185501575
epoch 59500  clean testing loss: 19.69422721862793
epoch 59600  training loss: 0.002306539798155427

 60%|██████████████████████████████████████████████                               | 59801/100000 [16:38<06:58, 96.07it/s]
epoch 59700  training loss: 0.002299191430211067

 60%|██████████████████████████████████████████████▏                              | 60001/100000 [16:40<07:01, 94.83it/s]
epoch 59800  training loss: 0.0022918498143553734
epoch 59800  clean testing loss: 19.725156784057617
epoch 59900  training loss: 0.002292618853971362

 60%|██████████████████████████████████████████████▎                              | 60191/100000 [16:42<06:54, 96.02it/s]
epoch 60000  training loss: 0.002277243183925748
epoch 60000  clean testing loss: 19.745346069335938
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 60100  training loss: 0.0022712189238518476

 60%|██████████████████████████████████████████████▍                              | 60381/100000 [16:44<06:50, 96.40it/s]
epoch 60200  training loss: 0.0022649522870779037
epoch 60200  clean testing loss: 19.762514114379883
epoch 60300  training loss: 0.002258404390886426

 61%|██████████████████████████████████████████████▋                              | 60581/100000 [16:46<06:47, 96.62it/s]
epoch 60400  training loss: 0.00225161318667233
epoch 60400  clean testing loss: 19.781219482421875
epoch 60500  training loss: 0.002245215466246009

 61%|██████████████████████████████████████████████▊                              | 60771/100000 [16:48<06:49, 95.78it/s]
epoch 60600  training loss: 0.0022376305423676968
epoch 60600  clean testing loss: 19.801265716552734
epoch 60700  training loss: 0.00223075645044446

 61%|██████████████████████████████████████████████▉                              | 60961/100000 [16:50<06:47, 95.76it/s]
epoch 60800  training loss: 0.002223609946668148
epoch 60800  clean testing loss: 19.821338653564453
epoch 60900  training loss: 0.0022165982518345118

 61%|███████████████████████████████████████████████                              | 61151/100000 [16:52<06:45, 95.83it/s]
epoch 61000  training loss: 0.002215172164142132
epoch 61000  clean testing loss: 19.841035842895508
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 61100  training loss: 0.0022043075878173113

 61%|███████████████████████████████████████████████▏                             | 61341/100000 [16:54<06:42, 96.03it/s]
epoch 61200  training loss: 0.002195898210629821
epoch 61200  clean testing loss: 19.861141204833984
epoch 61300  training loss: 0.0021893589291721582

 62%|███████████████████████████████████████████████▍                             | 61541/100000 [16:56<06:39, 96.16it/s]
epoch 61400  training loss: 0.0021822063717991114
epoch 61400  clean testing loss: 19.88090705871582
epoch 61500  training loss: 0.0021757965441793203

 62%|███████████████████████████████████████████████▌                             | 61731/100000 [16:58<06:37, 96.28it/s]
epoch 61600  training loss: 0.0021704002283513546
epoch 61600  clean testing loss: 19.90052032470703
epoch 61700  training loss: 0.002161505166441202

 62%|███████████████████████████████████████████████▋                             | 61881/100000 [17:00<06:35, 96.32it/s]
epoch 61800  training loss: 0.002154850633814931
epoch 61800  clean testing loss: 19.92030143737793
epoch 61900  training loss: 0.0021490249782800674

 62%|███████████████████████████████████████████████▊                             | 62071/100000 [17:02<06:33, 96.29it/s]
epoch 62000  training loss: 0.0021412987262010574
epoch 62000  clean testing loss: 19.939821243286133
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 62100  training loss: 0.0021346211433410645

 62%|███████████████████████████████████████████████▉                             | 62261/100000 [17:03<06:31, 96.50it/s]
epoch 62200  training loss: 0.0021279442589730024
epoch 62200  clean testing loss: 19.959138870239258
epoch 62300  training loss: 0.002122590783983469

 62%|████████████████████████████████████████████████                             | 62461/100000 [17:06<06:29, 96.48it/s]
epoch 62400  training loss: 0.0021161134354770184

 63%|████████████████████████████████████████████████▏                            | 62651/100000 [17:08<06:27, 96.30it/s]
epoch 62500  training loss: 0.002108185552060604
epoch 62500  clean testing loss: 19.98814582824707
epoch 62600  training loss: 0.002102128230035305

 63%|████████████████████████████████████████████████▍                            | 62841/100000 [17:10<06:25, 96.38it/s]
epoch 62700  training loss: 0.002095030387863517
epoch 62700  clean testing loss: 20.007450103759766
epoch 62800  training loss: 0.002088655484840274

 63%|████████████████████████████████████████████████▌                            | 63041/100000 [17:12<06:24, 96.05it/s]
epoch 62900  training loss: 0.002082197228446603
epoch 62900  clean testing loss: 20.026945114135742
epoch 63000  training loss: 0.002075587399303913
epoch 63000  clean testing loss: 20.036149978637695

 63%|████████████████████████████████████████████████▋                            | 63231/100000 [17:14<06:21, 96.36it/s]
epoch 63100  training loss: 0.002070243004709482
epoch 63100  clean testing loss: 20.043899536132812
epoch 63200  training loss: 0.0020647908095270395

 63%|████████████████████████████████████████████████▊                            | 63421/100000 [17:16<06:20, 96.18it/s]
epoch 63300  training loss: 0.0020590522326529026
epoch 63300  clean testing loss: 20.06048583984375
epoch 63400  training loss: 0.00205316417850554

 64%|████████████████████████████████████████████████▉                            | 63621/100000 [17:18<06:17, 96.37it/s]
epoch 63500  training loss: 0.0020469864830374718
epoch 63500  clean testing loss: 20.07860565185547
epoch 63600  training loss: 0.0020407624542713165

 64%|█████████████████████████████████████████████████▏                           | 63811/100000 [17:20<06:15, 96.37it/s]
epoch 63700  training loss: 0.0020346499513834715
epoch 63700  clean testing loss: 20.097148895263672
epoch 63800  training loss: 0.0020285584032535553

 64%|█████████████████████████████████████████████████▎                           | 64001/100000 [17:22<06:19, 94.95it/s]
epoch 63900  training loss: 0.002022508764639497
epoch 63900  clean testing loss: 20.115123748779297
epoch 64000  training loss: 0.0020163198933005333
epoch 64000  clean testing loss: 20.124311447143555

 64%|█████████████████████████████████████████████████▍                           | 64191/100000 [17:24<06:11, 96.42it/s]
epoch 64100  training loss: 0.002010251162573695
epoch 64100  clean testing loss: 20.133506774902344
epoch 64200  training loss: 0.002005129586905241

 64%|█████████████████████████████████████████████████▌                           | 64391/100000 [17:26<06:09, 96.41it/s]
epoch 64300  training loss: 0.0019981786608695984
epoch 64300  clean testing loss: 20.151641845703125
epoch 64400  training loss: 0.0019922517240047455

 65%|█████████████████████████████████████████████████▋                           | 64581/100000 [17:28<06:07, 96.42it/s]
epoch 64500  training loss: 0.0019860356114804745
epoch 64500  clean testing loss: 20.169923782348633
epoch 64600  training loss: 0.0019800877198576927

 65%|█████████████████████████████████████████████████▊                           | 64771/100000 [17:30<06:06, 96.21it/s]
epoch 64700  training loss: 0.0019742283038794994
epoch 64700  clean testing loss: 20.187793731689453
epoch 64800  training loss: 0.00196833279915154

 65%|██████████████████████████████████████████████████                           | 64971/100000 [17:32<06:02, 96.54it/s]
epoch 64900  training loss: 0.0019625003915280104
epoch 64900  clean testing loss: 20.20549201965332
epoch 65000  training loss: 0.0019568216521292925
epoch 65000  clean testing loss: 20.21448516845703

 65%|██████████████████████████████████████████████████▏                          | 65161/100000 [17:34<06:01, 96.42it/s]
epoch 65100  training loss: 0.0019507932011038065

 65%|██████████████████████████████████████████████████▎                          | 65351/100000 [17:36<05:59, 96.36it/s]
epoch 65200  training loss: 0.0019448860548436642
epoch 65200  clean testing loss: 20.232351303100586
epoch 65300  training loss: 0.0019391403766348958

 66%|██████████████████████████████████████████████████▍                          | 65551/100000 [17:38<05:57, 96.38it/s]
epoch 65400  training loss: 0.0019336276454851031
epoch 65400  clean testing loss: 20.250139236450195
epoch 65500  training loss: 0.0019275699742138386

 66%|██████████████████████████████████████████████████▌                          | 65741/100000 [17:40<05:55, 96.33it/s]
epoch 65600  training loss: 0.001921832445077598
epoch 65600  clean testing loss: 20.267704010009766
epoch 65700  training loss: 0.001916023320518434

 66%|██████████████████████████████████████████████████▊                          | 65931/100000 [17:42<05:53, 96.45it/s]
epoch 65800  training loss: 0.0019103795057162642
epoch 65800  clean testing loss: 20.285099029541016
epoch 65900  training loss: 0.0019047226523980498

 66%|██████████████████████████████████████████████████▉                          | 66131/100000 [17:44<05:51, 96.44it/s]
epoch 66000  training loss: 0.0019002696499228477
epoch 66000  clean testing loss: 20.302881240844727
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 66100  training loss: 0.0018944420153275132

 66%|███████████████████████████████████████████████████                          | 66321/100000 [17:46<05:50, 96.19it/s]
epoch 66200  training loss: 0.001889629173092544
epoch 66200  clean testing loss: 20.317161560058594
epoch 66300  training loss: 0.0018846762832254171

 67%|███████████████████████████████████████████████████▏                         | 66521/100000 [17:48<05:45, 96.78it/s]
epoch 66400  training loss: 0.0018795302603393793
epoch 66400  clean testing loss: 20.332958221435547
epoch 66500  training loss: 0.0018744211411103606

 67%|███████████████████████████████████████████████████▎                         | 66711/100000 [17:50<05:45, 96.32it/s]
epoch 66600  training loss: 0.0018689112039282918
epoch 66600  clean testing loss: 20.34988784790039
epoch 66700  training loss: 0.0018635803135111928

 67%|███████████████████████████████████████████████████▌                         | 66901/100000 [17:52<05:42, 96.62it/s]
epoch 66800  training loss: 0.0018582041375339031
epoch 66800  clean testing loss: 20.366535186767578
epoch 66900  training loss: 0.0018527767388150096

 67%|███████████████████████████████████████████████████▋                         | 67101/100000 [17:54<05:40, 96.73it/s]
epoch 67000  training loss: 0.001847494742833078
epoch 67000  clean testing loss: 20.383142471313477
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...
epoch 67100  training loss: 0.0018429317278787494

 67%|███████████████████████████████████████████████████▊                         | 67291/100000 [17:56<05:37, 96.82it/s]
epoch 67200  training loss: 0.0018369435565546155
epoch 67200  clean testing loss: 20.39977264404297
epoch 67300  training loss: 0.001832333393394947

 67%|███████████████████████████████████████████████████▉                         | 67491/100000 [17:58<05:35, 96.86it/s]
epoch 67400  training loss: 0.0018265432445332408
epoch 67400  clean testing loss: 20.416297912597656
epoch 67500  training loss: 0.0018212635768577456

 68%|████████████████████████████████████████████████████                         | 67681/100000 [18:00<05:33, 96.80it/s]
epoch 67600  training loss: 0.0018179411999881268
epoch 67600  clean testing loss: 20.432537078857422
epoch 67700  training loss: 0.0018109312513843179

 68%|████████████████████████████████████████████████████▎                        | 67871/100000 [18:02<05:32, 96.50it/s]
epoch 67800  training loss: 0.0018058134010061622

 68%|████████████████████████████████████████████████████▎                        | 67900/100000 [18:02<08:31, 62.73it/s]
epoch 67900  training loss: 0.0018007275648415089
epoch 67900  clean testing loss: 20.45725440979004
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise3.00e-01_invop1 ...