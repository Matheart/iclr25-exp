
  0%|          | 57/100000 [00:02<55:16, 30.14it/s]
epoch 0  training loss: 48.026851654052734
epoch 0  clean testing loss: 41.6964225769043

  0%|          | 117/100000 [00:04<55:13, 30.15it/s]
epoch 100  training loss: 1.0682239532470703


  0%|          | 236/100000 [00:08<55:10, 30.14it/s]
epoch 200  training loss: 0.48785075545310974


  0%|          | 344/100000 [00:11<55:07, 30.13it/s]
epoch 300  training loss: 0.33244097232818604

  0%|          | 404/100000 [00:13<55:18, 30.01it/s]
epoch 400  training loss: 0.2575558125972748


  1%|          | 524/100000 [00:17<55:05, 30.10it/s]
epoch 500  training loss: 0.21219925582408905


  1%|          | 644/100000 [00:21<55:02, 30.09it/s]
epoch 600  training loss: 0.17957544326782227

  1%|          | 704/100000 [00:23<55:14, 29.96it/s]
epoch 700  training loss: 0.15817180275917053


  1%|          | 825/100000 [00:27<55:02, 30.03it/s]
epoch 800  training loss: 0.14311307668685913


  1%|          | 943/100000 [00:31<54:57, 30.04it/s]
epoch 900  training loss: 0.13219667971134186

  1%|          | 1002/100000 [00:33<56:01, 29.45it/s]
epoch 1000  training loss: 0.12449651956558228
epoch 1000  clean testing loss: 0.07195635885000229


  1%|          | 1123/100000 [00:37<56:51, 28.98it/s]
epoch 1100  training loss: 0.11888480931520462


  1%|          | 1244/100000 [00:41<54:48, 30.03it/s]
epoch 1200  training loss: 0.11464286595582962

  1%|▏         | 1303/100000 [00:43<55:01, 29.89it/s]
epoch 1300  training loss: 0.11134397983551025


  1%|▏         | 1425/100000 [00:47<54:49, 29.96it/s]
epoch 1400  training loss: 0.10875333100557327


  2%|▏         | 1544/100000 [00:51<54:52, 29.90it/s]
epoch 1500  training loss: 0.10669433325529099

  2%|▏         | 1605/100000 [00:53<55:02, 29.80it/s]
epoch 1600  training loss: 0.10501605272293091


  2%|▏         | 1721/100000 [00:57<54:37, 29.99it/s]
epoch 1700  training loss: 0.10363276302814484


  2%|▏         | 1841/100000 [01:01<54:39, 29.93it/s]
epoch 1800  training loss: 0.10248005390167236

  2%|▏         | 1903/100000 [01:03<54:55, 29.76it/s]
epoch 1900  training loss: 0.10153394192457199


  2%|▏         | 2023/100000 [01:07<54:32, 29.94it/s]
epoch 2000  training loss: 0.1008349359035492
epoch 2000  clean testing loss: 0.009986549615859985


  2%|▏         | 2142/100000 [01:11<54:48, 29.76it/s]
epoch 2100  training loss: 0.10011480748653412

  2%|▏         | 2201/100000 [01:13<54:37, 29.84it/s]
epoch 2200  training loss: 0.09959317743778229


  2%|▏         | 2321/100000 [01:17<54:28, 29.89it/s]
epoch 2300  training loss: 0.09916584193706512


  2%|▏         | 2442/100000 [01:21<54:21, 29.92it/s]
epoch 2400  training loss: 0.09881803393363953

  3%|▎         | 2502/100000 [01:23<54:36, 29.76it/s]
epoch 2500  training loss: 0.09871480613946915


  3%|▎         | 2619/100000 [01:27<54:18, 29.89it/s]
epoch 2600  training loss: 0.09825515747070312


  3%|▎         | 2739/100000 [01:31<54:13, 29.89it/s]
epoch 2700  training loss: 0.09807459264993668


  3%|▎         | 2859/100000 [01:35<54:09, 29.89it/s]
epoch 2800  training loss: 0.09786532074213028

  3%|▎         | 2919/100000 [01:37<54:09, 29.87it/s]
epoch 2900  training loss: 0.0997064933180809


  3%|▎         | 3036/100000 [01:41<54:04, 29.89it/s]
epoch 3000  training loss: 0.0977819561958313
epoch 3000  clean testing loss: 0.0031574973836541176


  3%|▎         | 3156/100000 [01:45<53:59, 29.89it/s]
epoch 3100  training loss: 0.09748107194900513

  3%|▎         | 3216/100000 [01:47<54:02, 29.85it/s]
epoch 3200  training loss: 0.09739306569099426


  3%|▎         | 3336/100000 [01:51<53:55, 29.87it/s]
epoch 3300  training loss: 0.09731104224920273


  3%|▎         | 3456/100000 [01:55<53:52, 29.86it/s]
epoch 3400  training loss: 0.09723807871341705

  4%|▎         | 3513/100000 [01:57<53:58, 29.79it/s]
epoch 3500  training loss: 0.09850965440273285


  4%|▎         | 3633/100000 [02:01<53:45, 29.88it/s]
epoch 3600  training loss: 0.09711237251758575


  4%|▍         | 3753/100000 [02:05<53:43, 29.86it/s]
epoch 3700  training loss: 0.09706324338912964

  4%|▍         | 3813/100000 [02:07<53:46, 29.81it/s]
epoch 3800  training loss: 0.09916019439697266


  4%|▍         | 3933/100000 [02:11<53:37, 29.86it/s]
epoch 3900  training loss: 0.09696578234434128


  4%|▍         | 4053/100000 [02:15<53:30, 29.88it/s]
epoch 4000  training loss: 0.09693969786167145
epoch 4000  clean testing loss: 0.002687988802790642

  4%|▍         | 4113/100000 [02:17<53:35, 29.82it/s]
epoch 4100  training loss: 0.1040116548538208


  4%|▍         | 4230/100000 [02:21<53:33, 29.80it/s]
epoch 4200  training loss: 0.09685295075178146


  4%|▍         | 4350/100000 [02:25<53:24, 29.84it/s]
epoch 4300  training loss: 0.09681904315948486

  4%|▍         | 4410/100000 [02:27<53:29, 29.78it/s]
epoch 4400  training loss: 0.09680840373039246


  5%|▍         | 4527/100000 [02:31<53:16, 29.87it/s]
epoch 4500  training loss: 0.09746625274419785


  5%|▍         | 4647/100000 [02:35<53:11, 29.88it/s]
epoch 4600  training loss: 0.09673614054918289

  5%|▍         | 4707/100000 [02:37<53:20, 29.77it/s]
epoch 4700  training loss: 0.09731121361255646


  5%|▍         | 4827/100000 [02:41<53:09, 29.84it/s]
epoch 4800  training loss: 0.09668842703104019


  5%|▍         | 4947/100000 [02:45<53:03, 29.86it/s]
epoch 4900  training loss: 0.09667570888996124

  5%|▌         | 5007/100000 [02:47<53:33, 29.56it/s]
epoch 5000  training loss: 0.09665312618017197
epoch 5000  clean testing loss: 0.0020574270747601986


  5%|▌         | 5127/100000 [02:51<53:01, 29.82it/s]
epoch 5100  training loss: 0.0966276228427887


  5%|▌         | 5244/100000 [02:55<52:56, 29.83it/s]
epoch 5200  training loss: 0.09809311479330063

  5%|▌         | 5304/100000 [02:57<53:46, 29.35it/s]
epoch 5300  training loss: 0.0968329906463623


  5%|▌         | 5421/100000 [03:01<52:53, 29.80it/s]
epoch 5400  training loss: 0.0965736135840416


  6%|▌         | 5541/100000 [03:05<52:46, 29.83it/s]
epoch 5500  training loss: 0.0965665876865387

  6%|▌         | 5601/100000 [03:07<52:45, 29.82it/s]
epoch 5600  training loss: 0.09789107739925385


  6%|▌         | 5721/100000 [03:11<52:42, 29.81it/s]
epoch 5700  training loss: 0.09695147722959518


  6%|▌         | 5841/100000 [03:16<52:37, 29.82it/s]
epoch 5800  training loss: 0.09650914371013641

  6%|▌         | 5901/100000 [03:18<52:38, 29.80it/s]
epoch 5900  training loss: 0.09654482454061508


  6%|▌         | 6018/100000 [03:21<52:39, 29.74it/s]
epoch 6000  training loss: 0.09649073332548141
epoch 6000  clean testing loss: 0.0019760923460125923


  6%|▌         | 6138/100000 [03:25<52:30, 29.79it/s]
epoch 6100  training loss: 0.09646876156330109


  6%|▋         | 6255/100000 [03:29<52:23, 29.82it/s]
epoch 6200  training loss: 0.09645723551511765

  6%|▋         | 6315/100000 [03:31<52:24, 29.79it/s]
epoch 6300  training loss: 0.09644469618797302


  6%|▋         | 6435/100000 [03:36<52:17, 29.82it/s]
epoch 6400  training loss: 0.09643322974443436


  7%|▋         | 6555/100000 [03:40<52:12, 29.83it/s]
epoch 6500  training loss: 0.09642151743173599

  7%|▋         | 6615/100000 [03:42<52:17, 29.77it/s]
epoch 6600  training loss: 0.0964294895529747


  7%|▋         | 6735/100000 [03:46<52:08, 29.82it/s]
epoch 6700  training loss: 0.09651417285203934


  7%|▋         | 6852/100000 [03:50<52:02, 29.83it/s]
epoch 6800  training loss: 0.09714191406965256

  7%|▋         | 6912/100000 [03:52<52:03, 29.80it/s]
epoch 6900  training loss: 0.09638921916484833


  7%|▋         | 7032/100000 [03:56<52:01, 29.79it/s]
epoch 7000  training loss: 0.09971380233764648
epoch 7000  clean testing loss: 0.004341474734246731


  7%|▋         | 7149/100000 [04:00<51:53, 29.82it/s]
epoch 7100  training loss: 0.09635946154594421

  7%|▋         | 7209/100000 [04:02<52:02, 29.72it/s]
epoch 7200  training loss: 0.09661830216646194


  7%|▋         | 7329/100000 [04:06<51:48, 29.81it/s]
epoch 7300  training loss: 0.09636440128087997


  7%|▋         | 7449/100000 [04:10<51:43, 29.82it/s]
epoch 7400  training loss: 0.0963502749800682

  8%|▊         | 7509/100000 [04:12<51:50, 29.74it/s]
epoch 7500  training loss: 0.09631451219320297


  8%|▊         | 7626/100000 [04:16<51:44, 29.76it/s]
epoch 7600  training loss: 0.09630618989467621


  8%|▊         | 7746/100000 [04:20<51:34, 29.81it/s]
epoch 7700  training loss: 0.09629639983177185

  8%|▊         | 7806/100000 [04:22<51:45, 29.69it/s]
epoch 7800  training loss: 0.09628511220216751


  8%|▊         | 7926/100000 [04:26<51:31, 29.78it/s]
epoch 7900  training loss: 0.09628049284219742


  8%|▊         | 8043/100000 [04:30<51:23, 29.82it/s]
epoch 8000  training loss: 0.09774133563041687
epoch 8000  clean testing loss: 0.002121749334037304

  8%|▊         | 8103/100000 [04:32<51:40, 29.64it/s]
epoch 8100  training loss: 0.09625118970870972


  8%|▊         | 8223/100000 [04:36<51:19, 29.81it/s]
epoch 8200  training loss: 0.0962401032447815


  8%|▊         | 8340/100000 [04:40<51:21, 29.74it/s]
epoch 8300  training loss: 0.09623035788536072

  8%|▊         | 8400/100000 [04:42<51:13, 29.80it/s]
epoch 8400  training loss: 0.09623099118471146


  9%|▊         | 8520/100000 [04:46<51:09, 29.80it/s]
epoch 8500  training loss: 0.09621796756982803


  9%|▊         | 8640/100000 [04:50<51:05, 29.80it/s]
epoch 8600  training loss: 0.09620559215545654


  9%|▉         | 8760/100000 [04:54<51:03, 29.78it/s]
epoch 8700  training loss: 0.1025417223572731

  9%|▉         | 8817/100000 [04:56<51:04, 29.75it/s]
epoch 8800  training loss: 0.09615960717201233


  9%|▉         | 8937/100000 [05:00<50:53, 29.82it/s]
epoch 8900  training loss: 0.09614549577236176


  9%|▉         | 9054/100000 [05:04<50:53, 29.79it/s]
epoch 9000  training loss: 0.09620342403650284
epoch 9000  clean testing loss: 0.0019885110668838024

  9%|▉         | 9114/100000 [05:06<50:58, 29.72it/s]
epoch 9100  training loss: 0.0961114913225174


  9%|▉         | 9234/100000 [05:10<50:45, 29.81it/s]
epoch 9200  training loss: 0.09609518945217133


  9%|▉         | 9354/100000 [05:14<50:49, 29.72it/s]
epoch 9300  training loss: 0.09607736766338348

  9%|▉         | 9414/100000 [05:16<50:42, 29.78it/s]
epoch 9400  training loss: 0.09605655819177628


 10%|▉         | 9531/100000 [05:20<50:37, 29.79it/s]
epoch 9500  training loss: 0.09603528678417206


 10%|▉         | 9651/100000 [05:24<50:33, 29.79it/s]
epoch 9600  training loss: 0.0962221696972847

 10%|▉         | 9711/100000 [05:26<50:31, 29.78it/s]
epoch 9700  training loss: 0.09599313884973526


 10%|▉         | 9828/100000 [05:30<50:23, 29.82it/s]
epoch 9800  training loss: 0.09596648812294006


 10%|▉         | 9948/100000 [05:34<50:25, 29.76it/s]
epoch 9900  training loss: 0.09612227231264114

 10%|█         | 10008/100000 [05:36<50:46, 29.54it/s]
epoch 10000  training loss: 0.09709836542606354
epoch 10000  clean testing loss: 0.0035527481231838465


 10%|█         | 10125/100000 [05:40<50:17, 29.79it/s]
epoch 10100  training loss: 0.09624087810516357


 10%|█         | 10245/100000 [05:44<50:12, 29.80it/s]
epoch 10200  training loss: 0.09587522596120834

 10%|█         | 10305/100000 [05:46<50:18, 29.72it/s]
epoch 10300  training loss: 0.09585580974817276


 10%|█         | 10425/100000 [05:50<50:08, 29.78it/s]
epoch 10400  training loss: 0.09599679708480835


 11%|█         | 10545/100000 [05:54<50:00, 29.81it/s]
epoch 10500  training loss: 0.09589677304029465

 11%|█         | 10605/100000 [05:56<50:10, 29.69it/s]
epoch 10600  training loss: 0.09579392522573471


 11%|█         | 10722/100000 [06:00<49:56, 29.79it/s]
epoch 10700  training loss: 0.0958392322063446


 11%|█         | 10839/100000 [06:04<49:54, 29.78it/s]
epoch 10800  training loss: 0.09592988342046738

 11%|█         | 10899/100000 [06:06<49:53, 29.76it/s]
epoch 10900  training loss: 0.09575816988945007


 11%|█         | 11019/100000 [06:10<49:52, 29.74it/s]
epoch 11000  training loss: 0.09821100533008575
epoch 11000  clean testing loss: 0.005894631613045931


 11%|█         | 11139/100000 [06:14<49:39, 29.82it/s]
epoch 11100  training loss: 0.09569385647773743


 11%|█▏        | 11259/100000 [06:18<49:36, 29.81it/s]
epoch 11200  training loss: 0.0956767201423645

 11%|█▏        | 11319/100000 [06:20<49:37, 29.78it/s]
epoch 11300  training loss: 0.09566346555948257


 11%|█▏        | 11436/100000 [06:24<49:33, 29.79it/s]
epoch 11400  training loss: 0.09564057737588882


 12%|█▏        | 11556/100000 [06:28<50:26, 29.23it/s]
epoch 11500  training loss: 0.09562467038631439

 12%|█▏        | 11613/100000 [06:30<49:32, 29.74it/s]
epoch 11600  training loss: 0.09560762345790863


 12%|█▏        | 11733/100000 [06:34<49:32, 29.69it/s]
epoch 11700  training loss: 0.09561076760292053


 12%|█▏        | 11853/100000 [06:38<49:17, 29.80it/s]
epoch 11800  training loss: 0.09557454288005829

 12%|█▏        | 11913/100000 [06:40<49:22, 29.73it/s]
epoch 11900  training loss: 0.09556742012500763


 12%|█▏        | 12030/100000 [06:44<49:21, 29.71it/s]
epoch 12000  training loss: 0.09554078429937363
epoch 12000  clean testing loss: 0.0025507956743240356


 12%|█▏        | 12150/100000 [06:48<49:09, 29.78it/s]
epoch 12100  training loss: 0.09552846103906631

 12%|█▏        | 12210/100000 [06:50<49:12, 29.74it/s]
epoch 12200  training loss: 0.09551514685153961


 12%|█▏        | 12330/100000 [06:54<48:59, 29.82it/s]
epoch 12300  training loss: 0.0955001711845398


 12%|█▏        | 12447/100000 [06:58<50:26, 28.93it/s]
epoch 12400  training loss: 0.09548749774694443

 13%|█▎        | 12507/100000 [07:00<49:04, 29.71it/s]
epoch 12500  training loss: 0.0955377146601677


 13%|█▎        | 12627/100000 [07:04<48:51, 29.80it/s]
epoch 12600  training loss: 0.09547562152147293


 13%|█▎        | 12744/100000 [07:08<48:52, 29.75it/s]
epoch 12700  training loss: 0.09548952430486679

 13%|█▎        | 12804/100000 [07:10<48:59, 29.66it/s]
epoch 12800  training loss: 0.09543835371732712


 13%|█▎        | 12924/100000 [07:14<48:46, 29.76it/s]
epoch 12900  training loss: 0.09543201327323914


 13%|█▎        | 13044/100000 [07:18<48:42, 29.75it/s]
epoch 13000  training loss: 0.09621007740497589
epoch 13000  clean testing loss: 0.0038776069413870573

 13%|█▎        | 13104/100000 [07:20<48:49, 29.66it/s]
epoch 13100  training loss: 0.09540597349405289


 13%|█▎        | 13221/100000 [07:24<48:43, 29.69it/s]
epoch 13200  training loss: 0.09539592266082764


 13%|█▎        | 13341/100000 [07:28<50:10, 28.78it/s]
epoch 13300  training loss: 0.09540586918592453


 13%|█▎        | 13458/100000 [07:32<48:23, 29.81it/s]
epoch 13400  training loss: 0.09537836164236069

 14%|█▎        | 13518/100000 [07:34<48:24, 29.77it/s]
epoch 13500  training loss: 0.09537412971258163


 14%|█▎        | 13638/100000 [07:38<48:19, 29.79it/s]
epoch 13600  training loss: 0.09544166177511215


 14%|█▍        | 13758/100000 [07:42<48:17, 29.76it/s]
epoch 13700  training loss: 0.09535490721464157

 14%|█▍        | 13803/100000 [07:44<48:29, 29.63it/s]
epoch 13800  training loss: 0.09587462991476059


 14%|█▍        | 13920/100000 [07:48<48:09, 29.79it/s]
epoch 13900  training loss: 0.09537611901760101


 14%|█▍        | 14040/100000 [07:52<48:03, 29.81it/s]
epoch 14000  training loss: 0.09544764459133148
epoch 14000  clean testing loss: 0.0027973137330263853

 14%|█▍        | 14100/100000 [07:54<48:03, 29.79it/s]
epoch 14100  training loss: 0.09589162468910217


 14%|█▍        | 14220/100000 [07:58<48:15, 29.62it/s]
epoch 14200  training loss: 0.09529957920312881


 14%|█▍        | 14337/100000 [08:02<47:53, 29.81it/s]
epoch 14300  training loss: 0.09529362618923187

 14%|█▍        | 14397/100000 [08:04<47:55, 29.77it/s]
epoch 14400  training loss: 0.09528272598981857


 15%|█▍        | 14514/100000 [08:08<47:54, 29.74it/s]
epoch 14500  training loss: 0.09536679089069366


 15%|█▍        | 14634/100000 [08:12<47:45, 29.79it/s]
epoch 14600  training loss: 0.09527790546417236


 15%|█▍        | 14754/100000 [08:16<47:37, 29.83it/s]
epoch 14700  training loss: 0.0952700525522232

 15%|█▍        | 14814/100000 [08:18<47:43, 29.75it/s]
epoch 14800  training loss: 0.09525228291749954


 15%|█▍        | 14934/100000 [08:22<47:35, 29.79it/s]
epoch 14900  training loss: 0.09523597359657288


 15%|█▌        | 15051/100000 [08:26<47:35, 29.75it/s]
epoch 15000  training loss: 0.09523510187864304
epoch 15000  clean testing loss: 0.0028124831151217222

 15%|█▌        | 15111/100000 [08:28<47:33, 29.75it/s]
epoch 15100  training loss: 0.09521668404340744


 15%|█▌        | 15228/100000 [08:32<47:24, 29.80it/s]
epoch 15200  training loss: 0.09520978480577469


 15%|█▌        | 15348/100000 [08:36<47:23, 29.77it/s]
epoch 15300  training loss: 0.095201276242733

 15%|█▌        | 15408/100000 [08:38<47:26, 29.72it/s]
epoch 15400  training loss: 0.09519080072641373


 16%|█▌        | 15529/100000 [08:42<46:53, 30.03it/s]
epoch 15500  training loss: 0.09519145637750626


 16%|█▌        | 15649/100000 [08:46<46:56, 29.95it/s]
epoch 15600  training loss: 0.09517307579517365

 16%|█▌        | 15709/100000 [08:48<47:14, 29.74it/s]
epoch 15700  training loss: 0.09516363590955734


 16%|█▌        | 15826/100000 [08:52<47:06, 29.78it/s]
epoch 15800  training loss: 0.09515446424484253


 16%|█▌        | 15946/100000 [08:56<47:00, 29.80it/s]
epoch 15900  training loss: 0.09521263092756271

 16%|█▌        | 16006/100000 [08:58<47:49, 29.27it/s]
epoch 16000  training loss: 0.09515541791915894
epoch 16000  clean testing loss: 0.0029542448464781046


 16%|█▌        | 16123/100000 [09:02<46:55, 29.79it/s]
epoch 16100  training loss: 0.09512883424758911


 16%|█▌        | 16243/100000 [09:06<46:51, 29.79it/s]
epoch 16200  training loss: 0.09532762318849564

 16%|█▋        | 16303/100000 [09:08<47:06, 29.61it/s]
epoch 16300  training loss: 0.095120370388031


 16%|█▋        | 16420/100000 [09:12<46:49, 29.74it/s]
epoch 16400  training loss: 0.09514778107404709


 17%|█▋        | 16540/100000 [09:16<46:40, 29.81it/s]
epoch 16500  training loss: 0.09536231309175491

 17%|█▋        | 16600/100000 [09:18<46:37, 29.81it/s]
epoch 16600  training loss: 0.09508460760116577


 17%|█▋        | 16720/100000 [09:22<46:35, 29.79it/s]
epoch 16700  training loss: 0.09507378190755844


 17%|█▋        | 16840/100000 [09:26<46:30, 29.81it/s]
epoch 16800  training loss: 0.09507182240486145


 17%|█▋        | 16957/100000 [09:30<46:29, 29.77it/s]
epoch 16900  training loss: 0.09506618231534958

 17%|█▋        | 17017/100000 [09:32<46:36, 29.68it/s]
epoch 17000  training loss: 0.09505248814821243
epoch 17000  clean testing loss: 0.0029109695460647345


 17%|█▋        | 17134/100000 [09:36<46:20, 29.81it/s]
epoch 17100  training loss: 0.09504393488168716


 17%|█▋        | 17254/100000 [09:40<46:17, 29.79it/s]
epoch 17200  training loss: 0.09510935842990875

 17%|█▋        | 17314/100000 [09:42<46:22, 29.72it/s]
epoch 17300  training loss: 0.09515618532896042


 17%|█▋        | 17434/100000 [09:46<46:11, 29.79it/s]
epoch 17400  training loss: 0.09501378238201141


 18%|█▊        | 17554/100000 [09:50<46:05, 29.81it/s]
epoch 17500  training loss: 0.09500376135110855

 18%|█▊        | 17614/100000 [09:52<46:06, 29.78it/s]
epoch 17600  training loss: 0.09504516422748566


 18%|█▊        | 17731/100000 [09:56<46:00, 29.80it/s]
epoch 17700  training loss: 0.09498579055070877


 18%|█▊        | 17848/100000 [10:00<46:01, 29.74it/s]
epoch 17800  training loss: 0.09521521627902985

 18%|█▊        | 17908/100000 [10:02<46:03, 29.70it/s]
epoch 17900  training loss: 0.09497323632240295


 18%|█▊        | 18028/100000 [10:06<45:54, 29.76it/s]
epoch 18000  training loss: 0.09496309608221054
epoch 18000  clean testing loss: 0.0029949552845209837


 18%|█▊        | 18148/100000 [10:10<45:48, 29.78it/s]
epoch 18100  training loss: 0.0949556827545166

 18%|█▊        | 18208/100000 [10:12<45:55, 29.68it/s]
epoch 18200  training loss: 0.09494741261005402


 18%|█▊        | 18325/100000 [10:16<45:49, 29.70it/s]
epoch 18300  training loss: 0.09494158625602722


 18%|█▊        | 18445/100000 [10:20<45:38, 29.79it/s]
epoch 18400  training loss: 0.09493270516395569

 19%|█▊        | 18505/100000 [10:22<45:46, 29.68it/s]
epoch 18500  training loss: 0.09571436792612076


 19%|█▊        | 18625/100000 [10:26<45:35, 29.75it/s]
epoch 18600  training loss: 0.09491986781358719


 19%|█▊        | 18742/100000 [10:30<45:34, 29.72it/s]
epoch 18700  training loss: 0.09491247683763504

 19%|█▉        | 18802/100000 [10:32<45:40, 29.63it/s]
epoch 18800  training loss: 0.09490495175123215


 19%|█▉        | 18922/100000 [10:36<45:21, 29.79it/s]
epoch 18900  training loss: 0.09489860385656357


 19%|█▉        | 19039/100000 [10:40<45:19, 29.77it/s]
epoch 19000  training loss: 0.09489172697067261
epoch 19000  clean testing loss: 0.0030511359218508005


 19%|█▉        | 19159/100000 [10:44<45:15, 29.77it/s]
epoch 19100  training loss: 0.09488292038440704

 19%|█▉        | 19219/100000 [10:46<45:17, 29.73it/s]
epoch 19200  training loss: 0.09496854245662689


 19%|█▉        | 19339/100000 [10:50<45:10, 29.76it/s]
epoch 19300  training loss: 0.09515199065208435


 19%|█▉        | 19456/100000 [10:54<45:03, 29.79it/s]
epoch 19400  training loss: 0.09486456215381622

 20%|█▉        | 19516/100000 [10:56<45:03, 29.77it/s]
epoch 19500  training loss: 0.09488190710544586


 20%|█▉        | 19633/100000 [11:00<45:27, 29.46it/s]
epoch 19600  training loss: 0.0948546975851059


 20%|█▉        | 19753/100000 [11:04<44:53, 29.79it/s]
epoch 19700  training loss: 0.09484589844942093

 20%|█▉        | 19813/100000 [11:06<44:55, 29.74it/s]
epoch 19800  training loss: 0.09485318511724472


 20%|█▉        | 19933/100000 [11:10<44:48, 29.79it/s]
epoch 19900  training loss: 0.09483276307582855


 20%|██        | 20053/100000 [11:14<44:44, 29.78it/s]
epoch 20000  training loss: 0.09482740610837936
epoch 20000  clean testing loss: 0.0031026583164930344

 20%|██        | 20110/100000 [11:16<44:45, 29.74it/s]
epoch 20100  training loss: 0.09482058137655258


 20%|██        | 20230/100000 [11:20<44:36, 29.80it/s]
epoch 20200  training loss: 0.09509851038455963


 20%|██        | 20350/100000 [11:24<44:34, 29.78it/s]
epoch 20300  training loss: 0.09481067210435867

 20%|██        | 20410/100000 [11:26<44:36, 29.73it/s]
epoch 20400  training loss: 0.09482207894325256


 21%|██        | 20527/100000 [11:30<45:06, 29.37it/s]
epoch 20500  training loss: 0.09479371458292007


 21%|██        | 20647/100000 [11:34<44:23, 29.79it/s]
epoch 20600  training loss: 0.09479127079248428

 21%|██        | 20707/100000 [11:36<44:28, 29.71it/s]
epoch 20700  training loss: 0.0947907343506813


 21%|██        | 20824/100000 [11:40<44:16, 29.81it/s]
epoch 20800  training loss: 0.09477643668651581


 21%|██        | 20944/100000 [11:44<44:10, 29.82it/s]
epoch 20900  training loss: 0.09477055072784424

 21%|██        | 21004/100000 [11:46<44:45, 29.42it/s]
epoch 21000  training loss: 0.09476612508296967
epoch 21000  clean testing loss: 0.0031630636658519506


 21%|██        | 21124/100000 [11:50<44:09, 29.77it/s]
epoch 21100  training loss: 0.09476102143526077


 21%|██        | 21244/100000 [11:54<44:04, 29.79it/s]
epoch 21200  training loss: 0.09475479274988174

 21%|██▏       | 21301/100000 [11:56<44:05, 29.75it/s]
epoch 21300  training loss: 0.09475070238113403


 21%|██▏       | 21421/100000 [12:00<44:39, 29.33it/s]
epoch 21400  training loss: 0.09474536031484604


 22%|██▏       | 21538/100000 [12:04<43:54, 29.78it/s]
epoch 21500  training loss: 0.0947427973151207


 22%|██▏       | 21658/100000 [12:08<43:48, 29.81it/s]
epoch 21600  training loss: 0.09475468844175339

 22%|██▏       | 21718/100000 [12:10<43:49, 29.77it/s]
epoch 21700  training loss: 0.09473691135644913


 22%|██▏       | 21838/100000 [12:14<43:44, 29.78it/s]
epoch 21800  training loss: 0.09480102360248566


 22%|██▏       | 21958/100000 [12:18<43:37, 29.82it/s]
epoch 21900  training loss: 0.09471797198057175

 22%|██▏       | 22015/100000 [12:20<43:48, 29.67it/s]
epoch 22000  training loss: 0.0947132557630539
epoch 22000  clean testing loss: 0.0032125660218298435


 22%|██▏       | 22135/100000 [12:24<43:31, 29.81it/s]
epoch 22100  training loss: 0.09471876174211502


 22%|██▏       | 22255/100000 [12:28<43:28, 29.80it/s]
epoch 22200  training loss: 0.09470163285732269

 22%|██▏       | 22312/100000 [12:30<44:29, 29.10it/s]
epoch 22300  training loss: 0.09469882398843765


 22%|██▏       | 22432/100000 [12:34<43:22, 29.81it/s]
epoch 22400  training loss: 0.09469271451234818


 23%|██▎       | 22552/100000 [12:38<43:17, 29.82it/s]
epoch 22500  training loss: 0.09468913078308105

 23%|██▎       | 22612/100000 [12:40<43:21, 29.75it/s]
epoch 22600  training loss: 0.09468194097280502


 23%|██▎       | 22732/100000 [12:44<43:12, 29.80it/s]
epoch 22700  training loss: 0.09467504918575287


 23%|██▎       | 22849/100000 [12:48<43:07, 29.81it/s]
epoch 22800  training loss: 0.09466928243637085

 23%|██▎       | 22909/100000 [12:50<43:15, 29.71it/s]
epoch 22900  training loss: 0.09467138350009918


 23%|██▎       | 23029/100000 [12:54<43:01, 29.81it/s]
epoch 23000  training loss: 0.09467341005802155
epoch 23000  clean testing loss: 0.0032427916303277016


 23%|██▎       | 23149/100000 [12:58<43:00, 29.78it/s]
epoch 23100  training loss: 0.09465761482715607

 23%|██▎       | 23206/100000 [13:00<44:53, 28.51it/s]
epoch 23200  training loss: 0.09499697387218475


 23%|██▎       | 23326/100000 [13:04<42:56, 29.76it/s]
epoch 23300  training loss: 0.09464230388402939


 23%|██▎       | 23443/100000 [13:08<42:52, 29.76it/s]
epoch 23400  training loss: 0.09463765472173691

 24%|██▎       | 23503/100000 [13:10<43:00, 29.65it/s]
epoch 23500  training loss: 0.09466005861759186


 24%|██▎       | 23623/100000 [13:14<42:45, 29.77it/s]
epoch 23600  training loss: 0.09462641924619675


 24%|██▎       | 23743/100000 [13:18<42:41, 29.77it/s]
epoch 23700  training loss: 0.09462147206068039

 24%|██▍       | 23803/100000 [13:20<42:51, 29.63it/s]
epoch 23800  training loss: 0.09461867064237595


 24%|██▍       | 23923/100000 [13:24<42:36, 29.76it/s]
epoch 23900  training loss: 0.0946108028292656


 24%|██▍       | 24040/100000 [13:28<42:32, 29.76it/s]
epoch 24000  training loss: 0.09461186081171036
epoch 24000  clean testing loss: 0.0033355308696627617


 24%|██▍       | 24157/100000 [13:32<42:22, 29.83it/s]
epoch 24100  training loss: 0.09460122883319855

 24%|██▍       | 24217/100000 [13:34<42:26, 29.77it/s]
epoch 24200  training loss: 0.09459524601697922


 24%|██▍       | 24337/100000 [13:38<42:17, 29.82it/s]
epoch 24300  training loss: 0.09459185600280762


 24%|██▍       | 24457/100000 [13:42<42:14, 29.80it/s]
epoch 24400  training loss: 0.09458572417497635

 25%|██▍       | 24517/100000 [13:44<42:17, 29.75it/s]
epoch 24500  training loss: 0.09460300207138062


 25%|██▍       | 24634/100000 [13:48<42:10, 29.78it/s]
epoch 24600  training loss: 0.09457708895206451


 25%|██▍       | 24754/100000 [13:52<42:01, 29.84it/s]
epoch 24700  training loss: 0.09457243978977203

 25%|██▍       | 24814/100000 [13:54<42:05, 29.77it/s]
epoch 24800  training loss: 0.09462036192417145


 25%|██▍       | 24934/100000 [13:58<41:58, 29.81it/s]
epoch 24900  training loss: 0.0945618599653244


 25%|██▌       | 25051/100000 [14:02<41:54, 29.81it/s]
epoch 25000  training loss: 0.09456675499677658
epoch 25000  clean testing loss: 0.0033912803046405315

 25%|██▌       | 25111/100000 [14:04<41:57, 29.75it/s]
epoch 25100  training loss: 0.09457563608884811


 25%|██▌       | 25231/100000 [14:08<41:49, 29.80it/s]
epoch 25200  training loss: 0.0945475623011589


 25%|██▌       | 25348/100000 [14:12<41:43, 29.82it/s]
epoch 25300  training loss: 0.09454253315925598

 25%|██▌       | 25408/100000 [14:14<41:50, 29.72it/s]
epoch 25400  training loss: 0.09453711658716202


 26%|██▌       | 25528/100000 [14:18<41:41, 29.77it/s]
epoch 25500  training loss: 0.09453096240758896


 26%|██▌       | 25648/100000 [14:22<41:32, 29.83it/s]
epoch 25600  training loss: 0.09452956169843674

 26%|██▌       | 25708/100000 [14:24<41:40, 29.72it/s]
epoch 25700  training loss: 0.09452448785305023


 26%|██▌       | 25825/100000 [14:28<41:35, 29.72it/s]
epoch 25800  training loss: 0.09451957792043686


 26%|██▌       | 25945/100000 [14:32<41:31, 29.73it/s]
epoch 25900  training loss: 0.0947282463312149

 26%|██▌       | 26005/100000 [14:34<42:00, 29.36it/s]
epoch 26000  training loss: 0.09450677037239075
epoch 26000  clean testing loss: 0.003404229646548629


 26%|██▌       | 26122/100000 [14:38<41:18, 29.80it/s]
epoch 26100  training loss: 0.09464865922927856


 26%|██▌       | 26242/100000 [14:42<41:14, 29.81it/s]
epoch 26200  training loss: 0.09449990838766098

 26%|██▋       | 26302/100000 [14:44<41:29, 29.60it/s]
epoch 26300  training loss: 0.09449123591184616


 26%|██▋       | 26422/100000 [14:48<41:13, 29.74it/s]
epoch 26400  training loss: 0.09449931234121323


 27%|██▋       | 26542/100000 [14:52<41:05, 29.80it/s]
epoch 26500  training loss: 0.09458735585212708

 27%|██▋       | 26602/100000 [14:55<41:17, 29.63it/s]
epoch 26600  training loss: 0.09447666257619858


 27%|██▋       | 26719/100000 [14:58<41:09, 29.68it/s]
epoch 26700  training loss: 0.09449950605630875


 27%|██▋       | 26839/100000 [15:03<40:54, 29.81it/s]
epoch 26800  training loss: 0.09461182355880737


 27%|██▋       | 26956/100000 [15:06<40:58, 29.71it/s]
epoch 26900  training loss: 0.09454689919948578

 27%|██▋       | 27016/100000 [15:08<40:59, 29.67it/s]
epoch 27000  training loss: 0.09445764869451523
epoch 27000  clean testing loss: 0.003455615136772394


 27%|██▋       | 27136/100000 [15:13<40:52, 29.71it/s]
epoch 27100  training loss: 0.09444725513458252


 27%|██▋       | 27256/100000 [15:17<40:42, 29.79it/s]
epoch 27200  training loss: 0.09444363415241241

 27%|██▋       | 27316/100000 [15:19<40:48, 29.68it/s]
epoch 27300  training loss: 0.09443722665309906


 27%|██▋       | 27433/100000 [15:22<40:37, 29.78it/s]
epoch 27400  training loss: 0.09443309158086777


 28%|██▊       | 27553/100000 [15:27<40:29, 29.82it/s]
epoch 27500  training loss: 0.09449394047260284

 28%|██▊       | 27598/100000 [15:28<40:30, 29.79it/s]
epoch 27600  training loss: 0.09442183375358582


 28%|██▊       | 27715/100000 [15:32<40:33, 29.70it/s]
epoch 27700  training loss: 0.0944158211350441


 28%|██▊       | 27835/100000 [15:36<40:20, 29.81it/s]
epoch 27800  training loss: 0.09440997987985611

 28%|██▊       | 27895/100000 [15:38<40:21, 29.78it/s]
epoch 27900  training loss: 0.09440452605485916


 28%|██▊       | 28012/100000 [15:42<40:28, 29.64it/s]
epoch 28000  training loss: 0.09440092742443085
epoch 28000  clean testing loss: 0.0034785522148013115


 28%|██▊       | 28132/100000 [15:46<40:10, 29.81it/s]
epoch 28100  training loss: 0.09439224749803543

 28%|██▊       | 28192/100000 [15:48<40:10, 29.79it/s]
epoch 28200  training loss: 0.09439490735530853


 28%|██▊       | 28312/100000 [15:52<40:09, 29.75it/s]
epoch 28300  training loss: 0.09438808262348175


 28%|██▊       | 28432/100000 [15:56<40:01, 29.80it/s]
epoch 28400  training loss: 0.09440402686595917

 28%|██▊       | 28489/100000 [15:58<40:03, 29.75it/s]
epoch 28500  training loss: 0.09436767548322678


 29%|██▊       | 28609/100000 [16:02<40:14, 29.57it/s]
epoch 28600  training loss: 0.09436079859733582


 29%|██▊       | 28726/100000 [16:06<39:53, 29.78it/s]
epoch 28700  training loss: 0.09435398131608963


 29%|██▉       | 28846/100000 [16:10<39:47, 29.80it/s]
epoch 28800  training loss: 0.09436842799186707

 29%|██▉       | 28906/100000 [16:12<39:56, 29.66it/s]
epoch 28900  training loss: 0.0943579226732254


 29%|██▉       | 29026/100000 [16:16<39:43, 29.78it/s]
epoch 29000  training loss: 0.094350166618824
epoch 29000  clean testing loss: 0.0035917009226977825


 29%|██▉       | 29143/100000 [16:20<39:37, 29.80it/s]
epoch 29100  training loss: 0.09432846307754517

 29%|██▉       | 29203/100000 [16:22<39:47, 29.65it/s]
epoch 29200  training loss: 0.09432544559240341


 29%|██▉       | 29323/100000 [16:26<39:33, 29.78it/s]
epoch 29300  training loss: 0.09435568004846573


 29%|██▉       | 29443/100000 [16:30<39:27, 29.81it/s]
epoch 29400  training loss: 0.09431211650371552

 30%|██▉       | 29500/100000 [16:32<39:44, 29.56it/s]
epoch 29500  training loss: 0.09430519491434097


 30%|██▉       | 29620/100000 [16:36<39:22, 29.79it/s]
epoch 29600  training loss: 0.09429945796728134


 30%|██▉       | 29740/100000 [16:40<39:16, 29.81it/s]
epoch 29700  training loss: 0.0943368598818779


 30%|██▉       | 29860/100000 [16:44<39:12, 29.81it/s]
epoch 29800  training loss: 0.09433014690876007

 30%|██▉       | 29917/100000 [16:46<39:15, 29.75it/s]
epoch 29900  training loss: 0.09427916258573532


 30%|███       | 30037/100000 [16:50<39:08, 29.79it/s]
epoch 30000  training loss: 0.09427458047866821
epoch 30000  clean testing loss: 0.0035894950851798058


 30%|███       | 30157/100000 [16:54<39:02, 29.81it/s]
epoch 30100  training loss: 0.09426754713058472

 30%|███       | 30217/100000 [16:56<39:03, 29.78it/s]
epoch 30200  training loss: 0.09426344931125641


 30%|███       | 30337/100000 [17:00<38:58, 29.80it/s]
epoch 30300  training loss: 0.0942564457654953


 30%|███       | 30454/100000 [17:04<38:52, 29.81it/s]
epoch 30400  training loss: 0.09425067156553268

 31%|███       | 30514/100000 [17:06<38:57, 29.73it/s]
epoch 30500  training loss: 0.0943007692694664


 31%|███       | 30631/100000 [17:10<38:47, 29.81it/s]
epoch 30600  training loss: 0.0942445695400238


 31%|███       | 30751/100000 [17:14<38:43, 29.80it/s]
epoch 30700  training loss: 0.09423409402370453

 31%|███       | 30811/100000 [17:16<38:44, 29.77it/s]
epoch 30800  training loss: 0.09422696381807327


 31%|███       | 30931/100000 [17:20<38:31, 29.88it/s]
epoch 30900  training loss: 0.09422256797552109


 31%|███       | 31051/100000 [17:24<38:28, 29.87it/s]
epoch 31000  training loss: 0.09421734511852264
epoch 31000  clean testing loss: 0.0036283056251704693

 31%|███       | 31111/100000 [17:26<38:29, 29.83it/s]
epoch 31100  training loss: 0.09423794597387314


 31%|███       | 31229/100000 [17:30<38:08, 30.06it/s]
epoch 31200  training loss: 0.09423664212226868


 31%|███▏      | 31347/100000 [17:34<38:03, 30.07it/s]
epoch 31300  training loss: 0.09419839829206467

 31%|███▏      | 31410/100000 [17:36<38:08, 29.97it/s]
epoch 31400  training loss: 0.09419955313205719


 32%|███▏      | 31529/100000 [17:40<38:17, 29.80it/s]
epoch 31500  training loss: 0.09419170767068863


 32%|███▏      | 31649/100000 [17:44<38:15, 29.78it/s]
epoch 31600  training loss: 0.09418291598558426

 32%|███▏      | 31706/100000 [17:46<38:19, 29.70it/s]
epoch 31700  training loss: 0.09419426321983337


 32%|███▏      | 31826/100000 [17:50<38:08, 29.79it/s]
epoch 31800  training loss: 0.09417617321014404


 32%|███▏      | 31946/100000 [17:54<38:03, 29.80it/s]
epoch 31900  training loss: 0.09418215602636337

 32%|███▏      | 32006/100000 [17:56<38:41, 29.29it/s]
epoch 32000  training loss: 0.09416983276605606
epoch 32000  clean testing loss: 0.0036837738007307053


 32%|███▏      | 32126/100000 [18:00<37:56, 29.81it/s]
epoch 32100  training loss: 0.09415560960769653


 32%|███▏      | 32243/100000 [18:04<37:53, 29.80it/s]
epoch 32200  training loss: 0.09415380656719208

 32%|███▏      | 32303/100000 [18:06<38:04, 29.64it/s]
epoch 32300  training loss: 0.09414460510015488


 32%|███▏      | 32420/100000 [18:10<37:49, 29.78it/s]
epoch 32400  training loss: 0.09414704144001007


 33%|███▎      | 32540/100000 [18:14<37:43, 29.80it/s]
epoch 32500  training loss: 0.09413319081068039

 33%|███▎      | 32600/100000 [18:16<37:40, 29.82it/s]
epoch 32600  training loss: 0.09412921965122223


 33%|███▎      | 32720/100000 [18:20<37:38, 29.79it/s]
epoch 32700  training loss: 0.09412410110235214


 33%|███▎      | 32840/100000 [18:24<37:32, 29.81it/s]
epoch 32800  training loss: 0.09417525678873062


 33%|███▎      | 32957/100000 [18:28<37:29, 29.81it/s]
epoch 32900  training loss: 0.0941198393702507

 33%|███▎      | 33017/100000 [18:30<37:36, 29.69it/s]
epoch 33000  training loss: 0.094108946621418
epoch 33000  clean testing loss: 0.003739297389984131


 33%|███▎      | 33137/100000 [18:34<37:22, 29.82it/s]
epoch 33100  training loss: 0.09410340338945389


 33%|███▎      | 33254/100000 [18:38<37:16, 29.84it/s]
epoch 33200  training loss: 0.09410075098276138

 33%|███▎      | 33314/100000 [18:40<37:20, 29.76it/s]
epoch 33300  training loss: 0.09409628808498383


 33%|███▎      | 33434/100000 [18:44<37:12, 29.81it/s]
epoch 33400  training loss: 0.09409038722515106


 34%|███▎      | 33554/100000 [18:48<37:08, 29.82it/s]
epoch 33500  training loss: 0.09408865869045258

 34%|███▎      | 33614/100000 [18:50<37:09, 29.77it/s]
epoch 33600  training loss: 0.09408411383628845


 34%|███▎      | 33731/100000 [18:54<37:03, 29.80it/s]
epoch 33700  training loss: 0.0940791592001915


 34%|███▍      | 33851/100000 [18:58<37:04, 29.74it/s]
epoch 33800  training loss: 0.094075046479702

 34%|███▍      | 33911/100000 [19:00<36:58, 29.79it/s]
epoch 33900  training loss: 0.09407296776771545


 34%|███▍      | 34028/100000 [19:04<36:56, 29.76it/s]
epoch 34000  training loss: 0.09406454861164093
epoch 34000  clean testing loss: 0.003784400410950184


 34%|███▍      | 34148/100000 [19:08<36:51, 29.78it/s]
epoch 34100  training loss: 0.09405867755413055

 34%|███▍      | 34208/100000 [19:11<36:50, 29.76it/s]
epoch 34200  training loss: 0.09405498951673508


 34%|███▍      | 34328/100000 [19:15<36:42, 29.81it/s]
epoch 34300  training loss: 0.09405244141817093


 34%|███▍      | 34445/100000 [19:18<36:38, 29.81it/s]
epoch 34400  training loss: 0.09404711425304413

 35%|███▍      | 34505/100000 [19:20<36:47, 29.67it/s]
epoch 34500  training loss: 0.09404397010803223


 35%|███▍      | 34625/100000 [19:25<36:34, 29.79it/s]
epoch 34600  training loss: 0.09403826296329498


 35%|███▍      | 34745/100000 [19:29<36:35, 29.73it/s]
epoch 34700  training loss: 0.09403309226036072

 35%|███▍      | 34805/100000 [19:31<36:33, 29.72it/s]
epoch 34800  training loss: 0.09402908384799957


 35%|███▍      | 34922/100000 [19:35<36:23, 29.80it/s]
epoch 34900  training loss: 0.09403549134731293


 35%|███▌      | 35042/100000 [19:39<36:22, 29.77it/s]
epoch 35000  training loss: 0.09402100741863251
epoch 35000  clean testing loss: 0.003834990318864584

 35%|███▌      | 35099/100000 [19:41<36:16, 29.82it/s]
epoch 35100  training loss: 0.09401673078536987


 35%|███▌      | 35219/100000 [19:45<36:18, 29.73it/s]
epoch 35200  training loss: 0.09401276707649231


 35%|███▌      | 35339/100000 [19:49<36:07, 29.83it/s]
epoch 35300  training loss: 0.09400828927755356


 35%|███▌      | 35459/100000 [19:53<36:04, 29.82it/s]
epoch 35400  training loss: 0.09400859475135803

 36%|███▌      | 35519/100000 [19:55<36:13, 29.66it/s]
epoch 35500  training loss: 0.09400466829538345


 36%|███▌      | 35636/100000 [19:59<36:11, 29.65it/s]
epoch 35600  training loss: 0.09407123923301697


 36%|███▌      | 35756/100000 [20:03<38:51, 27.55it/s]
epoch 35700  training loss: 0.09399907290935516

 36%|███▌      | 35813/100000 [20:05<35:56, 29.76it/s]
epoch 35800  training loss: 0.09398721903562546


 36%|███▌      | 35933/100000 [20:09<35:50, 29.79it/s]
epoch 35900  training loss: 0.09398317337036133


 36%|███▌      | 36053/100000 [20:13<35:52, 29.71it/s]
epoch 36000  training loss: 0.09397940337657928
epoch 36000  clean testing loss: 0.003890362335368991

 36%|███▌      | 36113/100000 [20:15<35:46, 29.76it/s]
epoch 36100  training loss: 0.09397556632757187


 36%|███▌      | 36233/100000 [20:19<35:38, 29.82it/s]
epoch 36200  training loss: 0.0939706414937973


 36%|███▋      | 36350/100000 [20:23<35:40, 29.74it/s]
epoch 36300  training loss: 0.09396711736917496

 36%|███▋      | 36410/100000 [20:25<35:47, 29.62it/s]
epoch 36400  training loss: 0.09396463632583618


 37%|███▋      | 36530/100000 [20:29<35:37, 29.69it/s]
epoch 36500  training loss: 0.09396080672740936


 37%|███▋      | 36647/100000 [20:33<39:44, 26.57it/s]
epoch 36600  training loss: 0.09395712614059448

 37%|███▋      | 36707/100000 [20:35<35:28, 29.73it/s]
epoch 36700  training loss: 0.09395261853933334


 37%|███▋      | 36827/100000 [20:39<35:19, 29.81it/s]
epoch 36800  training loss: 0.09396525472402573


 37%|███▋      | 36947/100000 [20:43<35:14, 29.81it/s]
epoch 36900  training loss: 0.09394481033086777

 37%|███▋      | 37007/100000 [20:45<35:32, 29.54it/s]
epoch 37000  training loss: 0.09394101053476334
epoch 37000  clean testing loss: 0.003935137763619423


 37%|███▋      | 37124/100000 [20:49<35:10, 29.79it/s]
epoch 37100  training loss: 0.09396117180585861


 37%|███▋      | 37244/100000 [20:53<35:04, 29.83it/s]
epoch 37200  training loss: 0.09393312782049179

 37%|███▋      | 37304/100000 [20:55<35:22, 29.53it/s]
epoch 37300  training loss: 0.09392987936735153


 37%|███▋      | 37424/100000 [20:59<35:02, 29.76it/s]
epoch 37400  training loss: 0.09392523020505905


 38%|███▊      | 37544/100000 [21:03<34:56, 29.80it/s]
epoch 37500  training loss: 0.09392061084508896

 38%|███▊      | 37601/100000 [21:05<34:57, 29.75it/s]
epoch 37600  training loss: 0.09391780942678452


 38%|███▊      | 37721/100000 [21:09<34:47, 29.83it/s]
epoch 37700  training loss: 0.09391359984874725


 38%|███▊      | 37838/100000 [21:13<34:44, 29.82it/s]
epoch 37800  training loss: 0.0939081460237503


 38%|███▊      | 37958/100000 [21:17<34:40, 29.82it/s]
epoch 37900  training loss: 0.09390425682067871

 38%|███▊      | 38018/100000 [21:19<34:47, 29.70it/s]
epoch 38000  training loss: 0.09390293061733246
epoch 38000  clean testing loss: 0.003961883019655943


 38%|███▊      | 38138/100000 [21:23<34:36, 29.79it/s]
epoch 38100  training loss: 0.09389648586511612


 38%|███▊      | 38258/100000 [21:27<34:29, 29.83it/s]
epoch 38200  training loss: 0.09389270842075348

 38%|███▊      | 38315/100000 [21:29<34:33, 29.75it/s]
epoch 38300  training loss: 0.09390830993652344


 38%|███▊      | 38435/100000 [21:33<34:27, 29.78it/s]
epoch 38400  training loss: 0.09392426162958145


 39%|███▊      | 38552/100000 [21:37<34:19, 29.83it/s]
epoch 38500  training loss: 0.0938795879483223

 39%|███▊      | 38612/100000 [21:39<34:23, 29.74it/s]
epoch 38600  training loss: 0.09387832880020142


 39%|███▊      | 38732/100000 [21:43<34:16, 29.79it/s]
epoch 38700  training loss: 0.09387357532978058


 39%|███▉      | 38852/100000 [21:47<34:12, 29.79it/s]
epoch 38800  training loss: 0.09386882185935974

 39%|███▉      | 38912/100000 [21:49<34:12, 29.76it/s]
epoch 38900  training loss: 0.0938638374209404


 39%|███▉      | 39029/100000 [21:53<34:05, 29.80it/s]
epoch 39000  training loss: 0.09386157244443893
epoch 39000  clean testing loss: 0.004038880579173565


 39%|███▉      | 39149/100000 [21:57<34:02, 29.80it/s]
epoch 39100  training loss: 0.09385911375284195

 39%|███▉      | 39209/100000 [21:59<34:04, 29.74it/s]
epoch 39200  training loss: 0.09385441988706589


 39%|███▉      | 39329/100000 [22:03<33:57, 29.78it/s]
epoch 39300  training loss: 0.09385087341070175


 39%|███▉      | 39446/100000 [22:07<33:52, 29.80it/s]
epoch 39400  training loss: 0.09384751319885254

 40%|███▉      | 39506/100000 [22:09<33:55, 29.72it/s]
epoch 39500  training loss: 0.09384757280349731


 40%|███▉      | 39626/100000 [22:13<33:45, 29.81it/s]
epoch 39600  training loss: 0.09384040534496307


 40%|███▉      | 39746/100000 [22:17<33:39, 29.83it/s]
epoch 39700  training loss: 0.09383692592382431

 40%|███▉      | 39803/100000 [22:19<33:48, 29.67it/s]
epoch 39800  training loss: 0.093838632106781


 40%|███▉      | 39923/100000 [22:23<33:35, 29.80it/s]
epoch 39900  training loss: 0.0938330814242363


 40%|████      | 40043/100000 [22:27<33:29, 29.83it/s]
epoch 40000  training loss: 0.0938301607966423
epoch 40000  clean testing loss: 0.004045707173645496

 40%|████      | 40103/100000 [22:29<33:41, 29.63it/s]
epoch 40100  training loss: 0.09382115304470062


 40%|████      | 40223/100000 [22:33<33:25, 29.80it/s]
epoch 40200  training loss: 0.09381759911775589


 40%|████      | 40340/100000 [22:37<33:20, 29.82it/s]
epoch 40300  training loss: 0.09381554275751114

 40%|████      | 40400/100000 [22:39<33:19, 29.80it/s]
epoch 40400  training loss: 0.09381202608346939


 41%|████      | 40520/100000 [22:43<33:15, 29.80it/s]
epoch 40500  training loss: 0.0938085988163948


 41%|████      | 40637/100000 [22:47<33:11, 29.81it/s]
epoch 40600  training loss: 0.09380386769771576


 41%|████      | 40757/100000 [22:51<33:07, 29.82it/s]
epoch 40700  training loss: 0.09380188584327698

 41%|████      | 40817/100000 [22:53<33:05, 29.80it/s]
epoch 40800  training loss: 0.09379912912845612


 41%|████      | 40922/100000 [22:56<33:03, 29.78it/s]
epoch 40900  training loss: 0.09379497915506363


 41%|████      | 41042/100000 [23:01<32:58, 29.80it/s]
epoch 41000  training loss: 0.09379702061414719
epoch 41000  clean testing loss: 0.004097376950085163

 41%|████      | 41099/100000 [23:02<32:55, 29.82it/s]
epoch 41100  training loss: 0.09378840029239655


 41%|████      | 41219/100000 [23:07<32:54, 29.77it/s]
epoch 41200  training loss: 0.09378369897603989


 41%|████▏     | 41336/100000 [23:10<32:47, 29.82it/s]
epoch 41300  training loss: 0.09378042817115784

 41%|████▏     | 41396/100000 [23:12<32:46, 29.80it/s]
epoch 41400  training loss: 0.09377849847078323


 42%|████▏     | 41516/100000 [23:17<32:44, 29.76it/s]
epoch 41500  training loss: 0.09377394616603851


 42%|████▏     | 41636/100000 [23:21<32:41, 29.76it/s]
epoch 41600  training loss: 0.09377193450927734

 42%|████▏     | 41696/100000 [23:23<32:34, 29.83it/s]
epoch 41700  training loss: 0.09377708286046982


 42%|████▏     | 41813/100000 [23:26<32:35, 29.76it/s]
epoch 41800  training loss: 0.09376426786184311


 42%|████▏     | 41933/100000 [23:31<32:28, 29.81it/s]
epoch 41900  training loss: 0.09377472847700119


 42%|████▏     | 42050/100000 [23:35<33:07, 29.16it/s]
epoch 42000  training loss: 0.09376101195812225
epoch 42000  clean testing loss: 0.004173006396740675

 42%|████▏     | 42110/100000 [23:37<32:26, 29.74it/s]
epoch 42100  training loss: 0.09375669807195663


 42%|████▏     | 42230/100000 [23:41<32:18, 29.80it/s]
epoch 42200  training loss: 0.09375395625829697


 42%|████▏     | 42350/100000 [23:45<32:14, 29.80it/s]
epoch 42300  training loss: 0.09375003725290298

 42%|████▏     | 42410/100000 [23:47<32:16, 29.74it/s]
epoch 42400  training loss: 0.0937483161687851


 43%|████▎     | 42527/100000 [23:51<32:08, 29.80it/s]
epoch 42500  training loss: 0.09374555200338364


 43%|████▎     | 42647/100000 [23:55<32:14, 29.65it/s]
epoch 42600  training loss: 0.09374123066663742

 43%|████▎     | 42707/100000 [23:57<32:08, 29.71it/s]
epoch 42700  training loss: 0.0937383770942688


 43%|████▎     | 42827/100000 [24:01<31:58, 29.80it/s]
epoch 42800  training loss: 0.09373573213815689


 43%|████▎     | 42944/100000 [24:05<32:37, 29.15it/s]
epoch 42900  training loss: 0.09373541176319122

 43%|████▎     | 43004/100000 [24:07<32:21, 29.36it/s]
epoch 43000  training loss: 0.09373099356889725
epoch 43000  clean testing loss: 0.004194284789264202


 43%|████▎     | 43124/100000 [24:11<31:48, 29.80it/s]
epoch 43100  training loss: 0.09372792392969131


 43%|████▎     | 43241/100000 [24:15<31:47, 29.76it/s]
epoch 43200  training loss: 0.09372516721487045

 43%|████▎     | 43301/100000 [24:17<31:44, 29.77it/s]
epoch 43300  training loss: 0.09372223913669586


 43%|████▎     | 43421/100000 [24:21<31:38, 29.80it/s]
epoch 43400  training loss: 0.09372072666883469


 44%|████▎     | 43541/100000 [24:25<31:50, 29.55it/s]
epoch 43500  training loss: 0.09371837228536606

 44%|████▎     | 43601/100000 [24:27<31:34, 29.76it/s]
epoch 43600  training loss: 0.09371252357959747


 44%|████▎     | 43718/100000 [24:31<31:30, 29.76it/s]
epoch 43700  training loss: 0.0937110036611557


 44%|████▍     | 43838/100000 [24:35<32:14, 29.03it/s]
epoch 43800  training loss: 0.09370826184749603


 44%|████▍     | 43955/100000 [24:39<31:22, 29.77it/s]
epoch 43900  training loss: 0.09371384978294373

 44%|████▍     | 44015/100000 [24:41<31:26, 29.68it/s]
epoch 44000  training loss: 0.09370449930429459
epoch 44000  clean testing loss: 0.0042450702749192715


 44%|████▍     | 44135/100000 [24:45<31:16, 29.78it/s]
epoch 44100  training loss: 0.09370241314172745


 44%|████▍     | 44255/100000 [24:49<31:09, 29.82it/s]
epoch 44200  training loss: 0.09369585663080215

 44%|████▍     | 44315/100000 [24:51<31:09, 29.79it/s]
epoch 44300  training loss: 0.09369337558746338


 44%|████▍     | 44435/100000 [24:55<31:07, 29.75it/s]
epoch 44400  training loss: 0.09369170665740967


 45%|████▍     | 44552/100000 [24:59<31:02, 29.77it/s]
epoch 44500  training loss: 0.09368898719549179

 45%|████▍     | 44612/100000 [25:01<31:03, 29.73it/s]
epoch 44600  training loss: 0.09368620812892914


 45%|████▍     | 44732/100000 [25:05<31:53, 28.89it/s]
epoch 44700  training loss: 0.09368234872817993


 45%|████▍     | 44849/100000 [25:09<30:48, 29.83it/s]
epoch 44800  training loss: 0.09367972612380981

 45%|████▍     | 44909/100000 [25:11<30:54, 29.70it/s]
epoch 44900  training loss: 0.09367982298135757


 45%|████▌     | 45029/100000 [25:15<30:45, 29.79it/s]
epoch 45000  training loss: 0.09367411583662033
epoch 45000  clean testing loss: 0.004269692115485668


 45%|████▌     | 45149/100000 [25:19<30:41, 29.78it/s]
epoch 45100  training loss: 0.09367185086011887

 45%|████▌     | 45209/100000 [25:21<30:42, 29.74it/s]
epoch 45200  training loss: 0.0936683714389801


 45%|████▌     | 45326/100000 [25:25<30:43, 29.66it/s]
epoch 45300  training loss: 0.0936674103140831


 45%|████▌     | 45446/100000 [25:29<30:31, 29.78it/s]
epoch 45400  training loss: 0.09366487711668015

 46%|████▌     | 45506/100000 [25:31<30:34, 29.70it/s]
epoch 45500  training loss: 0.09366927295923233


 46%|████▌     | 45623/100000 [25:35<32:32, 27.85it/s]
epoch 45600  training loss: 0.09366238862276077


 46%|████▌     | 45743/100000 [25:39<30:21, 29.79it/s]
epoch 45700  training loss: 0.09365814924240112

 46%|████▌     | 45803/100000 [25:41<30:26, 29.68it/s]
epoch 45800  training loss: 0.09365495294332504


 46%|████▌     | 45923/100000 [25:45<30:16, 29.76it/s]
epoch 45900  training loss: 0.09365098923444748


 46%|████▌     | 46040/100000 [25:49<30:23, 29.59it/s]
epoch 46000  training loss: 0.09365004301071167
epoch 46000  clean testing loss: 0.004302022513002157

 46%|████▌     | 46100/100000 [25:51<30:07, 29.82it/s]
epoch 46100  training loss: 0.09364606440067291


 46%|████▌     | 46220/100000 [25:55<30:09, 29.72it/s]
epoch 46200  training loss: 0.09364491701126099


 46%|████▋     | 46340/100000 [25:59<30:00, 29.80it/s]
epoch 46300  training loss: 0.0936439037322998


 46%|████▋     | 46460/100000 [26:03<29:57, 29.79it/s]
epoch 46400  training loss: 0.09363886713981628

 47%|████▋     | 46517/100000 [26:05<32:19, 27.57it/s]
epoch 46500  training loss: 0.0936364009976387


 47%|████▋     | 46637/100000 [26:09<29:49, 29.82it/s]
epoch 46600  training loss: 0.09363504499197006


 47%|████▋     | 46757/100000 [26:13<29:45, 29.82it/s]
epoch 46700  training loss: 0.09363250434398651

 47%|████▋     | 46817/100000 [26:15<29:49, 29.72it/s]
epoch 46800  training loss: 0.09362881630659103


 47%|████▋     | 46934/100000 [26:19<29:39, 29.83it/s]
epoch 46900  training loss: 0.09362810105085373


 47%|████▋     | 47054/100000 [26:23<29:38, 29.78it/s]
epoch 47000  training loss: 0.09362516552209854
epoch 47000  clean testing loss: 0.004329797346144915

 47%|████▋     | 47114/100000 [26:25<29:38, 29.73it/s]
epoch 47100  training loss: 0.09362253546714783


 47%|████▋     | 47234/100000 [26:29<29:31, 29.79it/s]
epoch 47200  training loss: 0.09362004697322845


 47%|████▋     | 47351/100000 [26:33<29:29, 29.76it/s]
epoch 47300  training loss: 0.09361764043569565

 47%|████▋     | 47411/100000 [26:35<32:47, 26.74it/s]
epoch 47400  training loss: 0.09361368417739868


 48%|████▊     | 47531/100000 [26:39<29:21, 29.78it/s]
epoch 47500  training loss: 0.09361183643341064


 48%|████▊     | 47648/100000 [26:43<29:17, 29.78it/s]
epoch 47600  training loss: 0.09361077845096588

 48%|████▊     | 47708/100000 [26:45<29:24, 29.63it/s]
epoch 47700  training loss: 0.09360732138156891


 48%|████▊     | 47828/100000 [26:49<29:11, 29.78it/s]
epoch 47800  training loss: 0.09360382705926895


 48%|████▊     | 47948/100000 [26:53<29:06, 29.81it/s]
epoch 47900  training loss: 0.09360268712043762

 48%|████▊     | 48008/100000 [26:55<29:21, 29.51it/s]
epoch 48000  training loss: 0.0935991033911705
epoch 48000  clean testing loss: 0.004366202279925346


 48%|████▊     | 48125/100000 [26:59<29:01, 29.78it/s]
epoch 48100  training loss: 0.09359660744667053


 48%|████▊     | 48245/100000 [27:03<28:55, 29.82it/s]
epoch 48200  training loss: 0.09359454363584518

 48%|████▊     | 48305/100000 [27:05<32:38, 26.40it/s]
epoch 48300  training loss: 0.09359367936849594


 48%|████▊     | 48422/100000 [27:09<28:51, 29.79it/s]
epoch 48400  training loss: 0.09358996152877808


 49%|████▊     | 48542/100000 [27:13<28:45, 29.83it/s]
epoch 48500  training loss: 0.09358947724103928

 49%|████▊     | 48602/100000 [27:15<28:52, 29.67it/s]
epoch 48600  training loss: 0.09358661621809006


 49%|████▊     | 48722/100000 [27:19<28:42, 29.76it/s]
epoch 48700  training loss: 0.09358439594507217


 49%|████▉     | 48842/100000 [27:23<28:35, 29.83it/s]
epoch 48800  training loss: 0.09358051419258118

 49%|████▉     | 48902/100000 [27:25<28:44, 29.63it/s]
epoch 48900  training loss: 0.0935792326927185


 49%|████▉     | 49019/100000 [27:29<28:36, 29.70it/s]
epoch 49000  training loss: 0.09357678890228271
epoch 49000  clean testing loss: 0.004389228764921427


 49%|████▉     | 49139/100000 [27:33<28:31, 29.71it/s]
epoch 49100  training loss: 0.09357453882694244


 49%|████▉     | 49256/100000 [27:37<28:23, 29.79it/s]
epoch 49200  training loss: 0.09357208013534546

 49%|████▉     | 49316/100000 [27:39<28:21, 29.79it/s]
epoch 49300  training loss: 0.09356821328401566


 49%|████▉     | 49436/100000 [27:43<28:16, 29.81it/s]
epoch 49400  training loss: 0.09356707334518433


 50%|████▉     | 49556/100000 [27:47<28:11, 29.83it/s]
epoch 49500  training loss: 0.09356331825256348

 50%|████▉     | 49616/100000 [27:49<28:11, 29.79it/s]
epoch 49600  training loss: 0.09356217086315155


 50%|████▉     | 49733/100000 [27:53<28:09, 29.75it/s]
epoch 49700  training loss: 0.09355957806110382


 50%|████▉     | 49853/100000 [27:57<28:01, 29.83it/s]
epoch 49800  training loss: 0.09355705231428146

 50%|████▉     | 49913/100000 [27:59<28:02, 29.78it/s]
epoch 49900  training loss: 0.09355461597442627


 50%|█████     | 50033/100000 [28:03<27:58, 29.77it/s]
epoch 50000  training loss: 0.09355175495147705
epoch 50000  clean testing loss: 0.004427826032042503


 50%|█████     | 50150/100000 [28:07<27:52, 29.81it/s]
epoch 50100  training loss: 0.09355007112026215

 50%|█████     | 50210/100000 [28:09<27:54, 29.74it/s]
epoch 50200  training loss: 0.09354925900697708


 50%|█████     | 50330/100000 [28:13<27:49, 29.76it/s]
epoch 50300  training loss: 0.09354590624570847


 50%|█████     | 50447/100000 [28:17<27:40, 29.83it/s]
epoch 50400  training loss: 0.09354183822870255

 51%|█████     | 50506/100000 [28:19<27:33, 29.94it/s]
epoch 50500  training loss: 0.09353958815336227


 51%|█████     | 50630/100000 [28:23<27:23, 30.04it/s]
epoch 50600  training loss: 0.09353647381067276


 51%|█████     | 50747/100000 [28:27<27:31, 29.82it/s]
epoch 50700  training loss: 0.09353311359882355

 51%|█████     | 50807/100000 [28:29<27:33, 29.76it/s]
epoch 50800  training loss: 0.09353116899728775


 51%|█████     | 50927/100000 [28:33<27:23, 29.86it/s]
epoch 50900  training loss: 0.09352723509073257


 51%|█████     | 51044/100000 [28:37<27:20, 29.85it/s]
epoch 51000  training loss: 0.0935259461402893
epoch 51000  clean testing loss: 0.0044435118325054646

 51%|█████     | 51104/100000 [28:39<27:25, 29.71it/s]
epoch 51100  training loss: 0.09352367371320724


 51%|█████     | 51224/100000 [28:43<27:13, 29.85it/s]
epoch 51200  training loss: 0.09352000802755356


 51%|█████▏    | 51344/100000 [28:47<27:11, 29.82it/s]
epoch 51300  training loss: 0.09351889789104462

 51%|█████▏    | 51404/100000 [28:49<27:15, 29.71it/s]
epoch 51400  training loss: 0.09351649880409241


 52%|█████▏    | 51524/100000 [28:53<27:08, 29.77it/s]
epoch 51500  training loss: 0.09351274371147156


 52%|█████▏    | 51641/100000 [28:57<27:02, 29.81it/s]
epoch 51600  training loss: 0.09351137280464172

 52%|█████▏    | 51701/100000 [28:59<26:59, 29.82it/s]
epoch 51700  training loss: 0.09350837022066116


 52%|█████▏    | 51821/100000 [29:03<26:55, 29.83it/s]
epoch 51800  training loss: 0.09350527077913284


 52%|█████▏    | 51938/100000 [29:07<26:54, 29.78it/s]
epoch 51900  training loss: 0.09350362420082092


 52%|█████▏    | 52058/100000 [29:11<26:50, 29.76it/s]
epoch 52000  training loss: 0.09350124001502991
epoch 52000  clean testing loss: 0.0044675786048173904

 52%|█████▏    | 52118/100000 [29:13<26:47, 29.79it/s]
epoch 52100  training loss: 0.09349876642227173


 52%|█████▏    | 52238/100000 [29:17<26:42, 29.81it/s]
epoch 52200  training loss: 0.09349595755338669


 52%|█████▏    | 52358/100000 [29:21<26:36, 29.83it/s]
epoch 52300  training loss: 0.09349325299263

 52%|█████▏    | 52418/100000 [29:23<26:38, 29.77it/s]
epoch 52400  training loss: 0.09349067509174347


 53%|█████▎    | 52538/100000 [29:27<26:32, 29.80it/s]
epoch 52500  training loss: 0.09349103271961212


 53%|█████▎    | 52655/100000 [29:31<26:28, 29.80it/s]
epoch 52600  training loss: 0.09348594397306442

 53%|█████▎    | 52715/100000 [29:33<26:29, 29.75it/s]
epoch 52700  training loss: 0.09348130226135254


 53%|█████▎    | 52832/100000 [29:37<26:26, 29.73it/s]
epoch 52800  training loss: 0.09348000586032867


 53%|█████▎    | 52952/100000 [29:41<26:23, 29.72it/s]
epoch 52900  training loss: 0.09347716718912125

 53%|█████▎    | 53012/100000 [29:43<26:28, 29.58it/s]
epoch 53000  training loss: 0.09347566217184067
epoch 53000  clean testing loss: 0.004490658640861511


 53%|█████▎    | 53132/100000 [29:47<26:12, 29.81it/s]
epoch 53100  training loss: 0.09347172826528549


 53%|█████▎    | 53252/100000 [29:51<26:10, 29.77it/s]
epoch 53200  training loss: 0.09346875548362732

 53%|█████▎    | 53312/100000 [29:53<26:06, 29.80it/s]
epoch 53300  training loss: 0.09346605837345123


 53%|█████▎    | 53432/100000 [29:57<26:00, 29.85it/s]
epoch 53400  training loss: 0.09346301108598709


 54%|█████▎    | 53549/100000 [30:01<25:58, 29.81it/s]
epoch 53500  training loss: 0.09346017986536026

 54%|█████▎    | 53609/100000 [30:03<26:00, 29.72it/s]
epoch 53600  training loss: 0.09345752000808716


 54%|█████▎    | 53729/100000 [30:07<25:55, 29.74it/s]
epoch 53700  training loss: 0.09345469623804092


 54%|█████▍    | 53846/100000 [30:11<25:46, 29.85it/s]
epoch 53800  training loss: 0.09345163404941559

 54%|█████▍    | 53906/100000 [30:13<25:52, 29.69it/s]
epoch 53900  training loss: 0.09344739466905594


 54%|█████▍    | 54026/100000 [30:17<25:43, 29.79it/s]
epoch 54000  training loss: 0.0934458002448082
epoch 54000  clean testing loss: 0.004516851622611284


 54%|█████▍    | 54131/100000 [30:21<25:37, 29.83it/s]
epoch 54100  training loss: 0.09344328194856644

 54%|█████▍    | 54191/100000 [30:23<25:35, 29.84it/s]
epoch 54200  training loss: 0.09344084560871124


 54%|█████▍    | 54311/100000 [30:27<25:35, 29.76it/s]
epoch 54300  training loss: 0.09343823790550232


 54%|█████▍    | 54428/100000 [30:31<25:26, 29.85it/s]
epoch 54400  training loss: 0.0934356078505516

 54%|█████▍    | 54488/100000 [30:33<25:25, 29.84it/s]
epoch 54500  training loss: 0.09343473613262177


 55%|█████▍    | 54605/100000 [30:37<25:44, 29.38it/s]
epoch 54600  training loss: 0.09343016147613525


 55%|█████▍    | 54725/100000 [30:41<25:16, 29.86it/s]
epoch 54700  training loss: 0.09342771023511887


 55%|█████▍    | 54845/100000 [30:45<25:15, 29.80it/s]
epoch 54800  training loss: 0.09342467039823532

 55%|█████▍    | 54905/100000 [30:47<25:17, 29.72it/s]
epoch 54900  training loss: 0.09342186897993088


 55%|█████▌    | 55025/100000 [30:51<25:10, 29.78it/s]
epoch 55000  training loss: 0.09341903775930405
epoch 55000  clean testing loss: 0.004545344039797783


 55%|█████▌    | 55142/100000 [30:55<25:03, 29.84it/s]
epoch 55100  training loss: 0.09341619908809662

 55%|█████▌    | 55202/100000 [30:57<25:09, 29.68it/s]
epoch 55200  training loss: 0.09341336786746979


 55%|█████▌    | 55322/100000 [31:01<24:59, 29.79it/s]
epoch 55300  training loss: 0.09340920299291611


 55%|█████▌    | 55442/100000 [31:05<24:53, 29.84it/s]
epoch 55400  training loss: 0.09340767562389374

 55%|█████▌    | 55499/100000 [31:07<25:10, 29.46it/s]
epoch 55500  training loss: 0.09340356290340424


 56%|█████▌    | 55619/100000 [31:11<24:48, 29.81it/s]
epoch 55600  training loss: 0.09340064227581024


 56%|█████▌    | 55739/100000 [31:15<24:43, 29.84it/s]
epoch 55700  training loss: 0.09339925646781921


 56%|█████▌    | 55859/100000 [31:19<24:39, 29.83it/s]
epoch 55800  training loss: 0.09339611232280731

 56%|█████▌    | 55919/100000 [31:21<24:39, 29.80it/s]
epoch 55900  training loss: 0.09339354932308197


 56%|█████▌    | 56036/100000 [31:25<24:35, 29.80it/s]
epoch 56000  training loss: 0.09339209645986557
epoch 56000  clean testing loss: 0.0045676762238144875


 56%|█████▌    | 56156/100000 [31:29<24:30, 29.81it/s]
epoch 56100  training loss: 0.09338629245758057

 56%|█████▌    | 56216/100000 [31:31<24:28, 29.82it/s]
epoch 56200  training loss: 0.09338472783565521


 56%|█████▋    | 56336/100000 [31:35<24:26, 29.77it/s]
epoch 56300  training loss: 0.09338155388832092


 56%|█████▋    | 56453/100000 [31:39<24:11, 30.01it/s]
epoch 56400  training loss: 0.09338095784187317

 57%|█████▋    | 56512/100000 [31:41<24:11, 29.96it/s]
epoch 56500  training loss: 0.09337573498487473


 57%|█████▋    | 56632/100000 [31:45<24:09, 29.91it/s]
epoch 56600  training loss: 0.09337292611598969


 57%|█████▋    | 56752/100000 [31:49<24:09, 29.84it/s]
epoch 56700  training loss: 0.09337008744478226

 57%|█████▋    | 56812/100000 [31:51<24:10, 29.78it/s]
epoch 56800  training loss: 0.09336709976196289


 57%|█████▋    | 56932/100000 [31:55<24:04, 29.81it/s]
epoch 56900  training loss: 0.0933641567826271


 57%|█████▋    | 57052/100000 [31:59<23:58, 29.86it/s]
epoch 57000  training loss: 0.09336245059967041
epoch 57000  clean testing loss: 0.0045895748771727085

 57%|█████▋    | 57112/100000 [32:01<24:00, 29.77it/s]
epoch 57100  training loss: 0.093360036611557


 57%|█████▋    | 57229/100000 [32:05<23:55, 29.80it/s]
epoch 57200  training loss: 0.09335622191429138


 57%|█████▋    | 57349/100000 [32:09<23:52, 29.77it/s]
epoch 57300  training loss: 0.09335233271121979

 57%|█████▋    | 57409/100000 [32:11<23:51, 29.76it/s]
epoch 57400  training loss: 0.0933510810136795


 58%|█████▊    | 57526/100000 [32:15<23:45, 29.79it/s]
epoch 57500  training loss: 0.09335069358348846


 58%|█████▊    | 57646/100000 [32:19<23:40, 29.82it/s]
epoch 57600  training loss: 0.09334560483694077

 58%|█████▊    | 57706/100000 [32:21<23:43, 29.71it/s]
epoch 57700  training loss: 0.09334173053503036


 58%|█████▊    | 57826/100000 [32:25<23:34, 29.81it/s]
epoch 57800  training loss: 0.09334024786949158


 58%|█████▊    | 57946/100000 [32:29<23:30, 29.82it/s]
epoch 57900  training loss: 0.09333629906177521

 58%|█████▊    | 58006/100000 [32:31<23:47, 29.43it/s]
epoch 58000  training loss: 0.09333375096321106
epoch 58000  clean testing loss: 0.0046139867044985294


 58%|█████▊    | 58123/100000 [32:35<23:26, 29.78it/s]
epoch 58100  training loss: 0.09333201497793198


 58%|█████▊    | 58243/100000 [32:39<23:19, 29.83it/s]
epoch 58200  training loss: 0.09332946687936783

 58%|█████▊    | 58303/100000 [32:41<23:26, 29.65it/s]
epoch 58300  training loss: 0.0933256596326828


 58%|█████▊    | 58420/100000 [32:45<23:15, 29.80it/s]
epoch 58400  training loss: 0.09332424402236938


 59%|█████▊    | 58540/100000 [32:49<23:09, 29.84it/s]
epoch 58500  training loss: 0.09332134574651718

 59%|█████▊    | 58600/100000 [32:51<23:08, 29.81it/s]
epoch 58600  training loss: 0.09331870824098587


 59%|█████▊    | 58720/100000 [32:55<23:05, 29.80it/s]
epoch 58700  training loss: 0.09331604093313217


 59%|█████▉    | 58840/100000 [32:59<23:00, 29.81it/s]
epoch 58800  training loss: 0.09331456571817398


 59%|█████▉    | 58960/100000 [33:03<23:01, 29.70it/s]
epoch 58900  training loss: 0.09331064671278

 59%|█████▉    | 59017/100000 [33:05<22:58, 29.73it/s]
epoch 59000  training loss: 0.09330802410840988
epoch 59000  clean testing loss: 0.004634730983525515


 59%|█████▉    | 59137/100000 [33:09<22:54, 29.72it/s]
epoch 59100  training loss: 0.09330519288778305


 59%|█████▉    | 59254/100000 [33:13<22:46, 29.81it/s]
epoch 59200  training loss: 0.093302883207798

 59%|█████▉    | 59314/100000 [33:15<22:45, 29.80it/s]
epoch 59300  training loss: 0.09329987317323685


 59%|█████▉    | 59434/100000 [33:19<22:44, 29.74it/s]
epoch 59400  training loss: 0.0932973176240921


 60%|█████▉    | 59554/100000 [33:23<22:39, 29.74it/s]
epoch 59500  training loss: 0.09329456835985184

 60%|█████▉    | 59614/100000 [33:25<22:35, 29.79it/s]
epoch 59600  training loss: 0.09329050779342651


 60%|█████▉    | 59734/100000 [33:29<22:31, 29.79it/s]
epoch 59700  training loss: 0.09328943490982056


 60%|█████▉    | 59851/100000 [33:33<22:31, 29.71it/s]
epoch 59800  training loss: 0.09328696131706238

 60%|█████▉    | 59911/100000 [33:35<22:26, 29.77it/s]
epoch 59900  training loss: 0.09328275918960571


 60%|██████    | 60031/100000 [33:39<22:22, 29.78it/s]
epoch 60000  training loss: 0.09328018128871918
epoch 60000  clean testing loss: 0.004655903670936823


 60%|██████    | 60148/100000 [33:43<22:17, 29.79it/s]
epoch 60100  training loss: 0.09327897429466248

 60%|██████    | 60208/100000 [33:45<22:19, 29.71it/s]
epoch 60200  training loss: 0.09327688813209534


 60%|██████    | 60328/100000 [33:49<22:12, 29.78it/s]
epoch 60300  training loss: 0.09327470511198044


 60%|██████    | 60448/100000 [33:53<22:05, 29.83it/s]
epoch 60400  training loss: 0.09327232092618942

 61%|██████    | 60508/100000 [33:55<22:08, 29.72it/s]
epoch 60500  training loss: 0.09327005594968796


 61%|██████    | 60628/100000 [33:59<22:00, 29.82it/s]
epoch 60600  training loss: 0.09326638281345367


 61%|██████    | 60745/100000 [34:03<21:55, 29.83it/s]
epoch 60700  training loss: 0.093266062438488

 61%|██████    | 60805/100000 [34:05<22:03, 29.62it/s]
epoch 60800  training loss: 0.09326165169477463


 61%|██████    | 60925/100000 [34:09<21:51, 29.80it/s]
epoch 60900  training loss: 0.09326066821813583


 61%|██████    | 61042/100000 [34:13<21:51, 29.70it/s]
epoch 61000  training loss: 0.09325841814279556
epoch 61000  clean testing loss: 0.004677581135183573

 61%|██████    | 61102/100000 [34:15<22:02, 29.42it/s]
epoch 61100  training loss: 0.09325610101222992


 61%|██████    | 61222/100000 [34:19<21:42, 29.78it/s]
epoch 61200  training loss: 0.09325367212295532


 61%|██████▏   | 61342/100000 [34:23<21:35, 29.83it/s]
epoch 61300  training loss: 0.09325180947780609

 61%|██████▏   | 61402/100000 [34:25<21:42, 29.63it/s]
epoch 61400  training loss: 0.09324938803911209


 62%|██████▏   | 61522/100000 [34:30<21:31, 29.79it/s]
epoch 61500  training loss: 0.09324527531862259


 62%|██████▏   | 61639/100000 [34:33<21:26, 29.81it/s]
epoch 61600  training loss: 0.09324321150779724

 62%|██████▏   | 61699/100000 [34:35<21:25, 29.79it/s]
epoch 61700  training loss: 0.0932421013712883


 62%|██████▏   | 61819/100000 [34:40<21:20, 29.82it/s]
epoch 61800  training loss: 0.09323964267969131


 62%|██████▏   | 61936/100000 [34:43<21:22, 29.68it/s]
epoch 61900  training loss: 0.09323740005493164


 62%|██████▏   | 62056/100000 [34:48<21:14, 29.76it/s]
epoch 62000  training loss: 0.093235544860363
epoch 62000  clean testing loss: 0.004696121904999018

 62%|██████▏   | 62116/100000 [34:50<21:11, 29.81it/s]
epoch 62100  training loss: 0.09323281049728394


 62%|██████▏   | 62236/100000 [34:54<21:07, 29.80it/s]
epoch 62200  training loss: 0.09323067963123322


 62%|██████▏   | 62353/100000 [34:57<20:56, 29.95it/s]
epoch 62300  training loss: 0.09322836995124817

 62%|██████▏   | 62414/100000 [34:59<21:11, 29.55it/s]
epoch 62400  training loss: 0.09322602301836014


 63%|██████▎   | 62534/100000 [35:04<20:57, 29.80it/s]
epoch 62500  training loss: 0.09322374314069748


 63%|██████▎   | 62651/100000 [35:07<23:46, 26.19it/s]
epoch 62600  training loss: 0.09322129189968109

 63%|██████▎   | 62711/100000 [35:10<20:56, 29.67it/s]
epoch 62700  training loss: 0.0932191014289856


 63%|██████▎   | 62831/100000 [35:14<20:51, 29.70it/s]
epoch 62800  training loss: 0.09321824461221695


 63%|██████▎   | 62951/100000 [35:18<20:41, 29.85it/s]
epoch 62900  training loss: 0.09321577847003937

 63%|██████▎   | 63011/100000 [35:20<20:49, 29.59it/s]
epoch 63000  training loss: 0.09321092069149017
epoch 63000  clean testing loss: 0.004719699267297983


 63%|██████▎   | 63131/100000 [35:24<20:35, 29.85it/s]
epoch 63100  training loss: 0.09320922195911407


 63%|██████▎   | 63251/100000 [35:28<20:34, 29.77it/s]
epoch 63200  training loss: 0.09320860356092453

 63%|██████▎   | 63311/100000 [35:30<20:31, 29.80it/s]
epoch 63300  training loss: 0.09320812672376633


 63%|██████▎   | 63428/100000 [35:34<20:24, 29.87it/s]
epoch 63400  training loss: 0.09320604056119919


 64%|██████▎   | 63548/100000 [35:38<21:42, 27.98it/s]
epoch 63500  training loss: 0.09320274740457535

 64%|██████▎   | 63608/100000 [35:40<20:23, 29.74it/s]
epoch 63600  training loss: 0.0932021364569664


 64%|██████▎   | 63726/100000 [35:44<20:08, 30.01it/s]
epoch 63700  training loss: 0.09320024400949478


 64%|██████▍   | 63846/100000 [35:48<20:12, 29.82it/s]
epoch 63800  training loss: 0.09319817274808884

 64%|██████▍   | 63906/100000 [35:50<20:15, 29.71it/s]
epoch 63900  training loss: 0.09319473803043365


 64%|██████▍   | 64026/100000 [35:54<20:09, 29.74it/s]
epoch 64000  training loss: 0.0931941345334053
epoch 64000  clean testing loss: 0.004735975526273251


 64%|██████▍   | 64146/100000 [35:58<20:12, 29.57it/s]
epoch 64100  training loss: 0.09319217503070831

 64%|██████▍   | 64206/100000 [36:00<20:07, 29.65it/s]
epoch 64200  training loss: 0.0931917354464531


 64%|██████▍   | 64326/100000 [36:04<19:56, 29.81it/s]
epoch 64300  training loss: 0.09318714588880539


 64%|██████▍   | 64443/100000 [36:08<19:52, 29.81it/s]
epoch 64400  training loss: 0.09318632632493973

 65%|██████▍   | 64503/100000 [36:10<19:58, 29.61it/s]
epoch 64500  training loss: 0.09318292140960693


 65%|██████▍   | 64623/100000 [36:14<19:46, 29.81it/s]
epoch 64600  training loss: 0.09318240731954575


 65%|██████▍   | 64740/100000 [36:18<19:42, 29.82it/s]
epoch 64700  training loss: 0.0931805744767189

 65%|██████▍   | 64800/100000 [36:20<19:42, 29.78it/s]
epoch 64800  training loss: 0.09317860752344131


 65%|██████▍   | 64920/100000 [36:24<19:37, 29.79it/s]
epoch 64900  training loss: 0.09317523241043091


 65%|██████▌   | 65040/100000 [36:28<19:39, 29.63it/s]
epoch 65000  training loss: 0.0931745395064354
epoch 65000  clean testing loss: 0.004752335138618946


 65%|██████▌   | 65157/100000 [36:32<19:28, 29.81it/s]
epoch 65100  training loss: 0.09317110478878021

 65%|██████▌   | 65217/100000 [36:34<19:28, 29.77it/s]
epoch 65200  training loss: 0.09317076206207275


 65%|██████▌   | 65337/100000 [36:38<19:22, 29.82it/s]
epoch 65300  training loss: 0.09316875785589218


 65%|██████▌   | 65454/100000 [36:42<19:18, 29.82it/s]
epoch 65400  training loss: 0.09316673129796982

 66%|██████▌   | 65514/100000 [36:44<19:18, 29.77it/s]
epoch 65500  training loss: 0.0931636318564415


 66%|██████▌   | 65634/100000 [36:48<19:13, 29.79it/s]
epoch 65600  training loss: 0.09316179901361465


 66%|██████▌   | 65754/100000 [36:52<19:08, 29.81it/s]
epoch 65700  training loss: 0.09316110610961914

 66%|██████▌   | 65814/100000 [36:54<19:08, 29.75it/s]
epoch 65800  training loss: 0.09315919131040573


 66%|██████▌   | 65934/100000 [36:58<19:04, 29.78it/s]
epoch 65900  training loss: 0.09315574169158936


 66%|██████▌   | 66051/100000 [37:02<19:00, 29.77it/s]
epoch 66000  training loss: 0.09315532445907593
epoch 66000  clean testing loss: 0.004770631901919842

 66%|██████▌   | 66111/100000 [37:04<18:59, 29.74it/s]
epoch 66100  training loss: 0.09315232187509537


 66%|██████▌   | 66231/100000 [37:08<18:53, 29.80it/s]
epoch 66200  training loss: 0.09315222501754761


 66%|██████▋   | 66348/100000 [37:12<18:44, 29.91it/s]
epoch 66300  training loss: 0.09315057098865509

 66%|██████▋   | 66408/100000 [37:14<18:47, 29.80it/s]
epoch 66400  training loss: 0.09314761310815811


 67%|██████▋   | 66528/100000 [37:18<18:39, 29.89it/s]
epoch 66500  training loss: 0.09314579516649246


 67%|██████▋   | 66648/100000 [37:22<18:36, 29.88it/s]
epoch 66600  training loss: 0.09314561635255814

 67%|██████▋   | 66708/100000 [37:24<18:38, 29.77it/s]
epoch 66700  training loss: 0.09314411133527756


 67%|██████▋   | 66828/100000 [37:28<18:34, 29.75it/s]
epoch 66800  training loss: 0.09314213693141937


 67%|██████▋   | 66948/100000 [37:32<18:27, 29.86it/s]
epoch 66900  training loss: 0.09314059466123581

 67%|██████▋   | 67005/100000 [37:34<18:42, 29.39it/s]
epoch 67000  training loss: 0.09313749521970749
epoch 67000  clean testing loss: 0.004784407559782267


 67%|██████▋   | 67125/100000 [37:38<18:20, 29.87it/s]
epoch 67100  training loss: 0.09313584864139557


 67%|██████▋   | 67245/100000 [37:42<18:16, 29.88it/s]
epoch 67200  training loss: 0.09313561767339706

 67%|██████▋   | 67305/100000 [37:44<18:18, 29.76it/s]
epoch 67300  training loss: 0.09313426166772842


 67%|██████▋   | 67425/100000 [37:48<18:10, 29.88it/s]
epoch 67400  training loss: 0.09313097596168518


 68%|██████▊   | 67527/100000 [37:51<18:05, 29.92it/s]
epoch 67500  training loss: 0.09312952309846878

 68%|██████▊   | 67587/100000 [37:53<18:05, 29.87it/s]
epoch 67600  training loss: 0.09312902390956879


 68%|██████▊   | 67707/100000 [37:57<18:02, 29.84it/s]
epoch 67700  training loss: 0.09312590956687927


 68%|██████▊   | 67829/100000 [38:01<17:55, 29.91it/s]
epoch 67800  training loss: 0.09312429279088974

 68%|██████▊   | 67889/100000 [38:03<17:52, 29.95it/s]
epoch 67900  training loss: 0.09312410652637482


 68%|██████▊   | 68008/100000 [38:07<17:59, 29.63it/s]
epoch 68000  training loss: 0.09312240034341812
epoch 68000  clean testing loss: 0.00480187963694334


 68%|██████▊   | 68127/100000 [38:11<17:46, 29.90it/s]
epoch 68100  training loss: 0.0931193083524704

 68%|██████▊   | 68186/100000 [38:13<17:35, 30.13it/s]
epoch 68200  training loss: 0.09311904013156891


 68%|██████▊   | 68305/100000 [38:17<17:40, 29.89it/s]
epoch 68300  training loss: 0.09311729669570923


 68%|██████▊   | 68426/100000 [38:21<17:36, 29.88it/s]
epoch 68400  training loss: 0.09311582893133163

 68%|██████▊   | 68486/100000 [38:23<17:35, 29.86it/s]
epoch 68500  training loss: 0.09311278909444809


 69%|██████▊   | 68606/100000 [38:27<17:35, 29.73it/s]
epoch 68600  training loss: 0.09311254322528839


 69%|██████▊   | 68726/100000 [38:32<17:27, 29.86it/s]
epoch 68700  training loss: 0.09311104565858841


 69%|██████▉   | 68846/100000 [38:36<17:24, 29.84it/s]
epoch 68800  training loss: 0.09310922026634216

 69%|██████▉   | 68906/100000 [38:38<17:24, 29.77it/s]
epoch 68900  training loss: 0.09310748428106308


 69%|██████▉   | 69023/100000 [38:42<17:20, 29.77it/s]
epoch 69000  training loss: 0.09310591965913773
epoch 69000  clean testing loss: 0.0048150266520679


 69%|██████▉   | 69143/100000 [38:46<17:14, 29.82it/s]
epoch 69100  training loss: 0.0931045264005661

 69%|██████▉   | 69203/100000 [38:48<17:17, 29.68it/s]
epoch 69200  training loss: 0.09310200810432434


 69%|██████▉   | 69323/100000 [38:52<17:07, 29.87it/s]
epoch 69300  training loss: 0.09310058504343033


 69%|██████▉   | 69440/100000 [38:55<17:03, 29.86it/s]
epoch 69400  training loss: 0.09309923648834229

 70%|██████▉   | 69500/100000 [38:58<17:11, 29.56it/s]
epoch 69500  training loss: 0.0930991992354393


 70%|██████▉   | 69620/100000 [39:02<16:59, 29.81it/s]
epoch 69600  training loss: 0.09309776872396469


 70%|██████▉   | 69740/100000 [39:06<16:52, 29.87it/s]
epoch 69700  training loss: 0.09309496730566025

 70%|██████▉   | 69800/100000 [39:08<16:51, 29.86it/s]
epoch 69800  training loss: 0.0930948331952095


 70%|██████▉   | 69917/100000 [39:12<16:48, 29.84it/s]
epoch 69900  training loss: 0.09309355169534683


 70%|███████   | 70038/100000 [39:16<16:45, 29.79it/s]
epoch 70000  training loss: 0.09309207648038864
epoch 70000  clean testing loss: 0.0048287613317370415


 70%|███████   | 70158/100000 [39:20<16:39, 29.87it/s]
epoch 70100  training loss: 0.09309078007936478

 70%|███████   | 70218/100000 [39:22<16:38, 29.82it/s]
epoch 70200  training loss: 0.09308790415525436


 70%|███████   | 70338/100000 [39:26<16:36, 29.76it/s]
epoch 70300  training loss: 0.09308791905641556


 70%|███████   | 70455/100000 [39:30<16:31, 29.79it/s]
epoch 70400  training loss: 0.09308502078056335

 71%|███████   | 70515/100000 [39:32<16:28, 29.82it/s]
epoch 70500  training loss: 0.09308481961488724


 71%|███████   | 70635/100000 [39:36<16:24, 29.84it/s]
epoch 70600  training loss: 0.09308360517024994


 71%|███████   | 70755/100000 [39:40<16:34, 29.39it/s]
epoch 70700  training loss: 0.09308220446109772

 71%|███████   | 70812/100000 [39:42<16:20, 29.77it/s]
epoch 70800  training loss: 0.0930807963013649


 71%|███████   | 70932/100000 [39:46<16:15, 29.81it/s]
epoch 70900  training loss: 0.09307955950498581


 71%|███████   | 71052/100000 [39:50<16:12, 29.78it/s]
epoch 71000  training loss: 0.09307806938886642
epoch 71000  clean testing loss: 0.004839745350182056

 71%|███████   | 71112/100000 [39:52<16:09, 29.80it/s]
epoch 71100  training loss: 0.09307654947042465


 71%|███████   | 71232/100000 [39:56<16:06, 29.77it/s]
epoch 71200  training loss: 0.09307526797056198


 71%|███████▏  | 71352/100000 [40:00<16:00, 29.84it/s]
epoch 71300  training loss: 0.09307253360748291

 71%|███████▏  | 71412/100000 [40:02<15:59, 29.80it/s]
epoch 71400  training loss: 0.0930723249912262


 72%|███████▏  | 71532/100000 [40:06<15:53, 29.85it/s]
epoch 71500  training loss: 0.0930703654885292


 72%|███████▏  | 71649/100000 [40:10<16:11, 29.17it/s]
epoch 71600  training loss: 0.09306956827640533

 72%|███████▏  | 71709/100000 [40:12<15:50, 29.76it/s]
epoch 71700  training loss: 0.09306816756725311


 72%|███████▏  | 71826/100000 [40:16<15:44, 29.82it/s]
epoch 71800  training loss: 0.09306836873292923


 72%|███████▏  | 71946/100000 [40:20<15:39, 29.85it/s]
epoch 71900  training loss: 0.09306561946868896

 72%|███████▏  | 72006/100000 [40:22<15:51, 29.42it/s]
epoch 72000  training loss: 0.0930628851056099
epoch 72000  clean testing loss: 0.004854223690927029


 72%|███████▏  | 72126/100000 [40:26<15:34, 29.83it/s]
epoch 72100  training loss: 0.09306308627128601


 72%|███████▏  | 72246/100000 [40:30<15:29, 29.85it/s]
epoch 72200  training loss: 0.09306065738201141

 72%|███████▏  | 72306/100000 [40:32<15:32, 29.70it/s]
epoch 72300  training loss: 0.09306089580059052


 72%|███████▏  | 72426/100000 [40:36<15:24, 29.82it/s]
epoch 72400  training loss: 0.09305822104215622


 73%|███████▎  | 72543/100000 [40:40<16:10, 28.29it/s]
epoch 72500  training loss: 0.09305711090564728

 73%|███████▎  | 72603/100000 [40:42<15:23, 29.67it/s]
epoch 72600  training loss: 0.09305733442306519


 73%|███████▎  | 72723/100000 [40:46<15:15, 29.80it/s]
epoch 72700  training loss: 0.09305624663829803


 73%|███████▎  | 72840/100000 [40:50<15:09, 29.85it/s]
epoch 72800  training loss: 0.09305495768785477

 73%|███████▎  | 72900/100000 [40:52<15:08, 29.84it/s]
epoch 72900  training loss: 0.09305515885353088


 73%|███████▎  | 73020/100000 [40:56<15:07, 29.72it/s]
epoch 73000  training loss: 0.09305262565612793
epoch 73000  clean testing loss: 0.004866422154009342


 73%|███████▎  | 73140/100000 [41:00<15:00, 29.82it/s]
epoch 73100  training loss: 0.09305145591497421


 73%|███████▎  | 73260/100000 [41:04<14:56, 29.84it/s]
epoch 73200  training loss: 0.09304902702569962

 73%|███████▎  | 73320/100000 [41:06<14:55, 29.80it/s]
epoch 73300  training loss: 0.09304901957511902


 73%|███████▎  | 73437/100000 [41:10<15:45, 28.11it/s]
epoch 73400  training loss: 0.09304629266262054


 74%|███████▎  | 73557/100000 [41:14<14:45, 29.87it/s]
epoch 73500  training loss: 0.09304527938365936

 74%|███████▎  | 73617/100000 [41:16<14:45, 29.80it/s]
epoch 73600  training loss: 0.09304407984018326


 74%|███████▎  | 73737/100000 [41:20<14:39, 29.85it/s]
epoch 73700  training loss: 0.0930429995059967


 74%|███████▍  | 73854/100000 [41:24<14:37, 29.79it/s]
epoch 73800  training loss: 0.09304298460483551

 74%|███████▍  | 73914/100000 [41:26<14:35, 29.80it/s]
epoch 73900  training loss: 0.09304176270961761


 74%|███████▍  | 74034/100000 [41:30<14:30, 29.82it/s]
epoch 74000  training loss: 0.09304080903530121
epoch 74000  clean testing loss: 0.004876101389527321


 74%|███████▍  | 74154/100000 [41:34<14:26, 29.82it/s]
epoch 74100  training loss: 0.09303939342498779

 74%|███████▍  | 74214/100000 [41:36<14:25, 29.80it/s]
epoch 74200  training loss: 0.093036949634552


 74%|███████▍  | 74331/100000 [41:40<15:59, 26.74it/s]
epoch 74300  training loss: 0.09303721785545349


 74%|███████▍  | 74451/100000 [41:44<14:16, 29.81it/s]
epoch 74400  training loss: 0.09303605556488037

 75%|███████▍  | 74511/100000 [41:46<14:19, 29.67it/s]
epoch 74500  training loss: 0.09303488582372665


 75%|███████▍  | 74628/100000 [41:50<14:10, 29.82it/s]
epoch 74600  training loss: 0.09303238242864609


 75%|███████▍  | 74748/100000 [41:54<14:06, 29.82it/s]
epoch 74700  training loss: 0.09303244203329086

 75%|███████▍  | 74808/100000 [41:56<14:10, 29.62it/s]
epoch 74800  training loss: 0.0930313766002655


 75%|███████▍  | 74928/100000 [42:00<14:00, 29.84it/s]
epoch 74900  training loss: 0.09303025901317596


 75%|███████▌  | 75048/100000 [42:04<13:57, 29.79it/s]
epoch 75000  training loss: 0.09302771836519241
epoch 75000  clean testing loss: 0.004889326170086861

 75%|███████▌  | 75108/100000 [42:06<13:59, 29.66it/s]
epoch 75100  training loss: 0.09302689880132675


 75%|███████▌  | 75225/100000 [42:10<15:43, 26.25it/s]
epoch 75200  training loss: 0.09302718192338943


 75%|███████▌  | 75345/100000 [42:14<13:49, 29.74it/s]
epoch 75300  training loss: 0.09302598237991333

 75%|███████▌  | 75405/100000 [42:16<13:47, 29.72it/s]
epoch 75400  training loss: 0.09302511811256409


 76%|███████▌  | 75522/100000 [42:20<13:41, 29.79it/s]
epoch 75500  training loss: 0.09302281588315964


 76%|███████▌  | 75642/100000 [42:24<13:38, 29.75it/s]
epoch 75600  training loss: 0.09302183985710144

 76%|███████▌  | 75702/100000 [42:26<13:40, 29.63it/s]
epoch 75700  training loss: 0.0930221676826477


 76%|███████▌  | 75822/100000 [42:30<13:31, 29.78it/s]
epoch 75800  training loss: 0.09301994740962982


 76%|███████▌  | 75942/100000 [42:34<13:28, 29.76it/s]
epoch 75900  training loss: 0.09301880747079849

 76%|███████▌  | 75999/100000 [42:36<13:24, 29.82it/s]
epoch 76000  training loss: 0.0930178165435791
epoch 76000  clean testing loss: 0.004897907376289368


 76%|███████▌  | 76116/100000 [42:40<13:58, 28.50it/s]
epoch 76100  training loss: 0.09301817417144775


 76%|███████▌  | 76236/100000 [42:44<13:17, 29.81it/s]
epoch 76200  training loss: 0.09301722049713135


 76%|███████▋  | 76356/100000 [42:48<13:13, 29.82it/s]
epoch 76300  training loss: 0.09301630407571793

 76%|███████▋  | 76416/100000 [42:50<13:12, 29.77it/s]
epoch 76400  training loss: 0.09301523864269257


 77%|███████▋  | 76536/100000 [42:54<13:07, 29.79it/s]
epoch 76500  training loss: 0.09301289170980453


 77%|███████▋  | 76653/100000 [42:58<13:04, 29.77it/s]
epoch 76600  training loss: 0.09301327913999557

 77%|███████▋  | 76713/100000 [43:00<13:02, 29.78it/s]
epoch 76700  training loss: 0.09301219135522842


 77%|███████▋  | 76833/100000 [43:04<12:58, 29.78it/s]
epoch 76800  training loss: 0.09301122277975082


 77%|███████▋  | 76953/100000 [43:08<12:54, 29.74it/s]
epoch 76900  training loss: 0.09301017969846725

 77%|███████▋  | 77013/100000 [43:10<13:48, 27.76it/s]
epoch 77000  training loss: 0.09300781786441803
epoch 77000  clean testing loss: 0.00490727461874485


 77%|███████▋  | 77130/100000 [43:14<12:47, 29.82it/s]
epoch 77100  training loss: 0.09300683438777924


 77%|███████▋  | 77250/100000 [43:18<12:43, 29.80it/s]
epoch 77200  training loss: 0.0930071771144867

 77%|███████▋  | 77310/100000 [43:20<12:42, 29.78it/s]
epoch 77300  training loss: 0.09300626069307327


 77%|███████▋  | 77427/100000 [43:24<12:36, 29.83it/s]
epoch 77400  training loss: 0.09300391376018524


 78%|███████▊  | 77547/100000 [43:28<12:34, 29.78it/s]
epoch 77500  training loss: 0.09300290793180466

 78%|███████▊  | 77607/100000 [43:30<12:33, 29.70it/s]
epoch 77600  training loss: 0.0930032879114151


 78%|███████▊  | 77727/100000 [43:34<12:27, 29.81it/s]
epoch 77700  training loss: 0.09300238639116287


 78%|███████▊  | 77847/100000 [43:38<12:23, 29.79it/s]
epoch 77800  training loss: 0.09299986809492111

 78%|███████▊  | 77904/100000 [43:40<12:24, 29.67it/s]
epoch 77900  training loss: 0.09300029277801514


 78%|███████▊  | 78024/100000 [43:44<12:19, 29.72it/s]
epoch 78000  training loss: 0.09299792349338531
epoch 78000  clean testing loss: 0.004917236976325512


 78%|███████▊  | 78144/100000 [43:48<12:13, 29.81it/s]
epoch 78100  training loss: 0.09299859404563904

 78%|███████▊  | 78201/100000 [43:50<12:11, 29.79it/s]
epoch 78200  training loss: 0.09299764037132263


 78%|███████▊  | 78321/100000 [43:54<12:08, 29.77it/s]
epoch 78300  training loss: 0.09299679845571518


 78%|███████▊  | 78441/100000 [43:58<12:03, 29.81it/s]
epoch 78400  training loss: 0.09299606829881668

 79%|███████▊  | 78501/100000 [44:00<12:02, 29.74it/s]
epoch 78500  training loss: 0.09299517422914505


 79%|███████▊  | 78621/100000 [44:04<11:57, 29.78it/s]
epoch 78600  training loss: 0.092994324862957


 79%|███████▊  | 78738/100000 [44:08<11:52, 29.85it/s]
epoch 78700  training loss: 0.09299343079328537


 79%|███████▉  | 78858/100000 [44:12<11:48, 29.82it/s]
epoch 78800  training loss: 0.0929926335811615

 79%|███████▉  | 78918/100000 [44:14<11:47, 29.80it/s]
epoch 78900  training loss: 0.0929919183254242


 79%|███████▉  | 79035/100000 [44:18<11:46, 29.68it/s]
epoch 79000  training loss: 0.09299091249704361
epoch 79000  clean testing loss: 0.004925660789012909


 79%|███████▉  | 79155/100000 [44:22<11:36, 29.91it/s]
epoch 79100  training loss: 0.09299014508724213

 79%|███████▉  | 79215/100000 [44:24<11:33, 29.96it/s]
epoch 79200  training loss: 0.09298930317163467


 79%|███████▉  | 79335/100000 [44:28<11:31, 29.89it/s]
epoch 79300  training loss: 0.09298716485500336


 79%|███████▉  | 79455/100000 [44:32<11:28, 29.85it/s]
epoch 79400  training loss: 0.09298644959926605

 80%|███████▉  | 79515/100000 [44:34<11:27, 29.80it/s]
epoch 79500  training loss: 0.09298697859048843


 80%|███████▉  | 79635/100000 [44:38<11:22, 29.83it/s]
epoch 79600  training loss: 0.09298582375049591


 80%|███████▉  | 79752/100000 [44:42<11:19, 29.79it/s]
epoch 79700  training loss: 0.0929839089512825

 80%|███████▉  | 79812/100000 [44:44<11:19, 29.71it/s]
epoch 79800  training loss: 0.09298437088727951


 80%|███████▉  | 79932/100000 [44:48<11:13, 29.81it/s]
epoch 79900  training loss: 0.09298361092805862


 80%|████████  | 80049/100000 [44:52<11:09, 29.80it/s]
epoch 80000  training loss: 0.0929827019572258
epoch 80000  clean testing loss: 0.004934272728860378

 80%|████████  | 80109/100000 [44:54<11:08, 29.75it/s]
epoch 80100  training loss: 0.0929817482829094


 80%|████████  | 80229/100000 [44:58<11:03, 29.79it/s]
epoch 80200  training loss: 0.09298118203878403


 80%|████████  | 80349/100000 [45:02<10:58, 29.85it/s]
epoch 80300  training loss: 0.09297873824834824

 80%|████████  | 80409/100000 [45:04<10:57, 29.79it/s]
epoch 80400  training loss: 0.09297788143157959


 81%|████████  | 80529/100000 [45:08<10:52, 29.86it/s]
epoch 80500  training loss: 0.09297841787338257


 81%|████████  | 80646/100000 [45:12<10:47, 29.87it/s]
epoch 80600  training loss: 0.09297767281532288

 81%|████████  | 80706/100000 [45:14<10:48, 29.77it/s]
epoch 80700  training loss: 0.09297548234462738


 81%|████████  | 80811/100000 [45:18<10:43, 29.84it/s]
epoch 80800  training loss: 0.09297472983598709


 81%|████████  | 80929/100000 [45:22<10:37, 29.91it/s]
epoch 80900  training loss: 0.09297362715005875

 81%|████████  | 80990/100000 [45:24<10:36, 29.84it/s]
epoch 81000  training loss: 0.09297427535057068
epoch 81000  clean testing loss: 0.00494307791814208


 81%|████████  | 81110/100000 [45:28<10:34, 29.77it/s]
epoch 81100  training loss: 0.09297364950180054


 81%|████████  | 81230/100000 [45:32<10:27, 29.90it/s]
epoch 81200  training loss: 0.09297299385070801

 81%|████████▏ | 81290/100000 [45:34<10:25, 29.89it/s]
epoch 81300  training loss: 0.09297237545251846


 81%|████████▏ | 81410/100000 [45:38<10:24, 29.78it/s]
epoch 81400  training loss: 0.09297177940607071


 82%|████████▏ | 81528/100000 [45:42<10:27, 29.42it/s]
epoch 81500  training loss: 0.09297104179859161

 82%|████████▏ | 81588/100000 [45:44<10:16, 29.87it/s]
epoch 81600  training loss: 0.09297028928995132


 82%|████████▏ | 81705/100000 [45:48<10:15, 29.73it/s]
epoch 81700  training loss: 0.09296972304582596


 82%|████████▏ | 81825/100000 [45:52<10:08, 29.86it/s]
epoch 81800  training loss: 0.0929688960313797

 82%|████████▏ | 81885/100000 [45:54<10:05, 29.91it/s]
epoch 81900  training loss: 0.09296829253435135


 82%|████████▏ | 82005/100000 [45:58<10:11, 29.41it/s]
epoch 82000  training loss: 0.09296755492687225
epoch 82000  clean testing loss: 0.004949784837663174


 82%|████████▏ | 82125/100000 [46:02<09:57, 29.91it/s]
epoch 82100  training loss: 0.09296688437461853


 82%|████████▏ | 82245/100000 [46:06<09:54, 29.87it/s]
epoch 82200  training loss: 0.09296612441539764

 82%|████████▏ | 82306/100000 [46:08<09:53, 29.83it/s]
epoch 82300  training loss: 0.0929652601480484


 82%|████████▏ | 82424/100000 [46:12<10:00, 29.29it/s]
epoch 82400  training loss: 0.0929645225405693


 83%|████████▎ | 82541/100000 [46:16<09:44, 29.88it/s]
epoch 82500  training loss: 0.09296244382858276

 83%|████████▎ | 82601/100000 [46:18<09:42, 29.85it/s]
epoch 82600  training loss: 0.09296330064535141


 83%|████████▎ | 82721/100000 [46:22<09:38, 29.87it/s]
epoch 82700  training loss: 0.09296125173568726


 83%|████████▎ | 82841/100000 [46:26<09:34, 29.87it/s]
epoch 82800  training loss: 0.092961885035038

 83%|████████▎ | 82901/100000 [46:28<09:34, 29.79it/s]
epoch 82900  training loss: 0.09296102076768875


 83%|████████▎ | 83021/100000 [46:32<09:29, 29.82it/s]
epoch 83000  training loss: 0.09296045452356339
epoch 83000  clean testing loss: 0.004957565106451511


 83%|████████▎ | 83141/100000 [46:36<09:24, 29.88it/s]
epoch 83100  training loss: 0.09295958280563354

 83%|████████▎ | 83201/100000 [46:38<09:22, 29.86it/s]
epoch 83200  training loss: 0.09295900911092758


 83%|████████▎ | 83318/100000 [46:42<09:33, 29.07it/s]
epoch 83300  training loss: 0.09295829385519028


 83%|████████▎ | 83438/100000 [46:46<09:14, 29.89it/s]
epoch 83400  training loss: 0.09295757114887238


 84%|████████▎ | 83558/100000 [46:50<09:09, 29.91it/s]
epoch 83500  training loss: 0.09295684844255447

 84%|████████▎ | 83618/100000 [46:52<09:08, 29.88it/s]
epoch 83600  training loss: 0.09295618534088135


 84%|████████▎ | 83739/100000 [46:56<09:05, 29.80it/s]
epoch 83700  training loss: 0.09295547753572464


 84%|████████▍ | 83856/100000 [47:00<08:59, 29.91it/s]
epoch 83800  training loss: 0.09295479208230972

 84%|████████▍ | 83916/100000 [47:02<08:58, 29.87it/s]
epoch 83900  training loss: 0.09295406192541122


 84%|████████▍ | 84036/100000 [47:06<08:54, 29.89it/s]
epoch 84000  training loss: 0.09295201301574707
epoch 84000  clean testing loss: 0.0049649314023554325


 84%|████████▍ | 84156/100000 [47:10<08:50, 29.86it/s]
epoch 84100  training loss: 0.09295288473367691

 84%|████████▍ | 84213/100000 [47:12<09:14, 28.47it/s]
epoch 84200  training loss: 0.09295232594013214


 84%|████████▍ | 84333/100000 [47:16<08:44, 29.85it/s]
epoch 84300  training loss: 0.0929502323269844


 84%|████████▍ | 84453/100000 [47:20<08:40, 29.86it/s]
epoch 84400  training loss: 0.09295129030942917

 85%|████████▍ | 84513/100000 [47:22<08:39, 29.79it/s]
epoch 84500  training loss: 0.09295067191123962


 85%|████████▍ | 84633/100000 [47:26<08:34, 29.86it/s]
epoch 84600  training loss: 0.09295135736465454


 85%|████████▍ | 84753/100000 [47:30<08:32, 29.78it/s]
epoch 84700  training loss: 0.09294945746660233

 85%|████████▍ | 84813/100000 [47:32<08:29, 29.83it/s]
epoch 84800  training loss: 0.09294887632131577


 85%|████████▍ | 84933/100000 [47:36<08:24, 29.88it/s]
epoch 84900  training loss: 0.09294816851615906


 85%|████████▌ | 85050/100000 [47:40<08:20, 29.87it/s]
epoch 85000  training loss: 0.0929475650191307
epoch 85000  clean testing loss: 0.004970908164978027

 85%|████████▌ | 85110/100000 [47:42<08:44, 28.37it/s]
epoch 85100  training loss: 0.09294724464416504


 85%|████████▌ | 85230/100000 [47:46<08:14, 29.89it/s]
epoch 85200  training loss: 0.09294651448726654


 85%|████████▌ | 85350/100000 [47:50<08:10, 29.88it/s]
epoch 85300  training loss: 0.09294597804546356

 85%|████████▌ | 85410/100000 [47:52<08:09, 29.83it/s]
epoch 85400  training loss: 0.09294538199901581


 86%|████████▌ | 85530/100000 [47:56<08:05, 29.83it/s]
epoch 85500  training loss: 0.09294471144676208


 86%|████████▌ | 85647/100000 [48:00<08:00, 29.88it/s]
epoch 85600  training loss: 0.09294421225786209

 86%|████████▌ | 85707/100000 [48:02<08:00, 29.78it/s]
epoch 85700  training loss: 0.09294354915618896


 86%|████████▌ | 85827/100000 [48:06<07:54, 29.88it/s]
epoch 85800  training loss: 0.09294304996728897


 86%|████████▌ | 85947/100000 [48:10<07:50, 29.87it/s]
epoch 85900  training loss: 0.09294246882200241

 86%|████████▌ | 86004/100000 [48:12<08:43, 26.71it/s]
epoch 86000  training loss: 0.09294193983078003
epoch 86000  clean testing loss: 0.0049776360392570496


 86%|████████▌ | 86124/100000 [48:16<07:43, 29.92it/s]
epoch 86100  training loss: 0.09294121712446213


 86%|████████▌ | 86244/100000 [48:20<07:40, 29.89it/s]
epoch 86200  training loss: 0.09293942898511887

 86%|████████▋ | 86304/100000 [48:22<07:40, 29.77it/s]
epoch 86300  training loss: 0.09294016659259796


 86%|████████▋ | 86424/100000 [48:26<07:34, 29.87it/s]
epoch 86400  training loss: 0.09293822944164276


 87%|████████▋ | 86544/100000 [48:30<07:29, 29.92it/s]
epoch 86500  training loss: 0.09293893724679947

 87%|████████▋ | 86604/100000 [48:32<07:31, 29.70it/s]
epoch 86600  training loss: 0.0929383710026741


 87%|████████▋ | 86725/100000 [48:36<07:23, 29.94it/s]
epoch 86700  training loss: 0.09293802827596664


 87%|████████▋ | 86842/100000 [48:40<07:19, 29.93it/s]
epoch 86800  training loss: 0.09293723851442337

 87%|████████▋ | 86902/100000 [48:42<08:15, 26.46it/s]
epoch 86900  training loss: 0.09293670207262039


 87%|████████▋ | 87020/100000 [48:46<07:14, 29.87it/s]
epoch 87000  training loss: 0.09293738752603531
epoch 87000  clean testing loss: 0.0049836658872663975


 87%|████████▋ | 87141/100000 [48:50<07:09, 29.94it/s]
epoch 87100  training loss: 0.092934250831604

 87%|████████▋ | 87201/100000 [48:52<07:08, 29.90it/s]
epoch 87200  training loss: 0.09293515235185623


 87%|████████▋ | 87322/100000 [48:56<07:04, 29.89it/s]
epoch 87300  training loss: 0.0929332748055458


 87%|████████▋ | 87439/100000 [49:00<06:59, 29.93it/s]
epoch 87400  training loss: 0.09293290972709656

 88%|████████▊ | 87500/100000 [49:02<06:58, 29.86it/s]
epoch 87500  training loss: 0.09293387085199356


 88%|████████▊ | 87620/100000 [49:06<06:53, 29.94it/s]
epoch 87600  training loss: 0.09293331950902939


 88%|████████▊ | 87739/100000 [49:10<06:49, 29.95it/s]
epoch 87700  training loss: 0.09293276071548462


 88%|████████▊ | 87858/100000 [49:14<06:45, 29.91it/s]
epoch 87800  training loss: 0.09293225407600403

 88%|████████▊ | 87919/100000 [49:16<06:44, 29.83it/s]
epoch 87900  training loss: 0.09293188154697418


 88%|████████▊ | 88039/100000 [49:20<06:39, 29.93it/s]
epoch 88000  training loss: 0.0929313376545906
epoch 88000  clean testing loss: 0.004989033564925194


 88%|████████▊ | 88158/100000 [49:24<06:35, 29.95it/s]
epoch 88100  training loss: 0.09292963892221451

 88%|████████▊ | 88218/100000 [49:26<06:33, 29.90it/s]
epoch 88200  training loss: 0.09293045103549957


 88%|████████▊ | 88336/100000 [49:30<06:31, 29.83it/s]
epoch 88300  training loss: 0.0929286852478981


 88%|████████▊ | 88456/100000 [49:34<06:25, 29.97it/s]
epoch 88400  training loss: 0.09292808175086975

 89%|████████▊ | 88516/100000 [49:36<06:23, 29.92it/s]
epoch 88500  training loss: 0.0929291620850563


 89%|████████▊ | 88636/100000 [49:40<06:21, 29.77it/s]
epoch 88600  training loss: 0.09292703866958618


 89%|████████▉ | 88753/100000 [49:44<06:17, 29.83it/s]
epoch 88700  training loss: 0.09292665868997574

 89%|████████▉ | 88813/100000 [49:46<06:15, 29.79it/s]
epoch 88800  training loss: 0.09292744845151901


 89%|████████▉ | 88933/100000 [49:50<06:10, 29.84it/s]
epoch 88900  training loss: 0.09292715787887573


 89%|████████▉ | 89053/100000 [49:54<06:06, 29.88it/s]
epoch 89000  training loss: 0.09292654693126678
epoch 89000  clean testing loss: 0.004994232673197985

 89%|████████▉ | 89113/100000 [49:56<06:05, 29.79it/s]
epoch 89100  training loss: 0.09292619675397873


 89%|████████▉ | 89230/100000 [50:00<06:00, 29.85it/s]
epoch 89200  training loss: 0.09292562305927277


 89%|████████▉ | 89350/100000 [50:04<05:56, 29.85it/s]
epoch 89300  training loss: 0.09292518347501755

 89%|████████▉ | 89410/100000 [50:06<05:55, 29.81it/s]
epoch 89400  training loss: 0.09292333573102951


 90%|████████▉ | 89530/100000 [50:10<05:50, 29.88it/s]
epoch 89500  training loss: 0.09292428940534592


 90%|████████▉ | 89647/100000 [50:14<05:47, 29.83it/s]
epoch 89600  training loss: 0.09292235225439072

 90%|████████▉ | 89707/100000 [50:16<05:45, 29.80it/s]
epoch 89700  training loss: 0.09292323887348175


 90%|████████▉ | 89827/100000 [50:20<05:40, 29.85it/s]
epoch 89800  training loss: 0.09292271733283997


 90%|████████▉ | 89947/100000 [50:25<05:36, 29.84it/s]
epoch 89900  training loss: 0.09292228519916534

 90%|█████████ | 90007/100000 [50:27<05:37, 29.59it/s]
epoch 90000  training loss: 0.09292182326316833
epoch 90000  clean testing loss: 0.004999454598873854


 90%|█████████ | 90127/100000 [50:31<05:30, 29.86it/s]
epoch 90100  training loss: 0.09292133152484894


 90%|█████████ | 90247/100000 [50:35<05:26, 29.86it/s]
epoch 90200  training loss: 0.09292104095220566

 90%|█████████ | 90304/100000 [50:36<05:25, 29.75it/s]
epoch 90300  training loss: 0.0929207131266594


 90%|█████████ | 90424/100000 [50:41<05:20, 29.87it/s]
epoch 90400  training loss: 0.0929201990365982


 91%|█████████ | 90544/100000 [50:45<05:16, 29.84it/s]
epoch 90500  training loss: 0.09291858971118927

 91%|█████████ | 90604/100000 [50:47<05:15, 29.74it/s]
epoch 90600  training loss: 0.09291951358318329


 91%|█████████ | 90721/100000 [50:51<05:11, 29.79it/s]
epoch 90700  training loss: 0.09291905909776688


 91%|█████████ | 90841/100000 [50:55<05:06, 29.89it/s]
epoch 90800  training loss: 0.09291879832744598

 91%|█████████ | 90901/100000 [50:57<05:05, 29.78it/s]
epoch 90900  training loss: 0.09291698038578033


 91%|█████████ | 91021/100000 [51:01<05:01, 29.77it/s]
epoch 91000  training loss: 0.09291785955429077
epoch 91000  clean testing loss: 0.00500408373773098


 91%|█████████ | 91141/100000 [51:05<04:56, 29.86it/s]
epoch 91100  training loss: 0.09291765838861465

 91%|█████████ | 91201/100000 [51:07<04:55, 29.80it/s]
epoch 91200  training loss: 0.09291712194681168


 91%|█████████▏| 91321/100000 [51:11<04:50, 29.83it/s]
epoch 91300  training loss: 0.09291546046733856


 91%|█████████▏| 91438/100000 [51:15<04:47, 29.81it/s]
epoch 91400  training loss: 0.09291635453701019


 92%|█████████▏| 91558/100000 [51:19<04:42, 29.87it/s]
epoch 91500  training loss: 0.09291598945856094

 92%|█████████▏| 91618/100000 [51:21<04:40, 29.84it/s]
epoch 91600  training loss: 0.09291558712720871


 92%|█████████▏| 91735/100000 [51:25<04:37, 29.79it/s]
epoch 91700  training loss: 0.09291369467973709


 92%|█████████▏| 91855/100000 [51:29<04:32, 29.86it/s]
epoch 91800  training loss: 0.09291347116231918

 92%|█████████▏| 91915/100000 [51:31<04:31, 29.82it/s]
epoch 91900  training loss: 0.09291305392980576


 92%|█████████▏| 92035/100000 [51:35<04:26, 29.87it/s]
epoch 92000  training loss: 0.09291407465934753
epoch 92000  clean testing loss: 0.00500847864896059


 92%|█████████▏| 92155/100000 [51:39<04:22, 29.85it/s]
epoch 92100  training loss: 0.09291218966245651

 92%|█████████▏| 92215/100000 [51:41<04:21, 29.80it/s]
epoch 92200  training loss: 0.0929131954908371


 92%|█████████▏| 92332/100000 [51:45<04:17, 29.82it/s]
epoch 92300  training loss: 0.09291285276412964


 92%|█████████▏| 92452/100000 [51:49<04:12, 29.86it/s]
epoch 92400  training loss: 0.09291237592697144

 93%|█████████▎| 92512/100000 [51:51<04:11, 29.76it/s]
epoch 92500  training loss: 0.09291066974401474


 93%|█████████▎| 92632/100000 [51:55<04:06, 29.88it/s]
epoch 92600  training loss: 0.09291146695613861


 93%|█████████▎| 92752/100000 [51:59<04:02, 29.84it/s]
epoch 92700  training loss: 0.09290975332260132

 93%|█████████▎| 92809/100000 [52:01<04:01, 29.77it/s]
epoch 92800  training loss: 0.09290953725576401


 93%|█████████▎| 92929/100000 [52:05<03:57, 29.84it/s]
epoch 92900  training loss: 0.09291054308414459


 93%|█████████▎| 93049/100000 [52:09<03:52, 29.85it/s]
epoch 93000  training loss: 0.09291016310453415
epoch 93000  clean testing loss: 0.005012847948819399

 93%|█████████▎| 93109/100000 [52:11<03:51, 29.75it/s]
epoch 93100  training loss: 0.09290850907564163


 93%|█████████▎| 93226/100000 [52:15<03:47, 29.76it/s]
epoch 93200  training loss: 0.09290942549705505


 93%|█████████▎| 93346/100000 [52:19<03:42, 29.88it/s]
epoch 93300  training loss: 0.09290777146816254

 93%|█████████▎| 93406/100000 [52:21<03:41, 29.77it/s]
epoch 93400  training loss: 0.09290746599435806


 94%|█████████▎| 93527/100000 [52:25<03:36, 29.87it/s]
epoch 93500  training loss: 0.09290727227926254


 94%|█████████▎| 93645/100000 [52:29<03:32, 29.89it/s]
epoch 93600  training loss: 0.09290820360183716

 94%|█████████▎| 93705/100000 [52:31<03:31, 29.71it/s]
epoch 93700  training loss: 0.09290678799152374


 94%|█████████▍| 93825/100000 [52:35<03:26, 29.85it/s]
epoch 93800  training loss: 0.09290622174739838


 94%|█████████▍| 93945/100000 [52:39<03:23, 29.80it/s]
epoch 93900  training loss: 0.09290734678506851

 94%|█████████▍| 94005/100000 [52:41<03:23, 29.40it/s]
epoch 94000  training loss: 0.09290692955255508
epoch 94000  clean testing loss: 0.005016513634473085


 94%|█████████▍| 94122/100000 [52:45<03:17, 29.69it/s]
epoch 94100  training loss: 0.09290645271539688


 94%|█████████▍| 94224/100000 [52:48<03:13, 29.79it/s]
epoch 94200  training loss: 0.09290629625320435

 94%|█████████▍| 94284/100000 [52:50<03:11, 29.80it/s]
epoch 94300  training loss: 0.09290599077939987


 94%|█████████▍| 94404/100000 [52:54<03:08, 29.63it/s]
epoch 94400  training loss: 0.09290432184934616


 95%|█████████▍| 94524/100000 [52:58<03:03, 29.82it/s]
epoch 94500  training loss: 0.09290537983179092


 95%|█████████▍| 94644/100000 [53:02<02:59, 29.82it/s]
epoch 94600  training loss: 0.09290368854999542

 95%|█████████▍| 94704/100000 [53:04<02:58, 29.73it/s]
epoch 94700  training loss: 0.0929047241806984


 95%|█████████▍| 94821/100000 [53:08<02:53, 29.80it/s]
epoch 94800  training loss: 0.09290438890457153


 95%|█████████▍| 94941/100000 [53:12<02:49, 29.85it/s]
epoch 94900  training loss: 0.0929042398929596

 95%|█████████▍| 94998/100000 [53:14<02:54, 28.74it/s]
epoch 95000  training loss: 0.09290380775928497
epoch 95000  clean testing loss: 0.005020034499466419


 95%|█████████▌| 95118/100000 [53:18<02:43, 29.81it/s]
epoch 95100  training loss: 0.09290347993373871


 95%|█████████▌| 95238/100000 [53:22<02:39, 29.81it/s]
epoch 95200  training loss: 0.09290315955877304

 95%|█████████▌| 95298/100000 [53:24<02:37, 29.83it/s]
epoch 95300  training loss: 0.09290152788162231


 95%|█████████▌| 95418/100000 [53:28<02:34, 29.72it/s]
epoch 95400  training loss: 0.09290242940187454


 96%|█████████▌| 95535/100000 [53:32<02:29, 29.79it/s]
epoch 95500  training loss: 0.09290361404418945


 96%|█████████▌| 95655/100000 [53:36<02:25, 29.79it/s]
epoch 95600  training loss: 0.09290176630020142

 96%|█████████▌| 95715/100000 [53:38<02:23, 29.76it/s]
epoch 95700  training loss: 0.09290153533220291


 96%|█████████▌| 95835/100000 [53:42<02:19, 29.81it/s]
epoch 95800  training loss: 0.0929013341665268


 96%|█████████▌| 95952/100000 [53:46<02:15, 29.78it/s]
epoch 95900  training loss: 0.09290085732936859

 96%|█████████▌| 96012/100000 [53:48<02:14, 29.58it/s]
epoch 96000  training loss: 0.09290053695440292
epoch 96000  clean testing loss: 0.005023724399507046


 96%|█████████▌| 96132/100000 [53:52<02:09, 29.80it/s]
epoch 96100  training loss: 0.09290027618408203


 96%|█████████▌| 96249/100000 [53:56<02:06, 29.77it/s]
epoch 96200  training loss: 0.09290000051259995

 96%|█████████▋| 96309/100000 [53:58<02:03, 29.80it/s]
epoch 96300  training loss: 0.09289970993995667


 96%|█████████▋| 96429/100000 [54:02<01:59, 29.88it/s]
epoch 96400  training loss: 0.09289948642253876


 97%|█████████▋| 96549/100000 [54:06<01:55, 29.89it/s]
epoch 96500  training loss: 0.09289923310279846

 97%|█████████▋| 96609/100000 [54:08<01:53, 29.82it/s]
epoch 96600  training loss: 0.09289892762899399


 97%|█████████▋| 96729/100000 [54:13<01:49, 29.90it/s]
epoch 96700  training loss: 0.09289868175983429


 97%|█████████▋| 96847/100000 [54:17<01:45, 29.91it/s]
epoch 96800  training loss: 0.0928984135389328

 97%|█████████▋| 96907/100000 [54:19<01:43, 29.82it/s]
epoch 96900  training loss: 0.09289807081222534


 97%|█████████▋| 97027/100000 [54:23<01:39, 29.83it/s]
epoch 97000  training loss: 0.09289787709712982
epoch 97000  clean testing loss: 0.0050267805345356464


 97%|█████████▋| 97147/100000 [54:27<01:35, 29.87it/s]
epoch 97100  training loss: 0.09289754182100296

 97%|█████████▋| 97204/100000 [54:28<01:34, 29.61it/s]
epoch 97200  training loss: 0.0928974375128746


 97%|█████████▋| 97325/100000 [54:33<01:29, 29.91it/s]
epoch 97300  training loss: 0.09289710223674774


 97%|█████████▋| 97446/100000 [54:37<01:25, 29.82it/s]
epoch 97400  training loss: 0.09289686381816864

 98%|█████████▊| 97506/100000 [54:39<01:23, 29.78it/s]
epoch 97500  training loss: 0.09289655834436417


 98%|█████████▊| 97625/100000 [54:43<01:19, 29.92it/s]
epoch 97600  training loss: 0.0928964912891388


 98%|█████████▊| 97742/100000 [54:47<01:15, 29.90it/s]
epoch 97700  training loss: 0.09289602190256119

 98%|█████████▊| 97804/100000 [54:49<01:13, 29.85it/s]
epoch 97800  training loss: 0.09289587289094925


 98%|█████████▊| 97924/100000 [54:53<01:09, 29.96it/s]
epoch 97900  training loss: 0.09289554506540298


 98%|█████████▊| 98043/100000 [54:57<01:05, 29.87it/s]
epoch 98000  training loss: 0.0928952768445015
epoch 98000  clean testing loss: 0.005029931664466858

 98%|█████████▊| 98102/100000 [54:59<01:04, 29.62it/s]
epoch 98100  training loss: 0.09289507567882538


 98%|█████████▊| 98223/100000 [55:03<00:59, 29.94it/s]
epoch 98200  training loss: 0.09289475530385971


 98%|█████████▊| 98342/100000 [55:07<00:55, 29.94it/s]
epoch 98300  training loss: 0.09289459884166718

 98%|█████████▊| 98402/100000 [55:09<00:53, 29.70it/s]
epoch 98400  training loss: 0.09289424866437912


 99%|█████████▊| 98522/100000 [55:13<00:49, 29.93it/s]
epoch 98500  training loss: 0.09289401769638062


 99%|█████████▊| 98640/100000 [55:17<00:45, 29.95it/s]
epoch 98600  training loss: 0.0928935557603836

 99%|█████████▊| 98701/100000 [55:19<00:43, 29.81it/s]
epoch 98700  training loss: 0.09289348870515823


 99%|█████████▉| 98819/100000 [55:23<00:39, 29.93it/s]
epoch 98800  training loss: 0.09289325028657913


 99%|█████████▉| 98941/100000 [55:27<00:35, 29.97it/s]
epoch 98900  training loss: 0.09289295226335526

 99%|█████████▉| 99000/100000 [55:29<00:33, 29.91it/s]
epoch 99000  training loss: 0.09289273619651794
epoch 99000  clean testing loss: 0.0050329891964793205


 99%|█████████▉| 99120/100000 [55:33<00:29, 29.86it/s]
epoch 99100  training loss: 0.09289252758026123


 99%|█████████▉| 99241/100000 [55:37<00:25, 29.87it/s]
epoch 99200  training loss: 0.09289219975471497


 99%|█████████▉| 99358/100000 [55:41<00:21, 29.96it/s]
epoch 99300  training loss: 0.09289196878671646

 99%|█████████▉| 99420/100000 [55:43<00:19, 29.88it/s]
epoch 99400  training loss: 0.09289170056581497


100%|█████████▉| 99537/100000 [55:47<00:15, 29.94it/s]
epoch 99500  training loss: 0.09289151430130005


100%|█████████▉| 99658/100000 [55:51<00:11, 29.92it/s]
epoch 99600  training loss: 0.09289120882749557

100%|█████████▉| 99718/100000 [55:53<00:09, 29.71it/s]
epoch 99700  training loss: 0.09289126843214035


100%|█████████▉| 99838/100000 [55:57<00:05, 29.94it/s]
epoch 99800  training loss: 0.09289105981588364


100%|█████████▉| 99956/100000 [56:01<00:01, 29.96it/s]
epoch 99900  training loss: 0.09289069473743439

100%|██████████| 100000/100000 [56:02<00:00, 29.74it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_sin_size5000_noise1.00e-01_invop1_lr5e-05 ...