
  0%|                                                                                  | 34/100000 [00:01<1:02:33, 26.63it/s]
epoch 0  training loss: 50.7077522277832
epoch 0  clean testing loss: 30.809005737304688

  0%|                                                                                  | 88/100000 [00:03<1:02:10, 26.78it/s]
epoch 100  training loss: 0.9154351949691772


  0%|▏                                                                                | 193/100000 [00:07<1:01:55, 26.86it/s]
epoch 200  training loss: 0.17572751641273499


  0%|▏                                                                                | 292/100000 [00:11<1:12:45, 22.84it/s]
epoch 300  training loss: 0.12952961027622223



  0%|▎                                                                                | 424/100000 [00:17<1:19:01, 21.00it/s]
epoch 400  training loss: 0.13025030493736267


  1%|▍                                                                                | 508/100000 [00:21<1:24:04, 19.72it/s]
epoch 500  training loss: 0.07777545601129532



  1%|▌                                                                                | 629/100000 [00:27<1:22:46, 20.01it/s]
epoch 600  training loss: 0.09780916571617126


  1%|▌                                                                                | 707/100000 [00:31<1:24:29, 19.59it/s]
epoch 700  training loss: 0.07323416322469711



  1%|▋                                                                                | 826/100000 [00:37<1:22:25, 20.05it/s]
epoch 800  training loss: 0.07687310874462128


  1%|▋                                                                                | 906/100000 [00:41<1:22:28, 20.02it/s]
epoch 900  training loss: 0.08680205047130585



  1%|▊                                                                               | 1026/100000 [00:47<1:23:10, 19.83it/s]
epoch 1000  training loss: 0.07451633363962173
epoch 1000  clean testing loss: 0.11910282075405121


  1%|▉                                                                               | 1106/100000 [00:51<1:24:47, 19.44it/s]
epoch 1100  training loss: 0.07053644210100174



  1%|▉                                                                               | 1225/100000 [00:57<1:22:29, 19.96it/s]
epoch 1200  training loss: 0.06386616826057434


  1%|█                                                                               | 1304/100000 [01:01<1:26:35, 19.00it/s]
epoch 1300  training loss: 0.06987495720386505



  1%|█▏                                                                              | 1426/100000 [01:07<1:24:13, 19.50it/s]
epoch 1400  training loss: 0.05732204020023346


  2%|█▏                                                                              | 1504/100000 [01:11<1:22:40, 19.85it/s]
epoch 1500  training loss: 0.06533125787973404



  2%|█▎                                                                              | 1622/100000 [01:17<1:24:28, 19.41it/s]
epoch 1600  training loss: 0.2930319309234619


  2%|█▎                                                                              | 1701/100000 [01:21<1:22:12, 19.93it/s]
epoch 1700  training loss: 0.07506608963012695



  2%|█▍                                                                              | 1820/100000 [01:27<1:24:10, 19.44it/s]
epoch 1800  training loss: 0.06051740422844887


  2%|█▌                                                                              | 1901/100000 [01:31<1:23:58, 19.47it/s]
epoch 1900  training loss: 0.05970063433051109



  2%|█▌                                                                              | 2019/100000 [01:37<1:22:38, 19.76it/s]
epoch 2000  training loss: 0.06346824765205383
epoch 2000  clean testing loss: 0.1140165776014328



  2%|█▋                                                                              | 2139/100000 [01:43<1:23:38, 19.50it/s]
epoch 2100  training loss: 0.06454626470804214


  2%|█▊                                                                              | 2219/100000 [01:47<1:20:05, 20.35it/s]
epoch 2200  training loss: 0.05841338634490967



  2%|█▊                                                                              | 2339/100000 [01:53<1:23:04, 19.59it/s]
epoch 2300  training loss: 0.06210409104824066


  2%|█▉                                                                              | 2418/100000 [01:57<1:24:23, 19.27it/s]
epoch 2400  training loss: 0.06272275000810623



  3%|██                                                                              | 2536/100000 [02:03<1:22:50, 19.61it/s]
epoch 2500  training loss: 0.05991725996136665


  3%|██                                                                              | 2614/100000 [02:07<1:21:10, 20.00it/s]
epoch 2600  training loss: 0.07861890643835068



  3%|██▏                                                                             | 2733/100000 [02:13<1:21:06, 19.99it/s]
epoch 2700  training loss: 0.06921873241662979


  3%|██▏                                                                             | 2811/100000 [02:17<1:20:35, 20.10it/s]
epoch 2800  training loss: 0.053740084171295166



  3%|██▎                                                                             | 2932/100000 [02:23<1:21:48, 19.77it/s]
epoch 2900  training loss: 0.06076571345329285


  3%|██▍                                                                             | 3010/100000 [02:27<1:22:07, 19.68it/s]
epoch 3000  training loss: 0.07836256176233292
epoch 3000  clean testing loss: 0.08973933756351471



  3%|██▌                                                                             | 3129/100000 [02:34<1:22:11, 19.64it/s]
epoch 3100  training loss: 0.06161268427968025


  3%|██▌                                                                             | 3205/100000 [02:37<1:22:06, 19.65it/s]
epoch 3200  training loss: 0.055153101682662964



  3%|██▋                                                                             | 3324/100000 [02:44<1:25:31, 18.84it/s]
epoch 3300  training loss: 0.0494263619184494


  3%|██▋                                                                             | 3403/100000 [02:48<1:22:24, 19.54it/s]
epoch 3400  training loss: 0.05558532103896141



  4%|██▊                                                                             | 3520/100000 [02:54<1:22:12, 19.56it/s]
epoch 3500  training loss: 0.05019337683916092



  4%|██▉                                                                             | 3641/100000 [03:00<1:21:52, 19.61it/s]
epoch 3600  training loss: 0.05676193907856941


  4%|██▉                                                                             | 3718/100000 [03:04<1:23:19, 19.26it/s]
epoch 3700  training loss: 0.05175711214542389



  4%|███                                                                             | 3839/100000 [03:10<1:20:11, 19.99it/s]
epoch 3800  training loss: 0.05229182541370392


  4%|███▏                                                                            | 3908/100000 [03:13<1:21:39, 19.61it/s]
epoch 3900  training loss: 0.0561802014708519



  4%|███▏                                                                            | 4027/100000 [03:19<1:21:26, 19.64it/s]
epoch 4000  training loss: 0.0705098882317543
epoch 4000  clean testing loss: 0.0824994370341301


  4%|███▎                                                                            | 4105/100000 [03:23<1:22:14, 19.44it/s]
epoch 4100  training loss: 0.051348455250263214



  4%|███▍                                                                            | 4227/100000 [03:29<1:23:59, 19.01it/s]
epoch 4200  training loss: 0.04590430483222008


  4%|███▍                                                                            | 4306/100000 [03:33<1:21:38, 19.54it/s]
epoch 4300  training loss: 0.08795137703418732



  4%|███▌                                                                            | 4423/100000 [03:39<1:22:38, 19.27it/s]
epoch 4400  training loss: 0.06048249825835228


  4%|███▌                                                                            | 4500/100000 [03:43<1:25:06, 18.70it/s]
epoch 4500  training loss: 0.054548777639865875



  5%|███▋                                                                            | 4617/100000 [03:49<1:21:01, 19.62it/s]
epoch 4600  training loss: 0.05579940229654312


  5%|███▊                                                                            | 4697/100000 [03:53<1:19:38, 19.94it/s]
epoch 4700  training loss: 0.05387890711426735



  5%|███▊                                                                            | 4817/100000 [03:59<1:20:06, 19.80it/s]
epoch 4800  training loss: 0.05066825821995735


  5%|███▉                                                                            | 4895/100000 [04:03<1:20:59, 19.57it/s]
epoch 4900  training loss: 0.05448029562830925



  5%|████                                                                            | 5014/100000 [04:09<1:20:45, 19.60it/s]
epoch 5000  training loss: 0.05197620019316673
epoch 5000  clean testing loss: 0.08397224545478821



  5%|████                                                                            | 5130/100000 [04:15<1:23:03, 19.04it/s]
epoch 5100  training loss: 0.05977518856525421


  5%|████▏                                                                           | 5210/100000 [04:19<1:20:34, 19.61it/s]
epoch 5200  training loss: 0.0506686307489872



  5%|████▎                                                                           | 5331/100000 [04:25<1:21:04, 19.46it/s]
epoch 5300  training loss: 0.05712710693478584


  5%|████▎                                                                           | 5411/100000 [04:30<1:19:11, 19.91it/s]
epoch 5400  training loss: 0.05090133100748062



  6%|████▍                                                                           | 5527/100000 [04:36<1:18:16, 20.12it/s]
epoch 5500  training loss: 0.1904911994934082


  6%|████▍                                                                           | 5606/100000 [04:40<1:18:14, 20.11it/s]
epoch 5600  training loss: 0.051124271005392075



  6%|████▌                                                                           | 5724/100000 [04:46<1:18:55, 19.91it/s]
epoch 5700  training loss: 0.04868675395846367


  6%|████▋                                                                           | 5804/100000 [04:50<1:17:01, 20.38it/s]
epoch 5800  training loss: 0.051868878304958344



  6%|████▋                                                                           | 5925/100000 [04:56<1:19:06, 19.82it/s]
epoch 5900  training loss: 0.053232114762067795


  6%|████▊                                                                           | 6006/100000 [05:00<1:19:17, 19.76it/s]
epoch 6000  training loss: 0.05228595435619354
epoch 6000  clean testing loss: 0.08045753836631775



  6%|████▉                                                                           | 6124/100000 [05:06<1:20:15, 19.50it/s]
epoch 6100  training loss: 0.045790836215019226


  6%|████▉                                                                           | 6201/100000 [05:10<1:21:23, 19.21it/s]
epoch 6200  training loss: 0.04293733835220337



  6%|█████                                                                           | 6321/100000 [05:16<1:18:46, 19.82it/s]
epoch 6300  training loss: 0.04880564287304878


  6%|█████                                                                           | 6400/100000 [05:20<1:19:24, 19.64it/s]
epoch 6400  training loss: 0.04878399148583412



  7%|█████▏                                                                          | 6521/100000 [05:26<1:20:47, 19.28it/s]
epoch 6500  training loss: 0.0429215244948864


  7%|█████▎                                                                          | 6600/100000 [05:30<1:19:26, 19.60it/s]
epoch 6600  training loss: 0.06943827122449875



  7%|█████▍                                                                          | 6719/100000 [05:36<1:18:41, 19.76it/s]
epoch 6700  training loss: 0.0716632753610611


  7%|█████▍                                                                          | 6799/100000 [05:40<1:17:09, 20.13it/s]
epoch 6800  training loss: 0.05534084513783455



  7%|█████▌                                                                          | 6917/100000 [05:46<1:19:40, 19.47it/s]
epoch 6900  training loss: 0.055886391550302505



  7%|█████▋                                                                          | 7035/100000 [05:52<1:17:04, 20.10it/s]
epoch 7000  training loss: 0.07470571994781494
epoch 7000  clean testing loss: 0.0787341520190239


  7%|█████▋                                                                          | 7115/100000 [05:56<1:17:14, 20.04it/s]
epoch 7100  training loss: 0.05905849114060402



  7%|█████▊                                                                          | 7235/100000 [06:02<1:17:52, 19.85it/s]
epoch 7200  training loss: 0.06464365869760513


  7%|█████▊                                                                          | 7312/100000 [06:06<1:18:30, 19.68it/s]
epoch 7300  training loss: 0.05241038650274277



  7%|█████▉                                                                          | 7429/100000 [06:12<1:17:53, 19.81it/s]
epoch 7400  training loss: 0.048000577837228775


  8%|██████                                                                          | 7511/100000 [06:16<1:17:07, 19.99it/s]
epoch 7500  training loss: 0.049373187124729156



  8%|██████                                                                          | 7629/100000 [06:22<1:18:37, 19.58it/s]
epoch 7600  training loss: 0.0447375513613224


  8%|██████▏                                                                         | 7699/100000 [06:25<1:18:04, 19.70it/s]
epoch 7700  training loss: 0.04527817666530609



  8%|██████▎                                                                         | 7816/100000 [06:32<1:18:48, 19.49it/s]
epoch 7800  training loss: 0.053027037531137466


  8%|██████▎                                                                         | 7894/100000 [06:36<1:17:35, 19.79it/s]
epoch 7900  training loss: 0.04946054518222809



  8%|██████▍                                                                         | 8012/100000 [06:42<1:18:09, 19.62it/s]
epoch 8000  training loss: 0.05159885063767433
epoch 8000  clean testing loss: 0.07650049775838852



  8%|██████▌                                                                         | 8129/100000 [06:48<1:24:06, 18.21it/s]
epoch 8100  training loss: 0.04748660326004028


  8%|██████▌                                                                         | 8206/100000 [06:52<1:18:03, 19.60it/s]
epoch 8200  training loss: 0.10805626213550568



  8%|██████▋                                                                         | 8325/100000 [06:58<1:23:59, 18.19it/s]
epoch 8300  training loss: 0.05684725567698479


  8%|██████▋                                                                         | 8404/100000 [07:02<1:15:14, 20.29it/s]
epoch 8400  training loss: 0.07711470127105713



  9%|██████▊                                                                         | 8523/100000 [07:08<1:15:05, 20.30it/s]
epoch 8500  training loss: 0.05579562112689018


  9%|██████▉                                                                         | 8603/100000 [07:12<1:16:54, 19.80it/s]
epoch 8600  training loss: 0.05669755861163139



  9%|██████▉                                                                         | 8721/100000 [07:18<1:16:01, 20.01it/s]
epoch 8700  training loss: 0.05089953914284706


  9%|███████                                                                         | 8801/100000 [07:22<1:15:52, 20.03it/s]
epoch 8800  training loss: 0.04870710149407387



  9%|███████▏                                                                        | 8919/100000 [07:28<1:17:44, 19.53it/s]
epoch 8900  training loss: 0.043875113129615784


  9%|███████▏                                                                        | 8999/100000 [07:32<1:16:21, 19.86it/s]
epoch 9000  training loss: 0.04873296618461609
epoch 9000  clean testing loss: 0.07319986075162888



  9%|███████▎                                                                        | 9115/100000 [07:38<1:18:06, 19.39it/s]
epoch 9100  training loss: 0.051715005189180374


  9%|███████▎                                                                        | 9195/100000 [07:42<1:15:00, 20.18it/s]
epoch 9200  training loss: 0.054296672344207764



  9%|███████▍                                                                        | 9312/100000 [07:48<1:19:42, 18.96it/s]
epoch 9300  training loss: 0.04806651920080185



  9%|███████▌                                                                        | 9432/100000 [07:54<1:17:52, 19.38it/s]
epoch 9400  training loss: 0.06229303404688835


 10%|███████▌                                                                        | 9512/100000 [07:58<1:14:44, 20.18it/s]
epoch 9500  training loss: 0.06103353202342987



 10%|███████▋                                                                        | 9630/100000 [08:04<1:15:48, 19.87it/s]
epoch 9600  training loss: 0.05331294611096382


 10%|███████▊                                                                        | 9711/100000 [08:08<1:17:18, 19.46it/s]
epoch 9700  training loss: 0.09356945753097534



 10%|███████▊                                                                        | 9832/100000 [08:14<1:14:48, 20.09it/s]
epoch 9800  training loss: 0.05257103592157364


 10%|███████▉                                                                        | 9910/100000 [08:18<1:15:55, 19.77it/s]
epoch 9900  training loss: 0.05570121854543686



 10%|███████▉                                                                       | 10028/100000 [08:24<1:20:12, 18.69it/s]
epoch 10000  training loss: 0.04984494298696518
epoch 10000  clean testing loss: 0.06346222013235092


 10%|███████▉                                                                       | 10108/100000 [08:28<1:15:24, 19.87it/s]
epoch 10100  training loss: 0.06310583651065826



 10%|████████                                                                       | 10225/100000 [08:34<1:16:51, 19.47it/s]
epoch 10200  training loss: 0.06468334048986435


 10%|████████▏                                                                      | 10303/100000 [08:38<1:16:49, 19.46it/s]
epoch 10300  training loss: 0.06383368372917175



 10%|████████▏                                                                      | 10423/100000 [08:44<1:13:38, 20.27it/s]
epoch 10400  training loss: 0.04750525951385498



 11%|████████▎                                                                      | 10544/100000 [08:50<1:15:48, 19.67it/s]
epoch 10500  training loss: 0.05452082306146622


 11%|████████▍                                                                      | 10624/100000 [08:54<1:17:34, 19.20it/s]
epoch 10600  training loss: 0.04568006098270416



 11%|████████▍                                                                      | 10743/100000 [09:00<1:15:13, 19.78it/s]
epoch 10700  training loss: 0.04992198199033737


 11%|████████▌                                                                      | 10823/100000 [09:04<1:14:38, 19.91it/s]
epoch 10800  training loss: 0.04522446170449257



 11%|████████▋                                                                      | 10938/100000 [09:10<1:15:16, 19.72it/s]
epoch 10900  training loss: 0.04464362561702728


 11%|████████▋                                                                      | 11007/100000 [09:14<1:15:31, 19.64it/s]
epoch 11000  training loss: 0.04938386753201485
epoch 11000  clean testing loss: 0.08019684255123138



 11%|████████▊                                                                      | 11127/100000 [09:20<1:12:57, 20.30it/s]
epoch 11100  training loss: 0.052794259041547775


 11%|████████▊                                                                      | 11207/100000 [09:24<1:13:51, 20.03it/s]
epoch 11200  training loss: 0.051322199404239655



 11%|████████▉                                                                      | 11326/100000 [09:30<1:14:34, 19.82it/s]
epoch 11300  training loss: 0.06884314119815826


 11%|█████████                                                                      | 11407/100000 [09:34<1:14:07, 19.92it/s]
epoch 11400  training loss: 0.04565736651420593



 12%|█████████                                                                      | 11523/100000 [09:40<1:15:01, 19.65it/s]
epoch 11500  training loss: 0.04481641948223114


 12%|█████████▏                                                                     | 11602/100000 [09:44<1:21:30, 18.08it/s]
epoch 11600  training loss: 0.04428879916667938



 12%|█████████▎                                                                     | 11719/100000 [09:50<1:11:12, 20.66it/s]
epoch 11700  training loss: 0.04595431685447693



 12%|█████████▎                                                                     | 11831/100000 [09:56<1:30:03, 16.32it/s]
epoch 11800  training loss: 0.0476088747382164


 12%|█████████▍                                                                     | 11910/100000 [10:00<1:13:19, 20.02it/s]
epoch 11900  training loss: 0.04647133871912956



 12%|█████████▌                                                                     | 12029/100000 [10:06<1:14:22, 19.71it/s]
epoch 12000  training loss: 0.04705459997057915
epoch 12000  clean testing loss: 0.07766472548246384


 12%|█████████▌                                                                     | 12106/100000 [10:10<1:17:49, 18.82it/s]
epoch 12100  training loss: 0.043288540095090866



 12%|█████████▋                                                                     | 12227/100000 [10:16<1:11:56, 20.34it/s]
epoch 12200  training loss: 0.04255841299891472


 12%|█████████▋                                                                     | 12305/100000 [10:20<1:12:38, 20.12it/s]
epoch 12300  training loss: 0.040902554988861084



 12%|█████████▊                                                                     | 12425/100000 [10:26<1:17:49, 18.75it/s]
epoch 12400  training loss: 0.04024385288357735


 13%|█████████▉                                                                     | 12503/100000 [10:30<1:14:40, 19.53it/s]
epoch 12500  training loss: 0.03982023522257805



 13%|█████████▉                                                                     | 12622/100000 [10:36<1:13:43, 19.75it/s]
epoch 12600  training loss: 0.05306282639503479


 13%|██████████                                                                     | 12698/100000 [10:40<1:15:12, 19.35it/s]
epoch 12700  training loss: 0.041704535484313965



 13%|██████████▏                                                                    | 12818/100000 [10:46<1:14:21, 19.54it/s]
epoch 12800  training loss: 0.04695497453212738



 13%|██████████▏                                                                    | 12935/100000 [10:52<1:14:44, 19.41it/s]
epoch 12900  training loss: 0.06268952786922455


 13%|██████████▎                                                                    | 13017/100000 [10:56<1:14:11, 19.54it/s]
epoch 13000  training loss: 0.05016135796904564
epoch 13000  clean testing loss: 0.07927986979484558



 13%|██████████▍                                                                    | 13136/100000 [11:02<1:12:28, 19.98it/s]
epoch 13100  training loss: 0.08409598469734192


 13%|██████████▍                                                                    | 13217/100000 [11:06<1:09:50, 20.71it/s]
epoch 13200  training loss: 0.06453050673007965



 13%|██████████▌                                                                    | 13336/100000 [11:12<1:13:48, 19.57it/s]
epoch 13300  training loss: 0.05713961273431778


 13%|██████████▌                                                                    | 13414/100000 [11:16<1:14:58, 19.25it/s]
epoch 13400  training loss: 0.056908633559942245



 14%|██████████▋                                                                    | 13534/100000 [11:22<1:12:26, 19.89it/s]
epoch 13500  training loss: 0.053823139518499374


 14%|██████████▊                                                                    | 13610/100000 [11:26<1:13:08, 19.69it/s]
epoch 13600  training loss: 0.057090047746896744



 14%|██████████▊                                                                    | 13729/100000 [11:32<1:13:50, 19.47it/s]
epoch 13700  training loss: 0.05149226635694504


 14%|██████████▉                                                                    | 13809/100000 [11:36<1:11:23, 20.12it/s]
epoch 13800  training loss: 0.050554078072309494



 14%|███████████                                                                    | 13928/100000 [11:42<1:14:35, 19.23it/s]
epoch 13900  training loss: 0.05381424352526665


 14%|███████████                                                                    | 14006/100000 [11:46<1:14:57, 19.12it/s]
epoch 14000  training loss: 0.05612299591302872
epoch 14000  clean testing loss: 0.058604151010513306



 14%|███████████▏                                                                   | 14125/100000 [11:52<1:14:00, 19.34it/s]
epoch 14100  training loss: 0.056158602237701416


 14%|███████████▏                                                                   | 14202/100000 [11:56<1:12:21, 19.76it/s]
epoch 14200  training loss: 0.05270789563655853



 14%|███████████▎                                                                   | 14321/100000 [12:02<1:10:01, 20.39it/s]
epoch 14300  training loss: 0.05681360885500908



 14%|███████████▍                                                                   | 14439/100000 [12:08<1:11:48, 19.86it/s]
epoch 14400  training loss: 0.05094043165445328


 15%|███████████▍                                                                   | 14519/100000 [12:12<1:11:30, 19.92it/s]
epoch 14500  training loss: 0.06112579256296158



 15%|███████████▌                                                                   | 14637/100000 [12:18<1:12:46, 19.55it/s]
epoch 14600  training loss: 0.05015811324119568


 15%|███████████▌                                                                   | 14704/100000 [12:22<1:12:23, 19.64it/s]
epoch 14700  training loss: 0.053917016834020615



 15%|███████████▋                                                                   | 14822/100000 [12:28<1:14:19, 19.10it/s]
epoch 14800  training loss: 0.050341665744781494


 15%|███████████▊                                                                   | 14901/100000 [12:32<1:12:29, 19.56it/s]
epoch 14900  training loss: 0.04608381167054176



 15%|███████████▊                                                                   | 15021/100000 [12:38<1:10:48, 20.00it/s]
epoch 15000  training loss: 0.0513586699962616
epoch 15000  clean testing loss: 0.06637712568044662


 15%|███████████▉                                                                   | 15099/100000 [12:42<1:12:20, 19.56it/s]
epoch 15100  training loss: 0.04770159348845482



 15%|████████████                                                                   | 15216/100000 [12:48<1:10:36, 20.01it/s]
epoch 15200  training loss: 0.04721805453300476


 15%|████████████                                                                   | 15294/100000 [12:52<1:11:08, 19.85it/s]
epoch 15300  training loss: 0.050357136875391006



 15%|████████████▏                                                                  | 15413/100000 [12:58<1:10:18, 20.05it/s]
epoch 15400  training loss: 0.04961133748292923



 16%|████████████▎                                                                  | 15533/100000 [13:04<1:12:21, 19.46it/s]
epoch 15500  training loss: 0.04673729091882706


 16%|████████████▎                                                                  | 15612/100000 [13:08<1:11:11, 19.76it/s]
epoch 15600  training loss: 0.04886433482170105



 16%|████████████▍                                                                  | 15728/100000 [13:14<1:11:13, 19.72it/s]
epoch 15700  training loss: 0.04685724154114723


 16%|████████████▍                                                                  | 15807/100000 [13:18<1:11:17, 19.68it/s]
epoch 15800  training loss: 0.05390089377760887



 16%|████████████▌                                                                  | 15926/100000 [13:24<1:11:56, 19.48it/s]
epoch 15900  training loss: 0.042922236025333405


 16%|████████████▋                                                                  | 16004/100000 [13:28<1:09:38, 20.10it/s]
epoch 16000  training loss: 0.07262919843196869
epoch 16000  clean testing loss: 0.05518025532364845



 16%|████████████▋                                                                  | 16121/100000 [13:34<1:11:13, 19.63it/s]
epoch 16100  training loss: 0.058970484882593155


 16%|████████████▊                                                                  | 16198/100000 [13:38<1:16:15, 18.31it/s]
epoch 16200  training loss: 0.05180102959275246



 16%|████████████▉                                                                  | 16318/100000 [13:44<1:10:47, 19.70it/s]
epoch 16300  training loss: 0.05325767770409584


 16%|████████████▉                                                                  | 16397/100000 [13:48<1:10:31, 19.76it/s]
epoch 16400  training loss: 0.049944888800382614



 17%|█████████████                                                                  | 16515/100000 [13:54<1:10:55, 19.62it/s]
epoch 16500  training loss: 0.05129130929708481



 17%|█████████████▏                                                                 | 16636/100000 [14:00<1:11:26, 19.45it/s]
epoch 16600  training loss: 0.05328546464443207


 17%|█████████████▏                                                                 | 16715/100000 [14:04<1:07:34, 20.54it/s]
epoch 16700  training loss: 0.0471242256462574



 17%|█████████████▎                                                                 | 16833/100000 [14:10<1:10:57, 19.53it/s]
epoch 16800  training loss: 0.05295176059007645


 17%|█████████████▎                                                                 | 16911/100000 [14:14<1:09:16, 19.99it/s]
epoch 16900  training loss: 0.05132921040058136



 17%|█████████████▍                                                                 | 17035/100000 [14:20<1:01:19, 22.55it/s]
epoch 17000  training loss: 0.051342520862817764
epoch 17000  clean testing loss: 0.05283704400062561

 17%|█████████████▌                                                                 | 17125/100000 [14:24<1:09:43, 19.81it/s]
Traceback (most recent call last):
  File "/home/howon/aistats25-exp/nn_exp.py", line 272, in <module>
    for i in tqdm(range(epoch)):
  File "/home/howon/aistats25-exp/nn_exp.py", line 261, in closure
    clean_test_loss_record = []
  File "/home/howon/aistats25-exp/nn_exp.py", line 227, in compute_loss
    assert(train_y.shape == (args.sample_size, 1))
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/autograd/__init__.py", line 412, in grad
    result = _engine_run_backward(
  File "/home/howon/.conda/envs/cs552/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
epoch 17100  training loss: 0.04809505492448807
epoch 17100  clean testing loss: 0.05692769214510918