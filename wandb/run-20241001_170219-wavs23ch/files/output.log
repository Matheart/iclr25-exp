
  0%|          | 379/100000 [00:00<03:36, 460.94it/s]
epoch 0  training loss: 0.5926477909088135
epoch 0  clean testing loss: 0.4913894534111023
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size5000_noise1.00e-01_invop0 ...
epoch 100  training loss: 0.2465498000383377
epoch 100  clean testing loss: 0.13768471777439117
epoch 200  training loss: 0.19594693183898926
epoch 200  clean testing loss: 0.0917203351855278
epoch 300  training loss: 0.18098807334899902
epoch 300  clean testing loss: 0.07664451748132706
epoch 400  training loss: 0.1670590341091156
epoch 400  clean testing loss: 0.06263470649719238
epoch 500  training loss: 0.15598292648792267
epoch 500  clean testing loss: 0.05192570015788078
epoch 600  training loss: 0.14837759733200073
epoch 600  clean testing loss: 0.04459498077630997
epoch 700  training loss: 0.14336559176445007

epoch 700  clean testing loss: 0.039775341749191284
epoch 800  training loss: 0.13956601917743683
epoch 800  clean testing loss: 0.036298807710409164
epoch 900  training loss: 0.13660523295402527
epoch 900  clean testing loss: 0.03353758156299591
epoch 1000  training loss: 0.1341625303030014
epoch 1000  clean testing loss: 0.03148077055811882
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size5000_noise1.00e-01_invop0 ...
epoch 1100  training loss: 0.13217642903327942
epoch 1100  clean testing loss: 0.029963310807943344
epoch 1200  training loss: 0.13042309880256653
epoch 1200  clean testing loss: 0.02833569049835205
epoch 1300  training loss: 0.12895582616329193
epoch 1300  clean testing loss: 0.02714192122220993
epoch 1400  training loss: 0.12767983973026276
epoch 1400  clean testing loss: 0.026152029633522034
epoch 1500  training loss: 0.12654171884059906
epoch 1500  clean testing loss: 0.025277987122535706
epoch 1600  training loss: 0.1255677491426468

  2%|▏         | 2419/100000 [00:05<03:31, 462.10it/s]
epoch 1700  training loss: 0.12462801486253738
epoch 1700  clean testing loss: 0.023735608905553818
epoch 1800  training loss: 0.12392313778400421
epoch 1800  clean testing loss: 0.023125631734728813
epoch 1900  training loss: 0.12316330522298813
epoch 1900  clean testing loss: 0.02259371243417263
epoch 2000  training loss: 0.12250133603811264
epoch 2000  clean testing loss: 0.022097893059253693
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size5000_noise1.00e-01_invop0 ...
epoch 2100  training loss: 0.12189880013465881
epoch 2100  clean testing loss: 0.02164127118885517
epoch 2200  training loss: 0.12133114784955978
epoch 2200  clean testing loss: 0.021221550181508064
epoch 2300  training loss: 0.12082598358392715
epoch 2300  clean testing loss: 0.021051229909062386
epoch 2400  training loss: 0.12032272666692734
epoch 2400  clean testing loss: 0.020523712038993835
epoch 2500  training loss: 0.11990204453468323

  3%|▎         | 3369/100000 [00:07<03:27, 465.06it/s]
epoch 2600  training loss: 0.1195596307516098
epoch 2600  clean testing loss: 0.01990133710205555
epoch 2700  training loss: 0.1192295104265213
epoch 2700  clean testing loss: 0.019650639966130257
epoch 2800  training loss: 0.11887066066265106
epoch 2800  clean testing loss: 0.01944771595299244
epoch 2900  training loss: 0.11864562332630157
epoch 2900  clean testing loss: 0.019232768565416336
epoch 3000  training loss: 0.11834191530942917
epoch 3000  clean testing loss: 0.01901905983686447
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size5000_noise1.00e-01_invop0 ...
epoch 3100  training loss: 0.11809071898460388
epoch 3100  clean testing loss: 0.018899083137512207
epoch 3200  training loss: 0.11788564175367355
epoch 3200  clean testing loss: 0.018744539469480515
epoch 3300  training loss: 0.11769081652164459
epoch 3300  clean testing loss: 0.018605399876832962
epoch 3400  training loss: 0.11751459538936615

  4%|▍         | 3890/100000 [00:08<03:26, 464.64it/s]
epoch 3500  training loss: 0.11735169589519501
epoch 3500  clean testing loss: 0.0183037631213665
epoch 3600  training loss: 0.11715981364250183
epoch 3600  clean testing loss: 0.018147200345993042
epoch 3700  training loss: 0.11692363023757935
epoch 3700  clean testing loss: 0.018079077824950218
epoch 3800  training loss: 0.1168089434504509
epoch 3800  clean testing loss: 0.0180912297219038
epoch 3900  training loss: 0.11664403975009918

  5%|▍         | 4785/100000 [00:13<03:31, 450.06it/s]
epoch 4000  training loss: 0.11649833619594574
epoch 4000  clean testing loss: 0.01772766187787056
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size5000_noise1.00e-01_invop0 ...
epoch 4100  training loss: 0.1163262203335762
epoch 4100  clean testing loss: 0.01769067905843258
epoch 4200  training loss: 0.11616465449333191
epoch 4200  clean testing loss: 0.017546271905303
epoch 4300  training loss: 0.11606205999851227
epoch 4300  clean testing loss: 0.017438754439353943
epoch 4400  training loss: 0.11590960621833801
epoch 4400  clean testing loss: 0.017382677644491196
epoch 4500  training loss: 0.11581684648990631
epoch 4500  clean testing loss: 0.01727249287068844
epoch 4600  training loss: 0.11569511145353317
epoch 4600  clean testing loss: 0.01719203218817711
epoch 4700  training loss: 0.1155533418059349
epoch 4700  clean testing loss: 0.017126692458987236
epoch 4800  training loss: 0.11550251394510269

  5%|▌         | 5396/100000 [00:14<03:23, 464.13it/s]
epoch 4900  training loss: 0.11539328098297119
epoch 4900  clean testing loss: 0.017185820266604424
epoch 5000  training loss: 0.11520668864250183
epoch 5000  clean testing loss: 0.016946369782090187
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size5000_noise1.00e-01_invop0 ...
epoch 5100  training loss: 0.11509821563959122
epoch 5100  clean testing loss: 0.01689024642109871
epoch 5200  training loss: 0.11500110477209091
epoch 5200  clean testing loss: 0.016757238656282425
epoch 5300  training loss: 0.11489120870828629
epoch 5300  clean testing loss: 0.016724230721592903
epoch 5400  training loss: 0.11480235308408737

  6%|▌         | 6200/100000 [00:16<04:12, 371.44it/s]
epoch 5500  training loss: 0.1147003173828125
epoch 5500  clean testing loss: 0.01661173440515995
epoch 5600  training loss: 0.11463536322116852
epoch 5600  clean testing loss: 0.01666542887687683
epoch 5700  training loss: 0.1145280972123146
epoch 5700  clean testing loss: 0.016531918197870255
epoch 5800  training loss: 0.11446844041347504
epoch 5800  clean testing loss: 0.016562044620513916
epoch 5900  training loss: 0.11438880115747452
epoch 5900  clean testing loss: 0.01639552041888237
epoch 6000  training loss: 0.11430596560239792
epoch 6000  clean testing loss: 0.016375258564949036
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size5000_noise1.00e-01_invop0 ...
epoch 6100  training loss: 0.11424428224563599
epoch 6100  clean testing loss: 0.01635381206870079
epoch 6200  training loss: 0.11418800055980682
epoch 6200  clean testing loss: 0.016319621354341507
Validation loss variation < 1e-6, trained to interpolation, stop
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_relu_size5000_noise1.00e-01_invop0 ...