
  0%|                                                                                                 | 0/100000 [00:00<?, ?it/s]
epoch 0  training loss: 0.6140468716621399
epoch 0  clean testing loss: 7.701396942138672
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 100  training loss: 0.15710017085075378
epoch 100  clean testing loss: 0.06183367222547531
epoch 200  training loss: 0.14207997918128967
epoch 200  clean testing loss: 0.036790892481803894
epoch 300  training loss: 0.122014619410038
epoch 300  clean testing loss: 0.038431573659181595
epoch 400  training loss: 0.14316235482692719
epoch 400  clean testing loss: 0.04251594841480255
epoch 500  training loss: 0.1329485923051834

  1%|▍                                                                                     | 532/100000 [00:03<05:10, 320.83it/s]
epoch 600  training loss: 0.19803772866725922
epoch 600  clean testing loss: 0.05715177580714226
epoch 700  training loss: 0.1809358298778534
epoch 700  clean testing loss: 0.05575839430093765
epoch 800  training loss: 0.11950656026601791
epoch 800  clean testing loss: 0.04262996464967728
epoch 900  training loss: 0.10933330655097961
epoch 900  clean testing loss: 0.03665287047624588
epoch 1000  training loss: 0.1105244979262352
epoch 1000  clean testing loss: 0.03645629435777664
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 1100  training loss: 0.15705759823322296

  1%|▉                                                                                    | 1164/100000 [00:05<05:29, 299.82it/s]
epoch 1200  training loss: 0.14095425605773926
epoch 1200  clean testing loss: 0.04492078721523285
epoch 1300  training loss: 0.12211205810308456
epoch 1300  clean testing loss: 0.049509044736623764
epoch 1400  training loss: 0.11347458511590958
epoch 1400  clean testing loss: 0.03688521683216095
epoch 1500  training loss: 0.10593065619468689
epoch 1500  clean testing loss: 0.03358620032668114
epoch 1600  training loss: 0.10735245794057846
epoch 1600  clean testing loss: 0.03255027160048485
epoch 1700  training loss: 0.14624392986297607
epoch 1700  clean testing loss: 0.06215986981987953
epoch 1800  training loss: 0.10748979449272156

  2%|█▌                                                                                   | 1793/100000 [00:07<05:00, 326.74it/s]
epoch 1900  training loss: 0.11646126210689545
epoch 1900  clean testing loss: 0.03893175348639488
epoch 2000  training loss: 0.11877309530973434
epoch 2000  clean testing loss: 0.034695204347372055
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 2100  training loss: 0.11202263087034225
epoch 2100  clean testing loss: 0.033794570714235306
epoch 2200  training loss: 0.15770100057125092
epoch 2200  clean testing loss: 0.060728318989276886
epoch 2300  training loss: 0.10119196772575378
epoch 2300  clean testing loss: 0.033497218042612076
epoch 2400  training loss: 0.12496426701545715


  3%|██▋                                                                                  | 3117/100000 [00:11<04:59, 323.73it/s]
epoch 2500  training loss: 0.11403436958789825
epoch 2500  clean testing loss: 0.03846946358680725
epoch 2600  training loss: 0.10715469717979431
epoch 2600  clean testing loss: 0.03799650818109512
epoch 2700  training loss: 0.1069694310426712
epoch 2700  clean testing loss: 0.036238886415958405
epoch 2800  training loss: 0.10385100543498993
epoch 2800  clean testing loss: 0.038974110037088394
epoch 2900  training loss: 0.10800232738256454
epoch 2900  clean testing loss: 0.045975688844919205
epoch 3000  training loss: 0.09946396201848984
epoch 3000  clean testing loss: 0.03682183101773262
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 3100  training loss: 0.09540938585996628

  4%|███▏                                                                                 | 3748/100000 [00:13<04:54, 326.67it/s]
epoch 3200  training loss: 0.09413724392652512
epoch 3200  clean testing loss: 0.03814456984400749
epoch 3300  training loss: 0.09896324574947357
epoch 3300  clean testing loss: 0.03981897979974747
epoch 3400  training loss: 0.09317953884601593
epoch 3400  clean testing loss: 0.035371843725442886
epoch 3500  training loss: 0.09236860275268555
epoch 3500  clean testing loss: 0.036554452031850815
epoch 3600  training loss: 0.09984882175922394
epoch 3600  clean testing loss: 0.04013960435986519
epoch 3700  training loss: 0.09813778847455978

  4%|███▊                                                                                 | 4414/100000 [00:15<04:52, 326.30it/s]
epoch 3800  training loss: 0.08795773983001709
epoch 3800  clean testing loss: 0.037401385605335236
epoch 3900  training loss: 0.08541551977396011
epoch 3900  clean testing loss: 0.037533193826675415
epoch 4000  training loss: 0.11439082026481628
epoch 4000  clean testing loss: 0.04245404899120331
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 4100  training loss: 0.0986088439822197
epoch 4100  clean testing loss: 0.0398348867893219
epoch 4200  training loss: 0.0940813198685646
epoch 4200  clean testing loss: 0.03831519931554794
epoch 4300  training loss: 0.09342765808105469
epoch 4300  clean testing loss: 0.03627472370862961
epoch 4400  training loss: 0.08688744902610779

  5%|████▎                                                                                | 5076/100000 [00:17<04:53, 323.40it/s]
epoch 4500  training loss: 0.09518256783485413
epoch 4500  clean testing loss: 0.04845299944281578
epoch 4600  training loss: 0.0882217139005661
epoch 4600  clean testing loss: 0.03972369804978371
epoch 4700  training loss: 0.08772049844264984
epoch 4700  clean testing loss: 0.040959347039461136
epoch 4800  training loss: 0.08190692216157913
epoch 4800  clean testing loss: 0.040034219622612
epoch 4900  training loss: 0.08118472993373871
epoch 4900  clean testing loss: 0.03877269849181175
epoch 5000  training loss: 0.08593982458114624
epoch 5000  clean testing loss: 0.03666061908006668

  6%|████▊                                                                                | 5706/100000 [00:19<04:49, 325.88it/s]
epoch 5100  training loss: 0.08603131771087646
epoch 5100  clean testing loss: 0.036560844630002975
epoch 5200  training loss: 0.08469697833061218
epoch 5200  clean testing loss: 0.04164096713066101
epoch 5300  training loss: 0.08227116614580154
epoch 5300  clean testing loss: 0.037471070885658264
epoch 5400  training loss: 0.09612944722175598
epoch 5400  clean testing loss: 0.055536799132823944
epoch 5500  training loss: 0.07905364036560059
epoch 5500  clean testing loss: 0.037878602743148804
epoch 5600  training loss: 0.0911928191781044
epoch 5600  clean testing loss: 0.04583491384983063
epoch 5700  training loss: 0.07802986353635788

  6%|█████▍                                                                               | 6370/100000 [00:21<04:45, 328.38it/s]
epoch 5800  training loss: 0.07914545387029648
epoch 5800  clean testing loss: 0.04180969297885895
epoch 5900  training loss: 0.09269846230745316
epoch 5900  clean testing loss: 0.047405634075403214
epoch 6000  training loss: 0.07972092181444168
epoch 6000  clean testing loss: 0.04063614085316658
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 6100  training loss: 0.07590717077255249
epoch 6100  clean testing loss: 0.04133191332221031
epoch 6200  training loss: 0.12331505864858627
epoch 6200  clean testing loss: 0.05272713303565979
epoch 6300  training loss: 0.07951527833938599

  7%|█████▉                                                                               | 7035/100000 [00:23<04:47, 323.55it/s]
epoch 6400  training loss: 0.07923277467489243
epoch 6400  clean testing loss: 0.0424497127532959
epoch 6500  training loss: 0.08896046876907349
epoch 6500  clean testing loss: 0.04068891331553459
epoch 6600  training loss: 0.074855275452137
epoch 6600  clean testing loss: 0.04183617979288101
epoch 6700  training loss: 0.07383609563112259
epoch 6700  clean testing loss: 0.04391949251294136
epoch 6800  training loss: 0.1255025714635849
epoch 6800  clean testing loss: 0.06272793561220169
epoch 6900  training loss: 0.09466875344514847
epoch 6900  clean testing loss: 0.045436084270477295
epoch 7000  training loss: 0.08309376984834671
epoch 7000  clean testing loss: 0.04532447084784508

  8%|██████▌                                                                              | 7666/100000 [00:25<04:43, 325.34it/s]
epoch 7100  training loss: 0.07687059044837952
epoch 7100  clean testing loss: 0.044482141733169556
epoch 7200  training loss: 0.08156825602054596
epoch 7200  clean testing loss: 0.04363596439361572
epoch 7300  training loss: 0.07404246926307678
epoch 7300  clean testing loss: 0.04446739703416824
epoch 7400  training loss: 0.07419761270284653
epoch 7400  clean testing loss: 0.04488007724285126
epoch 7500  training loss: 0.07306888699531555
epoch 7500  clean testing loss: 0.04573903977870941
epoch 7600  training loss: 0.08005709201097488

  8%|███████                                                                              | 8333/100000 [00:27<04:41, 325.92it/s]
epoch 7700  training loss: 0.07215219736099243
epoch 7700  clean testing loss: 0.045806244015693665
epoch 7800  training loss: 0.07192500680685043
epoch 7800  clean testing loss: 0.04587661847472191
epoch 7900  training loss: 0.07051527500152588
epoch 7900  clean testing loss: 0.04588485509157181
epoch 8000  training loss: 0.08634678274393082
epoch 8000  clean testing loss: 0.0535915233194828
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 8100  training loss: 0.07345233112573624
epoch 8100  clean testing loss: 0.04779151454567909
epoch 8200  training loss: 0.07026895135641098
epoch 8200  clean testing loss: 0.04645136743783951
epoch 8300  training loss: 0.07071565091609955

  9%|███████▋                                                                             | 8995/100000 [00:29<04:37, 327.84it/s]
epoch 8400  training loss: 0.07180681079626083
epoch 8400  clean testing loss: 0.05210462585091591
epoch 8500  training loss: 0.06802873313426971
epoch 8500  clean testing loss: 0.047447096556425095
epoch 8600  training loss: 0.074196957051754
epoch 8600  clean testing loss: 0.04711385443806648
epoch 8700  training loss: 0.07452809065580368
epoch 8700  clean testing loss: 0.047395020723342896
epoch 8800  training loss: 0.0673048123717308
epoch 8800  clean testing loss: 0.047933924943208694
epoch 8900  training loss: 0.06910094618797302
epoch 8900  clean testing loss: 0.05066230893135071
epoch 9000  training loss: 0.07844734936952591
epoch 9000  clean testing loss: 0.04918534308671951

 10%|████████▏                                                                            | 9626/100000 [00:31<04:35, 327.50it/s]
epoch 9100  training loss: 0.06664624810218811
epoch 9100  clean testing loss: 0.049242984503507614
epoch 9200  training loss: 0.06612401455640793
epoch 9200  clean testing loss: 0.050497859716415405
epoch 9300  training loss: 0.06580822914838791
epoch 9300  clean testing loss: 0.05193847417831421
epoch 9400  training loss: 0.0680289939045906
epoch 9400  clean testing loss: 0.05012555420398712
epoch 9500  training loss: 0.06476522237062454
epoch 9500  clean testing loss: 0.05068926513195038
epoch 9600  training loss: 0.06650175899267197

 10%|████████▋                                                                           | 10290/100000 [00:33<04:33, 328.02it/s]
epoch 9700  training loss: 0.06427856534719467
epoch 9700  clean testing loss: 0.0533740259706974
epoch 9800  training loss: 0.06513702124357224
epoch 9800  clean testing loss: 0.05399041250348091
epoch 9900  training loss: 0.06483728438615799
epoch 9900  clean testing loss: 0.057165760546922684
epoch 10000  training loss: 0.06718020141124725
epoch 10000  clean testing loss: 0.055001385509967804
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 10100  training loss: 0.06312071532011032
epoch 10100  clean testing loss: 0.0527164526283741
epoch 10200  training loss: 0.07715151458978653
epoch 10200  clean testing loss: 0.05626456066966057
epoch 10300  training loss: 0.06546881049871445

 11%|█████████▏                                                                          | 10951/100000 [00:35<04:33, 326.02it/s]
epoch 10400  training loss: 0.075980044901371
epoch 10400  clean testing loss: 0.05357091501355171
epoch 10500  training loss: 0.06983400881290436
epoch 10500  clean testing loss: 0.05330188572406769
epoch 10600  training loss: 0.06162499263882637
epoch 10600  clean testing loss: 0.05382038652896881
epoch 10700  training loss: 0.06852898001670837
epoch 10700  clean testing loss: 0.05480392277240753
epoch 10800  training loss: 0.06147686019539833
epoch 10800  clean testing loss: 0.05482379347085953
epoch 10900  training loss: 0.06115750968456268

 12%|█████████▊                                                                          | 11614/100000 [00:37<04:31, 325.03it/s]
epoch 11000  training loss: 0.06117763742804527
epoch 11000  clean testing loss: 0.05727410316467285
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 11100  training loss: 0.06055242568254471
epoch 11100  clean testing loss: 0.05584477260708809
epoch 11200  training loss: 0.06005752086639404
epoch 11200  clean testing loss: 0.05522691458463669
epoch 11300  training loss: 0.0705280676484108
epoch 11300  clean testing loss: 0.06301870942115784
epoch 11400  training loss: 0.05969490855932236
epoch 11400  clean testing loss: 0.057367704808712006
epoch 11500  training loss: 0.0617322213947773
epoch 11500  clean testing loss: 0.05719076842069626
epoch 11600  training loss: 0.060346804559230804

 12%|██████████▎                                                                         | 12245/100000 [00:39<04:26, 329.08it/s]
epoch 11700  training loss: 0.06605296581983566
epoch 11700  clean testing loss: 0.05665815249085426
epoch 11800  training loss: 0.06314998120069504
epoch 11800  clean testing loss: 0.05901448056101799
epoch 11900  training loss: 0.057902101427316666
epoch 11900  clean testing loss: 0.062228668481111526
epoch 12000  training loss: 0.059473104774951935
epoch 12000  clean testing loss: 0.059251055121421814
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 12100  training loss: 0.057097017765045166
epoch 12100  clean testing loss: 0.0590561144053936
epoch 12200  training loss: 0.056628238409757614

 13%|██████████▊                                                                         | 12908/100000 [00:41<04:26, 326.96it/s]
epoch 12300  training loss: 0.05654516816139221
epoch 12300  clean testing loss: 0.06089396774768829
epoch 12400  training loss: 0.05609076842665672
epoch 12400  clean testing loss: 0.06127770617604256
epoch 12500  training loss: 0.05755778029561043
epoch 12500  clean testing loss: 0.060661569237709045
epoch 12600  training loss: 0.057101089507341385
epoch 12600  clean testing loss: 0.06315291672945023
epoch 12700  training loss: 0.05510534718632698
epoch 12700  clean testing loss: 0.062174975872039795
epoch 12800  training loss: 0.055766940116882324
epoch 12800  clean testing loss: 0.06294946372509003
epoch 12900  training loss: 0.05684182420372963

 14%|███████████▍                                                                        | 13571/100000 [00:43<04:25, 325.15it/s]
epoch 13000  training loss: 0.054366447031497955
epoch 13000  clean testing loss: 0.06346157938241959
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 13100  training loss: 0.05360228195786476
epoch 13100  clean testing loss: 0.06471610069274902
epoch 13200  training loss: 0.06291966885328293
epoch 13200  clean testing loss: 0.06747494637966156
epoch 13300  training loss: 0.05350834131240845
epoch 13300  clean testing loss: 0.06688925623893738
epoch 13400  training loss: 0.05757012963294983
epoch 13400  clean testing loss: 0.0636821910738945
epoch 13500  training loss: 0.05942827835679054

 14%|███████████▉                                                                        | 14200/100000 [00:45<04:21, 327.98it/s]
epoch 13600  training loss: 0.053329966962337494
epoch 13600  clean testing loss: 0.06543520838022232
epoch 13700  training loss: 0.0529523640871048
epoch 13700  clean testing loss: 0.06567994505167007
epoch 13800  training loss: 0.055342838168144226
epoch 13800  clean testing loss: 0.06431473046541214
epoch 13900  training loss: 0.052135348320007324
epoch 13900  clean testing loss: 0.06686139851808548
epoch 14000  training loss: 0.05193975195288658
epoch 14000  clean testing loss: 0.0682448297739029
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 14100  training loss: 0.05588070675730705
epoch 14100  clean testing loss: 0.06978601217269897
epoch 14200  training loss: 0.05286465212702751

 15%|████████████▍                                                                       | 14864/100000 [00:47<04:20, 327.23it/s]
epoch 14300  training loss: 0.05195363983511925
epoch 14300  clean testing loss: 0.06774134933948517
epoch 14400  training loss: 0.05137353762984276
epoch 14400  clean testing loss: 0.06733258068561554
epoch 14500  training loss: 0.05515490472316742
epoch 14500  clean testing loss: 0.07298202812671661
epoch 14600  training loss: 0.05203762650489807
epoch 14600  clean testing loss: 0.06836161762475967
epoch 14700  training loss: 0.05148531496524811
epoch 14700  clean testing loss: 0.07079868018627167
epoch 14800  training loss: 0.05137275531888008

 16%|█████████████                                                                       | 15527/100000 [00:49<04:18, 326.53it/s]
epoch 14900  training loss: 0.05049629509449005
epoch 14900  clean testing loss: 0.0691266804933548
epoch 15000  training loss: 0.054927606135606766
epoch 15000  clean testing loss: 0.06843885034322739
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 15100  training loss: 0.049998193979263306
epoch 15100  clean testing loss: 0.06938638538122177
epoch 15200  training loss: 0.04984439164400101
epoch 15200  clean testing loss: 0.06978809088468552
epoch 15300  training loss: 0.049901656806468964
epoch 15300  clean testing loss: 0.0700288712978363
epoch 15400  training loss: 0.04990188777446747
epoch 15400  clean testing loss: 0.07099605351686478
epoch 15500  training loss: 0.049375858157873154

 16%|█████████████▌                                                                      | 16159/100000 [00:51<04:15, 328.11it/s]
epoch 15600  training loss: 0.04889697581529617
epoch 15600  clean testing loss: 0.07101822644472122
epoch 15700  training loss: 0.050288502126932144
epoch 15700  clean testing loss: 0.0711076632142067
epoch 15800  training loss: 0.056158702820539474
epoch 15800  clean testing loss: 0.07231983542442322
epoch 15900  training loss: 0.05194060131907463
epoch 15900  clean testing loss: 0.0735875815153122
epoch 16000  training loss: 0.048516999930143356
epoch 16000  clean testing loss: 0.07269992679357529
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 16100  training loss: 0.04923466965556145

 17%|██████████████▏                                                                     | 16823/100000 [00:53<04:14, 326.29it/s]
epoch 16200  training loss: 0.05239003151655197
epoch 16200  clean testing loss: 0.07271803915500641
epoch 16300  training loss: 0.048051267862319946
epoch 16300  clean testing loss: 0.07268209755420685
epoch 16400  training loss: 0.04804479330778122
epoch 16400  clean testing loss: 0.07440442591905594
epoch 16500  training loss: 0.05454244464635849
epoch 16500  clean testing loss: 0.08658768236637115
epoch 16600  training loss: 0.047895144671201706
epoch 16600  clean testing loss: 0.07387552410364151
epoch 16700  training loss: 0.047649942338466644
epoch 16700  clean testing loss: 0.07473164796829224
epoch 16800  training loss: 0.04891853407025337

 17%|██████████████▋                                                                     | 17489/100000 [00:55<04:13, 326.12it/s]
epoch 16900  training loss: 0.047537196427583694
epoch 16900  clean testing loss: 0.07510081678628922
epoch 17000  training loss: 0.048363786190748215
epoch 17000  clean testing loss: 0.07407521456480026
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 17100  training loss: 0.04973021149635315
epoch 17100  clean testing loss: 0.0758170485496521
epoch 17200  training loss: 0.04853127896785736
epoch 17200  clean testing loss: 0.07359758019447327
epoch 17300  training loss: 0.047098927199840546
epoch 17300  clean testing loss: 0.07540635019540787
epoch 17400  training loss: 0.04797055199742317

 18%|███████████████▏                                                                    | 18119/100000 [00:57<04:13, 323.51it/s]
epoch 17500  training loss: 0.04706255719065666
epoch 17500  clean testing loss: 0.07538406550884247
epoch 17600  training loss: 0.04781530052423477
epoch 17600  clean testing loss: 0.07819490134716034
epoch 17700  training loss: 0.04697088897228241
epoch 17700  clean testing loss: 0.07515822350978851
epoch 17800  training loss: 0.04774892330169678
epoch 17800  clean testing loss: 0.07550898939371109
epoch 17900  training loss: 0.046381961554288864
epoch 17900  clean testing loss: 0.07658818364143372
epoch 18000  training loss: 0.04611138999462128
epoch 18000  clean testing loss: 0.07630159705877304
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 18100  training loss: 0.04585391283035278

 19%|███████████████▊                                                                    | 18780/100000 [00:59<04:08, 326.34it/s]
epoch 18200  training loss: 0.04556087777018547
epoch 18200  clean testing loss: 0.07683435082435608
epoch 18300  training loss: 0.04540982097387314
epoch 18300  clean testing loss: 0.07746008783578873
epoch 18400  training loss: 0.04522717371582985
epoch 18400  clean testing loss: 0.07808288931846619
epoch 18500  training loss: 0.04559633880853653
epoch 18500  clean testing loss: 0.07957253605127335
epoch 18600  training loss: 0.0464806891977787
epoch 18600  clean testing loss: 0.07861710339784622
epoch 18700  training loss: 0.04488151893019676

 19%|████████████████▎                                                                   | 19443/100000 [01:01<04:06, 327.19it/s]
epoch 18800  training loss: 0.04516169801354408
epoch 18800  clean testing loss: 0.08061949908733368
epoch 18900  training loss: 0.04488159343600273
epoch 18900  clean testing loss: 0.07943832129240036
epoch 19000  training loss: 0.04462326690554619
epoch 19000  clean testing loss: 0.07994738966226578
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 19100  training loss: 0.046309348195791245
epoch 19100  clean testing loss: 0.08406893163919449
epoch 19200  training loss: 0.04541783034801483
epoch 19200  clean testing loss: 0.08060851693153381
epoch 19300  training loss: 0.04427911713719368
epoch 19300  clean testing loss: 0.07989586889743805
epoch 19400  training loss: 0.044484492391347885

 20%|████████████████▊                                                                   | 20073/100000 [01:03<04:06, 324.71it/s]
epoch 19500  training loss: 0.04664735496044159
epoch 19500  clean testing loss: 0.07960598915815353
epoch 19600  training loss: 0.04401804879307747
epoch 19600  clean testing loss: 0.08015163242816925
epoch 19700  training loss: 0.044813983142375946
epoch 19700  clean testing loss: 0.08152461796998978
epoch 19800  training loss: 0.04397576302289963
epoch 19800  clean testing loss: 0.08171966671943665
epoch 19900  training loss: 0.04409100487828255
epoch 19900  clean testing loss: 0.08156763762235641
epoch 20000  training loss: 0.04373688995838165
epoch 20000  clean testing loss: 0.08087373524904251

 21%|█████████████████▍                                                                  | 20735/100000 [01:05<04:03, 325.63it/s]
epoch 20100  training loss: 0.04395222291350365
epoch 20100  clean testing loss: 0.08196103572845459
epoch 20200  training loss: 0.045092638581991196
epoch 20200  clean testing loss: 0.08461691439151764
epoch 20300  training loss: 0.04371580109000206
epoch 20300  clean testing loss: 0.0819990411400795
epoch 20400  training loss: 0.04341113567352295
epoch 20400  clean testing loss: 0.08188610523939133
epoch 20500  training loss: 0.04382440447807312
epoch 20500  clean testing loss: 0.08339890092611313
epoch 20600  training loss: 0.043089210987091064
epoch 20600  clean testing loss: 0.082978755235672
epoch 20700  training loss: 0.04325195401906967

 21%|█████████████████▉                                                                  | 21402/100000 [01:07<03:59, 327.50it/s]
epoch 20800  training loss: 0.04490837827324867
epoch 20800  clean testing loss: 0.08653136342763901
epoch 20900  training loss: 0.046625230461359024
epoch 20900  clean testing loss: 0.08876792341470718
epoch 21000  training loss: 0.043113917112350464
epoch 21000  clean testing loss: 0.08275200426578522
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 21100  training loss: 0.04273594915866852
epoch 21100  clean testing loss: 0.08426153659820557
epoch 21200  training loss: 0.04260991886258125
epoch 21200  clean testing loss: 0.08425218611955643
epoch 21300  training loss: 0.042509716004133224

 22%|██████████████████▌                                                                 | 22034/100000 [01:09<04:01, 322.73it/s]
epoch 21400  training loss: 0.042671140283346176
epoch 21400  clean testing loss: 0.08522669225931168
epoch 21500  training loss: 0.04256271943449974
epoch 21500  clean testing loss: 0.08511174470186234
epoch 21600  training loss: 0.042349159717559814
epoch 21600  clean testing loss: 0.08564043790102005
epoch 21700  training loss: 0.04224057123064995
epoch 21700  clean testing loss: 0.08606687933206558
epoch 21800  training loss: 0.04279403015971184
epoch 21800  clean testing loss: 0.0858277976512909
epoch 21900  training loss: 0.04236312583088875
epoch 21900  clean testing loss: 0.0851885974407196
epoch 22000  training loss: 0.04195227846503258
epoch 22000  clean testing loss: 0.08609373867511749

 23%|███████████████████                                                                 | 22699/100000 [01:11<03:57, 326.02it/s]
epoch 22100  training loss: 0.04228910431265831
epoch 22100  clean testing loss: 0.08618710935115814
epoch 22200  training loss: 0.04305202141404152
epoch 22200  clean testing loss: 0.08815048635005951
epoch 22300  training loss: 0.04183126986026764
epoch 22300  clean testing loss: 0.0880274847149849
epoch 22400  training loss: 0.04207676276564598
epoch 22400  clean testing loss: 0.08748108893632889
epoch 22500  training loss: 0.04197605699300766
epoch 22500  clean testing loss: 0.0867040678858757
epoch 22600  training loss: 0.04288169741630554

 23%|███████████████████▌                                                                | 23359/100000 [01:13<03:55, 326.07it/s]
epoch 22700  training loss: 0.04150862246751785
epoch 22700  clean testing loss: 0.08688601851463318
epoch 22800  training loss: 0.04186555743217468
epoch 22800  clean testing loss: 0.08783596009016037
epoch 22900  training loss: 0.04151775687932968
epoch 22900  clean testing loss: 0.08791026473045349
epoch 23000  training loss: 0.041835710406303406
epoch 23000  clean testing loss: 0.08967115730047226
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 23100  training loss: 0.04189346358180046
epoch 23100  clean testing loss: 0.08777589350938797
epoch 23200  training loss: 0.04340890049934387
epoch 23200  clean testing loss: 0.09255536645650864
epoch 23300  training loss: 0.04157918691635132

 24%|████████████████████▏                                                               | 24021/100000 [01:16<03:55, 322.23it/s]
epoch 23400  training loss: 0.04134709760546684
epoch 23400  clean testing loss: 0.08952272683382034
epoch 23500  training loss: 0.041286151856184006
epoch 23500  clean testing loss: 0.08889143913984299
epoch 23600  training loss: 0.041183847934007645
epoch 23600  clean testing loss: 0.08800957351922989
epoch 23700  training loss: 0.04165634512901306
epoch 23700  clean testing loss: 0.08907504379749298
epoch 23800  training loss: 0.04095609486103058
epoch 23800  clean testing loss: 0.0890343189239502
epoch 23900  training loss: 0.040939636528491974

 25%|████████████████████▋                                                               | 24652/100000 [01:17<03:48, 329.03it/s]
epoch 24000  training loss: 0.04145872965455055
epoch 24000  clean testing loss: 0.08874019980430603
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 24100  training loss: 0.04075777903199196
epoch 24100  clean testing loss: 0.08944743126630783
epoch 24200  training loss: 0.040658656507730484
epoch 24200  clean testing loss: 0.0898999571800232
epoch 24300  training loss: 0.0408167727291584
epoch 24300  clean testing loss: 0.09012357890605927
epoch 24400  training loss: 0.04041863605380058
epoch 24400  clean testing loss: 0.08960097283124924
epoch 24500  training loss: 0.04041852429509163
epoch 24500  clean testing loss: 0.0898076519370079
epoch 24600  training loss: 0.040710367262363434

 25%|█████████████████████▎                                                              | 25317/100000 [01:20<03:48, 326.26it/s]
epoch 24700  training loss: 0.04040229320526123
epoch 24700  clean testing loss: 0.09099643677473068
epoch 24800  training loss: 0.04024079442024231
epoch 24800  clean testing loss: 0.09116865694522858
epoch 24900  training loss: 0.04053279384970665
epoch 24900  clean testing loss: 0.09213338792324066
epoch 25000  training loss: 0.04015084728598595
epoch 25000  clean testing loss: 0.09183336049318314
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 25100  training loss: 0.04112625494599342
epoch 25100  clean testing loss: 0.09108947962522507
epoch 25200  training loss: 0.04059940204024315
epoch 25200  clean testing loss: 0.09201973676681519
epoch 25300  training loss: 0.043629758059978485

 26%|█████████████████████▊                                                              | 25980/100000 [01:22<03:47, 325.63it/s]
epoch 25400  training loss: 0.04018682241439819
epoch 25400  clean testing loss: 0.0920867845416069
epoch 25500  training loss: 0.03986480087041855
epoch 25500  clean testing loss: 0.0929894745349884
epoch 25600  training loss: 0.03989066556096077
epoch 25600  clean testing loss: 0.09224523603916168
epoch 25700  training loss: 0.03981059417128563
epoch 25700  clean testing loss: 0.09259478002786636
epoch 25800  training loss: 0.03981933370232582
epoch 25800  clean testing loss: 0.09459343552589417
epoch 25900  training loss: 0.0404646098613739

 27%|██████████████████████▍                                                             | 26643/100000 [01:24<03:44, 327.16it/s]
epoch 26000  training loss: 0.03968567028641701
epoch 26000  clean testing loss: 0.09371227025985718
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 26100  training loss: 0.04018183425068855
epoch 26100  clean testing loss: 0.0940735787153244
epoch 26200  training loss: 0.04015318304300308
epoch 26200  clean testing loss: 0.09455409646034241
epoch 26300  training loss: 0.04055217280983925
epoch 26300  clean testing loss: 0.09427684545516968
epoch 26400  training loss: 0.04049115628004074
epoch 26400  clean testing loss: 0.09587163478136063
epoch 26500  training loss: 0.03960270807147026
epoch 26500  clean testing loss: 0.09484496712684631
epoch 26600  training loss: 0.039321109652519226

 27%|██████████████████████▉                                                             | 27272/100000 [01:26<03:42, 326.74it/s]
epoch 26700  training loss: 0.039836395531892776
epoch 26700  clean testing loss: 0.09524530917406082
epoch 26800  training loss: 0.03905192017555237
epoch 26800  clean testing loss: 0.0951666384935379
epoch 26900  training loss: 0.03909619152545929
epoch 26900  clean testing loss: 0.09466762840747833
epoch 27000  training loss: 0.03881156072020531
epoch 27000  clean testing loss: 0.09523684531450272
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 27100  training loss: 0.03878013789653778
epoch 27100  clean testing loss: 0.09543837606906891
epoch 27200  training loss: 0.03867143765091896

 28%|███████████████████████▍                                                            | 27935/100000 [01:28<03:38, 329.32it/s]
epoch 27300  training loss: 0.038599446415901184
epoch 27300  clean testing loss: 0.09705808758735657
epoch 27400  training loss: 0.038499727845191956
epoch 27400  clean testing loss: 0.09736363589763641
epoch 27500  training loss: 0.0385575108230114
epoch 27500  clean testing loss: 0.09692033380270004
epoch 27600  training loss: 0.03844096139073372
epoch 27600  clean testing loss: 0.0978861078619957
epoch 27700  training loss: 0.038527507334947586
epoch 27700  clean testing loss: 0.09675178676843643
epoch 27800  training loss: 0.038730137050151825
epoch 27800  clean testing loss: 0.09788942337036133
epoch 27900  training loss: 0.03831316530704498

 29%|███████████████████████▉                                                            | 28565/100000 [01:30<03:38, 326.53it/s]
epoch 28000  training loss: 0.03962096571922302
epoch 28000  clean testing loss: 0.10079767554998398
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 28100  training loss: 0.03818821161985397
epoch 28100  clean testing loss: 0.09847982227802277
epoch 28200  training loss: 0.03845660760998726
epoch 28200  clean testing loss: 0.09831821173429489
epoch 28300  training loss: 0.03796989843249321
epoch 28300  clean testing loss: 0.09887494146823883
epoch 28400  training loss: 0.038193583488464355
epoch 28400  clean testing loss: 0.10006009042263031
epoch 28500  training loss: 0.03785630315542221

 29%|████████████████████████▌                                                           | 29227/100000 [01:32<03:37, 325.53it/s]
epoch 28600  training loss: 0.03786195442080498
epoch 28600  clean testing loss: 0.10012830048799515
epoch 28700  training loss: 0.03767826035618782
epoch 28700  clean testing loss: 0.09981478750705719
epoch 28800  training loss: 0.037821006029844284
epoch 28800  clean testing loss: 0.09988983720541
epoch 28900  training loss: 0.03781627118587494
epoch 28900  clean testing loss: 0.09994670003652573
epoch 29000  training loss: 0.0395655520260334
epoch 29000  clean testing loss: 0.10120011121034622
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 29100  training loss: 0.03759538382291794
epoch 29100  clean testing loss: 0.1004277765750885
epoch 29200  training loss: 0.03789789229631424

 30%|█████████████████████████                                                           | 29891/100000 [01:34<03:33, 328.34it/s]
epoch 29300  training loss: 0.03767913579940796
epoch 29300  clean testing loss: 0.1006869524717331
epoch 29400  training loss: 0.03743690624833107
epoch 29400  clean testing loss: 0.10117384046316147
epoch 29500  training loss: 0.03764908388257027
epoch 29500  clean testing loss: 0.10124797374010086
epoch 29600  training loss: 0.03771645575761795
epoch 29600  clean testing loss: 0.10160961747169495
epoch 29700  training loss: 0.03753937780857086
epoch 29700  clean testing loss: 0.10156320035457611
epoch 29800  training loss: 0.037450775504112244

 31%|█████████████████████████▋                                                          | 30523/100000 [01:36<03:32, 326.58it/s]
epoch 29900  training loss: 0.037378840148448944
epoch 29900  clean testing loss: 0.1020609512925148
epoch 30000  training loss: 0.037299271672964096
epoch 30000  clean testing loss: 0.10241083055734634
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 30100  training loss: 0.03723660483956337
epoch 30100  clean testing loss: 0.10263478755950928
epoch 30200  training loss: 0.037017688155174255
epoch 30200  clean testing loss: 0.10236658155918121
epoch 30300  training loss: 0.037115395069122314
epoch 30300  clean testing loss: 0.10252508521080017
epoch 30400  training loss: 0.03697817400097847
epoch 30400  clean testing loss: 0.10329445451498032
epoch 30500  training loss: 0.036916375160217285

 31%|██████████████████████████▏                                                         | 31185/100000 [01:38<03:31, 325.33it/s]
epoch 30600  training loss: 0.03691547363996506
epoch 30600  clean testing loss: 0.10364662855863571
epoch 30700  training loss: 0.036918945610523224
epoch 30700  clean testing loss: 0.10349830985069275
epoch 30800  training loss: 0.03808528557419777
epoch 30800  clean testing loss: 0.10423307120800018
epoch 30900  training loss: 0.0368540994822979
epoch 30900  clean testing loss: 0.10394324362277985
epoch 31000  training loss: 0.03705005347728729
epoch 31000  clean testing loss: 0.10421133041381836
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 31100  training loss: 0.03665308281779289

 32%|██████████████████████████▊                                                         | 31850/100000 [01:40<03:27, 328.70it/s]
epoch 31200  training loss: 0.036672838032245636
epoch 31200  clean testing loss: 0.10368071496486664
epoch 31300  training loss: 0.0368255078792572
epoch 31300  clean testing loss: 0.10403808206319809
epoch 31400  training loss: 0.03658203408122063
epoch 31400  clean testing loss: 0.10404551029205322
epoch 31500  training loss: 0.036646150052547455
epoch 31500  clean testing loss: 0.10437682271003723
epoch 31600  training loss: 0.03656774386763573
epoch 31600  clean testing loss: 0.1045878678560257
epoch 31700  training loss: 0.037837639451026917
epoch 31700  clean testing loss: 0.10505916178226471
epoch 31800  training loss: 0.03655970096588135

 32%|███████████████████████████▎                                                        | 32479/100000 [01:42<03:27, 324.96it/s]
epoch 31900  training loss: 0.03640679270029068
epoch 31900  clean testing loss: 0.10495824366807938
epoch 32000  training loss: 0.03660055994987488
epoch 32000  clean testing loss: 0.10525273531675339
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 32100  training loss: 0.03639591485261917
epoch 32100  clean testing loss: 0.1050311028957367
epoch 32200  training loss: 0.03666166961193085
epoch 32200  clean testing loss: 0.10519194602966309
epoch 32300  training loss: 0.03658794239163399
epoch 32300  clean testing loss: 0.10558151453733444
epoch 32400  training loss: 0.036775004118680954

 33%|███████████████████████████▊                                                        | 33143/100000 [01:44<03:24, 326.51it/s]
epoch 32500  training loss: 0.03652012720704079
epoch 32500  clean testing loss: 0.10497914254665375
epoch 32600  training loss: 0.03626560419797897
epoch 32600  clean testing loss: 0.1067088395357132
epoch 32700  training loss: 0.036316871643066406
epoch 32700  clean testing loss: 0.10534545034170151
epoch 32800  training loss: 0.037837155163288116
epoch 32800  clean testing loss: 0.10583703219890594
epoch 32900  training loss: 0.036169495433568954
epoch 32900  clean testing loss: 0.10632730275392532
epoch 33000  training loss: 0.036416638642549515
epoch 33000  clean testing loss: 0.10559441894292831
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 33100  training loss: 0.036083824932575226

 34%|████████████████████████████▍                                                       | 33808/100000 [01:46<03:22, 327.19it/s]
epoch 33200  training loss: 0.03595661744475365
epoch 33200  clean testing loss: 0.106326162815094
epoch 33300  training loss: 0.035985857248306274
epoch 33300  clean testing loss: 0.10655320435762405
epoch 33400  training loss: 0.035983096808195114
epoch 33400  clean testing loss: 0.1060662567615509
epoch 33500  training loss: 0.03591132164001465
epoch 33500  clean testing loss: 0.10613556206226349
epoch 33600  training loss: 0.03591228649020195
epoch 33600  clean testing loss: 0.10699833929538727
epoch 33700  training loss: 0.03590962290763855

 34%|████████████████████████████▉                                                       | 34437/100000 [01:48<03:20, 327.24it/s]
epoch 33800  training loss: 0.03637133911252022
epoch 33800  clean testing loss: 0.10770637542009354
epoch 33900  training loss: 0.03588547930121422
epoch 33900  clean testing loss: 0.10669194906949997
epoch 34000  training loss: 0.03591781482100487
epoch 34000  clean testing loss: 0.10702099651098251
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 34100  training loss: 0.03601162135601044
epoch 34100  clean testing loss: 0.10653509199619293
epoch 34200  training loss: 0.03569311276078224
epoch 34200  clean testing loss: 0.10703548043966293
epoch 34300  training loss: 0.035713713616132736
epoch 34300  clean testing loss: 0.1072012260556221
epoch 34400  training loss: 0.03594740480184555

 35%|█████████████████████████████▍                                                      | 35100/100000 [01:50<03:19, 325.57it/s]
epoch 34500  training loss: 0.03577491268515587
epoch 34500  clean testing loss: 0.10739551484584808
epoch 34600  training loss: 0.03562663868069649
epoch 34600  clean testing loss: 0.10749397426843643
epoch 34700  training loss: 0.03558560088276863
epoch 34700  clean testing loss: 0.10759446024894714
epoch 34800  training loss: 0.03566945716738701
epoch 34800  clean testing loss: 0.10797728598117828
epoch 34900  training loss: 0.03555406630039215
epoch 34900  clean testing loss: 0.10753723978996277
epoch 35000  training loss: 0.03554518148303032
epoch 35000  clean testing loss: 0.10751219838857651

 36%|██████████████████████████████                                                      | 35763/100000 [01:52<03:15, 328.15it/s]
epoch 35100  training loss: 0.0363280288875103
epoch 35100  clean testing loss: 0.10828404873609543
epoch 35200  training loss: 0.03548700734972954
epoch 35200  clean testing loss: 0.10825683921575546
epoch 35300  training loss: 0.03588986396789551
epoch 35300  clean testing loss: 0.10849229991436005
epoch 35400  training loss: 0.03543950617313385
epoch 35400  clean testing loss: 0.10776185244321823
epoch 35500  training loss: 0.03586798161268234
epoch 35500  clean testing loss: 0.10836254805326462
epoch 35600  training loss: 0.03547396510839462
epoch 35600  clean testing loss: 0.10853155702352524
epoch 35700  training loss: 0.03534114360809326

 36%|██████████████████████████████▌                                                     | 36427/100000 [01:54<03:14, 327.02it/s]
epoch 35800  training loss: 0.035367969423532486
epoch 35800  clean testing loss: 0.10832521319389343
epoch 35900  training loss: 0.03549933061003685
epoch 35900  clean testing loss: 0.10832703113555908
epoch 36000  training loss: 0.035407718271017075
epoch 36000  clean testing loss: 0.10913344472646713
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 36100  training loss: 0.03536039963364601
epoch 36100  clean testing loss: 0.10906187444925308
epoch 36200  training loss: 0.03526827320456505
epoch 36200  clean testing loss: 0.10879175364971161
epoch 36300  training loss: 0.03516510874032974

 37%|███████████████████████████████▏                                                    | 37059/100000 [01:56<03:13, 325.68it/s]
epoch 36400  training loss: 0.0351216197013855
epoch 36400  clean testing loss: 0.1090279147028923
epoch 36500  training loss: 0.03552583232522011
epoch 36500  clean testing loss: 0.10911443084478378
epoch 36600  training loss: 0.0351526252925396
epoch 36600  clean testing loss: 0.10932496935129166
epoch 36700  training loss: 0.03555205836892128
epoch 36700  clean testing loss: 0.11029829829931259
epoch 36800  training loss: 0.03519899398088455
epoch 36800  clean testing loss: 0.1094316765666008
epoch 36900  training loss: 0.03519095852971077
epoch 36900  clean testing loss: 0.10913463681936264
epoch 37000  training loss: 0.03501110151410103
epoch 37000  clean testing loss: 0.11027450859546661

 38%|███████████████████████████████▋                                                    | 37721/100000 [01:58<03:10, 326.29it/s]
epoch 37100  training loss: 0.03503597900271416
epoch 37100  clean testing loss: 0.10952332615852356
epoch 37200  training loss: 0.03523346781730652
epoch 37200  clean testing loss: 0.10986331850290298
epoch 37300  training loss: 0.035297662019729614
epoch 37300  clean testing loss: 0.11045452952384949
epoch 37400  training loss: 0.034926820546388626
epoch 37400  clean testing loss: 0.10972899943590164
epoch 37500  training loss: 0.03492533043026924
epoch 37500  clean testing loss: 0.10945810377597809
epoch 37600  training loss: 0.03500611335039139

 38%|████████████████████████████████▏                                                   | 38383/100000 [02:00<03:09, 325.78it/s]
epoch 37700  training loss: 0.03494691476225853
epoch 37700  clean testing loss: 0.11001478135585785
epoch 37800  training loss: 0.03486272320151329
epoch 37800  clean testing loss: 0.10955066978931427
epoch 37900  training loss: 0.03516194969415665
epoch 37900  clean testing loss: 0.1102774441242218
epoch 38000  training loss: 0.03475957736372948
epoch 38000  clean testing loss: 0.10924442112445831
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 38100  training loss: 0.03510766476392746
epoch 38100  clean testing loss: 0.1106511577963829
epoch 38200  training loss: 0.034775085747241974
epoch 38200  clean testing loss: 0.11085711419582367
epoch 38300  training loss: 0.034706953912973404

 39%|████████████████████████████████▊                                                   | 39014/100000 [02:02<03:07, 324.67it/s]
epoch 38400  training loss: 0.03464698791503906
epoch 38400  clean testing loss: 0.10981105268001556
epoch 38500  training loss: 0.0348798967897892
epoch 38500  clean testing loss: 0.11039315909147263
epoch 38600  training loss: 0.034681301563978195
epoch 38600  clean testing loss: 0.11119705438613892
epoch 38700  training loss: 0.03463734686374664
epoch 38700  clean testing loss: 0.1107180193066597
epoch 38800  training loss: 0.03510051965713501
epoch 38800  clean testing loss: 0.11073196679353714
epoch 38900  training loss: 0.03466470539569855

 40%|█████████████████████████████████▎                                                  | 39677/100000 [02:04<03:04, 326.09it/s]
epoch 39000  training loss: 0.03500690311193466
epoch 39000  clean testing loss: 0.11054518818855286
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 39100  training loss: 0.03459567204117775
epoch 39100  clean testing loss: 0.11069058626890182
epoch 39200  training loss: 0.0345388799905777
epoch 39200  clean testing loss: 0.11069220304489136
epoch 39300  training loss: 0.034424927085638046
epoch 39300  clean testing loss: 0.11083920300006866
epoch 39400  training loss: 0.034408800303936005
epoch 39400  clean testing loss: 0.11058715730905533
epoch 39500  training loss: 0.03446836769580841
epoch 39500  clean testing loss: 0.1108349934220314
epoch 39600  training loss: 0.03439145162701607

 40%|█████████████████████████████████▉                                                  | 40342/100000 [02:06<03:02, 326.59it/s]
epoch 39700  training loss: 0.034457527101039886
epoch 39700  clean testing loss: 0.11089791357517242
epoch 39800  training loss: 0.03438909351825714
epoch 39800  clean testing loss: 0.11087504774332047
epoch 39900  training loss: 0.03429846838116646
epoch 39900  clean testing loss: 0.111285500228405
epoch 40000  training loss: 0.03440406918525696
epoch 40000  clean testing loss: 0.1110893115401268
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 40100  training loss: 0.03442914038896561
epoch 40100  clean testing loss: 0.11130281537771225
epoch 40200  training loss: 0.034348711371421814

 41%|██████████████████████████████████▍                                                 | 40970/100000 [02:08<03:01, 326.05it/s]
epoch 40300  training loss: 0.03429928794503212
epoch 40300  clean testing loss: 0.11144273728132248
epoch 40400  training loss: 0.03431679680943489
epoch 40400  clean testing loss: 0.11148994415998459
epoch 40500  training loss: 0.034219563007354736
epoch 40500  clean testing loss: 0.11152593046426773
epoch 40600  training loss: 0.0343361422419548
epoch 40600  clean testing loss: 0.11167775839567184
epoch 40700  training loss: 0.03424696624279022
epoch 40700  clean testing loss: 0.11187344044446945
epoch 40800  training loss: 0.034263186156749725
epoch 40800  clean testing loss: 0.1114039495587349
epoch 40900  training loss: 0.03446581959724426

 42%|██████████████████████████████████▉                                                 | 41635/100000 [02:10<02:56, 330.08it/s]
epoch 41000  training loss: 0.03434031084179878
epoch 41000  clean testing loss: 0.11183129251003265
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 41100  training loss: 0.034141965210437775
epoch 41100  clean testing loss: 0.11206205934286118
epoch 41200  training loss: 0.03422065079212189
epoch 41200  clean testing loss: 0.11206396669149399
epoch 41300  training loss: 0.034078653901815414
epoch 41300  clean testing loss: 0.1120469868183136
epoch 41400  training loss: 0.03465350344777107
epoch 41400  clean testing loss: 0.11315985769033432
epoch 41500  training loss: 0.03420419618487358

 42%|███████████████████████████████████▌                                                | 42303/100000 [02:12<02:55, 328.38it/s]
epoch 41600  training loss: 0.03410666808485985
epoch 41600  clean testing loss: 0.11198865622282028
epoch 41700  training loss: 0.034060705453157425
epoch 41700  clean testing loss: 0.1119777262210846
epoch 41800  training loss: 0.034142181277275085
epoch 41800  clean testing loss: 0.1129191666841507
epoch 41900  training loss: 0.03408324718475342
epoch 41900  clean testing loss: 0.11227460205554962
epoch 42000  training loss: 0.03420555964112282
epoch 42000  clean testing loss: 0.1127297431230545
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 42100  training loss: 0.033966295421123505
epoch 42100  clean testing loss: 0.11260433495044708
epoch 42200  training loss: 0.03393533453345299

 43%|████████████████████████████████████                                                | 42933/100000 [02:14<02:54, 326.69it/s]
epoch 42300  training loss: 0.03390757367014885
epoch 42300  clean testing loss: 0.11260262876749039
epoch 42400  training loss: 0.033895235508680344
epoch 42400  clean testing loss: 0.11243408918380737
epoch 42500  training loss: 0.033866722136735916
epoch 42500  clean testing loss: 0.11280661076307297
epoch 42600  training loss: 0.033989809453487396
epoch 42600  clean testing loss: 0.1134890764951706
epoch 42700  training loss: 0.03385525196790695
epoch 42700  clean testing loss: 0.1130177229642868
epoch 42800  training loss: 0.033859312534332275
epoch 42800  clean testing loss: 0.11334790289402008
epoch 42900  training loss: 0.03383905813097954

 44%|████████████████████████████████████▌                                               | 43595/100000 [02:16<02:52, 326.46it/s]
epoch 43000  training loss: 0.034192197024822235
epoch 43000  clean testing loss: 0.11351244151592255
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 43100  training loss: 0.033797070384025574
epoch 43100  clean testing loss: 0.1131773442029953
epoch 43200  training loss: 0.033948611468076706
epoch 43200  clean testing loss: 0.11342868208885193
epoch 43300  training loss: 0.03383921831846237
epoch 43300  clean testing loss: 0.11363931745290756
epoch 43400  training loss: 0.033792801201343536
epoch 43400  clean testing loss: 0.1135241761803627
epoch 43500  training loss: 0.03386843204498291

 44%|█████████████████████████████████████▏                                              | 44258/100000 [02:18<02:51, 325.90it/s]
epoch 43600  training loss: 0.033737845718860626
epoch 43600  clean testing loss: 0.11367009580135345
epoch 43700  training loss: 0.03379897028207779
epoch 43700  clean testing loss: 0.1134723573923111
epoch 43800  training loss: 0.03372665122151375
epoch 43800  clean testing loss: 0.11363464593887329
epoch 43900  training loss: 0.03371775150299072
epoch 43900  clean testing loss: 0.11403122544288635
epoch 44000  training loss: 0.03366609290242195
epoch 44000  clean testing loss: 0.11372747272253036
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 44100  training loss: 0.033778611570596695
epoch 44100  clean testing loss: 0.1139601543545723
epoch 44200  training loss: 0.033788051456213

 45%|█████████████████████████████████████▋                                              | 44924/100000 [02:20<02:47, 328.27it/s]
epoch 44300  training loss: 0.03362404182553291
epoch 44300  clean testing loss: 0.11376339197158813
epoch 44400  training loss: 0.03362174332141876
epoch 44400  clean testing loss: 0.11425317078828812
epoch 44500  training loss: 0.03358790650963783
epoch 44500  clean testing loss: 0.1141456589102745
epoch 44600  training loss: 0.033556319773197174
epoch 44600  clean testing loss: 0.11426876485347748
epoch 44700  training loss: 0.03363135829567909
epoch 44700  clean testing loss: 0.11461388319730759
epoch 44800  training loss: 0.033692482858896255

 46%|██████████████████████████████████████▎                                             | 45557/100000 [02:22<02:46, 326.83it/s]
epoch 44900  training loss: 0.033537015318870544
epoch 44900  clean testing loss: 0.11436736583709717
epoch 45000  training loss: 0.03363930061459541
epoch 45000  clean testing loss: 0.11454462260007858
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 45100  training loss: 0.033479850739240646
epoch 45100  clean testing loss: 0.11408863216638565
epoch 45200  training loss: 0.03347444906830788
epoch 45200  clean testing loss: 0.11443392187356949
epoch 45300  training loss: 0.03348316252231598
epoch 45300  clean testing loss: 0.11436881124973297
epoch 45400  training loss: 0.03344269096851349
epoch 45400  clean testing loss: 0.11461557447910309
epoch 45500  training loss: 0.033517517149448395

 46%|██████████████████████████████████████▊                                             | 46223/100000 [02:24<02:44, 327.11it/s]
epoch 45600  training loss: 0.03350267559289932
epoch 45600  clean testing loss: 0.11499018222093582
epoch 45700  training loss: 0.0334961861371994
epoch 45700  clean testing loss: 0.11516838520765305
epoch 45800  training loss: 0.03342413529753685
epoch 45800  clean testing loss: 0.11478883028030396
epoch 45900  training loss: 0.03334938362240791
epoch 45900  clean testing loss: 0.11485835909843445
epoch 46000  training loss: 0.033360086381435394
epoch 46000  clean testing loss: 0.11482461541891098
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 46100  training loss: 0.033498939126729965

 47%|███████████████████████████████████████▍                                            | 46887/100000 [02:26<02:41, 327.91it/s]
epoch 46200  training loss: 0.03344270959496498
epoch 46200  clean testing loss: 0.11496372520923615
epoch 46300  training loss: 0.03346611186861992
epoch 46300  clean testing loss: 0.11515804380178452
epoch 46400  training loss: 0.03339412063360214
epoch 46400  clean testing loss: 0.11537861824035645
epoch 46500  training loss: 0.03329817205667496
epoch 46500  clean testing loss: 0.11512163281440735
epoch 46600  training loss: 0.033392999321222305
epoch 46600  clean testing loss: 0.11528292298316956
epoch 46700  training loss: 0.033305004239082336
epoch 46700  clean testing loss: 0.11578626930713654
epoch 46800  training loss: 0.03331818804144859

 48%|███████████████████████████████████████▉                                            | 47518/100000 [02:28<02:39, 329.09it/s]
epoch 46900  training loss: 0.03344958648085594
epoch 46900  clean testing loss: 0.11586423218250275
epoch 47000  training loss: 0.03327496349811554
epoch 47000  clean testing loss: 0.11567087471485138
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 47100  training loss: 0.033289968967437744
epoch 47100  clean testing loss: 0.11574580520391464
epoch 47200  training loss: 0.03320985659956932
epoch 47200  clean testing loss: 0.1156185045838356
epoch 47300  training loss: 0.033223383128643036
epoch 47300  clean testing loss: 0.11554863303899765
epoch 47400  training loss: 0.0332559309899807

 48%|████████████████████████████████████████▍                                           | 48182/100000 [02:30<02:37, 328.44it/s]
epoch 47500  training loss: 0.03323176130652428
epoch 47500  clean testing loss: 0.11631587892770767
epoch 47600  training loss: 0.03321196883916855
epoch 47600  clean testing loss: 0.11611148715019226
epoch 47700  training loss: 0.03323879837989807
epoch 47700  clean testing loss: 0.11589304357767105
epoch 47800  training loss: 0.033227648586034775
epoch 47800  clean testing loss: 0.11587012559175491
epoch 47900  training loss: 0.03316681087017059
epoch 47900  clean testing loss: 0.11594989895820618
epoch 48000  training loss: 0.033214304596185684
epoch 48000  clean testing loss: 0.11589105427265167
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 48100  training loss: 0.033107392489910126

 49%|█████████████████████████████████████████                                           | 48846/100000 [02:32<02:35, 328.05it/s]
epoch 48200  training loss: 0.03314179554581642
epoch 48200  clean testing loss: 0.11614345014095306
epoch 48300  training loss: 0.03312644362449646
epoch 48300  clean testing loss: 0.11648672074079514
epoch 48400  training loss: 0.03308769315481186
epoch 48400  clean testing loss: 0.11628428101539612
epoch 48500  training loss: 0.03305021673440933
epoch 48500  clean testing loss: 0.11616518348455429
epoch 48600  training loss: 0.033092185854911804
epoch 48600  clean testing loss: 0.11636145412921906
epoch 48700  training loss: 0.03306359425187111

 49%|█████████████████████████████████████████▌                                          | 49477/100000 [02:34<02:33, 328.81it/s]
epoch 48800  training loss: 0.033086564391851425
epoch 48800  clean testing loss: 0.11624279618263245
epoch 48900  training loss: 0.03310364857316017
epoch 48900  clean testing loss: 0.11636549979448318
epoch 49000  training loss: 0.03303057700395584
epoch 49000  clean testing loss: 0.11657010763883591
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 49100  training loss: 0.03305284306406975
epoch 49100  clean testing loss: 0.11656156182289124
epoch 49200  training loss: 0.03310692682862282
epoch 49200  clean testing loss: 0.1165359765291214
epoch 49300  training loss: 0.033000245690345764
epoch 49300  clean testing loss: 0.1164437010884285
epoch 49400  training loss: 0.03303398936986923

 50%|██████████████████████████████████████████                                          | 50140/100000 [02:36<02:33, 324.57it/s]
epoch 49500  training loss: 0.032974518835544586
epoch 49500  clean testing loss: 0.11670288443565369
epoch 49600  training loss: 0.032971061766147614
epoch 49600  clean testing loss: 0.11697949469089508
epoch 49700  training loss: 0.03299624100327492
epoch 49700  clean testing loss: 0.11699704825878143
epoch 49800  training loss: 0.033088717609643936
epoch 49800  clean testing loss: 0.1170402318239212
epoch 49900  training loss: 0.032912727445364
epoch 49900  clean testing loss: 0.11687078326940536
epoch 50000  training loss: 0.0329410620033741
epoch 50000  clean testing loss: 0.11728886514902115

 51%|██████████████████████████████████████████▋                                         | 50806/100000 [02:38<02:30, 326.56it/s]
epoch 50100  training loss: 0.03292602673172951
epoch 50100  clean testing loss: 0.11739189922809601
epoch 50200  training loss: 0.032906580716371536
epoch 50200  clean testing loss: 0.11698218435049057
epoch 50300  training loss: 0.03296482563018799
epoch 50300  clean testing loss: 0.1172284409403801
epoch 50400  training loss: 0.03294280171394348
epoch 50400  clean testing loss: 0.11719278991222382
epoch 50500  training loss: 0.032879143953323364
epoch 50500  clean testing loss: 0.11694547533988953
epoch 50600  training loss: 0.03285452723503113
epoch 50600  clean testing loss: 0.11746286600828171
epoch 50700  training loss: 0.03287423029541969

 51%|███████████████████████████████████████████▏                                        | 51468/100000 [02:40<02:28, 326.49it/s]
epoch 50800  training loss: 0.032976020127534866
epoch 50800  clean testing loss: 0.1174330785870552
epoch 50900  training loss: 0.0328650027513504
epoch 50900  clean testing loss: 0.1176300197839737
epoch 51000  training loss: 0.032829441130161285
epoch 51000  clean testing loss: 0.1175181195139885
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 51100  training loss: 0.032801926136016846
epoch 51100  clean testing loss: 0.1173783615231514
epoch 51200  training loss: 0.032781489193439484
epoch 51200  clean testing loss: 0.11699943989515305
epoch 51300  training loss: 0.032773010432720184

 52%|███████████████████████████████████████████▊                                        | 52097/100000 [02:42<02:27, 324.04it/s]
epoch 51400  training loss: 0.03279585763812065
epoch 51400  clean testing loss: 0.11741869151592255
epoch 51500  training loss: 0.03277797996997833
epoch 51500  clean testing loss: 0.11758076399564743
epoch 51600  training loss: 0.03276313096284866
epoch 51600  clean testing loss: 0.11770238727331161
epoch 51700  training loss: 0.03277245908975601
epoch 51700  clean testing loss: 0.11770445853471756
epoch 51800  training loss: 0.03274921700358391
epoch 51800  clean testing loss: 0.11787708103656769
epoch 51900  training loss: 0.032769396901130676
epoch 51900  clean testing loss: 0.11780313402414322
epoch 52000  training loss: 0.0327429361641407
epoch 52000  clean testing loss: 0.11797403544187546

 53%|████████████████████████████████████████████▎                                       | 52760/100000 [02:44<02:24, 325.84it/s]
epoch 52100  training loss: 0.03286302462220192
epoch 52100  clean testing loss: 0.11749237775802612
epoch 52200  training loss: 0.032692987471818924
epoch 52200  clean testing loss: 0.1179528534412384
epoch 52300  training loss: 0.03274193033576012
epoch 52300  clean testing loss: 0.11761937290430069
epoch 52400  training loss: 0.03272420912981033
epoch 52400  clean testing loss: 0.11780856549739838
epoch 52500  training loss: 0.032680533826351166
epoch 52500  clean testing loss: 0.11797183752059937
epoch 52600  training loss: 0.03267008438706398

 53%|████████████████████████████████████████████▊                                       | 53391/100000 [02:46<02:22, 327.10it/s]
epoch 52700  training loss: 0.03266993910074234
epoch 52700  clean testing loss: 0.11818622052669525
epoch 52800  training loss: 0.03266604617238045
epoch 52800  clean testing loss: 0.11834299564361572
epoch 52900  training loss: 0.0326751172542572
epoch 52900  clean testing loss: 0.11808807402849197
epoch 53000  training loss: 0.0326487272977829
epoch 53000  clean testing loss: 0.11816170066595078
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 53100  training loss: 0.03269696608185768
epoch 53100  clean testing loss: 0.11808179318904877
epoch 53200  training loss: 0.03269379585981369
epoch 53200  clean testing loss: 0.11812209337949753
epoch 53300  training loss: 0.03267791122198105

 54%|█████████████████████████████████████████████▍                                      | 54058/100000 [02:48<02:21, 325.64it/s]
epoch 53400  training loss: 0.03267882764339447
epoch 53400  clean testing loss: 0.11866899579763412
epoch 53500  training loss: 0.03257627785205841
epoch 53500  clean testing loss: 0.11860184371471405
epoch 53600  training loss: 0.03255686163902283
epoch 53600  clean testing loss: 0.11859604716300964
epoch 53700  training loss: 0.03255324810743332
epoch 53700  clean testing loss: 0.11823760718107224
epoch 53800  training loss: 0.03257749229669571
epoch 53800  clean testing loss: 0.11829569190740585
epoch 53900  training loss: 0.03260093554854393

 55%|█████████████████████████████████████████████▉                                      | 54721/100000 [02:50<02:18, 326.49it/s]
epoch 54000  training loss: 0.03258757293224335
epoch 54000  clean testing loss: 0.11863356828689575
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 54100  training loss: 0.03250633552670479
epoch 54100  clean testing loss: 0.11872010678052902
epoch 54200  training loss: 0.03251120448112488
epoch 54200  clean testing loss: 0.11898232996463776
epoch 54300  training loss: 0.032536040991544724
epoch 54300  clean testing loss: 0.11894895136356354
epoch 54400  training loss: 0.03250119090080261
epoch 54400  clean testing loss: 0.11868942528963089
epoch 54500  training loss: 0.032518234103918076
epoch 54500  clean testing loss: 0.1188059002161026
epoch 54600  training loss: 0.03247154504060745

 55%|██████████████████████████████████████████████▍                                     | 55353/100000 [02:52<02:16, 326.20it/s]
epoch 54700  training loss: 0.032510265707969666
epoch 54700  clean testing loss: 0.11894544959068298
epoch 54800  training loss: 0.03250923007726669
epoch 54800  clean testing loss: 0.11893584579229355
epoch 54900  training loss: 0.03249543905258179
epoch 54900  clean testing loss: 0.11875169724225998
epoch 55000  training loss: 0.03253454342484474
epoch 55000  clean testing loss: 0.11909446120262146
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 55100  training loss: 0.03247852623462677
epoch 55100  clean testing loss: 0.1190229058265686
epoch 55200  training loss: 0.03244688734412193

 56%|███████████████████████████████████████████████                                     | 56013/100000 [02:54<02:15, 324.50it/s]
epoch 55300  training loss: 0.032441146671772
epoch 55300  clean testing loss: 0.11913684755563736
epoch 55400  training loss: 0.03243817016482353
epoch 55400  clean testing loss: 0.11926408857107162
epoch 55500  training loss: 0.03242211788892746
epoch 55500  clean testing loss: 0.1190238669514656
epoch 55600  training loss: 0.03241243213415146
epoch 55600  clean testing loss: 0.11928914487361908
epoch 55700  training loss: 0.0324198342859745
epoch 55700  clean testing loss: 0.11902137100696564
epoch 55800  training loss: 0.032391421496868134
epoch 55800  clean testing loss: 0.11932968348264694
epoch 55900  training loss: 0.032426562160253525

 57%|███████████████████████████████████████████████▌                                    | 56677/100000 [02:56<02:12, 326.27it/s]
epoch 56000  training loss: 0.03244723752140999
epoch 56000  clean testing loss: 0.11967819929122925
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 56100  training loss: 0.03238800913095474
epoch 56100  clean testing loss: 0.11947601288557053
epoch 56200  training loss: 0.03236589580774307
epoch 56200  clean testing loss: 0.11946991086006165
epoch 56300  training loss: 0.03237342834472656
epoch 56300  clean testing loss: 0.11953487247228622
epoch 56400  training loss: 0.032372236251831055
epoch 56400  clean testing loss: 0.11946965754032135
epoch 56500  training loss: 0.032354727387428284

 57%|████████████████████████████████████████████████▏                                   | 57310/100000 [02:58<02:10, 326.88it/s]
epoch 56600  training loss: 0.03235993906855583
epoch 56600  clean testing loss: 0.1198238879442215
epoch 56700  training loss: 0.032344844192266464
epoch 56700  clean testing loss: 0.11938892304897308
epoch 56800  training loss: 0.03231693431735039
epoch 56800  clean testing loss: 0.11966994404792786
epoch 56900  training loss: 0.032340340316295624
epoch 56900  clean testing loss: 0.11978740245103836
epoch 57000  training loss: 0.03228504955768585
epoch 57000  clean testing loss: 0.11960454285144806
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 57100  training loss: 0.032307762652635574
epoch 57100  clean testing loss: 0.11966606229543686
epoch 57200  training loss: 0.03227237984538078

 58%|████████████████████████████████████████████████▋                                   | 57976/100000 [03:00<02:07, 328.43it/s]
epoch 57300  training loss: 0.032263483852148056
epoch 57300  clean testing loss: 0.11988848447799683
epoch 57400  training loss: 0.032290469855070114
epoch 57400  clean testing loss: 0.11992166936397552
epoch 57500  training loss: 0.032265301793813705
epoch 57500  clean testing loss: 0.11968501657247543
epoch 57600  training loss: 0.032296232879161835
epoch 57600  clean testing loss: 0.12021124362945557
epoch 57700  training loss: 0.032254427671432495
epoch 57700  clean testing loss: 0.11987195163965225
epoch 57800  training loss: 0.03224647790193558
epoch 57800  clean testing loss: 0.11993475258350372
epoch 57900  training loss: 0.03225750848650932

 59%|█████████████████████████████████████████████████▎                                  | 58640/100000 [03:02<02:06, 326.20it/s]
epoch 58000  training loss: 0.03224138915538788
epoch 58000  clean testing loss: 0.1202448159456253
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 58100  training loss: 0.03224632516503334
epoch 58100  clean testing loss: 0.12010706216096878
epoch 58200  training loss: 0.03226546198129654
epoch 58200  clean testing loss: 0.12013087421655655
epoch 58300  training loss: 0.03223300352692604
epoch 58300  clean testing loss: 0.12004927545785904
epoch 58400  training loss: 0.03222178295254707
epoch 58400  clean testing loss: 0.12016773968935013
epoch 58500  training loss: 0.03221805766224861

 59%|█████████████████████████████████████████████████▊                                  | 59274/100000 [03:04<02:04, 327.95it/s]
epoch 58600  training loss: 0.03220980986952782
epoch 58600  clean testing loss: 0.12014642357826233
epoch 58700  training loss: 0.032200440764427185
epoch 58700  clean testing loss: 0.12036141753196716
epoch 58800  training loss: 0.03217285871505737
epoch 58800  clean testing loss: 0.12046504765748978
epoch 58900  training loss: 0.03218092396855354
epoch 58900  clean testing loss: 0.1205931305885315
epoch 59000  training loss: 0.03214482218027115
epoch 59000  clean testing loss: 0.1202508956193924
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 59100  training loss: 0.03221079334616661
epoch 59100  clean testing loss: 0.12026264518499374
epoch 59200  training loss: 0.03217872604727745

 60%|██████████████████████████████████████████████████▎                                 | 59940/100000 [03:06<02:02, 328.10it/s]
epoch 59300  training loss: 0.03211170807480812
epoch 59300  clean testing loss: 0.12033146619796753
epoch 59400  training loss: 0.032186925411224365
epoch 59400  clean testing loss: 0.12056154757738113
epoch 59500  training loss: 0.03210994973778725
epoch 59500  clean testing loss: 0.12052838504314423
epoch 59600  training loss: 0.03211080655455589
epoch 59600  clean testing loss: 0.12040526419878006
epoch 59700  training loss: 0.03210125118494034
epoch 59700  clean testing loss: 0.12066470831632614
epoch 59800  training loss: 0.03208262845873833

 61%|██████████████████████████████████████████████████▉                                 | 60604/100000 [03:08<01:59, 328.77it/s]
epoch 59900  training loss: 0.032068781554698944
epoch 59900  clean testing loss: 0.12058945000171661
epoch 60000  training loss: 0.03207981958985329
epoch 60000  clean testing loss: 0.12079455703496933
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 60100  training loss: 0.032103635370731354
epoch 60100  clean testing loss: 0.12074089795351028
epoch 60200  training loss: 0.032070159912109375
epoch 60200  clean testing loss: 0.12066487222909927
epoch 60300  training loss: 0.03207523003220558
epoch 60300  clean testing loss: 0.12037158757448196
epoch 60400  training loss: 0.03206150233745575
epoch 60400  clean testing loss: 0.12078317999839783
epoch 60500  training loss: 0.03205448389053345

 61%|███████████████████████████████████████████████████▍                                | 61238/100000 [03:10<01:57, 328.58it/s]
epoch 60600  training loss: 0.03206351771950722
epoch 60600  clean testing loss: 0.12066201865673065
epoch 60700  training loss: 0.03203246369957924
epoch 60700  clean testing loss: 0.12078244984149933
epoch 60800  training loss: 0.032002124935388565
epoch 60800  clean testing loss: 0.12069056928157806
epoch 60900  training loss: 0.031998105347156525
epoch 60900  clean testing loss: 0.12057919800281525
epoch 61000  training loss: 0.03202639892697334
epoch 61000  clean testing loss: 0.12076706439256668
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 61100  training loss: 0.03200436010956764

 62%|████████████████████████████████████████████████████                                | 61907/100000 [03:12<01:56, 327.38it/s]
epoch 61200  training loss: 0.03199894353747368
epoch 61200  clean testing loss: 0.1209222748875618
epoch 61300  training loss: 0.03198235109448433
epoch 61300  clean testing loss: 0.12103912979364395
epoch 61400  training loss: 0.03195168077945709
epoch 61400  clean testing loss: 0.12110361456871033
epoch 61500  training loss: 0.03195834532380104
epoch 61500  clean testing loss: 0.12103274464607239
epoch 61600  training loss: 0.031945858150720596
epoch 61600  clean testing loss: 0.12112389504909515
epoch 61700  training loss: 0.031931206583976746
epoch 61700  clean testing loss: 0.12107234448194504
epoch 61800  training loss: 0.03191697970032692

 63%|████████████████████████████████████████████████████▌                               | 62569/100000 [03:14<01:54, 326.38it/s]
epoch 61900  training loss: 0.031900011003017426
epoch 61900  clean testing loss: 0.12100525200366974
epoch 62000  training loss: 0.03191770240664482
epoch 62000  clean testing loss: 0.12114381790161133
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 62100  training loss: 0.031905073672533035
epoch 62100  clean testing loss: 0.12143363058567047
epoch 62200  training loss: 0.0319121889770031
epoch 62200  clean testing loss: 0.12118344753980637
epoch 62300  training loss: 0.03192352503538132
epoch 62300  clean testing loss: 0.12142015993595123
epoch 62400  training loss: 0.03187454864382744

 63%|█████████████████████████████████████████████████████                               | 63202/100000 [03:16<01:53, 325.58it/s]
epoch 62500  training loss: 0.03194499760866165
epoch 62500  clean testing loss: 0.12135273963212967
epoch 62600  training loss: 0.031897157430648804
epoch 62600  clean testing loss: 0.12143344432115555
epoch 62700  training loss: 0.03188946470618248
epoch 62700  clean testing loss: 0.12134833633899689
epoch 62800  training loss: 0.031869616359472275
epoch 62800  clean testing loss: 0.12158064544200897
epoch 62900  training loss: 0.03189176321029663
epoch 62900  clean testing loss: 0.12166478484869003
epoch 63000  training loss: 0.031865496188402176
epoch 63000  clean testing loss: 0.12136495113372803
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 63100  training loss: 0.031824640929698944

 64%|█████████████████████████████████████████████████████▋                              | 63868/100000 [03:18<01:50, 326.87it/s]
epoch 63200  training loss: 0.03184742107987404
epoch 63200  clean testing loss: 0.12144066393375397
epoch 63300  training loss: 0.03183179721236229
epoch 63300  clean testing loss: 0.12148189544677734
epoch 63400  training loss: 0.031828831881284714
epoch 63400  clean testing loss: 0.12178485095500946
epoch 63500  training loss: 0.03180893138051033
epoch 63500  clean testing loss: 0.12179477512836456
epoch 63600  training loss: 0.03179451450705528
epoch 63600  clean testing loss: 0.12172664701938629
epoch 63700  training loss: 0.03178161382675171

 65%|██████████████████████████████████████████████████████▏                             | 64534/100000 [03:20<01:48, 325.60it/s]
epoch 63800  training loss: 0.031784895807504654
epoch 63800  clean testing loss: 0.12150940299034119
epoch 63900  training loss: 0.03173201158642769
epoch 63900  clean testing loss: 0.12183177471160889
epoch 64000  training loss: 0.031765781342983246
epoch 64000  clean testing loss: 0.12170460820198059
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 64100  training loss: 0.03174375742673874
epoch 64100  clean testing loss: 0.12174583971500397
epoch 64200  training loss: 0.03176892176270485
epoch 64200  clean testing loss: 0.12172547727823257
epoch 64300  training loss: 0.03177104517817497
epoch 64300  clean testing loss: 0.122022844851017
epoch 64400  training loss: 0.03177105635404587

 65%|██████████████████████████████████████████████████████▌                             | 64997/100000 [03:21<01:47, 325.16it/s]
epoch 64500  training loss: 0.03175738826394081
epoch 64500  clean testing loss: 0.12184971570968628
epoch 64600  training loss: 0.0317426398396492
epoch 64600  clean testing loss: 0.12207240611314774
epoch 64700  training loss: 0.03172954544425011
epoch 64700  clean testing loss: 0.12196482717990875
epoch 64800  training loss: 0.03170790895819664
epoch 64800  clean testing loss: 0.12210008502006531
epoch 64900  training loss: 0.03170761466026306
epoch 64900  clean testing loss: 0.12200319766998291
epoch 65000  training loss: 0.03169989213347435
epoch 65000  clean testing loss: 0.12202177941799164

 66%|███████████████████████████████████████████████████████▏                            | 65658/100000 [03:23<01:45, 325.55it/s]
epoch 65100  training loss: 0.031684666872024536
epoch 65100  clean testing loss: 0.12201854586601257
epoch 65200  training loss: 0.03172151744365692
epoch 65200  clean testing loss: 0.12218701094388962
epoch 65300  training loss: 0.03169753775000572
epoch 65300  clean testing loss: 0.1220124214887619
epoch 65400  training loss: 0.03168952092528343
epoch 65400  clean testing loss: 0.12210302799940109
epoch 65500  training loss: 0.03167840838432312
epoch 65500  clean testing loss: 0.12215662002563477
epoch 65600  training loss: 0.03167949989438057
epoch 65600  clean testing loss: 0.12220736593008041
epoch 65700  training loss: 0.031650520861148834

 66%|███████████████████████████████████████████████████████▋                            | 66322/100000 [03:25<01:42, 327.11it/s]
epoch 65800  training loss: 0.031630486249923706
epoch 65800  clean testing loss: 0.12210031598806381
epoch 65900  training loss: 0.03165276721119881
epoch 65900  clean testing loss: 0.12228793650865555
epoch 66000  training loss: 0.03165913373231888
epoch 66000  clean testing loss: 0.1222745031118393
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 66100  training loss: 0.031634148210287094
epoch 66100  clean testing loss: 0.12248460948467255
epoch 66200  training loss: 0.031642258167266846
epoch 66200  clean testing loss: 0.12226619571447372
epoch 66300  training loss: 0.03167428448796272

 67%|████████████████████████████████████████████████████████▎                           | 66988/100000 [03:28<01:41, 326.69it/s]
epoch 66400  training loss: 0.03161310404539108
epoch 66400  clean testing loss: 0.12222245335578918
epoch 66500  training loss: 0.031593047082424164
epoch 66500  clean testing loss: 0.12252262979745865
epoch 66600  training loss: 0.03161614388227463
epoch 66600  clean testing loss: 0.12231317162513733
epoch 66700  training loss: 0.03160145878791809
epoch 66700  clean testing loss: 0.12238171696662903
epoch 66800  training loss: 0.031603410840034485
epoch 66800  clean testing loss: 0.1222911849617958
epoch 66900  training loss: 0.031601741909980774
epoch 66900  clean testing loss: 0.12246721237897873
epoch 67000  training loss: 0.031574565917253494
epoch 67000  clean testing loss: 0.12243220955133438

 68%|████████████████████████████████████████████████████████▊                           | 67618/100000 [03:29<01:38, 327.89it/s]
epoch 67100  training loss: 0.03160801902413368
epoch 67100  clean testing loss: 0.12247050553560257
epoch 67200  training loss: 0.031596120446920395
epoch 67200  clean testing loss: 0.12254565209150314
epoch 67300  training loss: 0.03156958892941475
epoch 67300  clean testing loss: 0.12263821810483932
epoch 67400  training loss: 0.03154778853058815
epoch 67400  clean testing loss: 0.12251827865839005
epoch 67500  training loss: 0.03156671300530434
epoch 67500  clean testing loss: 0.12268459051847458
epoch 67600  training loss: 0.031558163464069366

 68%|█████████████████████████████████████████████████████████▎                          | 68283/100000 [03:32<01:36, 328.65it/s]
epoch 67700  training loss: 0.03153916448354721
epoch 67700  clean testing loss: 0.1228264644742012
epoch 67800  training loss: 0.03155887499451637
epoch 67800  clean testing loss: 0.12279736995697021
epoch 67900  training loss: 0.03152411803603172
epoch 67900  clean testing loss: 0.12275900691747665
epoch 68000  training loss: 0.031545739620923996
epoch 68000  clean testing loss: 0.12275239825248718
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 68100  training loss: 0.031546320766210556
epoch 68100  clean testing loss: 0.12289648503065109
epoch 68200  training loss: 0.03153550624847412
epoch 68200  clean testing loss: 0.12275779992341995
epoch 68300  training loss: 0.03152976557612419

 69%|█████████████████████████████████████████████████████████▉                          | 68948/100000 [03:34<01:35, 326.57it/s]
epoch 68400  training loss: 0.03150789439678192
epoch 68400  clean testing loss: 0.12288108468055725
epoch 68500  training loss: 0.03153133764863014
epoch 68500  clean testing loss: 0.12279155105352402
epoch 68600  training loss: 0.031505927443504333
epoch 68600  clean testing loss: 0.12296770513057709
epoch 68700  training loss: 0.03152447193861008
epoch 68700  clean testing loss: 0.12281608581542969
epoch 68800  training loss: 0.03150015324354172
epoch 68800  clean testing loss: 0.12295655906200409
epoch 68900  training loss: 0.03148665651679039
epoch 68900  clean testing loss: 0.12288004904985428
epoch 69000  training loss: 0.03148827701807022
epoch 69000  clean testing loss: 0.12308083474636078

 70%|██████████████████████████████████████████████████████████▍                         | 69583/100000 [03:35<01:32, 329.65it/s]
epoch 69100  training loss: 0.03149775415658951
epoch 69100  clean testing loss: 0.12287326902151108
epoch 69200  training loss: 0.03146282210946083
epoch 69200  clean testing loss: 0.12310604006052017
epoch 69300  training loss: 0.031452275812625885
epoch 69300  clean testing loss: 0.12292101979255676
epoch 69400  training loss: 0.0314716175198555
epoch 69400  clean testing loss: 0.12286276370286942
epoch 69500  training loss: 0.03147090971469879
epoch 69500  clean testing loss: 0.12296617776155472
epoch 69600  training loss: 0.031444963067770004

 70%|███████████████████████████████████████████████████████████                         | 70250/100000 [03:38<01:31, 325.40it/s]
epoch 69700  training loss: 0.03146844357252121
epoch 69700  clean testing loss: 0.12317677587270737
epoch 69800  training loss: 0.031481869518756866
epoch 69800  clean testing loss: 0.12316162139177322
epoch 69900  training loss: 0.03146126866340637
epoch 69900  clean testing loss: 0.12311045825481415
epoch 70000  training loss: 0.03146176412701607
epoch 70000  clean testing loss: 0.12291057407855988
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 70100  training loss: 0.03143729642033577
epoch 70100  clean testing loss: 0.12318523228168488
epoch 70200  training loss: 0.031420689076185226
epoch 70200  clean testing loss: 0.12310697883367538
epoch 70300  training loss: 0.03139570355415344

 71%|███████████████████████████████████████████████████████████▌                        | 70915/100000 [03:40<01:28, 328.05it/s]
epoch 70400  training loss: 0.031371887773275375
epoch 70400  clean testing loss: 0.122952900826931
epoch 70500  training loss: 0.0313907228410244
epoch 70500  clean testing loss: 0.12311054021120071
epoch 70600  training loss: 0.03140111267566681
epoch 70600  clean testing loss: 0.1232391744852066
epoch 70700  training loss: 0.031398531049489975
epoch 70700  clean testing loss: 0.12306062877178192
epoch 70800  training loss: 0.03137463703751564
epoch 70800  clean testing loss: 0.12316489219665527
epoch 70900  training loss: 0.03134785592556

 72%|████████████████████████████████████████████████████████████                        | 71547/100000 [03:42<01:26, 328.39it/s]
epoch 71000  training loss: 0.03136768192052841
epoch 71000  clean testing loss: 0.12321676313877106
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 71100  training loss: 0.03135691583156586
epoch 71100  clean testing loss: 0.12313791364431381
epoch 71200  training loss: 0.03135199099779129
epoch 71200  clean testing loss: 0.1230662390589714
epoch 71300  training loss: 0.03130582347512245
epoch 71300  clean testing loss: 0.12349490821361542
epoch 71400  training loss: 0.031317662447690964
epoch 71400  clean testing loss: 0.12326657772064209
epoch 71500  training loss: 0.03129700943827629
epoch 71500  clean testing loss: 0.1233610212802887
epoch 71600  training loss: 0.03130842000246048

 72%|████████████████████████████████████████████████████████████▋                       | 72210/100000 [03:44<01:25, 325.34it/s]
epoch 71700  training loss: 0.03128644824028015
epoch 71700  clean testing loss: 0.12330969423055649
epoch 71800  training loss: 0.031289953738451004
epoch 71800  clean testing loss: 0.12315043807029724
epoch 71900  training loss: 0.03130841255187988
epoch 71900  clean testing loss: 0.1234847903251648
epoch 72000  training loss: 0.03129864111542702
epoch 72000  clean testing loss: 0.12346813082695007
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 72100  training loss: 0.03129548951983452
epoch 72100  clean testing loss: 0.1232956200838089
epoch 72200  training loss: 0.031301915645599365

 73%|█████████████████████████████████████████████████████████████▏                      | 72837/100000 [03:46<01:30, 299.08it/s]
epoch 72300  training loss: 0.03127607703208923
epoch 72300  clean testing loss: 0.12340948730707169
epoch 72400  training loss: 0.031277138739824295
epoch 72400  clean testing loss: 0.12330687791109085
epoch 72500  training loss: 0.031268320977687836
epoch 72500  clean testing loss: 0.12337779998779297
epoch 72600  training loss: 0.031269706785678864
epoch 72600  clean testing loss: 0.12328732758760452
epoch 72700  training loss: 0.031276073306798935
epoch 72700  clean testing loss: 0.12337643653154373
epoch 72800  training loss: 0.031264517456293106

 73%|█████████████████████████████████████████████████████████████▌                      | 73353/100000 [03:48<01:43, 257.44it/s]
epoch 72900  training loss: 0.03126392140984535
epoch 72900  clean testing loss: 0.12377321720123291
epoch 73000  training loss: 0.031245339661836624
epoch 73000  clean testing loss: 0.12339406460523605
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 73100  training loss: 0.03125278651714325
epoch 73100  clean testing loss: 0.12340659648180008
epoch 73200  training loss: 0.031263627111911774
epoch 73200  clean testing loss: 0.12355607002973557
epoch 73300  training loss: 0.03122870810329914
epoch 73300  clean testing loss: 0.12381129711866379
epoch 73400  training loss: 0.031209275126457214

 74%|██████████████████████████████████████████████████████████████                      | 73884/100000 [03:50<01:41, 256.66it/s]
epoch 73500  training loss: 0.031238501891493797
epoch 73500  clean testing loss: 0.1235869824886322
epoch 73600  training loss: 0.031189145520329475
epoch 73600  clean testing loss: 0.12379874289035797
epoch 73700  training loss: 0.031200295314192772
epoch 73700  clean testing loss: 0.12364951521158218
epoch 73800  training loss: 0.031190650537610054
epoch 73800  clean testing loss: 0.12369858473539352
epoch 73900  training loss: 0.03121655434370041

 74%|██████████████████████████████████████████████████████████████▍                     | 74382/100000 [03:52<01:41, 253.59it/s]
epoch 74000  training loss: 0.03120996616780758
epoch 74000  clean testing loss: 0.1235303282737732
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 74100  training loss: 0.03114473447203636
epoch 74100  clean testing loss: 0.12365270406007767
epoch 74200  training loss: 0.03120090253651142
epoch 74200  clean testing loss: 0.12371826171875
epoch 74300  training loss: 0.031197665259242058
epoch 74300  clean testing loss: 0.12398688495159149
epoch 74400  training loss: 0.03119586408138275

 75%|██████████████████████████████████████████████████████████████▉                     | 74907/100000 [03:54<01:39, 253.20it/s]
epoch 74500  training loss: 0.03116784058511257
epoch 74500  clean testing loss: 0.12393096089363098
epoch 74600  training loss: 0.03116976097226143
epoch 74600  clean testing loss: 0.12396053969860077
epoch 74700  training loss: 0.031164923682808876
epoch 74700  clean testing loss: 0.1236884817481041
epoch 74800  training loss: 0.031133368611335754
epoch 74800  clean testing loss: 0.12378658354282379
epoch 74900  training loss: 0.031145140528678894

 75%|███████████████████████████████████████████████████████████████▎                    | 75359/100000 [03:56<01:54, 214.81it/s]
epoch 75000  training loss: 0.03114861622452736
epoch 75000  clean testing loss: 0.12387677282094955
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 75100  training loss: 0.031136423349380493
epoch 75100  clean testing loss: 0.12384121119976044
epoch 75200  training loss: 0.031121324747800827
epoch 75200  clean testing loss: 0.12397938221693039
epoch 75300  training loss: 0.031118756160140038

 76%|███████████████████████████████████████████████████████████████▋                    | 75784/100000 [03:58<01:52, 215.04it/s]
epoch 75400  training loss: 0.03109521046280861
epoch 75400  clean testing loss: 0.12398790568113327
epoch 75500  training loss: 0.03110777959227562
epoch 75500  clean testing loss: 0.12391214817762375
epoch 75600  training loss: 0.031115341931581497
epoch 75600  clean testing loss: 0.12397098541259766
epoch 75700  training loss: 0.03112027980387211
epoch 75700  clean testing loss: 0.1239149421453476
epoch 75800  training loss: 0.03112112358212471

 76%|████████████████████████████████████████████████████████████████                    | 76213/100000 [04:00<01:52, 211.71it/s]
epoch 75900  training loss: 0.031148497015237808
epoch 75900  clean testing loss: 0.12388235330581665
epoch 76000  training loss: 0.031107017770409584
epoch 76000  clean testing loss: 0.12398431450128555
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 76100  training loss: 0.031115295365452766
epoch 76100  clean testing loss: 0.1241503581404686
epoch 76200  training loss: 0.031092537567019463

 77%|████████████████████████████████████████████████████████████████▍                   | 76640/100000 [04:02<01:52, 207.60it/s]
epoch 76300  training loss: 0.031095430254936218
epoch 76300  clean testing loss: 0.12419401854276657
epoch 76400  training loss: 0.031085243448615074
epoch 76400  clean testing loss: 0.12401876598596573
epoch 76500  training loss: 0.031095387414097786
epoch 76500  clean testing loss: 0.12436104565858841
epoch 76600  training loss: 0.031114259734749794

 77%|████████████████████████████████████████████████████████████████▋                   | 77030/100000 [04:04<02:06, 182.02it/s]
epoch 76700  training loss: 0.031099921092391014
epoch 76700  clean testing loss: 0.12418399751186371
epoch 76800  training loss: 0.03110636956989765
epoch 76800  clean testing loss: 0.12412817031145096
epoch 76900  training loss: 0.031059427186846733
epoch 76900  clean testing loss: 0.12413626164197922
epoch 77000  training loss: 0.031079325824975967
epoch 77000  clean testing loss: 0.12414583563804626

 77%|█████████████████████████████████████████████████████████████████                   | 77387/100000 [04:06<02:05, 180.19it/s]
epoch 77100  training loss: 0.031064435839653015
epoch 77100  clean testing loss: 0.12433025240898132
epoch 77200  training loss: 0.031058087944984436
epoch 77200  clean testing loss: 0.124239981174469
epoch 77300  training loss: 0.031064830720424652
epoch 77300  clean testing loss: 0.124171182513237
epoch 77400  training loss: 0.031055396422743797

 78%|█████████████████████████████████████████████████████████████████▎                  | 77742/100000 [04:08<02:06, 175.39it/s]
epoch 77500  training loss: 0.031061705201864243
epoch 77500  clean testing loss: 0.12427592277526855
epoch 77600  training loss: 0.031068166717886925
epoch 77600  clean testing loss: 0.12424512207508087
epoch 77700  training loss: 0.031038859859108925

 78%|█████████████████████████████████████████████████████████████████▌                  | 78098/100000 [04:10<02:04, 176.47it/s]
epoch 77800  training loss: 0.031038638204336166
epoch 77800  clean testing loss: 0.12429229170084
epoch 77900  training loss: 0.03105451539158821
epoch 77900  clean testing loss: 0.12438485026359558
epoch 78000  training loss: 0.031045163050293922
epoch 78000  clean testing loss: 0.12433724105358124
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 78100  training loss: 0.031045876443386078

 78%|█████████████████████████████████████████████████████████████████▉                  | 78457/100000 [04:12<02:01, 177.03it/s]
epoch 78200  training loss: 0.031062472611665726
epoch 78200  clean testing loss: 0.12448451668024063
epoch 78300  training loss: 0.03104238398373127
epoch 78300  clean testing loss: 0.12426705658435822
epoch 78400  training loss: 0.031050607562065125

 79%|██████████████████████████████████████████████████████████████████▏                 | 78811/100000 [04:14<01:58, 178.30it/s]
epoch 78500  training loss: 0.031008955091238022
epoch 78500  clean testing loss: 0.12449097633361816
epoch 78600  training loss: 0.031042009592056274
epoch 78600  clean testing loss: 0.12440149486064911
epoch 78700  training loss: 0.031028026714920998
epoch 78700  clean testing loss: 0.12451556324958801
epoch 78800  training loss: 0.031019248068332672

 79%|██████████████████████████████████████████████████████████████████▍                 | 79162/100000 [04:16<02:00, 173.60it/s]
epoch 78900  training loss: 0.03103269264101982
epoch 78900  clean testing loss: 0.12458271533250809
epoch 79000  training loss: 0.031026571989059448
epoch 79000  clean testing loss: 0.12470926344394684
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 79100  training loss: 0.031024130061268806

 80%|██████████████████████████████████████████████████████████████████▊                 | 79515/100000 [04:18<01:56, 176.43it/s]
epoch 79200  training loss: 0.030989298596978188
epoch 79200  clean testing loss: 0.1245771050453186
epoch 79300  training loss: 0.031006677076220512
epoch 79300  clean testing loss: 0.1246192529797554
epoch 79400  training loss: 0.03096727654337883
epoch 79400  clean testing loss: 0.12475661933422089
epoch 79500  training loss: 0.03100317157804966

 80%|███████████████████████████████████████████████████████████████████                 | 79868/100000 [04:20<01:52, 178.66it/s]
epoch 79600  training loss: 0.031003301963210106
epoch 79600  clean testing loss: 0.12475212663412094
epoch 79700  training loss: 0.030988629907369614
epoch 79700  clean testing loss: 0.1246381625533104
epoch 79800  training loss: 0.030998744070529938

 80%|███████████████████████████████████████████████████████████████████▍                | 80219/100000 [04:22<01:53, 173.77it/s]
epoch 79900  training loss: 0.030998224392533302
epoch 79900  clean testing loss: 0.12469317018985748
epoch 80000  training loss: 0.030965279787778854
epoch 80000  clean testing loss: 0.12476300448179245
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 80100  training loss: 0.031015317887067795
epoch 80100  clean testing loss: 0.12478041648864746
epoch 80200  training loss: 0.030991315841674805

 81%|███████████████████████████████████████████████████████████████████▋                | 80590/100000 [04:24<01:51, 173.67it/s]
epoch 80300  training loss: 0.030988309532403946
epoch 80300  clean testing loss: 0.12478505820035934
epoch 80400  training loss: 0.030981123447418213
epoch 80400  clean testing loss: 0.12461458146572113
epoch 80500  training loss: 0.03096752241253853
epoch 80500  clean testing loss: 0.1246945858001709
epoch 80600  training loss: 0.030945023521780968

 81%|███████████████████████████████████████████████████████████████████▉                | 80943/100000 [04:26<01:47, 176.66it/s]
epoch 80700  training loss: 0.030977413058280945
epoch 80700  clean testing loss: 0.12457709014415741
epoch 80800  training loss: 0.030970189720392227
epoch 80800  clean testing loss: 0.1247074231505394
epoch 80900  training loss: 0.03096082992851734

 81%|████████████████████████████████████████████████████████████████████▎               | 81297/100000 [04:28<01:44, 178.63it/s]
epoch 81000  training loss: 0.030958378687500954
epoch 81000  clean testing loss: 0.1248089149594307
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 81100  training loss: 0.030940767377614975
epoch 81100  clean testing loss: 0.12476940453052521
epoch 81200  training loss: 0.03095589578151703
epoch 81200  clean testing loss: 0.12494732439517975
epoch 81300  training loss: 0.030958443880081177

 82%|████████████████████████████████████████████████████████████████████▌               | 81649/100000 [04:30<01:45, 173.71it/s]
epoch 81400  training loss: 0.03094593435525894
epoch 81400  clean testing loss: 0.12486804276704788
epoch 81500  training loss: 0.030923156067728996
epoch 81500  clean testing loss: 0.12492772936820984
epoch 81600  training loss: 0.030970217660069466

 82%|████████████████████████████████████████████████████████████████████▉               | 82002/100000 [04:32<01:41, 176.80it/s]
epoch 81700  training loss: 0.030929720029234886
epoch 81700  clean testing loss: 0.12495105713605881
epoch 81800  training loss: 0.030940109863877296
epoch 81800  clean testing loss: 0.1250443309545517
epoch 81900  training loss: 0.03092007152736187
epoch 81900  clean testing loss: 0.12506282329559326
epoch 82000  training loss: 0.030938932672142982
epoch 82000  clean testing loss: 0.12495126575231552

 82%|█████████████████████████████████████████████████████████████████████▏              | 82355/100000 [04:34<01:38, 178.64it/s]
epoch 82100  training loss: 0.03090512752532959
epoch 82100  clean testing loss: 0.12492971867322922
epoch 82200  training loss: 0.030900834128260612
epoch 82200  clean testing loss: 0.1250200718641281
epoch 82300  training loss: 0.03092053346335888

 83%|█████████████████████████████████████████████████████████████████████▍              | 82706/100000 [04:36<01:39, 173.83it/s]
epoch 82400  training loss: 0.030928712338209152
epoch 82400  clean testing loss: 0.1251789629459381
epoch 82500  training loss: 0.030909322202205658
epoch 82500  clean testing loss: 0.12517279386520386
epoch 82600  training loss: 0.030923310667276382
epoch 82600  clean testing loss: 0.1251470148563385
epoch 82700  training loss: 0.03089182823896408

 83%|█████████████████████████████████████████████████████████████████████▊              | 83061/100000 [04:38<01:36, 175.87it/s]
epoch 82800  training loss: 0.03091655857861042
epoch 82800  clean testing loss: 0.12495443969964981
epoch 82900  training loss: 0.0308915376663208
epoch 82900  clean testing loss: 0.1251799762248993
epoch 83000  training loss: 0.03087315708398819
epoch 83000  clean testing loss: 0.12524980306625366

 83%|██████████████████████████████████████████████████████████████████████              | 83414/100000 [04:40<01:32, 178.76it/s]
epoch 83100  training loss: 0.03086012601852417
epoch 83100  clean testing loss: 0.12510724365711212
epoch 83200  training loss: 0.030854713171720505
epoch 83200  clean testing loss: 0.1251523494720459
epoch 83300  training loss: 0.030858386307954788
epoch 83300  clean testing loss: 0.12516288459300995
epoch 83400  training loss: 0.030872875824570656

 84%|██████████████████████████████████████████████████████████████████████▍             | 83785/100000 [04:42<01:30, 179.09it/s]
epoch 83500  training loss: 0.030858147889375687
epoch 83500  clean testing loss: 0.12516765296459198
epoch 83600  training loss: 0.03085033968091011
epoch 83600  clean testing loss: 0.12526234984397888
epoch 83700  training loss: 0.030873335897922516

 84%|██████████████████████████████████████████████████████████████████████▋             | 84137/100000 [04:44<01:31, 174.10it/s]
epoch 83800  training loss: 0.03087165206670761
epoch 83800  clean testing loss: 0.12526825070381165
epoch 83900  training loss: 0.030863003805279732
epoch 83900  clean testing loss: 0.1252906322479248
epoch 84000  training loss: 0.030889665707945824
epoch 84000  clean testing loss: 0.12542611360549927
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 84100  training loss: 0.030855633318424225

 84%|██████████████████████████████████████████████████████████████████████▉             | 84490/100000 [04:46<01:27, 176.45it/s]
epoch 84200  training loss: 0.03084072656929493
epoch 84200  clean testing loss: 0.12532317638397217
epoch 84300  training loss: 0.030882950872182846
epoch 84300  clean testing loss: 0.125310480594635
epoch 84400  training loss: 0.030880482867360115

 85%|███████████████████████████████████████████████████████████████████████▎            | 84844/100000 [04:48<01:24, 178.67it/s]
epoch 84500  training loss: 0.03086245059967041
epoch 84500  clean testing loss: 0.12538273632526398
epoch 84600  training loss: 0.030853619799017906
epoch 84600  clean testing loss: 0.12530046701431274
epoch 84700  training loss: 0.030880028381943703
epoch 84700  clean testing loss: 0.1254740208387375
epoch 84800  training loss: 0.03087572194635868

 85%|███████████████████████████████████████████████████████████████████████▌            | 85195/100000 [04:50<01:25, 173.83it/s]
epoch 84900  training loss: 0.03085976466536522
epoch 84900  clean testing loss: 0.12538357079029083
epoch 85000  training loss: 0.03085455857217312
epoch 85000  clean testing loss: 0.12541833519935608
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 85100  training loss: 0.030855176970362663
epoch 85100  clean testing loss: 0.1254744529724121
epoch 85200  training loss: 0.03083409182727337

 86%|███████████████████████████████████████████████████████████████████████▊            | 85548/100000 [04:52<01:21, 176.94it/s]
epoch 85300  training loss: 0.03082146868109703
epoch 85300  clean testing loss: 0.12540993094444275
epoch 85400  training loss: 0.030835825949907303
epoch 85400  clean testing loss: 0.12539052963256836
epoch 85500  training loss: 0.03081340529024601

 86%|████████████████████████████████████████████████████████████████████████▏           | 85901/100000 [04:54<01:18, 179.60it/s]
epoch 85600  training loss: 0.030860017985105515
epoch 85600  clean testing loss: 0.12531138956546783
epoch 85700  training loss: 0.03082224726676941
epoch 85700  clean testing loss: 0.12540176510810852
epoch 85800  training loss: 0.030820589512586594
epoch 85800  clean testing loss: 0.12550921738147736
epoch 85900  training loss: 0.030848663300275803

 86%|████████████████████████████████████████████████████████████████████████▍           | 86251/100000 [04:56<01:18, 174.59it/s]
epoch 86000  training loss: 0.03084227442741394
epoch 86000  clean testing loss: 0.12560854852199554
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 86100  training loss: 0.03084411472082138
epoch 86100  clean testing loss: 0.12553367018699646
epoch 86200  training loss: 0.030858919024467468

 87%|████████████████████████████████████████████████████████████████████████▋           | 86605/100000 [04:58<01:16, 175.85it/s]
epoch 86300  training loss: 0.030862269923090935
epoch 86300  clean testing loss: 0.12558101117610931
epoch 86400  training loss: 0.030824095010757446
epoch 86400  clean testing loss: 0.12543077766895294
epoch 86500  training loss: 0.030847160145640373
epoch 86500  clean testing loss: 0.1255645602941513
epoch 86600  training loss: 0.03082648105919361

 87%|█████████████████████████████████████████████████████████████████████████           | 86958/100000 [05:00<01:12, 179.37it/s]
epoch 86700  training loss: 0.030790770426392555
epoch 86700  clean testing loss: 0.12560579180717468
epoch 86800  training loss: 0.030811402946710587
epoch 86800  clean testing loss: 0.12567338347434998
epoch 86900  training loss: 0.030796043574810028

 87%|█████████████████████████████████████████████████████████████████████████▎          | 87329/100000 [05:02<01:10, 179.13it/s]
epoch 87000  training loss: 0.030806712806224823
epoch 87000  clean testing loss: 0.12570495903491974
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 87100  training loss: 0.030833298340439796
epoch 87100  clean testing loss: 0.12557508051395416
epoch 87200  training loss: 0.030820023268461227
epoch 87200  clean testing loss: 0.12576603889465332
epoch 87300  training loss: 0.030801543965935707

 88%|█████████████████████████████████████████████████████████████████████████▋          | 87680/100000 [05:04<01:10, 174.60it/s]
epoch 87400  training loss: 0.03077547997236252
epoch 87400  clean testing loss: 0.12575264275074005
epoch 87500  training loss: 0.030787840485572815
epoch 87500  clean testing loss: 0.12567269802093506
epoch 87600  training loss: 0.030775025486946106

 88%|█████████████████████████████████████████████████████████████████████████▉          | 88032/100000 [05:06<01:07, 176.86it/s]
epoch 87700  training loss: 0.030762773007154465
epoch 87700  clean testing loss: 0.1256169080734253
epoch 87800  training loss: 0.030792243778705597
epoch 87800  clean testing loss: 0.1257808804512024
epoch 87900  training loss: 0.03080037422478199
epoch 87900  clean testing loss: 0.1256715953350067
epoch 88000  training loss: 0.030787775292992592
epoch 88000  clean testing loss: 0.12573352456092834

 88%|██████████████████████████████████████████████████████████████████████████▏         | 88384/100000 [05:08<01:04, 179.36it/s]
epoch 88100  training loss: 0.03076011873781681
epoch 88100  clean testing loss: 0.12583844363689423
epoch 88200  training loss: 0.03077572211623192
epoch 88200  clean testing loss: 0.12593384087085724
epoch 88300  training loss: 0.030759142711758614

 89%|██████████████████████████████████████████████████████████████████████████▌         | 88743/100000 [05:10<01:04, 175.36it/s]
epoch 88400  training loss: 0.030791711062192917
epoch 88400  clean testing loss: 0.12585881352424622
epoch 88500  training loss: 0.03078567050397396
epoch 88500  clean testing loss: 0.12582050263881683
epoch 88600  training loss: 0.030774954706430435
epoch 88600  clean testing loss: 0.1256573647260666
epoch 88700  training loss: 0.03073081746697426

 89%|██████████████████████████████████████████████████████████████████████████▊         | 89097/100000 [05:12<01:01, 176.51it/s]
epoch 88800  training loss: 0.030766533687710762
epoch 88800  clean testing loss: 0.1257978230714798
epoch 88900  training loss: 0.030762216076254845
epoch 88900  clean testing loss: 0.12586890161037445
epoch 89000  training loss: 0.03074686974287033
epoch 89000  clean testing loss: 0.1257721483707428

 89%|███████████████████████████████████████████████████████████████████████████▏        | 89450/100000 [05:14<00:59, 178.67it/s]
epoch 89100  training loss: 0.030748216435313225
epoch 89100  clean testing loss: 0.1258450746536255
epoch 89200  training loss: 0.03075719252228737
epoch 89200  clean testing loss: 0.12587541341781616
epoch 89300  training loss: 0.030774883925914764
epoch 89300  clean testing loss: 0.12596380710601807
epoch 89400  training loss: 0.030774034559726715

 90%|███████████████████████████████████████████████████████████████████████████▍        | 89802/100000 [05:16<00:58, 174.69it/s]
epoch 89500  training loss: 0.0307670496404171
epoch 89500  clean testing loss: 0.12587910890579224
epoch 89600  training loss: 0.030770184472203255
epoch 89600  clean testing loss: 0.12575595080852509
epoch 89700  training loss: 0.030727345496416092
epoch 89700  clean testing loss: 0.1257684826850891
epoch 89800  training loss: 0.030735764652490616

 90%|███████████████████████████████████████████████████████████████████████████▋        | 90155/100000 [05:18<00:55, 176.51it/s]
epoch 89900  training loss: 0.030749665573239326
epoch 89900  clean testing loss: 0.12583604454994202
epoch 90000  training loss: 0.030754486098885536
epoch 90000  clean testing loss: 0.12580640614032745
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 90100  training loss: 0.0307316891849041

 91%|████████████████████████████████████████████████████████████████████████████        | 90508/100000 [05:20<00:53, 178.73it/s]
epoch 90200  training loss: 0.03074808232486248
epoch 90200  clean testing loss: 0.1258820742368698
epoch 90300  training loss: 0.030734844505786896
epoch 90300  clean testing loss: 0.12590114772319794
epoch 90400  training loss: 0.03071567974984646
epoch 90400  clean testing loss: 0.12587207555770874
epoch 90500  training loss: 0.030714325606822968

 91%|████████████████████████████████████████████████████████████████████████████▎       | 90879/100000 [05:22<00:51, 178.67it/s]
epoch 90600  training loss: 0.030717240646481514
epoch 90600  clean testing loss: 0.12586748600006104
epoch 90700  training loss: 0.0307476706802845
epoch 90700  clean testing loss: 0.12581844627857208
epoch 90800  training loss: 0.030731581151485443

 91%|████████████████████████████████████████████████████████████████████████████▋       | 91231/100000 [05:24<00:50, 173.78it/s]
epoch 90900  training loss: 0.03073064610362053
epoch 90900  clean testing loss: 0.1259005069732666
epoch 91000  training loss: 0.030737604945898056
epoch 91000  clean testing loss: 0.1260162591934204
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 91100  training loss: 0.030693626031279564
epoch 91100  clean testing loss: 0.12605544924736023
epoch 91200  training loss: 0.030703362077474594

 92%|████████████████████████████████████████████████████████████████████████████▉       | 91585/100000 [05:26<00:47, 176.54it/s]
epoch 91300  training loss: 0.030712023377418518
epoch 91300  clean testing loss: 0.12591934204101562
epoch 91400  training loss: 0.03072482720017433
epoch 91400  clean testing loss: 0.12590882182121277
epoch 91500  training loss: 0.03070664219558239

 92%|█████████████████████████████████████████████████████████████████████████████▏      | 91939/100000 [05:28<00:45, 178.86it/s]
epoch 91600  training loss: 0.030698232352733612
epoch 91600  clean testing loss: 0.12593823671340942
epoch 91700  training loss: 0.03070903569459915
epoch 91700  clean testing loss: 0.1259308010339737
epoch 91800  training loss: 0.030702657997608185
epoch 91800  clean testing loss: 0.12595704197883606
epoch 91900  training loss: 0.030718030408024788

 92%|█████████████████████████████████████████████████████████████████████████████▌      | 92291/100000 [05:30<00:44, 174.35it/s]
epoch 92000  training loss: 0.030728287994861603
epoch 92000  clean testing loss: 0.12607301771640778
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 92100  training loss: 0.030721982941031456
epoch 92100  clean testing loss: 0.1258877068758011
epoch 92200  training loss: 0.03073049522936344

 93%|█████████████████████████████████████████████████████████████████████████████▊      | 92644/100000 [05:32<00:41, 176.64it/s]
epoch 92300  training loss: 0.030718987807631493
epoch 92300  clean testing loss: 0.125982865691185
epoch 92400  training loss: 0.03070683963596821
epoch 92400  clean testing loss: 0.12600229680538177
epoch 92500  training loss: 0.03069516085088253
epoch 92500  clean testing loss: 0.12601719796657562
epoch 92600  training loss: 0.030678225681185722

 93%|██████████████████████████████████████████████████████████████████████████████      | 92997/100000 [05:34<00:39, 178.75it/s]
epoch 92700  training loss: 0.030682431533932686
epoch 92700  clean testing loss: 0.12611539661884308
epoch 92800  training loss: 0.0307009294629097
epoch 92800  clean testing loss: 0.12607483565807343
epoch 92900  training loss: 0.030678313225507736

 93%|██████████████████████████████████████████████████████████████████████████████▍     | 93349/100000 [05:36<00:38, 173.72it/s]
epoch 93000  training loss: 0.030684838071465492
epoch 93000  clean testing loss: 0.12618283927440643
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 93100  training loss: 0.0307038351893425
epoch 93100  clean testing loss: 0.1261003166437149
epoch 93200  training loss: 0.030680406838655472
epoch 93200  clean testing loss: 0.12615446746349335
epoch 93300  training loss: 0.03069433383643627

 94%|██████████████████████████████████████████████████████████████████████████████▋     | 93703/100000 [05:38<00:35, 176.67it/s]
epoch 93400  training loss: 0.030682828277349472
epoch 93400  clean testing loss: 0.12608014047145844
epoch 93500  training loss: 0.030678369104862213
epoch 93500  clean testing loss: 0.12611649930477142
epoch 93600  training loss: 0.030679166316986084
epoch 93600  clean testing loss: 0.12608474493026733
epoch 93700  training loss: 0.030676906928420067

 94%|███████████████████████████████████████████████████████████████████████████████     | 94057/100000 [05:40<00:33, 178.00it/s]
epoch 93800  training loss: 0.030680786818265915
epoch 93800  clean testing loss: 0.1260056346654892
epoch 93900  training loss: 0.030690304934978485
epoch 93900  clean testing loss: 0.12602420151233673
epoch 94000  training loss: 0.030662957578897476
epoch 94000  clean testing loss: 0.1261189579963684

 94%|███████████████████████████████████████████████████████████████████████████████▎    | 94428/100000 [05:42<00:31, 178.90it/s]
epoch 94100  training loss: 0.03066072054207325
epoch 94100  clean testing loss: 0.12612852454185486
epoch 94200  training loss: 0.0306654404848814
epoch 94200  clean testing loss: 0.12617558240890503
epoch 94300  training loss: 0.030679849907755852
epoch 94300  clean testing loss: 0.12610091269016266
epoch 94400  training loss: 0.03068593703210354

 95%|███████████████████████████████████████████████████████████████████████████████▌    | 94780/100000 [05:44<00:29, 174.61it/s]
epoch 94500  training loss: 0.030691854655742645
epoch 94500  clean testing loss: 0.12611091136932373
epoch 94600  training loss: 0.030682409182190895
epoch 94600  clean testing loss: 0.12616921961307526
epoch 94700  training loss: 0.030656922608613968

 95%|███████████████████████████████████████████████████████████████████████████████▉    | 95134/100000 [05:46<00:27, 176.77it/s]
epoch 94800  training loss: 0.030630921944975853
epoch 94800  clean testing loss: 0.12616373598575592
epoch 94900  training loss: 0.030657926574349403
epoch 94900  clean testing loss: 0.12620128691196442
epoch 95000  training loss: 0.030659107491374016
epoch 95000  clean testing loss: 0.12623386085033417
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 95100  training loss: 0.03066941723227501

 95%|████████████████████████████████████████████████████████████████████████████████▏   | 95488/100000 [05:48<00:25, 178.49it/s]
epoch 95200  training loss: 0.03068212978541851
epoch 95200  clean testing loss: 0.12615621089935303
epoch 95300  training loss: 0.030674343928694725
epoch 95300  clean testing loss: 0.1262018382549286
epoch 95400  training loss: 0.03067711740732193

 96%|████████████████████████████████████████████████████████████████████████████████▌   | 95840/100000 [05:50<00:23, 174.74it/s]
epoch 95500  training loss: 0.030670171603560448
epoch 95500  clean testing loss: 0.1261885166168213
epoch 95600  training loss: 0.030630948022007942
epoch 95600  clean testing loss: 0.12622444331645966
epoch 95700  training loss: 0.030665947124361992
epoch 95700  clean testing loss: 0.126193568110466
epoch 95800  training loss: 0.03066328540444374

 96%|████████████████████████████████████████████████████████████████████████████████▊   | 96192/100000 [05:52<00:21, 176.66it/s]
epoch 95900  training loss: 0.03064616769552231
epoch 95900  clean testing loss: 0.1261809915304184
epoch 96000  training loss: 0.03065732680261135
epoch 96000  clean testing loss: 0.1261901706457138
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 96100  training loss: 0.030639469623565674

 97%|█████████████████████████████████████████████████████████████████████████████████   | 96545/100000 [05:54<00:19, 178.85it/s]
epoch 96200  training loss: 0.03067176789045334
epoch 96200  clean testing loss: 0.12611611187458038
epoch 96300  training loss: 0.030619405210018158
epoch 96300  clean testing loss: 0.1261514574289322
epoch 96400  training loss: 0.030617818236351013
epoch 96400  clean testing loss: 0.12615904211997986
epoch 96500  training loss: 0.030620092526078224

 97%|█████████████████████████████████████████████████████████████████████████████████▍  | 96896/100000 [05:56<00:17, 175.01it/s]
epoch 96600  training loss: 0.030638694763183594
epoch 96600  clean testing loss: 0.126106396317482
epoch 96700  training loss: 0.030638452619314194
epoch 96700  clean testing loss: 0.12633398175239563
epoch 96800  training loss: 0.030652642250061035

 97%|█████████████████████████████████████████████████████████████████████████████████▋  | 97266/100000 [05:58<00:15, 173.96it/s]
epoch 96900  training loss: 0.030657649040222168
epoch 96900  clean testing loss: 0.12624262273311615
epoch 97000  training loss: 0.030647793784737587
epoch 97000  clean testing loss: 0.12620897591114044
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 97100  training loss: 0.03064296394586563
epoch 97100  clean testing loss: 0.12617680430412292
epoch 97200  training loss: 0.030631905421614647

 98%|█████████████████████████████████████████████████████████████████████████████████▉  | 97619/100000 [06:00<00:13, 176.81it/s]
epoch 97300  training loss: 0.030627261847257614
epoch 97300  clean testing loss: 0.12623101472854614
epoch 97400  training loss: 0.030611051246523857
epoch 97400  clean testing loss: 0.12626907229423523
epoch 97500  training loss: 0.030632970854640007
epoch 97500  clean testing loss: 0.12637005746364594
epoch 97600  training loss: 0.03062269650399685

 98%|██████████████████████████████████████████████████████████████████████████████████▎ | 97972/100000 [06:02<00:11, 178.95it/s]
epoch 97700  training loss: 0.03061280958354473
epoch 97700  clean testing loss: 0.12627007067203522
epoch 97800  training loss: 0.03058907762169838
epoch 97800  clean testing loss: 0.12627051770687103
epoch 97900  training loss: 0.030606098473072052

 98%|██████████████████████████████████████████████████████████████████████████████████▌ | 98327/100000 [06:04<00:09, 175.25it/s]
epoch 98000  training loss: 0.030605686828494072
epoch 98000  clean testing loss: 0.1262398064136505
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 98100  training loss: 0.03061920776963234
epoch 98100  clean testing loss: 0.1262548565864563
epoch 98200  training loss: 0.030602576211094856
epoch 98200  clean testing loss: 0.12632852792739868
epoch 98300  training loss: 0.03060540370643139

 99%|██████████████████████████████████████████████████████████████████████████████████▉ | 98685/100000 [06:06<00:07, 174.25it/s]
epoch 98400  training loss: 0.03063761442899704
epoch 98400  clean testing loss: 0.12636646628379822
epoch 98500  training loss: 0.03062273934483528
epoch 98500  clean testing loss: 0.12641772627830505
epoch 98600  training loss: 0.03061983548104763

 99%|███████████████████████████████████████████████████████████████████████████████████▏| 99040/100000 [06:08<00:05, 177.35it/s]
epoch 98700  training loss: 0.03063681721687317
epoch 98700  clean testing loss: 0.12640172243118286
epoch 98800  training loss: 0.030611902475357056
epoch 98800  clean testing loss: 0.12634381651878357
epoch 98900  training loss: 0.030613800510764122
epoch 98900  clean testing loss: 0.12635888159275055
epoch 99000  training loss: 0.0306098610162735
epoch 99000  clean testing loss: 0.12628483772277832

 99%|███████████████████████████████████████████████████████████████████████████████████▍| 99393/100000 [06:10<00:03, 179.05it/s]
epoch 99100  training loss: 0.03061773255467415
epoch 99100  clean testing loss: 0.1263430416584015
epoch 99200  training loss: 0.03061743639409542
epoch 99200  clean testing loss: 0.12618812918663025
epoch 99300  training loss: 0.030624741688370705

100%|███████████████████████████████████████████████████████████████████████████████████▊| 99744/100000 [06:12<00:01, 174.25it/s]
epoch 99400  training loss: 0.030631138011813164
epoch 99400  clean testing loss: 0.12638376653194427
epoch 99500  training loss: 0.030615143477916718
epoch 99500  clean testing loss: 0.12627117335796356
epoch 99600  training loss: 0.030608301982283592
epoch 99600  clean testing loss: 0.1263962686061859
epoch 99700  training loss: 0.0306209996342659

100%|███████████████████████████████████████████████████████████████████████████████████| 100000/100000 [06:13<00:00, 267.39it/s]
epoch 99800  training loss: 0.030616797506809235
epoch 99800  clean testing loss: 0.12627826631069183
epoch 99900  training loss: 0.030643513426184654
epoch 99900  clean testing loss: 0.12631984055042267
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers3_relu_size500_noise1.00e-01_invop0_lr0.005 ...