
  0%|                                                                                | 89/100000 [00:01<23:20, 71.32it/s]
epoch 0  training loss: 45.886810302734375
epoch 0  clean testing loss: 43.17939376831055
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 100  training loss: 0.5328724384307861

  0%|▏                                                                              | 233/100000 [00:03<23:01, 72.21it/s]
epoch 200  training loss: 0.5026064515113831

  0%|▎                                                                              | 374/100000 [00:05<26:33, 62.53it/s]
epoch 300  training loss: 0.4959971308708191

  0%|▍                                                                              | 494/100000 [00:07<28:16, 58.65it/s]
epoch 400  training loss: 0.4921886622905731
epoch 400  clean testing loss: 0.019583124667406082
epoch 500  training loss: 0.4896167814731598

  1%|▍                                                                              | 603/100000 [00:09<32:35, 50.83it/s]
epoch 600  training loss: 0.48771700263023376

  1%|▌                                                                              | 723/100000 [00:11<28:09, 58.77it/s]
epoch 700  training loss: 0.48622241616249084

  1%|▋                                                                              | 843/100000 [00:13<28:10, 58.66it/s]
epoch 800  training loss: 0.48497891426086426

  1%|▊                                                                              | 958/100000 [00:15<27:55, 59.11it/s]
epoch 900  training loss: 0.48384156823158264

  1%|▊                                                                             | 1095/100000 [00:17<22:36, 72.90it/s]
epoch 1000  training loss: 0.48272302746772766
epoch 1000  clean testing loss: 0.025064321234822273
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 1100  training loss: 0.4815447926521301

  1%|▉                                                                             | 1239/100000 [00:19<22:45, 72.30it/s]
epoch 1200  training loss: 0.4802597165107727

  1%|█                                                                             | 1383/100000 [00:21<22:29, 73.09it/s]
epoch 1300  training loss: 0.4788069427013397

  2%|█▏                                                                            | 1535/100000 [00:23<22:33, 72.74it/s]
epoch 1400  training loss: 0.4771367907524109
epoch 1400  clean testing loss: 0.029018379747867584
epoch 1500  training loss: 0.47517630457878113

  2%|█▎                                                                            | 1679/100000 [00:25<22:29, 72.86it/s]
epoch 1600  training loss: 0.47283798456192017

  2%|█▍                                                                            | 1799/100000 [00:27<22:35, 72.47it/s]
epoch 1700  training loss: 0.4699989855289459

  2%|█▌                                                                            | 1967/100000 [00:29<22:23, 72.96it/s]
epoch 1800  training loss: 0.4665049612522125
epoch 1800  clean testing loss: 0.03709007427096367
epoch 1900  training loss: 0.4622276723384857

  2%|█▋                                                                            | 2119/100000 [00:31<22:25, 72.75it/s]
epoch 2000  training loss: 0.45704570412635803
epoch 2000  clean testing loss: 0.04593058302998543
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 2100  training loss: 0.4506492018699646

  2%|█▊                                                                            | 2263/100000 [00:33<22:32, 72.28it/s]
epoch 2200  training loss: 0.44287917017936707

  2%|█▉                                                                            | 2407/100000 [00:35<22:25, 72.51it/s]
epoch 2300  training loss: 0.4345550239086151
epoch 2300  clean testing loss: 0.0802268460392952
epoch 2400  training loss: 0.4248870611190796

  3%|█▉                                                                            | 2551/100000 [00:37<22:17, 72.87it/s]
epoch 2500  training loss: 0.41056767106056213

  3%|██                                                                            | 2703/100000 [00:39<22:10, 73.15it/s]
epoch 2600  training loss: 0.39695802330970764
epoch 2600  clean testing loss: 0.13952048122882843
epoch 2700  training loss: 0.3834351599216461

  3%|██▏                                                                           | 2847/100000 [00:41<22:17, 72.64it/s]
epoch 2800  training loss: 0.3721767067909241

  3%|██▎                                                                           | 2887/100000 [00:42<22:11, 72.95it/s]
epoch 2900  training loss: 0.36489027738571167
epoch 2900  clean testing loss: 0.18739144504070282
epoch 3000  training loss: 0.35818642377853394
epoch 3000  clean testing loss: 0.20199711620807648
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 3100  training loss: 0.3527572751045227
epoch 3100  clean testing loss: 0.21730154752731323
epoch 3200  training loss: 0.3473896086215973
epoch 3200  clean testing loss: 0.2350303679704666
epoch 3300  training loss: 0.34236854314804077
epoch 3300  clean testing loss: 0.25346624851226807
epoch 3400  training loss: 0.3375331461429596
epoch 3400  clean testing loss: 0.2712019085884094
epoch 3500  training loss: 0.3326370418071747
epoch 3500  clean testing loss: 0.2873932421207428
epoch 3600  training loss: 0.3275030851364136
epoch 3600  clean testing loss: 0.3018275797367096
epoch 3700  training loss: 0.32208386063575745

  4%|███                                                                           | 3871/100000 [00:55<22:01, 72.73it/s]
epoch 3800  training loss: 0.31670811772346497
epoch 3800  clean testing loss: 0.3271433115005493
epoch 3900  training loss: 0.310059517621994

  4%|███▏                                                                          | 4015/100000 [00:57<22:26, 71.27it/s]
epoch 4000  training loss: 0.29999840259552
epoch 4000  clean testing loss: 0.34723395109176636

  4%|███▏                                                                          | 4159/100000 [00:59<21:54, 72.88it/s]
epoch 4100  training loss: 0.2912071645259857
epoch 4100  clean testing loss: 0.3604368567466736
epoch 4200  training loss: 0.2823059856891632

  4%|███▎                                                                          | 4303/100000 [01:01<21:58, 72.59it/s]
epoch 4300  training loss: 0.2732005715370178

  4%|███▍                                                                          | 4455/100000 [01:03<21:55, 72.61it/s]
epoch 4400  training loss: 0.2638985216617584

  5%|███▌                                                                          | 4599/100000 [01:05<21:52, 72.70it/s]
epoch 4500  training loss: 0.2541177570819855
epoch 4500  clean testing loss: 0.49862203001976013
epoch 4600  training loss: 0.24661463499069214

  5%|███▋                                                                          | 4743/100000 [01:07<21:46, 72.89it/s]
epoch 4700  training loss: 0.2398419976234436

  5%|███▊                                                                          | 4887/100000 [01:09<21:39, 73.22it/s]
epoch 4800  training loss: 0.23389160633087158
epoch 4800  clean testing loss: 0.7685559391975403
epoch 4900  training loss: 0.2287372350692749

  5%|███▉                                                                          | 5039/100000 [01:11<21:54, 72.22it/s]
epoch 5000  training loss: 0.22399106621742249
epoch 5000  clean testing loss: 0.9030625820159912

  5%|████                                                                          | 5183/100000 [01:13<21:43, 72.71it/s]
epoch 5100  training loss: 0.21963275969028473
epoch 5100  clean testing loss: 0.9509337544441223
epoch 5200  training loss: 0.2152547985315323

  5%|████▏                                                                         | 5327/100000 [01:15<21:43, 72.65it/s]
epoch 5300  training loss: 0.21071133017539978

  5%|████▎                                                                         | 5471/100000 [01:17<21:38, 72.81it/s]
epoch 5400  training loss: 0.2056766152381897

  6%|████▍                                                                         | 5623/100000 [01:19<21:32, 73.00it/s]
epoch 5600  training loss: 0.19522003829479218

  6%|████▍                                                                         | 5767/100000 [01:21<21:32, 72.91it/s]
epoch 5700  training loss: 0.19143998622894287
epoch 5700  clean testing loss: 1.279471516609192
epoch 5800  training loss: 0.1968485713005066

  6%|████▌                                                                         | 5911/100000 [01:23<21:35, 72.65it/s]
epoch 5900  training loss: 0.18370027840137482

  6%|████▋                                                                         | 6055/100000 [01:25<21:36, 72.47it/s]
epoch 6000  training loss: 0.17986881732940674
epoch 6000  clean testing loss: 1.5050809383392334

  6%|████▊                                                                         | 6207/100000 [01:27<21:30, 72.69it/s]
epoch 6100  training loss: 0.1768350899219513
epoch 6100  clean testing loss: 1.5781207084655762
epoch 6200  training loss: 0.17353107035160065

  6%|████▉                                                                         | 6351/100000 [01:29<21:16, 73.34it/s]
epoch 6300  training loss: 0.17097939550876617

  6%|█████                                                                         | 6495/100000 [01:31<21:23, 72.84it/s]
epoch 6400  training loss: 0.16624855995178223

  7%|█████▏                                                                        | 6639/100000 [01:33<21:25, 72.61it/s]
epoch 6500  training loss: 0.16244228184223175
epoch 6500  clean testing loss: 2.0531160831451416
epoch 6600  training loss: 0.1695955991744995

  7%|█████▎                                                                        | 6791/100000 [01:35<21:17, 72.96it/s]
epoch 6700  training loss: 0.15481910109519958

  7%|█████▍                                                                        | 6935/100000 [01:37<21:13, 73.08it/s]
epoch 6800  training loss: 0.1580713540315628
epoch 6800  clean testing loss: 2.7297511100769043
epoch 6900  training loss: 0.14963647723197937

  7%|█████▌                                                                        | 7079/100000 [01:39<21:19, 72.64it/s]
epoch 7000  training loss: 0.14093317091464996
epoch 7000  clean testing loss: 3.306264877319336

  7%|█████▋                                                                        | 7223/100000 [01:41<21:26, 72.13it/s]
epoch 7100  training loss: 0.13768300414085388
epoch 7100  clean testing loss: 3.6156222820281982
epoch 7200  training loss: 0.13337185978889465

  7%|█████▊                                                                        | 7375/100000 [01:43<21:05, 73.19it/s]
epoch 7300  training loss: 0.1336010843515396

  8%|█████▊                                                                        | 7519/100000 [01:45<21:14, 72.55it/s]
epoch 7400  training loss: 0.12587134540081024
epoch 7400  clean testing loss: 4.633138656616211
epoch 7500  training loss: 0.12202845513820648

  8%|█████▉                                                                        | 7663/100000 [01:47<21:07, 72.87it/s]
epoch 7600  training loss: 0.11845968663692474

  8%|██████                                                                        | 7807/100000 [01:49<21:04, 72.93it/s]
epoch 7700  training loss: 0.1210029199719429
epoch 7700  clean testing loss: 5.63590145111084
epoch 7800  training loss: 0.11204919964075089

  8%|██████▏                                                                       | 7959/100000 [01:51<21:05, 72.76it/s]
epoch 7900  training loss: 0.11164392530918121

  8%|██████▎                                                                       | 8103/100000 [01:53<21:04, 72.67it/s]
epoch 8000  training loss: 0.10675250738859177
epoch 8000  clean testing loss: 6.469552516937256

  8%|██████▍                                                                       | 8247/100000 [01:55<21:00, 72.77it/s]
epoch 8100  training loss: 0.10805647820234299
epoch 8100  clean testing loss: 6.729840278625488
epoch 8200  training loss: 0.10223176330327988

  8%|██████▌                                                                       | 8391/100000 [01:57<20:56, 72.90it/s]
epoch 8300  training loss: 0.10059088468551636

  9%|██████▋                                                                       | 8543/100000 [01:59<20:56, 72.77it/s]
epoch 8400  training loss: 0.09894175827503204
epoch 8400  clean testing loss: 7.454292297363281
epoch 8500  training loss: 0.09801986813545227

  9%|██████▋                                                                       | 8593/100000 [02:00<19:00, 80.14it/s]
epoch 8600  training loss: 0.0958714634180069
epoch 8600  clean testing loss: 7.816418647766113
epoch 8700  training loss: 0.0942971259355545
epoch 8700  clean testing loss: 8.029638290405273
epoch 8800  training loss: 0.09272310137748718
epoch 8800  clean testing loss: 8.188310623168945
epoch 8900  training loss: 0.09038195013999939

  9%|██████▉                                                                       | 8940/100000 [02:04<20:44, 73.18it/s]
epoch 9000  training loss: 0.08884000778198242
epoch 9000  clean testing loss: 8.48004150390625

  9%|███████                                                                       | 9092/100000 [02:06<20:52, 72.60it/s]
epoch 9100  training loss: 0.0876351073384285
epoch 9100  clean testing loss: 8.605027198791504
epoch 9200  training loss: 0.08641427755355835

  9%|███████▏                                                                      | 9236/100000 [02:08<20:45, 72.86it/s]
epoch 9300  training loss: 0.08515198528766632


 10%|███████▍                                                                      | 9524/100000 [02:12<20:42, 72.82it/s]
epoch 9400  training loss: 0.08733789622783661
epoch 9400  clean testing loss: 8.956035614013672
epoch 9500  training loss: 0.08260171860456467

 10%|███████▌                                                                      | 9676/100000 [02:14<20:41, 72.73it/s]
epoch 9600  training loss: 0.08139914274215698

 10%|███████▋                                                                      | 9820/100000 [02:16<20:29, 73.34it/s]
epoch 9700  training loss: 0.08078108727931976
epoch 9700  clean testing loss: 9.258840560913086
epoch 9800  training loss: 0.0829773023724556

 10%|███████▊                                                                      | 9964/100000 [02:18<20:32, 73.04it/s]
epoch 9900  training loss: 0.07791217416524887

 10%|███████▊                                                                     | 10108/100000 [02:20<20:33, 72.88it/s]
epoch 10000  training loss: 0.07666604965925217
epoch 10000  clean testing loss: 9.49710750579834
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 10100  training loss: 0.07610300183296204

 10%|███████▉                                                                     | 10260/100000 [02:22<20:28, 73.07it/s]
epoch 10200  training loss: 0.07450243830680847

 10%|████████                                                                     | 10404/100000 [02:24<20:32, 72.72it/s]
epoch 10300  training loss: 0.07344596087932587

 11%|████████                                                                     | 10548/100000 [02:26<20:28, 72.79it/s]
epoch 10400  training loss: 0.07225774228572845
epoch 10400  clean testing loss: 9.771076202392578
epoch 10500  training loss: 0.07113531976938248

 11%|████████▏                                                                    | 10700/100000 [02:28<20:17, 73.33it/s]
epoch 10600  training loss: 0.07007396221160889

 11%|████████▎                                                                    | 10844/100000 [02:30<20:25, 72.74it/s]
epoch 10700  training loss: 0.07099486142396927
epoch 10700  clean testing loss: 9.929451942443848
epoch 10800  training loss: 0.06804928928613663

 11%|████████▍                                                                    | 10988/100000 [02:32<20:21, 72.86it/s]
epoch 10900  training loss: 0.06696218997240067

 11%|████████▌                                                                    | 11132/100000 [02:34<20:17, 73.01it/s]
epoch 11000  training loss: 0.067999929189682
epoch 11000  clean testing loss: 10.060322761535645
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 11100  training loss: 0.0649585872888565

 11%|████████▋                                                                    | 11276/100000 [02:36<20:24, 72.48it/s]
epoch 11200  training loss: 0.06415002793073654

 11%|████████▊                                                                    | 11428/100000 [02:38<20:13, 72.98it/s]
epoch 11300  training loss: 0.06306786090135574
epoch 11300  clean testing loss: 10.220621109008789
epoch 11400  training loss: 0.06260792165994644

 12%|████████▉                                                                    | 11572/100000 [02:40<20:14, 72.81it/s]
epoch 11500  training loss: 0.07283606380224228

 12%|█████████                                                                    | 11716/100000 [02:42<20:10, 72.91it/s]
epoch 11600  training loss: 0.0662941262125969
epoch 11600  clean testing loss: 10.334637641906738
epoch 11700  training loss: 0.059580154716968536

 12%|█████████▏                                                                   | 11860/100000 [02:44<20:13, 72.61it/s]
epoch 11800  training loss: 0.058416567742824554

 12%|█████████▏                                                                   | 12012/100000 [02:47<20:38, 71.02it/s]
epoch 11900  training loss: 0.057533182203769684
epoch 11900  clean testing loss: 10.459561347961426
epoch 12000  training loss: 0.05665653944015503
epoch 12000  clean testing loss: 10.502554893493652
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 12100  training loss: 0.055920880287885666


 12%|█████████▍                                                                   | 12300/100000 [02:50<20:09, 72.53it/s]
epoch 12200  training loss: 0.05515976995229721

 12%|█████████▌                                                                   | 12444/100000 [02:52<20:02, 72.80it/s]
epoch 12300  training loss: 0.05436590686440468
epoch 12300  clean testing loss: 10.624625205993652
epoch 12400  training loss: 0.05354355275630951

 13%|█████████▋                                                                   | 12596/100000 [02:55<20:00, 72.79it/s]
epoch 12500  training loss: 0.05275029316544533

 13%|█████████▊                                                                   | 12740/100000 [02:57<20:01, 72.64it/s]
epoch 12600  training loss: 0.05198092758655548
epoch 12600  clean testing loss: 10.761183738708496
epoch 12700  training loss: 0.051365289837121964

 13%|█████████▉                                                                   | 12884/100000 [02:59<19:51, 73.14it/s]
epoch 12800  training loss: 0.05082356557250023

 13%|██████████                                                                   | 13028/100000 [03:01<20:06, 72.08it/s]
epoch 12900  training loss: 0.0498056560754776
epoch 12900  clean testing loss: 10.927210807800293
epoch 13000  training loss: 0.04901671037077904
epoch 13000  clean testing loss: 10.984108924865723

 13%|██████████▏                                                                  | 13180/100000 [03:03<19:48, 73.08it/s]
epoch 13100  training loss: 0.04831569269299507

 13%|██████████▏                                                                  | 13196/100000 [03:03<19:50, 72.92it/s]
epoch 13200  training loss: 0.04766758903861046

 14%|██████████▋                                                                  | 13947/100000 [03:12<14:50, 96.66it/s]
epoch 13300  training loss: 0.049706585705280304
epoch 13300  clean testing loss: 11.18131160736084
epoch 13400  training loss: 0.04762759804725647
epoch 13400  clean testing loss: 11.269121170043945
epoch 13500  training loss: 0.047170381993055344
epoch 13500  clean testing loss: 11.310914993286133
epoch 13600  training loss: 0.046633604913949966
epoch 13600  clean testing loss: 11.4043550491333
epoch 13700  training loss: 0.04469755291938782
epoch 13700  clean testing loss: 11.466520309448242
epoch 13800  training loss: 0.044516876339912415
epoch 13800  clean testing loss: 11.534529685974121
epoch 13900  training loss: 0.044211335480213165
epoch 13900  clean testing loss: 11.609256744384766
epoch 14000  training loss: 0.043344687670469284
epoch 14000  clean testing loss: 11.699725151062012
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 14100  training loss: 0.042671963572502136
epoch 14100  clean testing loss: 11.778146743774414
epoch 14200  training loss: 0.04216715320944786
epoch 14200  clean testing loss: 11.857054710388184
epoch 14300  training loss: 0.04164645075798035
epoch 14300  clean testing loss: 11.945160865783691
epoch 14400  training loss: 0.041192345321178436
epoch 14400  clean testing loss: 12.018887519836426
epoch 14500  training loss: 0.04086768254637718
epoch 14500  clean testing loss: 12.106913566589355
epoch 14600  training loss: 0.04067498818039894
epoch 14600  clean testing loss: 12.184501647949219
epoch 14700  training loss: 0.040507953613996506
epoch 14700  clean testing loss: 12.290324211120605
epoch 14800  training loss: 0.03957674652338028
epoch 14800  clean testing loss: 12.36674690246582
epoch 14900  training loss: 0.04396003112196922
epoch 14900  clean testing loss: 12.506537437438965
epoch 15000  training loss: 0.039063211530447006
epoch 15000  clean testing loss: 12.558934211730957
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 15100  training loss: 0.038255784660577774

 15%|███████████▋                                                                 | 15143/100000 [03:30<19:20, 73.14it/s]
epoch 15200  training loss: 0.037902235984802246

 15%|███████████▊                                                                 | 15295/100000 [03:32<19:23, 72.79it/s]
epoch 15300  training loss: 0.03753174841403961
epoch 15300  clean testing loss: 12.809765815734863
epoch 15400  training loss: 0.037147004157304764

 15%|███████████▉                                                                 | 15439/100000 [03:34<19:20, 72.86it/s]
epoch 15500  training loss: 0.03677338734269142

 16%|███████████▉                                                                 | 15583/100000 [03:36<19:18, 72.84it/s]
epoch 15600  training loss: 0.037859927862882614
epoch 15600  clean testing loss: 13.073049545288086
epoch 15700  training loss: 0.03742337226867676

 16%|████████████                                                                 | 15735/100000 [03:38<19:15, 72.91it/s]
epoch 15800  training loss: 0.03588445484638214

 16%|████████████▏                                                                | 15879/100000 [03:40<19:08, 73.22it/s]
epoch 15900  training loss: 0.03526219725608826
epoch 15900  clean testing loss: 13.41113567352295
epoch 16000  training loss: 0.03632735833525658
epoch 16000  clean testing loss: 13.538013458251953

 16%|████████████▎                                                                | 16023/100000 [03:42<19:17, 72.56it/s]
epoch 16100  training loss: 0.03516637533903122

 16%|████████████▍                                                                | 16175/100000 [03:44<19:09, 72.95it/s]
epoch 16200  training loss: 0.03426105156540871

 16%|████████████▌                                                                | 16319/100000 [03:46<19:04, 73.15it/s]
epoch 16300  training loss: 0.03380090743303299
epoch 16300  clean testing loss: 13.853270530700684
epoch 16400  training loss: 0.03345028683543205

 16%|████████████▋                                                                | 16463/100000 [03:48<19:03, 73.06it/s]
epoch 16500  training loss: 0.033155642449855804

 17%|████████████▊                                                                | 16607/100000 [03:50<19:08, 72.63it/s]
epoch 16600  training loss: 0.034422021359205246
epoch 16600  clean testing loss: 14.1776762008667
epoch 16700  training loss: 0.03252563998103142

 17%|████████████▉                                                                | 16759/100000 [03:52<18:57, 73.20it/s]
epoch 16800  training loss: 0.034894708544015884

 17%|█████████████                                                                | 16903/100000 [03:54<19:07, 72.44it/s]
epoch 16900  training loss: 0.032940853387117386
epoch 16900  clean testing loss: 14.530104637145996
epoch 17000  training loss: 0.03147197142243385
epoch 17000  clean testing loss: 14.6618070602417

 17%|█████████████▏                                                               | 17047/100000 [03:56<19:01, 72.66it/s]
epoch 17100  training loss: 0.03372514620423317

 17%|█████████████▏                                                               | 17095/100000 [03:56<18:54, 73.06it/s]
epoch 17200  training loss: 0.030827032402157784
epoch 17200  clean testing loss: 14.902856826782227
epoch 17300  training loss: 0.030690353363752365
epoch 17300  clean testing loss: 15.008400917053223
epoch 17400  training loss: 0.03012826293706894
epoch 17400  clean testing loss: 15.137020111083984
epoch 17500  training loss: 0.02985726110637188
epoch 17500  clean testing loss: 15.259125709533691
epoch 17600  training loss: 0.02954525128006935

 18%|█████████████▋                                                               | 17711/100000 [04:05<18:46, 73.07it/s]
epoch 17700  training loss: 0.029360147193074226
epoch 17700  clean testing loss: 15.504561424255371
epoch 17800  training loss: 0.029001958668231964

 18%|█████████████▋                                                               | 17855/100000 [04:07<18:42, 73.19it/s]
epoch 17900  training loss: 0.02869720570743084

 18%|█████████████▊                                                               | 17999/100000 [04:09<18:38, 73.31it/s]
epoch 18000  training loss: 0.028531929478049278
epoch 18000  clean testing loss: 15.860967636108398
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 18100  training loss: 0.02805558405816555

 18%|█████████████▉                                                               | 18151/100000 [04:11<18:39, 73.12it/s]
epoch 18200  training loss: 0.02781524881720543

 18%|██████████████                                                               | 18295/100000 [04:13<18:39, 73.01it/s]
epoch 18300  training loss: 0.02756313420832157
epoch 18300  clean testing loss: 16.172082901000977
epoch 18400  training loss: 0.02730695903301239

 18%|██████████████▏                                                              | 18439/100000 [04:15<18:38, 72.91it/s]
epoch 18500  training loss: 0.027061643078923225

 19%|██████████████▎                                                              | 18591/100000 [04:17<18:34, 73.06it/s]
epoch 18600  training loss: 0.02922208234667778
epoch 18600  clean testing loss: 16.526586532592773
epoch 18700  training loss: 0.02658354677259922

 19%|██████████████▍                                                              | 18735/100000 [04:19<18:29, 73.26it/s]
epoch 18800  training loss: 0.026651525869965553

 19%|██████████████▌                                                              | 18879/100000 [04:21<18:34, 72.77it/s]
epoch 18900  training loss: 0.026139836758375168
epoch 18900  clean testing loss: 16.849502563476562
epoch 19000  training loss: 0.025930851697921753
epoch 19000  clean testing loss: 16.971393585205078

 19%|██████████████▋                                                              | 19023/100000 [04:23<18:36, 72.54it/s]
epoch 19100  training loss: 0.02568890154361725

 19%|██████████████▊                                                              | 19175/100000 [04:25<18:29, 72.86it/s]
epoch 19200  training loss: 0.02546166628599167


 19%|██████████████▉                                                              | 19463/100000 [04:29<18:21, 73.11it/s]
epoch 19300  training loss: 0.025266133248806
epoch 19300  clean testing loss: 17.30637550354004
epoch 19400  training loss: 0.02511523850262165

 20%|███████████████                                                              | 19615/100000 [04:31<18:29, 72.47it/s]
epoch 19500  training loss: 0.024846041575074196
epoch 19500  clean testing loss: 17.526687622070312
epoch 19600  training loss: 0.026247486472129822
epoch 19600  clean testing loss: 17.670812606811523
epoch 19700  training loss: 0.024490883573889732

 20%|███████████████▏                                                             | 19759/100000 [04:33<18:15, 73.22it/s]
epoch 19800  training loss: 0.024304868653416634

 20%|███████████████▎                                                             | 19903/100000 [04:35<18:25, 72.45it/s]
epoch 19900  training loss: 0.02423998713493347
epoch 19900  clean testing loss: 17.959394454956055
epoch 20000  training loss: 0.024084916338324547
epoch 20000  clean testing loss: 18.072895050048828


 20%|███████████████▌                                                             | 20199/100000 [04:39<18:11, 73.09it/s]
epoch 20100  training loss: 0.02425767108798027

 20%|███████████████▋                                                             | 20343/100000 [04:41<18:08, 73.21it/s]
epoch 20200  training loss: 0.02365267463028431
epoch 20200  clean testing loss: 18.27198600769043
epoch 20300  training loss: 0.0234807338565588

 20%|███████████████▊                                                             | 20455/100000 [04:42<18:10, 72.94it/s]
epoch 20400  training loss: 0.02336037904024124
epoch 20400  clean testing loss: 18.479942321777344
epoch 20500  training loss: 0.023554833605885506
epoch 20500  clean testing loss: 18.575164794921875
epoch 20600  training loss: 0.023034287616610527

 21%|███████████████▊                                                             | 20599/100000 [04:44<18:01, 73.44it/s]
epoch 20700  training loss: 0.02288839779794216

 21%|███████████████▉                                                             | 20743/100000 [04:46<18:05, 73.04it/s]
epoch 20800  training loss: 0.02274930290877819

 21%|████████████████                                                             | 20895/100000 [04:48<18:05, 72.85it/s]
epoch 20900  training loss: 0.022743212059140205
epoch 20900  clean testing loss: 18.985013961791992
epoch 21000  training loss: 0.02262749709188938
epoch 21000  clean testing loss: 19.076534271240234

 21%|████████████████▏                                                            | 21039/100000 [04:50<18:05, 72.76it/s]
epoch 21100  training loss: 0.02236560732126236

 21%|████████████████▎                                                            | 21183/100000 [04:52<18:01, 72.90it/s]
epoch 21200  training loss: 0.022257177159190178
epoch 21200  clean testing loss: 19.244354248046875
epoch 21300  training loss: 0.022141579538583755

 21%|████████████████▍                                                            | 21327/100000 [04:54<17:57, 72.99it/s]
epoch 21400  training loss: 0.02202165685594082

 21%|████████████████▌                                                            | 21479/100000 [04:56<17:57, 72.86it/s]
epoch 21500  training loss: 0.021898087114095688
epoch 21500  clean testing loss: 19.519119262695312
epoch 21600  training loss: 0.021778833121061325

 22%|████████████████▋                                                            | 21623/100000 [04:58<17:50, 73.24it/s]
epoch 21700  training loss: 0.021701673045754433

 22%|████████████████▊                                                            | 21767/100000 [05:00<17:58, 72.55it/s]
epoch 21800  training loss: 0.02154948189854622
epoch 21800  clean testing loss: 19.792736053466797
epoch 21900  training loss: 0.02464873157441616

 22%|████████████████▉                                                            | 21919/100000 [05:02<17:53, 72.72it/s]
epoch 22000  training loss: 0.021315645426511765
epoch 22000  clean testing loss: 19.975200653076172

 22%|████████████████▉                                                            | 22063/100000 [05:04<17:49, 72.87it/s]
epoch 22100  training loss: 0.021206285804510117
epoch 22100  clean testing loss: 20.068302154541016
epoch 22200  training loss: 0.021148601546883583

 22%|█████████████████                                                            | 22207/100000 [05:06<17:51, 72.57it/s]
epoch 22300  training loss: 0.02184608019888401

 22%|█████████████████▏                                                           | 22351/100000 [05:08<17:48, 72.68it/s]
epoch 22400  training loss: 0.02108697220683098
epoch 22400  clean testing loss: 20.3153133392334
epoch 22500  training loss: 0.02376369945704937

 23%|█████████████████▎                                                           | 22503/100000 [05:11<17:49, 72.49it/s]
epoch 22600  training loss: 0.020663529634475708

 23%|█████████████████▍                                                           | 22647/100000 [05:12<17:45, 72.62it/s]
epoch 22700  training loss: 0.020560434088110924

 23%|█████████████████▌                                                           | 22791/100000 [05:14<17:36, 73.08it/s]
epoch 22800  training loss: 0.02048989199101925
epoch 22800  clean testing loss: 20.667463302612305
epoch 22900  training loss: 0.021049415692687035

 23%|█████████████████▋                                                           | 22935/100000 [05:16<17:38, 72.83it/s]
epoch 23000  training loss: 0.020266469568014145
epoch 23000  clean testing loss: 20.84149742126465

 23%|█████████████████▊                                                           | 23087/100000 [05:19<17:31, 73.13it/s]
epoch 23100  training loss: 0.020161304622888565
epoch 23100  clean testing loss: 20.919275283813477
epoch 23200  training loss: 0.020071160048246384

 23%|█████████████████▉                                                           | 23231/100000 [05:21<17:39, 72.48it/s]
epoch 23300  training loss: 0.01996404305100441

 23%|█████████████████▉                                                           | 23375/100000 [05:22<17:31, 72.88it/s]
epoch 23400  training loss: 0.019873185083270073
epoch 23400  clean testing loss: 21.161184310913086
epoch 23500  training loss: 0.01991371065378189

 24%|██████████████████                                                           | 23519/100000 [05:24<17:30, 72.79it/s]
epoch 23600  training loss: 0.019771529361605644

 24%|██████████████████▏                                                          | 23671/100000 [05:27<17:26, 72.91it/s]
epoch 23700  training loss: 0.019617661833763123
epoch 23700  clean testing loss: 21.400114059448242
epoch 23800  training loss: 0.019591134041547775

 24%|██████████████████▎                                                          | 23815/100000 [05:29<17:27, 72.72it/s]
epoch 23900  training loss: 0.01940724439918995

 24%|██████████████████▍                                                          | 23959/100000 [05:31<17:26, 72.67it/s]
epoch 24000  training loss: 0.019532794132828712
epoch 24000  clean testing loss: 21.61927604675293
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 24100  training loss: 0.019237415865063667

 24%|██████████████████▌                                                          | 24103/100000 [05:33<17:22, 72.83it/s]
epoch 24200  training loss: 0.01915859244763851

 24%|██████████████████▋                                                          | 24255/100000 [05:35<17:18, 72.91it/s]
epoch 24300  training loss: 0.01907803863286972

 24%|██████████████████▊                                                          | 24399/100000 [05:37<17:18, 72.76it/s]
epoch 24400  training loss: 0.01899409107863903
epoch 24400  clean testing loss: 21.8978271484375
epoch 24500  training loss: 0.018919125199317932

 25%|██████████████████▉                                                          | 24543/100000 [05:39<17:24, 72.24it/s]
epoch 24600  training loss: 0.019013378769159317

 25%|███████████████████                                                          | 24687/100000 [05:41<17:18, 72.54it/s]
epoch 24700  training loss: 0.0187448151409626
epoch 24700  clean testing loss: 22.104337692260742
epoch 24800  training loss: 0.019182667136192322

 25%|███████████████████                                                          | 24831/100000 [05:43<17:11, 72.87it/s]
epoch 24900  training loss: 0.018710408359766006

 25%|███████████████████▏                                                         | 24983/100000 [05:45<17:14, 72.54it/s]
epoch 25000  training loss: 0.01853632740676403
epoch 25000  clean testing loss: 22.316495895385742
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 25100  training loss: 0.018441610038280487

 25%|███████████████████▎                                                         | 25127/100000 [05:47<17:13, 72.44it/s]
epoch 25200  training loss: 0.018453478813171387

 25%|███████████████████▍                                                         | 25271/100000 [05:49<17:09, 72.60it/s]
epoch 25300  training loss: 0.01832684688270092
epoch 25300  clean testing loss: 22.5207462310791
epoch 25400  training loss: 0.01831202767789364

 25%|███████████████████▌                                                         | 25415/100000 [05:51<17:06, 72.63it/s]
epoch 25500  training loss: 0.01816166751086712

 26%|███████████████████▋                                                         | 25559/100000 [05:53<17:02, 72.79it/s]
epoch 25600  training loss: 0.01807514950633049
epoch 25600  clean testing loss: 22.706140518188477
epoch 25700  training loss: 0.017944876104593277

 26%|███████████████████▊                                                         | 25703/100000 [05:55<17:26, 71.00it/s]
epoch 25800  training loss: 0.017894955351948738

 26%|███████████████████▉                                                         | 25847/100000 [05:57<16:59, 72.75it/s]
epoch 25900  training loss: 0.01813816837966442

 26%|████████████████████                                                         | 25989/100000 [05:59<17:06, 72.13it/s]
epoch 26000  training loss: 0.017746688798069954
epoch 26000  clean testing loss: 22.96104621887207
Saving the clean test loss file into log/new_plot/output_dim2_width512_layers3_sin_size500_noise5.00e-01_invop1 ...
epoch 26100  training loss: 0.017689187079668045

 26%|████████████████████                                                         | 26133/100000 [06:01<17:00, 72.42it/s]
epoch 26200  training loss: 0.017582111060619354

 26%|████████████████████▏                                                        | 26277/100000 [06:03<16:51, 72.86it/s]
epoch 26300  training loss: 0.017535554245114326
epoch 26300  clean testing loss: 23.1485595703125
epoch 26400  training loss: 0.017778348177671432

 26%|████████████████████▎                                                        | 26421/100000 [06:05<17:01, 72.05it/s]
epoch 26500  training loss: 0.01737038418650627

 27%|████████████████████▍                                                        | 26542/100000 [06:07<23:37, 51.83it/s]
epoch 26600  training loss: 0.017287343740463257

 27%|████████████████████▌                                                        | 26643/100000 [06:09<24:30, 49.89it/s]
epoch 26700  training loss: 0.01721321791410446

 27%|████████████████████▌                                                        | 26744/100000 [06:11<24:36, 49.60it/s]
epoch 26800  training loss: 0.017571816220879555


 27%|████████████████████▋                                                        | 26940/100000 [06:15<24:34, 49.56it/s]
epoch 26900  training loss: 0.017086254432797432
epoch 26900  clean testing loss: 23.48952865600586
epoch 27000  training loss: 0.017016660422086716
epoch 27000  clean testing loss: 23.544538497924805


 27%|████████████████████▉                                                        | 27141/100000 [06:19<24:30, 49.53it/s]
epoch 27100  training loss: 0.01695166900753975

 27%|████████████████████▉                                                        | 27237/100000 [06:21<24:29, 49.50it/s]
epoch 27200  training loss: 0.016890961676836014

 27%|█████████████████████                                                        | 27337/100000 [06:23<24:29, 49.43it/s]
epoch 27300  training loss: 0.016830842941999435

 27%|█████████████████████▏                                                       | 27437/100000 [06:25<24:25, 49.51it/s]
epoch 27400  training loss: 0.016766225919127464

 28%|█████████████████████▏                                                       | 27534/100000 [06:27<24:17, 49.70it/s]
epoch 27500  training loss: 0.016713380813598633

 28%|█████████████████████▎                                                       | 27634/100000 [06:29<24:22, 49.48it/s]
epoch 27600  training loss: 0.016638746485114098

 28%|█████████████████████▎                                                       | 27736/100000 [06:31<24:21, 49.44it/s]
epoch 27700  training loss: 0.01663903519511223

 28%|█████████████████████▍                                                       | 27836/100000 [06:33<24:16, 49.53it/s]
epoch 27800  training loss: 0.01652122475206852

 28%|█████████████████████▌                                                       | 27936/100000 [06:35<24:17, 49.45it/s]
epoch 27900  training loss: 0.01644931547343731

 28%|█████████████████████▌                                                       | 28032/100000 [06:37<24:17, 49.39it/s]
epoch 28000  training loss: 0.016384581103920937
epoch 28000  clean testing loss: 24.050859451293945

 28%|█████████████████████▋                                                       | 28132/100000 [06:39<24:11, 49.53it/s]
epoch 28100  training loss: 0.01645376905798912

 28%|█████████████████████▋                                                       | 28232/100000 [06:41<24:09, 49.53it/s]
epoch 28200  training loss: 0.016300970688462257

 28%|█████████████████████▊                                                       | 28332/100000 [06:43<24:10, 49.41it/s]
epoch 28300  training loss: 0.016641145572066307

 28%|█████████████████████▉                                                       | 28432/100000 [06:45<24:08, 49.41it/s]
epoch 28400  training loss: 0.016152534633874893

 29%|█████████████████████▉                                                       | 28529/100000 [06:47<23:54, 49.84it/s]
epoch 28500  training loss: 0.016071615740656853

 29%|██████████████████████                                                       | 28627/100000 [06:49<24:02, 49.49it/s]
epoch 28600  training loss: 0.016042882576584816

 29%|██████████████████████                                                       | 28727/100000 [06:51<24:10, 49.15it/s]
epoch 28700  training loss: 0.01598217338323593

 29%|██████████████████████▏                                                      | 28829/100000 [06:53<23:09, 51.22it/s]
epoch 28800  training loss: 0.015906555578112602

 29%|██████████████████████▎                                                      | 28943/100000 [06:55<20:08, 58.78it/s]
epoch 28900  training loss: 0.01585639826953411

 29%|██████████████████████▍                                                      | 29064/100000 [06:57<20:04, 58.88it/s]
epoch 29000  training loss: 0.015821579843759537
epoch 29000  clean testing loss: 24.529436111450195

 29%|██████████████████████▍                                                      | 29178/100000 [06:59<20:02, 58.90it/s]
epoch 29100  training loss: 0.015724249184131622

 29%|██████████████████████▌                                                      | 29298/100000 [07:01<20:00, 58.91it/s]
epoch 29200  training loss: 0.01569567807018757

 29%|██████████████████████▋                                                      | 29418/100000 [07:03<20:00, 58.79it/s]
epoch 29300  training loss: 0.01565016806125641
epoch 29300  clean testing loss: 24.658899307250977
epoch 29400  training loss: 0.015826530754566193

 30%|██████████████████████▋                                                      | 29534/100000 [07:05<19:43, 59.56it/s]
epoch 29500  training loss: 0.01578206941485405

 30%|██████████████████████▊                                                      | 29658/100000 [07:07<17:49, 65.77it/s]
epoch 29600  training loss: 0.015435930341482162
epoch 29600  clean testing loss: 24.792051315307617
epoch 29700  training loss: 0.015401558950543404

 30%|██████████████████████▉                                                      | 29802/100000 [07:09<16:07, 72.57it/s]
epoch 29800  training loss: 0.015378296375274658
epoch 29800  clean testing loss: 24.874195098876953
epoch 29900  training loss: 0.01528512965887785

 30%|███████████████████████                                                      | 29946/100000 [07:11<16:04, 72.63it/s]
epoch 30000  training loss: 0.015221037901937962
epoch 30000  clean testing loss: 24.957197189331055

 30%|███████████████████████▏                                                     | 30090/100000 [07:13<16:05, 72.38it/s]
epoch 30100  training loss: 0.015165667049586773
epoch 30100  clean testing loss: 24.991262435913086
epoch 30200  training loss: 0.015118594281375408

 30%|███████████████████████▎                                                     | 30234/100000 [07:15<15:59, 72.72it/s]
epoch 30300  training loss: 0.015070882625877857

 30%|███████████████████████▍                                                     | 30386/100000 [07:17<15:54, 72.92it/s]
epoch 30400  training loss: 0.015019682236015797
epoch 30400  clean testing loss: 25.099388122558594
epoch 30500  training loss: 0.014969146810472012


 31%|███████████████████████▌                                                     | 30674/100000 [07:21<16:03, 71.93it/s]
epoch 30600  training loss: 0.014916814863681793

 31%|███████████████████████▋                                                     | 30805/100000 [07:23<19:06, 60.33it/s]
epoch 30700  training loss: 0.014863461256027222

 31%|███████████████████████▊                                                     | 30927/100000 [07:25<19:26, 59.22it/s]
epoch 30800  training loss: 0.014817005954682827
epoch 30800  clean testing loss: 25.248676300048828
epoch 30900  training loss: 0.014836183749139309

 31%|███████████████████████▉                                                     | 31040/100000 [07:27<19:35, 58.67it/s]
epoch 31000  training loss: 0.014715500175952911
epoch 31000  clean testing loss: 25.32209014892578

 31%|███████████████████████▉                                                     | 31159/100000 [07:29<19:10, 59.86it/s]
epoch 31100  training loss: 0.01467079110443592

 31%|████████████████████████                                                     | 31283/100000 [07:31<19:07, 59.89it/s]
epoch 31200  training loss: 0.01461249403655529

 31%|████████████████████████▏                                                    | 31397/100000 [07:33<22:29, 50.84it/s]
epoch 31300  training loss: 0.014734824188053608

 31%|████████████████████████▎                                                    | 31494/100000 [07:35<23:02, 49.57it/s]
epoch 31400  training loss: 0.01450706273317337

 32%|████████████████████████▎                                                    | 31595/100000 [07:37<23:02, 49.47it/s]
epoch 31500  training loss: 0.014575882814824581

 32%|████████████████████████▍                                                    | 31691/100000 [07:39<22:58, 49.55it/s]
epoch 31600  training loss: 0.014402787201106548

 32%|████████████████████████▍                                                    | 31795/100000 [07:41<22:49, 49.79it/s]
epoch 31700  training loss: 0.014354370534420013

 32%|████████████████████████▌                                                    | 31892/100000 [07:43<22:52, 49.63it/s]
epoch 31800  training loss: 0.014315886422991753

 32%|████████████████████████▋                                                    | 31992/100000 [07:45<22:54, 49.47it/s]
epoch 31900  training loss: 0.014390152879059315

 32%|████████████████████████▋                                                    | 32089/100000 [07:47<22:51, 49.52it/s]
epoch 32000  training loss: 0.014216824434697628
epoch 32000  clean testing loss: 25.667110443115234

 32%|████████████████████████▊                                                    | 32190/100000 [07:49<22:46, 49.64it/s]
epoch 32100  training loss: 0.014186011627316475

 32%|████████████████████████▊                                                    | 32290/100000 [07:51<22:46, 49.56it/s]
epoch 32200  training loss: 0.014244908466935158

 32%|████████████████████████▉                                                    | 32387/100000 [07:53<22:38, 49.76it/s]
epoch 32300  training loss: 0.01408979669213295

 32%|████████████████████████▉                                                    | 32397/100000 [07:53<22:42, 49.62it/s]
epoch 32400  training loss: 0.014266911894083023

 33%|█████████████████████████▏                                                   | 32689/100000 [07:59<22:37, 49.58it/s]
epoch 32500  training loss: 0.014109829440712929
epoch 32500  clean testing loss: 25.822465896606445
epoch 32600  training loss: 0.013931319117546082

 33%|█████████████████████████▏                                                   | 32788/100000 [08:01<22:33, 49.65it/s]
epoch 32700  training loss: 0.013898358680307865

 33%|█████████████████████████▎                                                   | 32889/100000 [08:03<22:31, 49.65it/s]
epoch 32800  training loss: 0.013892628252506256

 33%|█████████████████████████▍                                                   | 32989/100000 [08:05<22:33, 49.51it/s]
epoch 32900  training loss: 0.013781750574707985

 33%|█████████████████████████▍                                                   | 33086/100000 [08:07<22:31, 49.50it/s]
epoch 33000  training loss: 0.013755550608038902
epoch 33000  clean testing loss: 25.980411529541016

 33%|█████████████████████████▌                                                   | 33182/100000 [08:09<22:27, 49.59it/s]
epoch 33100  training loss: 0.013691586442291737

 33%|█████████████████████████▋                                                   | 33282/100000 [08:11<22:25, 49.59it/s]
epoch 33200  training loss: 0.013652544468641281

 33%|█████████████████████████▋                                                   | 33384/100000 [08:13<22:21, 49.64it/s]
epoch 33300  training loss: 0.013611641712486744

 33%|█████████████████████████▊                                                   | 33484/100000 [08:15<22:25, 49.43it/s]
epoch 33400  training loss: 0.01356863509863615
epoch 33400  clean testing loss: 26.0784969329834
epoch 33500  training loss: 0.013636641204357147

 34%|█████████████████████████▊                                                   | 33584/100000 [08:17<22:58, 48.19it/s]
epoch 33600  training loss: 0.013477967120707035

 34%|█████████████████████████▉                                                   | 33679/100000 [08:19<22:18, 49.55it/s]
epoch 33700  training loss: 0.013445261865854263

 34%|██████████████████████████                                                   | 33782/100000 [08:21<22:07, 49.90it/s]
epoch 33800  training loss: 0.013388493098318577

 34%|██████████████████████████                                                   | 33857/100000 [08:23<22:14, 49.55it/s]
epoch 33900  training loss: 0.013341167941689491

 34%|██████████████████████████▏                                                  | 33953/100000 [08:25<22:14, 49.50it/s]
epoch 34000  training loss: 0.013300055637955666
epoch 34000  clean testing loss: 26.238079071044922

 34%|██████████████████████████▏                                                  | 34053/100000 [08:27<22:11, 49.55it/s]
epoch 34100  training loss: 0.013311895541846752

 34%|██████████████████████████▎                                                  | 34154/100000 [08:29<22:05, 49.67it/s]
epoch 34200  training loss: 0.0132108423858881

 34%|██████████████████████████▍                                                  | 34254/100000 [08:31<22:07, 49.51it/s]
epoch 34300  training loss: 0.013170506805181503

 34%|██████████████████████████▍                                                  | 34350/100000 [08:33<22:03, 49.61it/s]
epoch 34400  training loss: 0.013118105940520763

 34%|██████████████████████████▌                                                  | 34452/100000 [08:35<21:52, 49.95it/s]
epoch 34500  training loss: 0.013078341260552406

 35%|██████████████████████████▌                                                  | 34552/100000 [08:37<22:00, 49.58it/s]
epoch 34600  training loss: 0.013041031546890736

 35%|██████████████████████████▋                                                  | 34652/100000 [08:39<21:56, 49.62it/s]
epoch 34700  training loss: 0.012987236492335796

 35%|██████████████████████████▊                                                  | 34752/100000 [08:41<21:55, 49.60it/s]
epoch 34800  training loss: 0.012945245951414108

 35%|██████████████████████████▊                                                  | 34849/100000 [08:43<21:58, 49.43it/s]
epoch 34900  training loss: 0.012922627851366997

 35%|██████████████████████████▉                                                  | 34949/100000 [08:45<21:51, 49.60it/s]
epoch 35000  training loss: 0.012872403487563133
epoch 35000  clean testing loss: 26.483997344970703

 35%|██████████████████████████▉                                                  | 35050/100000 [08:47<21:51, 49.52it/s]
epoch 35100  training loss: 0.012820878997445107

 35%|███████████████████████████                                                  | 35145/100000 [08:49<21:48, 49.55it/s]
epoch 35200  training loss: 0.012777015566825867

 35%|███████████████████████████▏                                                 | 35246/100000 [08:51<21:45, 49.59it/s]
epoch 35300  training loss: 0.012727207504212856

 35%|███████████████████████████▏                                                 | 35346/100000 [08:53<21:46, 49.49it/s]
epoch 35400  training loss: 0.012698215432465076

 35%|███████████████████████████▎                                                 | 35447/100000 [08:55<21:43, 49.51it/s]
epoch 35500  training loss: 0.012658480554819107

 36%|███████████████████████████▎                                                 | 35543/100000 [08:57<21:38, 49.64it/s]
epoch 35600  training loss: 0.012606323696672916

 36%|███████████████████████████▍                                                 | 35643/100000 [08:59<21:36, 49.63it/s]
epoch 35700  training loss: 0.012573021464049816

 36%|███████████████████████████▌                                                 | 35745/100000 [09:01<21:35, 49.60it/s]
epoch 35800  training loss: 0.012518833391368389

 36%|███████████████████████████▌                                                 | 35843/100000 [09:03<21:25, 49.93it/s]
epoch 35900  training loss: 0.012475794181227684

 36%|███████████████████████████▋                                                 | 35943/100000 [09:05<21:32, 49.55it/s]
epoch 36000  training loss: 0.012427831999957561
epoch 36000  clean testing loss: 26.70792007446289

 36%|███████████████████████████▊                                                 | 36040/100000 [09:07<21:35, 49.38it/s]
epoch 36100  training loss: 0.01239300798624754

 36%|███████████████████████████▊                                                 | 36140/100000 [09:09<21:28, 49.55it/s]
epoch 36200  training loss: 0.012355892919003963

 36%|███████████████████████████▉                                                 | 36242/100000 [09:11<21:25, 49.59it/s]
epoch 36300  training loss: 0.012316727079451084

 36%|███████████████████████████▉                                                 | 36343/100000 [09:13<21:23, 49.58it/s]
epoch 36400  training loss: 0.012278099544346333

 36%|████████████████████████████                                                 | 36439/100000 [09:15<21:21, 49.59it/s]
epoch 36500  training loss: 0.012341192923486233

 37%|████████████████████████████▏                                                | 36539/100000 [09:17<21:21, 49.51it/s]
epoch 36600  training loss: 0.012405503541231155

 37%|████████████████████████████▏                                                | 36639/100000 [09:19<21:18, 49.58it/s]
epoch 36700  training loss: 0.012205325067043304

 37%|████████████████████████████▎                                                | 36739/100000 [09:21<21:18, 49.47it/s]
epoch 36800  training loss: 0.01211297232657671

 37%|████████████████████████████▎                                                | 36840/100000 [09:23<21:13, 49.61it/s]
epoch 36900  training loss: 0.012093414552509785

 37%|████████████████████████████▍                                                | 36940/100000 [09:25<21:16, 49.40it/s]
epoch 37000  training loss: 0.012031015940010548
epoch 37000  clean testing loss: 26.899106979370117

 37%|████████████████████████████▌                                                | 37036/100000 [09:27<21:17, 49.27it/s]
epoch 37100  training loss: 0.011990448459982872

 37%|████████████████████████████▌                                                | 37136/100000 [09:29<21:18, 49.16it/s]
epoch 37200  training loss: 0.01194812636822462

 37%|████████████████████████████▋                                                | 37236/100000 [09:31<21:07, 49.52it/s]
epoch 37300  training loss: 0.01192987710237503

 37%|████████████████████████████▋                                                | 37336/100000 [09:33<21:07, 49.45it/s]
epoch 37400  training loss: 0.01187907624989748

 37%|████████████████████████████▊                                                | 37433/100000 [09:35<21:00, 49.64it/s]
epoch 37500  training loss: 0.011894076131284237

 38%|████████████████████████████▉                                                | 37533/100000 [09:37<21:07, 49.30it/s]
epoch 37600  training loss: 0.011800319887697697

 38%|████████████████████████████▉                                                | 37633/100000 [09:39<20:58, 49.57it/s]
epoch 37700  training loss: 0.011745703406631947

 38%|█████████████████████████████                                                | 37729/100000 [09:41<20:54, 49.64it/s]
epoch 37800  training loss: 0.011705378070473671

 38%|█████████████████████████████▏                                               | 37830/100000 [09:43<21:44, 47.66it/s]
epoch 37900  training loss: 0.011689966544508934

 38%|█████████████████████████████▏                                               | 37931/100000 [09:45<20:50, 49.65it/s]
epoch 38000  training loss: 0.011623484082520008
epoch 38000  clean testing loss: 27.078516006469727

 38%|█████████████████████████████▎                                               | 38026/100000 [09:47<21:01, 49.11it/s]
epoch 38100  training loss: 0.01158318854868412

 38%|█████████████████████████████▎                                               | 38126/100000 [09:49<20:47, 49.59it/s]
epoch 38200  training loss: 0.011560758575797081

 38%|█████████████████████████████▍                                               | 38226/100000 [09:51<20:46, 49.55it/s]
epoch 38300  training loss: 0.011503322049975395


 38%|█████████████████████████████▌                                               | 38390/100000 [09:54<18:06, 56.69it/s]
epoch 38400  training loss: 0.011462068185210228
epoch 38400  clean testing loss: 27.150978088378906
epoch 38500  training loss: 0.011421343311667442

 39%|█████████████████████████████▋                                               | 38539/100000 [09:57<20:40, 49.55it/s]
epoch 38600  training loss: 0.011487478390336037

 39%|█████████████████████████████▊                                               | 38639/100000 [09:59<20:39, 49.51it/s]
epoch 38700  training loss: 0.011341836303472519

 39%|█████████████████████████████▊                                               | 38740/100000 [10:01<20:35, 49.56it/s]
epoch 38800  training loss: 0.011321119964122772

 39%|█████████████████████████████▉                                               | 38837/100000 [10:03<20:33, 49.60it/s]
epoch 38900  training loss: 0.011260569095611572

 39%|█████████████████████████████▉                                               | 38938/100000 [10:05<20:32, 49.56it/s]
epoch 39000  training loss: 0.011220809072256088
epoch 39000  clean testing loss: 27.247419357299805

 39%|██████████████████████████████                                               | 39037/100000 [10:07<20:32, 49.45it/s]
epoch 39100  training loss: 0.011186959221959114

 39%|██████████████████████████████▏                                              | 39137/100000 [10:09<20:27, 49.60it/s]
epoch 39200  training loss: 0.011153047904372215

 39%|██████████████████████████████▏                                              | 39238/100000 [10:11<20:25, 49.59it/s]
epoch 39300  training loss: 0.011117590591311455

 39%|██████████████████████████████▎                                              | 39333/100000 [10:13<20:23, 49.57it/s]
epoch 39400  training loss: 0.011080234311521053

 39%|██████████████████████████████▎                                              | 39433/100000 [10:15<20:26, 49.36it/s]
epoch 39500  training loss: 0.011310513131320477

 40%|██████████████████████████████▍                                              | 39534/100000 [10:17<21:02, 47.88it/s]
epoch 39600  training loss: 0.01100158877670765

 40%|██████████████████████████████▌                                              | 39634/100000 [10:19<20:18, 49.55it/s]
epoch 39700  training loss: 0.010964262299239635

 40%|██████████████████████████████▌                                              | 39729/100000 [10:21<20:16, 49.53it/s]
epoch 39800  training loss: 0.010937819257378578

 40%|██████████████████████████████▋                                              | 39830/100000 [10:23<20:16, 49.47it/s]
epoch 39900  training loss: 0.010908220894634724

 40%|██████████████████████████████▋                                              | 39931/100000 [10:25<20:08, 49.72it/s]
epoch 40000  training loss: 0.01087756734341383
epoch 40000  clean testing loss: 27.394460678100586

 40%|██████████████████████████████▊                                              | 40028/100000 [10:27<20:19, 49.18it/s]
epoch 40100  training loss: 0.010809071362018585

 40%|██████████████████████████████▉                                              | 40128/100000 [10:29<20:07, 49.57it/s]
epoch 40200  training loss: 0.010789242573082447

 40%|██████████████████████████████▉                                              | 40229/100000 [10:31<20:07, 49.49it/s]
epoch 40300  training loss: 0.010726631619036198

 40%|███████████████████████████████                                              | 40325/100000 [10:33<20:05, 49.52it/s]
epoch 40400  training loss: 0.010691883973777294

 40%|███████████████████████████████▏                                             | 40425/100000 [10:35<20:08, 49.31it/s]
epoch 40500  training loss: 0.01064702495932579

 41%|███████████████████████████████▏                                             | 40526/100000 [10:37<19:58, 49.64it/s]
epoch 40600  training loss: 0.010608268901705742

 41%|███████████████████████████████▎                                             | 40627/100000 [10:39<19:57, 49.56it/s]
epoch 40700  training loss: 0.010568056255578995

 41%|███████████████████████████████▎                                             | 40722/100000 [10:41<19:56, 49.55it/s]
epoch 40800  training loss: 0.01052933745086193


 41%|███████████████████████████████▌                                             | 40924/100000 [10:45<19:52, 49.55it/s]
epoch 40900  training loss: 0.010507479310035706

 41%|███████████████████████████████▌                                             | 41020/100000 [10:47<20:12, 48.64it/s]
epoch 41000  training loss: 0.010535145178437233
epoch 41000  clean testing loss: 27.5372314453125

 41%|███████████████████████████████▋                                             | 41120/100000 [10:49<19:47, 49.60it/s]
epoch 41100  training loss: 0.010412339121103287

 41%|███████████████████████████████▋                                             | 41220/100000 [10:51<19:45, 49.58it/s]
epoch 41200  training loss: 0.010373520664870739

 41%|███████████████████████████████▊                                             | 41320/100000 [10:53<19:44, 49.55it/s]
epoch 41300  training loss: 0.01033927220851183

 41%|███████████████████████████████▉                                             | 41421/100000 [10:55<19:37, 49.73it/s]
epoch 41400  training loss: 0.01029821578413248

 42%|███████████████████████████████▉                                             | 41519/100000 [10:57<19:36, 49.71it/s]
epoch 41500  training loss: 0.010272116400301456

 42%|████████████████████████████████                                             | 41620/100000 [10:59<19:33, 49.77it/s]
epoch 41600  training loss: 0.010224753059446812

 42%|████████████████████████████████                                             | 41720/100000 [11:01<19:35, 49.57it/s]
epoch 41700  training loss: 0.010213067755103111

 42%|████████████████████████████████▏                                            | 41817/100000 [11:03<19:34, 49.54it/s]
epoch 41800  training loss: 0.01013951376080513

 42%|████████████████████████████████▎                                            | 41918/100000 [11:05<19:28, 49.71it/s]
epoch 41900  training loss: 0.01010665763169527

 42%|████████████████████████████████▎                                            | 42016/100000 [11:07<19:49, 48.74it/s]
epoch 42000  training loss: 0.010107279755175114
epoch 42000  clean testing loss: 27.677183151245117

 42%|████████████████████████████████▍                                            | 42116/100000 [11:09<19:26, 49.63it/s]
epoch 42100  training loss: 0.010028423741459846

 42%|████████████████████████████████▌                                            | 42216/100000 [11:11<19:25, 49.57it/s]
epoch 42200  training loss: 0.009994040243327618

 42%|████████████████████████████████▌                                            | 42314/100000 [11:13<19:21, 49.68it/s]
epoch 42300  training loss: 0.009958993643522263


 43%|████████████████████████████████▋                                            | 42514/100000 [11:17<19:18, 49.62it/s]
epoch 42400  training loss: 0.009923952631652355

 43%|████████████████████████████████▊                                            | 42614/100000 [11:19<19:20, 49.44it/s]
epoch 42500  training loss: 0.009913668036460876

 43%|████████████████████████████████▉                                            | 42710/100000 [11:21<19:17, 49.49it/s]
epoch 42600  training loss: 0.0098454924300313

 43%|████████████████████████████████▉                                            | 42812/100000 [11:23<19:13, 49.58it/s]
epoch 42700  training loss: 0.009823793545365334

 43%|█████████████████████████████████                                            | 42907/100000 [11:25<19:15, 49.41it/s]
epoch 42800  training loss: 0.009768575429916382

 43%|█████████████████████████████████                                            | 43006/100000 [11:27<19:52, 47.78it/s]
epoch 42900  training loss: 0.00973048061132431

 43%|█████████████████████████████████▏                                           | 43107/100000 [11:29<19:01, 49.85it/s]
epoch 43000  training loss: 0.009693003259599209
epoch 43000  clean testing loss: 27.79285430908203

 43%|█████████████████████████████████▎                                           | 43208/100000 [11:31<19:05, 49.57it/s]
epoch 43100  training loss: 0.009652308188378811

 43%|█████████████████████████████████▎                                           | 43308/100000 [11:33<19:04, 49.53it/s]
epoch 43200  training loss: 0.009614494629204273

 43%|█████████████████████████████████▍                                           | 43406/100000 [11:35<18:57, 49.75it/s]
epoch 43300  training loss: 0.009587305597960949

 44%|█████████████████████████████████▌                                           | 43508/100000 [11:37<19:00, 49.54it/s]
epoch 43400  training loss: 0.009541931562125683

 44%|█████████████████████████████████▌                                           | 43608/100000 [11:39<18:57, 49.56it/s]
epoch 43500  training loss: 0.009501190856099129

 44%|█████████████████████████████████▋                                           | 43703/100000 [11:41<18:54, 49.61it/s]
epoch 43600  training loss: 0.00946617778390646

 44%|█████████████████████████████████▋                                           | 43804/100000 [11:43<18:54, 49.52it/s]
epoch 43700  training loss: 0.009434113278985023
epoch 43700  clean testing loss: 27.884281158447266
epoch 43800  training loss: 0.009385599754750729

 44%|█████████████████████████████████▊                                           | 43904/100000 [11:45<18:51, 49.56it/s]
epoch 43900  training loss: 0.009350954554975033

 44%|█████████████████████████████████▉                                           | 44005/100000 [11:47<18:46, 49.72it/s]
epoch 44000  training loss: 0.009308732114732265
epoch 44000  clean testing loss: 27.91527557373047

 44%|█████████████████████████████████▉                                           | 44102/100000 [11:49<18:47, 49.57it/s]
epoch 44100  training loss: 0.009276940487325191

 44%|██████████████████████████████████                                           | 44202/100000 [11:51<18:50, 49.38it/s]
epoch 44200  training loss: 0.009329946711659431

 44%|██████████████████████████████████                                           | 44277/100000 [11:53<18:42, 49.63it/s]
epoch 44300  training loss: 0.009201118722558022

 44%|██████████████████████████████████▏                                          | 44377/100000 [11:55<18:41, 49.58it/s]
epoch 44400  training loss: 0.009154673665761948

 44%|██████████████████████████████████▏                                          | 44477/100000 [11:57<18:37, 49.70it/s]
epoch 44500  training loss: 0.009116524830460548

 45%|██████████████████████████████████▎                                          | 44577/100000 [11:59<18:39, 49.52it/s]
epoch 44600  training loss: 0.009087353944778442

 45%|██████████████████████████████████▎                                          | 44597/100000 [11:59<18:38, 49.55it/s]
epoch 44700  training loss: 0.009041561745107174

 45%|██████████████████████████████████▍                                          | 44774/100000 [12:03<17:54, 51.40it/s]
epoch 44800  training loss: 0.009002499282360077

 45%|██████████████████████████████████▌                                          | 44880/100000 [12:05<18:30, 49.66it/s]
epoch 44900  training loss: 0.00899653322994709

 45%|██████████████████████████████████▋                                          | 44980/100000 [12:07<18:30, 49.56it/s]
epoch 45000  training loss: 0.008941766805946827
epoch 45000  clean testing loss: 28.02952766418457

 45%|██████████████████████████████████▋                                          | 45081/100000 [12:09<18:28, 49.54it/s]
epoch 45100  training loss: 0.008896567858755589

 45%|██████████████████████████████████▊                                          | 45177/100000 [12:11<18:25, 49.58it/s]
epoch 45200  training loss: 0.008864937350153923

 45%|██████████████████████████████████▊                                          | 45277/100000 [12:13<18:24, 49.56it/s]
epoch 45300  training loss: 0.008831815794110298

 45%|██████████████████████████████████▉                                          | 45378/100000 [12:15<18:19, 49.68it/s]
epoch 45400  training loss: 0.008797142654657364

 45%|███████████████████████████████████                                          | 45474/100000 [12:17<18:23, 49.43it/s]
epoch 45500  training loss: 0.0087608452886343

 46%|███████████████████████████████████                                          | 45575/100000 [12:19<18:19, 49.49it/s]
epoch 45600  training loss: 0.008723381906747818

 46%|███████████████████████████████████▏                                         | 45675/100000 [12:21<18:18, 49.43it/s]
epoch 45700  training loss: 0.008685018867254257

 46%|███████████████████████████████████▏                                         | 45775/100000 [12:23<18:13, 49.61it/s]
epoch 45800  training loss: 0.008649075403809547

 46%|███████████████████████████████████▎                                         | 45871/100000 [12:25<18:13, 49.48it/s]
epoch 45900  training loss: 0.008613573387265205

 46%|███████████████████████████████████▍                                         | 45971/100000 [12:27<18:12, 49.48it/s]
epoch 46000  training loss: 0.008580531924962997
epoch 46000  clean testing loss: 28.137941360473633

 46%|███████████████████████████████████▍                                         | 46073/100000 [12:29<18:09, 49.49it/s]
epoch 46100  training loss: 0.008567829616367817

 46%|███████████████████████████████████▌                                         | 46168/100000 [12:31<18:05, 49.59it/s]
epoch 46200  training loss: 0.00850576814264059

 46%|███████████████████████████████████▋                                         | 46268/100000 [12:33<18:03, 49.59it/s]
epoch 46300  training loss: 0.00846412219107151

 46%|███████████████████████████████████▋                                         | 46368/100000 [12:35<18:01, 49.60it/s]
epoch 46400  training loss: 0.00843796506524086

 46%|███████████████████████████████████▊                                         | 46470/100000 [12:37<17:55, 49.75it/s]
epoch 46500  training loss: 0.008397718891501427

 47%|███████████████████████████████████▊                                         | 46568/100000 [12:39<17:57, 49.61it/s]
epoch 46600  training loss: 0.008356484584510326

 47%|███████████████████████████████████▉                                         | 46665/100000 [12:41<17:54, 49.66it/s]
epoch 46700  training loss: 0.008344520814716816

 47%|████████████████████████████████████                                         | 46767/100000 [12:43<17:55, 49.51it/s]
epoch 46800  training loss: 0.008282758295536041

 47%|████████████████████████████████████                                         | 46863/100000 [12:45<17:49, 49.68it/s]
epoch 46900  training loss: 0.00825503095984459

 47%|████████████████████████████████████▏                                        | 46964/100000 [12:47<17:52, 49.44it/s]
epoch 47000  training loss: 0.008208406157791615
epoch 47000  clean testing loss: 28.25733184814453

 47%|████████████████████████████████████▏                                        | 47067/100000 [12:49<17:45, 49.70it/s]
epoch 47100  training loss: 0.008174180053174496

 47%|████████████████████████████████████▎                                        | 47163/100000 [12:51<17:45, 49.57it/s]
epoch 47200  training loss: 0.008138466626405716

 47%|████████████████████████████████████▍                                        | 47264/100000 [12:53<17:45, 49.51it/s]
epoch 47300  training loss: 0.008106037974357605

 47%|████████████████████████████████████▍                                        | 47364/100000 [12:55<17:42, 49.54it/s]
epoch 47400  training loss: 0.008069983683526516

 47%|████████████████████████████████████▌                                        | 47461/100000 [12:57<17:35, 49.79it/s]
epoch 47500  training loss: 0.00803252775222063

 48%|████████████████████████████████████▌                                        | 47562/100000 [12:59<17:39, 49.49it/s]
epoch 47600  training loss: 0.007997885346412659

 48%|████████████████████████████████████▋                                        | 47662/100000 [13:01<17:38, 49.44it/s]
epoch 47700  training loss: 0.007969736121594906

 48%|████████████████████████████████████▋                                        | 47698/100000 [13:02<17:29, 49.82it/s]
epoch 47800  training loss: 0.007921439595520496

 48%|████████████████████████████████████▊                                        | 47861/100000 [13:05<17:01, 51.05it/s]
epoch 47900  training loss: 0.007886539213359356

 48%|████████████████████████████████████▉                                        | 47964/100000 [13:07<17:29, 49.60it/s]
epoch 48000  training loss: 0.007851311936974525
epoch 48000  clean testing loss: 28.375749588012695

 48%|█████████████████████████████████████                                        | 48063/100000 [13:09<17:28, 49.52it/s]
epoch 48100  training loss: 0.007822751067578793

 48%|█████████████████████████████████████                                        | 48160/100000 [13:11<17:25, 49.59it/s]
epoch 48200  training loss: 0.00779263349249959

 48%|█████████████████████████████████████▏                                       | 48260/100000 [13:13<17:26, 49.45it/s]
epoch 48300  training loss: 0.0077606975100934505

 48%|█████████████████████████████████████▏                                       | 48360/100000 [13:15<17:23, 49.50it/s]
epoch 48400  training loss: 0.007728028576821089

 48%|█████████████████████████████████████▎                                       | 48461/100000 [13:17<17:15, 49.77it/s]
epoch 48500  training loss: 0.0077039762400090694

 49%|█████████████████████████████████████▍                                       | 48556/100000 [13:19<17:19, 49.50it/s]
epoch 48600  training loss: 0.007663399912416935

 49%|█████████████████████████████████████▍                                       | 48657/100000 [13:21<17:16, 49.52it/s]
epoch 48700  training loss: 0.007625449914485216

 49%|█████████████████████████████████████▌                                       | 48755/100000 [13:23<17:13, 49.58it/s]
epoch 48800  training loss: 0.007592604961246252

 49%|█████████████████████████████████████▌                                       | 48856/100000 [13:25<17:45, 48.02it/s]
epoch 48900  training loss: 0.007560220081359148

 49%|█████████████████████████████████████▋                                       | 48952/100000 [13:27<17:10, 49.56it/s]
epoch 49000  training loss: 0.007527951616793871
epoch 49000  clean testing loss: 28.491355895996094

 49%|█████████████████████████████████████▊                                       | 49051/100000 [13:29<17:09, 49.47it/s]
epoch 49100  training loss: 0.0074921343475580215

 49%|█████████████████████████████████████▊                                       | 49151/100000 [13:31<17:06, 49.52it/s]
epoch 49200  training loss: 0.007460687775164843

 49%|█████████████████████████████████████▉                                       | 49246/100000 [13:33<17:44, 47.69it/s]
epoch 49300  training loss: 0.007429217919707298

 49%|█████████████████████████████████████▉                                       | 49346/100000 [13:35<17:04, 49.46it/s]
epoch 49400  training loss: 0.007394402753561735

 49%|██████████████████████████████████████                                       | 49447/100000 [13:37<16:52, 49.92it/s]
epoch 49500  training loss: 0.007368399761617184

 50%|██████████████████████████████████████▏                                      | 49548/100000 [13:39<16:58, 49.52it/s]
epoch 49600  training loss: 0.007329415529966354

 50%|██████████████████████████████████████▏                                      | 49643/100000 [13:41<16:56, 49.54it/s]
epoch 49700  training loss: 0.00730133755132556

 50%|██████████████████████████████████████▎                                      | 49743/100000 [13:43<16:55, 49.50it/s]
epoch 49800  training loss: 0.007264015730470419

 50%|██████████████████████████████████████▍                                      | 49843/100000 [13:45<16:48, 49.73it/s]
epoch 49900  training loss: 0.007237245794385672

 50%|██████████████████████████████████████▍                                      | 49944/100000 [13:47<16:46, 49.73it/s]
epoch 50000  training loss: 0.007202544249594212
epoch 50000  clean testing loss: 28.61447525024414

 50%|██████████████████████████████████████▌                                      | 50043/100000 [13:49<16:50, 49.46it/s]
epoch 50100  training loss: 0.007169014308601618

 50%|██████████████████████████████████████▌                                      | 50143/100000 [13:51<16:47, 49.50it/s]
epoch 50200  training loss: 0.007138451561331749

 50%|██████████████████████████████████████▋                                      | 50243/100000 [13:53<16:43, 49.57it/s]
epoch 50300  training loss: 0.007104904856532812

 50%|██████████████████████████████████████▊                                      | 50339/100000 [13:55<16:44, 49.45it/s]
epoch 50400  training loss: 0.007075168192386627

 50%|██████████████████████████████████████▊                                      | 50440/100000 [13:57<16:40, 49.56it/s]
epoch 50500  training loss: 0.007058341987431049

 51%|██████████████████████████████████████▉                                      | 50542/100000 [13:59<16:35, 49.68it/s]
epoch 50600  training loss: 0.007016606163233519

 51%|██████████████████████████████████████▉                                      | 50639/100000 [14:01<16:25, 50.10it/s]
epoch 50700  training loss: 0.00698183523491025

 51%|███████████████████████████████████████                                      | 50740/100000 [14:03<16:34, 49.52it/s]
epoch 50800  training loss: 0.006951240357011557

 51%|███████████████████████████████████████▏                                     | 50841/100000 [14:05<16:26, 49.84it/s]
epoch 50900  training loss: 0.006922392174601555

 51%|███████████████████████████████████████▏                                     | 50936/100000 [14:07<16:31, 49.50it/s]
epoch 51000  training loss: 0.006892277859151363
epoch 51000  clean testing loss: 28.73929214477539

 51%|███████████████████████████████████████▎                                     | 51035/100000 [14:09<16:31, 49.37it/s]
epoch 51100  training loss: 0.006866887211799622

 51%|███████████████████████████████████████▎                                     | 51135/100000 [14:11<16:27, 49.51it/s]
epoch 51200  training loss: 0.006842459086328745

 51%|███████████████████████████████████████▍                                     | 51236/100000 [14:13<16:23, 49.57it/s]
epoch 51300  training loss: 0.006816178094595671

 51%|███████████████████████████████████████▌                                     | 51337/100000 [14:15<16:19, 49.67it/s]
epoch 51400  training loss: 0.0067888954654335976

 51%|███████████████████████████████████████▌                                     | 51437/100000 [14:17<16:19, 49.56it/s]
epoch 51500  training loss: 0.006779220420867205

 52%|███████████████████████████████████████▋                                     | 51533/100000 [14:19<16:16, 49.64it/s]
epoch 51600  training loss: 0.006732553709298372

 52%|███████████████████████████████████████▊                                     | 51633/100000 [14:21<16:17, 49.47it/s]
epoch 51700  training loss: 0.006704560946673155

 52%|███████████████████████████████████████▊                                     | 51734/100000 [14:23<16:15, 49.47it/s]
epoch 51800  training loss: 0.006674208212643862

 52%|███████████████████████████████████████▉                                     | 51835/100000 [14:25<16:06, 49.83it/s]
epoch 51900  training loss: 0.006646314170211554

 52%|███████████████████████████████████████▉                                     | 51932/100000 [14:27<16:07, 49.71it/s]
epoch 52000  training loss: 0.006619335617870092
epoch 52000  clean testing loss: 28.856983184814453

 52%|████████████████████████████████████████                                     | 52029/100000 [14:29<16:14, 49.21it/s]
epoch 52100  training loss: 0.0065908655524253845

 52%|████████████████████████████████████████▏                                    | 52131/100000 [14:31<16:09, 49.35it/s]
epoch 52200  training loss: 0.006563242059201002

 52%|████████████████████████████████████████▏                                    | 52232/100000 [14:33<16:00, 49.74it/s]
epoch 52300  training loss: 0.006535752676427364

 52%|████████████████████████████████████████▎                                    | 52328/100000 [14:35<15:59, 49.66it/s]
epoch 52400  training loss: 0.0065079680643975735

 52%|████████████████████████████████████████▎                                    | 52430/100000 [14:37<15:57, 49.66it/s]
epoch 52500  training loss: 0.0064826528541743755

 53%|████████████████████████████████████████▍                                    | 52526/100000 [14:39<15:58, 49.55it/s]
epoch 52600  training loss: 0.006453854963183403

 53%|████████████████████████████████████████▌                                    | 52626/100000 [14:41<15:58, 49.40it/s]
epoch 52700  training loss: 0.006450246553868055

 53%|████████████████████████████████████████▌                                    | 52726/100000 [14:43<15:54, 49.54it/s]
epoch 52800  training loss: 0.006425130181014538

 53%|████████████████████████████████████████▋                                    | 52826/100000 [14:45<15:51, 49.56it/s]
epoch 52900  training loss: 0.006379946134984493

 53%|████████████████████████████████████████▊                                    | 52927/100000 [14:48<15:50, 49.50it/s]
epoch 53000  training loss: 0.006348441820591688
epoch 53000  clean testing loss: 28.97987174987793

 53%|████████████████████████████████████████▊                                    | 53025/100000 [14:49<15:57, 49.05it/s]
epoch 53100  training loss: 0.006345636211335659

 53%|████████████████████████████████████████▉                                    | 53125/100000 [14:52<15:45, 49.58it/s]
epoch 53200  training loss: 0.006320611573755741

 53%|████████████████████████████████████████▉                                    | 53221/100000 [14:53<15:44, 49.52it/s]
epoch 53300  training loss: 0.006269934121519327

 53%|█████████████████████████████████████████                                    | 53324/100000 [14:56<15:39, 49.70it/s]
epoch 53400  training loss: 0.006243590731173754

 53%|█████████████████████████████████████████▏                                   | 53419/100000 [14:57<16:30, 47.01it/s]
epoch 53500  training loss: 0.006221740506589413

 54%|█████████████████████████████████████████▏                                   | 53522/100000 [15:00<15:37, 49.56it/s]
epoch 53600  training loss: 0.00619581900537014


 54%|█████████████████████████████████████████▎                                   | 53720/100000 [15:04<15:46, 48.92it/s]
epoch 53700  training loss: 0.006165819708257914

 54%|█████████████████████████████████████████▍                                   | 53821/100000 [15:06<15:29, 49.67it/s]
epoch 53800  training loss: 0.006140542216598988

 54%|█████████████████████████████████████████▌                                   | 53917/100000 [15:08<15:29, 49.57it/s]
epoch 53900  training loss: 0.006116414908319712

 54%|█████████████████████████████████████████▌                                   | 54015/100000 [15:10<15:47, 48.51it/s]
epoch 54000  training loss: 0.006107667461037636
epoch 54000  clean testing loss: 29.10096549987793

 54%|█████████████████████████████████████████▋                                   | 54118/100000 [15:12<15:25, 49.56it/s]
epoch 54100  training loss: 0.006069929338991642

 54%|█████████████████████████████████████████▋                                   | 54213/100000 [15:14<15:25, 49.50it/s]
epoch 54200  training loss: 0.0060477531515061855

 54%|█████████████████████████████████████████▊                                   | 54314/100000 [15:16<15:20, 49.64it/s]
epoch 54300  training loss: 0.006026543211191893

 54%|█████████████████████████████████████████▉                                   | 54414/100000 [15:18<15:20, 49.54it/s]
epoch 54400  training loss: 0.006003821734338999

 55%|█████████████████████████████████████████▉                                   | 54515/100000 [15:20<15:17, 49.59it/s]
epoch 54500  training loss: 0.005979522597044706

 55%|██████████████████████████████████████████                                   | 54613/100000 [15:22<15:17, 49.48it/s]
epoch 54600  training loss: 0.005957769230008125

 55%|██████████████████████████████████████████                                   | 54688/100000 [15:23<15:16, 49.43it/s]
epoch 54700  training loss: 0.005941092502325773

 55%|██████████████████████████████████████████▏                                  | 54789/100000 [15:25<15:11, 49.61it/s]
epoch 54800  training loss: 0.005907855462282896

 55%|██████████████████████████████████████████▎                                  | 54885/100000 [15:27<15:10, 49.54it/s]
epoch 54900  training loss: 0.005886562634259462

 55%|██████████████████████████████████████████▎                                  | 54985/100000 [15:29<15:06, 49.67it/s]
epoch 55000  training loss: 0.0058642541989684105
epoch 55000  clean testing loss: 29.20823860168457

 55%|██████████████████████████████████████████▍                                  | 55083/100000 [15:31<15:06, 49.56it/s]
epoch 55100  training loss: 0.005837277974933386

 55%|██████████████████████████████████████████▍                                  | 55183/100000 [15:33<15:01, 49.69it/s]
epoch 55200  training loss: 0.00581409502774477

 55%|██████████████████████████████████████████▌                                  | 55285/100000 [15:35<15:04, 49.46it/s]
epoch 55300  training loss: 0.005790320690721273

 55%|██████████████████████████████████████████▋                                  | 55385/100000 [15:37<15:00, 49.55it/s]
epoch 55400  training loss: 0.0057666790671646595

 55%|██████████████████████████████████████████▋                                  | 55482/100000 [15:39<14:50, 49.99it/s]
epoch 55500  training loss: 0.005743884015828371

 56%|██████████████████████████████████████████▊                                  | 55583/100000 [15:41<14:56, 49.55it/s]
epoch 55600  training loss: 0.005720039829611778

 56%|██████████████████████████████████████████▉                                  | 55683/100000 [15:43<14:55, 49.50it/s]
epoch 55700  training loss: 0.005698889959603548

 56%|██████████████████████████████████████████▉                                  | 55783/100000 [15:45<14:53, 49.50it/s]
epoch 55800  training loss: 0.005675335880368948

 56%|███████████████████████████████████████████                                  | 55879/100000 [15:47<14:51, 49.50it/s]
epoch 55900  training loss: 0.005652081687003374

 56%|███████████████████████████████████████████                                  | 55979/100000 [15:49<14:47, 49.61it/s]
epoch 56000  training loss: 0.005629739258438349
epoch 56000  clean testing loss: 29.31612205505371

 56%|███████████████████████████████████████████▏                                 | 56077/100000 [15:51<14:47, 49.52it/s]
epoch 56100  training loss: 0.005605553276836872

 56%|███████████████████████████████████████████▎                                 | 56177/100000 [15:53<14:45, 49.51it/s]
epoch 56200  training loss: 0.005583082791417837

 56%|███████████████████████████████████████████▎                                 | 56276/100000 [15:55<14:43, 49.49it/s]
epoch 56300  training loss: 0.005560547579079866

 56%|███████████████████████████████████████████▍                                 | 56377/100000 [15:57<14:41, 49.48it/s]
epoch 56400  training loss: 0.005538166966289282

 56%|███████████████████████████████████████████▍                                 | 56478/100000 [15:59<14:37, 49.62it/s]
epoch 56500  training loss: 0.005517119076102972

 57%|███████████████████████████████████████████▌                                 | 56576/100000 [16:01<14:32, 49.77it/s]
epoch 56600  training loss: 0.005494226235896349

 57%|███████████████████████████████████████████▋                                 | 56676/100000 [16:03<14:34, 49.52it/s]
epoch 56700  training loss: 0.005471311043947935

 57%|███████████████████████████████████████████▋                                 | 56776/100000 [16:05<14:32, 49.51it/s]
epoch 56800  training loss: 0.005448668729513884

 57%|███████████████████████████████████████████▊                                 | 56872/100000 [16:07<14:29, 49.58it/s]
epoch 56900  training loss: 0.005426017567515373

 57%|███████████████████████████████████████████▊                                 | 56972/100000 [16:09<14:28, 49.52it/s]
epoch 57000  training loss: 0.005405389703810215
epoch 57000  clean testing loss: 29.423486709594727

 57%|███████████████████████████████████████████▉                                 | 57073/100000 [16:11<14:28, 49.45it/s]
epoch 57100  training loss: 0.005386276636272669


 57%|████████████████████████████████████████████                                 | 57194/100000 [16:14<14:21, 49.68it/s]
epoch 57200  training loss: 0.005367289762943983
epoch 57200  clean testing loss: 29.44073486328125
epoch 57300  training loss: 0.005347382742911577

 57%|████████████████████████████████████████████▏                                | 57445/100000 [16:19<14:18, 49.58it/s]
epoch 57400  training loss: 0.005326145328581333

 58%|████████████████████████████████████████████▎                                | 57546/100000 [16:21<14:18, 49.43it/s]
epoch 57500  training loss: 0.005305180791765451

 58%|████████████████████████████████████████████▎                                | 57599/100000 [16:22<14:13, 49.69it/s]
epoch 57600  training loss: 0.00528419716283679
epoch 57600  clean testing loss: 29.479524612426758
epoch 57700  training loss: 0.0052632116712629795
epoch 57700  clean testing loss: 29.489364624023438
epoch 57800  training loss: 0.005242566578090191

 58%|████████████████████████████████████████████▌                                | 57825/100000 [16:29<14:22, 48.90it/s]
epoch 57900  training loss: 0.005221291910856962

 58%|████████████████████████████████████████████▌                                | 57926/100000 [16:31<14:08, 49.57it/s]
epoch 58000  training loss: 0.005200554616749287
epoch 58000  clean testing loss: 29.519739151000977

 58%|████████████████████████████████████████████▋                                | 58024/100000 [16:33<15:04, 46.42it/s]
epoch 58100  training loss: 0.0051786634139716625

 58%|████████████████████████████████████████████▊                                | 58119/100000 [16:35<14:03, 49.64it/s]
epoch 58200  training loss: 0.005157032981514931

 58%|████████████████████████████████████████████▊                                | 58220/100000 [16:37<14:03, 49.55it/s]
epoch 58300  training loss: 0.005136959254741669

 58%|████████████████████████████████████████████▉                                | 58320/100000 [16:39<14:00, 49.59it/s]
epoch 58400  training loss: 0.005116570740938187

 58%|████████████████████████████████████████████▉                                | 58421/100000 [16:41<13:56, 49.69it/s]
epoch 58500  training loss: 0.0050961715169250965

 59%|█████████████████████████████████████████████                                | 58517/100000 [16:43<13:57, 49.56it/s]
epoch 58600  training loss: 0.005081033334136009

 59%|█████████████████████████████████████████████▏                               | 58617/100000 [16:45<13:54, 49.60it/s]
epoch 58700  training loss: 0.005061389412730932

 59%|█████████████████████████████████████████████▏                               | 58717/100000 [16:47<13:52, 49.60it/s]
epoch 58800  training loss: 0.005034128203988075

 59%|█████████████████████████████████████████████▎                               | 58817/100000 [16:49<13:50, 49.59it/s]
epoch 58900  training loss: 0.005012411158531904

 59%|█████████████████████████████████████████████▎                               | 58918/100000 [16:51<13:47, 49.67it/s]
epoch 59000  training loss: 0.004991576541215181
epoch 59000  clean testing loss: 29.616567611694336

 59%|█████████████████████████████████████████████▍                               | 59016/100000 [16:53<14:14, 47.98it/s]
epoch 59100  training loss: 0.0049724457785487175

 59%|█████████████████████████████████████████████▌                               | 59111/100000 [16:55<13:43, 49.68it/s]
epoch 59200  training loss: 0.004951126873493195

 59%|█████████████████████████████████████████████▌                               | 59212/100000 [16:57<13:42, 49.56it/s]
epoch 59300  training loss: 0.004933480639010668

 59%|█████████████████████████████████████████████▋                               | 59312/100000 [16:59<13:40, 49.58it/s]
epoch 59400  training loss: 0.0049107917584478855

 59%|█████████████████████████████████████████████▋                               | 59413/100000 [17:01<13:38, 49.59it/s]
epoch 59500  training loss: 0.004890529438853264

 60%|█████████████████████████████████████████████▊                               | 59513/100000 [17:03<13:36, 49.59it/s]
epoch 59600  training loss: 0.004869959782809019

 60%|█████████████████████████████████████████████▉                               | 59589/100000 [17:04<13:34, 49.61it/s]
epoch 59700  training loss: 0.004849843215197325

 60%|█████████████████████████████████████████████▉                               | 59689/100000 [17:06<13:34, 49.51it/s]
epoch 59800  training loss: 0.004830335732549429

 60%|██████████████████████████████████████████████                               | 59786/100000 [17:08<13:32, 49.51it/s]
epoch 59900  training loss: 0.004811413120478392

 60%|██████████████████████████████████████████████                               | 59883/100000 [17:10<13:27, 49.70it/s]
epoch 60000  training loss: 0.00479546096175909
epoch 60000  clean testing loss: 29.71453857421875


 60%|██████████████████████████████████████████████▎                              | 60084/100000 [17:14<13:24, 49.63it/s]
epoch 60100  training loss: 0.0047729648649692535

 60%|██████████████████████████████████████████████▎                              | 60182/100000 [17:16<13:22, 49.63it/s]
epoch 60200  training loss: 0.004756730515509844

 60%|██████████████████████████████████████████████▍                              | 60282/100000 [17:18<13:21, 49.58it/s]
epoch 60300  training loss: 0.004738533869385719

 60%|██████████████████████████████████████████████▍                              | 60383/100000 [17:21<13:19, 49.56it/s]
epoch 60400  training loss: 0.004720218945294619

 60%|██████████████████████████████████████████████▌                              | 60480/100000 [17:22<13:16, 49.59it/s]
epoch 60500  training loss: 0.004700875375419855

 61%|██████████████████████████████████████████████▋                              | 60580/100000 [17:24<13:14, 49.60it/s]
epoch 60600  training loss: 0.004681748803704977

 61%|██████████████████████████████████████████████▋                              | 60680/100000 [17:27<13:13, 49.56it/s]
epoch 60700  training loss: 0.004662845283746719

 61%|██████████████████████████████████████████████▊                              | 60779/100000 [17:28<13:11, 49.58it/s]
epoch 60800  training loss: 0.004644471220672131

 61%|██████████████████████████████████████████████▉                              | 60880/100000 [17:31<13:09, 49.53it/s]
epoch 60900  training loss: 0.004625038709491491

 61%|██████████████████████████████████████████████▉                              | 60976/100000 [17:32<13:23, 48.56it/s]
epoch 61000  training loss: 0.0046062530018389225
epoch 61000  clean testing loss: 29.799299240112305

 61%|███████████████████████████████████████████████                              | 61074/100000 [17:34<13:02, 49.77it/s]
epoch 61100  training loss: 0.004590990487486124

 61%|███████████████████████████████████████████████                              | 61175/100000 [17:37<13:04, 49.51it/s]
epoch 61200  training loss: 0.004569372162222862

 61%|███████████████████████████████████████████████▏                             | 61275/100000 [17:39<13:15, 48.67it/s]
epoch 61300  training loss: 0.004550308454781771

 61%|███████████████████████████████████████████████▎                             | 61375/100000 [17:41<12:59, 49.54it/s]
epoch 61400  training loss: 0.00453229621052742

 61%|███████████████████████████████████████████████▎                             | 61472/100000 [17:43<12:55, 49.70it/s]
epoch 61500  training loss: 0.004513292573392391

 62%|███████████████████████████████████████████████▍                             | 61573/100000 [17:45<12:52, 49.76it/s]
epoch 61600  training loss: 0.004495039116591215

 62%|███████████████████████████████████████████████▍                             | 61673/100000 [17:47<12:54, 49.51it/s]
epoch 61700  training loss: 0.004476473666727543

 62%|███████████████████████████████████████████████▌                             | 61773/100000 [17:49<12:51, 49.56it/s]
epoch 61800  training loss: 0.0044577536173164845
epoch 61800  clean testing loss: 29.871173858642578
Validation loss variation < 1e-6, trained to interpolation, stop

 62%|███████████████████████████████████████████████▌                             | 61800/100000 [17:49<11:01, 57.77it/s]