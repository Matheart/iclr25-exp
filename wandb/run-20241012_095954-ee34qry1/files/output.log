
  0%|          | 34/100000 [00:06<1:17:02, 21.62it/s]
epoch 0  training loss: 14532.1015625
epoch 0  clean testing loss: 2621.589599609375


  0%|          | 145/100000 [00:10<1:00:07, 27.68it/s]
epoch 100  training loss: 38.61838150024414

  0%|          | 202/100000 [00:12<1:00:33, 27.47it/s]
epoch 200  training loss: 38.08061218261719


  0%|          | 310/100000 [00:16<1:00:12, 27.59it/s]
epoch 300  training loss: 35.49367904663086


  0%|          | 421/100000 [00:20<1:00:04, 27.63it/s]
epoch 400  training loss: 33.06557846069336


  1%|          | 532/100000 [00:24<59:59, 27.64it/s]
epoch 500  training loss: 31.127111434936523


  1%|          | 640/100000 [00:28<59:56, 27.63it/s]
epoch 600  training loss: 38.2510986328125


  1%|          | 751/100000 [00:32<59:50, 27.64it/s]
epoch 700  training loss: 32.91468811035156

  1%|          | 808/100000 [00:34<59:59, 27.56it/s]
epoch 800  training loss: 26.240140914916992


  1%|          | 919/100000 [00:38<59:51, 27.59it/s]
epoch 900  training loss: 34.11891555786133


  1%|          | 1027/100000 [00:42<59:48, 27.58it/s]
epoch 1000  training loss: 23.9114933013916
epoch 1000  clean testing loss: 22.932920455932617


  1%|          | 1138/100000 [00:46<59:44, 27.58it/s]
epoch 1100  training loss: 28.480342864990234


  1%|          | 1249/100000 [00:50<59:38, 27.60it/s]
epoch 1200  training loss: 22.631404876708984

  1%|▏         | 1303/100000 [00:52<1:01:23, 26.79it/s]
epoch 1300  training loss: 23.449020385742188


  1%|▏         | 1414/100000 [00:56<59:40, 27.54it/s]
epoch 1400  training loss: 22.123336791992188


  2%|▏         | 1525/100000 [01:00<59:32, 27.56it/s]
epoch 1500  training loss: 22.553945541381836


  2%|▏         | 1633/100000 [01:04<59:29, 27.56it/s]
epoch 1600  training loss: 22.037487030029297


  2%|▏         | 1744/100000 [01:08<59:25, 27.56it/s]
epoch 1700  training loss: 43.41835021972656

  2%|▏         | 1801/100000 [01:10<59:24, 27.55it/s]
epoch 1800  training loss: 21.27204704284668


  2%|▏         | 1909/100000 [01:14<59:24, 27.52it/s]
epoch 1900  training loss: 20.983427047729492


  2%|▏         | 2020/100000 [01:18<59:26, 27.48it/s]
epoch 2000  training loss: 23.533512115478516
epoch 2000  clean testing loss: 22.2866153717041


  2%|▏         | 2128/100000 [01:22<1:01:11, 26.66it/s]
epoch 2100  training loss: 20.368865966796875


  2%|▏         | 2239/100000 [01:26<59:11, 27.53it/s]
epoch 2200  training loss: 20.15949249267578


  2%|▏         | 2350/100000 [01:30<59:01, 27.57it/s]
epoch 2300  training loss: 20.215925216674805

  2%|▏         | 2404/100000 [01:32<59:16, 27.44it/s]
epoch 2400  training loss: 19.57540512084961


  3%|▎         | 2515/100000 [01:36<59:01, 27.53it/s]
epoch 2500  training loss: 19.491331100463867


  3%|▎         | 2626/100000 [01:40<58:56, 27.53it/s]
epoch 2600  training loss: 18.7867374420166


  3%|▎         | 2737/100000 [01:44<58:52, 27.53it/s]
epoch 2700  training loss: 18.31074333190918


  3%|▎         | 2848/100000 [01:48<58:48, 27.54it/s]
epoch 2800  training loss: 17.673887252807617

  3%|▎         | 2902/100000 [01:50<59:13, 27.32it/s]
epoch 2900  training loss: 17.533658981323242


  3%|▎         | 3010/100000 [01:54<59:09, 27.32it/s]
epoch 3000  training loss: 16.561899185180664
epoch 3000  clean testing loss: 15.767988204956055


  3%|▎         | 3121/100000 [01:58<58:45, 27.48it/s]
epoch 3100  training loss: 15.515625


  3%|▎         | 3232/100000 [02:02<58:36, 27.51it/s]
epoch 3200  training loss: 14.918431282043457


  3%|▎         | 3340/100000 [02:06<58:30, 27.53it/s]
epoch 3300  training loss: 15.397743225097656


  3%|▎         | 3451/100000 [02:10<58:24, 27.55it/s]
epoch 3400  training loss: 13.149496078491211

  4%|▎         | 3505/100000 [02:12<58:40, 27.41it/s]
epoch 3500  training loss: 12.656393051147461


  4%|▎         | 3616/100000 [02:16<58:24, 27.50it/s]
epoch 3600  training loss: 15.252890586853027


  4%|▎         | 3727/100000 [02:20<58:15, 27.54it/s]
epoch 3700  training loss: 11.208755493164062


  4%|▍         | 3835/100000 [02:24<58:13, 27.53it/s]
epoch 3800  training loss: 11.647543907165527


  4%|▍         | 3946/100000 [02:28<58:10, 27.52it/s]
epoch 3900  training loss: 12.37012004852295

  4%|▍         | 4000/100000 [02:30<58:13, 27.48it/s]
epoch 4000  training loss: 9.290132522583008
epoch 4000  clean testing loss: 8.699285507202148


  4%|▍         | 4111/100000 [02:34<58:08, 27.48it/s]
epoch 4100  training loss: 9.64841365814209


  4%|▍         | 4222/100000 [02:38<58:01, 27.51it/s]
epoch 4200  training loss: 7.993615627288818


  4%|▍         | 4327/100000 [02:42<57:56, 27.52it/s]
epoch 4300  training loss: 7.0313849449157715


  4%|▍         | 4441/100000 [02:46<57:53, 27.51it/s]
epoch 4400  training loss: 6.435206890106201


  5%|▍         | 4552/100000 [02:50<57:47, 27.53it/s]
epoch 4500  training loss: 5.251584053039551

  5%|▍         | 4606/100000 [02:52<1:02:22, 25.49it/s]
epoch 4600  training loss: 6.481853008270264


  5%|▍         | 4714/100000 [02:56<57:48, 27.47it/s]
epoch 4700  training loss: 8.562665939331055


  5%|▍         | 4825/100000 [03:00<57:37, 27.53it/s]
epoch 4800  training loss: 2.4588465690612793


  5%|▍         | 4936/100000 [03:04<57:42, 27.46it/s]
epoch 4900  training loss: 69.8605728149414


  5%|▌         | 5044/100000 [03:08<57:28, 27.53it/s]
epoch 5000  training loss: 1.4895730018615723
epoch 5000  clean testing loss: 1.4145398139953613

  5%|▌         | 5101/100000 [03:10<57:36, 27.45it/s]
epoch 5100  training loss: 1.2936511039733887


  5%|▌         | 5209/100000 [03:14<57:33, 27.45it/s]
epoch 5200  training loss: 1.8553237915039062


  5%|▌         | 5320/100000 [03:18<57:29, 27.45it/s]
epoch 5300  training loss: 1.144822597503662


  5%|▌         | 5428/100000 [03:22<1:05:25, 24.09it/s]
epoch 5400  training loss: 1.1681195497512817


  6%|▌         | 5539/100000 [03:26<57:13, 27.51it/s]
epoch 5500  training loss: 1.0347909927368164


  6%|▌         | 5650/100000 [03:30<57:15, 27.46it/s]
epoch 5600  training loss: 1.0077155828475952

  6%|▌         | 5704/100000 [03:32<57:28, 27.34it/s]
epoch 5700  training loss: 1.4435505867004395


  6%|▌         | 5815/100000 [03:36<57:16, 27.41it/s]
epoch 5800  training loss: 0.9955547451972961


  6%|▌         | 5926/100000 [03:40<57:43, 27.16it/s]
epoch 5900  training loss: 0.956171452999115


  6%|▌         | 6034/100000 [03:44<56:56, 27.50it/s]
epoch 6000  training loss: 0.9499161839485168
epoch 6000  clean testing loss: 0.9895960688591003


  6%|▌         | 6145/100000 [03:48<56:49, 27.53it/s]
epoch 6100  training loss: 0.9414798617362976

  6%|▌         | 6199/100000 [03:50<56:49, 27.51it/s]
epoch 6200  training loss: 0.9425705671310425


  6%|▋         | 6307/100000 [03:54<56:55, 27.43it/s]
epoch 6300  training loss: 0.9310829043388367


  6%|▋         | 6418/100000 [03:58<56:43, 27.49it/s]
epoch 6400  training loss: 0.9028293490409851


  7%|▋         | 6529/100000 [04:02<56:47, 27.43it/s]
epoch 6500  training loss: 0.8952237963676453


  7%|▋         | 6640/100000 [04:06<56:49, 27.38it/s]
epoch 6600  training loss: 11.304765701293945


  7%|▋         | 6748/100000 [04:10<56:41, 27.41it/s]
epoch 6700  training loss: 0.8301142454147339

  7%|▋         | 6805/100000 [04:12<56:46, 27.36it/s]
epoch 6800  training loss: 21.15254783630371


  7%|▋         | 6913/100000 [04:16<56:31, 27.45it/s]
epoch 6900  training loss: 0.8136813044548035


  7%|▋         | 7024/100000 [04:20<56:28, 27.44it/s]
epoch 7000  training loss: 0.8380060195922852
epoch 7000  clean testing loss: 0.8019727468490601


  7%|▋         | 7132/100000 [04:24<56:16, 27.50it/s]
epoch 7100  training loss: 0.8278751969337463


  7%|▋         | 7243/100000 [04:28<56:10, 27.52it/s]
epoch 7200  training loss: 0.796142578125


  7%|▋         | 7354/100000 [04:32<56:05, 27.53it/s]
epoch 7300  training loss: 17.930646896362305

  7%|▋         | 7408/100000 [04:34<56:11, 27.46it/s]
epoch 7400  training loss: 0.8220158219337463


  8%|▊         | 7519/100000 [04:38<56:04, 27.49it/s]
epoch 7500  training loss: 0.8278551697731018


  8%|▊         | 7627/100000 [04:42<56:07, 27.43it/s]
epoch 7600  training loss: 0.9457177519798279


  8%|▊         | 7738/100000 [04:46<55:53, 27.51it/s]
epoch 7700  training loss: 0.8759304285049438


  8%|▊         | 7849/100000 [04:50<55:48, 27.52it/s]
epoch 7800  training loss: 0.8135513663291931

  8%|▊         | 7903/100000 [04:52<56:03, 27.39it/s]
epoch 7900  training loss: 0.7625164985656738


  8%|▊         | 8011/100000 [04:56<56:06, 27.32it/s]
epoch 8000  training loss: 3.798140525817871
epoch 8000  clean testing loss: 3.33831524848938


  8%|▊         | 8122/100000 [05:00<55:39, 27.51it/s]
epoch 8100  training loss: 0.7467373609542847


  8%|▊         | 8233/100000 [05:04<55:35, 27.51it/s]
epoch 8200  training loss: 2.444118022918701


  8%|▊         | 8341/100000 [05:08<55:30, 27.52it/s]
epoch 8300  training loss: 0.7487280964851379


  8%|▊         | 8452/100000 [05:12<55:32, 27.47it/s]
epoch 8400  training loss: 0.7398459911346436

  9%|▊         | 8509/100000 [05:14<55:31, 27.46it/s]
epoch 8500  training loss: 0.7445600628852844


  9%|▊         | 8617/100000 [05:18<55:22, 27.50it/s]
epoch 8600  training loss: 0.7224933505058289


  9%|▊         | 8728/100000 [05:22<55:16, 27.52it/s]
epoch 8700  training loss: 0.8034608960151672


  9%|▉         | 8836/100000 [05:26<55:14, 27.51it/s]
epoch 8800  training loss: 0.7219284772872925


  9%|▉         | 8947/100000 [05:30<55:09, 27.51it/s]
epoch 8900  training loss: 0.7118146419525146

  9%|▉         | 9001/100000 [05:32<56:10, 27.00it/s]
epoch 9000  training loss: 0.7006944417953491
epoch 9000  clean testing loss: 0.648286759853363


  9%|▉         | 9112/100000 [05:36<55:07, 27.48it/s]
epoch 9100  training loss: 0.7107599377632141


  9%|▉         | 9223/100000 [05:41<54:59, 27.51it/s]
epoch 9200  training loss: 0.7079492807388306


  9%|▉         | 9334/100000 [05:45<54:58, 27.49it/s]
epoch 9300  training loss: 0.6956855058670044


  9%|▉         | 9442/100000 [05:48<54:42, 27.59it/s]
epoch 9400  training loss: 0.6812917590141296


 10%|▉         | 9553/100000 [05:53<54:38, 27.59it/s]
epoch 9500  training loss: 0.745253324508667

 10%|▉         | 9607/100000 [05:55<54:53, 27.45it/s]
epoch 9600  training loss: 0.6718626618385315


 10%|▉         | 9718/100000 [05:59<54:36, 27.55it/s]
epoch 9700  training loss: 0.9833839535713196


 10%|▉         | 9826/100000 [06:02<54:30, 27.57it/s]
epoch 9800  training loss: 0.6578593850135803


 10%|▉         | 9937/100000 [06:07<54:24, 27.59it/s]
epoch 9900  training loss: 0.8617359399795532


 10%|█         | 10048/100000 [06:11<54:22, 27.58it/s]
epoch 10000  training loss: 0.6469299793243408
epoch 10000  clean testing loss: 0.5954625606536865

 10%|█         | 10102/100000 [06:13<54:38, 27.42it/s]
epoch 10100  training loss: 0.6494356989860535


 10%|█         | 10213/100000 [06:17<54:19, 27.54it/s]
epoch 10200  training loss: 0.6578788757324219


 10%|█         | 10324/100000 [06:21<54:14, 27.55it/s]
epoch 10300  training loss: 0.6219903826713562


 10%|█         | 10432/100000 [06:25<54:14, 27.52it/s]
epoch 10400  training loss: 0.6292173862457275


 11%|█         | 10543/100000 [06:29<54:03, 27.58it/s]
epoch 10500  training loss: 0.60640549659729


 11%|█         | 10654/100000 [06:33<53:57, 27.60it/s]
epoch 10600  training loss: 7.047945976257324

 11%|█         | 10708/100000 [06:35<54:02, 27.54it/s]
epoch 10700  training loss: 0.631546676158905


 11%|█         | 10819/100000 [06:39<53:54, 27.58it/s]
epoch 10800  training loss: 0.6281509399414062


 11%|█         | 10930/100000 [06:43<53:49, 27.58it/s]
epoch 10900  training loss: 7.48959493637085


 11%|█         | 11041/100000 [06:47<53:47, 27.56it/s]
epoch 11000  training loss: 0.6257489919662476
epoch 11000  clean testing loss: 0.5819272994995117


 11%|█         | 11152/100000 [06:51<53:39, 27.60it/s]
epoch 11100  training loss: 0.5751026272773743

 11%|█         | 11206/100000 [06:53<53:58, 27.42it/s]
epoch 11200  training loss: 0.684033989906311


 11%|█▏        | 11314/100000 [06:57<53:41, 27.53it/s]
epoch 11300  training loss: 0.6000545024871826


 11%|█▏        | 11425/100000 [07:01<53:31, 27.58it/s]
epoch 11400  training loss: 0.5991441011428833


 12%|█▏        | 11536/100000 [07:05<53:26, 27.59it/s]
epoch 11500  training loss: 0.5888566374778748


 12%|█▏        | 11647/100000 [07:09<53:22, 27.59it/s]
epoch 11600  training loss: 0.5947402119636536

 12%|█▏        | 11701/100000 [07:11<53:32, 27.48it/s]
epoch 11700  training loss: 0.6129922270774841


 12%|█▏        | 11812/100000 [07:15<53:20, 27.55it/s]
epoch 11800  training loss: 0.5858981013298035


 12%|█▏        | 11923/100000 [07:19<53:13, 27.58it/s]
epoch 11900  training loss: 0.636563241481781


 12%|█▏        | 12034/100000 [07:23<53:08, 27.59it/s]
epoch 12000  training loss: 0.5746691226959229
epoch 12000  clean testing loss: 0.5268329977989197


 12%|█▏        | 12142/100000 [07:27<53:07, 27.56it/s]
epoch 12100  training loss: 0.5771429538726807


 12%|█▏        | 12253/100000 [07:31<53:00, 27.59it/s]
epoch 12200  training loss: 0.5735317468643188

 12%|█▏        | 12307/100000 [07:33<53:11, 27.48it/s]
epoch 12300  training loss: 0.5305495262145996


 12%|█▏        | 12403/100000 [07:36<53:12, 27.44it/s]
epoch 12400  training loss: 0.554602324962616


 13%|█▎        | 12514/100000 [07:40<52:55, 27.55it/s]
epoch 12500  training loss: 0.5565166473388672


 13%|█▎        | 12625/100000 [07:44<52:51, 27.55it/s]
epoch 12600  training loss: 0.6283103227615356


 13%|█▎        | 12736/100000 [07:48<52:43, 27.58it/s]
epoch 12700  training loss: 0.5389533042907715


 13%|█▎        | 12844/100000 [07:52<52:39, 27.58it/s]
epoch 12800  training loss: 0.5412070155143738


 13%|█▎        | 12955/100000 [07:56<52:40, 27.54it/s]
epoch 12900  training loss: 0.5343426465988159

 13%|█▎        | 13009/100000 [07:58<53:04, 27.32it/s]
epoch 13000  training loss: 0.5330234169960022
epoch 13000  clean testing loss: 0.4661647379398346


 13%|█▎        | 13120/100000 [08:02<52:33, 27.55it/s]
epoch 13100  training loss: 0.5543357133865356


 13%|█▎        | 13231/100000 [08:06<52:25, 27.58it/s]
epoch 13200  training loss: 0.589349091053009


 13%|█▎        | 13342/100000 [08:10<52:19, 27.60it/s]
epoch 13300  training loss: 0.5684112906455994


 13%|█▎        | 13450/100000 [08:14<52:29, 27.48it/s]
epoch 13400  training loss: 0.522915780544281

 14%|█▎        | 13507/100000 [08:16<52:24, 27.50it/s]
epoch 13500  training loss: 0.5493859052658081


 14%|█▎        | 13618/100000 [08:20<52:14, 27.56it/s]
epoch 13600  training loss: 0.5165079236030579


 14%|█▎        | 13726/100000 [08:24<54:17, 26.48it/s]
epoch 13700  training loss: 0.5070352554321289


 14%|█▍        | 13837/100000 [08:28<52:06, 27.56it/s]
epoch 13800  training loss: 0.49144622683525085


 14%|█▍        | 13945/100000 [08:32<52:01, 27.57it/s]
epoch 13900  training loss: 0.49733054637908936

 14%|█▍        | 14002/100000 [08:34<52:59, 27.04it/s]
epoch 14000  training loss: 0.48997411131858826
epoch 14000  clean testing loss: 0.4315268099308014


 14%|█▍        | 14113/100000 [08:38<51:57, 27.55it/s]
epoch 14100  training loss: 0.4983530044555664


 14%|█▍        | 14221/100000 [08:42<51:56, 27.53it/s]
epoch 14200  training loss: 0.5097757577896118


 14%|█▍        | 14332/100000 [08:46<51:45, 27.59it/s]
epoch 14300  training loss: 0.4932829439640045


 14%|█▍        | 14443/100000 [08:50<51:40, 27.59it/s]
epoch 14400  training loss: 0.5546463131904602


 15%|█▍        | 14551/100000 [08:54<54:40, 26.05it/s]
epoch 14500  training loss: 0.47859570384025574

 15%|█▍        | 14608/100000 [08:56<51:47, 27.48it/s]
epoch 14600  training loss: 3.6430678367614746


 15%|█▍        | 14719/100000 [09:00<51:32, 27.58it/s]
epoch 14700  training loss: 0.5145439505577087


 15%|█▍        | 14827/100000 [09:04<51:28, 27.58it/s]
epoch 14800  training loss: 0.5003805160522461


 15%|█▍        | 14938/100000 [09:08<51:30, 27.52it/s]
epoch 14900  training loss: 0.4772345721721649


 15%|█▌        | 15049/100000 [09:12<51:19, 27.59it/s]
epoch 15000  training loss: 0.5123934149742126
epoch 15000  clean testing loss: 0.4399612247943878

 15%|█▌        | 15103/100000 [09:14<51:38, 27.40it/s]
epoch 15100  training loss: 0.47814440727233887


 15%|█▌        | 15214/100000 [09:18<51:22, 27.51it/s]
epoch 15200  training loss: 0.4792267382144928


 15%|█▌        | 15325/100000 [09:22<51:10, 27.57it/s]
epoch 15300  training loss: 0.4862753748893738


 15%|█▌        | 15433/100000 [09:26<51:13, 27.51it/s]
epoch 15400  training loss: 0.4652746915817261


 16%|█▌        | 15544/100000 [09:30<51:07, 27.53it/s]
epoch 15500  training loss: 0.4661029279232025

 16%|█▌        | 15598/100000 [09:32<50:59, 27.59it/s]
epoch 15600  training loss: 0.569918155670166


 16%|█▌        | 15709/100000 [09:36<51:02, 27.53it/s]
epoch 15700  training loss: 0.452438086271286


 16%|█▌        | 15820/100000 [09:41<50:53, 27.57it/s]
epoch 15800  training loss: 0.530362606048584


 16%|█▌        | 15931/100000 [09:45<50:46, 27.60it/s]
epoch 15900  training loss: 0.4555372893810272


 16%|█▌        | 16042/100000 [09:49<50:42, 27.59it/s]
epoch 16000  training loss: 0.45574724674224854
epoch 16000  clean testing loss: 0.37966087460517883


 16%|█▌        | 16150/100000 [09:52<50:39, 27.59it/s]
epoch 16100  training loss: 0.45526376366615295

 16%|█▌        | 16207/100000 [09:55<50:47, 27.50it/s]
epoch 16200  training loss: 0.44173476099967957


 16%|█▋        | 16315/100000 [09:59<50:42, 27.51it/s]
epoch 16300  training loss: 0.4726809561252594


 16%|█▋        | 16426/100000 [10:03<50:28, 27.59it/s]
epoch 16400  training loss: 0.4540553689002991


 17%|█▋        | 16537/100000 [10:07<50:24, 27.59it/s]
epoch 16500  training loss: 4.934064865112305


 17%|█▋        | 16648/100000 [10:11<50:21, 27.59it/s]
epoch 16600  training loss: 0.42651230096817017

 17%|█▋        | 16702/100000 [10:13<50:36, 27.43it/s]
epoch 16700  training loss: 2.0245680809020996


 17%|█▋        | 16813/100000 [10:17<50:20, 27.54it/s]
epoch 16800  training loss: 0.44329169392585754


 17%|█▋        | 16921/100000 [10:21<50:21, 27.49it/s]
epoch 16900  training loss: 2.5254294872283936


 17%|█▋        | 17032/100000 [10:25<50:06, 27.59it/s]
epoch 17000  training loss: 0.4271981418132782
epoch 17000  clean testing loss: 0.37430697679519653


 17%|█▋        | 17143/100000 [10:29<50:02, 27.59it/s]
epoch 17100  training loss: 3.3458340167999268


 17%|█▋        | 17251/100000 [10:33<49:59, 27.58it/s]
epoch 17200  training loss: 0.40750738978385925

 17%|█▋        | 17308/100000 [10:35<50:03, 27.53it/s]
epoch 17300  training loss: 0.4201735258102417


 17%|█▋        | 17419/100000 [10:39<49:54, 27.58it/s]
epoch 17400  training loss: 0.40550878643989563


 18%|█▊        | 17527/100000 [10:43<49:49, 27.58it/s]
epoch 17500  training loss: 0.44604453444480896


 18%|█▊        | 17638/100000 [10:47<49:44, 27.60it/s]
epoch 17600  training loss: 0.4324653148651123


 18%|█▊        | 17749/100000 [10:51<49:41, 27.59it/s]
epoch 17700  training loss: 0.6836573481559753

 18%|█▊        | 17803/100000 [10:53<49:55, 27.44it/s]
epoch 17800  training loss: 0.40816807746887207


 18%|█▊        | 17914/100000 [10:57<49:40, 27.55it/s]
epoch 17900  training loss: 0.9959205985069275


 18%|█▊        | 18022/100000 [11:01<49:39, 27.51it/s]
epoch 18000  training loss: 0.44225263595581055
epoch 18000  clean testing loss: 0.35825058817863464


 18%|█▊        | 18133/100000 [11:05<49:26, 27.60it/s]
epoch 18100  training loss: 0.3937898874282837


 18%|█▊        | 18244/100000 [11:09<49:24, 27.58it/s]
epoch 18200  training loss: 0.3923492729663849


 18%|█▊        | 18355/100000 [11:13<49:21, 27.57it/s]
epoch 18300  training loss: 0.3898770213127136

 18%|█▊        | 18409/100000 [11:15<49:23, 27.53it/s]
epoch 18400  training loss: 0.3892268240451813


 19%|█▊        | 18520/100000 [11:19<49:15, 27.57it/s]
epoch 18500  training loss: 0.39527052640914917


 19%|█▊        | 18631/100000 [11:23<49:07, 27.61it/s]
epoch 18600  training loss: 0.42981570959091187


 19%|█▊        | 18739/100000 [11:27<49:06, 27.58it/s]
epoch 18700  training loss: 0.4205184578895569


 19%|█▉        | 18850/100000 [11:31<49:00, 27.60it/s]
epoch 18800  training loss: 0.38945379853248596

 19%|█▉        | 18907/100000 [11:33<49:05, 27.53it/s]
epoch 18900  training loss: 0.3900125026702881


 19%|█▉        | 19015/100000 [11:37<49:07, 27.48it/s]
epoch 19000  training loss: 0.4142460227012634
epoch 19000  clean testing loss: 0.3419892489910126


 19%|█▉        | 19126/100000 [11:41<48:53, 27.57it/s]
epoch 19100  training loss: 0.48025497794151306


 19%|█▉        | 19237/100000 [11:45<48:49, 27.56it/s]
epoch 19200  training loss: 0.39931878447532654


 19%|█▉        | 19348/100000 [11:49<48:46, 27.56it/s]
epoch 19300  training loss: 0.6917355060577393

 19%|█▉        | 19402/100000 [11:51<48:54, 27.46it/s]
epoch 19400  training loss: 0.38197124004364014


 20%|█▉        | 19513/100000 [11:55<48:41, 27.55it/s]
epoch 19500  training loss: 0.8043628931045532


 20%|█▉        | 19621/100000 [11:59<48:35, 27.57it/s]
epoch 19600  training loss: 0.38320761919021606


 20%|█▉        | 19732/100000 [12:03<48:28, 27.60it/s]
epoch 19700  training loss: 1.3869085311889648


 20%|█▉        | 19843/100000 [12:07<48:23, 27.61it/s]
epoch 19800  training loss: 0.37021440267562866


 20%|█▉        | 19954/100000 [12:11<48:20, 27.59it/s]
epoch 19900  training loss: 0.37186115980148315

 20%|██        | 20008/100000 [12:13<48:45, 27.35it/s]
epoch 20000  training loss: 0.3738614022731781
epoch 20000  clean testing loss: 0.31049975752830505


 20%|██        | 20119/100000 [12:17<48:19, 27.55it/s]
epoch 20100  training loss: 0.3756696581840515


 20%|██        | 20230/100000 [12:21<48:13, 27.57it/s]
epoch 20200  training loss: 0.38864436745643616


 20%|██        | 20341/100000 [12:25<48:06, 27.59it/s]
epoch 20300  training loss: 0.38310009241104126


 20%|██        | 20449/100000 [12:29<48:03, 27.59it/s]
epoch 20400  training loss: 0.4532623887062073

 21%|██        | 20503/100000 [12:31<48:18, 27.43it/s]
epoch 20500  training loss: 0.35838377475738525


 21%|██        | 20614/100000 [12:35<48:03, 27.53it/s]
epoch 20600  training loss: 0.43006208539009094


 21%|██        | 20725/100000 [12:39<47:53, 27.59it/s]
epoch 20700  training loss: 0.37690669298171997


 21%|██        | 20836/100000 [12:43<47:49, 27.58it/s]
epoch 20800  training loss: 0.4088148772716522


 21%|██        | 20947/100000 [12:47<47:46, 27.58it/s]
epoch 20900  training loss: 0.3688771426677704

 21%|██        | 21001/100000 [12:49<48:40, 27.05it/s]
epoch 21000  training loss: 0.531844973564148
epoch 21000  clean testing loss: 0.31684380769729614


 21%|██        | 21112/100000 [12:53<47:44, 27.54it/s]
epoch 21100  training loss: 0.3710974454879761


 21%|██        | 21220/100000 [12:57<47:45, 27.49it/s]
epoch 21200  training loss: 0.36178356409072876


 21%|██▏       | 21331/100000 [13:01<47:34, 27.56it/s]
epoch 21300  training loss: 0.35754159092903137


 21%|██▏       | 21442/100000 [13:05<47:24, 27.61it/s]
epoch 21400  training loss: 0.3512820601463318


 22%|██▏       | 21550/100000 [13:09<47:25, 27.57it/s]
epoch 21500  training loss: 0.34688064455986023

 22%|██▏       | 21607/100000 [13:11<47:30, 27.50it/s]
epoch 21600  training loss: 0.34285804629325867


 22%|██▏       | 21718/100000 [13:15<47:19, 27.57it/s]
epoch 21700  training loss: 0.34183189272880554


 22%|██▏       | 21829/100000 [13:19<47:13, 27.58it/s]
epoch 21800  training loss: 0.3448561131954193


 22%|██▏       | 21937/100000 [13:23<47:10, 27.58it/s]
epoch 21900  training loss: 0.3579115569591522


 22%|██▏       | 22048/100000 [13:27<47:12, 27.52it/s]
epoch 22000  training loss: 0.35706931352615356
epoch 22000  clean testing loss: 0.3027752935886383

 22%|██▏       | 22102/100000 [13:29<47:16, 27.47it/s]
epoch 22100  training loss: 0.3428550064563751


 22%|██▏       | 22213/100000 [13:33<47:02, 27.56it/s]
epoch 22200  training loss: 0.4960397779941559


 22%|██▏       | 22324/100000 [13:37<46:56, 27.58it/s]
epoch 22300  training loss: 0.7596628069877625


 22%|██▏       | 22432/100000 [13:41<46:50, 27.60it/s]
epoch 22400  training loss: 0.3350318372249603


 23%|██▎       | 22543/100000 [13:45<46:47, 27.59it/s]
epoch 22500  training loss: 0.34109267592430115


 23%|██▎       | 22654/100000 [13:49<46:44, 27.57it/s]
epoch 22600  training loss: 0.33293333649635315

 23%|██▎       | 22711/100000 [13:51<46:50, 27.50it/s]
epoch 22700  training loss: 0.39536717534065247


 23%|██▎       | 22819/100000 [13:55<46:42, 27.54it/s]
epoch 22800  training loss: 0.3459841310977936


 23%|██▎       | 22930/100000 [13:59<46:35, 27.57it/s]
epoch 22900  training loss: 0.3303964138031006


 23%|██▎       | 23038/100000 [14:03<46:29, 27.59it/s]
epoch 23000  training loss: 0.7859392166137695
epoch 23000  clean testing loss: 1.030862808227539


 23%|██▎       | 23149/100000 [14:07<46:25, 27.59it/s]
epoch 23100  training loss: 0.3253123164176941

 23%|██▎       | 23206/100000 [14:09<46:34, 27.48it/s]
epoch 23200  training loss: 0.3454715311527252


 23%|██▎       | 23314/100000 [14:13<46:27, 27.51it/s]
epoch 23300  training loss: 0.32334280014038086


 23%|██▎       | 23425/100000 [14:17<46:16, 27.58it/s]
epoch 23400  training loss: 0.4369399845600128


 24%|██▎       | 23536/100000 [14:21<46:12, 27.58it/s]
epoch 23500  training loss: 0.3242970108985901


 24%|██▎       | 23647/100000 [14:25<46:05, 27.61it/s]
epoch 23600  training loss: 1.0778595209121704

 24%|██▎       | 23698/100000 [14:27<46:26, 27.38it/s]

epoch 23700  training loss: 0.3287163972854614

 24%|██▍       | 23812/100000 [14:31<46:07, 27.53it/s]
epoch 23800  training loss: 0.8504557609558105


 24%|██▍       | 23923/100000 [14:35<45:59, 27.57it/s]
epoch 23900  training loss: 0.3067610263824463


 24%|██▍       | 24031/100000 [14:39<45:55, 27.57it/s]
epoch 24000  training loss: 0.32006633281707764
epoch 24000  clean testing loss: 0.24497584998607635


 24%|██▍       | 24142/100000 [14:43<45:49, 27.59it/s]
epoch 24100  training loss: 0.319721519947052


 24%|██▍       | 24253/100000 [14:47<45:44, 27.60it/s]
epoch 24200  training loss: 0.32323166728019714

 24%|██▍       | 24307/100000 [14:49<45:52, 27.50it/s]
epoch 24300  training loss: 0.31092679500579834


 24%|██▍       | 24418/100000 [14:53<45:40, 27.58it/s]
epoch 24400  training loss: 0.2970358431339264


 25%|██▍       | 24529/100000 [14:57<45:51, 27.43it/s]
epoch 24500  training loss: 0.3127759099006653


 25%|██▍       | 24637/100000 [15:01<45:33, 27.57it/s]
epoch 24600  training loss: 0.29255542159080505


 25%|██▍       | 24736/100000 [15:05<45:27, 27.59it/s]
epoch 24700  training loss: 0.3288699686527252


 25%|██▍       | 24844/100000 [15:09<45:23, 27.59it/s]
epoch 24800  training loss: 0.3301692605018616

 25%|██▍       | 24901/100000 [15:11<45:25, 27.56it/s]
epoch 24900  training loss: 0.288486510515213


 25%|██▌       | 25339/100000 [15:27<49:22, 25.20it/s]
epoch 25000  training loss: 0.2904667556285858
epoch 25000  clean testing loss: 0.2304954081773758
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu2_size5000_noise1.00e-01_invop1_lr5e-05 ...
epoch 25100  training loss: 0.34488001465797424
epoch 25100  clean testing loss: 0.32396480441093445
epoch 25200  training loss: 0.2900821268558502
epoch 25200  clean testing loss: 0.22785422205924988
epoch 25300  training loss: 0.43016287684440613


 25%|██▌       | 25450/100000 [15:31<45:07, 27.54it/s]
epoch 25400  training loss: 0.29749661684036255

 26%|██▌       | 25507/100000 [15:33<45:10, 27.48it/s]
epoch 25500  training loss: 0.2999425232410431


 26%|██▌       | 25615/100000 [15:37<45:02, 27.52it/s]
epoch 25600  training loss: 0.2904911935329437


 26%|██▌       | 25726/100000 [15:41<44:55, 27.55it/s]
epoch 25700  training loss: 0.292906254529953


 26%|██▌       | 25837/100000 [15:45<44:52, 27.55it/s]
epoch 25800  training loss: 0.27670618891716003


 26%|██▌       | 25948/100000 [15:49<44:42, 27.60it/s]
epoch 25900  training loss: 0.3003233075141907

 26%|██▌       | 26002/100000 [15:51<45:28, 27.12it/s]
epoch 26000  training loss: 0.2745938301086426
epoch 26000  clean testing loss: 0.20896506309509277


 26%|██▌       | 26113/100000 [15:55<44:40, 27.56it/s]
epoch 26100  training loss: 0.2702486217021942


 26%|██▌       | 26221/100000 [15:59<44:40, 27.52it/s]
epoch 26200  training loss: 0.2888159155845642


 26%|██▋       | 26332/100000 [16:03<44:28, 27.61it/s]
epoch 26300  training loss: 0.2610423266887665


 26%|██▋       | 26443/100000 [16:07<44:25, 27.60it/s]
epoch 26400  training loss: 0.2600707411766052


 27%|██▋       | 26554/100000 [16:11<44:22, 27.58it/s]
epoch 26500  training loss: 0.2562965154647827

 27%|██▋       | 26608/100000 [16:13<44:25, 27.53it/s]
epoch 26600  training loss: 0.2738853394985199


 27%|██▋       | 26719/100000 [16:17<44:17, 27.58it/s]
epoch 26700  training loss: 0.253799706697464


 27%|██▋       | 26830/100000 [16:21<44:14, 27.57it/s]
epoch 26800  training loss: 0.2663566768169403


 27%|██▋       | 26941/100000 [16:25<44:08, 27.58it/s]
epoch 26900  training loss: 0.2542784810066223


 27%|██▋       | 27049/100000 [16:29<44:04, 27.59it/s]
epoch 27000  training loss: 0.25225985050201416
epoch 27000  clean testing loss: 0.18408536911010742

 27%|██▋       | 27103/100000 [16:31<44:25, 27.35it/s]
epoch 27100  training loss: 0.2448042929172516


 27%|██▋       | 27214/100000 [16:35<44:01, 27.56it/s]
epoch 27200  training loss: 0.2529447078704834


 27%|██▋       | 27325/100000 [16:39<43:59, 27.53it/s]
epoch 27300  training loss: 0.2506871521472931


 27%|██▋       | 27436/100000 [16:43<43:49, 27.60it/s]
epoch 27400  training loss: 0.2428387701511383


 28%|██▊       | 27547/100000 [16:47<43:45, 27.60it/s]
epoch 27500  training loss: 0.24281051754951477


 28%|██▊       | 27658/100000 [16:51<43:41, 27.60it/s]
epoch 27600  training loss: 0.5390453934669495

 28%|██▊       | 27712/100000 [16:53<43:48, 27.50it/s]
epoch 27700  training loss: 0.2400626689195633


 28%|██▊       | 27820/100000 [16:57<49:07, 24.49it/s]
epoch 27800  training loss: 0.23082055151462555


 28%|██▊       | 27931/100000 [17:01<43:35, 27.56it/s]
epoch 27900  training loss: 0.22833232581615448


 28%|██▊       | 28042/100000 [17:05<43:27, 27.60it/s]
epoch 28000  training loss: 0.23950856924057007
epoch 28000  clean testing loss: 0.17047227919101715


 28%|██▊       | 28153/100000 [17:09<43:33, 27.49it/s]
epoch 28100  training loss: 0.23551979660987854

 28%|██▊       | 28207/100000 [17:11<43:37, 27.42it/s]
epoch 28200  training loss: 0.23134765028953552


 28%|██▊       | 28318/100000 [17:15<43:19, 27.58it/s]
epoch 28300  training loss: 0.23128117620944977


 28%|██▊       | 28429/100000 [17:19<43:15, 27.57it/s]
epoch 28400  training loss: 0.6944248080253601


 29%|██▊       | 28540/100000 [17:23<43:09, 27.59it/s]
epoch 28500  training loss: 0.2292526811361313


 29%|██▊       | 28648/100000 [17:27<45:17, 26.26it/s]
epoch 28600  training loss: 0.2296702116727829

 29%|██▊       | 28702/100000 [17:29<43:19, 27.42it/s]
epoch 28700  training loss: 0.21376550197601318


 29%|██▉       | 28813/100000 [17:33<43:04, 27.55it/s]
epoch 28800  training loss: 0.2302807867527008


 29%|██▉       | 28924/100000 [17:37<42:57, 27.58it/s]
epoch 28900  training loss: 0.22090677917003632


 29%|██▉       | 29035/100000 [17:41<42:53, 27.58it/s]
epoch 29000  training loss: 0.20946940779685974
epoch 29000  clean testing loss: 0.1428571492433548


 29%|██▉       | 29143/100000 [17:45<42:50, 27.57it/s]
epoch 29100  training loss: 0.20930929481983185


 29%|██▉       | 29254/100000 [17:49<42:45, 27.57it/s]
epoch 29200  training loss: 0.5234960913658142

 29%|██▉       | 29311/100000 [17:51<42:48, 27.52it/s]
epoch 29300  training loss: 0.22046425938606262


 29%|██▉       | 29422/100000 [17:55<42:38, 27.59it/s]
epoch 29400  training loss: 0.2117486298084259


 30%|██▉       | 29530/100000 [17:59<42:35, 27.58it/s]
epoch 29500  training loss: 0.6394937634468079


 30%|██▉       | 29641/100000 [18:03<42:30, 27.58it/s]
epoch 29600  training loss: 0.21217145025730133


 30%|██▉       | 29752/100000 [18:07<42:25, 27.60it/s]
epoch 29700  training loss: 0.23996730148792267

 30%|██▉       | 29806/100000 [18:09<42:35, 27.47it/s]
epoch 29800  training loss: 0.20373760163784027


 30%|██▉       | 29917/100000 [18:13<42:23, 27.56it/s]
epoch 29900  training loss: 0.22308924794197083


 30%|███       | 30028/100000 [18:17<42:19, 27.56it/s]
epoch 30000  training loss: 0.1963711678981781
epoch 30000  clean testing loss: 0.12639088928699493


 30%|███       | 30136/100000 [18:21<42:12, 27.59it/s]
epoch 30100  training loss: 0.19707976281642914


 30%|███       | 30247/100000 [18:25<42:13, 27.53it/s]
epoch 30200  training loss: 0.19705581665039062


 30%|███       | 30355/100000 [18:29<42:05, 27.58it/s]
epoch 30300  training loss: 0.19568786025047302

 30%|███       | 30412/100000 [18:31<42:06, 27.55it/s]
epoch 30400  training loss: 0.20051534473896027


 31%|███       | 30523/100000 [18:35<41:59, 27.58it/s]
epoch 30500  training loss: 0.19251178205013275


 31%|███       | 30631/100000 [18:39<41:55, 27.58it/s]
epoch 30600  training loss: 0.19103969633579254


 31%|███       | 30742/100000 [18:43<41:49, 27.60it/s]
epoch 30700  training loss: 0.19911639392375946


 31%|███       | 30853/100000 [18:47<41:48, 27.56it/s]
epoch 30800  training loss: 0.18568627536296844

 31%|███       | 30907/100000 [18:49<41:55, 27.47it/s]
epoch 30900  training loss: 0.3408876061439514


 31%|███       | 31018/100000 [18:53<41:48, 27.50it/s]
epoch 31000  training loss: 0.1912262886762619
epoch 31000  clean testing loss: 0.11893061548471451


 31%|███       | 31129/100000 [18:57<41:37, 27.57it/s]
epoch 31100  training loss: 0.19005966186523438


 31%|███       | 31237/100000 [19:01<41:31, 27.60it/s]
epoch 31200  training loss: 0.19072413444519043


 31%|███▏      | 31348/100000 [19:05<41:26, 27.61it/s]
epoch 31300  training loss: 0.18515798449516296


 31%|███▏      | 31459/100000 [19:09<41:23, 27.60it/s]
epoch 31400  training loss: 0.19482208788394928

 32%|███▏      | 31513/100000 [19:11<41:25, 27.56it/s]
epoch 31500  training loss: 0.1783277988433838


 32%|███▏      | 31624/100000 [19:15<41:18, 27.59it/s]
epoch 31600  training loss: 0.22351957857608795


 32%|███▏      | 31735/100000 [19:19<41:13, 27.60it/s]
epoch 31700  training loss: 0.18892087042331696


 32%|███▏      | 31846/100000 [19:23<41:09, 27.60it/s]
epoch 31800  training loss: 0.4622589647769928


 32%|███▏      | 31957/100000 [19:27<41:13, 27.51it/s]
epoch 31900  training loss: 0.18138627707958221

 32%|███▏      | 32011/100000 [19:29<41:25, 27.35it/s]
epoch 32000  training loss: 0.17907655239105225
epoch 32000  clean testing loss: 0.11074604094028473


 32%|███▏      | 32119/100000 [19:33<41:03, 27.55it/s]
epoch 32100  training loss: 0.17726561427116394


 32%|███▏      | 32230/100000 [19:37<40:56, 27.59it/s]
epoch 32200  training loss: 0.18266315758228302


 32%|███▏      | 32341/100000 [19:41<40:52, 27.59it/s]
epoch 32300  training loss: 0.17982682585716248


 32%|███▏      | 32452/100000 [19:45<40:47, 27.60it/s]
epoch 32400  training loss: 0.17082524299621582

 33%|███▎      | 32506/100000 [19:47<40:54, 27.50it/s]
epoch 32500  training loss: 0.18629112839698792


 33%|███▎      | 32617/100000 [19:51<40:47, 27.53it/s]
epoch 32600  training loss: 0.17312487959861755


 33%|███▎      | 32728/100000 [19:55<40:40, 27.57it/s]
epoch 32700  training loss: 0.23767128586769104


 33%|███▎      | 32836/100000 [19:59<40:37, 27.55it/s]
epoch 32800  training loss: 0.16906321048736572


 33%|███▎      | 32947/100000 [20:03<40:28, 27.61it/s]
epoch 32900  training loss: 0.18289823830127716


 33%|███▎      | 33058/100000 [20:07<40:26, 27.59it/s]
epoch 33000  training loss: 0.17324045300483704
epoch 33000  clean testing loss: 0.10390929877758026

 33%|███▎      | 33112/100000 [20:09<40:29, 27.53it/s]
epoch 33100  training loss: 0.1654118299484253


 33%|███▎      | 33223/100000 [20:13<40:23, 27.56it/s]
epoch 33200  training loss: 0.17048805952072144


 33%|███▎      | 33334/100000 [20:17<40:16, 27.59it/s]
epoch 33300  training loss: 0.1666795015335083


 33%|███▎      | 33445/100000 [20:21<40:13, 27.58it/s]
epoch 33400  training loss: 0.16194719076156616


 34%|███▎      | 33556/100000 [20:25<40:23, 27.41it/s]
epoch 33500  training loss: 0.1683778017759323

 34%|███▎      | 33610/100000 [20:27<40:13, 27.51it/s]
epoch 33600  training loss: 0.1682654470205307


 34%|███▎      | 33718/100000 [20:31<40:03, 27.57it/s]
epoch 33700  training loss: 0.15937665104866028


 34%|███▍      | 33829/100000 [20:35<39:59, 27.57it/s]
epoch 33800  training loss: 0.17228496074676514


 34%|███▍      | 33940/100000 [20:39<39:54, 27.59it/s]
epoch 33900  training loss: 0.16127222776412964


 34%|███▍      | 34051/100000 [20:43<39:50, 27.59it/s]
epoch 34000  training loss: 0.16298089921474457
epoch 34000  clean testing loss: 0.09508807212114334


 34%|███▍      | 34162/100000 [20:47<39:48, 27.56it/s]
epoch 34100  training loss: 0.1805359274148941

 34%|███▍      | 34216/100000 [20:49<39:46, 27.57it/s]
epoch 34200  training loss: 0.15989632904529572


 34%|███▍      | 34327/100000 [20:53<39:40, 27.59it/s]
epoch 34300  training loss: 0.19156473875045776


 34%|███▍      | 34438/100000 [20:57<39:41, 27.53it/s]
epoch 34400  training loss: 0.15643109381198883


 35%|███▍      | 34546/100000 [21:01<39:32, 27.59it/s]
epoch 34500  training loss: 0.16370177268981934


 35%|███▍      | 34657/100000 [21:05<39:29, 27.57it/s]
epoch 34600  training loss: 0.1548459231853485

 35%|███▍      | 34711/100000 [21:07<39:30, 27.54it/s]
epoch 34700  training loss: 0.16160106658935547


 35%|███▍      | 34822/100000 [21:11<39:22, 27.59it/s]
epoch 34800  training loss: 0.16081209480762482


 35%|███▍      | 34933/100000 [21:15<39:18, 27.59it/s]
epoch 34900  training loss: 0.1576295793056488


 35%|███▌      | 35044/100000 [21:20<39:15, 27.58it/s]
epoch 35000  training loss: 0.15473362803459167
epoch 35000  clean testing loss: 0.08704126626253128


 35%|███▌      | 35155/100000 [21:24<39:12, 27.57it/s]
epoch 35100  training loss: 0.15170861780643463


 35%|███▌      | 35263/100000 [21:27<39:10, 27.54it/s]
epoch 35200  training loss: 0.150881826877594

 35%|███▌      | 35317/100000 [21:29<39:19, 27.42it/s]
epoch 35300  training loss: 0.15071459114551544


 35%|███▌      | 35428/100000 [21:34<39:03, 27.56it/s]
epoch 35400  training loss: 0.1527542918920517


 36%|███▌      | 35539/100000 [21:38<38:58, 27.57it/s]
epoch 35500  training loss: 0.15690059959888458


 36%|███▌      | 35650/100000 [21:42<38:51, 27.60it/s]
epoch 35600  training loss: 0.14650432765483856


 36%|███▌      | 35761/100000 [21:46<38:50, 27.56it/s]
epoch 35700  training loss: 0.15191550552845

 36%|███▌      | 35815/100000 [21:48<38:54, 27.49it/s]
epoch 35800  training loss: 0.1518464833498001


 36%|███▌      | 35926/100000 [21:52<38:51, 27.49it/s]
epoch 35900  training loss: 0.1440957486629486


 36%|███▌      | 36037/100000 [21:56<38:39, 27.58it/s]
epoch 36000  training loss: 0.14575757086277008
epoch 36000  clean testing loss: 0.08173110336065292


 36%|███▌      | 36145/100000 [22:00<38:42, 27.50it/s]
epoch 36100  training loss: 0.14309291541576385


 36%|███▋      | 36256/100000 [22:04<38:28, 27.61it/s]
epoch 36200  training loss: 0.1492910385131836

 36%|███▋      | 36310/100000 [22:06<38:39, 27.46it/s]
epoch 36300  training loss: 0.1491849422454834


 36%|███▋      | 36421/100000 [22:10<38:29, 27.53it/s]
epoch 36400  training loss: 0.1481030285358429


 37%|███▋      | 36532/100000 [22:14<38:22, 27.57it/s]
epoch 36500  training loss: 0.14717690646648407


 37%|███▋      | 36643/100000 [22:18<38:16, 27.59it/s]
epoch 36600  training loss: 0.1457146406173706


 37%|███▋      | 36754/100000 [22:22<38:17, 27.53it/s]
epoch 36700  training loss: 0.1480894237756729


 37%|███▋      | 36865/100000 [22:26<38:11, 27.55it/s]
epoch 36800  training loss: 0.29652440547943115

 37%|███▋      | 36919/100000 [22:28<38:08, 27.57it/s]
epoch 36900  training loss: 0.14710669219493866


 37%|███▋      | 37027/100000 [22:32<38:04, 27.57it/s]
epoch 37000  training loss: 0.1406697779893875
epoch 37000  clean testing loss: 0.0753897875547409


 37%|███▋      | 37138/100000 [22:36<38:00, 27.57it/s]
epoch 37100  training loss: 0.13697147369384766


 37%|███▋      | 37249/100000 [22:40<37:58, 27.55it/s]
epoch 37200  training loss: 0.14316332340240479


 37%|███▋      | 37360/100000 [22:44<37:54, 27.54it/s]
epoch 37300  training loss: 0.1922391802072525

 37%|███▋      | 37414/100000 [22:46<37:52, 27.55it/s]
epoch 37400  training loss: 0.13555258512496948


 38%|███▊      | 37510/100000 [22:49<37:51, 27.51it/s]
epoch 37500  training loss: 0.14137467741966248


 38%|███▊      | 37621/100000 [22:53<37:41, 27.58it/s]
epoch 37600  training loss: 0.140925794839859


 38%|███▊      | 37732/100000 [22:57<37:35, 27.60it/s]
epoch 37700  training loss: 0.14048920571804047


 38%|███▊      | 37840/100000 [23:01<37:34, 27.58it/s]
epoch 37800  training loss: 0.1411660611629486


 38%|███▊      | 37951/100000 [23:05<37:28, 27.59it/s]
epoch 37900  training loss: 0.1412823498249054

 38%|███▊      | 38005/100000 [23:07<37:54, 27.25it/s]
epoch 38000  training loss: 0.14022912085056305
epoch 38000  clean testing loss: 0.07112900912761688


 38%|███▊      | 38116/100000 [23:11<37:24, 27.57it/s]
epoch 38100  training loss: 0.1359747052192688


 38%|███▊      | 38227/100000 [23:15<37:19, 27.58it/s]
epoch 38200  training loss: 0.13040712475776672


 38%|███▊      | 38338/100000 [23:19<37:12, 27.61it/s]
epoch 38300  training loss: 0.139396071434021


 38%|███▊      | 38449/100000 [23:23<37:22, 27.45it/s]
epoch 38400  training loss: 0.1400546282529831

 39%|███▊      | 38503/100000 [23:25<37:21, 27.44it/s]
epoch 38500  training loss: 0.1318739652633667


 39%|███▊      | 38614/100000 [23:29<38:33, 26.53it/s]
epoch 38600  training loss: 0.13520239293575287


 39%|███▊      | 38722/100000 [23:33<37:03, 27.56it/s]
epoch 38700  training loss: 0.1302395761013031


 39%|███▉      | 38833/100000 [23:37<36:57, 27.58it/s]
epoch 38800  training loss: 0.12846525013446808


 39%|███▉      | 38944/100000 [23:41<36:52, 27.59it/s]
epoch 38900  training loss: 0.12889203429222107

 39%|███▉      | 38998/100000 [23:43<36:52, 27.58it/s]
epoch 39000  training loss: 0.1267579048871994
epoch 39000  clean testing loss: 0.06345631182193756


 39%|███▉      | 39109/100000 [23:47<36:52, 27.52it/s]
epoch 39100  training loss: 0.12907904386520386


 39%|███▉      | 39220/100000 [23:51<36:44, 27.58it/s]
epoch 39200  training loss: 0.1325114518404007


 39%|███▉      | 39331/100000 [23:55<37:03, 27.28it/s]
epoch 39300  training loss: 0.12755747139453888


 39%|███▉      | 39439/100000 [23:59<38:20, 26.33it/s]
epoch 39400  training loss: 0.1295226663351059


 40%|███▉      | 39550/100000 [24:03<36:34, 27.54it/s]
epoch 39500  training loss: 0.13197597861289978

 40%|███▉      | 39604/100000 [24:05<36:36, 27.50it/s]
epoch 39600  training loss: 0.1245727613568306


 40%|███▉      | 39715/100000 [24:09<36:26, 27.58it/s]
epoch 39700  training loss: 0.13344800472259521


 40%|███▉      | 39826/100000 [24:13<36:20, 27.59it/s]
epoch 39800  training loss: 0.12430089712142944


 40%|███▉      | 39937/100000 [24:17<36:17, 27.59it/s]
epoch 39900  training loss: 0.13138215243816376


 40%|████      | 40048/100000 [24:21<36:15, 27.56it/s]
epoch 40000  training loss: 0.12740744650363922
epoch 40000  clean testing loss: 0.061872173100709915

 40%|████      | 40102/100000 [24:23<36:22, 27.45it/s]
epoch 40100  training loss: 0.12387020885944366


 40%|████      | 40213/100000 [24:27<36:16, 27.46it/s]
epoch 40200  training loss: 0.13215547800064087


 40%|████      | 40321/100000 [24:31<36:03, 27.58it/s]
epoch 40300  training loss: 0.12540319561958313


 40%|████      | 40432/100000 [24:35<36:02, 27.54it/s]
epoch 40400  training loss: 0.15825155377388


 41%|████      | 40543/100000 [24:39<35:54, 27.59it/s]
epoch 40500  training loss: 0.1242440864443779


 41%|████      | 40654/100000 [24:43<35:51, 27.59it/s]
epoch 40600  training loss: 0.12919077277183533

 41%|████      | 40708/100000 [24:45<35:53, 27.53it/s]
epoch 40700  training loss: 0.16098015010356903


 41%|████      | 40819/100000 [24:49<35:51, 27.51it/s]
epoch 40800  training loss: 0.12324237823486328


 41%|████      | 40930/100000 [24:53<35:53, 27.43it/s]
epoch 40900  training loss: 0.1323232352733612


 41%|████      | 41041/100000 [24:57<35:38, 27.57it/s]
epoch 41000  training loss: 0.14344103634357452
epoch 41000  clean testing loss: 0.08299197256565094


 41%|████      | 41149/100000 [25:01<35:32, 27.60it/s]
epoch 41100  training loss: 0.121500164270401

 41%|████      | 41206/100000 [25:04<35:38, 27.49it/s]
epoch 41200  training loss: 0.12475217133760452


 41%|████▏     | 41314/100000 [25:07<35:30, 27.55it/s]
epoch 41300  training loss: 0.17118975520133972


 41%|████▏     | 41425/100000 [25:11<35:25, 27.55it/s]
epoch 41400  training loss: 0.12063480168581009


 42%|████▏     | 41869/100000 [25:28<35:10, 27.55it/s]
epoch 41500  training loss: 0.11973656713962555
epoch 41500  clean testing loss: 0.05721433460712433
epoch 41600  training loss: 0.12282390147447586
epoch 41600  clean testing loss: 0.05828230455517769
epoch 41700  training loss: 0.12517152726650238
epoch 41700  clean testing loss: 0.05796206369996071
epoch 41800  training loss: 0.12374335527420044

 42%|████▏     | 41923/100000 [25:30<38:21, 25.24it/s]
epoch 41900  training loss: 0.11810664087533951


 42%|████▏     | 42031/100000 [25:33<35:01, 27.59it/s]
epoch 42000  training loss: 0.12029649317264557
epoch 42000  clean testing loss: 0.05724205821752548


 42%|████▏     | 42142/100000 [25:38<34:57, 27.59it/s]
epoch 42100  training loss: 0.11822955310344696


 42%|████▏     | 42253/100000 [25:42<34:53, 27.58it/s]
epoch 42200  training loss: 0.11952205747365952

 42%|████▏     | 42307/100000 [25:44<34:56, 27.52it/s]
epoch 42300  training loss: 0.11624988913536072


 42%|████▏     | 42418/100000 [25:48<34:47, 27.59it/s]
epoch 42400  training loss: 0.1172204315662384


 43%|████▎     | 42529/100000 [25:52<34:44, 27.57it/s]
epoch 42500  training loss: 0.11599748581647873


 43%|████▎     | 42640/100000 [25:56<34:48, 27.47it/s]
epoch 42600  training loss: 0.1158967986702919


 43%|████▎     | 42748/100000 [26:00<34:35, 27.58it/s]
epoch 42700  training loss: 0.11698640137910843

 43%|████▎     | 42805/100000 [26:02<34:41, 27.48it/s]
epoch 42800  training loss: 0.1364763379096985


 43%|████▎     | 42916/100000 [26:06<34:35, 27.50it/s]
epoch 42900  training loss: 0.1220412477850914


 43%|████▎     | 43024/100000 [26:10<34:28, 27.54it/s]
epoch 43000  training loss: 0.12037751078605652
epoch 43000  clean testing loss: 0.0542384497821331


 43%|████▎     | 43135/100000 [26:14<34:24, 27.55it/s]
epoch 43100  training loss: 0.11804263293743134


 43%|████▎     | 43246/100000 [26:18<34:16, 27.60it/s]
epoch 43200  training loss: 0.13275986909866333

 43%|████▎     | 43300/100000 [26:20<34:14, 27.60it/s]
epoch 43300  training loss: 0.11633936315774918


 43%|████▎     | 43411/100000 [26:24<34:14, 27.55it/s]
epoch 43400  training loss: 0.12402644008398056


 44%|████▎     | 43522/100000 [26:28<34:12, 27.52it/s]
epoch 43500  training loss: 0.11796736717224121


 44%|████▎     | 43630/100000 [26:32<34:05, 27.56it/s]
epoch 43600  training loss: 0.11407069116830826


 44%|████▎     | 43741/100000 [26:36<33:59, 27.59it/s]
epoch 43700  training loss: 0.12333925813436508


 44%|████▍     | 43852/100000 [26:40<34:00, 27.52it/s]
epoch 43800  training loss: 0.11702533811330795

 44%|████▍     | 43906/100000 [26:42<34:00, 27.50it/s]
epoch 43900  training loss: 0.11967809498310089


 44%|████▍     | 44017/100000 [26:46<33:55, 27.51it/s]
epoch 44000  training loss: 0.1124383881688118
epoch 44000  clean testing loss: 0.05141827091574669


 44%|████▍     | 44128/100000 [26:50<33:46, 27.56it/s]
epoch 44100  training loss: 0.11762192100286484


 44%|████▍     | 44239/100000 [26:54<33:44, 27.55it/s]
epoch 44200  training loss: 0.11218544840812683


 44%|████▍     | 44350/100000 [26:58<33:39, 27.55it/s]
epoch 44300  training loss: 0.11416855454444885

 44%|████▍     | 44404/100000 [27:00<33:43, 27.47it/s]
epoch 44400  training loss: 0.11599364876747131


 45%|████▍     | 44512/100000 [27:04<33:36, 27.52it/s]
epoch 44500  training loss: 0.11760019510984421


 45%|████▍     | 44623/100000 [27:08<33:28, 27.57it/s]
epoch 44600  training loss: 0.11675398796796799


 45%|████▍     | 44734/100000 [27:12<33:25, 27.56it/s]
epoch 44700  training loss: 0.1154278814792633


 45%|████▍     | 44845/100000 [27:16<33:17, 27.61it/s]
epoch 44800  training loss: 0.10899350047111511


 45%|████▍     | 44956/100000 [27:20<33:14, 27.60it/s]
epoch 44900  training loss: 0.10971004515886307

 45%|████▌     | 45010/100000 [27:22<33:26, 27.40it/s]
epoch 45000  training loss: 0.10836630314588547
epoch 45000  clean testing loss: 0.04738316684961319


 45%|████▌     | 45121/100000 [27:26<33:17, 27.47it/s]
epoch 45100  training loss: 0.11243622750043869


 45%|████▌     | 45232/100000 [27:30<33:05, 27.58it/s]
epoch 45200  training loss: 0.10830441862344742


 45%|████▌     | 45340/100000 [27:34<33:00, 27.59it/s]
epoch 45300  training loss: 0.1098281741142273


 45%|████▌     | 45451/100000 [27:38<32:58, 27.56it/s]
epoch 45400  training loss: 0.1128840520977974

 46%|████▌     | 45505/100000 [27:40<33:06, 27.44it/s]
epoch 45500  training loss: 0.1131511703133583


 46%|████▌     | 45616/100000 [27:44<32:54, 27.54it/s]
epoch 45600  training loss: 0.11254638433456421


 46%|████▌     | 45727/100000 [27:48<32:47, 27.59it/s]
epoch 45700  training loss: 0.10971103608608246


 46%|████▌     | 45838/100000 [27:52<32:43, 27.58it/s]
epoch 45800  training loss: 0.10889722406864166


 46%|████▌     | 45949/100000 [27:56<32:44, 27.52it/s]
epoch 45900  training loss: 0.1129523515701294


 46%|████▌     | 46057/100000 [28:00<32:37, 27.55it/s]
epoch 46000  training loss: 0.11037266254425049
epoch 46000  clean testing loss: 0.045571692287921906

 46%|████▌     | 46111/100000 [28:02<32:40, 27.48it/s]
epoch 46100  training loss: 0.1090274378657341


 46%|████▌     | 46222/100000 [28:06<32:29, 27.58it/s]
epoch 46200  training loss: 0.11252348124980927


 46%|████▋     | 46333/100000 [28:10<32:24, 27.59it/s]
epoch 46300  training loss: 0.12082614749670029


 46%|████▋     | 46444/100000 [28:14<32:20, 27.60it/s]
epoch 46400  training loss: 0.11101029813289642


 47%|████▋     | 46555/100000 [28:18<32:17, 27.59it/s]
epoch 46500  training loss: 0.10746826976537704

 47%|████▋     | 46609/100000 [28:20<32:21, 27.51it/s]
epoch 46600  training loss: 0.10915914922952652


 47%|████▋     | 46720/100000 [28:24<32:11, 27.59it/s]
epoch 46700  training loss: 0.11114922910928726


 47%|████▋     | 46831/100000 [28:28<32:08, 27.57it/s]
epoch 46800  training loss: 0.10607195645570755


 47%|████▋     | 46939/100000 [28:32<32:07, 27.53it/s]
epoch 46900  training loss: 0.10921455174684525


 47%|████▋     | 47050/100000 [28:36<31:58, 27.60it/s]
epoch 47000  training loss: 0.11016514897346497
epoch 47000  clean testing loss: 0.0512993149459362


 47%|████▋     | 47158/100000 [28:40<31:54, 27.60it/s]
epoch 47100  training loss: 0.11012224107980728

 47%|████▋     | 47215/100000 [28:42<31:55, 27.56it/s]
epoch 47200  training loss: 0.10590346157550812


 47%|████▋     | 47326/100000 [28:46<31:50, 27.57it/s]
epoch 47300  training loss: 0.10513929277658463


 47%|████▋     | 47434/100000 [28:50<31:49, 27.53it/s]
epoch 47400  training loss: 0.10819628834724426


 48%|████▊     | 47545/100000 [28:54<31:43, 27.55it/s]
epoch 47500  training loss: 0.10752811282873154


 48%|████▊     | 47656/100000 [28:58<31:39, 27.56it/s]
epoch 47600  training loss: 0.10477671772241592

 48%|████▊     | 47713/100000 [29:00<31:39, 27.53it/s]
epoch 47700  training loss: 0.10660067945718765


 48%|████▊     | 47821/100000 [29:04<31:32, 27.58it/s]
epoch 47800  training loss: 0.10522440075874329


 48%|████▊     | 47932/100000 [29:08<31:26, 27.59it/s]
epoch 47900  training loss: 0.10700643062591553


 48%|████▊     | 48040/100000 [29:12<31:22, 27.60it/s]
epoch 48000  training loss: 0.10451919585466385
epoch 48000  clean testing loss: 0.04247258976101875


 48%|████▊     | 48151/100000 [29:16<31:17, 27.61it/s]
epoch 48100  training loss: 0.10713915526866913

 48%|████▊     | 48208/100000 [29:18<31:21, 27.53it/s]
epoch 48200  training loss: 0.10230175405740738


 48%|████▊     | 48319/100000 [29:22<31:15, 27.56it/s]
epoch 48300  training loss: 0.1073586642742157


 48%|████▊     | 48427/100000 [29:26<31:11, 27.56it/s]
epoch 48400  training loss: 0.10299544781446457


 49%|████▊     | 48538/100000 [29:30<31:05, 27.58it/s]
epoch 48500  training loss: 0.10411419719457626


 49%|████▊     | 48649/100000 [29:34<31:00, 27.61it/s]
epoch 48600  training loss: 0.10672865808010101


 49%|████▉     | 48757/100000 [29:38<30:58, 27.58it/s]
epoch 48700  training loss: 0.1294153779745102

 49%|████▉     | 48814/100000 [29:40<30:56, 27.58it/s]
epoch 48800  training loss: 0.10289904475212097


 49%|████▉     | 48925/100000 [29:44<30:50, 27.60it/s]
epoch 48900  training loss: 0.11128737777471542


 49%|████▉     | 49033/100000 [29:48<30:47, 27.59it/s]
epoch 49000  training loss: 0.10224124789237976
epoch 49000  clean testing loss: 0.040602490305900574


 49%|████▉     | 49144/100000 [29:52<30:42, 27.61it/s]
epoch 49100  training loss: 0.10996711999177933


 49%|████▉     | 49255/100000 [29:56<30:37, 27.62it/s]
epoch 49200  training loss: 0.10574306547641754

 49%|████▉     | 49309/100000 [29:58<30:42, 27.51it/s]
epoch 49300  training loss: 0.10188310593366623


 49%|████▉     | 49420/100000 [30:02<30:45, 27.40it/s]
epoch 49400  training loss: 0.11981984227895737


 50%|████▉     | 49531/100000 [30:06<30:28, 27.60it/s]
epoch 49500  training loss: 0.10375917702913284


 50%|████▉     | 49642/100000 [30:10<30:24, 27.61it/s]
epoch 49600  training loss: 0.10496503859758377


 50%|████▉     | 49750/100000 [30:14<30:21, 27.59it/s]
epoch 49700  training loss: 0.10566245019435883


 50%|████▉     | 49849/100000 [30:18<30:17, 27.59it/s]
epoch 49800  training loss: 0.10749831050634384

 50%|████▉     | 49903/100000 [30:20<30:26, 27.43it/s]
epoch 49900  training loss: 0.1399977207183838


 50%|█████     | 50014/100000 [30:24<30:22, 27.42it/s]
epoch 50000  training loss: 0.1077047809958458
epoch 50000  clean testing loss: 0.041681088507175446


 50%|█████     | 50125/100000 [30:28<30:08, 27.58it/s]
epoch 50100  training loss: 0.10802142322063446


 50%|█████     | 50233/100000 [30:32<31:16, 26.52it/s]
epoch 50200  training loss: 0.10619169473648071


 50%|█████     | 50344/100000 [30:36<29:58, 27.61it/s]
epoch 50300  training loss: 0.10503751039505005

 50%|█████     | 50398/100000 [30:38<29:57, 27.59it/s]
epoch 50400  training loss: 0.1014401763677597


 51%|█████     | 50509/100000 [30:42<29:59, 27.51it/s]
epoch 50500  training loss: 0.10123638808727264


 51%|█████     | 50620/100000 [30:46<29:52, 27.54it/s]
epoch 50600  training loss: 0.102063849568367


 51%|█████     | 50731/100000 [30:50<29:46, 27.57it/s]
epoch 50700  training loss: 0.10426214337348938


 51%|█████     | 50842/100000 [30:54<29:41, 27.60it/s]
epoch 50800  training loss: 0.10247775912284851

 51%|█████     | 50896/100000 [30:56<29:44, 27.51it/s]
epoch 50900  training loss: 0.09956835955381393


 51%|█████     | 51007/100000 [31:00<29:54, 27.31it/s]
epoch 51000  training loss: 0.10109519213438034
epoch 51000  clean testing loss: 0.03902490809559822


 51%|█████     | 51115/100000 [31:04<29:37, 27.51it/s]
epoch 51100  training loss: 0.10020489245653152


 51%|█████     | 51226/100000 [31:08<29:27, 27.59it/s]
epoch 51200  training loss: 0.10445987433195114


 51%|█████▏    | 51337/100000 [31:12<29:25, 27.57it/s]
epoch 51300  training loss: 0.1045895516872406


 51%|█████▏    | 51448/100000 [31:16<29:20, 27.58it/s]
epoch 51400  training loss: 0.09975907951593399

 52%|█████▏    | 51502/100000 [31:18<29:28, 27.42it/s]
epoch 51500  training loss: 0.10059412568807602


 52%|█████▏    | 51613/100000 [31:22<29:16, 27.55it/s]
epoch 51600  training loss: 0.10524588078260422


 52%|█████▏    | 51724/100000 [31:26<29:12, 27.55it/s]
epoch 51700  training loss: 0.10252214223146439


 52%|█████▏    | 51835/100000 [31:30<29:11, 27.50it/s]
epoch 51800  training loss: 0.09879283607006073


 52%|█████▏    | 51943/100000 [31:34<29:06, 27.52it/s]
epoch 51900  training loss: 0.10553019493818283

 52%|█████▏    | 52000/100000 [31:36<29:02, 27.54it/s]
epoch 52000  training loss: 0.09937497228384018
epoch 52000  clean testing loss: 0.038030680269002914


 52%|█████▏    | 52108/100000 [31:40<29:01, 27.50it/s]
epoch 52100  training loss: 0.10035160928964615


 52%|█████▏    | 52219/100000 [31:44<28:55, 27.53it/s]
epoch 52200  training loss: 0.10598764568567276


 52%|█████▏    | 52330/100000 [31:48<28:49, 27.56it/s]
epoch 52300  training loss: 0.1009698212146759


 52%|█████▏    | 52441/100000 [31:52<28:44, 27.58it/s]
epoch 52400  training loss: 0.09806717187166214


 53%|█████▎    | 52552/100000 [31:56<28:45, 27.49it/s]
epoch 52500  training loss: 0.10363311320543289

 53%|█████▎    | 52606/100000 [31:58<28:47, 27.43it/s]
epoch 52600  training loss: 0.10362838953733444


 53%|█████▎    | 52714/100000 [32:02<32:56, 23.92it/s]
epoch 52700  training loss: 0.1064319834113121


 53%|█████▎    | 52825/100000 [32:06<28:30, 27.58it/s]
epoch 52800  training loss: 0.0996466875076294


 53%|█████▎    | 52936/100000 [32:10<28:30, 27.51it/s]
epoch 52900  training loss: 0.09846994280815125


 53%|█████▎    | 53047/100000 [32:14<28:25, 27.54it/s]
epoch 53000  training loss: 0.09871803224086761
epoch 53000  clean testing loss: 0.03671860694885254

 53%|█████▎    | 53101/100000 [32:16<28:23, 27.53it/s]
epoch 53100  training loss: 0.09964202344417572


 53%|█████▎    | 53212/100000 [32:20<28:18, 27.55it/s]
epoch 53200  training loss: 0.1002211645245552


 53%|█████▎    | 53323/100000 [32:24<28:13, 27.57it/s]
epoch 53300  training loss: 0.10588926821947098


 53%|█████▎    | 53434/100000 [32:28<28:06, 27.61it/s]
epoch 53400  training loss: 0.10102993249893188


 54%|█████▎    | 53542/100000 [32:32<30:51, 25.09it/s]
epoch 53500  training loss: 0.09798183292150497

 54%|█████▎    | 53599/100000 [32:34<28:02, 27.58it/s]
epoch 53600  training loss: 0.10002945363521576


 54%|█████▎    | 53707/100000 [32:38<28:01, 27.53it/s]
epoch 53700  training loss: 0.10386344790458679


 54%|█████▍    | 53818/100000 [32:42<27:54, 27.59it/s]
epoch 53800  training loss: 0.09976088255643845


 54%|█████▍    | 53929/100000 [32:46<27:50, 27.58it/s]
epoch 53900  training loss: 0.09825215488672256


 54%|█████▍    | 54040/100000 [32:50<27:49, 27.52it/s]
epoch 54000  training loss: 0.10045928508043289
epoch 54000  clean testing loss: 0.03753611817955971


 54%|█████▍    | 54151/100000 [32:54<27:41, 27.60it/s]
epoch 54100  training loss: 0.09809959679841995

 54%|█████▍    | 54205/100000 [32:56<27:48, 27.45it/s]
epoch 54200  training loss: 0.10212638974189758


 54%|█████▍    | 54316/100000 [33:00<27:37, 27.56it/s]
epoch 54300  training loss: 0.09953129291534424


 54%|█████▍    | 54424/100000 [33:04<27:33, 27.56it/s]
epoch 54400  training loss: 0.09720245003700256


 55%|█████▍    | 54535/100000 [33:08<27:27, 27.60it/s]
epoch 54500  training loss: 0.10459167510271072


 55%|█████▍    | 54646/100000 [33:12<27:23, 27.59it/s]
epoch 54600  training loss: 0.09996704012155533

 55%|█████▍    | 54703/100000 [33:14<27:28, 27.47it/s]
epoch 54700  training loss: 0.09674207866191864


 55%|█████▍    | 54811/100000 [33:18<27:22, 27.51it/s]
epoch 54800  training loss: 0.09788697212934494


 55%|█████▍    | 54922/100000 [33:22<27:12, 27.61it/s]
epoch 54900  training loss: 0.09910338371992111


 55%|█████▌    | 55033/100000 [33:26<27:09, 27.60it/s]
epoch 55000  training loss: 0.1004382073879242
epoch 55000  clean testing loss: 0.03712168335914612


 55%|█████▌    | 55144/100000 [33:30<27:05, 27.60it/s]
epoch 55100  training loss: 0.09979202598333359


 55%|█████▌    | 55252/100000 [33:34<27:01, 27.60it/s]
epoch 55200  training loss: 0.10015103220939636

 55%|█████▌    | 55306/100000 [33:36<27:07, 27.46it/s]
epoch 55300  training loss: 0.09914480149745941


 55%|█████▌    | 55417/100000 [33:40<26:58, 27.54it/s]
epoch 55400  training loss: 0.10900159925222397


 56%|█████▌    | 55528/100000 [33:44<26:51, 27.60it/s]
epoch 55500  training loss: 0.09886269271373749


 56%|█████▌    | 55639/100000 [33:48<26:49, 27.56it/s]
epoch 55600  training loss: 0.09953518956899643


 56%|█████▌    | 55750/100000 [33:52<26:42, 27.62it/s]
epoch 55700  training loss: 0.09956662356853485

 56%|█████▌    | 55804/100000 [33:54<26:51, 27.43it/s]
epoch 55800  training loss: 0.10058897733688354


 56%|█████▌    | 55915/100000 [33:58<26:39, 27.56it/s]
epoch 55900  training loss: 0.10190331190824509


 56%|█████▌    | 56026/100000 [34:02<26:35, 27.57it/s]
epoch 56000  training loss: 0.09874129295349121
epoch 56000  clean testing loss: 0.03653297573328018


 56%|█████▌    | 56134/100000 [34:06<26:29, 27.60it/s]
epoch 56100  training loss: 0.09650243073701859


 56%|█████▌    | 56245/100000 [34:10<26:25, 27.59it/s]
epoch 56200  training loss: 0.09591107815504074

 56%|█████▋    | 56299/100000 [34:12<26:24, 27.58it/s]
epoch 56300  training loss: 0.09478823095560074


 56%|█████▋    | 56410/100000 [34:16<26:22, 27.54it/s]
epoch 56400  training loss: 0.09595908224582672


 57%|█████▋    | 56521/100000 [34:20<26:16, 27.57it/s]
epoch 56500  training loss: 0.09561062604188919


 57%|█████▋    | 56632/100000 [34:24<26:10, 27.61it/s]
epoch 56600  training loss: 0.0957009419798851


 57%|█████▋    | 56743/100000 [34:28<26:08, 27.57it/s]
epoch 56700  training loss: 0.09529664367437363


 57%|█████▋    | 56854/100000 [34:32<26:02, 27.61it/s]
epoch 56800  training loss: 0.09508328884840012

 57%|█████▋    | 56908/100000 [34:34<26:06, 27.52it/s]
epoch 56900  training loss: 0.09583719074726105


 57%|█████▋    | 57016/100000 [34:38<26:03, 27.49it/s]
epoch 57000  training loss: 0.0954144075512886
epoch 57000  clean testing loss: 0.034099072217941284


 57%|█████▋    | 57127/100000 [34:42<25:54, 27.58it/s]
epoch 57100  training loss: 0.10004715621471405


 57%|█████▋    | 57238/100000 [34:46<25:50, 27.57it/s]
epoch 57200  training loss: 0.09535139799118042


 57%|█████▋    | 57349/100000 [34:50<25:46, 27.58it/s]
epoch 57300  training loss: 0.09798961877822876

 57%|█████▋    | 57403/100000 [34:52<25:53, 27.42it/s]
epoch 57400  training loss: 0.09844358265399933


 58%|█████▊    | 57514/100000 [34:56<25:41, 27.57it/s]
epoch 57500  training loss: 0.0947972983121872


 58%|█████▊    | 57625/100000 [35:00<25:35, 27.60it/s]
epoch 57600  training loss: 0.1018204316496849


 58%|█████▊    | 57733/100000 [35:04<25:36, 27.52it/s]
epoch 57700  training loss: 0.09452669322490692


 58%|█████▊    | 57844/100000 [35:08<25:28, 27.59it/s]
epoch 57800  training loss: 0.10029726475477219


 58%|█████▊    | 57955/100000 [35:12<25:28, 27.51it/s]
epoch 57900  training loss: 0.09396984428167343

 58%|█████▊    | 58009/100000 [35:14<25:35, 27.35it/s]
epoch 58000  training loss: 0.09978487342596054
epoch 58000  clean testing loss: 0.034527551382780075


 58%|█████▊    | 58120/100000 [35:18<25:18, 27.57it/s]
epoch 58100  training loss: 0.09399070590734482


 58%|█████▊    | 58231/100000 [35:22<25:14, 27.58it/s]
epoch 58200  training loss: 0.10023592412471771


 58%|█████▊    | 58342/100000 [35:26<25:10, 27.57it/s]
epoch 58300  training loss: 0.09458538889884949


 58%|█████▊    | 58450/100000 [35:30<25:06, 27.58it/s]
epoch 58400  training loss: 0.0983666256070137

 59%|█████▊    | 58507/100000 [35:32<25:07, 27.52it/s]
epoch 58500  training loss: 0.09656105935573578


 59%|█████▊    | 58615/100000 [35:36<25:02, 27.55it/s]
epoch 58600  training loss: 0.10013038665056229


 59%|█████▊    | 58726/100000 [35:40<24:56, 27.58it/s]
epoch 58700  training loss: 0.09416873753070831


 59%|█████▉    | 58837/100000 [35:44<24:52, 27.57it/s]
epoch 58800  training loss: 0.09987001866102219


 59%|█████▉    | 58948/100000 [35:48<24:47, 27.59it/s]
epoch 58900  training loss: 0.09414876997470856

 59%|█████▉    | 59002/100000 [35:50<25:14, 27.07it/s]
epoch 59000  training loss: 0.09823146462440491
epoch 59000  clean testing loss: 0.03373236581683159


 59%|█████▉    | 59113/100000 [35:54<24:44, 27.54it/s]
epoch 59100  training loss: 0.09433557093143463


 59%|█████▉    | 59224/100000 [35:58<24:38, 27.58it/s]
epoch 59200  training loss: 0.10031741857528687


 59%|█████▉    | 59332/100000 [36:02<24:36, 27.55it/s]
epoch 59300  training loss: 0.09299882501363754


 59%|█████▉    | 59443/100000 [36:06<24:29, 27.60it/s]
epoch 59400  training loss: 0.09959186613559723


 60%|█████▉    | 59554/100000 [36:10<24:21, 27.67it/s]
epoch 59500  training loss: 0.09420884400606155

 60%|█████▉    | 59608/100000 [36:12<24:27, 27.53it/s]
epoch 59600  training loss: 0.10002848505973816


 60%|█████▉    | 59719/100000 [36:16<24:18, 27.62it/s]
epoch 59700  training loss: 0.093962661921978


 60%|█████▉    | 59830/100000 [36:20<24:12, 27.65it/s]
epoch 59800  training loss: 0.09837818145751953


 60%|█████▉    | 59941/100000 [36:24<24:07, 27.68it/s]
epoch 59900  training loss: 0.09425883740186691


 60%|██████    | 60052/100000 [36:28<24:04, 27.65it/s]
epoch 60000  training loss: 0.09606295824050903
epoch 60000  clean testing loss: 0.03431713953614235

 60%|██████    | 60106/100000 [36:30<24:08, 27.54it/s]
epoch 60100  training loss: 0.09552642703056335


 60%|██████    | 60217/100000 [36:34<24:06, 27.50it/s]
epoch 60200  training loss: 0.0956961140036583


 60%|██████    | 60325/100000 [36:38<23:55, 27.64it/s]
epoch 60300  training loss: 0.09665818512439728


 60%|██████    | 60436/100000 [36:42<23:51, 27.64it/s]
epoch 60400  training loss: 0.09863853454589844


 61%|██████    | 60547/100000 [36:46<23:47, 27.63it/s]
epoch 60500  training loss: 0.09637880325317383

 61%|██████    | 60604/100000 [36:48<23:50, 27.55it/s]
epoch 60600  training loss: 0.09349008649587631


 61%|██████    | 60715/100000 [36:52<23:41, 27.63it/s]
epoch 60700  training loss: 0.09295681864023209


 61%|██████    | 60826/100000 [36:57<23:36, 27.65it/s]
epoch 60800  training loss: 0.09514733403921127


 61%|██████    | 60934/100000 [37:00<23:33, 27.64it/s]
epoch 60900  training loss: 0.09760910272598267


 61%|██████    | 61045/100000 [37:05<23:39, 27.44it/s]
epoch 61000  training loss: 0.09830617159605026
epoch 61000  clean testing loss: 0.03431113809347153

 61%|██████    | 61099/100000 [37:06<23:26, 27.66it/s]
epoch 61100  training loss: 0.09638255089521408


 61%|██████    | 61210/100000 [37:10<23:25, 27.60it/s]
epoch 61200  training loss: 0.09410816431045532


 61%|██████▏   | 61321/100000 [37:14<23:18, 27.65it/s]
epoch 61300  training loss: 0.09281124174594879


 61%|██████▏   | 61432/100000 [37:19<23:14, 27.65it/s]
epoch 61400  training loss: 0.09237202256917953


 62%|██████▏   | 61543/100000 [37:23<23:10, 27.65it/s]
epoch 61500  training loss: 0.09257345646619797


 62%|██████▏   | 61654/100000 [37:27<23:05, 27.67it/s]
epoch 61600  training loss: 0.09271395951509476

 62%|██████▏   | 61708/100000 [37:28<23:06, 27.61it/s]
epoch 61700  training loss: 0.09271088987588882


 62%|██████▏   | 61819/100000 [37:33<23:01, 27.63it/s]
epoch 61800  training loss: 0.09478356689214706


 62%|██████▏   | 61930/100000 [37:37<22:56, 27.66it/s]
epoch 61900  training loss: 0.09730847924947739


 62%|██████▏   | 62041/100000 [37:41<22:52, 27.66it/s]
epoch 62000  training loss: 0.09480325132608414
epoch 62000  clean testing loss: 0.033937811851501465


 62%|██████▏   | 62152/100000 [37:45<22:47, 27.67it/s]
epoch 62100  training loss: 0.0963716134428978

 62%|██████▏   | 62206/100000 [37:47<22:51, 27.56it/s]
epoch 62200  training loss: 0.09662508219480515


 62%|██████▏   | 62317/100000 [37:51<22:44, 27.61it/s]
epoch 62300  training loss: 0.09512142091989517


 62%|██████▏   | 62428/100000 [37:55<22:39, 27.64it/s]
epoch 62400  training loss: 0.09369657933712006


 63%|██████▎   | 62524/100000 [37:58<22:35, 27.65it/s]
epoch 62500  training loss: 0.09139974415302277


 63%|██████▎   | 62635/100000 [38:02<22:32, 27.63it/s]
epoch 62600  training loss: 0.09198934584856033

 63%|██████▎   | 62689/100000 [38:04<24:17, 25.61it/s]
epoch 62700  training loss: 0.093124620616436


 63%|██████▎   | 62800/100000 [38:08<22:29, 27.57it/s]
epoch 62800  training loss: 0.09374503791332245


 63%|██████▎   | 62908/100000 [38:12<22:24, 27.58it/s]
epoch 62900  training loss: 0.09585470706224442


 63%|██████▎   | 63019/100000 [38:16<22:21, 27.56it/s]
epoch 63000  training loss: 0.09634875506162643
epoch 63000  clean testing loss: 0.033485062420368195


 63%|██████▎   | 63130/100000 [38:20<22:15, 27.61it/s]
epoch 63100  training loss: 0.09202305227518082


 63%|██████▎   | 63241/100000 [38:24<22:12, 27.59it/s]
epoch 63200  training loss: 0.09445900470018387

 63%|██████▎   | 63298/100000 [38:26<22:08, 27.62it/s]
epoch 63300  training loss: 0.09758753329515457


 63%|██████▎   | 63409/100000 [38:30<22:10, 27.50it/s]
epoch 63400  training loss: 0.09482955932617188


 64%|██████▎   | 63517/100000 [38:34<24:26, 24.88it/s]
epoch 63500  training loss: 0.0924089252948761


 64%|██████▎   | 63628/100000 [38:38<21:56, 27.63it/s]
epoch 63600  training loss: 0.09245920181274414


 64%|██████▎   | 63739/100000 [38:42<21:53, 27.60it/s]
epoch 63700  training loss: 0.09417681396007538

 64%|██████▍   | 63793/100000 [38:44<21:50, 27.63it/s]
epoch 63800  training loss: 0.0965520367026329


 64%|██████▍   | 63904/100000 [38:48<21:54, 27.46it/s]
epoch 63900  training loss: 0.0954718291759491


 64%|██████▍   | 64015/100000 [38:52<21:50, 27.46it/s]
epoch 64000  training loss: 0.0935254693031311
epoch 64000  clean testing loss: 0.03325887396931648


 64%|██████▍   | 64126/100000 [38:56<21:41, 27.57it/s]
epoch 64100  training loss: 0.09328267723321915


 64%|██████▍   | 64237/100000 [39:00<21:35, 27.61it/s]
epoch 64200  training loss: 0.09323132783174515

 64%|██████▍   | 64291/100000 [39:02<21:31, 27.64it/s]
epoch 64300  training loss: 0.09375128895044327


 64%|██████▍   | 64402/100000 [39:06<21:37, 27.44it/s]
epoch 64400  training loss: 0.09384740889072418


 65%|██████▍   | 64510/100000 [39:10<21:26, 27.59it/s]
epoch 64500  training loss: 0.09475390613079071


 65%|██████▍   | 64621/100000 [39:14<21:20, 27.62it/s]
epoch 64600  training loss: 0.09493674337863922


 65%|██████▍   | 64732/100000 [39:18<21:15, 27.66it/s]
epoch 64700  training loss: 0.09541330486536026


 65%|██████▍   | 64843/100000 [39:22<21:12, 27.62it/s]
epoch 64800  training loss: 0.0943247377872467

 65%|██████▍   | 64900/100000 [39:24<21:09, 27.65it/s]
epoch 64900  training loss: 0.09202124923467636


 65%|██████▌   | 65008/100000 [39:28<21:20, 27.32it/s]
epoch 65000  training loss: 0.09468334168195724
epoch 65000  clean testing loss: 0.032836366444826126


 65%|██████▌   | 65119/100000 [39:32<21:02, 27.63it/s]
epoch 65100  training loss: 0.09353958070278168


 65%|██████▌   | 65230/100000 [39:36<20:59, 27.60it/s]
epoch 65200  training loss: 0.09228186309337616


 65%|██████▌   | 65338/100000 [39:40<20:53, 27.65it/s]
epoch 65300  training loss: 0.09607924520969391

 65%|██████▌   | 65395/100000 [39:42<20:52, 27.62it/s]
epoch 65400  training loss: 0.09313013404607773


 66%|██████▌   | 65506/100000 [39:46<20:52, 27.53it/s]
epoch 65500  training loss: 0.09155531972646713


 66%|██████▌   | 65617/100000 [39:50<20:45, 27.61it/s]
epoch 65600  training loss: 0.09387658536434174


 66%|██████▌   | 65728/100000 [39:54<20:39, 27.65it/s]
epoch 65700  training loss: 0.0956680104136467


 66%|██████▌   | 65836/100000 [39:58<20:36, 27.62it/s]
epoch 65800  training loss: 0.09532764554023743

 66%|██████▌   | 65893/100000 [40:00<20:33, 27.64it/s]
epoch 65900  training loss: 0.09539294242858887


 66%|██████▌   | 66004/100000 [40:04<20:46, 27.28it/s]
epoch 66000  training loss: 0.09305184334516525
epoch 66000  clean testing loss: 0.03197203949093819


 66%|██████▌   | 66112/100000 [40:08<20:28, 27.59it/s]
epoch 66100  training loss: 0.09541162848472595


 66%|██████▌   | 66223/100000 [40:12<20:24, 27.58it/s]
epoch 66200  training loss: 0.091543048620224


 66%|██████▋   | 66334/100000 [40:16<20:18, 27.64it/s]
epoch 66300  training loss: 0.09346560388803482


 66%|██████▋   | 66445/100000 [40:20<20:13, 27.66it/s]
epoch 66400  training loss: 0.09584075212478638

 66%|██████▋   | 66499/100000 [40:22<20:12, 27.64it/s]
epoch 66500  training loss: 0.09530394524335861


 67%|██████▋   | 66610/100000 [40:26<20:10, 27.58it/s]
epoch 66600  training loss: 0.09267672896385193


 67%|██████▋   | 66721/100000 [40:30<20:04, 27.63it/s]
epoch 66700  training loss: 0.09088379889726639


 67%|██████▋   | 66832/100000 [40:34<19:59, 27.65it/s]
epoch 66800  training loss: 0.09951644390821457


 67%|██████▋   | 66940/100000 [40:38<19:55, 27.65it/s]
epoch 66900  training loss: 0.09549716860055923

 67%|██████▋   | 66997/100000 [40:40<19:53, 27.66it/s]
epoch 67000  training loss: 0.09148694574832916
epoch 67000  clean testing loss: 0.03243447095155716


 67%|██████▋   | 67108/100000 [40:44<19:51, 27.61it/s]
epoch 67100  training loss: 0.09138260036706924


 67%|██████▋   | 67219/100000 [40:48<19:46, 27.64it/s]
epoch 67200  training loss: 0.09445593506097794


 67%|██████▋   | 67330/100000 [40:53<19:42, 27.64it/s]
epoch 67300  training loss: 0.0942382961511612


 67%|██████▋   | 67438/100000 [40:56<19:39, 27.61it/s]
epoch 67400  training loss: 0.09261676669120789

 67%|██████▋   | 67495/100000 [40:58<19:35, 27.65it/s]
epoch 67500  training loss: 0.09243140369653702


 68%|██████▊   | 67606/100000 [41:03<19:36, 27.54it/s]
epoch 67600  training loss: 0.09063659608364105


 68%|██████▊   | 67714/100000 [41:06<19:35, 27.46it/s]
epoch 67700  training loss: 0.09015332162380219


 68%|██████▊   | 67825/100000 [41:10<19:24, 27.64it/s]
epoch 67800  training loss: 0.0903167575597763


 68%|██████▊   | 67936/100000 [41:15<19:18, 27.67it/s]
epoch 67900  training loss: 0.09210196137428284


 68%|██████▊   | 68047/100000 [41:19<19:15, 27.66it/s]
epoch 68000  training loss: 0.09444468468427658
epoch 68000  clean testing loss: 0.03301454335451126

 68%|██████▊   | 68101/100000 [41:20<19:15, 27.61it/s]
epoch 68100  training loss: 0.09394749253988266


 68%|██████▊   | 68212/100000 [41:25<19:11, 27.61it/s]
epoch 68200  training loss: 0.09382501989603043


 68%|██████▊   | 68323/100000 [41:29<19:06, 27.64it/s]
epoch 68300  training loss: 0.09238997846841812


 68%|██████▊   | 68434/100000 [41:33<19:01, 27.65it/s]
epoch 68400  training loss: 0.09153789281845093


 69%|██████▊   | 68542/100000 [41:37<19:07, 27.42it/s]
epoch 68500  training loss: 0.0917757898569107

 69%|██████▊   | 68599/100000 [41:39<18:54, 27.67it/s]
epoch 68600  training loss: 0.09020179510116577


 69%|██████▊   | 68710/100000 [41:43<18:51, 27.64it/s]
epoch 68700  training loss: 0.09093942493200302


 69%|██████▉   | 68821/100000 [41:47<18:48, 27.62it/s]
epoch 68800  training loss: 0.0916525200009346


 69%|██████▉   | 68932/100000 [41:51<18:43, 27.66it/s]
epoch 68900  training loss: 0.09108292311429977


 69%|██████▉   | 69040/100000 [41:55<18:41, 27.62it/s]
epoch 69000  training loss: 0.09100224822759628
epoch 69000  clean testing loss: 0.03244634345173836

 69%|██████▉   | 69097/100000 [41:57<18:37, 27.66it/s]
epoch 69100  training loss: 0.09419533610343933


 69%|██████▉   | 69208/100000 [42:01<18:35, 27.60it/s]
epoch 69200  training loss: 0.09177286177873611


 69%|██████▉   | 69319/100000 [42:05<18:30, 27.62it/s]
epoch 69300  training loss: 0.09291324764490128


 69%|██████▉   | 69427/100000 [42:09<18:27, 27.62it/s]
epoch 69400  training loss: 0.09085221588611603


 70%|██████▉   | 69538/100000 [42:13<18:21, 27.65it/s]
epoch 69500  training loss: 0.0932789146900177

 70%|██████▉   | 69595/100000 [42:15<18:19, 27.66it/s]
epoch 69600  training loss: 0.09357254207134247


 70%|██████▉   | 69703/100000 [42:19<18:22, 27.48it/s]
epoch 69700  training loss: 0.09077367931604385


 70%|██████▉   | 69814/100000 [42:23<18:12, 27.63it/s]
epoch 69800  training loss: 0.0925806313753128


 70%|██████▉   | 69925/100000 [42:27<18:07, 27.66it/s]
epoch 69900  training loss: 0.09316007047891617


 70%|███████   | 70036/100000 [42:31<18:04, 27.63it/s]
epoch 70000  training loss: 0.08954621106386185
epoch 70000  clean testing loss: 0.03188248723745346


 70%|███████   | 70147/100000 [42:35<17:59, 27.66it/s]
epoch 70100  training loss: 0.09401801228523254

 70%|███████   | 70201/100000 [42:37<18:13, 27.25it/s]
epoch 70200  training loss: 0.0896468460559845


 70%|███████   | 70312/100000 [42:41<17:55, 27.61it/s]
epoch 70300  training loss: 0.0933573916554451


 70%|███████   | 70423/100000 [42:45<17:50, 27.64it/s]
epoch 70400  training loss: 0.0893237292766571


 71%|███████   | 70534/100000 [42:49<17:44, 27.67it/s]
epoch 70500  training loss: 0.09362298250198364


 71%|███████   | 70645/100000 [42:53<17:41, 27.66it/s]
epoch 70600  training loss: 0.09009706974029541

 71%|███████   | 70699/100000 [42:55<17:40, 27.64it/s]
epoch 70700  training loss: 0.09271270781755447


 71%|███████   | 70810/100000 [42:59<17:37, 27.60it/s]
epoch 70800  training loss: 0.09213851392269135


 71%|███████   | 70921/100000 [43:03<17:31, 27.64it/s]
epoch 70900  training loss: 0.09153344482183456


 71%|███████   | 71029/100000 [43:07<17:44, 27.20it/s]
epoch 71000  training loss: 0.09164493530988693
epoch 71000  clean testing loss: 0.033157214522361755


 71%|███████   | 71140/100000 [43:11<17:22, 27.67it/s]
epoch 71100  training loss: 0.09320852905511856

 71%|███████   | 71197/100000 [43:13<17:21, 27.66it/s]
epoch 71200  training loss: 0.09177514165639877


 71%|███████▏  | 71305/100000 [43:17<17:20, 27.58it/s]
epoch 71300  training loss: 0.09106794744729996


 71%|███████▏  | 71416/100000 [43:21<17:14, 27.63it/s]
epoch 71400  training loss: 0.09359102696180344


 72%|███████▏  | 71527/100000 [43:25<17:09, 27.65it/s]
epoch 71500  training loss: 0.09021363407373428


 72%|███████▏  | 71638/100000 [43:29<17:05, 27.66it/s]
epoch 71600  training loss: 0.09332296997308731


 72%|███████▏  | 71749/100000 [43:33<17:00, 27.67it/s]
epoch 71700  training loss: 0.09106064587831497

 72%|███████▏  | 71806/100000 [43:35<17:02, 27.58it/s]
epoch 71800  training loss: 0.09241721034049988


 72%|███████▏  | 71914/100000 [43:39<16:56, 27.63it/s]
epoch 71900  training loss: 0.09452187269926071


 72%|███████▏  | 72025/100000 [43:43<16:52, 27.64it/s]
epoch 72000  training loss: 0.09127900749444962
epoch 72000  clean testing loss: 0.03227794170379639


 72%|███████▏  | 72136/100000 [43:47<16:46, 27.68it/s]
epoch 72100  training loss: 0.09094858169555664


 72%|███████▏  | 72247/100000 [43:51<16:42, 27.68it/s]
epoch 72200  training loss: 0.09286006540060043

 72%|███████▏  | 72301/100000 [43:53<16:42, 27.63it/s]
epoch 72300  training loss: 0.09470827132463455


 72%|███████▏  | 72412/100000 [43:57<16:38, 27.64it/s]
epoch 72400  training loss: 0.0936514288187027


 73%|███████▎  | 72523/100000 [44:01<16:33, 27.66it/s]
epoch 72500  training loss: 0.09116709232330322


 73%|███████▎  | 72634/100000 [44:05<16:29, 27.65it/s]
epoch 72600  training loss: 0.09307458996772766


 73%|███████▎  | 72742/100000 [44:09<16:25, 27.65it/s]
epoch 72700  training loss: 0.09351827204227448

 73%|███████▎  | 72799/100000 [44:11<16:23, 27.67it/s]
epoch 72800  training loss: 0.09161729365587234


 73%|███████▎  | 72910/100000 [44:15<16:20, 27.62it/s]
epoch 72900  training loss: 0.09368698298931122


 73%|███████▎  | 73021/100000 [44:19<16:19, 27.56it/s]
epoch 73000  training loss: 0.0916350930929184
epoch 73000  clean testing loss: 0.0327812135219574


 73%|███████▎  | 73132/100000 [44:23<16:11, 27.65it/s]
epoch 73100  training loss: 0.0936243012547493


 73%|███████▎  | 73243/100000 [44:27<16:07, 27.66it/s]
epoch 73200  training loss: 0.09233269095420837


 73%|███████▎  | 73351/100000 [44:31<16:04, 27.64it/s]
epoch 73300  training loss: 0.09257704019546509

 73%|███████▎  | 73408/100000 [44:33<16:04, 27.58it/s]
epoch 73400  training loss: 0.09195534139871597


 74%|███████▎  | 73516/100000 [44:37<16:20, 27.02it/s]
epoch 73500  training loss: 0.09180793166160583


 74%|███████▎  | 73627/100000 [44:41<15:54, 27.64it/s]
epoch 73600  training loss: 0.09276706725358963


 74%|███████▎  | 73738/100000 [44:45<15:49, 27.65it/s]
epoch 73700  training loss: 0.09357542544603348


 74%|███████▍  | 73849/100000 [44:49<15:46, 27.64it/s]
epoch 73800  training loss: 0.09355828166007996

 74%|███████▍  | 73903/100000 [44:51<15:48, 27.50it/s]
epoch 73900  training loss: 0.09375384449958801


 74%|███████▍  | 74014/100000 [44:55<15:45, 27.49it/s]
epoch 74000  training loss: 0.09392134100198746
epoch 74000  clean testing loss: 0.03350387513637543


 74%|███████▍  | 74125/100000 [44:59<15:36, 27.64it/s]
epoch 74100  training loss: 0.09324944764375687


 74%|███████▍  | 74236/100000 [45:03<15:32, 27.63it/s]
epoch 74200  training loss: 0.09222142398357391


 74%|███████▍  | 74344/100000 [45:07<15:28, 27.64it/s]
epoch 74300  training loss: 0.09429097175598145

 74%|███████▍  | 74401/100000 [45:09<15:27, 27.60it/s]
epoch 74400  training loss: 0.09500925242900848


 75%|███████▍  | 74512/100000 [45:13<15:23, 27.60it/s]
epoch 74500  training loss: 0.09291292726993561


 75%|███████▍  | 74620/100000 [45:17<15:18, 27.62it/s]
epoch 74600  training loss: 0.09226202219724655


 75%|███████▍  | 74731/100000 [45:21<15:15, 27.60it/s]
epoch 74700  training loss: 0.09254966676235199


 75%|███████▍  | 74842/100000 [45:25<15:11, 27.61it/s]
epoch 74800  training loss: 0.09401761740446091


 75%|███████▍  | 74953/100000 [45:29<15:06, 27.64it/s]
epoch 74900  training loss: 0.09438280016183853

 75%|███████▌  | 75007/100000 [45:31<15:13, 27.37it/s]
epoch 75000  training loss: 0.09338197112083435
epoch 75000  clean testing loss: 0.03297685459256172


 75%|███████▌  | 75118/100000 [45:35<15:01, 27.61it/s]
epoch 75100  training loss: 0.0923798531293869


 75%|███████▌  | 75214/100000 [45:39<15:00, 27.51it/s]
epoch 75200  training loss: 0.09376785904169083


 75%|███████▌  | 75325/100000 [45:43<14:54, 27.59it/s]
epoch 75300  training loss: 0.09221852570772171


 75%|███████▌  | 75436/100000 [45:47<14:49, 27.62it/s]
epoch 75400  training loss: 0.09260215610265732

 75%|███████▌  | 75490/100000 [45:49<14:46, 27.64it/s]
epoch 75500  training loss: 0.09391506016254425


 76%|███████▌  | 75601/100000 [45:53<14:44, 27.59it/s]
epoch 75600  training loss: 0.0928473100066185


 76%|███████▌  | 75712/100000 [45:57<14:39, 27.60it/s]
epoch 75700  training loss: 0.09447299689054489


 76%|███████▌  | 75823/100000 [46:01<14:35, 27.62it/s]
epoch 75800  training loss: 0.0935044139623642


 76%|███████▌  | 75934/100000 [46:05<14:29, 27.66it/s]
epoch 75900  training loss: 0.09419272094964981


 76%|███████▌  | 76042/100000 [46:09<14:29, 27.56it/s]
epoch 76000  training loss: 0.0962226390838623
epoch 76000  clean testing loss: 0.031763359904289246


 76%|███████▌  | 76153/100000 [46:13<14:23, 27.63it/s]
epoch 76100  training loss: 0.09671828150749207

 76%|███████▌  | 76210/100000 [46:15<14:21, 27.61it/s]
epoch 76200  training loss: 0.09708701819181442


 76%|███████▋  | 76318/100000 [46:19<14:17, 27.63it/s]
epoch 76300  training loss: 0.09645169228315353


 76%|███████▋  | 76429/100000 [46:23<14:12, 27.64it/s]
epoch 76400  training loss: 0.09535370767116547


 77%|███████▋  | 76540/100000 [46:27<14:07, 27.67it/s]
epoch 76500  training loss: 0.0964834913611412


 77%|███████▋  | 76651/100000 [46:31<14:04, 27.66it/s]
epoch 76600  training loss: 0.09658044576644897

 77%|███████▋  | 76708/100000 [46:33<14:04, 27.60it/s]
epoch 76700  training loss: 0.09574245661497116


 77%|███████▋  | 76819/100000 [46:37<13:58, 27.64it/s]
epoch 76800  training loss: 0.09517447650432587


 77%|███████▋  | 76927/100000 [46:41<13:54, 27.64it/s]
epoch 76900  training loss: 0.09400977194309235


 77%|███████▋  | 77038/100000 [46:45<13:50, 27.66it/s]
epoch 77000  training loss: 0.09448135644197464
epoch 77000  clean testing loss: 0.032402899116277695


 77%|███████▋  | 77149/100000 [46:49<13:46, 27.65it/s]
epoch 77100  training loss: 0.0958084836602211

 77%|███████▋  | 77203/100000 [46:51<13:50, 27.47it/s]
epoch 77200  training loss: 0.09683392196893692


 77%|███████▋  | 77314/100000 [46:55<13:41, 27.61it/s]
epoch 77300  training loss: 0.0944441705942154


 77%|███████▋  | 77425/100000 [46:59<13:36, 27.64it/s]
epoch 77400  training loss: 0.09399137645959854


 78%|███████▊  | 77536/100000 [47:03<13:31, 27.67it/s]
epoch 77500  training loss: 0.09510593116283417


 78%|███████▊  | 77647/100000 [47:07<13:28, 27.65it/s]
epoch 77600  training loss: 0.09374964237213135

 78%|███████▊  | 77701/100000 [47:09<13:31, 27.48it/s]
epoch 77700  training loss: 0.09383349120616913


 78%|███████▊  | 77812/100000 [47:13<13:24, 27.60it/s]
epoch 77800  training loss: 0.09244834631681442


 78%|███████▊  | 77923/100000 [47:17<13:18, 27.64it/s]
epoch 77900  training loss: 0.09475291520357132


 78%|███████▊  | 78031/100000 [47:21<13:15, 27.62it/s]
epoch 78000  training loss: 0.09263267368078232
epoch 78000  clean testing loss: 0.031335972249507904


 78%|███████▊  | 78142/100000 [47:25<13:10, 27.64it/s]
epoch 78100  training loss: 0.09285273402929306


 78%|███████▊  | 78253/100000 [47:29<13:05, 27.67it/s]
epoch 78200  training loss: 0.09292315691709518

 78%|███████▊  | 78310/100000 [47:31<13:06, 27.56it/s]
epoch 78300  training loss: 0.09296020120382309


 78%|███████▊  | 78421/100000 [47:35<13:00, 27.65it/s]
epoch 78400  training loss: 0.09311935305595398


 79%|███████▊  | 78529/100000 [47:39<13:02, 27.45it/s]
epoch 78500  training loss: 0.09328252822160721


 79%|███████▊  | 78640/100000 [47:43<12:52, 27.63it/s]
epoch 78600  training loss: 0.09178083389997482


 79%|███████▉  | 78751/100000 [47:47<12:48, 27.66it/s]
epoch 78700  training loss: 0.09239985048770905

 79%|███████▉  | 78805/100000 [47:49<12:49, 27.55it/s]
epoch 78800  training loss: 0.09380432218313217


 79%|███████▉  | 78916/100000 [47:53<12:43, 27.63it/s]
epoch 78900  training loss: 0.09232015907764435


 79%|███████▉  | 79027/100000 [47:57<12:39, 27.60it/s]
epoch 79000  training loss: 0.09236195683479309
epoch 79000  clean testing loss: 0.03169459104537964


 79%|███████▉  | 79138/100000 [48:01<12:34, 27.66it/s]
epoch 79100  training loss: 0.0935121402144432


 79%|███████▉  | 79249/100000 [48:05<12:30, 27.65it/s]
epoch 79200  training loss: 0.09139523655176163

 79%|███████▉  | 79303/100000 [48:07<12:32, 27.52it/s]
epoch 79300  training loss: 0.09139388054609299


 79%|███████▉  | 79414/100000 [48:11<12:24, 27.64it/s]
epoch 79400  training loss: 0.09337043017148972


 80%|███████▉  | 79525/100000 [48:15<12:20, 27.65it/s]
epoch 79500  training loss: 0.09387043118476868


 80%|███████▉  | 79633/100000 [48:19<12:16, 27.65it/s]
epoch 79600  training loss: 0.09295138716697693


 80%|███████▉  | 79744/100000 [48:23<12:12, 27.66it/s]
epoch 79700  training loss: 0.09081687033176422

 80%|███████▉  | 79801/100000 [48:25<12:11, 27.63it/s]
epoch 79800  training loss: 0.09280124306678772


 80%|███████▉  | 79912/100000 [48:29<12:07, 27.60it/s]
epoch 79900  training loss: 0.09232628345489502


 80%|████████  | 80023/100000 [48:33<12:03, 27.62it/s]
epoch 80000  training loss: 0.09248358756303787
epoch 80000  clean testing loss: 0.03272799029946327


 80%|████████  | 80131/100000 [48:37<11:58, 27.65it/s]
epoch 80100  training loss: 0.093838170170784


 80%|████████  | 80242/100000 [48:41<11:54, 27.64it/s]
epoch 80200  training loss: 0.09324879199266434


 80%|████████  | 80353/100000 [48:45<11:50, 27.65it/s]
epoch 80300  training loss: 0.0937013030052185

 80%|████████  | 80407/100000 [48:47<11:51, 27.55it/s]
epoch 80400  training loss: 0.09290958195924759


 81%|████████  | 80518/100000 [48:51<11:45, 27.63it/s]
epoch 80500  training loss: 0.09511256217956543


 81%|████████  | 80629/100000 [48:55<11:40, 27.64it/s]
epoch 80600  training loss: 0.0923900306224823


 81%|████████  | 80740/100000 [48:59<11:36, 27.66it/s]
epoch 80700  training loss: 0.09443077445030212


 81%|████████  | 80851/100000 [49:03<11:32, 27.66it/s]
epoch 80800  training loss: 0.09138484299182892

 81%|████████  | 80905/100000 [49:05<11:32, 27.56it/s]
epoch 80900  training loss: 0.09399161487817764


 81%|████████  | 81013/100000 [49:09<11:47, 26.82it/s]
epoch 81000  training loss: 0.09507224708795547
epoch 81000  clean testing loss: 0.03282540291547775


 81%|████████  | 81124/100000 [49:13<11:22, 27.66it/s]
epoch 81100  training loss: 0.09353484958410263


 81%|████████  | 81235/100000 [49:17<11:17, 27.68it/s]
epoch 81200  training loss: 0.09407254308462143


 81%|████████▏ | 81346/100000 [49:21<11:14, 27.66it/s]
epoch 81300  training loss: 0.0941513255238533

 81%|████████▏ | 81403/100000 [49:23<11:16, 27.50it/s]
epoch 81400  training loss: 0.09381265938282013


 82%|████████▏ | 81511/100000 [49:27<11:09, 27.62it/s]
epoch 81500  training loss: 0.09353777766227722


 82%|████████▏ | 81625/100000 [49:31<11:04, 27.64it/s]
epoch 81600  training loss: 0.09300511330366135


 82%|████████▏ | 81733/100000 [49:35<11:03, 27.54it/s]
epoch 81700  training loss: 0.09282952547073364


 82%|████████▏ | 81844/100000 [49:39<11:50, 25.55it/s]
epoch 81800  training loss: 0.09409156441688538


 82%|████████▏ | 81955/100000 [49:43<10:52, 27.64it/s]
epoch 81900  training loss: 0.09431593865156174

 82%|████████▏ | 82009/100000 [49:45<10:57, 27.38it/s]
epoch 82000  training loss: 0.09288700670003891
epoch 82000  clean testing loss: 0.033746808767318726


 82%|████████▏ | 82120/100000 [49:49<10:47, 27.60it/s]
epoch 82100  training loss: 0.09349304437637329


 82%|████████▏ | 82231/100000 [49:53<10:42, 27.66it/s]
epoch 82200  training loss: 0.0931176021695137


 82%|████████▏ | 82342/100000 [49:57<10:39, 27.62it/s]
epoch 82300  training loss: 0.09152860194444656


 82%|████████▏ | 82453/100000 [50:01<10:34, 27.66it/s]
epoch 82400  training loss: 0.09171544015407562

 83%|████████▎ | 82507/100000 [50:03<10:35, 27.54it/s]
epoch 82500  training loss: 0.0927024856209755


 83%|████████▎ | 82618/100000 [50:07<10:29, 27.62it/s]
epoch 82600  training loss: 0.09401338547468185


 83%|████████▎ | 82729/100000 [50:11<10:24, 27.66it/s]
epoch 82700  training loss: 0.0953732430934906


 83%|████████▎ | 82837/100000 [50:15<10:20, 27.65it/s]
epoch 82800  training loss: 0.0944550484418869


 83%|████████▎ | 82948/100000 [50:19<10:15, 27.69it/s]
epoch 82900  training loss: 0.09465374797582626

 83%|████████▎ | 83005/100000 [50:21<10:24, 27.22it/s]
epoch 83000  training loss: 0.09451469779014587
epoch 83000  clean testing loss: 0.032867565751075745


 83%|████████▎ | 83116/100000 [50:25<10:11, 27.63it/s]
epoch 83100  training loss: 0.09357127547264099


 83%|████████▎ | 83227/100000 [50:29<10:06, 27.65it/s]
epoch 83200  training loss: 0.09311650693416595


 83%|████████▎ | 83338/100000 [50:33<10:02, 27.67it/s]
epoch 83300  training loss: 0.09253156185150146


 83%|████████▎ | 83446/100000 [50:37<09:59, 27.60it/s]
epoch 83400  training loss: 0.09313609451055527

 84%|████████▎ | 83500/100000 [50:39<10:09, 27.09it/s]
epoch 83500  training loss: 0.09328806400299072


 84%|████████▎ | 83611/100000 [50:43<09:53, 27.61it/s]
epoch 83600  training loss: 0.09430384635925293


 84%|████████▎ | 83722/100000 [50:47<09:49, 27.60it/s]
epoch 83700  training loss: 0.09469053894281387


 84%|████████▍ | 83833/100000 [50:51<09:44, 27.67it/s]
epoch 83800  training loss: 0.09510285407304764


 84%|████████▍ | 83944/100000 [50:55<09:40, 27.67it/s]
epoch 83900  training loss: 0.09475655108690262

 84%|████████▍ | 83998/100000 [50:57<09:38, 27.67it/s]

epoch 84000  training loss: 0.09511648863554001
epoch 84000  clean testing loss: 0.03313825652003288

 84%|████████▍ | 84109/100000 [51:01<09:36, 27.59it/s]
epoch 84100  training loss: 0.09341840445995331


 84%|████████▍ | 84220/100000 [51:05<09:30, 27.66it/s]
epoch 84200  training loss: 0.09244745224714279


 84%|████████▍ | 84331/100000 [51:09<09:26, 27.67it/s]
epoch 84300  training loss: 0.09318584948778152


 84%|████████▍ | 84442/100000 [51:13<09:22, 27.66it/s]
epoch 84400  training loss: 0.09416478872299194


 85%|████████▍ | 84553/100000 [51:17<09:18, 27.68it/s]
epoch 84500  training loss: 0.09498798847198486

 85%|████████▍ | 84607/100000 [51:19<09:17, 27.59it/s]
epoch 84600  training loss: 0.09499714523553848


 85%|████████▍ | 84718/100000 [51:23<09:13, 27.59it/s]
epoch 84700  training loss: 0.09491568058729172


 85%|████████▍ | 84829/100000 [51:27<09:08, 27.67it/s]
epoch 84800  training loss: 0.09304657578468323


 85%|████████▍ | 84940/100000 [51:31<09:04, 27.66it/s]
epoch 84900  training loss: 0.09365765005350113


 85%|████████▌ | 85051/100000 [51:35<09:00, 27.66it/s]
epoch 85000  training loss: 0.09560175240039825
epoch 85000  clean testing loss: 0.033735472708940506

 85%|████████▌ | 85105/100000 [51:37<09:00, 27.55it/s]
epoch 85100  training loss: 0.09538477659225464


 85%|████████▌ | 85216/100000 [51:41<08:55, 27.62it/s]
epoch 85200  training loss: 0.09368332475423813


 85%|████████▌ | 85327/100000 [51:45<08:50, 27.65it/s]
epoch 85300  training loss: 0.09468282014131546


 85%|████████▌ | 85435/100000 [51:49<08:47, 27.61it/s]
epoch 85400  training loss: 0.09581625461578369


 86%|████████▌ | 85546/100000 [51:53<08:43, 27.61it/s]
epoch 85500  training loss: 0.09492845088243484

 86%|████████▌ | 85603/100000 [51:55<08:46, 27.35it/s]
epoch 85600  training loss: 0.09354473650455475


 86%|████████▌ | 85714/100000 [51:59<08:36, 27.65it/s]
epoch 85700  training loss: 0.09467339515686035


 86%|████████▌ | 85825/100000 [52:03<08:32, 27.66it/s]
epoch 85800  training loss: 0.09508809447288513


 86%|████████▌ | 85936/100000 [52:07<08:28, 27.67it/s]
epoch 85900  training loss: 0.09543720632791519


 86%|████████▌ | 86044/100000 [52:11<08:24, 27.66it/s]
epoch 86000  training loss: 0.09611838310956955
epoch 86000  clean testing loss: 0.03391294926404953


 86%|████████▌ | 86155/100000 [52:15<08:20, 27.66it/s]
epoch 86100  training loss: 0.09624623507261276

 86%|████████▌ | 86209/100000 [52:17<08:19, 27.59it/s]
epoch 86200  training loss: 0.09563767910003662


 86%|████████▋ | 86320/100000 [52:21<08:15, 27.59it/s]
epoch 86300  training loss: 0.09594839811325073


 86%|████████▋ | 86431/100000 [52:25<08:10, 27.65it/s]
epoch 86400  training loss: 0.09579355269670486


 87%|████████▋ | 86542/100000 [52:29<08:06, 27.67it/s]
epoch 86500  training loss: 0.09437251091003418


 87%|████████▋ | 86653/100000 [52:33<08:02, 27.67it/s]
epoch 86600  training loss: 0.0937512218952179

 87%|████████▋ | 86707/100000 [52:35<08:02, 27.57it/s]
epoch 86700  training loss: 0.09341751784086227


 87%|████████▋ | 86818/100000 [52:39<07:56, 27.65it/s]
epoch 86800  training loss: 0.09392079710960388


 87%|████████▋ | 86929/100000 [52:44<07:52, 27.65it/s]
epoch 86900  training loss: 0.0946669802069664


 87%|████████▋ | 87040/100000 [52:48<07:48, 27.67it/s]
epoch 87000  training loss: 0.0948302149772644
epoch 87000  clean testing loss: 0.03341241553425789


 87%|████████▋ | 87148/100000 [52:51<07:44, 27.64it/s]
epoch 87100  training loss: 0.0936611071228981

 87%|████████▋ | 87205/100000 [52:54<07:44, 27.56it/s]
epoch 87200  training loss: 0.09504958242177963


 87%|████████▋ | 87316/100000 [52:58<07:39, 27.60it/s]
epoch 87300  training loss: 0.09232208877801895


 87%|████████▋ | 87427/100000 [53:02<07:34, 27.66it/s]
epoch 87400  training loss: 0.09393094480037689


 88%|████████▊ | 87538/100000 [53:06<07:30, 27.67it/s]
epoch 87500  training loss: 0.09437099099159241


 88%|████████▊ | 87649/100000 [53:10<07:26, 27.68it/s]
epoch 87600  training loss: 0.09314656257629395

 88%|████████▊ | 87703/100000 [53:12<07:27, 27.51it/s]
epoch 87700  training loss: 0.09225582331418991


 88%|████████▊ | 87811/100000 [53:15<07:21, 27.61it/s]
epoch 87800  training loss: 0.09244059771299362


 88%|████████▊ | 87922/100000 [53:20<07:17, 27.61it/s]
epoch 87900  training loss: 0.09264125674962997


 88%|████████▊ | 88021/100000 [53:23<07:14, 27.59it/s]
epoch 88000  training loss: 0.0937090739607811
epoch 88000  clean testing loss: 0.032863255590200424


 88%|████████▊ | 88129/100000 [53:27<07:09, 27.65it/s]
epoch 88100  training loss: 0.09250064194202423

 88%|████████▊ | 88186/100000 [53:29<07:06, 27.67it/s]
epoch 88200  training loss: 0.09134930372238159


 88%|████████▊ | 88297/100000 [53:33<07:03, 27.66it/s]
epoch 88300  training loss: 0.09102954715490341


 88%|████████▊ | 88408/100000 [53:37<07:00, 27.58it/s]
epoch 88400  training loss: 0.0913519412279129


 89%|████████▊ | 88516/100000 [53:41<06:58, 27.45it/s]
epoch 88500  training loss: 0.09309905767440796


 89%|████████▊ | 88627/100000 [53:45<06:51, 27.64it/s]
epoch 88600  training loss: 0.09107059985399246


 89%|████████▊ | 88738/100000 [53:49<06:47, 27.67it/s]
epoch 88700  training loss: 0.09279445558786392


 89%|████████▉ | 88849/100000 [53:53<06:43, 27.65it/s]
epoch 88800  training loss: 0.09170068055391312

 89%|████████▉ | 88903/100000 [53:55<06:43, 27.52it/s]
epoch 88900  training loss: 0.09109846502542496


 89%|████████▉ | 89014/100000 [53:59<06:38, 27.54it/s]
epoch 89000  training loss: 0.09319884330034256
epoch 89000  clean testing loss: 0.03238842263817787


 89%|████████▉ | 89125/100000 [54:03<06:33, 27.63it/s]
epoch 89100  training loss: 0.09347867965698242


 89%|████████▉ | 89236/100000 [54:07<06:29, 27.65it/s]
epoch 89200  training loss: 0.09102364629507065


 89%|████████▉ | 89344/100000 [54:11<06:30, 27.30it/s]
epoch 89300  training loss: 0.09144662320613861

 89%|████████▉ | 89401/100000 [54:13<06:23, 27.63it/s]
epoch 89400  training loss: 0.09343857318162918


 90%|████████▉ | 89512/100000 [54:17<06:19, 27.61it/s]
epoch 89500  training loss: 0.09146611392498016


 90%|████████▉ | 89623/100000 [54:21<06:16, 27.56it/s]
epoch 89600  training loss: 0.0917946919798851


 90%|████████▉ | 89734/100000 [54:25<06:11, 27.66it/s]
epoch 89700  training loss: 0.09397564828395844


 90%|████████▉ | 89842/100000 [54:29<06:07, 27.64it/s]
epoch 89800  training loss: 0.09177672117948532


 90%|████████▉ | 89953/100000 [54:33<06:03, 27.65it/s]
epoch 89900  training loss: 0.09182465821504593

 90%|█████████ | 90010/100000 [54:35<06:05, 27.36it/s]
epoch 90000  training loss: 0.09446156024932861
epoch 90000  clean testing loss: 0.032786399126052856


 90%|█████████ | 90121/100000 [54:39<05:57, 27.66it/s]
epoch 90100  training loss: 0.09251637756824493


 90%|█████████ | 90229/100000 [54:43<05:54, 27.59it/s]
epoch 90200  training loss: 0.09127669781446457


 90%|█████████ | 90340/100000 [54:47<05:49, 27.65it/s]
epoch 90300  training loss: 0.0930284857749939


 90%|█████████ | 90451/100000 [54:51<05:45, 27.65it/s]
epoch 90400  training loss: 0.09446326643228531

 91%|█████████ | 90505/100000 [54:53<05:44, 27.56it/s]
epoch 90500  training loss: 0.09361590445041656


 91%|█████████ | 90616/100000 [54:57<05:40, 27.56it/s]
epoch 90600  training loss: 0.09166249632835388


 91%|█████████ | 90727/100000 [55:01<05:35, 27.63it/s]
epoch 90700  training loss: 0.09349911659955978


 91%|█████████ | 90838/100000 [55:05<05:31, 27.65it/s]
epoch 90800  training loss: 0.09401686489582062


 91%|█████████ | 90949/100000 [55:09<05:27, 27.64it/s]
epoch 90900  training loss: 0.0918515995144844

 91%|█████████ | 91003/100000 [55:11<05:50, 25.69it/s]
epoch 91000  training loss: 0.09359950572252274
epoch 91000  clean testing loss: 0.03265763446688652


 91%|█████████▏| 91444/100000 [55:27<05:10, 27.56it/s]
epoch 91100  training loss: 0.09425457566976547
epoch 91100  clean testing loss: 0.032804083079099655
epoch 91200  training loss: 0.09214179217815399
epoch 91200  clean testing loss: 0.03231927379965782
epoch 91300  training loss: 0.09303217381238937
epoch 91300  clean testing loss: 0.03248875215649605
epoch 91400  training loss: 0.0947493240237236

 92%|█████████▏| 91501/100000 [55:29<05:07, 27.63it/s]
epoch 91500  training loss: 0.09165720641613007


 92%|█████████▏| 91612/100000 [55:33<05:04, 27.58it/s]
epoch 91600  training loss: 0.09441723674535751


 92%|█████████▏| 91720/100000 [55:37<05:00, 27.60it/s]
epoch 91700  training loss: 0.0922413319349289


 92%|█████████▏| 91831/100000 [55:41<05:12, 26.10it/s]
epoch 91800  training loss: 0.09475093334913254


 92%|█████████▏| 91942/100000 [55:45<04:52, 27.56it/s]
epoch 91900  training loss: 0.09294743090867996


 92%|█████████▏| 92053/100000 [55:49<04:48, 27.58it/s]
epoch 92000  training loss: 0.09398836642503738
epoch 92000  clean testing loss: 0.03220447897911072

 92%|█████████▏| 92107/100000 [55:51<04:48, 27.38it/s]
epoch 92100  training loss: 0.0932430848479271


 92%|█████████▏| 92218/100000 [55:55<04:41, 27.60it/s]
epoch 92200  training loss: 0.09376057982444763


 92%|█████████▏| 92329/100000 [55:59<04:37, 27.60it/s]
epoch 92300  training loss: 0.09217328578233719


 92%|█████████▏| 92440/100000 [56:03<04:33, 27.64it/s]
epoch 92400  training loss: 0.09444218873977661


 93%|█████████▎| 92551/100000 [56:07<04:29, 27.64it/s]
epoch 92500  training loss: 0.09176891297101974

 93%|█████████▎| 92605/100000 [56:09<04:28, 27.53it/s]
epoch 92600  training loss: 0.09398584812879562


 93%|█████████▎| 92713/100000 [56:13<04:24, 27.54it/s]
epoch 92700  training loss: 0.09208278357982635


 93%|█████████▎| 92824/100000 [56:17<04:20, 27.57it/s]
epoch 92800  training loss: 0.09369867295026779


 93%|█████████▎| 92935/100000 [56:21<04:16, 27.59it/s]
epoch 92900  training loss: 0.09180231392383575


 93%|█████████▎| 93046/100000 [56:25<04:12, 27.53it/s]
epoch 93000  training loss: 0.09402387589216232
epoch 93000  clean testing loss: 0.031648047268390656

 93%|█████████▎| 93100/100000 [56:27<04:09, 27.61it/s]
epoch 93100  training loss: 0.09313084185123444


 93%|█████████▎| 93211/100000 [56:31<04:06, 27.53it/s]
epoch 93200  training loss: 0.09175047278404236


 93%|█████████▎| 93322/100000 [56:35<04:01, 27.62it/s]
epoch 93300  training loss: 0.09271156787872314


 93%|█████████▎| 93433/100000 [56:39<03:57, 27.62it/s]
epoch 93400  training loss: 0.09339240193367004


 94%|█████████▎| 93541/100000 [56:43<03:54, 27.53it/s]
epoch 93500  training loss: 0.09124735742807388


 94%|█████████▎| 93652/100000 [56:47<03:50, 27.52it/s]
epoch 93600  training loss: 0.09205146133899689

 94%|█████████▎| 93709/100000 [56:50<03:48, 27.52it/s]
epoch 93700  training loss: 0.0917886421084404


 94%|█████████▍| 93820/100000 [56:54<03:44, 27.53it/s]
epoch 93800  training loss: 0.09191101789474487


 94%|█████████▍| 93928/100000 [56:57<03:40, 27.56it/s]
epoch 93900  training loss: 0.09177213907241821


 94%|█████████▍| 94039/100000 [57:02<03:35, 27.60it/s]
epoch 94000  training loss: 0.09108229726552963
epoch 94000  clean testing loss: 0.031354211270809174


 94%|█████████▍| 94150/100000 [57:06<03:32, 27.50it/s]
epoch 94100  training loss: 0.09216806292533875

 94%|█████████▍| 94204/100000 [57:07<03:31, 27.46it/s]
epoch 94200  training loss: 0.09276439994573593


 94%|█████████▍| 94315/100000 [57:12<03:43, 25.46it/s]
epoch 94300  training loss: 0.09184722602367401


 94%|█████████▍| 94426/100000 [57:16<03:21, 27.60it/s]
epoch 94400  training loss: 0.0915355533361435


 95%|█████████▍| 94537/100000 [57:20<03:17, 27.62it/s]
epoch 94500  training loss: 0.09241008013486862


 95%|█████████▍| 94645/100000 [57:24<03:14, 27.60it/s]
epoch 94600  training loss: 0.09141581505537033


 95%|█████████▍| 94756/100000 [57:28<03:09, 27.60it/s]
epoch 94700  training loss: 0.09244827926158905

 95%|█████████▍| 94813/100000 [57:30<03:08, 27.59it/s]
epoch 94800  training loss: 0.0906648263335228


 95%|█████████▍| 94924/100000 [57:34<03:03, 27.62it/s]
epoch 94900  training loss: 0.09219617396593094


 95%|█████████▌| 95032/100000 [57:38<02:59, 27.61it/s]
epoch 95000  training loss: 0.09069579094648361
epoch 95000  clean testing loss: 0.03103579580783844


 95%|█████████▌| 95143/100000 [57:42<02:55, 27.63it/s]
epoch 95100  training loss: 0.09256330132484436


 95%|█████████▌| 95254/100000 [57:46<02:51, 27.62it/s]
epoch 95200  training loss: 0.09052436798810959

 95%|█████████▌| 95308/100000 [57:48<02:50, 27.53it/s]
epoch 95300  training loss: 0.09296270459890366


 95%|█████████▌| 95419/100000 [57:52<02:46, 27.59it/s]
epoch 95400  training loss: 0.08998299390077591


 96%|█████████▌| 95530/100000 [57:56<02:42, 27.52it/s]
epoch 95500  training loss: 0.09336093813180923


 96%|█████████▌| 95641/100000 [58:00<02:37, 27.62it/s]
epoch 95600  training loss: 0.09071139246225357


 96%|█████████▌| 95749/100000 [58:04<02:33, 27.61it/s]
epoch 95700  training loss: 0.09259111434221268

 96%|█████████▌| 95806/100000 [58:06<02:32, 27.51it/s]
epoch 95800  training loss: 0.09071293473243713


 96%|█████████▌| 95917/100000 [58:10<02:27, 27.61it/s]
epoch 95900  training loss: 0.09241839498281479


 96%|█████████▌| 96025/100000 [58:14<02:24, 27.57it/s]
epoch 96000  training loss: 0.0924946591258049
epoch 96000  clean testing loss: 0.030596135184168816


 96%|█████████▌| 96136/100000 [58:18<02:19, 27.62it/s]
epoch 96100  training loss: 0.09101221710443497


 96%|█████████▌| 96247/100000 [58:22<02:15, 27.62it/s]
epoch 96200  training loss: 0.09132932871580124


 96%|█████████▋| 96355/100000 [58:26<02:12, 27.61it/s]
epoch 96300  training loss: 0.09343608468770981

 96%|█████████▋| 96412/100000 [58:28<02:10, 27.56it/s]
epoch 96400  training loss: 0.09185457229614258


 97%|█████████▋| 96523/100000 [58:32<02:05, 27.60it/s]
epoch 96500  training loss: 0.09119422733783722


 97%|█████████▋| 96634/100000 [58:36<02:01, 27.63it/s]
epoch 96600  training loss: 0.09243379533290863


 97%|█████████▋| 96742/100000 [58:40<01:57, 27.62it/s]
epoch 96700  training loss: 0.09367109090089798


 97%|█████████▋| 96853/100000 [58:44<01:53, 27.63it/s]
epoch 96800  training loss: 0.09245915710926056

 97%|█████████▋| 96907/100000 [58:46<01:52, 27.54it/s]
epoch 96900  training loss: 0.09099952131509781


 97%|█████████▋| 97018/100000 [58:50<01:48, 27.53it/s]
epoch 97000  training loss: 0.09229111671447754
epoch 97000  clean testing loss: 0.030948344618082047


 97%|█████████▋| 97129/100000 [58:54<01:43, 27.64it/s]
epoch 97100  training loss: 0.09409097582101822


 97%|█████████▋| 97240/100000 [58:58<01:39, 27.63it/s]
epoch 97200  training loss: 0.09151732921600342


 97%|█████████▋| 97351/100000 [59:02<01:35, 27.64it/s]
epoch 97300  training loss: 0.09210877120494843

 97%|█████████▋| 97405/100000 [59:04<01:34, 27.55it/s]
epoch 97400  training loss: 0.09380798041820526


 98%|█████████▊| 97516/100000 [59:08<01:29, 27.61it/s]
epoch 97500  training loss: 0.09174391627311707


 98%|█████████▊| 97627/100000 [59:12<01:25, 27.62it/s]
epoch 97600  training loss: 0.09288077056407928


 98%|█████████▊| 97735/100000 [59:16<01:21, 27.64it/s]
epoch 97700  training loss: 0.09398134797811508


 98%|█████████▊| 97846/100000 [59:20<01:17, 27.64it/s]
epoch 97800  training loss: 0.09320268034934998


 98%|█████████▊| 97957/100000 [59:24<01:13, 27.64it/s]
epoch 97900  training loss: 0.09181895852088928

 98%|█████████▊| 98014/100000 [59:26<01:12, 27.45it/s]
epoch 98000  training loss: 0.09174191206693649
epoch 98000  clean testing loss: 0.030604161322116852


 98%|█████████▊| 98125/100000 [59:30<01:07, 27.65it/s]
epoch 98100  training loss: 0.09274589270353317


 98%|█████████▊| 98233/100000 [59:34<01:03, 27.63it/s]
epoch 98200  training loss: 0.09376632422208786


 98%|█████████▊| 98344/100000 [59:38<00:59, 27.63it/s]
epoch 98300  training loss: 0.09194540232419968


 98%|█████████▊| 98455/100000 [59:42<00:55, 27.66it/s]
epoch 98400  training loss: 0.09231402724981308

 99%|█████████▊| 98509/100000 [59:44<00:54, 27.44it/s]
epoch 98500  training loss: 0.09300152957439423


 99%|█████████▊| 98620/100000 [59:48<00:49, 27.61it/s]
epoch 98600  training loss: 0.09114086627960205


 99%|█████████▊| 98731/100000 [59:52<00:45, 27.62it/s]
epoch 98700  training loss: 0.0935811772942543


 99%|█████████▉| 98839/100000 [59:56<00:41, 27.65it/s]
epoch 98800  training loss: 0.09166312962770462


 99%|█████████▉| 98950/100000 [1:00:00<00:37, 27.65it/s]
epoch 98900  training loss: 0.09118669480085373


 99%|█████████▉| 99061/100000 [1:00:04<00:33, 27.65it/s]
epoch 99000  training loss: 0.0936858132481575
epoch 99000  clean testing loss: 0.030885424464941025

 99%|█████████▉| 99118/100000 [1:00:06<00:31, 27.64it/s]
epoch 99100  training loss: 0.09326010942459106


 99%|█████████▉| 99229/100000 [1:00:10<00:27, 27.66it/s]
epoch 99200  training loss: 0.09222433716058731


 99%|█████████▉| 99337/100000 [1:00:14<00:24, 27.46it/s]
epoch 99300  training loss: 0.09134609252214432


 99%|█████████▉| 99448/100000 [1:00:18<00:19, 27.64it/s]
epoch 99400  training loss: 0.09144856035709381


100%|█████████▉| 99559/100000 [1:00:22<00:15, 27.63it/s]
epoch 99500  training loss: 0.0917474627494812

100%|█████████▉| 99613/100000 [1:00:24<00:14, 27.62it/s]
epoch 99600  training loss: 0.09302961081266403


100%|█████████▉| 99724/100000 [1:00:28<00:09, 27.63it/s]
epoch 99700  training loss: 0.09320244938135147


100%|█████████▉| 99835/100000 [1:00:32<00:05, 27.63it/s]
epoch 99800  training loss: 0.09187734127044678


100%|█████████▉| 99946/100000 [1:00:36<00:01, 27.65it/s]
epoch 99900  training loss: 0.09275960177183151

100%|██████████| 100000/100000 [1:00:38<00:00, 27.48it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu2_size5000_noise1.00e-01_invop1_lr5e-05 ...