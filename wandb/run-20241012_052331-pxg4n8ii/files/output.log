
  1%|          | 701/100000 [00:01<03:07, 529.79it/s]
epoch 0  training loss: 0.5421505570411682
epoch 0  clean testing loss: 2.2803633213043213
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 100  training loss: 0.09579157084226608
epoch 100  clean testing loss: 0.055490367114543915
epoch 200  training loss: 0.09514929354190826
epoch 200  clean testing loss: 0.04204292595386505
epoch 300  training loss: 0.07551409304141998
epoch 300  clean testing loss: 0.03588135913014412
epoch 400  training loss: 0.08622065931558609
epoch 400  clean testing loss: 0.044230032712221146
epoch 500  training loss: 0.10797205567359924
epoch 500  clean testing loss: 0.051746439188718796
epoch 600  training loss: 0.07067442685365677
epoch 600  clean testing loss: 0.03347404673695564
epoch 700  training loss: 0.1016974076628685

  2%|▏         | 1802/100000 [00:03<03:04, 533.43it/s]
epoch 800  training loss: 0.08479399979114532
epoch 800  clean testing loss: 0.04333927482366562
epoch 900  training loss: 0.07240638881921768
epoch 900  clean testing loss: 0.0323680080473423
epoch 1000  training loss: 0.08514287322759628
epoch 1000  clean testing loss: 0.03846866637468338
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 1100  training loss: 0.08330521732568741
epoch 1100  clean testing loss: 0.04123556241393089
epoch 1200  training loss: 0.07181784510612488
epoch 1200  clean testing loss: 0.034177765250205994
epoch 1300  training loss: 0.06963282823562622
epoch 1300  clean testing loss: 0.03302210196852684
epoch 1400  training loss: 0.06456007063388824
epoch 1400  clean testing loss: 0.028281213715672493
epoch 1500  training loss: 0.06335314363241196
epoch 1500  clean testing loss: 0.02847147174179554
epoch 1600  training loss: 0.07114546746015549
epoch 1600  clean testing loss: 0.04123988375067711
epoch 1700  training loss: 0.07461506873369217
epoch 1700  clean testing loss: 0.033965423703193665
epoch 1800  training loss: 0.07134658098220825

  3%|▎         | 2848/100000 [00:05<03:00, 536.90it/s]
epoch 1900  training loss: 0.07125630229711533
epoch 1900  clean testing loss: 0.03496836870908737
epoch 2000  training loss: 0.06876727193593979
epoch 2000  clean testing loss: 0.0324738509953022
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 2100  training loss: 0.06386934220790863
epoch 2100  clean testing loss: 0.02852654829621315
epoch 2200  training loss: 0.0631941705942154
epoch 2200  clean testing loss: 0.028548048809170723
epoch 2300  training loss: 0.06272951513528824
epoch 2300  clean testing loss: 0.028026971966028214
epoch 2400  training loss: 0.06286969780921936
epoch 2400  clean testing loss: 0.030592069029808044
epoch 2500  training loss: 0.12077897042036057
epoch 2500  clean testing loss: 0.04479018971323967
epoch 2600  training loss: 0.06369548290967941
epoch 2600  clean testing loss: 0.02912767417728901
epoch 2700  training loss: 0.06208597868680954
epoch 2700  clean testing loss: 0.02746432274580002
epoch 2800  training loss: 0.061677150428295135
epoch 2800  clean testing loss: 0.027345143258571625
epoch 2900  training loss: 0.061689943075180054

  4%|▍         | 3952/100000 [00:07<02:58, 539.00it/s]
epoch 3000  training loss: 0.06163916364312172
epoch 3000  clean testing loss: 0.028462521731853485
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 3100  training loss: 0.061200451105833054
epoch 3100  clean testing loss: 0.02775348722934723
epoch 3200  training loss: 0.06120152398943901
epoch 3200  clean testing loss: 0.0281661469489336
epoch 3300  training loss: 0.061317410320043564
epoch 3300  clean testing loss: 0.026884233579039574
epoch 3400  training loss: 0.06120063737034798
epoch 3400  clean testing loss: 0.028476400300860405
epoch 3500  training loss: 0.07235841453075409
epoch 3500  clean testing loss: 0.0566706508398056
epoch 3600  training loss: 0.06139625608921051
epoch 3600  clean testing loss: 0.028120126575231552
epoch 3700  training loss: 0.061186276376247406
epoch 3700  clean testing loss: 0.027184322476387024
epoch 3800  training loss: 0.06128696724772453
epoch 3800  clean testing loss: 0.028482699766755104
epoch 3900  training loss: 0.061517298221588135
epoch 3900  clean testing loss: 0.026995999738574028
epoch 4000  training loss: 0.07307182252407074
epoch 4000  clean testing loss: 0.05022701621055603

  5%|▌         | 5001/100000 [00:09<02:59, 528.04it/s]
epoch 4100  training loss: 0.06206759065389633
epoch 4100  clean testing loss: 0.02894449047744274
epoch 4200  training loss: 0.06111221760511398
epoch 4200  clean testing loss: 0.027606172487139702
epoch 4300  training loss: 0.061438802629709244
epoch 4300  clean testing loss: 0.02874588966369629
epoch 4400  training loss: 0.06150912865996361
epoch 4400  clean testing loss: 0.02903021313250065
epoch 4500  training loss: 0.06095908582210541
epoch 4500  clean testing loss: 0.028251580893993378
epoch 4600  training loss: 0.062352973967790604
epoch 4600  clean testing loss: 0.027822934091091156
epoch 4700  training loss: 0.06117066740989685
epoch 4700  clean testing loss: 0.02767973579466343
epoch 4800  training loss: 0.06102141737937927
epoch 4800  clean testing loss: 0.02824556455016136
epoch 4900  training loss: 0.06105487793684006
epoch 4900  clean testing loss: 0.02873389422893524
epoch 5000  training loss: 0.061553727835416794
epoch 5000  clean testing loss: 0.027515998110175133
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 5100  training loss: 0.06101124361157417

  6%|▌         | 6103/100000 [00:11<02:56, 532.55it/s]
epoch 5200  training loss: 0.06085054203867912
epoch 5200  clean testing loss: 0.027538998052477837
epoch 5300  training loss: 0.06131580471992493
epoch 5300  clean testing loss: 0.027280297130346298
epoch 5400  training loss: 0.06158001348376274
epoch 5400  clean testing loss: 0.030252356082201004
epoch 5500  training loss: 0.06268187612295151
epoch 5500  clean testing loss: 0.028055842965841293
epoch 5600  training loss: 0.0610782764852047
epoch 5600  clean testing loss: 0.028287678956985474
epoch 5700  training loss: 0.060949359089136124
epoch 5700  clean testing loss: 0.027906665578484535
epoch 5800  training loss: 0.06116258352994919
epoch 5800  clean testing loss: 0.028438609093427658
epoch 5900  training loss: 0.06164319068193436
epoch 5900  clean testing loss: 0.02888074703514576
epoch 6000  training loss: 0.06104506924748421
epoch 6000  clean testing loss: 0.030014842748641968
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 6100  training loss: 0.060726288706064224
epoch 6100  clean testing loss: 0.028205960988998413
epoch 6200  training loss: 0.060606032609939575

  7%|▋         | 7209/100000 [00:13<02:54, 532.40it/s]
epoch 6300  training loss: 0.0605839267373085
epoch 6300  clean testing loss: 0.027966873720288277
epoch 6400  training loss: 0.0603363960981369
epoch 6400  clean testing loss: 0.02875407412648201
epoch 6500  training loss: 0.060761868953704834
epoch 6500  clean testing loss: 0.02926214411854744
epoch 6600  training loss: 0.06068628281354904
epoch 6600  clean testing loss: 0.029966924339532852
epoch 6700  training loss: 0.06037455424666405
epoch 6700  clean testing loss: 0.02798965759575367
epoch 6800  training loss: 0.060232944786548615
epoch 6800  clean testing loss: 0.028621450066566467
epoch 6900  training loss: 0.062314197421073914
epoch 6900  clean testing loss: 0.030398685485124588
epoch 7000  training loss: 0.06097271293401718
epoch 7000  clean testing loss: 0.028072454035282135
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 7100  training loss: 0.060450922697782516
epoch 7100  clean testing loss: 0.028238745406270027
epoch 7200  training loss: 0.06033889204263687

  8%|▊         | 8253/100000 [00:15<02:51, 533.43it/s]
epoch 7300  training loss: 0.060590457171201706
epoch 7300  clean testing loss: 0.027969732880592346
epoch 7400  training loss: 0.060449425131082535
epoch 7400  clean testing loss: 0.0280947033315897
epoch 7500  training loss: 0.06590684503316879
epoch 7500  clean testing loss: 0.03453052043914795
epoch 7600  training loss: 0.06547121703624725
epoch 7600  clean testing loss: 0.02843930944800377
epoch 7700  training loss: 0.06062457710504532
epoch 7700  clean testing loss: 0.028396548703312874
epoch 7800  training loss: 0.06017608195543289
epoch 7800  clean testing loss: 0.028763188049197197
epoch 7900  training loss: 0.06011028587818146
epoch 7900  clean testing loss: 0.0283061470836401
epoch 8000  training loss: 0.06394943594932556
epoch 8000  clean testing loss: 0.03076038509607315
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 8100  training loss: 0.07013401389122009
epoch 8100  clean testing loss: 0.030686521902680397
epoch 8200  training loss: 0.06011463329195976
epoch 8200  clean testing loss: 0.028520433232188225
epoch 8300  training loss: 0.05988619104027748

  9%|▉         | 9352/100000 [00:17<02:48, 536.64it/s]
epoch 8400  training loss: 0.062104832381010056
epoch 8400  clean testing loss: 0.02812189608812332
epoch 8500  training loss: 0.06126653030514717
epoch 8500  clean testing loss: 0.02900339476764202
epoch 8600  training loss: 0.06135353818535805
epoch 8600  clean testing loss: 0.0295980554074049
epoch 8700  training loss: 0.06042869761586189
epoch 8700  clean testing loss: 0.02859925851225853
epoch 8800  training loss: 0.060524459928274155
epoch 8800  clean testing loss: 0.028311505913734436
epoch 8900  training loss: 0.06145387515425682
epoch 8900  clean testing loss: 0.02859927900135517
epoch 9000  training loss: 0.05991894751787186
epoch 9000  clean testing loss: 0.02885689213871956
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 9100  training loss: 0.05972098931670189
epoch 9100  clean testing loss: 0.028934800997376442
epoch 9200  training loss: 0.05959614738821983
epoch 9200  clean testing loss: 0.028938325121998787
epoch 9300  training loss: 0.05949047952890396
epoch 9300  clean testing loss: 0.029143666848540306
epoch 9400  training loss: 0.05949368327856064

 10%|█         | 10446/100000 [00:19<02:47, 535.81it/s]
epoch 9500  training loss: 0.059387460350990295
epoch 9500  clean testing loss: 0.029012223705649376
epoch 9600  training loss: 0.0593942254781723
epoch 9600  clean testing loss: 0.028872471302747726
epoch 9700  training loss: 0.05932148918509483
epoch 9700  clean testing loss: 0.02928960882127285
epoch 9800  training loss: 0.059206273406744
epoch 9800  clean testing loss: 0.02909037098288536
epoch 9900  training loss: 0.060401514172554016
epoch 9900  clean testing loss: 0.02981872484087944
epoch 10000  training loss: 0.05950833112001419
epoch 10000  clean testing loss: 0.029605839401483536
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 10100  training loss: 0.05926574394106865
epoch 10100  clean testing loss: 0.029496286064386368
epoch 10200  training loss: 0.05919981375336647
epoch 10200  clean testing loss: 0.02945871837437153
epoch 10300  training loss: 0.0637873187661171
epoch 10300  clean testing loss: 0.029812704771757126
epoch 10400  training loss: 0.059224482625722885
epoch 10400  clean testing loss: 0.029598988592624664
epoch 10500  training loss: 0.06080158054828644

 11%|█▏        | 11494/100000 [00:21<02:43, 541.20it/s]
epoch 10600  training loss: 0.059147875756025314
epoch 10600  clean testing loss: 0.029177149757742882
epoch 10700  training loss: 0.05909958481788635
epoch 10700  clean testing loss: 0.029641887173056602
epoch 10800  training loss: 0.05913279205560684
epoch 10800  clean testing loss: 0.030037086457014084
epoch 10900  training loss: 0.06653810292482376
epoch 10900  clean testing loss: 0.03603507578372955
epoch 11000  training loss: 0.059158749878406525
epoch 11000  clean testing loss: 0.029303528368473053
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 11100  training loss: 0.058977264910936356
epoch 11100  clean testing loss: 0.029475638642907143
epoch 11200  training loss: 0.05887247622013092
epoch 11200  clean testing loss: 0.029411379247903824
epoch 11300  training loss: 0.05878978967666626
epoch 11300  clean testing loss: 0.02972015179693699
epoch 11400  training loss: 0.05929199233651161
epoch 11400  clean testing loss: 0.03210921213030815
epoch 11500  training loss: 0.05903958901762962

 13%|█▎        | 12541/100000 [00:23<03:17, 443.41it/s]
epoch 11600  training loss: 0.05882733315229416
epoch 11600  clean testing loss: 0.029621265828609467
epoch 11700  training loss: 0.05876984819769859
epoch 11700  clean testing loss: 0.02980198711156845
epoch 11800  training loss: 0.058836229145526886
epoch 11800  clean testing loss: 0.029092488810420036
epoch 11900  training loss: 0.05895422771573067
epoch 11900  clean testing loss: 0.03001885674893856
epoch 12000  training loss: 0.059127964079380035
epoch 12000  clean testing loss: 0.02931874990463257
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 12100  training loss: 0.058632608503103256
epoch 12100  clean testing loss: 0.0296243317425251
epoch 12200  training loss: 0.05856486037373543
epoch 12200  clean testing loss: 0.029781082645058632
epoch 12300  training loss: 0.05865922570228577
epoch 12300  clean testing loss: 0.03014574944972992
epoch 12400  training loss: 0.05853160098195076
epoch 12400  clean testing loss: 0.029850533232092857
epoch 12500  training loss: 0.05861028656363487
epoch 12500  clean testing loss: 0.03013380989432335
epoch 12600  training loss: 0.058657120913267136

 14%|█▎        | 13634/100000 [00:25<02:40, 539.16it/s]
epoch 12700  training loss: 0.058770351111888885
epoch 12700  clean testing loss: 0.030970841646194458
epoch 12800  training loss: 0.05858729034662247
epoch 12800  clean testing loss: 0.02970619685947895
epoch 12900  training loss: 0.05867592245340347
epoch 12900  clean testing loss: 0.029454248026013374
epoch 13000  training loss: 0.05854989215731621
epoch 13000  clean testing loss: 0.030940799042582512
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 13100  training loss: 0.05866527929902077
epoch 13100  clean testing loss: 0.029484471306204796
epoch 13200  training loss: 0.058497894555330276
epoch 13200  clean testing loss: 0.029814356938004494
epoch 13300  training loss: 0.058506857603788376
epoch 13300  clean testing loss: 0.030379001051187515
epoch 13400  training loss: 0.05844477191567421
epoch 13400  clean testing loss: 0.029591351747512817
epoch 13500  training loss: 0.058612268418073654
epoch 13500  clean testing loss: 0.029512938112020493
epoch 13600  training loss: 0.05902581661939621
epoch 13600  clean testing loss: 0.03033827804028988
epoch 13700  training loss: 0.05839954689145088

 15%|█▍        | 14686/100000 [00:27<02:37, 540.74it/s]
epoch 13800  training loss: 0.05851580947637558
epoch 13800  clean testing loss: 0.029494866728782654
epoch 13900  training loss: 0.05902146175503731
epoch 13900  clean testing loss: 0.029486050829291344
epoch 14000  training loss: 0.0584121011197567
epoch 14000  clean testing loss: 0.029871193692088127
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 14100  training loss: 0.06066545471549034
epoch 14100  clean testing loss: 0.03005950152873993
epoch 14200  training loss: 0.05841250717639923
epoch 14200  clean testing loss: 0.029785700142383575
epoch 14300  training loss: 0.0583401657640934
epoch 14300  clean testing loss: 0.030103715136647224
epoch 14400  training loss: 0.05841205641627312
epoch 14400  clean testing loss: 0.03016122430562973
epoch 14500  training loss: 0.058580391108989716
epoch 14500  clean testing loss: 0.029375722631812096
epoch 14600  training loss: 0.058371443301439285
epoch 14600  clean testing loss: 0.0302556324750185
epoch 14700  training loss: 0.058492984622716904

 16%|█▌        | 15788/100000 [00:29<02:36, 539.39it/s]
epoch 14800  training loss: 0.058442484587430954
epoch 14800  clean testing loss: 0.029475992545485497
epoch 14900  training loss: 0.058342769742012024
epoch 14900  clean testing loss: 0.02992393635213375
epoch 15000  training loss: 0.0583435483276844
epoch 15000  clean testing loss: 0.029694678261876106
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 15100  training loss: 0.05821661278605461
epoch 15100  clean testing loss: 0.030013740062713623
epoch 15200  training loss: 0.058162838220596313
epoch 15200  clean testing loss: 0.029880288988351822
epoch 15300  training loss: 0.058189500123262405
epoch 15300  clean testing loss: 0.030284790322184563
epoch 15400  training loss: 0.058514274656772614
epoch 15400  clean testing loss: 0.030751338228583336
epoch 15500  training loss: 0.058154597878456116
epoch 15500  clean testing loss: 0.030658641830086708
epoch 15600  training loss: 0.058206140995025635
epoch 15600  clean testing loss: 0.029479090124368668
epoch 15700  training loss: 0.05809366703033447
epoch 15700  clean testing loss: 0.029641490429639816
epoch 15800  training loss: 0.0582641139626503

 17%|█▋        | 16831/100000 [00:31<02:34, 538.99it/s]
epoch 15900  training loss: 0.05820656940340996
epoch 15900  clean testing loss: 0.029554609209299088
epoch 16000  training loss: 0.05836329236626625
epoch 16000  clean testing loss: 0.029519224539399147
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 16100  training loss: 0.058126069605350494
epoch 16100  clean testing loss: 0.03101394511759281
epoch 16200  training loss: 0.058081962168216705
epoch 16200  clean testing loss: 0.030300244688987732
epoch 16300  training loss: 0.05797058343887329
epoch 16300  clean testing loss: 0.03002067655324936
epoch 16400  training loss: 0.05812632665038109
epoch 16400  clean testing loss: 0.029461795464158058
epoch 16500  training loss: 0.058011919260025024
epoch 16500  clean testing loss: 0.030655190348625183
epoch 16600  training loss: 0.058005087077617645
epoch 16600  clean testing loss: 0.030564596876502037
epoch 16700  training loss: 0.0590473935008049
epoch 16700  clean testing loss: 0.030571473762392998
epoch 16800  training loss: 0.05794922634959221
epoch 16800  clean testing loss: 0.0299989040941
epoch 16900  training loss: 0.05790729075670242

 18%|█▊        | 17930/100000 [00:33<02:32, 538.91it/s]
epoch 17000  training loss: 0.058028146624565125
epoch 17000  clean testing loss: 0.030699389055371284
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 17100  training loss: 0.058177798986434937
epoch 17100  clean testing loss: 0.03146059438586235
epoch 17200  training loss: 0.05795195326209068
epoch 17200  clean testing loss: 0.03037351928651333
epoch 17300  training loss: 0.05822812020778656
epoch 17300  clean testing loss: 0.03115503117442131
epoch 17400  training loss: 0.05789199844002724
epoch 17400  clean testing loss: 0.029924122616648674
epoch 17500  training loss: 0.0578744150698185
epoch 17500  clean testing loss: 0.029875803738832474
epoch 17600  training loss: 0.057900819927453995
epoch 17600  clean testing loss: 0.02982890047132969
epoch 17700  training loss: 0.05847553908824921
epoch 17700  clean testing loss: 0.02954416535794735
epoch 17800  training loss: 0.058326784521341324
epoch 17800  clean testing loss: 0.02956828661262989
epoch 17900  training loss: 0.057974930852651596
epoch 17900  clean testing loss: 0.029601791873574257
epoch 18000  training loss: 0.058786001056432724
epoch 18000  clean testing loss: 0.031665731221437454

 19%|█▉        | 19033/100000 [00:35<02:32, 531.37it/s]
epoch 18100  training loss: 0.05772365257143974
epoch 18100  clean testing loss: 0.030112789943814278
epoch 18200  training loss: 0.057682961225509644
epoch 18200  clean testing loss: 0.03009740076959133
epoch 18300  training loss: 0.05763347074389458
epoch 18300  clean testing loss: 0.03005887381732464
epoch 18400  training loss: 0.05758632346987724
epoch 18400  clean testing loss: 0.030087513849139214
epoch 18500  training loss: 0.057592205703258514
epoch 18500  clean testing loss: 0.03074144572019577
epoch 18600  training loss: 0.057694192975759506
epoch 18600  clean testing loss: 0.029839608818292618
epoch 18700  training loss: 0.05758780986070633
epoch 18700  clean testing loss: 0.03063994087278843
epoch 18800  training loss: 0.05748682841658592
epoch 18800  clean testing loss: 0.030304450541734695
epoch 18900  training loss: 0.05755264684557915
epoch 18900  clean testing loss: 0.029929865151643753
epoch 19000  training loss: 0.05747323855757713
epoch 19000  clean testing loss: 0.03016224503517151
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 19100  training loss: 0.05754587799310684

 20%|██        | 20085/100000 [00:37<02:28, 536.87it/s]
epoch 19200  training loss: 0.057557400315999985
epoch 19200  clean testing loss: 0.029743053019046783
epoch 19300  training loss: 0.05736205726861954
epoch 19300  clean testing loss: 0.030524156987667084
epoch 19400  training loss: 0.05733533948659897
epoch 19400  clean testing loss: 0.030125316232442856
epoch 19500  training loss: 0.057519830763339996
epoch 19500  clean testing loss: 0.029830658808350563
epoch 19600  training loss: 0.05750379338860512
epoch 19600  clean testing loss: 0.029756849631667137
epoch 19700  training loss: 0.05778918042778969
epoch 19700  clean testing loss: 0.02970508113503456
epoch 19800  training loss: 0.05755702778697014
epoch 19800  clean testing loss: 0.029683545231819153
epoch 19900  training loss: 0.057401251047849655
epoch 19900  clean testing loss: 0.0301987212151289
epoch 20000  training loss: 0.057273637503385544
epoch 20000  clean testing loss: 0.02998708188533783
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 20100  training loss: 0.05737602338194847

 21%|██        | 21189/100000 [00:39<02:25, 539.94it/s]
epoch 20200  training loss: 0.0573216937482357
epoch 20200  clean testing loss: 0.03060806728899479
epoch 20300  training loss: 0.05722769722342491
epoch 20300  clean testing loss: 0.03015041910111904
epoch 20400  training loss: 0.0572335384786129
epoch 20400  clean testing loss: 0.03015775792300701
epoch 20500  training loss: 0.0573098286986351
epoch 20500  clean testing loss: 0.029949570074677467
epoch 20600  training loss: 0.05719790980219841
epoch 20600  clean testing loss: 0.030683357268571854
epoch 20700  training loss: 0.05729195848107338
epoch 20700  clean testing loss: 0.03076792322099209
epoch 20800  training loss: 0.057698704302310944
epoch 20800  clean testing loss: 0.029827911406755447
epoch 20900  training loss: 0.05718476325273514
epoch 20900  clean testing loss: 0.030579566955566406
epoch 21000  training loss: 0.057578157633543015
epoch 21000  clean testing loss: 0.029784124344587326
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 21100  training loss: 0.057116929441690445
epoch 21100  clean testing loss: 0.030407419428229332
epoch 21200  training loss: 0.0570954829454422

 22%|██▏       | 22234/100000 [00:41<02:25, 536.24it/s]
epoch 21300  training loss: 0.05710179731249809
epoch 21300  clean testing loss: 0.0305233933031559
epoch 21400  training loss: 0.05711182579398155
epoch 21400  clean testing loss: 0.03029371052980423
epoch 21500  training loss: 0.05708188936114311
epoch 21500  clean testing loss: 0.030503831803798676
epoch 21600  training loss: 0.05719342827796936
epoch 21600  clean testing loss: 0.03000504896044731
epoch 21700  training loss: 0.057197071611881256
epoch 21700  clean testing loss: 0.029963720589876175
epoch 21800  training loss: 0.05710146203637123
epoch 21800  clean testing loss: 0.030832810327410698
epoch 21900  training loss: 0.05722011253237724
epoch 21900  clean testing loss: 0.03129036724567413
epoch 22000  training loss: 0.05705077573657036
epoch 22000  clean testing loss: 0.030224716290831566
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 22100  training loss: 0.05706873536109924
epoch 22100  clean testing loss: 0.030416926369071007
epoch 22200  training loss: 0.05726548656821251
epoch 22200  clean testing loss: 0.031261879950761795
epoch 22300  training loss: 0.057055965065956116
 23%|██▎       | 23276/100000 [00:43<02:23, 534.32it/s]wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2 seconds.), retrying request
 23%|██▎       | 23330/100000 [00:43<02:24, 528.77it/s]
epoch 22400  training loss: 0.05724282190203667
epoch 22400  clean testing loss: 0.03108440898358822
epoch 22500  training loss: 0.05719655007123947
epoch 22500  clean testing loss: 0.03007122501730919
epoch 22600  training loss: 0.057070404291152954
epoch 22600  clean testing loss: 0.030874328687787056
epoch 22700  training loss: 0.05702141672372818
epoch 22700  clean testing loss: 0.030561765655875206
epoch 22800  training loss: 0.05703387036919594
epoch 22800  clean testing loss: 0.030329089611768723
epoch 22900  training loss: 0.05711422860622406
epoch 22900  clean testing loss: 0.03002988174557686
epoch 23000  training loss: 0.05706309899687767
epoch 23000  clean testing loss: 0.029957016929984093
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 23100  training loss: 0.0571969710290432
epoch 23100  clean testing loss: 0.03088187240064144
epoch 23200  training loss: 0.05699589103460312
epoch 23200  clean testing loss: 0.03084426186978817
epoch 23300  training loss: 0.056967660784721375
epoch 23300  clean testing loss: 0.03038412146270275
epoch 23400  training loss: 0.05697941780090332

 24%|██▍       | 24428/100000 [00:45<02:20, 537.41it/s]
epoch 23500  training loss: 0.05717211216688156
epoch 23500  clean testing loss: 0.02994399517774582
epoch 23600  training loss: 0.05709836259484291
epoch 23600  clean testing loss: 0.029967661947011948
epoch 23700  training loss: 0.05703912302851677
epoch 23700  clean testing loss: 0.03004182130098343
epoch 23800  training loss: 0.05695754662156105
epoch 23800  clean testing loss: 0.030385667458176613
epoch 23900  training loss: 0.05698695778846741
epoch 23900  clean testing loss: 0.030200917273759842
epoch 24000  training loss: 0.05702986568212509
epoch 24000  clean testing loss: 0.03101852722465992
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 24100  training loss: 0.05690623074769974
epoch 24100  clean testing loss: 0.030432401224970818
epoch 24200  training loss: 0.056900911033153534
epoch 24200  clean testing loss: 0.030422359704971313
epoch 24300  training loss: 0.05689201131463051
epoch 24300  clean testing loss: 0.030546974390745163
epoch 24400  training loss: 0.05687699839472771
epoch 24400  clean testing loss: 0.03057650476694107
epoch 24500  training loss: 0.05687357485294342

 25%|██▌       | 25476/100000 [00:47<02:17, 542.54it/s]
epoch 24600  training loss: 0.056864116340875626
epoch 24600  clean testing loss: 0.03039371222257614
epoch 24700  training loss: 0.05686661973595619
epoch 24700  clean testing loss: 0.030466655269265175
epoch 24800  training loss: 0.05700932815670967
epoch 24800  clean testing loss: 0.029999975115060806
epoch 24900  training loss: 0.0568530298769474
epoch 24900  clean testing loss: 0.030466383323073387
epoch 25000  training loss: 0.056896887719631195
epoch 25000  clean testing loss: 0.030826549977064133
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 25100  training loss: 0.05713202431797981
epoch 25100  clean testing loss: 0.030053071677684784
epoch 25200  training loss: 0.05683273449540138
epoch 25200  clean testing loss: 0.03043854981660843
epoch 25300  training loss: 0.05689694732427597
epoch 25300  clean testing loss: 0.030818862840533257
epoch 25400  training loss: 0.05682166665792465
epoch 25400  clean testing loss: 0.03035334125161171
epoch 25500  training loss: 0.05695446953177452

 27%|██▋       | 26576/100000 [00:49<02:15, 541.33it/s]
epoch 25600  training loss: 0.05703234300017357
epoch 25600  clean testing loss: 0.0299138892441988
epoch 25700  training loss: 0.0568460188806057
epoch 25700  clean testing loss: 0.030320843681693077
epoch 25800  training loss: 0.056830182671546936
epoch 25800  clean testing loss: 0.030098233371973038
epoch 25900  training loss: 0.05680856481194496
epoch 25900  clean testing loss: 0.030266745015978813
epoch 26000  training loss: 0.05678644776344299
epoch 26000  clean testing loss: 0.030478332191705704
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 26100  training loss: 0.05684001371264458
epoch 26100  clean testing loss: 0.03080303966999054
epoch 26200  training loss: 0.05686180293560028
epoch 26200  clean testing loss: 0.030911680310964584
epoch 26300  training loss: 0.056857749819755554
epoch 26300  clean testing loss: 0.03115999512374401
epoch 26400  training loss: 0.05681541562080383
epoch 26400  clean testing loss: 0.030363066121935844
epoch 26500  training loss: 0.05677301809191704
epoch 26500  clean testing loss: 0.030567694455385208
epoch 26600  training loss: 0.056782517582178116

 28%|██▊       | 27624/100000 [00:51<02:14, 539.84it/s]
epoch 26700  training loss: 0.05692009627819061
epoch 26700  clean testing loss: 0.03120926208794117
epoch 26800  training loss: 0.05688834190368652
epoch 26800  clean testing loss: 0.031149672344326973
epoch 26900  training loss: 0.05683140456676483
epoch 26900  clean testing loss: 0.030795687809586525
epoch 27000  training loss: 0.05675443634390831
epoch 27000  clean testing loss: 0.03045078180730343
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 27100  training loss: 0.056718308478593826
epoch 27100  clean testing loss: 0.03045537881553173
epoch 27200  training loss: 0.05671868473291397
epoch 27200  clean testing loss: 0.030509261414408684
epoch 27300  training loss: 0.05670662224292755
epoch 27300  clean testing loss: 0.030581127852201462
epoch 27400  training loss: 0.056714680045843124
epoch 27400  clean testing loss: 0.030706774443387985
epoch 27500  training loss: 0.05679069831967354
epoch 27500  clean testing loss: 0.030917221680283546
epoch 27600  training loss: 0.056717634201049805
epoch 27600  clean testing loss: 0.03078722395002842
epoch 27700  training loss: 0.05674499645829201

 29%|██▊       | 28672/100000 [00:53<02:12, 537.18it/s]
epoch 27800  training loss: 0.05668453127145767
epoch 27800  clean testing loss: 0.03042549453675747
epoch 27900  training loss: 0.05674554407596588
epoch 27900  clean testing loss: 0.030136093497276306
epoch 28000  training loss: 0.05673059821128845
epoch 28000  clean testing loss: 0.030858278274536133
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 28100  training loss: 0.05678911879658699
epoch 28100  clean testing loss: 0.031090261414647102
epoch 28200  training loss: 0.05669187381863594
epoch 28200  clean testing loss: 0.03058675304055214
epoch 28300  training loss: 0.05666939914226532
epoch 28300  clean testing loss: 0.030553201213479042
epoch 28400  training loss: 0.05672220513224602
epoch 28400  clean testing loss: 0.030265530571341515
epoch 28500  training loss: 0.05669284239411354
epoch 28500  clean testing loss: 0.030838340520858765
epoch 28600  training loss: 0.05664902180433273
epoch 28600  clean testing loss: 0.030413692817091942
epoch 28700  training loss: 0.05666012316942215

 30%|██▉       | 29761/100000 [00:55<02:09, 540.69it/s]
epoch 28800  training loss: 0.05665561929345131
epoch 28800  clean testing loss: 0.030450157821178436
epoch 28900  training loss: 0.05681339278817177
epoch 28900  clean testing loss: 0.029991742223501205
epoch 29000  training loss: 0.05670352652668953
epoch 29000  clean testing loss: 0.03090638481080532
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 29100  training loss: 0.05662916228175163
epoch 29100  clean testing loss: 0.03049461357295513
epoch 29200  training loss: 0.05665018782019615
epoch 29200  clean testing loss: 0.030386781319975853
epoch 29300  training loss: 0.0566423200070858
epoch 29300  clean testing loss: 0.030338849872350693
epoch 29400  training loss: 0.05679231509566307
epoch 29400  clean testing loss: 0.03134369105100632
epoch 29500  training loss: 0.056617043912410736
epoch 29500  clean testing loss: 0.030527574941515923
epoch 29600  training loss: 0.05661538988351822
epoch 29600  clean testing loss: 0.030373364686965942
epoch 29700  training loss: 0.05664229765534401
epoch 29700  clean testing loss: 0.030326731503009796
epoch 29800  training loss: 0.056622035801410675

 31%|███       | 30862/100000 [00:57<02:07, 541.87it/s]
epoch 29900  training loss: 0.05667490512132645
epoch 29900  clean testing loss: 0.030187401920557022
epoch 30000  training loss: 0.05666276440024376
epoch 30000  clean testing loss: 0.030311642214655876
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 30100  training loss: 0.0565730445086956
epoch 30100  clean testing loss: 0.030445735901594162
epoch 30200  training loss: 0.05657130107283592
epoch 30200  clean testing loss: 0.030573559924960136
epoch 30300  training loss: 0.05658448114991188
epoch 30300  clean testing loss: 0.03063775785267353
epoch 30400  training loss: 0.056552402675151825
epoch 30400  clean testing loss: 0.03058142215013504
epoch 30500  training loss: 0.0565553717315197
epoch 30500  clean testing loss: 0.03050452657043934
epoch 30600  training loss: 0.05657768249511719
epoch 30600  clean testing loss: 0.030767248943448067
epoch 30700  training loss: 0.05655713751912117
epoch 30700  clean testing loss: 0.030331863090395927
epoch 30800  training loss: 0.05656975880265236
epoch 30800  clean testing loss: 0.03023212030529976
epoch 30900  training loss: 0.05654190480709076

 32%|███▏      | 31905/100000 [00:59<02:08, 530.79it/s]
epoch 31000  training loss: 0.05656689777970314
epoch 31000  clean testing loss: 0.030802186578512192
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 31100  training loss: 0.05653785541653633
epoch 31100  clean testing loss: 0.030513878911733627
epoch 31200  training loss: 0.05652459338307381
epoch 31200  clean testing loss: 0.03045932576060295
epoch 31300  training loss: 0.05652784928679466
epoch 31300  clean testing loss: 0.03045683726668358
epoch 31400  training loss: 0.056596919894218445
epoch 31400  clean testing loss: 0.03018469177186489
epoch 31500  training loss: 0.05654912814497948
epoch 31500  clean testing loss: 0.03034469299018383
epoch 31600  training loss: 0.05657371133565903
epoch 31600  clean testing loss: 0.030837422236800194
epoch 31700  training loss: 0.056510087102651596
epoch 31700  clean testing loss: 0.030314402654767036
epoch 31800  training loss: 0.05653019994497299
epoch 31800  clean testing loss: 0.03056107461452484
epoch 31900  training loss: 0.056550852954387665
epoch 31900  clean testing loss: 0.030254757031798363
epoch 32000  training loss: 0.0565505251288414
epoch 32000  clean testing loss: 0.0302591435611248

 33%|███▎      | 33006/100000 [01:01<02:06, 529.54it/s]
epoch 32100  training loss: 0.056504182517528534
epoch 32100  clean testing loss: 0.030242672190070152
epoch 32200  training loss: 0.056548260152339935
epoch 32200  clean testing loss: 0.030172647908329964
epoch 32300  training loss: 0.05648842081427574
epoch 32300  clean testing loss: 0.03041776269674301
epoch 32400  training loss: 0.05650635063648224
epoch 32400  clean testing loss: 0.030840305611491203
epoch 32500  training loss: 0.05650242418050766
epoch 32500  clean testing loss: 0.0307847261428833
epoch 32600  training loss: 0.056473392993211746
epoch 32600  clean testing loss: 0.03068695403635502
epoch 32700  training loss: 0.056476254016160965
epoch 32700  clean testing loss: 0.030586643144488335
epoch 32800  training loss: 0.056468069553375244
epoch 32800  clean testing loss: 0.030609130859375
epoch 32900  training loss: 0.05647341534495354
epoch 32900  clean testing loss: 0.030340027064085007
epoch 33000  training loss: 0.056451696902513504
epoch 33000  clean testing loss: 0.030483413487672806

 34%|███▍      | 34046/100000 [01:03<02:04, 529.70it/s]
epoch 33100  training loss: 0.05643565580248833
epoch 33100  clean testing loss: 0.030475812032818794
epoch 33200  training loss: 0.056426964700222015
epoch 33200  clean testing loss: 0.030459173023700714
epoch 33300  training loss: 0.05641565099358559
epoch 33300  clean testing loss: 0.030432142317295074
epoch 33400  training loss: 0.05641896277666092
epoch 33400  clean testing loss: 0.03030770644545555
epoch 33500  training loss: 0.056408800184726715
epoch 33500  clean testing loss: 0.030350644141435623
epoch 33600  training loss: 0.05640072748064995
epoch 33600  clean testing loss: 0.030431954190135002
epoch 33700  training loss: 0.056417979300022125
epoch 33700  clean testing loss: 0.03025801293551922
epoch 33800  training loss: 0.056388676166534424
epoch 33800  clean testing loss: 0.030425705015659332
epoch 33900  training loss: 0.05641878396272659
epoch 33900  clean testing loss: 0.030646231025457382
epoch 34000  training loss: 0.05639102682471275
epoch 34000  clean testing loss: 0.03068552538752556
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 34100  training loss: 0.05638683959841728

 35%|███▌      | 35152/100000 [01:05<02:00, 536.21it/s]
epoch 34200  training loss: 0.05637901648879051
epoch 34200  clean testing loss: 0.030414951965212822
epoch 34300  training loss: 0.05645112693309784
epoch 34300  clean testing loss: 0.03010886162519455
epoch 34400  training loss: 0.05636833608150482
epoch 34400  clean testing loss: 0.030374370515346527
epoch 34500  training loss: 0.056368835270404816
epoch 34500  clean testing loss: 0.030629213899374008
epoch 34600  training loss: 0.056391388177871704
epoch 34600  clean testing loss: 0.030835391953587532
epoch 34700  training loss: 0.05636163800954819
epoch 34700  clean testing loss: 0.030458390712738037
epoch 34800  training loss: 0.05636266618967056
epoch 34800  clean testing loss: 0.030667917802929878
epoch 34900  training loss: 0.05639972165226936
epoch 34900  clean testing loss: 0.030831100419163704
epoch 35000  training loss: 0.05633239448070526
epoch 35000  clean testing loss: 0.030601706355810165
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 35100  training loss: 0.056339334696531296
epoch 35100  clean testing loss: 0.03061838634312153
epoch 35200  training loss: 0.056327059864997864

 36%|███▋      | 36252/100000 [01:07<01:58, 537.21it/s]
epoch 35300  training loss: 0.056346748024225235
epoch 35300  clean testing loss: 0.030247680842876434
epoch 35400  training loss: 0.056316077709198
epoch 35400  clean testing loss: 0.030500147491693497
epoch 35500  training loss: 0.05633082240819931
epoch 35500  clean testing loss: 0.030408624559640884
epoch 35600  training loss: 0.056316226720809937
epoch 35600  clean testing loss: 0.030598532408475876
epoch 35700  training loss: 0.056398674845695496
epoch 35700  clean testing loss: 0.030926641076803207
epoch 35800  training loss: 0.056327175348997116
epoch 35800  clean testing loss: 0.030688997358083725
epoch 35900  training loss: 0.0563124343752861
epoch 35900  clean testing loss: 0.030337976291775703
epoch 36000  training loss: 0.05632694810628891
epoch 36000  clean testing loss: 0.030567064881324768
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 36100  training loss: 0.05628703534603119
epoch 36100  clean testing loss: 0.030604660511016846
epoch 36200  training loss: 0.05627850443124771
epoch 36200  clean testing loss: 0.030475663021206856
epoch 36300  training loss: 0.056286148726940155

 37%|███▋      | 37296/100000 [01:09<01:55, 541.35it/s]
epoch 36400  training loss: 0.05627549812197685
epoch 36400  clean testing loss: 0.030557285994291306
epoch 36500  training loss: 0.05627385154366493
epoch 36500  clean testing loss: 0.030431505292654037
epoch 36600  training loss: 0.05630863457918167
epoch 36600  clean testing loss: 0.03028179332613945
epoch 36700  training loss: 0.0562908835709095
epoch 36700  clean testing loss: 0.03070547990500927
epoch 36800  training loss: 0.0563012920320034
epoch 36800  clean testing loss: 0.030370721593499184
epoch 36900  training loss: 0.056258004158735275
epoch 36900  clean testing loss: 0.03053840808570385
epoch 37000  training loss: 0.056273203343153
epoch 37000  clean testing loss: 0.030740592628717422
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 37100  training loss: 0.05626428872346878
epoch 37100  clean testing loss: 0.030461842194199562
epoch 37200  training loss: 0.056286465376615524
epoch 37200  clean testing loss: 0.030311888083815575
epoch 37300  training loss: 0.05626986175775528
epoch 37300  clean testing loss: 0.03035912849009037
epoch 37400  training loss: 0.0562434121966362

 38%|███▊      | 38391/100000 [01:11<01:53, 542.66it/s]
epoch 37500  training loss: 0.05624442547559738
epoch 37500  clean testing loss: 0.030348490923643112
epoch 37600  training loss: 0.056244753301143646
epoch 37600  clean testing loss: 0.030642753466963768
epoch 37700  training loss: 0.05623714625835419
epoch 37700  clean testing loss: 0.030610600486397743
epoch 37800  training loss: 0.056233782321214676
epoch 37800  clean testing loss: 0.03043248876929283
epoch 37900  training loss: 0.056247103959321976
epoch 37900  clean testing loss: 0.030748315155506134
epoch 38000  training loss: 0.05622468143701553
epoch 38000  clean testing loss: 0.030588949099183083
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 38100  training loss: 0.05622336268424988
epoch 38100  clean testing loss: 0.030519284307956696
epoch 38200  training loss: 0.05624569207429886
epoch 38200  clean testing loss: 0.03032730333507061
epoch 38300  training loss: 0.05621811002492905
epoch 38300  clean testing loss: 0.030511578544974327
epoch 38400  training loss: 0.056214507669210434

 39%|███▉      | 39494/100000 [01:13<01:51, 543.09it/s]
epoch 38500  training loss: 0.05621308460831642
epoch 38500  clean testing loss: 0.030455121770501137
epoch 38600  training loss: 0.056207552552223206
epoch 38600  clean testing loss: 0.03063986264169216
epoch 38700  training loss: 0.05620826408267021
epoch 38700  clean testing loss: 0.03057718090713024
epoch 38800  training loss: 0.05619766563177109
epoch 38800  clean testing loss: 0.03047550655901432
epoch 38900  training loss: 0.056199122220277786
epoch 38900  clean testing loss: 0.03045092523097992
epoch 39000  training loss: 0.05621037632226944
epoch 39000  clean testing loss: 0.03038443811237812
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 39100  training loss: 0.056184008717536926
epoch 39100  clean testing loss: 0.03056800179183483
epoch 39200  training loss: 0.05618232116103172
epoch 39200  clean testing loss: 0.030520865693688393
epoch 39300  training loss: 0.056183066219091415
epoch 39300  clean testing loss: 0.03053891845047474
epoch 39400  training loss: 0.05617902800440788
epoch 39400  clean testing loss: 0.030453767627477646
epoch 39500  training loss: 0.05618119612336159

 41%|████      | 40545/100000 [01:15<01:49, 541.36it/s]
epoch 39600  training loss: 0.056183330714702606
epoch 39600  clean testing loss: 0.030355416238307953
epoch 39700  training loss: 0.05618220940232277
epoch 39700  clean testing loss: 0.030727168545126915
epoch 39800  training loss: 0.056171976029872894
epoch 39800  clean testing loss: 0.030442019924521446
epoch 39900  training loss: 0.056160494685173035
epoch 39900  clean testing loss: 0.030636833980679512
epoch 40000  training loss: 0.056164663285017014
epoch 40000  clean testing loss: 0.03046317957341671
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 40100  training loss: 0.056162890046834946
epoch 40100  clean testing loss: 0.03049090877175331
epoch 40200  training loss: 0.056157659739255905
epoch 40200  clean testing loss: 0.030544716864824295
epoch 40300  training loss: 0.056156598031520844
epoch 40300  clean testing loss: 0.030435213819146156
epoch 40400  training loss: 0.056146182119846344
epoch 40400  clean testing loss: 0.030537890270352364
epoch 40500  training loss: 0.05616019666194916
epoch 40500  clean testing loss: 0.030736016109585762
epoch 40600  training loss: 0.05614648386836052

 42%|████▏     | 41649/100000 [01:17<01:47, 542.24it/s]
epoch 40700  training loss: 0.05617083981633186
epoch 40700  clean testing loss: 0.030796624720096588
epoch 40800  training loss: 0.05614035949110985
epoch 40800  clean testing loss: 0.030767297372221947
epoch 40900  training loss: 0.056161392480134964
epoch 40900  clean testing loss: 0.030811306089162827
epoch 41000  training loss: 0.056153230369091034
epoch 41000  clean testing loss: 0.030477311462163925
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 41100  training loss: 0.05613098293542862
epoch 41100  clean testing loss: 0.030564939603209496
epoch 41200  training loss: 0.0561392679810524
epoch 41200  clean testing loss: 0.030785847455263138
epoch 41300  training loss: 0.056137096136808395
epoch 41300  clean testing loss: 0.030454223975539207
epoch 41400  training loss: 0.056124743074178696
epoch 41400  clean testing loss: 0.03063995949923992
epoch 41500  training loss: 0.05611651763319969
epoch 41500  clean testing loss: 0.030626611784100533
epoch 41600  training loss: 0.05612848326563835
epoch 41600  clean testing loss: 0.03047211281955242
epoch 41700  training loss: 0.056119322776794434

 43%|████▎     | 42699/100000 [01:19<01:45, 545.27it/s]
epoch 41800  training loss: 0.056130364537239075
epoch 41800  clean testing loss: 0.03092263825237751
epoch 41900  training loss: 0.0561119019985199
epoch 41900  clean testing loss: 0.03059462271630764
epoch 42000  training loss: 0.05610751733183861
epoch 42000  clean testing loss: 0.03056222014129162
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 42100  training loss: 0.056097362190485
epoch 42100  clean testing loss: 0.03062889352440834
epoch 42200  training loss: 0.05609787255525589
epoch 42200  clean testing loss: 0.030596086755394936
epoch 42300  training loss: 0.056097108870744705
epoch 42300  clean testing loss: 0.03059576265513897
epoch 42400  training loss: 0.056104015558958054
epoch 42400  clean testing loss: 0.0304721649736166
epoch 42500  training loss: 0.056094709783792496
epoch 42500  clean testing loss: 0.03052680194377899
epoch 42600  training loss: 0.0560891292989254
epoch 42600  clean testing loss: 0.0306344423443079
epoch 42700  training loss: 0.05608681961894035
epoch 42700  clean testing loss: 0.03054180182516575
epoch 42800  training loss: 0.05609678477048874

 44%|████▍     | 43799/100000 [01:21<01:43, 542.93it/s]
epoch 42900  training loss: 0.0560857430100441
epoch 42900  clean testing loss: 0.030589863657951355
epoch 43000  training loss: 0.05609161779284477
epoch 43000  clean testing loss: 0.030812034383416176
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 43100  training loss: 0.05608265846967697
epoch 43100  clean testing loss: 0.030482666566967964
epoch 43200  training loss: 0.056093089282512665
epoch 43200  clean testing loss: 0.030754994601011276
epoch 43300  training loss: 0.05607912316918373
epoch 43300  clean testing loss: 0.030661839991807938
epoch 43400  training loss: 0.05608513206243515
epoch 43400  clean testing loss: 0.03079861029982567
epoch 43500  training loss: 0.05607851222157478
epoch 43500  clean testing loss: 0.030502725392580032
epoch 43600  training loss: 0.05608118325471878
epoch 43600  clean testing loss: 0.030787594616413116
epoch 43700  training loss: 0.05606962740421295
epoch 43700  clean testing loss: 0.030657541006803513
epoch 43800  training loss: 0.05607271194458008

 45%|████▍     | 44840/100000 [01:23<01:42, 537.30it/s]
epoch 43900  training loss: 0.05606488883495331
epoch 43900  clean testing loss: 0.030567612498998642
epoch 44000  training loss: 0.05608208850026131
epoch 44000  clean testing loss: 0.030464105308055878
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 44100  training loss: 0.05606094002723694
epoch 44100  clean testing loss: 0.030586175620555878
epoch 44200  training loss: 0.056058358401060104
epoch 44200  clean testing loss: 0.030642347410321236
epoch 44300  training loss: 0.05605902522802353
epoch 44300  clean testing loss: 0.030680205672979355
epoch 44400  training loss: 0.05605529248714447
epoch 44400  clean testing loss: 0.030508972704410553
epoch 44500  training loss: 0.05606437847018242
epoch 44500  clean testing loss: 0.03078746795654297
epoch 44600  training loss: 0.05605260282754898
epoch 44600  clean testing loss: 0.03049146570265293
epoch 44700  training loss: 0.05604736506938934
epoch 44700  clean testing loss: 0.030670395120978355
epoch 44800  training loss: 0.056047067046165466
epoch 44800  clean testing loss: 0.03075142204761505
epoch 44900  training loss: 0.056042831391096115

 46%|████▌     | 45882/100000 [01:25<01:40, 540.90it/s]
epoch 45000  training loss: 0.056048959493637085
epoch 45000  clean testing loss: 0.030587850138545036
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 45100  training loss: 0.05603927746415138
epoch 45100  clean testing loss: 0.030582133680582047
epoch 45200  training loss: 0.05603550374507904
epoch 45200  clean testing loss: 0.030565213412046432
epoch 45300  training loss: 0.05603260174393654
epoch 45300  clean testing loss: 0.030565084889531136
epoch 45400  training loss: 0.05603236332535744
epoch 45400  clean testing loss: 0.030672239139676094
epoch 45500  training loss: 0.05602601170539856
epoch 45500  clean testing loss: 0.03069794736802578
epoch 45600  training loss: 0.05602578818798065
epoch 45600  clean testing loss: 0.030663060024380684
epoch 45700  training loss: 0.0560230053961277
epoch 45700  clean testing loss: 0.030667094513773918
epoch 45800  training loss: 0.05602442845702171
epoch 45800  clean testing loss: 0.03066273033618927
epoch 45900  training loss: 0.05602143332362175
epoch 45900  clean testing loss: 0.030717240646481514
epoch 46000  training loss: 0.0560244619846344
epoch 46000  clean testing loss: 0.030779801309108734

 47%|████▋     | 46986/100000 [01:27<01:37, 545.44it/s]
epoch 46100  training loss: 0.05601600930094719
epoch 46100  clean testing loss: 0.030637426301836967
epoch 46200  training loss: 0.056015726178884506
epoch 46200  clean testing loss: 0.030566023662686348
epoch 46300  training loss: 0.05601586773991585
epoch 46300  clean testing loss: 0.030586441978812218
epoch 46400  training loss: 0.05600952357053757
epoch 46400  clean testing loss: 0.030623385682702065
epoch 46500  training loss: 0.05600839480757713
epoch 46500  clean testing loss: 0.03069334849715233
epoch 46600  training loss: 0.05600888654589653
epoch 46600  clean testing loss: 0.030699986964464188
epoch 46700  training loss: 0.05600285902619362
epoch 46700  clean testing loss: 0.030683530494570732
epoch 46800  training loss: 0.056006986647844315
epoch 46800  clean testing loss: 0.030780626460909843
epoch 46900  training loss: 0.056003596633672714
epoch 46900  clean testing loss: 0.03060067445039749
epoch 47000  training loss: 0.056003887206315994
epoch 47000  clean testing loss: 0.030786316841840744

 48%|████▊     | 48089/100000 [01:29<01:36, 539.43it/s]
epoch 47100  training loss: 0.056007008999586105
epoch 47100  clean testing loss: 0.030541930347681046
epoch 47200  training loss: 0.056000739336013794
epoch 47200  clean testing loss: 0.030688615515828133
epoch 47300  training loss: 0.055993203073740005
epoch 47300  clean testing loss: 0.03061269409954548
epoch 47400  training loss: 0.055997882038354874
epoch 47400  clean testing loss: 0.030575694516301155
epoch 47500  training loss: 0.0559978149831295
epoch 47500  clean testing loss: 0.03082158789038658
epoch 47600  training loss: 0.05600045621395111
epoch 47600  clean testing loss: 0.03079695999622345
epoch 47700  training loss: 0.05598847568035126
epoch 47700  clean testing loss: 0.030678922310471535
epoch 47800  training loss: 0.05598784238100052
epoch 47800  clean testing loss: 0.030646052211523056
epoch 47900  training loss: 0.05600195750594139
epoch 47900  clean testing loss: 0.03055380843579769
epoch 48000  training loss: 0.05599544569849968
epoch 48000  clean testing loss: 0.0307485181838274
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 48100  training loss: 0.05598081648349762

 49%|████▉     | 49141/100000 [01:31<01:34, 536.80it/s]
epoch 48200  training loss: 0.05597894266247749
epoch 48200  clean testing loss: 0.030685700476169586
epoch 48300  training loss: 0.05597404018044472
epoch 48300  clean testing loss: 0.030667798593640327
epoch 48400  training loss: 0.05597703903913498
epoch 48400  clean testing loss: 0.03076864778995514
epoch 48500  training loss: 0.055970605462789536
epoch 48500  clean testing loss: 0.030740492045879364
epoch 48600  training loss: 0.05596905201673508
epoch 48600  clean testing loss: 0.030658327043056488
epoch 48700  training loss: 0.05597124621272087
epoch 48700  clean testing loss: 0.030673034489154816
epoch 48800  training loss: 0.05596550554037094
epoch 48800  clean testing loss: 0.03071538545191288
epoch 48900  training loss: 0.05596834048628807
epoch 48900  clean testing loss: 0.030713273212313652
epoch 49000  training loss: 0.05596979707479477
epoch 49000  clean testing loss: 0.030643781647086143
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 49100  training loss: 0.05596335232257843
epoch 49100  clean testing loss: 0.030763141810894012
epoch 49200  training loss: 0.055960964411497116

 50%|█████     | 50244/100000 [01:33<01:32, 535.78it/s]
epoch 49300  training loss: 0.055961284786462784
epoch 49300  clean testing loss: 0.030650466680526733
epoch 49400  training loss: 0.05595821514725685
epoch 49400  clean testing loss: 0.03063642419874668
epoch 49500  training loss: 0.05595437437295914
epoch 49500  clean testing loss: 0.03074239194393158
epoch 49600  training loss: 0.05595371499657631
epoch 49600  clean testing loss: 0.030696015805006027
epoch 49700  training loss: 0.05595222860574722
epoch 49700  clean testing loss: 0.03065590001642704
epoch 49800  training loss: 0.055952347815036774
epoch 49800  clean testing loss: 0.030765743926167488
epoch 49900  training loss: 0.055950503796339035
epoch 49900  clean testing loss: 0.030673222616314888
epoch 50000  training loss: 0.05595611408352852
epoch 50000  clean testing loss: 0.030808519572019577
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 50100  training loss: 0.055949579924345016
epoch 50100  clean testing loss: 0.030651668086647987
epoch 50200  training loss: 0.055947985500097275
epoch 50200  clean testing loss: 0.030770841985940933
epoch 50300  training loss: 0.05594571307301521

 51%|█████▏    | 51289/100000 [01:35<01:29, 541.49it/s]
epoch 50400  training loss: 0.05594922602176666
epoch 50400  clean testing loss: 0.03082285448908806
epoch 50500  training loss: 0.05593978986144066
epoch 50500  clean testing loss: 0.030700555071234703
epoch 50600  training loss: 0.05594184994697571
epoch 50600  clean testing loss: 0.03064410574734211
epoch 50700  training loss: 0.05594039335846901
epoch 50700  clean testing loss: 0.030782019719481468
epoch 50800  training loss: 0.05594000592827797
epoch 50800  clean testing loss: 0.030739661306142807
epoch 50900  training loss: 0.05593709647655487
epoch 50900  clean testing loss: 0.030733224004507065
epoch 51000  training loss: 0.05593978241086006
epoch 51000  clean testing loss: 0.03068958781659603
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 51100  training loss: 0.05593055859208107
epoch 51100  clean testing loss: 0.03067704662680626
epoch 51200  training loss: 0.05592825636267662
epoch 51200  clean testing loss: 0.030677951872348785
epoch 51300  training loss: 0.055927470326423645
epoch 51300  clean testing loss: 0.03069950081408024
epoch 51400  training loss: 0.05592791363596916

 52%|█████▏    | 52394/100000 [01:37<01:27, 543.74it/s]
epoch 51500  training loss: 0.05593162029981613
epoch 51500  clean testing loss: 0.030688634142279625
epoch 51600  training loss: 0.05592459440231323
epoch 51600  clean testing loss: 0.03069462813436985
epoch 51700  training loss: 0.05592542886734009
epoch 51700  clean testing loss: 0.03070746548473835
epoch 51800  training loss: 0.0559251606464386
epoch 51800  clean testing loss: 0.030748944729566574
epoch 51900  training loss: 0.05592435225844383
epoch 51900  clean testing loss: 0.030790384858846664
epoch 52000  training loss: 0.05592105910181999
epoch 52000  clean testing loss: 0.03071707859635353
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 52100  training loss: 0.05591827630996704
epoch 52100  clean testing loss: 0.030795704573392868
epoch 52200  training loss: 0.05591914802789688
epoch 52200  clean testing loss: 0.03067244589328766
epoch 52300  training loss: 0.055921413004398346
epoch 52300  clean testing loss: 0.030812127515673637
epoch 52400  training loss: 0.05591687560081482

 53%|█████▎    | 53444/100000 [01:39<01:26, 541.24it/s]
epoch 52500  training loss: 0.05591503530740738
epoch 52500  clean testing loss: 0.03074479103088379
epoch 52600  training loss: 0.055915046483278275
epoch 52600  clean testing loss: 0.03073323704302311
epoch 52700  training loss: 0.05591322481632233
epoch 52700  clean testing loss: 0.030739691108465195
epoch 52800  training loss: 0.055910807102918625
epoch 52800  clean testing loss: 0.030733957886695862
epoch 52900  training loss: 0.05591816455125809
epoch 52900  clean testing loss: 0.03078354522585869
epoch 53000  training loss: 0.055910419672727585
epoch 53000  clean testing loss: 0.030681585893034935
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 53100  training loss: 0.05591074377298355
epoch 53100  clean testing loss: 0.030641833320260048
epoch 53200  training loss: 0.05590745806694031
epoch 53200  clean testing loss: 0.030816050246357918
epoch 53300  training loss: 0.055906977504491806
epoch 53300  clean testing loss: 0.030769923701882362
epoch 53400  training loss: 0.055906783789396286
epoch 53400  clean testing loss: 0.030685093253850937
epoch 53500  training loss: 0.0559048168361187

 55%|█████▍    | 54550/100000 [01:41<01:23, 542.29it/s]
epoch 53600  training loss: 0.05590251460671425
epoch 53600  clean testing loss: 0.030682992190122604
epoch 53700  training loss: 0.05590100213885307
epoch 53700  clean testing loss: 0.030689405277371407
epoch 53800  training loss: 0.05589909851551056
epoch 53800  clean testing loss: 0.03077700175344944
epoch 53900  training loss: 0.05589840188622475
epoch 53900  clean testing loss: 0.030832035467028618
epoch 54000  training loss: 0.05589886009693146
epoch 54000  clean testing loss: 0.030756875872612
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 54100  training loss: 0.055894527584314346
epoch 54100  clean testing loss: 0.030774589627981186
epoch 54200  training loss: 0.05589325353503227
epoch 54200  clean testing loss: 0.03074321150779724
epoch 54300  training loss: 0.05589265748858452
epoch 54300  clean testing loss: 0.030747490003705025
epoch 54400  training loss: 0.0558927021920681
epoch 54400  clean testing loss: 0.03076215088367462
epoch 54500  training loss: 0.055889543145895004
epoch 54500  clean testing loss: 0.03070191666483879
epoch 54600  training loss: 0.05588884279131889

 56%|█████▌    | 55652/100000 [01:43<01:22, 538.12it/s]
epoch 54700  training loss: 0.05588706582784653
epoch 54700  clean testing loss: 0.030796697363257408
epoch 54800  training loss: 0.055885788053274155
epoch 54800  clean testing loss: 0.03077584132552147
epoch 54900  training loss: 0.05588763579726219
epoch 54900  clean testing loss: 0.030777258798480034
epoch 55000  training loss: 0.05588415265083313
epoch 55000  clean testing loss: 0.030794212594628334
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 55100  training loss: 0.05588124319911003
epoch 55100  clean testing loss: 0.030770976096391678
epoch 55200  training loss: 0.05588485300540924
epoch 55200  clean testing loss: 0.030793949961662292
epoch 55300  training loss: 0.055879976600408554
epoch 55300  clean testing loss: 0.03074440360069275
epoch 55400  training loss: 0.05587805435061455
epoch 55400  clean testing loss: 0.030761629343032837
epoch 55500  training loss: 0.05587875470519066
epoch 55500  clean testing loss: 0.030789120122790337
epoch 55600  training loss: 0.05587878078222275
epoch 55600  clean testing loss: 0.03083116188645363
epoch 55700  training loss: 0.05587424710392952

 57%|█████▋    | 56701/100000 [01:45<01:19, 541.40it/s]
epoch 55800  training loss: 0.05587541311979294
epoch 55800  clean testing loss: 0.030816175043582916
epoch 55900  training loss: 0.05587383732199669
epoch 55900  clean testing loss: 0.030802374705672264
epoch 56000  training loss: 0.05587180703878403
epoch 56000  clean testing loss: 0.030733365565538406
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 56100  training loss: 0.05587027594447136
epoch 56100  clean testing loss: 0.030804062262177467
epoch 56200  training loss: 0.055867746472358704
epoch 56200  clean testing loss: 0.03077501617372036
epoch 56300  training loss: 0.05586765706539154
epoch 56300  clean testing loss: 0.030795671045780182
epoch 56400  training loss: 0.05586964264512062
epoch 56400  clean testing loss: 0.030780000612139702
epoch 56500  training loss: 0.055870555341243744
epoch 56500  clean testing loss: 0.030833784490823746
epoch 56600  training loss: 0.05586802959442139
epoch 56600  clean testing loss: 0.030843423679471016
epoch 56700  training loss: 0.05586647242307663
epoch 56700  clean testing loss: 0.030711721628904343
epoch 56800  training loss: 0.055863432586193085

 58%|█████▊    | 57801/100000 [01:47<01:18, 539.30it/s]
epoch 56900  training loss: 0.055863380432128906
epoch 56900  clean testing loss: 0.030795061960816383
epoch 57000  training loss: 0.055861879140138626
epoch 57000  clean testing loss: 0.030786821618676186
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 57100  training loss: 0.055858172476291656
epoch 57100  clean testing loss: 0.03083772398531437
epoch 57200  training loss: 0.055857058614492416
epoch 57200  clean testing loss: 0.03078831546008587
epoch 57300  training loss: 0.055856265127658844
epoch 57300  clean testing loss: 0.030769892036914825
epoch 57400  training loss: 0.055855050683021545
epoch 57400  clean testing loss: 0.03076057881116867
epoch 57500  training loss: 0.055854663252830505
epoch 57500  clean testing loss: 0.03082507662475109
epoch 57600  training loss: 0.055853694677352905
epoch 57600  clean testing loss: 0.030803484842181206
epoch 57700  training loss: 0.05585339665412903
epoch 57700  clean testing loss: 0.030805449932813644
epoch 57800  training loss: 0.055852100253105164

 59%|█████▉    | 58844/100000 [01:49<01:16, 540.04it/s]
epoch 57900  training loss: 0.05585043504834175
epoch 57900  clean testing loss: 0.03081572614610195
epoch 58000  training loss: 0.055849093943834305
epoch 58000  clean testing loss: 0.030795089900493622
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 58100  training loss: 0.05584951862692833
epoch 58100  clean testing loss: 0.030803930014371872
epoch 58200  training loss: 0.05584759637713432
epoch 58200  clean testing loss: 0.030780965462327003
epoch 58300  training loss: 0.055847328156232834
epoch 58300  clean testing loss: 0.030827457085251808
epoch 58400  training loss: 0.05584762617945671
epoch 58400  clean testing loss: 0.030789289623498917
epoch 58500  training loss: 0.055844295769929886
epoch 58500  clean testing loss: 0.030833473429083824
epoch 58600  training loss: 0.055843815207481384
epoch 58600  clean testing loss: 0.030815603211522102
epoch 58700  training loss: 0.055842719972133636
epoch 58700  clean testing loss: 0.03079582005739212
epoch 58800  training loss: 0.05584265664219856
epoch 58800  clean testing loss: 0.030817870050668716
epoch 58900  training loss: 0.055841609835624695

 60%|█████▉    | 59949/100000 [01:51<01:13, 541.94it/s]
epoch 59000  training loss: 0.05584019795060158
epoch 59000  clean testing loss: 0.030880745500326157
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 59100  training loss: 0.05584237352013588
epoch 59100  clean testing loss: 0.03087746538221836
epoch 59200  training loss: 0.0558377243578434
epoch 59200  clean testing loss: 0.030850447714328766
epoch 59300  training loss: 0.055836476385593414
epoch 59300  clean testing loss: 0.03081555664539337
epoch 59400  training loss: 0.05583770200610161
epoch 59400  clean testing loss: 0.03079550340771675
epoch 59500  training loss: 0.055836595594882965
epoch 59500  clean testing loss: 0.030815433710813522
epoch 59600  training loss: 0.05583369359374046
epoch 59600  clean testing loss: 0.030784646049141884
epoch 59700  training loss: 0.05583205819129944
epoch 59700  clean testing loss: 0.030837232246994972
epoch 59800  training loss: 0.055831942707300186
epoch 59800  clean testing loss: 0.03085375390946865
epoch 59900  training loss: 0.05583101883530617
epoch 59900  clean testing loss: 0.030762992799282074
epoch 60000  training loss: 0.05583248287439346
epoch 60000  clean testing loss: 0.030802860856056213

 61%|██████    | 61050/100000 [01:53<01:13, 530.28it/s]
epoch 60100  training loss: 0.05582795292139053
epoch 60100  clean testing loss: 0.030817130580544472
epoch 60200  training loss: 0.055827029049396515
epoch 60200  clean testing loss: 0.0308114904910326
epoch 60300  training loss: 0.05582667514681816
epoch 60300  clean testing loss: 0.030827278271317482
epoch 60400  training loss: 0.05582604557275772
epoch 60400  clean testing loss: 0.03080558590590954
epoch 60500  training loss: 0.055825792253017426
epoch 60500  clean testing loss: 0.030843552201986313
epoch 60600  training loss: 0.05582551658153534
epoch 60600  clean testing loss: 0.030820926651358604
epoch 60700  training loss: 0.055824924260377884
epoch 60700  clean testing loss: 0.030828438699245453
epoch 60800  training loss: 0.05582273378968239
epoch 60800  clean testing loss: 0.03083418868482113
epoch 60900  training loss: 0.055822934955358505
epoch 60900  clean testing loss: 0.030800946056842804
epoch 61000  training loss: 0.0558219738304615
epoch 61000  clean testing loss: 0.03085028938949108
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 61100  training loss: 0.05581946671009064

 62%|██████▏   | 62088/100000 [01:55<01:10, 535.57it/s]
epoch 61200  training loss: 0.05582042783498764
epoch 61200  clean testing loss: 0.03084915317595005
epoch 61300  training loss: 0.05581928789615631
epoch 61300  clean testing loss: 0.030834108591079712
epoch 61400  training loss: 0.05581841990351677
epoch 61400  clean testing loss: 0.03081529028713703
epoch 61500  training loss: 0.055816758424043655
epoch 61500  clean testing loss: 0.03083348646759987
epoch 61600  training loss: 0.055815938860177994
epoch 61600  clean testing loss: 0.03082520142197609
epoch 61700  training loss: 0.05581675097346306
epoch 61700  clean testing loss: 0.030839048326015472
epoch 61800  training loss: 0.05581647902727127
epoch 61800  clean testing loss: 0.030799459666013718
epoch 61900  training loss: 0.055815599858760834
epoch 61900  clean testing loss: 0.030876249074935913
epoch 62000  training loss: 0.0558137446641922
epoch 62000  clean testing loss: 0.030868886038661003
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 62100  training loss: 0.05581573024392128

 63%|██████▎   | 63139/100000 [01:57<01:08, 537.07it/s]
epoch 62200  training loss: 0.055813487619161606
epoch 62200  clean testing loss: 0.030864937230944633
epoch 62300  training loss: 0.055813539773225784
epoch 62300  clean testing loss: 0.030899150297045708
epoch 62400  training loss: 0.05581176280975342
epoch 62400  clean testing loss: 0.030874066054821014
epoch 62500  training loss: 0.055810585618019104
epoch 62500  clean testing loss: 0.030834317207336426
epoch 62600  training loss: 0.055808745324611664
epoch 62600  clean testing loss: 0.030820172280073166
epoch 62700  training loss: 0.05581054091453552
epoch 62700  clean testing loss: 0.03090704418718815
epoch 62800  training loss: 0.055808138102293015
epoch 62800  clean testing loss: 0.03080386109650135
epoch 62900  training loss: 0.055806178599596024
epoch 62900  clean testing loss: 0.03085610270500183
epoch 63000  training loss: 0.055805642157793045
epoch 63000  clean testing loss: 0.03086644969880581
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 63100  training loss: 0.05580499395728111
epoch 63100  clean testing loss: 0.030855417251586914
epoch 63200  training loss: 0.05580414831638336

 64%|██████▍   | 64242/100000 [01:59<01:06, 536.74it/s]
epoch 63300  training loss: 0.055802248418331146
epoch 63300  clean testing loss: 0.030856462195515633
epoch 63400  training loss: 0.055801935493946075
epoch 63400  clean testing loss: 0.030845416709780693
epoch 63500  training loss: 0.05580049008131027
epoch 63500  clean testing loss: 0.030856244266033173
epoch 63600  training loss: 0.05580034852027893
epoch 63600  clean testing loss: 0.030854154378175735
epoch 63700  training loss: 0.0558001846075058
epoch 63700  clean testing loss: 0.03085068240761757
epoch 63800  training loss: 0.0558001734316349
epoch 63800  clean testing loss: 0.030841557309031487
epoch 63900  training loss: 0.055799100548028946
epoch 63900  clean testing loss: 0.03084641695022583
epoch 64000  training loss: 0.055798109620809555
epoch 64000  clean testing loss: 0.030852949246764183
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 64100  training loss: 0.055796410888433456
epoch 64100  clean testing loss: 0.030855104327201843
epoch 64200  training loss: 0.05579742416739464
epoch 64200  clean testing loss: 0.03083815798163414
epoch 64300  training loss: 0.05579613894224167

 65%|██████▌   | 65287/100000 [02:01<01:04, 540.77it/s]
epoch 64400  training loss: 0.05579525604844093
epoch 64400  clean testing loss: 0.030852584168314934
epoch 64500  training loss: 0.055794280022382736
epoch 64500  clean testing loss: 0.03084590844810009
epoch 64600  training loss: 0.05579434335231781
epoch 64600  clean testing loss: 0.030896300449967384
epoch 64700  training loss: 0.05579299479722977
epoch 64700  clean testing loss: 0.030877552926540375
epoch 64800  training loss: 0.055792391300201416
epoch 64800  clean testing loss: 0.030845418572425842
epoch 64900  training loss: 0.05579204857349396
epoch 64900  clean testing loss: 0.030856452882289886
epoch 65000  training loss: 0.055790651589632034
epoch 65000  clean testing loss: 0.03088684380054474
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 65100  training loss: 0.055791255086660385
epoch 65100  clean testing loss: 0.03082978166639805
epoch 65200  training loss: 0.055789098143577576
epoch 65200  clean testing loss: 0.03089938871562481
epoch 65300  training loss: 0.05578919127583504
epoch 65300  clean testing loss: 0.030864479020237923
epoch 65400  training loss: 0.05578885227441788

 66%|██████▋   | 66386/100000 [02:03<01:02, 541.39it/s]
epoch 65500  training loss: 0.05578811094164848
epoch 65500  clean testing loss: 0.0308636873960495
epoch 65600  training loss: 0.05578730255365372
epoch 65600  clean testing loss: 0.03084161877632141
epoch 65700  training loss: 0.05578731372952461
epoch 65700  clean testing loss: 0.030844025313854218
epoch 65800  training loss: 0.05578651651740074
epoch 65800  clean testing loss: 0.030902471393346786
epoch 65900  training loss: 0.055784694850444794
epoch 65900  clean testing loss: 0.030860010534524918
epoch 66000  training loss: 0.05578351020812988
epoch 66000  clean testing loss: 0.030871160328388214
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 66100  training loss: 0.05578326806426048
epoch 66100  clean testing loss: 0.03087366744875908
epoch 66200  training loss: 0.05578334257006645
epoch 66200  clean testing loss: 0.030873456969857216
epoch 66300  training loss: 0.05578230321407318
epoch 66300  clean testing loss: 0.03088795207440853
epoch 66400  training loss: 0.055781081318855286

 67%|██████▋   | 67491/100000 [02:05<00:59, 544.61it/s]
epoch 66500  training loss: 0.05578097328543663
epoch 66500  clean testing loss: 0.03086422011256218
epoch 66600  training loss: 0.05578101798892021
epoch 66600  clean testing loss: 0.030877722427248955
epoch 66700  training loss: 0.05578029900789261
epoch 66700  clean testing loss: 0.0309024415910244
epoch 66800  training loss: 0.055779773741960526
epoch 66800  clean testing loss: 0.03086666204035282
epoch 66900  training loss: 0.05577849969267845
epoch 66900  clean testing loss: 0.03086727298796177
epoch 67000  training loss: 0.05577768385410309
epoch 67000  clean testing loss: 0.030872933566570282
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 67100  training loss: 0.05577641725540161
epoch 67100  clean testing loss: 0.030879929661750793
epoch 67200  training loss: 0.055776771157979965
epoch 67200  clean testing loss: 0.030882034450769424
epoch 67300  training loss: 0.055774837732315063
epoch 67300  clean testing loss: 0.03090527467429638
epoch 67400  training loss: 0.055775001645088196
epoch 67400  clean testing loss: 0.03089570254087448
epoch 67500  training loss: 0.05577445402741432

 69%|██████▊   | 68542/100000 [02:07<00:57, 542.46it/s]
epoch 67600  training loss: 0.055774323642253876
epoch 67600  clean testing loss: 0.03084859997034073
epoch 67700  training loss: 0.05577293410897255
epoch 67700  clean testing loss: 0.030871469527482986
epoch 67800  training loss: 0.05577277019619942
epoch 67800  clean testing loss: 0.030895231291651726
epoch 67900  training loss: 0.05577191710472107
epoch 67900  clean testing loss: 0.030888501554727554
epoch 68000  training loss: 0.05577115714550018
epoch 68000  clean testing loss: 0.030891450121998787
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 68100  training loss: 0.055770836770534515
epoch 68100  clean testing loss: 0.030906327068805695
epoch 68200  training loss: 0.055770572274923325
epoch 68200  clean testing loss: 0.03089141473174095
epoch 68300  training loss: 0.05576945096254349
epoch 68300  clean testing loss: 0.03087601624429226
epoch 68400  training loss: 0.05576903373003006
epoch 68400  clean testing loss: 0.030883818864822388
epoch 68500  training loss: 0.05576857551932335
epoch 68500  clean testing loss: 0.030904380604624748
epoch 68600  training loss: 0.0557677261531353

 70%|██████▉   | 69647/100000 [02:09<00:55, 542.20it/s]
epoch 68700  training loss: 0.05576734244823456
epoch 68700  clean testing loss: 0.030873937532305717
epoch 68800  training loss: 0.05576790124177933
epoch 68800  clean testing loss: 0.030902009457349777
epoch 68900  training loss: 0.05576641857624054
epoch 68900  clean testing loss: 0.03087444417178631
epoch 69000  training loss: 0.0557655394077301
epoch 69000  clean testing loss: 0.030900241807103157
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 69100  training loss: 0.05576437711715698
epoch 69100  clean testing loss: 0.030894197523593903
epoch 69200  training loss: 0.05576425418257713
epoch 69200  clean testing loss: 0.03089241497218609
epoch 69300  training loss: 0.055763427168130875
epoch 69300  clean testing loss: 0.030888328328728676
epoch 69400  training loss: 0.055762939155101776
epoch 69400  clean testing loss: 0.030894847586750984
epoch 69500  training loss: 0.055763330310583115
epoch 69500  clean testing loss: 0.030900688841938972
epoch 69600  training loss: 0.0557623989880085
epoch 69600  clean testing loss: 0.030903127044439316
epoch 69700  training loss: 0.055761367082595825

 71%|███████   | 70698/100000 [02:11<00:53, 545.90it/s]
epoch 69800  training loss: 0.05576156824827194
epoch 69800  clean testing loss: 0.030895153060555458
epoch 69900  training loss: 0.055760547518730164
epoch 69900  clean testing loss: 0.03090670518577099
epoch 70000  training loss: 0.05576068162918091
epoch 70000  clean testing loss: 0.030898168683052063
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 70100  training loss: 0.05575922131538391
epoch 70100  clean testing loss: 0.030898649245500565
epoch 70200  training loss: 0.055758919566869736
epoch 70200  clean testing loss: 0.03088865429162979
epoch 70300  training loss: 0.055759165436029434
epoch 70300  clean testing loss: 0.030897920951247215
epoch 70400  training loss: 0.05575795844197273
epoch 70400  clean testing loss: 0.030882690101861954
epoch 70500  training loss: 0.055758241564035416
epoch 70500  clean testing loss: 0.03089642897248268
epoch 70600  training loss: 0.05575697496533394
epoch 70600  clean testing loss: 0.03089570812880993
epoch 70700  training loss: 0.05575693026185036
epoch 70700  clean testing loss: 0.030902637168765068
epoch 70800  training loss: 0.05575596168637276

 72%|███████▏  | 71799/100000 [02:13<00:52, 540.84it/s]
epoch 70900  training loss: 0.05575577914714813
epoch 70900  clean testing loss: 0.03090556152164936
epoch 71000  training loss: 0.05575557053089142
epoch 71000  clean testing loss: 0.030898405238986015
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 71100  training loss: 0.05575501546263695
epoch 71100  clean testing loss: 0.030914613977074623
epoch 71200  training loss: 0.05575427785515785
epoch 71200  clean testing loss: 0.030897848308086395
epoch 71300  training loss: 0.0557536706328392
epoch 71300  clean testing loss: 0.030888104811310768
epoch 71400  training loss: 0.055752888321876526
epoch 71400  clean testing loss: 0.030904412269592285
epoch 71500  training loss: 0.0557531975209713
epoch 71500  clean testing loss: 0.030893908813595772
epoch 71600  training loss: 0.05575242266058922
epoch 71600  clean testing loss: 0.030878916382789612
epoch 71700  training loss: 0.055752262473106384
epoch 71700  clean testing loss: 0.030906233936548233
epoch 71800  training loss: 0.055752433836460114
epoch 71800  clean testing loss: 0.030928032472729683
epoch 71900  training loss: 0.05575045198202133

 73%|███████▎  | 72899/100000 [02:15<00:49, 544.35it/s]
epoch 72000  training loss: 0.055751968175172806
epoch 72000  clean testing loss: 0.030916184186935425
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 72100  training loss: 0.05574950575828552
epoch 72100  clean testing loss: 0.03091564029455185
epoch 72200  training loss: 0.05574971064925194
epoch 72200  clean testing loss: 0.03091263957321644
epoch 72300  training loss: 0.05574946478009224
epoch 72300  clean testing loss: 0.030904868617653847
epoch 72400  training loss: 0.0557490773499012
epoch 72400  clean testing loss: 0.030899155884981155
epoch 72500  training loss: 0.055748242884874344
epoch 72500  clean testing loss: 0.03091050125658512
epoch 72600  training loss: 0.05574728548526764
epoch 72600  clean testing loss: 0.030908506363630295
epoch 72700  training loss: 0.05574783310294151
epoch 72700  clean testing loss: 0.03089856170117855
epoch 72800  training loss: 0.05574695020914078
epoch 72800  clean testing loss: 0.030914168804883957
epoch 72900  training loss: 0.05574627220630646

 74%|███████▍  | 73945/100000 [02:17<00:48, 542.17it/s]
epoch 73000  training loss: 0.055746905505657196
epoch 73000  clean testing loss: 0.03091658093035221
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 73100  training loss: 0.055746980011463165
epoch 73100  clean testing loss: 0.030912425369024277
epoch 73200  training loss: 0.05574582517147064
epoch 73200  clean testing loss: 0.030904779210686684
epoch 73300  training loss: 0.055744923651218414
epoch 73300  clean testing loss: 0.03088618814945221
epoch 73400  training loss: 0.0557449534535408
epoch 73400  clean testing loss: 0.03092063218355179
epoch 73500  training loss: 0.0557449646294117
epoch 73500  clean testing loss: 0.0309041365981102
epoch 73600  training loss: 0.05574442446231842
epoch 73600  clean testing loss: 0.03092377260327339
epoch 73700  training loss: 0.05574444681406021
epoch 73700  clean testing loss: 0.03092280775308609
epoch 73800  training loss: 0.05574369430541992
epoch 73800  clean testing loss: 0.030882030725479126
epoch 73900  training loss: 0.05574362725019455
epoch 73900  clean testing loss: 0.030912252143025398
epoch 74000  training loss: 0.055743731558322906
epoch 74000  clean testing loss: 0.03092210181057453

 75%|███████▌  | 75047/100000 [02:19<00:46, 532.50it/s]
epoch 74100  training loss: 0.05574232339859009
epoch 74100  clean testing loss: 0.030902955681085587
epoch 74200  training loss: 0.05574287474155426
epoch 74200  clean testing loss: 0.03090965375304222
epoch 74300  training loss: 0.055742546916007996
epoch 74300  clean testing loss: 0.03091096319258213
epoch 74400  training loss: 0.05574198439717293
epoch 74400  clean testing loss: 0.03090147115290165
epoch 74500  training loss: 0.055742066353559494
epoch 74500  clean testing loss: 0.03091667965054512
epoch 74600  training loss: 0.055741678923368454
epoch 74600  clean testing loss: 0.030893422663211823
epoch 74700  training loss: 0.055741820484399796
epoch 74700  clean testing loss: 0.030913889408111572
epoch 74800  training loss: 0.055740684270858765
epoch 74800  clean testing loss: 0.030928893014788628
epoch 74900  training loss: 0.05574004724621773
epoch 74900  clean testing loss: 0.030924117192626
epoch 75000  training loss: 0.05574017018079758
epoch 75000  clean testing loss: 0.03092162497341633
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 75100  training loss: 0.05573946237564087

 76%|███████▌  | 76097/100000 [02:21<00:44, 537.45it/s]
epoch 75200  training loss: 0.055739227682352066
epoch 75200  clean testing loss: 0.03091544099152088
epoch 75300  training loss: 0.055739015340805054
epoch 75300  clean testing loss: 0.03093869797885418
epoch 75400  training loss: 0.05573859065771103
epoch 75400  clean testing loss: 0.03092684969305992
epoch 75500  training loss: 0.05573813617229462
epoch 75500  clean testing loss: 0.03093019686639309
epoch 75600  training loss: 0.05573776736855507
epoch 75600  clean testing loss: 0.030924435704946518
epoch 75700  training loss: 0.05573723092675209
epoch 75700  clean testing loss: 0.030927766114473343
epoch 75800  training loss: 0.05573713406920433
epoch 75800  clean testing loss: 0.030923426151275635
epoch 75900  training loss: 0.0557372085750103
epoch 75900  clean testing loss: 0.03093511052429676
epoch 76000  training loss: 0.0557369664311409
epoch 76000  clean testing loss: 0.030917102470993996
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 76100  training loss: 0.055736057460308075
epoch 76100  clean testing loss: 0.030923180282115936
epoch 76200  training loss: 0.0557362325489521

 77%|███████▋  | 77201/100000 [02:23<00:42, 533.10it/s]
epoch 76300  training loss: 0.055735938251018524
epoch 76300  clean testing loss: 0.030919967219233513
epoch 76400  training loss: 0.055735789239406586
epoch 76400  clean testing loss: 0.030921174213290215
epoch 76500  training loss: 0.05573548376560211
epoch 76500  clean testing loss: 0.030924474820494652
epoch 76600  training loss: 0.055735040456056595
epoch 76600  clean testing loss: 0.030929993838071823
epoch 76700  training loss: 0.055734675377607346
epoch 76700  clean testing loss: 0.030919305980205536
epoch 76800  training loss: 0.05573529377579689
epoch 76800  clean testing loss: 0.030935058370232582
epoch 76900  training loss: 0.055734969675540924
epoch 76900  clean testing loss: 0.0309104323387146
epoch 77000  training loss: 0.05573490634560585
epoch 77000  clean testing loss: 0.030922850593924522
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 77100  training loss: 0.0557342953979969
epoch 77100  clean testing loss: 0.03091423586010933
epoch 77200  training loss: 0.055733270943164825

 78%|███████▊  | 78239/100000 [02:25<00:41, 530.60it/s]
epoch 77300  training loss: 0.05573348328471184
epoch 77300  clean testing loss: 0.03090560808777809
epoch 77400  training loss: 0.05573321133852005
epoch 77400  clean testing loss: 0.03093562461435795
epoch 77500  training loss: 0.05573291331529617
epoch 77500  clean testing loss: 0.030925055965781212
epoch 77600  training loss: 0.05573272332549095
epoch 77600  clean testing loss: 0.030913954600691795
epoch 77700  training loss: 0.05573217198252678
epoch 77700  clean testing loss: 0.030934812501072884
epoch 77800  training loss: 0.05573219805955887
epoch 77800  clean testing loss: 0.030934952199459076
epoch 77900  training loss: 0.055732324719429016
epoch 77900  clean testing loss: 0.030938630923628807
epoch 78000  training loss: 0.055731937289237976
epoch 78000  clean testing loss: 0.030927840620279312
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 78100  training loss: 0.05573121830821037
epoch 78100  clean testing loss: 0.030938943848013878
epoch 78200  training loss: 0.05573093518614769
epoch 78200  clean testing loss: 0.030920805409550667
epoch 78300  training loss: 0.055730730295181274

 79%|███████▉  | 79281/100000 [02:27<00:38, 541.63it/s]
epoch 78400  training loss: 0.0557301789522171
epoch 78400  clean testing loss: 0.030932413414120674
epoch 78500  training loss: 0.05572989210486412
epoch 78500  clean testing loss: 0.030929263681173325
epoch 78600  training loss: 0.05573052540421486
epoch 78600  clean testing loss: 0.030935246497392654
epoch 78700  training loss: 0.05572972446680069
epoch 78700  clean testing loss: 0.030933961272239685
epoch 78800  training loss: 0.05572948604822159
epoch 78800  clean testing loss: 0.03094037063419819
epoch 78900  training loss: 0.05572958663105965
epoch 78900  clean testing loss: 0.030940622091293335
epoch 79000  training loss: 0.05572929605841637
epoch 79000  clean testing loss: 0.030935360118746758
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 79100  training loss: 0.05572900548577309
epoch 79100  clean testing loss: 0.03094562329351902
epoch 79200  training loss: 0.055729083716869354
epoch 79200  clean testing loss: 0.0309282336384058
epoch 79300  training loss: 0.05572842061519623
epoch 79300  clean testing loss: 0.03094531036913395
epoch 79400  training loss: 0.055728327482938766

 80%|████████  | 80382/100000 [02:29<00:36, 542.76it/s]
epoch 79500  training loss: 0.05572837218642235
epoch 79500  clean testing loss: 0.030932389199733734
epoch 79600  training loss: 0.055727794766426086
epoch 79600  clean testing loss: 0.03093096800148487
epoch 79700  training loss: 0.05572783574461937
epoch 79700  clean testing loss: 0.03094382956624031
epoch 79800  training loss: 0.05572815611958504
epoch 79800  clean testing loss: 0.030955927446484566
epoch 79900  training loss: 0.05572735518217087
epoch 79900  clean testing loss: 0.0309324711561203
epoch 80000  training loss: 0.05572705343365669
epoch 80000  clean testing loss: 0.03092590905725956
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 80100  training loss: 0.0557270422577858
epoch 80100  clean testing loss: 0.030933549627661705
epoch 80200  training loss: 0.055726733058691025
epoch 80200  clean testing loss: 0.030924497172236443
epoch 80300  training loss: 0.055726248770952225
epoch 80300  clean testing loss: 0.030930256471037865
epoch 80400  training loss: 0.055726442486047745

 81%|████████▏ | 81487/100000 [02:31<00:33, 545.38it/s]
epoch 80500  training loss: 0.055725932121276855
epoch 80500  clean testing loss: 0.03092530556023121
epoch 80600  training loss: 0.055725645273923874
epoch 80600  clean testing loss: 0.03093196637928486
epoch 80700  training loss: 0.055724889039993286
epoch 80700  clean testing loss: 0.030942300334572792
epoch 80800  training loss: 0.055725108832120895
epoch 80800  clean testing loss: 0.030945610255002975
epoch 80900  training loss: 0.05572473630309105
epoch 80900  clean testing loss: 0.03095066361129284
epoch 81000  training loss: 0.05572381988167763
epoch 81000  clean testing loss: 0.030945129692554474
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 81100  training loss: 0.055723514407873154
epoch 81100  clean testing loss: 0.03094315342605114
epoch 81200  training loss: 0.055723756551742554
epoch 81200  clean testing loss: 0.030932534486055374
epoch 81300  training loss: 0.05572366714477539
epoch 81300  clean testing loss: 0.030942857265472412
epoch 81400  training loss: 0.05572318658232689
epoch 81400  clean testing loss: 0.030935129150748253
epoch 81500  training loss: 0.0557229220867157

 83%|████████▎ | 82537/100000 [02:33<00:32, 540.53it/s]
epoch 81600  training loss: 0.055722787976264954
epoch 81600  clean testing loss: 0.030954554677009583
epoch 81700  training loss: 0.05572258308529854
epoch 81700  clean testing loss: 0.03094528056681156
epoch 81800  training loss: 0.055722564458847046
epoch 81800  clean testing loss: 0.03094622492790222
epoch 81900  training loss: 0.0557221956551075
epoch 81900  clean testing loss: 0.030955709517002106
epoch 82000  training loss: 0.05572209879755974
epoch 82000  clean testing loss: 0.030943164601922035
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 82100  training loss: 0.055721819400787354
epoch 82100  clean testing loss: 0.030939949676394463
epoch 82200  training loss: 0.05572153627872467
epoch 82200  clean testing loss: 0.030948476865887642
epoch 82300  training loss: 0.055721431970596313
epoch 82300  clean testing loss: 0.030928323045372963
epoch 82400  training loss: 0.05572134628891945
epoch 82400  clean testing loss: 0.030955282971262932
epoch 82500  training loss: 0.05572092533111572
epoch 82500  clean testing loss: 0.030949966982007027
epoch 82600  training loss: 0.05572088807821274

 84%|████████▎ | 83640/100000 [02:35<00:30, 542.67it/s]
epoch 82700  training loss: 0.05572083964943886
epoch 82700  clean testing loss: 0.030956197530031204
epoch 82800  training loss: 0.055720698088407516
epoch 82800  clean testing loss: 0.03095230646431446
epoch 82900  training loss: 0.05571978911757469
epoch 82900  clean testing loss: 0.03094640001654625
epoch 83000  training loss: 0.055720116943120956
epoch 83000  clean testing loss: 0.030940933153033257
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 83100  training loss: 0.055720217525959015
epoch 83100  clean testing loss: 0.0309491865336895
epoch 83200  training loss: 0.05571998283267021
epoch 83200  clean testing loss: 0.030942410230636597
epoch 83300  training loss: 0.05571994185447693
epoch 83300  clean testing loss: 0.030942421406507492
epoch 83400  training loss: 0.05571957677602768
epoch 83400  clean testing loss: 0.03094329684972763
epoch 83500  training loss: 0.055719319730997086
epoch 83500  clean testing loss: 0.030951105058193207
epoch 83600  training loss: 0.055719077587127686
epoch 83600  clean testing loss: 0.030940016731619835
epoch 83700  training loss: 0.05571891739964485

 85%|████████▍ | 84691/100000 [02:37<00:28, 544.79it/s]
epoch 83800  training loss: 0.05571891367435455
epoch 83800  clean testing loss: 0.030963100492954254
epoch 83900  training loss: 0.05571885406970978
epoch 83900  clean testing loss: 0.030948391184210777
epoch 84000  training loss: 0.0557180792093277
epoch 84000  clean testing loss: 0.03096001222729683
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 84100  training loss: 0.05571790039539337
epoch 84100  clean testing loss: 0.030956899747252464
epoch 84200  training loss: 0.05571770668029785
epoch 84200  clean testing loss: 0.03096083737909794
epoch 84300  training loss: 0.0557175911962986
epoch 84300  clean testing loss: 0.030950913205742836
epoch 84400  training loss: 0.055717453360557556
epoch 84400  clean testing loss: 0.03095211088657379
epoch 84500  training loss: 0.05571718141436577
epoch 84500  clean testing loss: 0.030942419543862343
epoch 84600  training loss: 0.05571703985333443
epoch 84600  clean testing loss: 0.030950184911489487
epoch 84700  training loss: 0.055716708302497864
epoch 84700  clean testing loss: 0.03094121627509594
epoch 84800  training loss: 0.05571676418185234

 86%|████████▌ | 85795/100000 [02:39<00:26, 544.03it/s]
epoch 84900  training loss: 0.05571644753217697
epoch 84900  clean testing loss: 0.030958713963627815
epoch 85000  training loss: 0.05571674555540085
epoch 85000  clean testing loss: 0.03094653971493244
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 85100  training loss: 0.05571616813540459
epoch 85100  clean testing loss: 0.030957581475377083
epoch 85200  training loss: 0.05571598559617996
epoch 85200  clean testing loss: 0.03094875067472458
epoch 85300  training loss: 0.05571579933166504
epoch 85300  clean testing loss: 0.030943868681788445
epoch 85400  training loss: 0.05571568384766579
epoch 85400  clean testing loss: 0.030942054465413094
epoch 85500  training loss: 0.055715411901474
epoch 85500  clean testing loss: 0.03094872273504734
epoch 85600  training loss: 0.055715132504701614
epoch 85600  clean testing loss: 0.030942486599087715
epoch 85700  training loss: 0.05571512132883072
epoch 85700  clean testing loss: 0.030949046835303307
epoch 85800  training loss: 0.055715180933475494
epoch 85800  clean testing loss: 0.030952146276831627
epoch 85900  training loss: 0.055714868009090424

 87%|████████▋ | 86897/100000 [02:41<00:24, 544.92it/s]
epoch 86000  training loss: 0.05571466311812401
epoch 86000  clean testing loss: 0.030966492369771004
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 86100  training loss: 0.055714838206768036
epoch 86100  clean testing loss: 0.03095199353992939
epoch 86200  training loss: 0.05571448802947998
epoch 86200  clean testing loss: 0.03095105290412903
epoch 86300  training loss: 0.055714357644319534
epoch 86300  clean testing loss: 0.030948758125305176
epoch 86400  training loss: 0.05571415275335312
epoch 86400  clean testing loss: 0.030948037281632423
epoch 86500  training loss: 0.055714428424835205
epoch 86500  clean testing loss: 0.03094554878771305
epoch 86600  training loss: 0.05571410804986954
epoch 86600  clean testing loss: 0.030963880941271782
epoch 86700  training loss: 0.055713944137096405
epoch 86700  clean testing loss: 0.030959514901041985
epoch 86800  training loss: 0.055713456124067307
epoch 86800  clean testing loss: 0.030959095805883408
epoch 86900  training loss: 0.055713679641485214

 88%|████████▊ | 87942/100000 [02:43<00:22, 537.13it/s]
epoch 87000  training loss: 0.055713631212711334
epoch 87000  clean testing loss: 0.030946295708417892
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 87100  training loss: 0.055713195353746414
epoch 87100  clean testing loss: 0.030952561646699905
epoch 87200  training loss: 0.055712901055812836
epoch 87200  clean testing loss: 0.030964044854044914
epoch 87300  training loss: 0.05571291595697403
epoch 87300  clean testing loss: 0.030960235744714737
epoch 87400  training loss: 0.055712711066007614
epoch 87400  clean testing loss: 0.030953364446759224
epoch 87500  training loss: 0.05571287125349045
epoch 87500  clean testing loss: 0.03096875734627247
epoch 87600  training loss: 0.05571262538433075
epoch 87600  clean testing loss: 0.030963631346821785
epoch 87700  training loss: 0.0557124987244606
epoch 87700  clean testing loss: 0.030958451330661774
epoch 87800  training loss: 0.05571260303258896
epoch 87800  clean testing loss: 0.03095453605055809
epoch 87900  training loss: 0.05571232736110687
epoch 87900  clean testing loss: 0.030960552394390106
epoch 88000  training loss: 0.05571233108639717
epoch 88000  clean testing loss: 0.030961714684963226

 89%|████████▉ | 89041/100000 [02:45<00:20, 531.53it/s]
epoch 88100  training loss: 0.05571195110678673
epoch 88100  clean testing loss: 0.030949898064136505
epoch 88200  training loss: 0.05571211874485016
epoch 88200  clean testing loss: 0.030960995703935623
epoch 88300  training loss: 0.05571211874485016
epoch 88300  clean testing loss: 0.030971279367804527
epoch 88400  training loss: 0.05571173503994942
epoch 88400  clean testing loss: 0.030950559303164482
epoch 88500  training loss: 0.05571165680885315
epoch 88500  clean testing loss: 0.03096868470311165
epoch 88600  training loss: 0.05571162700653076
epoch 88600  clean testing loss: 0.030952295288443565
epoch 88700  training loss: 0.05571134388446808
epoch 88700  clean testing loss: 0.03095811791718006
epoch 88800  training loss: 0.05571117624640465
epoch 88800  clean testing loss: 0.030962659046053886
epoch 88900  training loss: 0.05571094900369644
epoch 88900  clean testing loss: 0.030965905636548996
epoch 89000  training loss: 0.05571115389466286
epoch 89000  clean testing loss: 0.030968034639954567
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 89100  training loss: 0.05571112409234047

 90%|█████████ | 90091/100000 [02:47<00:18, 539.75it/s]
epoch 89200  training loss: 0.05571070685982704
epoch 89200  clean testing loss: 0.030961820855736732
epoch 89300  training loss: 0.055710550397634506
epoch 89300  clean testing loss: 0.030956747010350227
epoch 89400  training loss: 0.05571064352989197
epoch 89400  clean testing loss: 0.03097010776400566
epoch 89500  training loss: 0.05571051314473152
epoch 89500  clean testing loss: 0.030964620411396027
epoch 89600  training loss: 0.055710386484861374
epoch 89600  clean testing loss: 0.030966417863965034
epoch 89700  training loss: 0.0557105578482151
epoch 89700  clean testing loss: 0.030960114672780037
epoch 89800  training loss: 0.05571010708808899
epoch 89800  clean testing loss: 0.030963029712438583
epoch 89900  training loss: 0.05570992827415466
epoch 89900  clean testing loss: 0.03096059337258339
epoch 90000  training loss: 0.05570991709828377
epoch 90000  clean testing loss: 0.030960973352193832
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 90100  training loss: 0.05570966750383377
epoch 90100  clean testing loss: 0.03095727600157261
epoch 90200  training loss: 0.05570970103144646

 91%|█████████ | 91196/100000 [02:49<00:16, 541.76it/s]
epoch 90300  training loss: 0.055709514766931534
epoch 90300  clean testing loss: 0.03096579946577549
epoch 90400  training loss: 0.05570957437157631
epoch 90400  clean testing loss: 0.03095986135303974
epoch 90500  training loss: 0.055709466338157654
epoch 90500  clean testing loss: 0.030962176620960236
epoch 90600  training loss: 0.05570932850241661
epoch 90600  clean testing loss: 0.030968941748142242
epoch 90700  training loss: 0.05570942535996437
epoch 90700  clean testing loss: 0.030957482755184174
epoch 90800  training loss: 0.05570923164486885
epoch 90800  clean testing loss: 0.03095915913581848
epoch 90900  training loss: 0.055709194391965866
epoch 90900  clean testing loss: 0.03097139112651348
epoch 91000  training loss: 0.05570905655622482
epoch 91000  clean testing loss: 0.03096022456884384
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 91100  training loss: 0.05570894479751587
epoch 91100  clean testing loss: 0.030966512858867645
epoch 91200  training loss: 0.05570872873067856
epoch 91200  clean testing loss: 0.030962800607085228
epoch 91300  training loss: 0.05570884048938751

 92%|█████████▏| 92245/100000 [02:51<00:14, 538.71it/s]
epoch 91400  training loss: 0.055708691477775574
epoch 91400  clean testing loss: 0.03096713125705719
epoch 91500  training loss: 0.05570852756500244
epoch 91500  clean testing loss: 0.030966006219387054
epoch 91600  training loss: 0.05570829287171364
epoch 91600  clean testing loss: 0.030969927087426186
epoch 91700  training loss: 0.05570835992693901
epoch 91700  clean testing loss: 0.030971096828579903
epoch 91800  training loss: 0.05570836365222931
epoch 91800  clean testing loss: 0.03097168169915676
epoch 91900  training loss: 0.055708326399326324
epoch 91900  clean testing loss: 0.03097127377986908
epoch 92000  training loss: 0.05570824071764946
epoch 92000  clean testing loss: 0.030976803973317146
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 92100  training loss: 0.055707987397909164
epoch 92100  clean testing loss: 0.030968740582466125
epoch 92200  training loss: 0.0557081401348114
epoch 92200  clean testing loss: 0.030970007181167603
epoch 92300  training loss: 0.0557078942656517

 93%|█████████▎| 93348/100000 [02:53<00:12, 534.36it/s]
epoch 92400  training loss: 0.05570811405777931
epoch 92400  clean testing loss: 0.030972404405474663
epoch 92500  training loss: 0.05570775642991066
epoch 92500  clean testing loss: 0.030961111187934875
epoch 92600  training loss: 0.055707529187202454
epoch 92600  clean testing loss: 0.030969589948654175
epoch 92700  training loss: 0.05570737645030022
epoch 92700  clean testing loss: 0.030964598059654236
epoch 92800  training loss: 0.05570757016539574
epoch 92800  clean testing loss: 0.030967343598604202
epoch 92900  training loss: 0.05570733919739723
epoch 92900  clean testing loss: 0.030972052365541458
epoch 93000  training loss: 0.05570727214217186
epoch 93000  clean testing loss: 0.030972646549344063
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 93100  training loss: 0.0557069405913353
epoch 93100  clean testing loss: 0.030969731509685516
epoch 93200  training loss: 0.05570712313055992
epoch 93200  clean testing loss: 0.03096753917634487
epoch 93300  training loss: 0.05570700764656067
epoch 93300  clean testing loss: 0.03097567707300186
epoch 93400  training loss: 0.055707063525915146

 94%|█████████▍| 94387/100000 [02:55<00:10, 533.19it/s]
epoch 93500  training loss: 0.05570698529481888
epoch 93500  clean testing loss: 0.030972573906183243
epoch 93600  training loss: 0.05570671334862709
epoch 93600  clean testing loss: 0.030972206965088844
epoch 93700  training loss: 0.05570666864514351
epoch 93700  clean testing loss: 0.030964482575654984
epoch 93800  training loss: 0.05570657178759575
epoch 93800  clean testing loss: 0.03097894787788391
epoch 93900  training loss: 0.05570660158991814
epoch 93900  clean testing loss: 0.030969876796007156
epoch 94000  training loss: 0.0557064451277256
epoch 94000  clean testing loss: 0.030967561528086662
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 94100  training loss: 0.05570632591843605
epoch 94100  clean testing loss: 0.030966496095061302
epoch 94200  training loss: 0.05570632591843605
epoch 94200  clean testing loss: 0.03096790984272957
epoch 94300  training loss: 0.055706415325403214
epoch 94300  clean testing loss: 0.03097471408545971
epoch 94400  training loss: 0.05570627748966217
epoch 94400  clean testing loss: 0.030977590009570122
epoch 94500  training loss: 0.055706169456243515

 95%|█████████▌| 95490/100000 [02:57<00:08, 545.27it/s]
epoch 94600  training loss: 0.05570599064230919
epoch 94600  clean testing loss: 0.030976902693510056
epoch 94700  training loss: 0.05570591613650322
epoch 94700  clean testing loss: 0.03097652457654476
epoch 94800  training loss: 0.05570578947663307
epoch 94800  clean testing loss: 0.030969228595495224
epoch 94900  training loss: 0.055705875158309937
epoch 94900  clean testing loss: 0.03096398152410984
epoch 95000  training loss: 0.05570588633418083
epoch 95000  clean testing loss: 0.030978068709373474
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 95100  training loss: 0.0557057149708271
epoch 95100  clean testing loss: 0.030975205823779106
epoch 95200  training loss: 0.055705659091472626
epoch 95200  clean testing loss: 0.030973710119724274
epoch 95300  training loss: 0.055705659091472626
epoch 95300  clean testing loss: 0.03096957877278328
epoch 95400  training loss: 0.05570549890398979
epoch 95400  clean testing loss: 0.030977822840213776
epoch 95500  training loss: 0.055705368518829346

 97%|█████████▋| 96537/100000 [02:59<00:06, 542.50it/s]
epoch 95600  training loss: 0.055705390870571136
epoch 95600  clean testing loss: 0.030974145978689194
epoch 95700  training loss: 0.05570526421070099
epoch 95700  clean testing loss: 0.030972963199019432
epoch 95800  training loss: 0.055705104023218155
epoch 95800  clean testing loss: 0.03097749687731266
epoch 95900  training loss: 0.055705126374959946
epoch 95900  clean testing loss: 0.030968330800533295
epoch 96000  training loss: 0.05570506677031517
epoch 96000  clean testing loss: 0.030980810523033142
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 96100  training loss: 0.05570504441857338
epoch 96100  clean testing loss: 0.0309734046459198
epoch 96200  training loss: 0.05570497363805771
epoch 96200  clean testing loss: 0.030974339693784714
epoch 96300  training loss: 0.05570502579212189
epoch 96300  clean testing loss: 0.03097294084727764
epoch 96400  training loss: 0.055704906582832336
epoch 96400  clean testing loss: 0.03098057396709919
epoch 96500  training loss: 0.05570484325289726
epoch 96500  clean testing loss: 0.030977072194218636
epoch 96600  training loss: 0.055704787373542786

 98%|█████████▊| 97644/100000 [03:01<00:04, 542.98it/s]
epoch 96700  training loss: 0.055704712867736816
epoch 96700  clean testing loss: 0.03097580187022686
epoch 96800  training loss: 0.055704742670059204
epoch 96800  clean testing loss: 0.030975785106420517
epoch 96900  training loss: 0.055704668164253235
epoch 96900  clean testing loss: 0.03098161891102791
epoch 97000  training loss: 0.055704690515995026
epoch 97000  clean testing loss: 0.03097153641283512
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 97100  training loss: 0.055704522877931595
epoch 97100  clean testing loss: 0.030976468697190285
epoch 97200  training loss: 0.05570454150438309
epoch 97200  clean testing loss: 0.030976995825767517
epoch 97300  training loss: 0.05570449307560921
epoch 97300  clean testing loss: 0.03097301721572876
epoch 97400  training loss: 0.0557045079767704
epoch 97400  clean testing loss: 0.03097967430949211
epoch 97500  training loss: 0.05570431053638458
epoch 97500  clean testing loss: 0.030976401641964912
epoch 97600  training loss: 0.055704325437545776
epoch 97600  clean testing loss: 0.03097815066576004
epoch 97700  training loss: 0.055704329162836075

 99%|█████████▊| 98694/100000 [03:03<00:02, 545.34it/s]
epoch 97800  training loss: 0.05570420250296593
epoch 97800  clean testing loss: 0.030979126691818237
epoch 97900  training loss: 0.05570425093173981
epoch 97900  clean testing loss: 0.030982015654444695
epoch 98000  training loss: 0.05570413917303085
epoch 98000  clean testing loss: 0.030974268913269043
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 98100  training loss: 0.055704034864902496
epoch 98100  clean testing loss: 0.030982675030827522
epoch 98200  training loss: 0.05570404976606369
epoch 98200  clean testing loss: 0.030974343419075012
epoch 98300  training loss: 0.05570412054657936
epoch 98300  clean testing loss: 0.030983926728367805
epoch 98400  training loss: 0.0557040199637413
epoch 98400  clean testing loss: 0.030980370938777924
epoch 98500  training loss: 0.05570390075445175
epoch 98500  clean testing loss: 0.030981913208961487
epoch 98600  training loss: 0.05570383742451668
epoch 98600  clean testing loss: 0.030975982546806335
epoch 98700  training loss: 0.05570388212800026
epoch 98700  clean testing loss: 0.030979810282588005
epoch 98800  training loss: 0.0557037852704525

100%|█████████▉| 99796/100000 [03:05<00:00, 543.74it/s]
epoch 98900  training loss: 0.05570368468761444
epoch 98900  clean testing loss: 0.030980758368968964
epoch 99000  training loss: 0.055703822523355484
epoch 99000  clean testing loss: 0.030976461246609688
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...
epoch 99100  training loss: 0.055703576654195786
epoch 99100  clean testing loss: 0.030978109687566757
epoch 99200  training loss: 0.05570356920361519
epoch 99200  clean testing loss: 0.030980292707681656
epoch 99300  training loss: 0.055703528225421906
epoch 99300  clean testing loss: 0.030980097129940987
epoch 99400  training loss: 0.05570350959897041
epoch 99400  clean testing loss: 0.030978480353951454
epoch 99500  training loss: 0.05570341646671295
epoch 99500  clean testing loss: 0.03098183125257492
epoch 99600  training loss: 0.05570337548851967
epoch 99600  clean testing loss: 0.03097979538142681
epoch 99700  training loss: 0.0557032972574234
epoch 99700  clean testing loss: 0.030979832634329796
epoch 99800  training loss: 0.0557032972574234
epoch 99800  clean testing loss: 0.030981013551354408
epoch 99900  training loss: 0.05570332705974579

100%|██████████| 100000/100000 [03:06<00:00, 536.95it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise5.00e-02_invop0_lr0.005 ...