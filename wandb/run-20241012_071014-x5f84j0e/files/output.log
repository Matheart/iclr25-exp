
  0%|          | 19/100000 [00:01<1:50:42, 15.05it/s]
epoch 0  training loss: 49.82444763183594
epoch 0  clean testing loss: 42.20380401611328



  0%|          | 111/100000 [00:07<1:49:25, 15.21it/s]
epoch 100  training loss: 1.3474700450897217



  0%|          | 203/100000 [00:13<1:49:34, 15.18it/s]
epoch 200  training loss: 0.673490583896637



  0%|          | 295/100000 [00:19<1:49:05, 15.23it/s]
epoch 300  training loss: 0.427524209022522




  0%|          | 415/100000 [00:27<1:49:10, 15.20it/s]
epoch 400  training loss: 0.31039756536483765



  1%|          | 507/100000 [00:33<1:49:16, 15.18it/s]
epoch 500  training loss: 0.24124310910701752



  1%|          | 599/100000 [00:39<1:48:58, 15.20it/s]
epoch 600  training loss: 0.19700521230697632




  1%|          | 721/100000 [00:47<1:48:53, 15.20it/s]
epoch 700  training loss: 0.16863799095153809



  1%|          | 811/100000 [00:53<1:48:57, 15.17it/s]
epoch 800  training loss: 0.14964045584201813



  1%|          | 901/100000 [00:59<1:48:54, 15.17it/s]
epoch 900  training loss: 0.1364808976650238




  1%|          | 1023/100000 [01:07<1:48:38, 15.18it/s]
epoch 1000  training loss: 0.12719574570655823
epoch 1000  clean testing loss: 0.030413305386900902



  1%|          | 1115/100000 [01:13<1:48:35, 15.18it/s]
epoch 1100  training loss: 0.1204306110739708



  1%|          | 1205/100000 [01:19<1:48:53, 15.12it/s]
epoch 1200  training loss: 0.11550167948007584




  1%|▏         | 1327/100000 [01:27<1:48:25, 15.17it/s]
epoch 1300  training loss: 0.1119002178311348



  1%|▏         | 1419/100000 [01:33<1:48:15, 15.18it/s]
epoch 1400  training loss: 0.10925310105085373



  2%|▏         | 1509/100000 [01:39<1:48:29, 15.13it/s]
epoch 1500  training loss: 0.10728208720684052



  2%|▏         | 1601/100000 [01:45<1:48:17, 15.14it/s]
epoch 1600  training loss: 0.1057843267917633




  2%|▏         | 1721/100000 [01:53<1:48:00, 15.16it/s]
epoch 1700  training loss: 0.1046190857887268



  2%|▏         | 1813/100000 [01:59<1:48:04, 15.14it/s]
epoch 1800  training loss: 0.1036883294582367



  2%|▏         | 1903/100000 [02:05<1:47:55, 15.15it/s]
epoch 1900  training loss: 0.10293055325746536




  2%|▏         | 2025/100000 [02:13<1:47:33, 15.18it/s]
epoch 2000  training loss: 0.10231254994869232
epoch 2000  clean testing loss: 0.0054803756065666676



  2%|▏         | 2117/100000 [02:19<1:47:20, 15.20it/s]
epoch 2100  training loss: 0.10182362794876099



  2%|▏         | 2207/100000 [02:25<1:49:20, 14.91it/s]
epoch 2200  training loss: 0.10138765722513199




  2%|▏         | 2329/100000 [02:33<1:47:07, 15.20it/s]
epoch 2300  training loss: 0.10109731554985046



  2%|▏         | 2419/100000 [02:39<1:47:08, 15.18it/s]
epoch 2400  training loss: 0.10088729113340378



  3%|▎         | 2511/100000 [02:45<1:47:17, 15.14it/s]
epoch 2500  training loss: 0.10050792992115021



  3%|▎         | 2603/100000 [02:51<1:47:18, 15.13it/s]
epoch 2600  training loss: 0.10030771046876907




  3%|▎         | 2723/100000 [02:59<1:46:52, 15.17it/s]
epoch 2700  training loss: 0.10013660043478012



  3%|▎         | 2815/100000 [03:05<1:46:54, 15.15it/s]
epoch 2800  training loss: 0.09997837990522385



  3%|▎         | 2905/100000 [03:11<1:46:55, 15.13it/s]
epoch 2900  training loss: 0.09985233843326569




  3%|▎         | 3027/100000 [03:19<1:46:30, 15.18it/s]
epoch 3000  training loss: 0.09972932934761047
epoch 3000  clean testing loss: 0.002326978137716651



  3%|▎         | 3117/100000 [03:25<1:49:37, 14.73it/s]
epoch 3100  training loss: 0.09964242577552795



  3%|▎         | 3209/100000 [03:31<1:46:22, 15.17it/s]
epoch 3200  training loss: 0.09956087172031403




  3%|▎         | 3331/100000 [03:39<1:46:26, 15.14it/s]
epoch 3300  training loss: 0.09948411583900452



  3%|▎         | 3421/100000 [03:45<1:46:14, 15.15it/s]
epoch 3400  training loss: 0.09941218048334122



  4%|▎         | 3513/100000 [03:51<1:46:03, 15.16it/s]
epoch 3500  training loss: 0.09935590624809265



  4%|▎         | 3603/100000 [03:57<1:46:16, 15.12it/s]
epoch 3600  training loss: 0.09929123520851135




  4%|▎         | 3725/100000 [04:05<1:45:54, 15.15it/s]
epoch 3700  training loss: 0.09923486411571503



  4%|▍         | 3815/100000 [04:11<1:45:43, 15.16it/s]
epoch 3800  training loss: 0.09918905794620514



  4%|▍         | 3907/100000 [04:17<1:45:49, 15.13it/s]
epoch 3900  training loss: 0.09913842380046844




  4%|▍         | 4027/100000 [04:25<1:50:35, 14.46it/s]
epoch 4000  training loss: 0.10039346665143967
epoch 4000  clean testing loss: 0.002341459272429347



  4%|▍         | 4119/100000 [04:32<1:45:20, 15.17it/s]
epoch 4100  training loss: 0.09905397891998291



  4%|▍         | 4209/100000 [04:37<1:45:21, 15.15it/s]
epoch 4200  training loss: 0.09916464239358902



  4%|▍         | 4301/100000 [04:44<1:45:18, 15.15it/s]
epoch 4300  training loss: 0.09897971898317337




  4%|▍         | 4423/100000 [04:52<1:45:03, 15.16it/s]
epoch 4400  training loss: 0.09894417226314545



  5%|▍         | 4513/100000 [04:58<1:45:02, 15.15it/s]
epoch 4500  training loss: 0.09943791478872299



  5%|▍         | 4603/100000 [05:04<1:45:11, 15.12it/s]
epoch 4600  training loss: 0.0988818034529686




  5%|▍         | 4725/100000 [05:12<1:44:39, 15.17it/s]
epoch 4700  training loss: 0.09984594583511353



  5%|▍         | 4817/100000 [05:18<1:44:37, 15.16it/s]
epoch 4800  training loss: 0.09882443398237228



  5%|▍         | 4907/100000 [05:24<1:44:42, 15.14it/s]
epoch 4900  training loss: 0.09879596531391144




  5%|▌         | 5029/100000 [05:32<1:44:21, 15.17it/s]
epoch 5000  training loss: 0.09877467900514603
epoch 5000  clean testing loss: 0.0014024850679561496



  5%|▌         | 5119/100000 [05:38<1:44:16, 15.17it/s]
epoch 5100  training loss: 0.09877150505781174



  5%|▌         | 5211/100000 [05:44<1:44:12, 15.16it/s]
epoch 5200  training loss: 0.09872390329837799



  5%|▌         | 5301/100000 [05:50<1:44:11, 15.15it/s]
epoch 5300  training loss: 0.09872079640626907




  5%|▌         | 5423/100000 [05:58<1:43:58, 15.16it/s]
epoch 5400  training loss: 0.09868045896291733



  6%|▌         | 5513/100000 [06:04<1:43:53, 15.16it/s]
epoch 5500  training loss: 0.09868570417165756



  6%|▌         | 5605/100000 [06:10<1:44:05, 15.11it/s]
epoch 5600  training loss: 0.09864258766174316




  6%|▌         | 5727/100000 [06:18<1:43:38, 15.16it/s]
epoch 5700  training loss: 0.10218501091003418



  6%|▌         | 5817/100000 [06:24<1:43:28, 15.17it/s]
epoch 5800  training loss: 0.09860628098249435



  6%|▌         | 5907/100000 [06:30<1:43:24, 15.17it/s]
epoch 5900  training loss: 0.09858822822570801




  6%|▌         | 6029/100000 [06:38<1:43:03, 15.20it/s]
epoch 6000  training loss: 0.09868089109659195
epoch 6000  clean testing loss: 0.0013853965792804956



  6%|▌         | 6121/100000 [06:44<1:43:03, 15.18it/s]
epoch 6100  training loss: 0.09855975955724716



  6%|▌         | 6211/100000 [06:50<1:42:57, 15.18it/s]
epoch 6200  training loss: 0.0985458493232727



  6%|▋         | 6303/100000 [06:56<1:43:11, 15.13it/s]
epoch 6300  training loss: 0.09853240847587585




  6%|▋         | 6425/100000 [07:04<1:42:37, 15.20it/s]
epoch 6400  training loss: 0.09851907193660736



  7%|▋         | 6515/100000 [07:10<1:42:32, 15.19it/s]
epoch 6500  training loss: 0.09850601851940155



  7%|▋         | 6607/100000 [07:16<1:42:32, 15.18it/s]
epoch 6600  training loss: 0.09852657467126846




  7%|▋         | 6729/100000 [07:24<1:42:11, 15.21it/s]
epoch 6700  training loss: 0.09848251938819885



  7%|▋         | 6819/100000 [07:30<1:42:08, 15.20it/s]
epoch 6800  training loss: 0.09873780608177185



  7%|▋         | 6911/100000 [07:36<1:42:01, 15.21it/s]
epoch 6900  training loss: 0.1097186878323555



  7%|▋         | 7003/100000 [07:42<1:43:06, 15.03it/s]
epoch 7000  training loss: 0.09845096617937088
epoch 7000  clean testing loss: 0.0012837770627811551




  7%|▋         | 7125/100000 [07:50<1:41:54, 15.19it/s]
epoch 7100  training loss: 0.09843969345092773



  7%|▋         | 7215/100000 [07:56<1:41:45, 15.20it/s]
epoch 7200  training loss: 0.10074218362569809



  7%|▋         | 7299/100000 [08:01<1:41:34, 15.21it/s]
epoch 7300  training loss: 0.09842216223478317




  7%|▋         | 7421/100000 [08:09<1:41:31, 15.20it/s]
epoch 7400  training loss: 0.0985012799501419



  8%|▊         | 7511/100000 [08:15<1:41:25, 15.20it/s]
epoch 7500  training loss: 0.09840422123670578



  8%|▊         | 7603/100000 [08:21<1:41:34, 15.16it/s]
epoch 7600  training loss: 0.09844841808080673



  8%|▊         | 7693/100000 [08:27<1:42:10, 15.06it/s]
epoch 7700  training loss: 0.09838912636041641




  8%|▊         | 7815/100000 [08:35<1:40:59, 15.21it/s]
epoch 7800  training loss: 0.09843127429485321



  8%|▊         | 7907/100000 [08:42<1:41:00, 15.20it/s]
epoch 7900  training loss: 0.09837370365858078



  8%|▊         | 7999/100000 [08:48<1:40:39, 15.23it/s]
epoch 8000  training loss: 0.09839878976345062
epoch 8000  clean testing loss: 0.0012852060608565807




  8%|▊         | 8121/100000 [08:56<1:40:38, 15.22it/s]
epoch 8100  training loss: 0.09852055460214615



  8%|▊         | 8211/100000 [09:02<1:40:35, 15.21it/s]
epoch 8200  training loss: 0.09835439175367355



  8%|▊         | 8303/100000 [09:08<1:40:46, 15.17it/s]
epoch 8300  training loss: 0.09835272282361984



  8%|▊         | 8395/100000 [09:14<1:40:21, 15.21it/s]
epoch 8400  training loss: 0.09836412966251373




  9%|▊         | 8517/100000 [09:22<1:40:12, 15.22it/s]
epoch 8500  training loss: 0.09833792597055435



  9%|▊         | 8607/100000 [09:28<1:41:31, 15.00it/s]
epoch 8600  training loss: 0.09833681583404541



  9%|▊         | 8699/100000 [09:34<1:40:00, 15.22it/s]
epoch 8700  training loss: 0.09867050498723984




  9%|▉         | 8821/100000 [09:42<1:39:51, 15.22it/s]
epoch 8800  training loss: 0.0985528901219368



  9%|▉         | 8911/100000 [09:48<1:39:50, 15.21it/s]
epoch 8900  training loss: 0.09880850464105606



  9%|▉         | 9003/100000 [09:54<1:40:47, 15.05it/s]
epoch 9000  training loss: 0.09830901771783829
epoch 9000  clean testing loss: 0.001303872442804277



  9%|▉         | 9093/100000 [10:00<1:39:31, 15.22it/s]
epoch 9100  training loss: 0.09830459207296371




  9%|▉         | 9215/100000 [10:08<1:39:32, 15.20it/s]
epoch 9200  training loss: 0.09829980134963989



  9%|▉         | 9307/100000 [10:14<1:39:29, 15.19it/s]
epoch 9300  training loss: 0.09829500317573547



  9%|▉         | 9399/100000 [10:20<1:39:16, 15.21it/s]
epoch 9400  training loss: 0.09829002618789673




 10%|▉         | 9519/100000 [10:28<1:40:55, 14.94it/s]
epoch 9500  training loss: 0.0989517942070961



 10%|▉         | 9611/100000 [10:34<1:39:06, 15.20it/s]
epoch 9600  training loss: 0.09829911589622498



 10%|▉         | 9703/100000 [10:40<1:39:23, 15.14it/s]
epoch 9700  training loss: 0.0993879958987236




 10%|▉         | 9825/100000 [10:48<1:38:50, 15.20it/s]
epoch 9800  training loss: 0.09837434440851212



 10%|▉         | 9915/100000 [10:54<1:38:44, 15.21it/s]
epoch 9900  training loss: 0.0982685536146164



 10%|█         | 10007/100000 [11:00<1:39:03, 15.14it/s]
epoch 10000  training loss: 0.09830262511968613
epoch 10000  clean testing loss: 0.0013311890652403235




 10%|█         | 10129/100000 [11:08<1:38:25, 15.22it/s]
epoch 10100  training loss: 0.09826178848743439



 10%|█         | 10219/100000 [11:14<1:38:24, 15.21it/s]
epoch 10200  training loss: 0.09899526089429855



 10%|█         | 10311/100000 [11:20<1:38:18, 15.21it/s]
epoch 10300  training loss: 0.09825138002634048



 10%|█         | 10403/100000 [11:26<1:38:28, 15.16it/s]
epoch 10400  training loss: 0.09824961423873901




 11%|█         | 10523/100000 [11:34<1:38:01, 15.21it/s]
epoch 10500  training loss: 0.09829521924257278



 11%|█         | 10615/100000 [11:40<1:38:15, 15.16it/s]
epoch 10600  training loss: 0.09823861718177795



 11%|█         | 10707/100000 [11:46<1:38:08, 15.16it/s]
epoch 10700  training loss: 0.0982368141412735




 11%|█         | 10827/100000 [11:54<1:37:51, 15.19it/s]
epoch 10800  training loss: 0.09824231266975403



 11%|█         | 10919/100000 [12:00<1:37:48, 15.18it/s]
epoch 10900  training loss: 0.09831780195236206



 11%|█         | 11009/100000 [12:06<1:38:09, 15.11it/s]
epoch 11000  training loss: 0.0982573926448822
epoch 11000  clean testing loss: 0.0014046989381313324



 11%|█         | 11101/100000 [12:12<1:37:36, 15.18it/s]
epoch 11100  training loss: 0.09825807064771652




 11%|█         | 11223/100000 [12:20<1:37:30, 15.17it/s]
epoch 11200  training loss: 0.10160248726606369



 11%|█▏        | 11313/100000 [12:26<1:37:31, 15.16it/s]
epoch 11300  training loss: 0.09820935875177383



 11%|█▏        | 11405/100000 [12:32<1:37:39, 15.12it/s]
epoch 11400  training loss: 0.09820518642663956




 12%|█▏        | 11527/100000 [12:40<1:37:17, 15.16it/s]
epoch 11500  training loss: 0.09820204228162766



 12%|█▏        | 11617/100000 [12:46<1:36:55, 15.20it/s]
epoch 11600  training loss: 0.09820196777582169



 12%|█▏        | 11709/100000 [12:52<1:37:02, 15.16it/s]
epoch 11700  training loss: 0.09958301484584808




 12%|█▏        | 11831/100000 [13:00<1:36:30, 15.23it/s]
epoch 11800  training loss: 0.09818809479475021



 12%|█▏        | 11921/100000 [13:06<1:36:42, 15.18it/s]
epoch 11900  training loss: 0.09819794446229935



 12%|█▏        | 12013/100000 [13:12<1:36:59, 15.12it/s]
epoch 12000  training loss: 0.09818776696920395
epoch 12000  clean testing loss: 0.0013775156112387776



 12%|█▏        | 12105/100000 [13:18<1:36:49, 15.13it/s]
epoch 12100  training loss: 0.09817622601985931




 12%|█▏        | 12225/100000 [13:26<1:36:25, 15.17it/s]
epoch 12200  training loss: 0.09817229956388474



 12%|█▏        | 12317/100000 [13:32<1:36:25, 15.16it/s]
epoch 12300  training loss: 0.09816829860210419



 12%|█▏        | 12407/100000 [13:38<1:36:27, 15.13it/s]
epoch 12400  training loss: 0.09816394746303558




 13%|█▎        | 12529/100000 [13:46<1:36:15, 15.15it/s]
epoch 12500  training loss: 0.09850939363241196



 13%|█▎        | 12621/100000 [13:52<1:36:20, 15.12it/s]
epoch 12600  training loss: 0.0981556847691536



 13%|█▎        | 12709/100000 [13:58<1:36:03, 15.14it/s]
epoch 12700  training loss: 0.09817984700202942



 13%|█▎        | 12801/100000 [14:04<1:36:02, 15.13it/s]
epoch 12800  training loss: 0.09874699264764786




 13%|█▎        | 12923/100000 [14:12<1:35:49, 15.15it/s]
epoch 12900  training loss: 0.09814329445362091



 13%|█▎        | 13015/100000 [14:18<1:35:41, 15.15it/s]
epoch 13000  training loss: 0.09815279394388199
epoch 13000  clean testing loss: 0.0014210151275619864



 13%|█▎        | 13105/100000 [14:24<1:35:45, 15.13it/s]
epoch 13100  training loss: 0.09813627600669861




 13%|█▎        | 13227/100000 [14:32<1:35:24, 15.16it/s]
epoch 13200  training loss: 0.09829208999872208



 13%|█▎        | 13317/100000 [14:38<1:35:20, 15.15it/s]
epoch 13300  training loss: 0.09812676906585693



 13%|█▎        | 13409/100000 [14:44<1:35:32, 15.11it/s]
epoch 13400  training loss: 0.09812592715024948




 14%|█▎        | 13529/100000 [14:52<1:35:03, 15.16it/s]
epoch 13500  training loss: 0.09822409600019455



 14%|█▎        | 13621/100000 [14:58<1:34:58, 15.16it/s]
epoch 13600  training loss: 0.09833802282810211



 14%|█▎        | 13711/100000 [15:04<1:34:55, 15.15it/s]
epoch 13700  training loss: 0.09811276942491531



 14%|█▍        | 13803/100000 [15:10<1:35:04, 15.11it/s]
epoch 13800  training loss: 0.09810861200094223




 14%|█▍        | 13925/100000 [15:18<1:34:37, 15.16it/s]
epoch 13900  training loss: 0.09813029319047928



 14%|█▍        | 14015/100000 [15:24<1:34:35, 15.15it/s]
epoch 14000  training loss: 0.09810598194599152
epoch 14000  clean testing loss: 0.0014394576428458095



 14%|█▍        | 14099/100000 [15:30<1:35:12, 15.04it/s]
epoch 14100  training loss: 0.09811195731163025




 14%|█▍        | 14219/100000 [15:38<1:34:19, 15.16it/s]
epoch 14200  training loss: 0.09814614057540894



 14%|█▍        | 14311/100000 [15:44<1:34:24, 15.13it/s]
epoch 14300  training loss: 0.09809155017137527



 14%|█▍        | 14401/100000 [15:50<1:34:12, 15.14it/s]
epoch 14400  training loss: 0.09809153527021408



 14%|█▍        | 14493/100000 [15:56<1:33:58, 15.16it/s]
epoch 14500  training loss: 0.09808596968650818




 15%|█▍        | 14613/100000 [16:04<1:33:56, 15.15it/s]
epoch 14600  training loss: 0.09809213876724243



 15%|█▍        | 14705/100000 [16:10<1:33:59, 15.12it/s]
epoch 14700  training loss: 0.09809236973524094



 15%|█▍        | 14795/100000 [16:16<1:33:38, 15.17it/s]
epoch 14800  training loss: 0.09818631410598755




 15%|█▍        | 14917/100000 [16:24<1:33:35, 15.15it/s]
epoch 14900  training loss: 0.09810145199298859



 15%|█▌        | 15007/100000 [16:30<1:36:22, 14.70it/s]
epoch 15000  training loss: 0.09808499366044998
epoch 15000  clean testing loss: 0.0014872733736410737



 15%|█▌        | 15099/100000 [16:36<1:33:27, 15.14it/s]
epoch 15100  training loss: 0.09807034581899643




 15%|█▌        | 15221/100000 [16:44<1:33:14, 15.15it/s]
epoch 15200  training loss: 0.09806828200817108



 15%|█▌        | 15311/100000 [16:50<1:33:11, 15.15it/s]
epoch 15300  training loss: 0.09806608408689499



 15%|█▌        | 15403/100000 [16:56<1:33:20, 15.11it/s]
epoch 15400  training loss: 0.09806384146213531



 15%|█▌        | 15493/100000 [17:02<1:32:45, 15.18it/s]
epoch 15500  training loss: 0.09808097034692764




 16%|█▌        | 15615/100000 [17:10<1:32:45, 15.16it/s]
epoch 15600  training loss: 0.09810023009777069



 16%|█▌        | 15705/100000 [17:16<1:32:44, 15.15it/s]
epoch 15700  training loss: 0.0987941101193428



 16%|█▌        | 15797/100000 [17:22<1:32:24, 15.19it/s]
epoch 15800  training loss: 0.09817778319120407




 16%|█▌        | 15919/100000 [17:30<1:35:23, 14.69it/s]
epoch 15900  training loss: 0.09805632382631302



 16%|█▌        | 16009/100000 [17:36<1:32:34, 15.12it/s]
epoch 16000  training loss: 0.09805381298065186
epoch 16000  clean testing loss: 0.0015036945696920156



 16%|█▌        | 16101/100000 [17:42<1:32:09, 15.17it/s]
epoch 16100  training loss: 0.09805519878864288




 16%|█▌        | 16223/100000 [17:50<1:31:39, 15.23it/s]
epoch 16200  training loss: 0.09807517379522324



 16%|█▋        | 16313/100000 [17:56<1:31:48, 15.19it/s]
epoch 16300  training loss: 0.09805545210838318



 16%|█▋        | 16405/100000 [18:02<1:32:07, 15.12it/s]
epoch 16400  training loss: 0.09804613888263702




 17%|█▋        | 16525/100000 [18:10<1:31:38, 15.18it/s]
epoch 16500  training loss: 0.0980551689863205



 17%|█▋        | 16617/100000 [18:16<1:31:28, 15.19it/s]
epoch 16600  training loss: 0.09804214537143707



 17%|█▋        | 16709/100000 [18:22<1:31:27, 15.18it/s]
epoch 16700  training loss: 0.0980568453669548




 17%|█▋        | 16829/100000 [18:30<1:35:14, 14.55it/s]
epoch 16800  training loss: 0.0981987863779068



 17%|█▋        | 16921/100000 [18:36<1:31:06, 15.20it/s]
epoch 16900  training loss: 0.09815388172864914



 17%|█▋        | 17013/100000 [18:42<1:31:15, 15.16it/s]
epoch 17000  training loss: 0.09816885739564896
epoch 17000  clean testing loss: 0.0015969647793099284



 17%|█▋        | 17103/100000 [18:48<1:31:22, 15.12it/s]
epoch 17100  training loss: 0.09805378317832947




 17%|█▋        | 17225/100000 [18:56<1:30:45, 15.20it/s]
epoch 17200  training loss: 0.09808214753866196



 17%|█▋        | 17317/100000 [19:02<1:30:44, 15.19it/s]
epoch 17300  training loss: 0.09846054762601852



 17%|█▋        | 17407/100000 [19:08<1:30:45, 15.17it/s]
epoch 17400  training loss: 0.09803009778261185




 18%|█▊        | 17529/100000 [19:16<1:30:30, 15.19it/s]
epoch 17500  training loss: 0.0980353131890297



 18%|█▊        | 17621/100000 [19:22<1:30:27, 15.18it/s]
epoch 17600  training loss: 0.09848844259977341



 18%|█▊        | 17711/100000 [19:28<1:30:34, 15.14it/s]
epoch 17700  training loss: 0.09825582057237625



 18%|█▊        | 17803/100000 [19:34<1:30:25, 15.15it/s]
epoch 17800  training loss: 0.09802531450986862




 18%|█▊        | 17925/100000 [19:43<1:30:02, 15.19it/s]
epoch 17900  training loss: 0.09802397340536118



 18%|█▊        | 18015/100000 [19:48<1:30:08, 15.16it/s]
epoch 18000  training loss: 0.09802887588739395
epoch 18000  clean testing loss: 0.0015376547817140818



 18%|█▊        | 18107/100000 [19:54<1:30:01, 15.16it/s]
epoch 18100  training loss: 0.09802163392305374




 18%|█▊        | 18229/100000 [20:03<1:29:44, 15.19it/s]
epoch 18200  training loss: 0.09802061319351196



 18%|█▊        | 18319/100000 [20:08<1:29:31, 15.21it/s]
epoch 18300  training loss: 0.09801929444074631



 18%|█▊        | 18411/100000 [20:15<1:29:32, 15.19it/s]
epoch 18400  training loss: 0.09801826626062393



 19%|█▊        | 18503/100000 [20:21<1:29:49, 15.12it/s]
epoch 18500  training loss: 0.09812872856855392




 19%|█▊        | 18623/100000 [20:28<1:29:15, 15.19it/s]
epoch 18600  training loss: 0.09807602316141129



 19%|█▊        | 18715/100000 [20:35<1:29:12, 15.19it/s]
epoch 18700  training loss: 0.09801478683948517



 19%|█▉        | 18805/100000 [20:41<1:29:21, 15.14it/s]
epoch 18800  training loss: 0.09801442921161652




 19%|█▉        | 18927/100000 [20:49<1:28:57, 15.19it/s]
epoch 18900  training loss: 0.09801357239484787



 19%|█▉        | 19019/100000 [20:55<1:28:49, 15.19it/s]
epoch 19000  training loss: 0.09801145642995834
epoch 19000  clean testing loss: 0.0015442068688571453



 19%|█▉        | 19111/100000 [21:01<1:28:41, 15.20it/s]
epoch 19100  training loss: 0.09801539778709412




 19%|█▉        | 19231/100000 [21:09<1:28:32, 15.20it/s]
epoch 19200  training loss: 0.09801547974348068



 19%|█▉        | 19323/100000 [21:15<1:28:26, 15.20it/s]
epoch 19300  training loss: 0.09801041334867477



 19%|█▉        | 19415/100000 [21:21<1:28:19, 15.21it/s]
epoch 19400  training loss: 0.09800772368907928



 20%|█▉        | 19505/100000 [21:27<1:28:27, 15.17it/s]
epoch 19500  training loss: 0.09800861030817032




 20%|█▉        | 19627/100000 [21:35<1:28:10, 15.19it/s]
epoch 19600  training loss: 0.09800617396831512



 20%|█▉        | 19719/100000 [21:41<1:28:03, 15.19it/s]
epoch 19700  training loss: 0.098004549741745



 20%|█▉        | 19809/100000 [21:47<1:28:07, 15.17it/s]
epoch 19800  training loss: 0.09801673144102097




 20%|█▉        | 19931/100000 [21:55<1:27:51, 15.19it/s]
epoch 19900  training loss: 0.09801939874887466



 20%|██        | 20023/100000 [22:01<1:27:44, 15.19it/s]
epoch 20000  training loss: 0.09800191223621368
epoch 20000  clean testing loss: 0.0015559670282527804



 20%|██        | 20113/100000 [22:07<1:27:46, 15.17it/s]
epoch 20100  training loss: 0.09800230711698532



 20%|██        | 20205/100000 [22:13<1:27:46, 15.15it/s]
epoch 20200  training loss: 0.09800683706998825




 20%|██        | 20327/100000 [22:21<1:27:28, 15.18it/s]
epoch 20300  training loss: 0.09819702804088593



 20%|██        | 20417/100000 [22:27<1:27:33, 15.15it/s]
epoch 20400  training loss: 0.09799684584140778



 21%|██        | 20507/100000 [22:33<1:27:40, 15.11it/s]
epoch 20500  training loss: 0.09800022095441818




 21%|██        | 20629/100000 [22:41<1:27:06, 15.19it/s]
epoch 20600  training loss: 0.09843751788139343



 21%|██        | 20713/100000 [22:46<1:27:07, 15.17it/s]
epoch 20700  training loss: 0.09799397736787796



 21%|██        | 20805/100000 [22:52<1:27:15, 15.13it/s]
epoch 20800  training loss: 0.09799309819936752




 21%|██        | 20925/100000 [23:00<1:26:51, 15.17it/s]
epoch 20900  training loss: 0.09799303114414215



 21%|██        | 21017/100000 [23:06<1:26:49, 15.16it/s]
epoch 21000  training loss: 0.09841961413621902
epoch 21000  clean testing loss: 0.001700389664620161



 21%|██        | 21107/100000 [23:12<1:26:52, 15.13it/s]
epoch 21100  training loss: 0.09799038618803024



 21%|██        | 21199/100000 [23:18<1:26:34, 15.17it/s]
epoch 21200  training loss: 0.09798961877822876




 21%|██▏       | 21321/100000 [23:26<1:26:28, 15.16it/s]
epoch 21300  training loss: 0.09798881411552429



 21%|██▏       | 21411/100000 [23:32<1:27:37, 14.95it/s]
epoch 21400  training loss: 0.09798789769411087



 22%|██▏       | 21501/100000 [23:38<1:26:18, 15.16it/s]
epoch 21500  training loss: 0.09798696637153625




 22%|██▏       | 21623/100000 [23:46<1:26:06, 15.17it/s]
epoch 21600  training loss: 0.09798908233642578



 22%|██▏       | 21715/100000 [23:52<1:25:52, 15.19it/s]
epoch 21700  training loss: 0.09799531102180481



 22%|██▏       | 21807/100000 [23:59<1:25:58, 15.16it/s]
epoch 21800  training loss: 0.09798397868871689




 22%|██▏       | 21927/100000 [24:07<1:25:38, 15.19it/s]
epoch 21900  training loss: 0.09798332303762436



 22%|██▏       | 22019/100000 [24:13<1:25:38, 15.18it/s]
epoch 22000  training loss: 0.09807489812374115
epoch 22000  clean testing loss: 0.0015955823473632336



 22%|██▏       | 22109/100000 [24:18<1:25:30, 15.18it/s]
epoch 22100  training loss: 0.09806634485721588



 22%|██▏       | 22201/100000 [24:25<1:25:21, 15.19it/s]
epoch 22200  training loss: 0.09798043221235275




 22%|██▏       | 22323/100000 [24:33<1:27:46, 14.75it/s]
epoch 22300  training loss: 0.098255455493927



 22%|██▏       | 22413/100000 [24:39<1:25:11, 15.18it/s]
epoch 22400  training loss: 0.09798101335763931



 23%|██▎       | 22505/100000 [24:45<1:25:10, 15.16it/s]
epoch 22500  training loss: 0.09797773510217667




 23%|██▎       | 22627/100000 [24:53<1:24:51, 15.20it/s]
epoch 22600  training loss: 0.09798514097929001



 23%|██▎       | 22717/100000 [24:59<1:24:52, 15.17it/s]
epoch 22700  training loss: 0.09797587990760803



 23%|██▎       | 22809/100000 [25:05<1:24:49, 15.17it/s]
epoch 22800  training loss: 0.09797593951225281



 23%|██▎       | 22901/100000 [25:11<1:24:37, 15.18it/s]
epoch 22900  training loss: 0.09797496348619461




 23%|██▎       | 23021/100000 [25:19<1:24:29, 15.18it/s]
epoch 23000  training loss: 0.09797497093677521
epoch 23000  clean testing loss: 0.0015831500058993697



 23%|██▎       | 23113/100000 [25:25<1:24:30, 15.16it/s]
epoch 23100  training loss: 0.09797762334346771



 23%|██▎       | 23205/100000 [25:31<1:24:35, 15.13it/s]
epoch 23200  training loss: 0.09798883646726608




 23%|██▎       | 23325/100000 [25:39<1:24:17, 15.16it/s]
epoch 23300  training loss: 0.09803733229637146



 23%|██▎       | 23417/100000 [25:45<1:24:10, 15.16it/s]
epoch 23400  training loss: 0.09796963632106781



 24%|██▎       | 23507/100000 [25:51<1:24:10, 15.15it/s]
epoch 23500  training loss: 0.09796905517578125




 24%|██▎       | 23629/100000 [25:59<1:23:56, 15.16it/s]
epoch 23600  training loss: 0.0980655699968338



 24%|██▎       | 23719/100000 [26:05<1:24:40, 15.01it/s]
epoch 23700  training loss: 0.09796729683876038



 24%|██▍       | 23811/100000 [26:11<1:23:43, 15.17it/s]
epoch 23800  training loss: 0.09796854853630066



 24%|██▍       | 23903/100000 [26:17<1:23:55, 15.11it/s]
epoch 23900  training loss: 0.09796545654535294




 24%|██▍       | 24023/100000 [26:25<1:23:29, 15.17it/s]
epoch 24000  training loss: 0.09796470403671265
epoch 24000  clean testing loss: 0.0015868698246777058



 24%|██▍       | 24115/100000 [26:31<1:23:22, 15.17it/s]
epoch 24100  training loss: 0.09796370565891266



 24%|██▍       | 24205/100000 [26:37<1:23:38, 15.10it/s]
epoch 24200  training loss: 0.09796305000782013




 24%|██▍       | 24327/100000 [26:45<1:23:08, 15.17it/s]
epoch 24300  training loss: 0.09796223789453506



 24%|██▍       | 24419/100000 [26:51<1:23:03, 15.17it/s]
epoch 24400  training loss: 0.09796138852834702



 25%|██▍       | 24509/100000 [26:57<1:23:05, 15.14it/s]
epoch 24500  training loss: 0.09796109795570374




 25%|██▍       | 24631/100000 [27:05<1:22:51, 15.16it/s]
epoch 24600  training loss: 0.09796012938022614



 25%|██▍       | 24721/100000 [27:11<1:22:46, 15.16it/s]
epoch 24700  training loss: 0.09795887023210526



 25%|██▍       | 24813/100000 [27:17<1:22:41, 15.15it/s]
epoch 24800  training loss: 0.0980449691414833



 25%|██▍       | 24903/100000 [27:23<1:22:51, 15.11it/s]
epoch 24900  training loss: 0.09795715659856796




 25%|██▌       | 25025/100000 [27:31<1:22:25, 15.16it/s]
epoch 25000  training loss: 0.09795626997947693
epoch 25000  clean testing loss: 0.0015942180762067437



 25%|██▌       | 25115/100000 [27:37<1:22:19, 15.16it/s]
epoch 25100  training loss: 0.09795688837766647



 25%|██▌       | 25207/100000 [27:43<1:22:21, 15.14it/s]
epoch 25200  training loss: 0.09795455634593964




 25%|██▌       | 25329/100000 [27:51<1:22:13, 15.13it/s]
epoch 25300  training loss: 0.09795533120632172



 25%|██▌       | 25419/100000 [27:57<1:21:59, 15.16it/s]
epoch 25400  training loss: 0.09795309603214264



 26%|██▌       | 25509/100000 [28:03<1:21:59, 15.14it/s]
epoch 25500  training loss: 0.09795314073562622



 26%|██▌       | 25601/100000 [28:09<1:21:51, 15.15it/s]
epoch 25600  training loss: 0.0979510247707367




 26%|██▌       | 25723/100000 [28:17<1:21:38, 15.16it/s]
epoch 25700  training loss: 0.09795135259628296



 26%|██▌       | 25813/100000 [28:23<1:21:34, 15.16it/s]
epoch 25800  training loss: 0.09795238822698593



 26%|██▌       | 25905/100000 [28:29<1:21:40, 15.12it/s]
epoch 25900  training loss: 0.09794867038726807




 26%|██▌       | 26025/100000 [28:37<1:21:20, 15.16it/s]
epoch 26000  training loss: 0.09794815629720688
epoch 26000  clean testing loss: 0.001605384168215096



 26%|██▌       | 26117/100000 [28:43<1:21:10, 15.17it/s]
epoch 26100  training loss: 0.09794705361127853



 26%|██▌       | 26207/100000 [28:49<1:21:12, 15.14it/s]
epoch 26200  training loss: 0.0980810672044754




 26%|██▋       | 26329/100000 [28:57<1:20:57, 15.17it/s]
epoch 26300  training loss: 0.09794540703296661



 26%|██▋       | 26421/100000 [29:03<1:20:54, 15.16it/s]
epoch 26400  training loss: 0.09794487059116364



 27%|██▋       | 26511/100000 [29:09<1:21:21, 15.05it/s]
epoch 26500  training loss: 0.09794600307941437



 27%|██▋       | 26601/100000 [29:15<1:20:43, 15.16it/s]
epoch 26600  training loss: 0.09804940223693848




 27%|██▋       | 26723/100000 [29:23<1:20:31, 15.17it/s]
epoch 26700  training loss: 0.09794194996356964



 27%|██▋       | 26815/100000 [29:29<1:20:16, 15.20it/s]
epoch 26800  training loss: 0.09802871197462082



 27%|██▋       | 26905/100000 [29:35<1:20:56, 15.05it/s]
epoch 26900  training loss: 0.09807775914669037




 27%|██▋       | 27027/100000 [29:43<1:19:47, 15.24it/s]
epoch 27000  training loss: 0.09801743179559708
epoch 27000  clean testing loss: 0.0016415920108556747



 27%|██▋       | 27117/100000 [29:49<1:20:02, 15.17it/s]
epoch 27100  training loss: 0.0979389101266861



 27%|██▋       | 27209/100000 [29:55<1:20:06, 15.14it/s]
epoch 27200  training loss: 0.09793827682733536



 27%|██▋       | 27299/100000 [30:01<1:19:55, 15.16it/s]
epoch 27300  training loss: 0.09793736040592194




 27%|██▋       | 27413/100000 [30:09<1:19:54, 15.14it/s]
epoch 27400  training loss: 0.0979364812374115



 28%|██▊       | 27505/100000 [30:15<1:20:03, 15.09it/s]
epoch 27500  training loss: 0.09804234653711319



 28%|██▊       | 27595/100000 [30:21<1:19:36, 15.16it/s]
epoch 27600  training loss: 0.09793483465909958




 28%|██▊       | 27717/100000 [30:29<1:19:28, 15.16it/s]
epoch 27700  training loss: 0.09793443232774734



 28%|██▊       | 27807/100000 [30:35<1:21:33, 14.75it/s]
epoch 27800  training loss: 0.09796538949012756



 28%|██▊       | 27899/100000 [30:41<1:19:16, 15.16it/s]
epoch 27900  training loss: 0.09793245047330856




 28%|██▊       | 28021/100000 [30:49<1:19:08, 15.16it/s]
epoch 28000  training loss: 0.09798488765954971
epoch 28000  clean testing loss: 0.0016482211649417877



 28%|██▊       | 28111/100000 [30:55<1:19:05, 15.15it/s]
epoch 28100  training loss: 0.09793835133314133



 28%|██▊       | 28203/100000 [31:01<1:19:05, 15.13it/s]
epoch 28200  training loss: 0.09793207794427872



 28%|██▊       | 28293/100000 [31:07<1:18:35, 15.21it/s]
epoch 28300  training loss: 0.09804484248161316




 28%|██▊       | 28415/100000 [31:15<1:18:36, 15.18it/s]
epoch 28400  training loss: 0.09796122461557388



 29%|██▊       | 28507/100000 [31:21<1:18:34, 15.17it/s]
epoch 28500  training loss: 0.09793033450841904



 29%|██▊       | 28599/100000 [31:27<1:18:17, 15.20it/s]
epoch 28600  training loss: 0.09793068468570709




 29%|██▊       | 28719/100000 [31:35<1:22:57, 14.32it/s]
epoch 28700  training loss: 0.09793063998222351



 29%|██▉       | 28811/100000 [31:41<1:18:11, 15.18it/s]
epoch 28800  training loss: 0.09811105579137802



 29%|██▉       | 28901/100000 [31:47<1:18:03, 15.18it/s]
epoch 28900  training loss: 0.09805608540773392



 29%|██▉       | 28993/100000 [31:53<1:17:53, 15.19it/s]
epoch 29000  training loss: 0.09801241755485535
epoch 29000  clean testing loss: 0.0016988316783681512




 29%|██▉       | 29115/100000 [32:01<1:17:44, 15.20it/s]
epoch 29100  training loss: 0.09792299568653107



 29%|██▉       | 29205/100000 [32:07<1:18:02, 15.12it/s]
epoch 29200  training loss: 0.09792184084653854



 29%|██▉       | 29297/100000 [32:13<1:17:32, 15.20it/s]
epoch 29300  training loss: 0.09792378544807434




 29%|██▉       | 29419/100000 [32:21<1:17:24, 15.20it/s]
epoch 29400  training loss: 0.09792329370975494



 30%|██▉       | 29511/100000 [32:27<1:17:19, 15.19it/s]
epoch 29500  training loss: 0.09791987389326096



 30%|██▉       | 29601/100000 [32:33<1:17:14, 15.19it/s]
epoch 29600  training loss: 0.09795553982257843




 30%|██▉       | 29723/100000 [32:41<1:17:03, 15.20it/s]
epoch 29700  training loss: 0.0979340523481369



 30%|██▉       | 29813/100000 [32:47<1:16:58, 15.20it/s]
epoch 29800  training loss: 0.09792385250329971



 30%|██▉       | 29905/100000 [32:53<1:17:00, 15.17it/s]
epoch 29900  training loss: 0.09792670607566833




 30%|███       | 30027/100000 [33:01<1:16:41, 15.21it/s]
epoch 30000  training loss: 0.09791729599237442
epoch 30000  clean testing loss: 0.0016415048157796264



 30%|███       | 30117/100000 [33:07<1:16:40, 15.19it/s]
epoch 30100  training loss: 0.09791500866413116



 30%|███       | 30207/100000 [33:13<1:16:42, 15.16it/s]
epoch 30200  training loss: 0.09791453927755356



 30%|███       | 30301/100000 [33:19<1:16:26, 15.20it/s]
epoch 30300  training loss: 0.09791382402181625




 30%|███       | 30423/100000 [33:27<1:16:20, 15.19it/s]
epoch 30400  training loss: 0.09791295975446701



 31%|███       | 30513/100000 [33:33<1:16:14, 15.19it/s]
epoch 30500  training loss: 0.09794890135526657



 31%|███       | 30605/100000 [33:39<1:16:46, 15.07it/s]
epoch 30600  training loss: 0.09791136533021927




 31%|███       | 30727/100000 [33:47<1:15:58, 15.20it/s]
epoch 30700  training loss: 0.09791170060634613



 31%|███       | 30817/100000 [33:53<1:15:51, 15.20it/s]
epoch 30800  training loss: 0.09791123867034912



 31%|███       | 30909/100000 [33:59<1:15:47, 15.19it/s]
epoch 30900  training loss: 0.09790927171707153



 31%|███       | 31001/100000 [34:05<1:16:45, 14.98it/s]
epoch 31000  training loss: 0.0979258269071579
epoch 31000  clean testing loss: 0.0016826792852953076




 31%|███       | 31121/100000 [34:13<1:15:30, 15.20it/s]
epoch 31100  training loss: 0.09790750592947006



 31%|███       | 31213/100000 [34:19<1:15:24, 15.20it/s]
epoch 31200  training loss: 0.09793400764465332



 31%|███▏      | 31305/100000 [34:25<1:15:28, 15.17it/s]
epoch 31300  training loss: 0.0979202538728714




 31%|███▏      | 31427/100000 [34:33<1:15:10, 15.20it/s]
epoch 31400  training loss: 0.0979052186012268



 32%|███▏      | 31517/100000 [34:39<1:15:20, 15.15it/s]
epoch 31500  training loss: 0.0979045107960701



 32%|███▏      | 31609/100000 [34:45<1:15:04, 15.18it/s]
epoch 31600  training loss: 0.09790510684251785




 32%|███▏      | 31729/100000 [34:53<1:14:57, 15.18it/s]
epoch 31700  training loss: 0.09790312498807907



 32%|███▏      | 31821/100000 [34:59<1:14:50, 15.18it/s]
epoch 31800  training loss: 0.09790205955505371



 32%|███▏      | 31913/100000 [35:05<1:14:44, 15.18it/s]
epoch 31900  training loss: 0.09790125489234924



 32%|███▏      | 32003/100000 [35:11<1:15:23, 15.03it/s]
epoch 32000  training loss: 0.09790133684873581
epoch 32000  clean testing loss: 0.001653771148994565




 32%|███▏      | 32125/100000 [35:19<1:14:31, 15.18it/s]
epoch 32100  training loss: 0.09790009260177612



 32%|███▏      | 32215/100000 [35:25<1:14:24, 15.18it/s]
epoch 32200  training loss: 0.09789882600307465



 32%|███▏      | 32307/100000 [35:31<1:14:30, 15.14it/s]
epoch 32300  training loss: 0.09789997339248657




 32%|███▏      | 32429/100000 [35:40<1:14:03, 15.21it/s]
epoch 32400  training loss: 0.09790191799402237



 33%|███▎      | 32519/100000 [35:45<1:14:05, 15.18it/s]
epoch 32500  training loss: 0.09790469706058502



 33%|███▎      | 32611/100000 [35:52<1:14:01, 15.17it/s]
epoch 32600  training loss: 0.09789716452360153



 33%|███▎      | 32703/100000 [35:58<1:14:12, 15.12it/s]
epoch 32700  training loss: 0.097908616065979




 33%|███▎      | 32823/100000 [36:05<1:13:49, 15.16it/s]
epoch 32800  training loss: 0.09789437055587769



 33%|███▎      | 32915/100000 [36:12<1:13:44, 15.16it/s]
epoch 32900  training loss: 0.09789331257343292



 33%|███▎      | 33005/100000 [36:18<1:14:10, 15.05it/s]
epoch 33000  training loss: 0.09789880365133286
epoch 33000  clean testing loss: 0.001660552923567593




 33%|███▎      | 33127/100000 [36:26<1:13:27, 15.17it/s]
epoch 33100  training loss: 0.09789182245731354



 33%|███▎      | 33217/100000 [36:32<1:13:23, 15.17it/s]
epoch 33200  training loss: 0.09789131581783295



 33%|███▎      | 33309/100000 [36:38<1:13:36, 15.10it/s]
epoch 33300  training loss: 0.09789058566093445




 33%|███▎      | 33429/100000 [36:46<1:13:06, 15.18it/s]
epoch 33400  training loss: 0.09788961708545685



 34%|███▎      | 33521/100000 [36:52<1:13:03, 15.16it/s]
epoch 33500  training loss: 0.09791828691959381



 34%|███▎      | 33613/100000 [36:58<1:13:01, 15.15it/s]
epoch 33600  training loss: 0.0978880450129509



 34%|███▎      | 33703/100000 [37:04<1:13:06, 15.11it/s]
epoch 33700  training loss: 0.09788737446069717




 34%|███▍      | 33825/100000 [37:12<1:12:43, 15.16it/s]
epoch 33800  training loss: 0.09799905866384506



 34%|███▍      | 33915/100000 [37:18<1:12:40, 15.16it/s]
epoch 33900  training loss: 0.09788540750741959



 34%|███▍      | 34007/100000 [37:24<1:12:58, 15.07it/s]
epoch 34000  training loss: 0.09788495302200317
epoch 34000  clean testing loss: 0.0016691720811650157




 34%|███▍      | 34127/100000 [37:32<1:12:26, 15.15it/s]
epoch 34100  training loss: 0.09788544476032257



 34%|███▍      | 34219/100000 [37:38<1:12:38, 15.09it/s]
epoch 34200  training loss: 0.09791412204504013



 34%|███▍      | 34309/100000 [37:44<1:12:22, 15.13it/s]
epoch 34300  training loss: 0.09788206964731216



 34%|███▍      | 34393/100000 [37:49<1:12:07, 15.16it/s]
epoch 34400  training loss: 0.09792466461658478




 35%|███▍      | 34515/100000 [37:57<1:12:03, 15.15it/s]
epoch 34500  training loss: 0.097897008061409



 35%|███▍      | 34605/100000 [38:03<1:12:01, 15.13it/s]
epoch 34600  training loss: 0.09788289666175842



 35%|███▍      | 34695/100000 [38:09<1:11:48, 15.16it/s]
epoch 34700  training loss: 0.09788604825735092




 35%|███▍      | 34817/100000 [38:17<1:11:39, 15.16it/s]
epoch 34800  training loss: 0.09791059792041779



 35%|███▍      | 34909/100000 [38:23<1:11:38, 15.14it/s]
epoch 34900  training loss: 0.09787684679031372



 35%|███▍      | 34999/100000 [38:29<1:11:30, 15.15it/s]
epoch 35000  training loss: 0.09787851572036743
epoch 35000  clean testing loss: 0.001675775507465005




 35%|███▌      | 35119/100000 [38:37<1:14:06, 14.59it/s]
epoch 35100  training loss: 0.09787630289793015



 35%|███▌      | 35211/100000 [38:43<1:11:23, 15.12it/s]
epoch 35200  training loss: 0.09792157262563705



 35%|███▌      | 35301/100000 [38:49<1:11:13, 15.14it/s]
epoch 35300  training loss: 0.09787352383136749



 35%|███▌      | 35393/100000 [38:55<1:11:02, 15.16it/s]
epoch 35400  training loss: 0.0978747010231018




 36%|███▌      | 35515/100000 [39:03<1:10:57, 15.15it/s]
epoch 35500  training loss: 0.09787397086620331



 36%|███▌      | 35605/100000 [39:09<1:11:23, 15.03it/s]
epoch 35600  training loss: 0.09787258505821228



 36%|███▌      | 35695/100000 [39:15<1:10:41, 15.16it/s]
epoch 35700  training loss: 0.09788317233324051




 36%|███▌      | 35817/100000 [39:23<1:10:35, 15.15it/s]
epoch 35800  training loss: 0.09786885976791382



 36%|███▌      | 35909/100000 [39:30<1:10:38, 15.12it/s]
epoch 35900  training loss: 0.09786819666624069



 36%|███▌      | 35999/100000 [39:35<1:10:22, 15.16it/s]
epoch 36000  training loss: 0.09786812216043472
epoch 36000  clean testing loss: 0.0016924008959904313




 36%|███▌      | 36121/100000 [39:44<1:10:17, 15.14it/s]
epoch 36100  training loss: 0.09786629676818848



 36%|███▌      | 36211/100000 [39:50<1:10:13, 15.14it/s]
epoch 36200  training loss: 0.09786558896303177



 36%|███▋      | 36303/100000 [39:56<1:10:17, 15.10it/s]
epoch 36300  training loss: 0.0978647917509079



 36%|███▋      | 36393/100000 [40:02<1:09:57, 15.16it/s]
epoch 36400  training loss: 0.09786383807659149




 37%|███▋      | 36515/100000 [40:10<1:09:51, 15.15it/s]
epoch 36500  training loss: 0.0978631004691124



 37%|███▋      | 36605/100000 [40:16<1:09:54, 15.11it/s]
epoch 36600  training loss: 0.09786207228899002



 37%|███▋      | 36697/100000 [40:22<1:09:35, 15.16it/s]
epoch 36700  training loss: 0.09786130487918854




 37%|███▋      | 36817/100000 [40:30<1:09:30, 15.15it/s]
epoch 36800  training loss: 0.09786406904459



 37%|███▋      | 36909/100000 [40:36<1:09:26, 15.14it/s]
epoch 36900  training loss: 0.09788054972887039




 37%|███▋      | 37029/100000 [40:44<1:09:14, 15.16it/s]
epoch 37000  training loss: 0.09786656498908997
epoch 37000  clean testing loss: 0.001715737278573215



 37%|███▋      | 37121/100000 [40:50<1:09:10, 15.15it/s]
epoch 37100  training loss: 0.09787092357873917



 37%|███▋      | 37211/100000 [40:56<1:09:05, 15.15it/s]
epoch 37200  training loss: 0.09786400198936462



 37%|███▋      | 37303/100000 [41:02<1:09:10, 15.10it/s]
epoch 37300  training loss: 0.09785542637109756




 37%|███▋      | 37423/100000 [41:10<1:08:56, 15.13it/s]
epoch 37400  training loss: 0.09785664826631546



 38%|███▊      | 37515/100000 [41:16<1:08:42, 15.16it/s]
epoch 37500  training loss: 0.09785351157188416



 38%|███▊      | 37605/100000 [41:22<1:08:49, 15.11it/s]
epoch 37600  training loss: 0.09785273671150208




 38%|███▊      | 37727/100000 [41:30<1:08:27, 15.16it/s]
epoch 37700  training loss: 0.09785334765911102



 38%|███▊      | 37819/100000 [41:36<1:08:24, 15.15it/s]
epoch 37800  training loss: 0.09785214811563492



 38%|███▊      | 37909/100000 [41:42<1:08:19, 15.14it/s]
epoch 37900  training loss: 0.09785880148410797




 38%|███▊      | 38031/100000 [41:50<1:08:07, 15.16it/s]
epoch 38000  training loss: 0.09789717197418213
epoch 38000  clean testing loss: 0.0017812789883464575



 38%|███▊      | 38121/100000 [41:56<1:08:02, 15.16it/s]
epoch 38100  training loss: 0.09784925729036331



 38%|███▊      | 38213/100000 [42:02<1:07:58, 15.15it/s]
epoch 38200  training loss: 0.09784785658121109



 38%|███▊      | 38303/100000 [42:08<1:08:04, 15.10it/s]
epoch 38300  training loss: 0.09784915298223495




 38%|███▊      | 38423/100000 [42:16<1:07:42, 15.16it/s]
epoch 38400  training loss: 0.09784546494483948



 39%|███▊      | 38515/100000 [42:22<1:07:37, 15.15it/s]
epoch 38500  training loss: 0.09784393012523651



 39%|███▊      | 38605/100000 [42:28<1:07:41, 15.11it/s]
epoch 38600  training loss: 0.09784894436597824




 39%|███▊      | 38727/100000 [42:36<1:07:21, 15.16it/s]
epoch 38700  training loss: 0.09787912666797638



 39%|███▉      | 38817/100000 [42:42<1:07:15, 15.16it/s]
epoch 38800  training loss: 0.09784109890460968



 39%|███▉      | 38909/100000 [42:48<1:07:16, 15.14it/s]
epoch 38900  training loss: 0.09784477204084396




 39%|███▉      | 39031/100000 [42:56<1:07:01, 15.16it/s]
epoch 39000  training loss: 0.09784971177577972
epoch 39000  clean testing loss: 0.0017245410708710551



 39%|███▉      | 39121/100000 [43:02<1:06:57, 15.15it/s]
epoch 39100  training loss: 0.09783830493688583



 39%|███▉      | 39213/100000 [43:08<1:06:50, 15.16it/s]
epoch 39200  training loss: 0.0978374257683754



 39%|███▉      | 39303/100000 [43:14<1:06:50, 15.14it/s]
epoch 39300  training loss: 0.09783665835857391




 39%|███▉      | 39425/100000 [43:22<1:06:27, 15.19it/s]
epoch 39400  training loss: 0.09783565253019333



 40%|███▉      | 39515/100000 [43:28<1:06:22, 15.19it/s]
epoch 39500  training loss: 0.09784377366304398



 40%|███▉      | 39607/100000 [43:34<1:06:21, 15.17it/s]
epoch 39600  training loss: 0.09783389419317245




 40%|███▉      | 39729/100000 [43:42<1:06:05, 15.20it/s]
epoch 39700  training loss: 0.09783988445997238



 40%|███▉      | 39819/100000 [43:48<1:05:59, 15.20it/s]
epoch 39800  training loss: 0.09783899784088135



 40%|███▉      | 39911/100000 [43:54<1:05:57, 15.18it/s]
epoch 39900  training loss: 0.09783168137073517



 40%|████      | 40001/100000 [44:00<1:06:55, 14.94it/s]
epoch 40000  training loss: 0.09783926606178284
epoch 40000  clean testing loss: 0.001751484232954681




 40%|████      | 40123/100000 [44:08<1:05:41, 15.19it/s]
epoch 40100  training loss: 0.09782955050468445



 40%|████      | 40213/100000 [44:14<1:05:37, 15.18it/s]
epoch 40200  training loss: 0.09782853722572327



 40%|████      | 40305/100000 [44:20<1:05:40, 15.15it/s]
epoch 40300  training loss: 0.0978274941444397




 40%|████      | 40427/100000 [44:28<1:05:25, 15.18it/s]
epoch 40400  training loss: 0.09782659262418747



 41%|████      | 40517/100000 [44:34<1:05:18, 15.18it/s]
epoch 40500  training loss: 0.097825787961483



 41%|████      | 40609/100000 [44:40<1:05:41, 15.07it/s]
epoch 40600  training loss: 0.0978248119354248




 41%|████      | 40731/100000 [44:48<1:05:06, 15.17it/s]
epoch 40700  training loss: 0.09782446920871735



 41%|████      | 40821/100000 [44:54<1:05:01, 15.17it/s]
epoch 40800  training loss: 0.09782309085130692



 41%|████      | 40913/100000 [45:00<1:04:51, 15.18it/s]
epoch 40900  training loss: 0.09782210737466812



 41%|████      | 41003/100000 [45:06<1:05:23, 15.04it/s]
epoch 41000  training loss: 0.09782122820615768
epoch 41000  clean testing loss: 0.0017508218297734857




 41%|████      | 41125/100000 [45:14<1:04:32, 15.20it/s]
epoch 41100  training loss: 0.09782100468873978



 41%|████      | 41217/100000 [45:20<1:04:27, 15.20it/s]
epoch 41200  training loss: 0.09781954437494278



 41%|████▏     | 41307/100000 [45:26<1:04:26, 15.18it/s]
epoch 41300  training loss: 0.09781843423843384


 42%|████▏     | 41879/100000 [46:04<1:08:55, 14.05it/s]
epoch 41400  training loss: 0.09781880676746368
epoch 41400  clean testing loss: 0.001756503595970571
epoch 41500  training loss: 0.09781698882579803
epoch 41500  clean testing loss: 0.0017583562294021249
epoch 41600  training loss: 0.09783339500427246
epoch 41600  clean testing loss: 0.0017698947340250015
epoch 41700  training loss: 0.09781522303819656
epoch 41700  clean testing loss: 0.001759893144480884
epoch 41800  training loss: 0.0978279635310173

 42%|████▏     | 41909/100000 [46:06<1:03:55, 15.15it/s]
epoch 41900  training loss: 0.09781371057033539



 42%|████▏     | 41999/100000 [46:12<1:03:43, 15.17it/s]
epoch 42000  training loss: 0.09781268239021301
epoch 42000  clean testing loss: 0.001763854525052011




 42%|████▏     | 42121/100000 [46:20<1:03:31, 15.18it/s]
epoch 42100  training loss: 0.09781200438737869



 42%|████▏     | 42211/100000 [46:26<1:03:22, 15.20it/s]
epoch 42200  training loss: 0.09781116992235184



 42%|████▏     | 42303/100000 [46:32<1:03:23, 15.17it/s]
epoch 42300  training loss: 0.09781037271022797



 42%|████▏     | 42395/100000 [46:38<1:02:49, 15.28it/s]
epoch 42400  training loss: 0.09780951589345932




 43%|████▎     | 42517/100000 [46:46<1:02:46, 15.26it/s]
epoch 42500  training loss: 0.09781782329082489



 43%|████▎     | 42609/100000 [46:52<1:02:30, 15.30it/s]
epoch 42600  training loss: 0.09780782461166382



 43%|████▎     | 42701/100000 [46:58<1:02:23, 15.31it/s]
epoch 42700  training loss: 0.0978076383471489



 43%|████▎     | 42793/100000 [47:04<1:02:13, 15.32it/s]
epoch 42800  training loss: 0.09780958294868469




 43%|████▎     | 42915/100000 [47:12<1:02:11, 15.30it/s]
epoch 42900  training loss: 0.09780570864677429



 43%|████▎     | 43007/100000 [47:18<1:02:18, 15.25it/s]
epoch 43000  training loss: 0.09781792014837265
epoch 43000  clean testing loss: 0.0017769131809473038



 43%|████▎     | 43099/100000 [47:24<1:01:51, 15.33it/s]
epoch 43100  training loss: 0.09780417382717133




 43%|████▎     | 43223/100000 [47:32<1:01:43, 15.33it/s]
epoch 43200  training loss: 0.09780444204807281



 43%|████▎     | 43315/100000 [47:38<1:01:35, 15.34it/s]
epoch 43300  training loss: 0.09780246019363403



 43%|████▎     | 43405/100000 [47:44<1:01:39, 15.30it/s]
epoch 43400  training loss: 0.09780178219079971



 43%|████▎     | 43497/100000 [47:50<1:01:22, 15.34it/s]
epoch 43500  training loss: 0.09780188649892807




 44%|████▎     | 43621/100000 [47:58<1:01:18, 15.33it/s]
epoch 43600  training loss: 0.09780019521713257



 44%|████▎     | 43713/100000 [48:04<1:01:12, 15.33it/s]
epoch 43700  training loss: 0.09779945760965347



 44%|████▍     | 43805/100000 [48:10<1:01:17, 15.28it/s]
epoch 43800  training loss: 0.09779882431030273



 44%|████▍     | 43897/100000 [48:16<1:01:01, 15.32it/s]
epoch 43900  training loss: 0.09779860079288483




 44%|████▍     | 44019/100000 [48:24<1:01:02, 15.29it/s]
epoch 44000  training loss: 0.09779716283082962
epoch 44000  clean testing loss: 0.001786986249499023



 44%|████▍     | 44111/100000 [48:30<1:00:45, 15.33it/s]
epoch 44100  training loss: 0.09779752045869827



 44%|████▍     | 44203/100000 [48:36<1:00:51, 15.28it/s]
epoch 44200  training loss: 0.09779638051986694



 44%|████▍     | 44295/100000 [48:42<1:00:32, 15.34it/s]
epoch 44300  training loss: 0.09779588133096695




 44%|████▍     | 44417/100000 [48:50<1:00:25, 15.33it/s]
epoch 44400  training loss: 0.097794309258461



 45%|████▍     | 44509/100000 [48:56<1:00:23, 15.31it/s]
epoch 44500  training loss: 0.09779331088066101



 45%|████▍     | 44601/100000 [49:02<1:00:17, 15.32it/s]
epoch 44600  training loss: 0.09779331088066101




 45%|████▍     | 44725/100000 [49:10<1:00:03, 15.34it/s]
epoch 44700  training loss: 0.09779196232557297



 45%|████▍     | 44815/100000 [49:16<1:00:00, 15.33it/s]
epoch 44800  training loss: 0.09779124706983566



 45%|████▍     | 44907/100000 [49:22<59:57, 15.31it/s]
epoch 44900  training loss: 0.09779174625873566



 45%|████▌     | 45001/100000 [49:28<1:00:40, 15.11it/s]
epoch 45000  training loss: 0.09779042750597
epoch 45000  clean testing loss: 0.001797000295482576




 45%|████▌     | 45123/100000 [49:36<59:38, 15.33it/s]
epoch 45100  training loss: 0.09778908640146255



 45%|████▌     | 45215/100000 [49:42<59:45, 15.28it/s]
epoch 45200  training loss: 0.09778854995965958



 45%|████▌     | 45307/100000 [49:48<59:32, 15.31it/s]
epoch 45300  training loss: 0.09778790175914764



 45%|████▌     | 45399/100000 [49:54<59:20, 15.33it/s]
epoch 45400  training loss: 0.09778717905282974




 46%|████▌     | 45521/100000 [50:02<59:13, 15.33it/s]
epoch 45500  training loss: 0.09779100120067596



 46%|████▌     | 45613/100000 [50:08<59:07, 15.33it/s]
epoch 45600  training loss: 0.09778565168380737



 46%|████▌     | 45705/100000 [50:14<59:12, 15.29it/s]
epoch 45700  training loss: 0.09778644889593124



 46%|████▌     | 45797/100000 [50:20<58:55, 15.33it/s]
epoch 45800  training loss: 0.0977846160531044




 46%|████▌     | 45919/100000 [50:28<58:46, 15.33it/s]
epoch 45900  training loss: 0.09778362512588501



 46%|████▌     | 46011/100000 [50:34<58:48, 15.30it/s]
epoch 46000  training loss: 0.09778644889593124
epoch 46000  clean testing loss: 0.0018128026276826859



 46%|████▌     | 46105/100000 [50:40<58:43, 15.30it/s]
epoch 46100  training loss: 0.09778282046318054




 46%|████▌     | 46227/100000 [50:48<58:22, 15.35it/s]
epoch 46200  training loss: 0.09778185933828354



 46%|████▋     | 46319/100000 [50:54<58:17, 15.35it/s]
epoch 46300  training loss: 0.09778133779764175



 46%|████▋     | 46411/100000 [51:00<58:15, 15.33it/s]
epoch 46400  training loss: 0.09778030961751938



 47%|████▋     | 46503/100000 [51:06<58:18, 15.29it/s]
epoch 46500  training loss: 0.09778016805648804




 47%|████▋     | 46625/100000 [51:14<58:09, 15.30it/s]
epoch 46600  training loss: 0.09778189659118652



 47%|████▋     | 46717/100000 [51:21<58:01, 15.30it/s]
epoch 46700  training loss: 0.09777837246656418



 47%|████▋     | 46809/100000 [51:27<58:00, 15.28it/s]
epoch 46800  training loss: 0.09777763485908508



 47%|████▋     | 46901/100000 [51:33<57:54, 15.28it/s]
epoch 46900  training loss: 0.09777695685625076




 47%|████▋     | 47023/100000 [51:41<57:43, 15.30it/s]
epoch 47000  training loss: 0.09777753800153732
epoch 47000  clean testing loss: 0.0018131103133782744



 47%|████▋     | 47115/100000 [51:47<57:36, 15.30it/s]
epoch 47100  training loss: 0.09777574986219406



 47%|████▋     | 47207/100000 [51:53<57:36, 15.27it/s]
epoch 47200  training loss: 0.09777524322271347



 47%|████▋     | 47299/100000 [51:59<57:26, 15.29it/s]
epoch 47300  training loss: 0.09777498245239258




 47%|████▋     | 47421/100000 [52:07<57:16, 15.30it/s]
epoch 47400  training loss: 0.09777379035949707



 48%|████▊     | 47513/100000 [52:13<57:48, 15.13it/s]
epoch 47500  training loss: 0.09777273237705231



 48%|████▊     | 47603/100000 [52:19<57:22, 15.22it/s]
epoch 47600  training loss: 0.09777195751667023




 48%|████▊     | 47727/100000 [52:27<56:56, 15.30it/s]
epoch 47700  training loss: 0.09777167439460754



 48%|████▊     | 47819/100000 [52:33<56:56, 15.27it/s]
epoch 47800  training loss: 0.09777339547872543



 48%|████▊     | 47911/100000 [52:39<56:50, 15.27it/s]
epoch 47900  training loss: 0.09777018427848816



 48%|████▊     | 48001/100000 [52:45<57:32, 15.06it/s]
epoch 48000  training loss: 0.09776917845010757
epoch 48000  clean testing loss: 0.001824439619667828




 48%|████▊     | 48117/100000 [52:52<56:32, 15.29it/s]
epoch 48100  training loss: 0.09776857495307922



 48%|████▊     | 48209/100000 [52:58<56:36, 15.25it/s]
epoch 48200  training loss: 0.09776805341243744



 48%|████▊     | 48301/100000 [53:04<56:20, 15.29it/s]
epoch 48300  training loss: 0.0977674275636673



 48%|████▊     | 48393/100000 [53:10<56:11, 15.31it/s]
epoch 48400  training loss: 0.09776663780212402




 49%|████▊     | 48513/100000 [53:18<56:07, 15.29it/s]
epoch 48500  training loss: 0.09776630252599716



 49%|████▊     | 48605/100000 [53:24<56:12, 15.24it/s]
epoch 48600  training loss: 0.09776567667722702



 49%|████▊     | 48697/100000 [53:30<55:54, 15.30it/s]
epoch 48700  training loss: 0.09776478260755539




 49%|████▉     | 48819/100000 [53:38<56:13, 15.17it/s]
epoch 48800  training loss: 0.09776421636343002



 49%|████▉     | 48911/100000 [53:44<55:57, 15.22it/s]
epoch 48900  training loss: 0.09776390343904495



 49%|████▉     | 49001/100000 [53:50<59:11, 14.36it/s]
epoch 49000  training loss: 0.09776262938976288
epoch 49000  clean testing loss: 0.0018310720333829522



 49%|████▉     | 49093/100000 [53:56<55:45, 15.22it/s]
epoch 49100  training loss: 0.09776189178228378




 49%|████▉     | 49215/100000 [54:04<55:40, 15.20it/s]
epoch 49200  training loss: 0.09776143729686737



 49%|████▉     | 49307/100000 [54:10<55:36, 15.19it/s]
epoch 49300  training loss: 0.09776049852371216



 49%|████▉     | 49397/100000 [54:16<55:28, 15.20it/s]
epoch 49400  training loss: 0.09776090830564499




 50%|████▉     | 49519/100000 [54:24<55:20, 15.20it/s]
epoch 49500  training loss: 0.09775938838720322



 50%|████▉     | 49611/100000 [54:30<55:18, 15.18it/s]
epoch 49600  training loss: 0.09775877743959427



 50%|████▉     | 49701/100000 [54:36<55:12, 15.18it/s]
epoch 49700  training loss: 0.09775786846876144



 50%|████▉     | 49793/100000 [54:42<55:02, 15.20it/s]
epoch 49800  training loss: 0.09775727242231369




 50%|████▉     | 49915/100000 [54:51<54:56, 15.19it/s]
epoch 49900  training loss: 0.09775654971599579



 50%|█████     | 50005/100000 [54:56<55:16, 15.08it/s]
epoch 50000  training loss: 0.09775568544864655
epoch 50000  clean testing loss: 0.0018389225006103516



 50%|█████     | 50097/100000 [55:02<54:46, 15.18it/s]
epoch 50100  training loss: 0.09775508940219879




 50%|█████     | 50219/100000 [55:11<54:37, 15.19it/s]
epoch 50200  training loss: 0.09775425493717194



 50%|█████     | 50309/100000 [55:17<54:32, 15.18it/s]
epoch 50300  training loss: 0.0977662056684494



 50%|█████     | 50401/100000 [55:23<54:16, 15.23it/s]
epoch 50400  training loss: 0.09775294363498688




 51%|█████     | 50523/100000 [55:31<54:05, 15.24it/s]
epoch 50500  training loss: 0.09775260835886002



 51%|█████     | 50615/100000 [55:37<54:01, 15.23it/s]
epoch 50600  training loss: 0.09775134921073914



 51%|█████     | 50705/100000 [55:43<54:01, 15.21it/s]
epoch 50700  training loss: 0.09775067865848541




 51%|█████     | 50827/100000 [55:51<53:43, 15.25it/s]
epoch 50800  training loss: 0.09775301814079285



 51%|█████     | 50919/100000 [55:57<53:41, 15.24it/s]
epoch 50900  training loss: 0.09774922579526901



 51%|█████     | 51011/100000 [56:03<53:40, 15.21it/s]
epoch 51000  training loss: 0.09774843603372574
epoch 51000  clean testing loss: 0.001846635015681386



 51%|█████     | 51101/100000 [56:09<53:34, 15.21it/s]
epoch 51100  training loss: 0.09774777293205261




 51%|█████     | 51223/100000 [56:17<53:17, 15.26it/s]
epoch 51200  training loss: 0.09774713218212128



 51%|█████▏    | 51315/100000 [56:23<53:17, 15.22it/s]
epoch 51300  training loss: 0.09774640202522278



 51%|█████▏    | 51407/100000 [56:29<53:13, 15.21it/s]
epoch 51400  training loss: 0.09774579852819443




 52%|█████▏    | 51529/100000 [56:37<53:00, 15.24it/s]
epoch 51500  training loss: 0.09774722903966904



 52%|█████▏    | 51621/100000 [56:43<52:54, 15.24it/s]
epoch 51600  training loss: 0.09774418920278549



 52%|█████▏    | 51711/100000 [56:49<52:49, 15.24it/s]
epoch 51700  training loss: 0.09774351865053177



 52%|█████▏    | 51803/100000 [56:55<52:53, 15.19it/s]
epoch 51800  training loss: 0.09774335473775864




 52%|█████▏    | 51925/100000 [57:03<52:34, 15.24it/s]
epoch 51900  training loss: 0.0977424904704094



 52%|█████▏    | 52017/100000 [57:09<52:28, 15.24it/s]
epoch 52000  training loss: 0.09774206578731537
epoch 52000  clean testing loss: 0.0018557383446022868



 52%|█████▏    | 52107/100000 [57:15<52:49, 15.11it/s]
epoch 52100  training loss: 0.09774070233106613




 52%|█████▏    | 52229/100000 [57:23<52:14, 15.24it/s]
epoch 52200  training loss: 0.09774063527584076



 52%|█████▏    | 52321/100000 [57:29<52:08, 15.24it/s]
epoch 52300  training loss: 0.09773899614810944



 52%|█████▏    | 52413/100000 [57:35<52:02, 15.24it/s]
epoch 52400  training loss: 0.09773825109004974



 53%|█████▎    | 52505/100000 [57:41<52:03, 15.21it/s]
epoch 52500  training loss: 0.09774211049079895




 53%|█████▎    | 52625/100000 [57:49<51:47, 15.24it/s]
epoch 52600  training loss: 0.09773663431406021



 53%|█████▎    | 52717/100000 [57:55<51:40, 15.25it/s]
epoch 52700  training loss: 0.09773704409599304



 53%|█████▎    | 52809/100000 [58:01<51:38, 15.23it/s]
epoch 52800  training loss: 0.09773510694503784



 53%|█████▎    | 52901/100000 [58:07<51:33, 15.23it/s]
epoch 52900  training loss: 0.0977344661951065




 53%|█████▎    | 53021/100000 [58:15<51:56, 15.07it/s]
epoch 53000  training loss: 0.09773378819227219
epoch 53000  clean testing loss: 0.0018622535280883312



 53%|█████▎    | 53113/100000 [58:21<51:20, 15.22it/s]
epoch 53100  training loss: 0.09773334860801697



 53%|█████▎    | 53205/100000 [58:27<51:18, 15.20it/s]
epoch 53200  training loss: 0.09773194044828415




 53%|█████▎    | 53327/100000 [58:35<51:03, 15.24it/s]
epoch 53300  training loss: 0.09773112833499908



 53%|█████▎    | 53419/100000 [58:41<50:57, 15.24it/s]
epoch 53400  training loss: 0.09773050248622894



 54%|█████▎    | 53509/100000 [58:47<50:54, 15.22it/s]
epoch 53500  training loss: 0.09773079305887222



 54%|█████▎    | 53601/100000 [58:53<50:49, 15.21it/s]
epoch 53600  training loss: 0.09773000329732895




 54%|█████▎    | 53723/100000 [59:01<50:37, 15.24it/s]
epoch 53700  training loss: 0.09772779047489166



 54%|█████▍    | 53815/100000 [59:07<50:32, 15.23it/s]
epoch 53800  training loss: 0.09772694110870361



 54%|█████▍    | 53905/100000 [59:13<50:32, 15.20it/s]
epoch 53900  training loss: 0.0977262556552887




 54%|█████▍    | 54027/100000 [59:21<50:18, 15.23it/s]
epoch 54000  training loss: 0.097725510597229
epoch 54000  clean testing loss: 0.00186781061347574



 54%|█████▍    | 54119/100000 [59:27<50:12, 15.23it/s]
epoch 54100  training loss: 0.09772448986768723



 54%|█████▍    | 54211/100000 [59:33<50:10, 15.21it/s]
epoch 54200  training loss: 0.09772390872240067



 54%|█████▍    | 54303/100000 [59:39<50:07, 15.19it/s]
epoch 54300  training loss: 0.09772300720214844




 54%|█████▍    | 54423/100000 [59:47<49:50, 15.24it/s]
epoch 54400  training loss: 0.09772252291440964



 55%|█████▍    | 54515/100000 [59:53<49:43, 15.25it/s]
epoch 54500  training loss: 0.0977216511964798



 55%|█████▍    | 54607/100000 [59:59<49:43, 15.21it/s]
epoch 54600  training loss: 0.09772089123725891




 55%|█████▍    | 54729/100000 [1:00:07<49:26, 15.26it/s]
epoch 54700  training loss: 0.09772010147571564



 55%|█████▍    | 54821/100000 [1:00:13<49:22, 15.25it/s]
epoch 54800  training loss: 0.09771931171417236



 55%|█████▍    | 54913/100000 [1:00:19<49:19, 15.24it/s]
epoch 54900  training loss: 0.09771830588579178



 55%|█████▌    | 55003/100000 [1:00:25<49:48, 15.06it/s]
epoch 55000  training loss: 0.09771746397018433
epoch 55000  clean testing loss: 0.0018748365109786391




 55%|█████▌    | 55119/100000 [1:00:33<49:02, 15.25it/s]
epoch 55100  training loss: 0.09771669656038284



 55%|█████▌    | 55209/100000 [1:00:39<49:01, 15.23it/s]
epoch 55200  training loss: 0.0977158322930336



 55%|█████▌    | 55301/100000 [1:00:45<48:53, 15.24it/s]
epoch 55300  training loss: 0.09771507233381271



 55%|█████▌    | 55393/100000 [1:00:51<48:44, 15.25it/s]
epoch 55400  training loss: 0.09771409630775452




 56%|█████▌    | 55515/100000 [1:00:59<48:37, 15.25it/s]
epoch 55500  training loss: 0.09771347790956497



 56%|█████▌    | 55607/100000 [1:01:05<48:36, 15.22it/s]
epoch 55600  training loss: 0.09771248698234558



 56%|█████▌    | 55697/100000 [1:01:11<48:26, 15.24it/s]
epoch 55700  training loss: 0.09771176427602768




 56%|█████▌    | 55819/100000 [1:01:19<48:17, 15.25it/s]
epoch 55800  training loss: 0.09771266579627991



 56%|█████▌    | 55911/100000 [1:01:25<48:13, 15.24it/s]
epoch 55900  training loss: 0.09771010279655457



 56%|█████▌    | 56003/100000 [1:01:31<48:43, 15.05it/s]
epoch 56000  training loss: 0.09770916402339935
epoch 56000  clean testing loss: 0.0018801509868353605



 56%|█████▌    | 56095/100000 [1:01:37<48:01, 15.24it/s]
epoch 56100  training loss: 0.09770858287811279




 56%|█████▌    | 56217/100000 [1:01:45<47:50, 15.25it/s]
epoch 56200  training loss: 0.0977073609828949



 56%|█████▋    | 56307/100000 [1:01:51<47:49, 15.23it/s]
epoch 56300  training loss: 0.09770657867193222



 56%|█████▋    | 56399/100000 [1:01:57<47:40, 15.24it/s]
epoch 56400  training loss: 0.09770569205284119




 57%|█████▋    | 56521/100000 [1:02:05<47:32, 15.24it/s]
epoch 56500  training loss: 0.09770499914884567



 57%|█████▋    | 56613/100000 [1:02:11<47:28, 15.23it/s]
epoch 56600  training loss: 0.09770411998033524



 57%|█████▋    | 56703/100000 [1:02:17<47:43, 15.12it/s]
epoch 56700  training loss: 0.09770403057336807



 57%|█████▋    | 56795/100000 [1:02:23<47:14, 15.24it/s]
epoch 56800  training loss: 0.09770239144563675




 57%|█████▋    | 56917/100000 [1:02:31<47:08, 15.23it/s]
epoch 56900  training loss: 0.09770142287015915



 57%|█████▋    | 57009/100000 [1:02:37<47:14, 15.17it/s]
epoch 57000  training loss: 0.09770133346319199
epoch 57000  clean testing loss: 0.00188589992467314



 57%|█████▋    | 57099/100000 [1:02:43<46:56, 15.23it/s]
epoch 57100  training loss: 0.09769999980926514




 57%|█████▋    | 57221/100000 [1:02:51<46:45, 15.25it/s]
epoch 57200  training loss: 0.09769924730062485



 57%|█████▋    | 57313/100000 [1:02:57<46:43, 15.23it/s]
epoch 57300  training loss: 0.09769865870475769



 57%|█████▋    | 57405/100000 [1:03:03<46:41, 15.20it/s]
epoch 57400  training loss: 0.09769795089960098




 58%|█████▊    | 57527/100000 [1:03:11<46:25, 15.25it/s]
epoch 57500  training loss: 0.09769720584154129



 58%|█████▊    | 57617/100000 [1:03:17<46:37, 15.15it/s]
epoch 57600  training loss: 0.09769630432128906



 58%|█████▊    | 57709/100000 [1:03:23<46:17, 15.23it/s]
epoch 57700  training loss: 0.09769560396671295



 58%|█████▊    | 57801/100000 [1:03:29<46:10, 15.23it/s]
epoch 57800  training loss: 0.09769497066736221




 58%|█████▊    | 57923/100000 [1:03:37<46:00, 15.25it/s]
epoch 57900  training loss: 0.09769415855407715



 58%|█████▊    | 58015/100000 [1:03:43<45:56, 15.23it/s]
epoch 58000  training loss: 0.09769386053085327
epoch 58000  clean testing loss: 0.0018948882352560759



 58%|█████▊    | 58105/100000 [1:03:49<45:58, 15.19it/s]
epoch 58100  training loss: 0.09769247472286224




 58%|█████▊    | 58227/100000 [1:03:57<45:38, 15.25it/s]
epoch 58200  training loss: 0.09769170731306076



 58%|█████▊    | 58319/100000 [1:04:03<45:32, 15.25it/s]
epoch 58300  training loss: 0.0976915955543518



 58%|█████▊    | 58411/100000 [1:04:09<45:38, 15.19it/s]
epoch 58400  training loss: 0.097690150141716



 59%|█████▊    | 58503/100000 [1:04:15<45:29, 15.21it/s]
epoch 58500  training loss: 0.09768930077552795




 59%|█████▊    | 58623/100000 [1:04:23<45:14, 15.24it/s]
epoch 58600  training loss: 0.09768866747617722



 59%|█████▊    | 58715/100000 [1:04:29<45:12, 15.22it/s]
epoch 58700  training loss: 0.09768782556056976



 59%|█████▉    | 58807/100000 [1:04:35<45:07, 15.22it/s]
epoch 58800  training loss: 0.09768759459257126




 59%|█████▉    | 58929/100000 [1:04:43<44:53, 15.25it/s]
epoch 58900  training loss: 0.09768638759851456



 59%|█████▉    | 59021/100000 [1:04:49<44:49, 15.24it/s]
epoch 59000  training loss: 0.09768558293581009
epoch 59000  clean testing loss: 0.0018964415648952127



 59%|█████▉    | 59111/100000 [1:04:55<44:48, 15.21it/s]
epoch 59100  training loss: 0.09768464416265488



 59%|█████▉    | 59203/100000 [1:05:01<44:46, 15.19it/s]
epoch 59200  training loss: 0.09768415242433548




 59%|█████▉    | 59325/100000 [1:05:09<44:42, 15.16it/s]
epoch 59300  training loss: 0.09768334776163101



 59%|█████▉    | 59417/100000 [1:05:15<44:22, 15.24it/s]
epoch 59400  training loss: 0.09768248349428177



 60%|█████▉    | 59509/100000 [1:05:21<44:21, 15.21it/s]
epoch 59500  training loss: 0.09768170118331909




 60%|█████▉    | 59631/100000 [1:05:29<44:09, 15.24it/s]
epoch 59600  training loss: 0.09768106043338776



 60%|█████▉    | 59721/100000 [1:05:35<44:06, 15.22it/s]
epoch 59700  training loss: 0.09768050163984299



 60%|█████▉    | 59813/100000 [1:05:41<44:00, 15.22it/s]
epoch 59800  training loss: 0.0976797491312027




 60%|█████▉    | 59927/100000 [1:05:49<43:50, 15.23it/s]
epoch 59900  training loss: 0.09767941385507584



 60%|██████    | 60019/100000 [1:05:55<43:46, 15.22it/s]
epoch 60000  training loss: 0.09767792373895645
epoch 60000  clean testing loss: 0.0019016123842447996



 60%|██████    | 60111/100000 [1:06:01<43:40, 15.22it/s]
epoch 60100  training loss: 0.09767753630876541



 60%|██████    | 60201/100000 [1:06:07<43:39, 15.19it/s]
epoch 60200  training loss: 0.09767686575651169




 60%|██████    | 60323/100000 [1:06:15<43:25, 15.23it/s]
epoch 60300  training loss: 0.09767603874206543



 60%|██████    | 60415/100000 [1:06:21<43:19, 15.23it/s]
epoch 60400  training loss: 0.09767568111419678



 61%|██████    | 60507/100000 [1:06:27<43:17, 15.20it/s]
epoch 60500  training loss: 0.09767507016658783




 61%|██████    | 60629/100000 [1:06:35<43:08, 15.21it/s]
epoch 60600  training loss: 0.09767437726259232



 61%|██████    | 60721/100000 [1:06:42<42:57, 15.24it/s]
epoch 60700  training loss: 0.09767379611730576



 61%|██████    | 60811/100000 [1:06:47<46:13, 14.13it/s]
epoch 60800  training loss: 0.09767334908246994



 61%|██████    | 60903/100000 [1:06:54<42:53, 15.19it/s]
epoch 60900  training loss: 0.09767260402441025




 61%|██████    | 61025/100000 [1:07:02<42:38, 15.23it/s]
epoch 61000  training loss: 0.09767188131809235
epoch 61000  clean testing loss: 0.0019074224401265383



 61%|██████    | 61117/100000 [1:07:08<42:32, 15.23it/s]
epoch 61100  training loss: 0.09767115116119385



 61%|██████    | 61207/100000 [1:07:13<42:29, 15.21it/s]
epoch 61200  training loss: 0.09767032414674759




 61%|██████▏   | 61329/100000 [1:07:22<42:22, 15.21it/s]
epoch 61300  training loss: 0.09767016023397446



 61%|██████▏   | 61421/100000 [1:07:28<42:13, 15.23it/s]
epoch 61400  training loss: 0.09766902029514313



 62%|██████▏   | 61513/100000 [1:07:34<42:07, 15.23it/s]
epoch 61500  training loss: 0.09766840189695358



 62%|██████▏   | 61605/100000 [1:07:40<42:07, 15.19it/s]
epoch 61600  training loss: 0.09766791015863419




 62%|██████▏   | 61725/100000 [1:07:48<43:03, 14.82it/s]
epoch 61700  training loss: 0.09766720235347748



 62%|██████▏   | 61817/100000 [1:07:54<41:45, 15.24it/s]
epoch 61800  training loss: 0.09766656160354614



 62%|██████▏   | 61909/100000 [1:08:00<41:44, 15.21it/s]
epoch 61900  training loss: 0.0976659432053566



 62%|██████▏   | 62001/100000 [1:08:06<42:18, 14.97it/s]
epoch 62000  training loss: 0.09766526520252228
epoch 62000  clean testing loss: 0.0019107687985524535




 62%|██████▏   | 62115/100000 [1:08:13<41:29, 15.22it/s]
epoch 62100  training loss: 0.09766465425491333



 62%|██████▏   | 62205/100000 [1:08:19<41:33, 15.16it/s]
epoch 62200  training loss: 0.09766468405723572



 62%|██████▏   | 62297/100000 [1:08:25<41:14, 15.24it/s]
epoch 62300  training loss: 0.09766334295272827




 62%|██████▏   | 62419/100000 [1:08:33<41:06, 15.23it/s]
epoch 62400  training loss: 0.09766291826963425



 63%|██████▎   | 62511/100000 [1:08:39<41:06, 15.20it/s]
epoch 62500  training loss: 0.09766218066215515



 63%|██████▎   | 62603/100000 [1:08:45<41:03, 15.18it/s]
epoch 62600  training loss: 0.09766165167093277



 63%|██████▎   | 62693/100000 [1:08:51<40:46, 15.25it/s]
epoch 62700  training loss: 0.09766114503145218




 63%|██████▎   | 62815/100000 [1:08:59<40:42, 15.23it/s]
epoch 62800  training loss: 0.09766039997339249



 63%|██████▎   | 62907/100000 [1:09:05<40:38, 15.21it/s]
epoch 62900  training loss: 0.09765977412462234



 63%|██████▎   | 62999/100000 [1:09:11<40:28, 15.23it/s]
epoch 63000  training loss: 0.09765920788049698
epoch 63000  clean testing loss: 0.0019160949159413576




 63%|██████▎   | 63119/100000 [1:09:19<41:00, 14.99it/s]
epoch 63100  training loss: 0.09765860438346863



 63%|██████▎   | 63211/100000 [1:09:25<40:16, 15.23it/s]
epoch 63200  training loss: 0.09765814244747162



 63%|██████▎   | 63303/100000 [1:09:31<40:13, 15.21it/s]
epoch 63300  training loss: 0.09765753149986267



 63%|██████▎   | 63395/100000 [1:09:37<40:04, 15.22it/s]
epoch 63400  training loss: 0.09765730798244476




 64%|██████▎   | 63517/100000 [1:09:45<39:52, 15.25it/s]
epoch 63500  training loss: 0.09765675663948059



 64%|██████▎   | 63607/100000 [1:09:51<39:57, 15.18it/s]
epoch 63600  training loss: 0.09765606373548508



 64%|██████▎   | 63699/100000 [1:09:57<39:40, 15.25it/s]
epoch 63700  training loss: 0.09765562415122986




 64%|██████▍   | 63821/100000 [1:10:05<39:33, 15.24it/s]
epoch 63800  training loss: 0.09765509516000748



 64%|██████▍   | 63913/100000 [1:10:11<39:28, 15.24it/s]
epoch 63900  training loss: 0.09765446186065674



 64%|██████▍   | 64005/100000 [1:10:17<39:44, 15.10it/s]
epoch 64000  training loss: 0.09765402227640152
epoch 64000  clean testing loss: 0.0019203216070309281



 64%|██████▍   | 64095/100000 [1:10:23<39:20, 15.21it/s]
epoch 64100  training loss: 0.09765349328517914




 64%|██████▍   | 64217/100000 [1:10:31<39:08, 15.23it/s]
epoch 64200  training loss: 0.09765302389860153



 64%|██████▍   | 64309/100000 [1:10:37<39:03, 15.23it/s]
epoch 64300  training loss: 0.09765235334634781



 64%|██████▍   | 64401/100000 [1:10:43<38:57, 15.23it/s]
epoch 64400  training loss: 0.09765185415744781




 65%|██████▍   | 64523/100000 [1:10:52<38:48, 15.23it/s]
epoch 64500  training loss: 0.09765142947435379



 65%|██████▍   | 64613/100000 [1:10:57<38:42, 15.23it/s]
epoch 64600  training loss: 0.09765099734067917



 65%|██████▍   | 64705/100000 [1:11:03<38:42, 15.20it/s]
epoch 64700  training loss: 0.09765040874481201




 65%|██████▍   | 64827/100000 [1:11:12<38:29, 15.23it/s]
epoch 64800  training loss: 0.09764984250068665



 65%|██████▍   | 64919/100000 [1:11:18<38:27, 15.20it/s]
epoch 64900  training loss: 0.09764950722455978



 65%|██████▌   | 65011/100000 [1:11:24<38:21, 15.20it/s]
epoch 65000  training loss: 0.09764881432056427
epoch 65000  clean testing loss: 0.0019238261738792062



 65%|██████▌   | 65101/100000 [1:11:30<38:12, 15.23it/s]
epoch 65100  training loss: 0.09764841943979263




 65%|██████▌   | 65225/100000 [1:11:38<38:04, 15.22it/s]
epoch 65200  training loss: 0.09764789044857025



 65%|██████▌   | 65315/100000 [1:11:44<37:56, 15.24it/s]
epoch 65300  training loss: 0.09764738380908966



 65%|██████▌   | 65407/100000 [1:11:50<40:12, 14.34it/s]
epoch 65400  training loss: 0.0976475328207016




 66%|██████▌   | 65529/100000 [1:11:58<37:41, 15.24it/s]
epoch 65500  training loss: 0.09764643013477325



 66%|██████▌   | 65621/100000 [1:12:04<37:40, 15.21it/s]
epoch 65600  training loss: 0.0976460799574852



 66%|██████▌   | 65711/100000 [1:12:10<37:29, 15.24it/s]
epoch 65700  training loss: 0.09764531254768372



 66%|██████▌   | 65803/100000 [1:12:16<37:33, 15.17it/s]
epoch 65800  training loss: 0.09764467179775238




 66%|██████▌   | 65925/100000 [1:12:24<37:14, 15.25it/s]
epoch 65900  training loss: 0.0976453423500061



 66%|██████▌   | 66017/100000 [1:12:30<37:12, 15.22it/s]
epoch 66000  training loss: 0.09764397889375687
epoch 66000  clean testing loss: 0.0019289077026769519



 66%|██████▌   | 66109/100000 [1:12:36<37:06, 15.22it/s]
epoch 66100  training loss: 0.09764329344034195




 66%|██████▌   | 66231/100000 [1:12:44<36:54, 15.25it/s]
epoch 66200  training loss: 0.09764302521944046



 66%|██████▋   | 66323/100000 [1:12:50<36:49, 15.24it/s]
epoch 66300  training loss: 0.09764258563518524



 66%|██████▋   | 66413/100000 [1:12:56<36:46, 15.22it/s]
epoch 66400  training loss: 0.09764206409454346



 67%|██████▋   | 66505/100000 [1:13:02<36:42, 15.21it/s]
epoch 66500  training loss: 0.09764174371957779




 67%|██████▋   | 66627/100000 [1:13:10<36:29, 15.24it/s]
epoch 66600  training loss: 0.09764141589403152



 67%|██████▋   | 66719/100000 [1:13:16<36:26, 15.22it/s]
epoch 66700  training loss: 0.09764092415571213



 67%|██████▋   | 66809/100000 [1:13:22<36:21, 15.21it/s]
epoch 66800  training loss: 0.09764047712087631



 67%|██████▋   | 66901/100000 [1:13:28<36:12, 15.23it/s]
epoch 66900  training loss: 0.09764005243778229




 67%|██████▋   | 67023/100000 [1:13:36<36:02, 15.25it/s]
epoch 67000  training loss: 0.09764104336500168
epoch 67000  clean testing loss: 0.0019304915331304073



 67%|██████▋   | 67115/100000 [1:13:42<35:58, 15.24it/s]
epoch 67100  training loss: 0.09763918071985245



 67%|██████▋   | 67207/100000 [1:13:48<35:55, 15.21it/s]
epoch 67200  training loss: 0.09763891249895096




 67%|██████▋   | 67327/100000 [1:13:56<35:44, 15.24it/s]
epoch 67300  training loss: 0.0976383239030838



 67%|██████▋   | 67419/100000 [1:14:02<35:39, 15.23it/s]
epoch 67400  training loss: 0.09763879328966141



 68%|██████▊   | 67511/100000 [1:14:08<35:34, 15.22it/s]
epoch 67500  training loss: 0.09763769805431366



 68%|██████▊   | 67603/100000 [1:14:14<35:33, 15.19it/s]
epoch 67600  training loss: 0.09763709455728531




 68%|██████▊   | 67723/100000 [1:14:22<35:29, 15.16it/s]
epoch 67700  training loss: 0.09763716906309128



 68%|██████▊   | 67815/100000 [1:14:28<35:12, 15.23it/s]
epoch 67800  training loss: 0.09763642400503159



 68%|██████▊   | 67907/100000 [1:14:34<35:10, 15.20it/s]
epoch 67900  training loss: 0.09763593971729279




 68%|██████▊   | 68029/100000 [1:14:42<34:57, 15.24it/s]
epoch 68000  training loss: 0.09763537347316742
epoch 68000  clean testing loss: 0.001937135704793036



 68%|██████▊   | 68121/100000 [1:14:48<34:51, 15.24it/s]
epoch 68100  training loss: 0.09763527661561966



 68%|██████▊   | 68211/100000 [1:14:54<34:47, 15.23it/s]
epoch 68200  training loss: 0.09763483703136444



 68%|██████▊   | 68303/100000 [1:15:00<34:47, 15.19it/s]
epoch 68300  training loss: 0.0976344645023346




 68%|██████▊   | 68425/100000 [1:15:08<34:33, 15.23it/s]
epoch 68400  training loss: 0.0976337417960167



 69%|██████▊   | 68517/100000 [1:15:14<34:27, 15.23it/s]
epoch 68500  training loss: 0.09763327240943909



 69%|██████▊   | 68609/100000 [1:15:20<34:23, 15.21it/s]
epoch 68600  training loss: 0.09763319790363312




 69%|██████▊   | 68729/100000 [1:15:28<34:11, 15.25it/s]
epoch 68700  training loss: 0.09763278812170029



 69%|██████▉   | 68821/100000 [1:15:34<34:06, 15.23it/s]
epoch 68800  training loss: 0.09763219952583313



 69%|██████▉   | 68913/100000 [1:15:40<34:01, 15.23it/s]
epoch 68900  training loss: 0.0976317822933197



 69%|██████▉   | 69005/100000 [1:15:46<34:11, 15.11it/s]
epoch 69000  training loss: 0.09763137251138687
epoch 69000  clean testing loss: 0.0019413329428061843




 69%|██████▉   | 69125/100000 [1:15:54<33:46, 15.23it/s]
epoch 69100  training loss: 0.09763097018003464



 69%|██████▉   | 69209/100000 [1:16:00<33:42, 15.22it/s]
epoch 69200  training loss: 0.0976308062672615



 69%|██████▉   | 69301/100000 [1:16:06<33:36, 15.23it/s]
epoch 69300  training loss: 0.09763031452894211



 69%|██████▉   | 69393/100000 [1:16:12<33:27, 15.24it/s]
epoch 69400  training loss: 0.09763026982545853




 70%|██████▉   | 69515/100000 [1:16:20<33:20, 15.24it/s]
epoch 69500  training loss: 0.09762965887784958



 70%|██████▉   | 69605/100000 [1:16:26<33:23, 15.17it/s]
epoch 69600  training loss: 0.09762944281101227



 70%|██████▉   | 69697/100000 [1:16:32<33:08, 15.24it/s]
epoch 69700  training loss: 0.09762905538082123




 70%|██████▉   | 69819/100000 [1:16:40<33:02, 15.22it/s]
epoch 69800  training loss: 0.09762868285179138



 70%|██████▉   | 69911/100000 [1:16:46<32:54, 15.24it/s]
epoch 69900  training loss: 0.09762868285179138



 70%|███████   | 70003/100000 [1:16:52<34:44, 14.39it/s]
epoch 70000  training loss: 0.09762798994779587
epoch 70000  clean testing loss: 0.0019448130624368787



 70%|███████   | 70093/100000 [1:16:58<32:46, 15.21it/s]
epoch 70100  training loss: 0.09762769192457199




 70%|███████   | 70215/100000 [1:17:06<32:37, 15.22it/s]
epoch 70200  training loss: 0.09762735664844513



 70%|███████   | 70307/100000 [1:17:12<32:31, 15.21it/s]
epoch 70300  training loss: 0.0976269394159317



 70%|███████   | 70399/100000 [1:17:18<32:23, 15.23it/s]
epoch 70400  training loss: 0.09762658178806305




 71%|███████   | 70521/100000 [1:17:26<32:14, 15.24it/s]
epoch 70500  training loss: 0.09762661159038544



 71%|███████   | 70613/100000 [1:17:32<32:15, 15.18it/s]
epoch 70600  training loss: 0.09762610495090485



 71%|███████   | 70703/100000 [1:17:38<32:10, 15.18it/s]
epoch 70700  training loss: 0.09762554615736008



 71%|███████   | 70795/100000 [1:17:44<31:56, 15.24it/s]
epoch 70800  training loss: 0.09762559831142426




 71%|███████   | 70917/100000 [1:17:52<34:10, 14.18it/s]
epoch 70900  training loss: 0.09762512892484665



 71%|███████   | 71007/100000 [1:17:58<31:53, 15.16it/s]
epoch 71000  training loss: 0.09762463718652725
epoch 71000  clean testing loss: 0.001948744524270296



 71%|███████   | 71099/100000 [1:18:04<31:36, 15.24it/s]
epoch 71100  training loss: 0.09762442111968994




 71%|███████   | 71221/100000 [1:18:12<31:28, 15.24it/s]
epoch 71200  training loss: 0.09762407839298248



 71%|███████▏  | 71313/100000 [1:18:18<31:24, 15.23it/s]
epoch 71300  training loss: 0.09762363880872726



 71%|███████▏  | 71405/100000 [1:18:24<31:22, 15.19it/s]
epoch 71400  training loss: 0.09762326627969742




 72%|███████▏  | 71527/100000 [1:18:32<31:08, 15.24it/s]
epoch 71500  training loss: 0.09762290120124817



 72%|███████▏  | 71617/100000 [1:18:38<31:02, 15.24it/s]
epoch 71600  training loss: 0.09762261062860489



 72%|███████▏  | 71709/100000 [1:18:44<30:59, 15.21it/s]
epoch 71700  training loss: 0.09762226790189743



 72%|███████▏  | 71801/100000 [1:18:50<30:51, 15.23it/s]
epoch 71800  training loss: 0.09762208163738251




 72%|███████▏  | 71923/100000 [1:18:58<30:42, 15.24it/s]
epoch 71900  training loss: 0.09762173891067505



 72%|███████▏  | 72013/100000 [1:19:04<30:40, 15.20it/s]
epoch 72000  training loss: 0.0976213663816452
epoch 72000  clean testing loss: 0.00195253174751997



 72%|███████▏  | 72105/100000 [1:19:10<30:36, 15.19it/s]
epoch 72100  training loss: 0.09762105345726013




 72%|███████▏  | 72227/100000 [1:19:18<30:22, 15.24it/s]
epoch 72200  training loss: 0.09762077778577805



 72%|███████▏  | 72319/100000 [1:19:24<30:21, 15.20it/s]
epoch 72300  training loss: 0.09762060642242432



 72%|███████▏  | 72409/100000 [1:19:30<30:11, 15.23it/s]
epoch 72400  training loss: 0.09762027114629745



 73%|███████▎  | 72501/100000 [1:19:36<30:05, 15.23it/s]
epoch 72500  training loss: 0.09762001037597656




 73%|███████▎  | 72623/100000 [1:19:44<29:56, 15.24it/s]
epoch 72600  training loss: 0.09761984646320343



 73%|███████▎  | 72715/100000 [1:19:50<29:51, 15.23it/s]
epoch 72700  training loss: 0.09761936962604523



 73%|███████▎  | 72805/100000 [1:19:56<29:48, 15.20it/s]
epoch 72800  training loss: 0.0976191833615303




 73%|███████▎  | 72929/100000 [1:20:04<29:34, 15.25it/s]
epoch 72900  training loss: 0.09761884808540344



 73%|███████▎  | 73019/100000 [1:20:10<29:30, 15.24it/s]
epoch 73000  training loss: 0.09761863946914673
epoch 73000  clean testing loss: 0.0019555699545890093



 73%|███████▎  | 73111/100000 [1:20:16<29:25, 15.23it/s]
epoch 73100  training loss: 0.09761832654476166



 73%|███████▎  | 73203/100000 [1:20:22<29:23, 15.20it/s]
epoch 73200  training loss: 0.09761810302734375




 73%|███████▎  | 73325/100000 [1:20:30<29:08, 15.25it/s]
epoch 73300  training loss: 0.09761793911457062



 73%|███████▎  | 73417/100000 [1:20:36<29:03, 15.25it/s]
epoch 73400  training loss: 0.09761771559715271



 74%|███████▎  | 73507/100000 [1:20:42<28:59, 15.23it/s]
epoch 73500  training loss: 0.09761747717857361




 74%|███████▎  | 73629/100000 [1:20:50<28:49, 15.25it/s]
epoch 73600  training loss: 0.09761697053909302



 74%|███████▎  | 73721/100000 [1:20:56<28:43, 15.25it/s]
epoch 73700  training loss: 0.09761682897806168



 74%|███████▍  | 73813/100000 [1:21:02<28:38, 15.24it/s]
epoch 73800  training loss: 0.0976165160536766



 74%|███████▍  | 73905/100000 [1:21:08<28:34, 15.22it/s]
epoch 73900  training loss: 0.09761621803045273




 74%|███████▍  | 74027/100000 [1:21:16<28:23, 15.25it/s]
epoch 74000  training loss: 0.09761592745780945
epoch 74000  clean testing loss: 0.001959963236004114



 74%|███████▍  | 74117/100000 [1:21:22<28:17, 15.24it/s]
epoch 74100  training loss: 0.09761550277471542



 74%|███████▍  | 74209/100000 [1:21:28<28:13, 15.23it/s]
epoch 74200  training loss: 0.09761518985033035



 74%|███████▍  | 74301/100000 [1:21:34<28:07, 15.23it/s]
epoch 74300  training loss: 0.097615085542202




 74%|███████▍  | 74423/100000 [1:21:42<27:57, 15.25it/s]
epoch 74400  training loss: 0.09761489182710648



 75%|███████▍  | 74515/100000 [1:21:48<27:52, 15.24it/s]
epoch 74500  training loss: 0.09761439263820648



 75%|███████▍  | 74605/100000 [1:21:54<28:05, 15.06it/s]
epoch 74600  training loss: 0.09761443734169006




 75%|███████▍  | 74727/100000 [1:22:02<27:37, 15.25it/s]
epoch 74700  training loss: 0.0976141020655632



 75%|███████▍  | 74819/100000 [1:22:08<27:31, 15.25it/s]
epoch 74800  training loss: 0.0976138785481453



 75%|███████▍  | 74911/100000 [1:22:14<27:26, 15.24it/s]
epoch 74900  training loss: 0.09761351346969604



 75%|███████▌  | 75003/100000 [1:22:21<27:38, 15.08it/s]
epoch 75000  training loss: 0.09761317074298859
epoch 75000  clean testing loss: 0.001962257781997323




 75%|███████▌  | 75123/100000 [1:22:28<27:11, 15.25it/s]
epoch 75100  training loss: 0.09761317819356918



 75%|███████▌  | 75215/100000 [1:22:34<27:07, 15.23it/s]
epoch 75200  training loss: 0.09761260449886322



 75%|███████▌  | 75307/100000 [1:22:41<27:01, 15.22it/s]
epoch 75300  training loss: 0.09761246293783188




 75%|███████▌  | 75429/100000 [1:22:49<26:51, 15.25it/s]
epoch 75400  training loss: 0.09761234372854233



 76%|███████▌  | 75519/100000 [1:22:54<27:31, 14.82it/s]
epoch 75500  training loss: 0.09761207550764084



 76%|███████▌  | 75611/100000 [1:23:01<26:40, 15.24it/s]
epoch 75600  training loss: 0.09761177748441696



 76%|███████▌  | 75703/100000 [1:23:07<26:39, 15.19it/s]
epoch 75700  training loss: 0.09761162102222443




 76%|███████▌  | 75825/100000 [1:23:15<26:25, 15.25it/s]
epoch 75800  training loss: 0.09761149436235428



 76%|███████▌  | 75909/100000 [1:23:20<26:26, 15.18it/s]
epoch 75900  training loss: 0.09761114418506622



 76%|███████▌  | 75999/100000 [1:23:26<26:15, 15.23it/s]
epoch 76000  training loss: 0.0976109504699707
epoch 76000  clean testing loss: 0.0019644154235720634




 76%|███████▌  | 76121/100000 [1:23:34<26:06, 15.24it/s]
epoch 76100  training loss: 0.09761063009500504



 76%|███████▌  | 76213/100000 [1:23:40<26:08, 15.17it/s]
epoch 76200  training loss: 0.09761051833629608



 76%|███████▋  | 76305/100000 [1:23:46<26:00, 15.19it/s]
epoch 76300  training loss: 0.09761007130146027



 76%|███████▋  | 76397/100000 [1:23:52<25:48, 15.24it/s]
epoch 76400  training loss: 0.09761007130146027




 77%|███████▋  | 76519/100000 [1:24:00<25:40, 15.24it/s]
epoch 76500  training loss: 0.097609743475914



 77%|███████▋  | 76609/100000 [1:24:06<25:36, 15.22it/s]
epoch 76600  training loss: 0.09760960191488266



 77%|███████▋  | 76701/100000 [1:24:12<25:29, 15.23it/s]
epoch 76700  training loss: 0.0976092740893364



 77%|███████▋  | 76793/100000 [1:24:18<25:23, 15.24it/s]
epoch 76800  training loss: 0.09760896116495132




 77%|███████▋  | 76915/100000 [1:24:26<25:16, 15.22it/s]
epoch 76900  training loss: 0.09760889410972595



 77%|███████▋  | 77005/100000 [1:24:32<25:21, 15.11it/s]
epoch 77000  training loss: 0.0976085513830185
epoch 77000  clean testing loss: 0.001966756070032716



 77%|███████▋  | 77097/100000 [1:24:38<25:02, 15.24it/s]
epoch 77100  training loss: 0.0976085364818573




 77%|███████▋  | 77219/100000 [1:24:46<24:54, 15.24it/s]
epoch 77200  training loss: 0.09760822355747223



 77%|███████▋  | 77311/100000 [1:24:52<24:50, 15.22it/s]
epoch 77300  training loss: 0.09760799258947372



 77%|███████▋  | 77403/100000 [1:24:58<24:47, 15.19it/s]
epoch 77400  training loss: 0.09760784357786179



 77%|███████▋  | 77493/100000 [1:25:04<24:37, 15.24it/s]
epoch 77500  training loss: 0.0976075753569603




 78%|███████▊  | 77615/100000 [1:25:12<24:29, 15.23it/s]
epoch 77600  training loss: 0.09760744124650955



 78%|███████▊  | 77707/100000 [1:25:18<24:25, 15.21it/s]
epoch 77700  training loss: 0.0976070985198021



 78%|███████▊  | 77799/100000 [1:25:24<24:17, 15.23it/s]
epoch 77800  training loss: 0.09760682284832001




 78%|███████▊  | 77921/100000 [1:25:32<24:08, 15.24it/s]
epoch 77900  training loss: 0.09760677069425583



 78%|███████▊  | 78011/100000 [1:25:38<24:06, 15.20it/s]
epoch 78000  training loss: 0.09760652482509613
epoch 78000  clean testing loss: 0.0019696245435625315



 78%|███████▊  | 78103/100000 [1:25:44<24:02, 15.18it/s]
epoch 78100  training loss: 0.09760615974664688




 78%|███████▊  | 78225/100000 [1:25:52<23:49, 15.24it/s]
epoch 78200  training loss: 0.0976061150431633



 78%|███████▊  | 78317/100000 [1:25:58<23:42, 15.24it/s]
epoch 78300  training loss: 0.09760580211877823



 78%|███████▊  | 78407/100000 [1:26:04<23:39, 15.21it/s]
epoch 78400  training loss: 0.0976056233048439




 79%|███████▊  | 78529/100000 [1:26:12<23:28, 15.24it/s]
epoch 78500  training loss: 0.09760560840368271



 79%|███████▊  | 78621/100000 [1:26:18<23:22, 15.24it/s]
epoch 78600  training loss: 0.0976053774356842



 79%|███████▊  | 78713/100000 [1:26:24<23:17, 15.23it/s]
epoch 78700  training loss: 0.0976051390171051



 79%|███████▉  | 78803/100000 [1:26:30<23:16, 15.18it/s]
epoch 78800  training loss: 0.09760496765375137




 79%|███████▉  | 78925/100000 [1:26:38<23:03, 15.23it/s]
epoch 78900  training loss: 0.09760483354330063



 79%|███████▉  | 79017/100000 [1:26:45<22:59, 15.22it/s]
epoch 79000  training loss: 0.09760455787181854
epoch 79000  clean testing loss: 0.001971864840015769



 79%|███████▉  | 79109/100000 [1:26:51<22:52, 15.23it/s]
epoch 79100  training loss: 0.09760430455207825




 79%|███████▉  | 79231/100000 [1:26:59<22:42, 15.24it/s]
epoch 79200  training loss: 0.09760425984859467



 79%|███████▉  | 79321/100000 [1:27:05<22:36, 15.24it/s]
epoch 79300  training loss: 0.09760400652885437



 79%|███████▉  | 79413/100000 [1:27:11<22:31, 15.23it/s]
epoch 79400  training loss: 0.09760380536317825



 80%|███████▉  | 79505/100000 [1:27:17<22:27, 15.21it/s]
epoch 79500  training loss: 0.09760349988937378




 80%|███████▉  | 79627/100000 [1:27:25<22:17, 15.23it/s]
epoch 79600  training loss: 0.09760359674692154



 80%|███████▉  | 79719/100000 [1:27:31<22:11, 15.24it/s]
epoch 79700  training loss: 0.09760323166847229



 80%|███████▉  | 79809/100000 [1:27:37<22:06, 15.22it/s]
epoch 79800  training loss: 0.09760303050279617



 80%|███████▉  | 79901/100000 [1:27:43<21:59, 15.23it/s]
epoch 79900  training loss: 0.09760290384292603




 80%|████████  | 80023/100000 [1:27:51<21:50, 15.24it/s]
epoch 80000  training loss: 0.09760276973247528
epoch 80000  clean testing loss: 0.0019736620597541332



 80%|████████  | 80115/100000 [1:27:57<21:49, 15.18it/s]
epoch 80100  training loss: 0.09760259836912155



 80%|████████  | 80205/100000 [1:28:03<21:41, 15.21it/s]
epoch 80200  training loss: 0.09760213643312454




 80%|████████  | 80327/100000 [1:28:11<21:30, 15.24it/s]
epoch 80300  training loss: 0.09760220348834991



 80%|████████  | 80419/100000 [1:28:17<21:25, 15.24it/s]
epoch 80400  training loss: 0.09760179370641708



 81%|████████  | 80511/100000 [1:28:23<21:20, 15.22it/s]
epoch 80500  training loss: 0.09760191291570663



 81%|████████  | 80601/100000 [1:28:29<21:14, 15.22it/s]
epoch 80600  training loss: 0.09760160744190216




 81%|████████  | 80723/100000 [1:28:37<21:04, 15.24it/s]
epoch 80700  training loss: 0.09760136157274246



 81%|████████  | 80815/100000 [1:28:43<20:59, 15.23it/s]
epoch 80800  training loss: 0.09760122746229172



 81%|████████  | 80907/100000 [1:28:49<20:56, 15.20it/s]
epoch 80900  training loss: 0.09760114550590515




 81%|████████  | 81029/100000 [1:28:57<20:52, 15.15it/s]
epoch 81000  training loss: 0.09760086238384247
epoch 81000  clean testing loss: 0.0019763100426644087



 81%|████████  | 81119/100000 [1:29:03<20:38, 15.24it/s]
epoch 81100  training loss: 0.09760069847106934



 81%|████████  | 81211/100000 [1:29:09<20:34, 15.22it/s]
epoch 81200  training loss: 0.09760043770074844



 81%|████████▏ | 81303/100000 [1:29:15<20:31, 15.19it/s]
epoch 81300  training loss: 0.09760034084320068




 81%|████████▏ | 81425/100000 [1:29:23<20:18, 15.24it/s]
epoch 81400  training loss: 0.09760027378797531



 82%|████████▏ | 81517/100000 [1:29:29<20:12, 15.24it/s]
epoch 81500  training loss: 0.097600057721138



 82%|████████▏ | 81607/100000 [1:29:35<20:10, 15.20it/s]
epoch 81600  training loss: 0.09759987890720367




 82%|████████▏ | 81729/100000 [1:29:43<19:59, 15.24it/s]
epoch 81700  training loss: 0.0975998044013977



 82%|████████▏ | 81821/100000 [1:29:49<19:52, 15.24it/s]
epoch 81800  training loss: 0.09759967774152756



 82%|████████▏ | 81913/100000 [1:29:55<19:47, 15.23it/s]
epoch 81900  training loss: 0.09759952127933502



 82%|████████▏ | 82003/100000 [1:30:01<19:53, 15.08it/s]
epoch 82000  training loss: 0.09759917855262756
epoch 82000  clean testing loss: 0.0019776206463575363




 82%|████████▏ | 82125/100000 [1:30:09<19:33, 15.23it/s]
epoch 82100  training loss: 0.09759926795959473



 82%|████████▏ | 82217/100000 [1:30:15<19:26, 15.24it/s]
epoch 82200  training loss: 0.09759899973869324



 82%|████████▏ | 82309/100000 [1:30:21<19:22, 15.22it/s]
epoch 82300  training loss: 0.09759890288114548




 82%|████████▏ | 82431/100000 [1:30:29<19:12, 15.24it/s]
epoch 82400  training loss: 0.09759865701198578



 83%|████████▎ | 82521/100000 [1:30:35<19:06, 15.24it/s]
epoch 82500  training loss: 0.0975986123085022



 83%|████████▎ | 82613/100000 [1:30:41<19:01, 15.23it/s]
epoch 82600  training loss: 0.0975983589887619



 83%|████████▎ | 82697/100000 [1:30:47<18:55, 15.24it/s]
epoch 82700  training loss: 0.09759817272424698




 83%|████████▎ | 82819/100000 [1:30:55<18:46, 15.25it/s]
epoch 82800  training loss: 0.09759807586669922



 83%|████████▎ | 82911/100000 [1:31:01<18:42, 15.22it/s]
epoch 82900  training loss: 0.09759791195392609



 83%|████████▎ | 83003/100000 [1:31:07<18:48, 15.06it/s]
epoch 83000  training loss: 0.0975978821516037
epoch 83000  clean testing loss: 0.0019795813132077456



 83%|████████▎ | 83093/100000 [1:31:13<18:29, 15.24it/s]
epoch 83100  training loss: 0.0975976511836052




 83%|████████▎ | 83215/100000 [1:31:21<18:21, 15.24it/s]
epoch 83200  training loss: 0.09759742021560669



 83%|████████▎ | 83307/100000 [1:31:27<20:04, 13.86it/s]
epoch 83300  training loss: 0.09759724140167236



 83%|████████▎ | 83399/100000 [1:31:33<18:08, 15.24it/s]
epoch 83400  training loss: 0.09759719669818878




 84%|████████▎ | 83521/100000 [1:31:41<18:01, 15.24it/s]
epoch 83500  training loss: 0.09759682416915894



 84%|████████▎ | 83611/100000 [1:31:47<17:56, 15.23it/s]
epoch 83600  training loss: 0.09759694337844849



 84%|████████▎ | 83703/100000 [1:31:53<17:52, 15.19it/s]
epoch 83700  training loss: 0.09759657084941864



 84%|████████▍ | 83795/100000 [1:31:59<17:43, 15.24it/s]
epoch 83800  training loss: 0.09759655594825745




 84%|████████▍ | 83917/100000 [1:32:07<17:35, 15.24it/s]
epoch 83900  training loss: 0.09759632498025894



 84%|████████▍ | 84009/100000 [1:32:13<17:33, 15.17it/s]
epoch 84000  training loss: 0.09759626537561417
epoch 84000  clean testing loss: 0.0019811291713267565



 84%|████████▍ | 84099/100000 [1:32:19<17:23, 15.24it/s]
epoch 84100  training loss: 0.09759622812271118




 84%|████████▍ | 84221/100000 [1:32:27<17:15, 15.23it/s]
epoch 84200  training loss: 0.09759606420993805



 84%|████████▍ | 84313/100000 [1:32:33<17:10, 15.23it/s]
epoch 84300  training loss: 0.09759588539600372



 84%|████████▍ | 84405/100000 [1:32:39<17:05, 15.20it/s]
epoch 84400  training loss: 0.09759590774774551



 84%|████████▍ | 84495/100000 [1:32:45<16:56, 15.25it/s]
epoch 84500  training loss: 0.09759559482336044




 85%|████████▍ | 84617/100000 [1:32:53<16:49, 15.23it/s]
epoch 84600  training loss: 0.09759553521871567



 85%|████████▍ | 84709/100000 [1:32:59<16:44, 15.22it/s]
epoch 84700  training loss: 0.0975954532623291



 85%|████████▍ | 84801/100000 [1:33:05<16:38, 15.23it/s]
epoch 84800  training loss: 0.0975952222943306




 85%|████████▍ | 84923/100000 [1:33:13<16:28, 15.25it/s]
epoch 84900  training loss: 0.09759502857923508



 85%|████████▌ | 85013/100000 [1:33:19<16:25, 15.21it/s]
epoch 85000  training loss: 0.09759487956762314
epoch 85000  clean testing loss: 0.0019824858754873276



 85%|████████▌ | 85105/100000 [1:33:25<16:20, 15.20it/s]
epoch 85100  training loss: 0.0975949689745903




 85%|████████▌ | 85227/100000 [1:33:33<16:09, 15.24it/s]
epoch 85200  training loss: 0.09759471565485



 85%|████████▌ | 85319/100000 [1:33:39<16:03, 15.24it/s]
epoch 85300  training loss: 0.09759457409381866



 85%|████████▌ | 85409/100000 [1:33:45<15:58, 15.22it/s]
epoch 85400  training loss: 0.09759456664323807



 86%|████████▌ | 85501/100000 [1:33:51<15:51, 15.23it/s]
epoch 85500  training loss: 0.09759426862001419




 86%|████████▌ | 85623/100000 [1:33:59<15:44, 15.23it/s]
epoch 85600  training loss: 0.09759435802698135



 86%|████████▌ | 85715/100000 [1:34:05<15:38, 15.23it/s]
epoch 85700  training loss: 0.09759405255317688



 86%|████████▌ | 85807/100000 [1:34:11<15:33, 15.21it/s]
epoch 85800  training loss: 0.09759396314620972




 86%|████████▌ | 85929/100000 [1:34:19<15:23, 15.24it/s]
epoch 85900  training loss: 0.0975937768816948



 86%|████████▌ | 86019/100000 [1:34:25<15:18, 15.22it/s]
epoch 86000  training loss: 0.09759368747472763
epoch 86000  clean testing loss: 0.0019839522428810596



 86%|████████▌ | 86111/100000 [1:34:31<15:12, 15.22it/s]
epoch 86100  training loss: 0.09759356081485748



 86%|████████▌ | 86203/100000 [1:34:37<15:11, 15.14it/s]
epoch 86200  training loss: 0.0975932702422142




 86%|████████▋ | 86325/100000 [1:34:45<14:57, 15.23it/s]
epoch 86300  training loss: 0.0975932702422142



 86%|████████▋ | 86415/100000 [1:34:51<14:52, 15.23it/s]
epoch 86400  training loss: 0.09759309887886047



 87%|████████▋ | 86507/100000 [1:34:57<14:47, 15.21it/s]
epoch 86500  training loss: 0.0975930243730545




 87%|████████▋ | 86629/100000 [1:35:05<14:37, 15.24it/s]
epoch 86600  training loss: 0.09759283810853958



 87%|████████▋ | 86721/100000 [1:35:11<14:31, 15.24it/s]
epoch 86700  training loss: 0.09759262204170227



 87%|████████▋ | 86811/100000 [1:35:17<14:25, 15.23it/s]
epoch 86800  training loss: 0.09759251773357391



 87%|████████▋ | 86903/100000 [1:35:23<14:22, 15.18it/s]
epoch 86900  training loss: 0.09759245812892914




 87%|████████▋ | 87025/100000 [1:35:31<14:11, 15.24it/s]
epoch 87000  training loss: 0.09759239107370377
epoch 87000  clean testing loss: 0.001985298004001379



 87%|████████▋ | 87117/100000 [1:35:37<14:05, 15.24it/s]
epoch 87100  training loss: 0.09759239852428436



 87%|████████▋ | 87209/100000 [1:35:43<14:00, 15.23it/s]
epoch 87200  training loss: 0.09759234637022018




 87%|████████▋ | 87331/100000 [1:35:51<13:51, 15.24it/s]
epoch 87300  training loss: 0.09759195148944855



 87%|████████▋ | 87421/100000 [1:35:57<13:45, 15.24it/s]
epoch 87400  training loss: 0.09759195894002914



 88%|████████▊ | 87513/100000 [1:36:03<13:39, 15.23it/s]
epoch 87500  training loss: 0.09759204089641571



 88%|████████▊ | 87605/100000 [1:36:09<13:38, 15.14it/s]
epoch 87600  training loss: 0.09759170562028885




 88%|████████▊ | 87727/100000 [1:36:17<13:24, 15.25it/s]
epoch 87700  training loss: 0.09759168326854706



 88%|████████▊ | 87817/100000 [1:36:23<13:20, 15.22it/s]
epoch 87800  training loss: 0.09759146720170975



 88%|████████▊ | 87909/100000 [1:36:29<13:17, 15.16it/s]
epoch 87900  training loss: 0.09759146720170975



 88%|████████▊ | 88001/100000 [1:36:35<13:21, 14.97it/s]
epoch 88000  training loss: 0.09759123623371124
epoch 88000  clean testing loss: 0.001986403251066804




 88%|████████▊ | 88123/100000 [1:36:43<12:59, 15.23it/s]
epoch 88100  training loss: 0.09759118407964706



 88%|████████▊ | 88213/100000 [1:36:49<12:53, 15.23it/s]
epoch 88200  training loss: 0.09759119898080826



 88%|████████▊ | 88305/100000 [1:36:55<12:49, 15.19it/s]
epoch 88300  training loss: 0.0975910872220993




 88%|████████▊ | 88427/100000 [1:37:03<12:39, 15.24it/s]
epoch 88400  training loss: 0.09759082645177841



 89%|████████▊ | 88519/100000 [1:37:09<12:34, 15.22it/s]
epoch 88500  training loss: 0.09759090095758438



 89%|████████▊ | 88609/100000 [1:37:15<12:29, 15.20it/s]
epoch 88600  training loss: 0.0975908637046814



 89%|████████▊ | 88701/100000 [1:37:21<12:22, 15.23it/s]
epoch 88700  training loss: 0.09759052097797394




 89%|████████▉ | 88823/100000 [1:37:29<12:18, 15.13it/s]
epoch 88800  training loss: 0.09759063273668289



 89%|████████▉ | 88915/100000 [1:37:36<12:07, 15.23it/s]
epoch 88900  training loss: 0.09759034216403961



 89%|████████▉ | 89005/100000 [1:37:41<12:07, 15.12it/s]
epoch 89000  training loss: 0.09759022295475006
epoch 89000  clean testing loss: 0.0019878484308719635




 89%|████████▉ | 89127/100000 [1:37:49<11:53, 15.23it/s]
epoch 89100  training loss: 0.09759026765823364



 89%|████████▉ | 89219/100000 [1:37:55<11:47, 15.24it/s]
epoch 89200  training loss: 0.09759005904197693



 89%|████████▉ | 89311/100000 [1:38:02<11:41, 15.23it/s]
epoch 89300  training loss: 0.09759002178907394



 89%|████████▉ | 89401/100000 [1:38:07<11:36, 15.22it/s]
epoch 89400  training loss: 0.09758967906236649




 90%|████████▉ | 89517/100000 [1:38:15<11:28, 15.22it/s]
epoch 89500  training loss: 0.09758979082107544



 90%|████████▉ | 89607/100000 [1:38:21<11:23, 15.20it/s]
epoch 89600  training loss: 0.0975896492600441



 90%|████████▉ | 89699/100000 [1:38:27<11:16, 15.22it/s]
epoch 89700  training loss: 0.09758943319320679




 90%|████████▉ | 89821/100000 [1:38:35<11:11, 15.16it/s]
epoch 89800  training loss: 0.09758934378623962



 90%|████████▉ | 89913/100000 [1:38:41<11:02, 15.23it/s]
epoch 89900  training loss: 0.09758920967578888



 90%|█████████ | 90003/100000 [1:38:47<11:03, 15.06it/s]
epoch 90000  training loss: 0.09758907556533813
epoch 90000  clean testing loss: 0.001988788601011038



 90%|█████████ | 90095/100000 [1:38:53<10:50, 15.24it/s]
epoch 90100  training loss: 0.09758923202753067




 90%|█████████ | 90217/100000 [1:39:01<10:42, 15.23it/s]
epoch 90200  training loss: 0.09758898615837097



 90%|█████████ | 90309/100000 [1:39:07<10:36, 15.21it/s]
epoch 90300  training loss: 0.09758895635604858



 90%|█████████ | 90399/100000 [1:39:13<10:30, 15.24it/s]
epoch 90400  training loss: 0.09758879989385605




 91%|█████████ | 90521/100000 [1:39:21<10:22, 15.23it/s]
epoch 90500  training loss: 0.09758873283863068



 91%|█████████ | 90613/100000 [1:39:27<10:16, 15.23it/s]
epoch 90600  training loss: 0.09758877754211426



 91%|█████████ | 90705/100000 [1:39:33<10:11, 15.21it/s]
epoch 90700  training loss: 0.09758879244327545



 91%|█████████ | 90795/100000 [1:39:39<10:04, 15.23it/s]
epoch 90800  training loss: 0.09758850932121277




 91%|█████████ | 90917/100000 [1:39:47<09:57, 15.20it/s]
epoch 90900  training loss: 0.09758846461772919



 91%|█████████ | 91009/100000 [1:39:53<09:54, 15.13it/s]
epoch 91000  training loss: 0.09758846461772919
epoch 91000  clean testing loss: 0.001989601878449321



 91%|█████████ | 91101/100000 [1:39:59<10:25, 14.23it/s]
epoch 91100  training loss: 0.0975882038474083




 91%|█████████ | 91223/100000 [1:40:07<09:36, 15.22it/s]
epoch 91200  training loss: 0.09758803248405457



 91%|█████████▏| 91313/100000 [1:40:13<09:30, 15.23it/s]
epoch 91300  training loss: 0.09758804738521576



 91%|█████████▏| 91405/100000 [1:40:19<09:26, 15.17it/s]
epoch 91400  training loss: 0.09758810698986053



 91%|█████████▏| 91497/100000 [1:40:25<09:17, 15.24it/s]
epoch 91500  training loss: 0.09758789092302322




 92%|█████████▏| 91619/100000 [1:40:33<09:10, 15.23it/s]
epoch 91600  training loss: 0.09758787602186203



 92%|█████████▏| 91709/100000 [1:40:39<09:04, 15.22it/s]
epoch 91700  training loss: 0.09758774936199188



 92%|█████████▏| 91801/100000 [1:40:45<08:58, 15.22it/s]
epoch 91800  training loss: 0.09758782386779785




 92%|█████████▏| 91923/100000 [1:40:53<08:50, 15.24it/s]
epoch 91900  training loss: 0.09758750349283218



 92%|█████████▏| 92015/100000 [1:40:59<08:45, 15.20it/s]
epoch 92000  training loss: 0.09758765250444412
epoch 92000  clean testing loss: 0.0019906149245798588



 92%|█████████▏| 92105/100000 [1:41:05<08:39, 15.20it/s]
epoch 92100  training loss: 0.09758736938238144




 92%|█████████▏| 92227/100000 [1:41:13<08:30, 15.23it/s]
epoch 92200  training loss: 0.09758735448122025



 92%|█████████▏| 92319/100000 [1:41:19<08:24, 15.22it/s]
epoch 92300  training loss: 0.09758725017309189



 92%|█████████▏| 92411/100000 [1:41:25<08:18, 15.22it/s]
epoch 92400  training loss: 0.0975872203707695



 93%|█████████▎| 92503/100000 [1:41:31<08:10, 15.27it/s]
epoch 92500  training loss: 0.0975872203707695




 93%|█████████▎| 92625/100000 [1:41:39<08:02, 15.29it/s]
epoch 92600  training loss: 0.09758695960044861



 93%|█████████▎| 92717/100000 [1:41:45<07:56, 15.29it/s]
epoch 92700  training loss: 0.09758710116147995



 93%|█████████▎| 92809/100000 [1:41:52<07:52, 15.22it/s]
epoch 92800  training loss: 0.09758704900741577



 93%|█████████▎| 92901/100000 [1:41:58<07:46, 15.21it/s]
epoch 92900  training loss: 0.09758677333593369




 93%|█████████▎| 93021/100000 [1:42:06<07:38, 15.22it/s]
epoch 93000  training loss: 0.09758676588535309
epoch 93000  clean testing loss: 0.0019914954900741577



 93%|█████████▎| 93113/100000 [1:42:12<07:32, 15.22it/s]
epoch 93100  training loss: 0.09758654981851578



 93%|█████████▎| 93205/100000 [1:42:18<07:27, 15.19it/s]
epoch 93200  training loss: 0.09758655726909637




 93%|█████████▎| 93327/100000 [1:42:26<07:18, 15.23it/s]
epoch 93300  training loss: 0.09758667647838593



 93%|█████████▎| 93417/100000 [1:42:32<07:13, 15.19it/s]
epoch 93400  training loss: 0.0975864976644516



 94%|█████████▎| 93509/100000 [1:42:38<07:07, 15.20it/s]
epoch 93500  training loss: 0.09758634120225906




 94%|█████████▎| 93631/100000 [1:42:46<06:58, 15.23it/s]
epoch 93600  training loss: 0.09758610278367996



 94%|█████████▎| 93723/100000 [1:42:52<06:51, 15.24it/s]
epoch 93700  training loss: 0.09758616983890533



 94%|█████████▍| 93813/100000 [1:42:58<06:46, 15.23it/s]
epoch 93800  training loss: 0.09758610278367996



 94%|█████████▍| 93905/100000 [1:43:04<06:41, 15.19it/s]
epoch 93900  training loss: 0.09758604317903519




 94%|█████████▍| 94027/100000 [1:43:12<06:32, 15.24it/s]
epoch 94000  training loss: 0.09758596122264862
epoch 94000  clean testing loss: 0.00199224054813385



 94%|█████████▍| 94117/100000 [1:43:18<06:26, 15.23it/s]
epoch 94100  training loss: 0.0975857675075531



 94%|█████████▍| 94209/100000 [1:43:24<06:20, 15.23it/s]
epoch 94200  training loss: 0.09758580476045609



 94%|█████████▍| 94301/100000 [1:43:30<06:14, 15.22it/s]
epoch 94300  training loss: 0.0975857600569725




 94%|█████████▍| 94423/100000 [1:43:38<06:05, 15.24it/s]
epoch 94400  training loss: 0.09758564084768295



 95%|█████████▍| 94513/100000 [1:43:44<06:00, 15.23it/s]
epoch 94500  training loss: 0.09758555889129639



 95%|█████████▍| 94605/100000 [1:43:50<05:55, 15.20it/s]
epoch 94600  training loss: 0.097585529088974




 95%|█████████▍| 94727/100000 [1:43:58<05:46, 15.24it/s]
epoch 94700  training loss: 0.09758546203374863



 95%|█████████▍| 94819/100000 [1:44:04<05:39, 15.24it/s]
epoch 94800  training loss: 0.09758540987968445



 95%|█████████▍| 94911/100000 [1:44:10<05:34, 15.23it/s]
epoch 94900  training loss: 0.09758525341749191



 95%|█████████▌| 95001/100000 [1:44:16<05:33, 14.99it/s]
epoch 95000  training loss: 0.09758515655994415
epoch 95000  clean testing loss: 0.0019931376446038485




 95%|█████████▌| 95123/100000 [1:44:24<05:19, 15.24it/s]
epoch 95100  training loss: 0.0975852906703949



 95%|█████████▌| 95215/100000 [1:44:30<05:14, 15.24it/s]
epoch 95200  training loss: 0.097585029900074



 95%|█████████▌| 95307/100000 [1:44:36<05:08, 15.21it/s]
epoch 95300  training loss: 0.09758502244949341




 95%|█████████▌| 95429/100000 [1:44:44<04:59, 15.24it/s]
epoch 95400  training loss: 0.09758514910936356



 96%|█████████▌| 95519/100000 [1:44:50<04:53, 15.24it/s]
epoch 95500  training loss: 0.09758495539426804



 96%|█████████▌| 95611/100000 [1:44:56<04:48, 15.23it/s]
epoch 95600  training loss: 0.09758486598730087



 96%|█████████▌| 95703/100000 [1:45:02<04:46, 14.99it/s]
epoch 95700  training loss: 0.0975847989320755




 96%|█████████▌| 95825/100000 [1:45:10<04:34, 15.22it/s]
epoch 95800  training loss: 0.0975847989320755



 96%|█████████▌| 95915/100000 [1:45:16<04:28, 15.24it/s]
epoch 95900  training loss: 0.09758475422859192



 96%|█████████▌| 96007/100000 [1:45:22<04:23, 15.16it/s]
epoch 96000  training loss: 0.09758467227220535
epoch 96000  clean testing loss: 0.001993749523535371




 96%|█████████▌| 96129/100000 [1:45:30<04:14, 15.23it/s]
epoch 96100  training loss: 0.09758464992046356



 96%|█████████▌| 96221/100000 [1:45:36<04:08, 15.22it/s]
epoch 96200  training loss: 0.09758451581001282



 96%|█████████▋| 96313/100000 [1:45:42<04:02, 15.22it/s]
epoch 96300  training loss: 0.09758461266756058



 96%|█████████▋| 96403/100000 [1:45:48<03:56, 15.18it/s]
epoch 96400  training loss: 0.09758438169956207




 97%|█████████▋| 96525/100000 [1:45:56<03:48, 15.23it/s]
epoch 96500  training loss: 0.09758426994085312



 97%|█████████▋| 96609/100000 [1:46:02<04:01, 14.05it/s]
epoch 96600  training loss: 0.09758420288562775



 97%|█████████▋| 96701/100000 [1:46:08<03:36, 15.23it/s]
epoch 96700  training loss: 0.09758434444665909




 97%|█████████▋| 96823/100000 [1:46:16<03:28, 15.24it/s]
epoch 96800  training loss: 0.09758410602807999



 97%|█████████▋| 96915/100000 [1:46:22<03:22, 15.22it/s]
epoch 96900  training loss: 0.09758404642343521



 97%|█████████▋| 97005/100000 [1:46:28<03:18, 15.12it/s]
epoch 97000  training loss: 0.09758400917053223
epoch 97000  clean testing loss: 0.0019944263622164726



 97%|█████████▋| 97097/100000 [1:46:34<03:10, 15.24it/s]
epoch 97100  training loss: 0.09758416563272476




 97%|█████████▋| 97219/100000 [1:46:42<03:02, 15.25it/s]
epoch 97200  training loss: 0.09758395701646805



 97%|█████████▋| 97311/100000 [1:46:48<02:56, 15.22it/s]
epoch 97300  training loss: 0.09758393466472626



 97%|█████████▋| 97403/100000 [1:46:54<02:50, 15.19it/s]
epoch 97400  training loss: 0.09758389741182327



 97%|█████████▋| 97493/100000 [1:47:00<02:44, 15.26it/s]
epoch 97500  training loss: 0.09758365899324417




 98%|█████████▊| 97615/100000 [1:47:08<02:36, 15.24it/s]
epoch 97600  training loss: 0.09758371114730835



 98%|█████████▊| 97707/100000 [1:47:14<02:30, 15.21it/s]
epoch 97700  training loss: 0.09758368134498596



 98%|█████████▊| 97799/100000 [1:47:20<02:24, 15.24it/s]
epoch 97800  training loss: 0.09758363664150238




 98%|█████████▊| 97921/100000 [1:47:28<02:16, 15.24it/s]
epoch 97900  training loss: 0.09758350253105164



 98%|█████████▊| 98011/100000 [1:47:34<02:10, 15.19it/s]
epoch 98000  training loss: 0.09758344292640686
epoch 98000  clean testing loss: 0.0019950701389461756



 98%|█████████▊| 98103/100000 [1:47:40<02:04, 15.20it/s]
epoch 98100  training loss: 0.09758330136537552



 98%|█████████▊| 98195/100000 [1:47:46<01:58, 15.24it/s]
epoch 98200  training loss: 0.09758346527814865




 98%|█████████▊| 98317/100000 [1:47:54<01:50, 15.25it/s]
epoch 98300  training loss: 0.09758315235376358



 98%|█████████▊| 98409/100000 [1:48:00<01:44, 15.22it/s]
epoch 98400  training loss: 0.09758337587118149



 98%|█████████▊| 98499/100000 [1:48:06<01:38, 15.24it/s]
epoch 98500  training loss: 0.09758322685956955




 99%|█████████▊| 98621/100000 [1:48:14<01:30, 15.25it/s]
epoch 98600  training loss: 0.09758332371711731



 99%|█████████▊| 98713/100000 [1:48:20<01:24, 15.25it/s]
epoch 98700  training loss: 0.09758315980434418



 99%|█████████▉| 98805/100000 [1:48:26<01:18, 15.20it/s]
epoch 98800  training loss: 0.09758312255144119




 99%|█████████▉| 98927/100000 [1:48:34<01:10, 15.21it/s]
epoch 98900  training loss: 0.09758282452821732



 99%|█████████▉| 99017/100000 [1:48:40<01:04, 15.21it/s]
epoch 99000  training loss: 0.09758276492357254
epoch 99000  clean testing loss: 0.001995580969378352



 99%|█████████▉| 99109/100000 [1:48:46<00:58, 15.23it/s]
epoch 99100  training loss: 0.09758289903402328



 99%|█████████▉| 99201/100000 [1:48:52<00:52, 15.24it/s]
epoch 99200  training loss: 0.09758282452821732




 99%|█████████▉| 99323/100000 [1:49:00<00:44, 15.25it/s]
epoch 99300  training loss: 0.09758281707763672



 99%|█████████▉| 99413/100000 [1:49:06<00:38, 15.24it/s]
epoch 99400  training loss: 0.09758273512125015



100%|█████████▉| 99505/100000 [1:49:12<00:32, 15.22it/s]
epoch 99500  training loss: 0.09758264571428299




100%|█████████▉| 99627/100000 [1:49:20<00:24, 15.23it/s]
epoch 99600  training loss: 0.09758246690034866



100%|█████████▉| 99719/100000 [1:49:26<00:18, 15.25it/s]
epoch 99700  training loss: 0.09758280962705612



100%|█████████▉| 99811/100000 [1:49:32<00:12, 15.23it/s]
epoch 99800  training loss: 0.09758256375789642



100%|█████████▉| 99901/100000 [1:49:38<00:06, 15.23it/s]
epoch 99900  training loss: 0.09758260101079941




100%|██████████| 100000/100000 [1:49:44<00:00, 15.19it/s]
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_sin_size10000_noise1.00e-01_invop1_lr5e-05 ...