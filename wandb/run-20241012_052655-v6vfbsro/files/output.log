
  1%|          | 979/100000 [00:01<03:02, 542.71it/s]
epoch 0  training loss: 0.5692679286003113
epoch 0  clean testing loss: 1.9160234928131104
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 100  training loss: 0.15453487634658813
epoch 100  clean testing loss: 0.0637531504034996
epoch 200  training loss: 0.12825387716293335
epoch 200  clean testing loss: 0.036154814064502716
epoch 300  training loss: 0.12500795722007751
epoch 300  clean testing loss: 0.03372902423143387
epoch 400  training loss: 0.1423775851726532
epoch 400  clean testing loss: 0.03386630862951279
epoch 500  training loss: 0.11807727813720703
epoch 500  clean testing loss: 0.029043713584542274
epoch 600  training loss: 0.13648372888565063
epoch 600  clean testing loss: 0.039613038301467896
epoch 700  training loss: 0.11707587540149689
epoch 700  clean testing loss: 0.02836892008781433
epoch 800  training loss: 0.13292819261550903

epoch 800  clean testing loss: 0.03780391439795494
epoch 900  training loss: 0.11257947236299515
epoch 900  clean testing loss: 0.02726634219288826
epoch 1000  training loss: 0.11035723239183426
epoch 1000  clean testing loss: 0.026615334674715996
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 1100  training loss: 0.11575227975845337
epoch 1100  clean testing loss: 0.03154931589961052
epoch 1200  training loss: 0.10970845073461533
epoch 1200  clean testing loss: 0.027310825884342194
epoch 1300  training loss: 0.12574990093708038
epoch 1300  clean testing loss: 0.03915496915578842
epoch 1400  training loss: 0.10858801007270813
epoch 1400  clean testing loss: 0.026799315586686134
epoch 1500  training loss: 0.10792173445224762
epoch 1500  clean testing loss: 0.02637423388659954
epoch 1600  training loss: 0.10693181306123734
epoch 1600  clean testing loss: 0.02920011803507805
epoch 1700  training loss: 0.12023653090000153
epoch 1700  clean testing loss: 0.029965030029416084
epoch 1800  training loss: 0.1075710877776146

  3%|▎         | 3122/100000 [00:05<03:00, 536.82it/s]
epoch 1900  training loss: 0.10604003071784973
epoch 1900  clean testing loss: 0.02813657373189926
epoch 2000  training loss: 0.12584137916564941
epoch 2000  clean testing loss: 0.038456451147794724
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 2100  training loss: 0.10665883123874664
epoch 2100  clean testing loss: 0.026734353974461555
epoch 2200  training loss: 0.10435782372951508
epoch 2200  clean testing loss: 0.027198296040296555
epoch 2300  training loss: 0.10499469190835953
epoch 2300  clean testing loss: 0.027764590457081795
epoch 2400  training loss: 0.10664041340351105
epoch 2400  clean testing loss: 0.028466805815696716
epoch 2500  training loss: 0.10557180643081665
epoch 2500  clean testing loss: 0.028296587988734245
epoch 2600  training loss: 0.10339809209108353
epoch 2600  clean testing loss: 0.02868597023189068
epoch 2700  training loss: 0.10315482318401337
epoch 2700  clean testing loss: 0.028515197336673737
epoch 2800  training loss: 0.1079568937420845
epoch 2800  clean testing loss: 0.03829792141914368
epoch 2900  training loss: 0.10185631364583969

  4%|▍         | 4225/100000 [00:07<02:57, 539.92it/s]
epoch 3000  training loss: 0.10084056109189987
epoch 3000  clean testing loss: 0.02925117500126362
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 3100  training loss: 0.1003899872303009
epoch 3100  clean testing loss: 0.02941787987947464
epoch 3200  training loss: 0.10005521029233932
epoch 3200  clean testing loss: 0.029570447281003
epoch 3300  training loss: 0.10145615041255951
epoch 3300  clean testing loss: 0.030221357941627502
epoch 3400  training loss: 0.0994071215391159
epoch 3400  clean testing loss: 0.030178971588611603
epoch 3500  training loss: 0.10136260837316513
epoch 3500  clean testing loss: 0.030493827536702156
epoch 3600  training loss: 0.09944836795330048
epoch 3600  clean testing loss: 0.030174778774380684
epoch 3700  training loss: 0.09926210343837738
epoch 3700  clean testing loss: 0.030284741893410683
epoch 3800  training loss: 0.1017182394862175
epoch 3800  clean testing loss: 0.031840912997722626
epoch 3900  training loss: 0.09897375851869583
epoch 3900  clean testing loss: 0.030224202200770378
epoch 4000  training loss: 0.09845362603664398
epoch 4000  clean testing loss: 0.030360940843820572

  5%|▌         | 5273/100000 [00:09<02:54, 541.43it/s]
epoch 4100  training loss: 0.10582361370325089
epoch 4100  clean testing loss: 0.032068777829408646
epoch 4200  training loss: 0.09838796406984329
epoch 4200  clean testing loss: 0.0311496052891016
epoch 4300  training loss: 0.09788956493139267
epoch 4300  clean testing loss: 0.030846791341900826
epoch 4400  training loss: 0.09754189103841782
epoch 4400  clean testing loss: 0.030946599319577217
epoch 4500  training loss: 0.09826787561178207
epoch 4500  clean testing loss: 0.0321221724152565
epoch 4600  training loss: 0.10400161892175674
epoch 4600  clean testing loss: 0.03480294346809387
epoch 4700  training loss: 0.10035093128681183
epoch 4700  clean testing loss: 0.032253243029117584
epoch 4800  training loss: 0.09772775322198868
epoch 4800  clean testing loss: 0.03134686127305031
epoch 4900  training loss: 0.09652020782232285
epoch 4900  clean testing loss: 0.03174493834376335
epoch 5000  training loss: 0.09642793983221054
epoch 5000  clean testing loss: 0.032210517674684525
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 5100  training loss: 0.10103241354227066

  6%|▌         | 6097/100000 [00:11<02:54, 539.22it/s]
epoch 5200  training loss: 0.09694550931453705
epoch 5200  clean testing loss: 0.03202385827898979
epoch 5300  training loss: 0.09659222513437271
epoch 5300  clean testing loss: 0.03240584582090378
epoch 5400  training loss: 0.09576141089200974
epoch 5400  clean testing loss: 0.03212198242545128
epoch 5500  training loss: 0.09581958502531052
epoch 5500  clean testing loss: 0.03346956893801689
epoch 5600  training loss: 0.11644051223993301
epoch 5600  clean testing loss: 0.045905839651823044
epoch 5700  training loss: 0.09897346794605255
epoch 5700  clean testing loss: 0.033721357583999634
epoch 5800  training loss: 0.09564525634050369
epoch 5800  clean testing loss: 0.032361384481191635
epoch 5900  training loss: 0.0951894149184227
epoch 5900  clean testing loss: 0.03329320624470711
epoch 6000  training loss: 0.09491094946861267
epoch 6000  clean testing loss: 0.03315182030200958
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 6100  training loss: 0.0944463238120079

  7%|▋         | 7197/100000 [00:13<02:51, 541.84it/s]
epoch 6200  training loss: 0.09399794787168503
epoch 6200  clean testing loss: 0.03329666703939438
epoch 6300  training loss: 0.09396142512559891
epoch 6300  clean testing loss: 0.034504540264606476
epoch 6400  training loss: 0.0937589481472969
epoch 6400  clean testing loss: 0.033902447670698166
epoch 6500  training loss: 0.0947183221578598
epoch 6500  clean testing loss: 0.03475708141922951
epoch 6600  training loss: 0.09431004524230957
epoch 6600  clean testing loss: 0.03667961806058884
epoch 6700  training loss: 0.09440366178750992
epoch 6700  clean testing loss: 0.03343779966235161
epoch 6800  training loss: 0.09319845587015152
epoch 6800  clean testing loss: 0.035547830164432526
epoch 6900  training loss: 0.0932881087064743
epoch 6900  clean testing loss: 0.034254007041454315
epoch 7000  training loss: 0.0924496203660965
epoch 7000  clean testing loss: 0.0351705476641655
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 7100  training loss: 0.095147505402565
epoch 7100  clean testing loss: 0.035898078233003616
epoch 7200  training loss: 0.09305375069379807

  8%|▊         | 8241/100000 [00:15<02:51, 535.78it/s]
epoch 7300  training loss: 0.0937548354268074
epoch 7300  clean testing loss: 0.03731231763958931
epoch 7400  training loss: 0.09203864634037018
epoch 7400  clean testing loss: 0.03549184277653694
epoch 7500  training loss: 0.09161730110645294
epoch 7500  clean testing loss: 0.03529742360115051
epoch 7600  training loss: 0.0916074737906456
epoch 7600  clean testing loss: 0.03578406572341919
epoch 7700  training loss: 0.10016633570194244
epoch 7700  clean testing loss: 0.03738056495785713
epoch 7800  training loss: 0.10549837350845337
epoch 7800  clean testing loss: 0.034873753786087036
epoch 7900  training loss: 0.09133042395114899
epoch 7900  clean testing loss: 0.035388898104429245
epoch 8000  training loss: 0.09174317121505737
epoch 8000  clean testing loss: 0.03611110895872116
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 8100  training loss: 0.09098631888628006
epoch 8100  clean testing loss: 0.03542033210396767
epoch 8200  training loss: 0.09397926926612854
epoch 8200  clean testing loss: 0.038619574159383774
epoch 8300  training loss: 0.09425137937068939

  9%|▉         | 9342/100000 [00:17<02:48, 539.37it/s]
epoch 8400  training loss: 0.09098847210407257
epoch 8400  clean testing loss: 0.03656443953514099
epoch 8500  training loss: 0.0906216949224472
epoch 8500  clean testing loss: 0.036563027650117874
epoch 8600  training loss: 0.09248390793800354
epoch 8600  clean testing loss: 0.03751999884843826
epoch 8700  training loss: 0.09048884361982346
epoch 8700  clean testing loss: 0.036159370094537735
epoch 8800  training loss: 0.09382717311382294
epoch 8800  clean testing loss: 0.04040567949414253
epoch 8900  training loss: 0.09897781908512115
epoch 8900  clean testing loss: 0.038321930915117264
epoch 9000  training loss: 0.08982483297586441
epoch 9000  clean testing loss: 0.03612233325839043
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 9100  training loss: 0.08963832259178162
epoch 9100  clean testing loss: 0.03695639222860336
epoch 9200  training loss: 0.08945633471012115
epoch 9200  clean testing loss: 0.03681090101599693
epoch 9300  training loss: 0.08908070623874664
epoch 9300  clean testing loss: 0.03677107393741608
epoch 9400  training loss: 0.08980293571949005

 10%|█         | 10441/100000 [00:19<02:45, 539.60it/s]
epoch 9500  training loss: 0.09085331857204437
epoch 9500  clean testing loss: 0.03710663691163063
epoch 9600  training loss: 0.08973293006420135
epoch 9600  clean testing loss: 0.037650130689144135
epoch 9700  training loss: 0.08902418613433838
epoch 9700  clean testing loss: 0.037097200751304626
epoch 9800  training loss: 0.0886707454919815
epoch 9800  clean testing loss: 0.03712864965200424
epoch 9900  training loss: 0.08863063156604767
epoch 9900  clean testing loss: 0.038111407309770584
epoch 10000  training loss: 0.09451063722372055
epoch 10000  clean testing loss: 0.043454609811306
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 10100  training loss: 0.0886172503232956
epoch 10100  clean testing loss: 0.038324687629938126
epoch 10200  training loss: 0.08878457546234131
epoch 10200  clean testing loss: 0.03758426010608673
epoch 10300  training loss: 0.08823227882385254
epoch 10300  clean testing loss: 0.037860430777072906
epoch 10400  training loss: 0.08805511891841888
epoch 10400  clean testing loss: 0.037674520164728165
epoch 10500  training loss: 0.08858881145715714

epoch 10500  clean testing loss: 0.038325510919094086
epoch 10600  training loss: 0.08815428614616394
epoch 10600  clean testing loss: 0.03801272436976433
epoch 10700  training loss: 0.08871746063232422
epoch 10700  clean testing loss: 0.037577688694000244
epoch 10800  training loss: 0.08849430084228516
epoch 10800  clean testing loss: 0.03763984888792038
epoch 10900  training loss: 0.08790619671344757
epoch 10900  clean testing loss: 0.039182763546705246
epoch 11000  training loss: 0.08757011592388153
epoch 11000  clean testing loss: 0.038258545100688934
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 11100  training loss: 0.08739999681711197
epoch 11100  clean testing loss: 0.038986656814813614
epoch 11200  training loss: 0.08751750737428665
epoch 11200  clean testing loss: 0.04132576286792755
epoch 11300  training loss: 0.08718686550855637
epoch 11300  clean testing loss: 0.03929198533296585
epoch 11400  training loss: 0.08816791325807571
epoch 11400  clean testing loss: 0.0395340658724308
epoch 11500  training loss: 0.09017627686262131

 13%|█▎        | 12589/100000 [00:23<02:40, 544.82it/s]
epoch 11600  training loss: 0.08674653619527817
epoch 11600  clean testing loss: 0.038339585065841675
epoch 11700  training loss: 0.08711683750152588
epoch 11700  clean testing loss: 0.03856514394283295
epoch 11800  training loss: 0.08644996583461761
epoch 11800  clean testing loss: 0.0389162078499794
epoch 11900  training loss: 0.08643288165330887
epoch 11900  clean testing loss: 0.039297208189964294
epoch 12000  training loss: 0.09450683742761612
epoch 12000  clean testing loss: 0.0416814349591732
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 12100  training loss: 0.08603036403656006
epoch 12100  clean testing loss: 0.03858329728245735
epoch 12200  training loss: 0.08586803078651428
epoch 12200  clean testing loss: 0.03891866281628609
epoch 12300  training loss: 0.08574709296226501
epoch 12300  clean testing loss: 0.03923836722970009
epoch 12400  training loss: 0.0859411358833313
epoch 12400  clean testing loss: 0.0392489917576313
epoch 12500  training loss: 0.08602344244718552
epoch 12500  clean testing loss: 0.03987783566117287
epoch 12600  training loss: 0.08557555079460144

 14%|█▎        | 13623/100000 [00:25<02:40, 538.29it/s]
epoch 12700  training loss: 0.08538995683193207
epoch 12700  clean testing loss: 0.039764270186424255
epoch 12800  training loss: 0.08571108430624008
epoch 12800  clean testing loss: 0.03926937282085419
epoch 12900  training loss: 0.08530694991350174
epoch 12900  clean testing loss: 0.03919944912195206
epoch 13000  training loss: 0.08548220247030258
epoch 13000  clean testing loss: 0.04068263620138168
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 13100  training loss: 0.085609570145607
epoch 13100  clean testing loss: 0.03966579958796501
epoch 13200  training loss: 0.08513734489679337
epoch 13200  clean testing loss: 0.039372146129608154
epoch 13300  training loss: 0.08546620607376099
epoch 13300  clean testing loss: 0.03934614732861519
epoch 13400  training loss: 0.08574695140123367
epoch 13400  clean testing loss: 0.04019048437476158
epoch 13500  training loss: 0.08571799099445343
epoch 13500  clean testing loss: 0.04054200276732445
epoch 13600  training loss: 0.08519074320793152

 15%|█▍        | 14671/100000 [00:27<02:37, 542.52it/s]
epoch 13700  training loss: 0.0849837064743042
epoch 13700  clean testing loss: 0.03934890031814575
epoch 13800  training loss: 0.08544705808162689
epoch 13800  clean testing loss: 0.039122529327869415
epoch 13900  training loss: 0.08453220129013062
epoch 13900  clean testing loss: 0.03969312086701393
epoch 14000  training loss: 0.08504536002874374
epoch 14000  clean testing loss: 0.041750285774469376
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 14100  training loss: 0.08474869281053543
epoch 14100  clean testing loss: 0.03992842882871628
epoch 14200  training loss: 0.08571784943342209
epoch 14200  clean testing loss: 0.039320431649684906
epoch 14300  training loss: 0.08486515283584595
epoch 14300  clean testing loss: 0.040821436792612076
epoch 14400  training loss: 0.08429721742868423
epoch 14400  clean testing loss: 0.03983693942427635
epoch 14500  training loss: 0.08420617878437042
epoch 14500  clean testing loss: 0.03986877575516701
epoch 14600  training loss: 0.08483906835317612
epoch 14600  clean testing loss: 0.04123944416642189
epoch 14700  training loss: 0.0851929560303688

 16%|█▌        | 15768/100000 [00:29<02:35, 543.15it/s]
epoch 14800  training loss: 0.08411005139350891
epoch 14800  clean testing loss: 0.03961417078971863
epoch 14900  training loss: 0.08387891203165054
epoch 14900  clean testing loss: 0.039836108684539795
epoch 15000  training loss: 0.08381934463977814
epoch 15000  clean testing loss: 0.03998003154993057
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 15100  training loss: 0.08383867144584656
epoch 15100  clean testing loss: 0.039986733347177505
epoch 15200  training loss: 0.0836152657866478
epoch 15200  clean testing loss: 0.040446970611810684
epoch 15300  training loss: 0.08343840390443802
epoch 15300  clean testing loss: 0.039959680289030075
epoch 15400  training loss: 0.0833321139216423
epoch 15400  clean testing loss: 0.040114931762218475
epoch 15500  training loss: 0.08356756716966629
epoch 15500  clean testing loss: 0.04039362072944641
epoch 15600  training loss: 0.08391261845827103
epoch 15600  clean testing loss: 0.041723061352968216
epoch 15700  training loss: 0.0834350436925888
epoch 15700  clean testing loss: 0.040752213448286057
epoch 15800  training loss: 0.08343394100666046

 17%|█▋        | 16808/100000 [00:31<02:35, 536.69it/s]
epoch 15900  training loss: 0.08337202668190002
epoch 15900  clean testing loss: 0.03996224328875542
epoch 16000  training loss: 0.08387405425310135
epoch 16000  clean testing loss: 0.04103635251522064
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 16100  training loss: 0.08346819877624512
epoch 16100  clean testing loss: 0.04101061448454857
epoch 16200  training loss: 0.08397136628627777
epoch 16200  clean testing loss: 0.040417369455099106
epoch 16300  training loss: 0.0832422599196434
epoch 16300  clean testing loss: 0.040774453431367874
epoch 16400  training loss: 0.08301017433404922
epoch 16400  clean testing loss: 0.0411563366651535
epoch 16500  training loss: 0.08305259048938751
epoch 16500  clean testing loss: 0.04115930572152138
epoch 16600  training loss: 0.08473554998636246
epoch 16600  clean testing loss: 0.0410427451133728
epoch 16700  training loss: 0.08297546952962875
epoch 16700  clean testing loss: 0.040048159658908844
epoch 16800  training loss: 0.08293160051107407
epoch 16800  clean testing loss: 0.04130946472287178
epoch 16900  training loss: 0.08281757682561874

 18%|█▊        | 17906/100000 [00:33<02:32, 539.16it/s]
epoch 17000  training loss: 0.08333079516887665
epoch 17000  clean testing loss: 0.041544072329998016
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 17100  training loss: 0.08310512453317642
epoch 17100  clean testing loss: 0.040521763265132904
epoch 17200  training loss: 0.08273874223232269
epoch 17200  clean testing loss: 0.04101688042283058
epoch 17300  training loss: 0.0836307555437088
epoch 17300  clean testing loss: 0.04129772633314133
epoch 17400  training loss: 0.08360565453767776
epoch 17400  clean testing loss: 0.042050860822200775
epoch 17500  training loss: 0.08284042775630951
epoch 17500  clean testing loss: 0.04092565178871155
epoch 17600  training loss: 0.0832371860742569
epoch 17600  clean testing loss: 0.040840934962034225
epoch 17700  training loss: 0.08316025137901306
epoch 17700  clean testing loss: 0.04229454696178436
epoch 17800  training loss: 0.08339832723140717
epoch 17800  clean testing loss: 0.0407540388405323
epoch 17900  training loss: 0.08220714330673218

 19%|█▉        | 19007/100000 [00:35<02:32, 531.59it/s]
epoch 18000  training loss: 0.0827014148235321
epoch 18000  clean testing loss: 0.04105285927653313
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 18100  training loss: 0.08186794072389603
epoch 18100  clean testing loss: 0.04108889028429985
epoch 18200  training loss: 0.08177801966667175
epoch 18200  clean testing loss: 0.0415637381374836
epoch 18300  training loss: 0.08182024210691452
epoch 18300  clean testing loss: 0.04110078886151314
epoch 18400  training loss: 0.08191069215536118
epoch 18400  clean testing loss: 0.041011691093444824
epoch 18500  training loss: 0.08190889656543732
epoch 18500  clean testing loss: 0.04111810401082039
epoch 18600  training loss: 0.08146840333938599
epoch 18600  clean testing loss: 0.041726842522621155
epoch 18700  training loss: 0.08148068934679031
epoch 18700  clean testing loss: 0.04209962487220764
epoch 18800  training loss: 0.0822841078042984
epoch 18800  clean testing loss: 0.04178901016712189
epoch 18900  training loss: 0.08212289959192276
epoch 18900  clean testing loss: 0.04140979424118996
epoch 19000  training loss: 0.08481509983539581
epoch 19000  clean testing loss: 0.04284216836094856

 20%|██        | 20057/100000 [00:37<02:29, 536.15it/s]
epoch 19100  training loss: 0.08117222785949707
epoch 19100  clean testing loss: 0.04176773875951767
epoch 19200  training loss: 0.08147679269313812
epoch 19200  clean testing loss: 0.041726212948560715
epoch 19300  training loss: 0.08162659406661987
epoch 19300  clean testing loss: 0.041787922382354736
epoch 19400  training loss: 0.08103041350841522
epoch 19400  clean testing loss: 0.04127483814954758
epoch 19500  training loss: 0.0815645158290863
epoch 19500  clean testing loss: 0.04300840571522713
epoch 19600  training loss: 0.08139654248952866
epoch 19600  clean testing loss: 0.04261402413249016
epoch 19700  training loss: 0.08097841590642929
epoch 19700  clean testing loss: 0.04297284781932831
epoch 19800  training loss: 0.08130834996700287
epoch 19800  clean testing loss: 0.041686251759529114
epoch 19900  training loss: 0.08206524699926376
epoch 19900  clean testing loss: 0.04228542000055313
epoch 20000  training loss: 0.08084863424301147
epoch 20000  clean testing loss: 0.041604410856962204
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 20100  training loss: 0.0807056799530983

 21%|██        | 21157/100000 [00:39<02:26, 539.54it/s]
epoch 20200  training loss: 0.08072763681411743
epoch 20200  clean testing loss: 0.04196515679359436
epoch 20300  training loss: 0.0811057835817337
epoch 20300  clean testing loss: 0.041929084807634354
epoch 20400  training loss: 0.08068809658288956
epoch 20400  clean testing loss: 0.04155817627906799
epoch 20500  training loss: 0.0804436206817627
epoch 20500  clean testing loss: 0.04182635620236397
epoch 20600  training loss: 0.08033742010593414
epoch 20600  clean testing loss: 0.041582196950912476
epoch 20700  training loss: 0.08035658299922943
epoch 20700  clean testing loss: 0.041763897985219955
epoch 20800  training loss: 0.08056682348251343
epoch 20800  clean testing loss: 0.04171935096383095
epoch 20900  training loss: 0.08018619567155838
epoch 20900  clean testing loss: 0.042409323155879974
epoch 21000  training loss: 0.08134318888187408
epoch 21000  clean testing loss: 0.04214932769536972
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 21100  training loss: 0.07997148483991623
epoch 21100  clean testing loss: 0.04205869510769844
epoch 21200  training loss: 0.07992852479219437

 22%|██▏       | 22197/100000 [00:41<02:24, 538.84it/s]
epoch 21300  training loss: 0.07988733053207397
epoch 21300  clean testing loss: 0.04206405580043793
epoch 21400  training loss: 0.07995668053627014
epoch 21400  clean testing loss: 0.04258287325501442
epoch 21500  training loss: 0.08036007732152939
epoch 21500  clean testing loss: 0.04252741485834122
epoch 21600  training loss: 0.08021294325590134
epoch 21600  clean testing loss: 0.042173583060503006
epoch 21700  training loss: 0.07984520494937897
epoch 21700  clean testing loss: 0.04211929440498352
epoch 21800  training loss: 0.07988954335451126
epoch 21800  clean testing loss: 0.042307693511247635
epoch 21900  training loss: 0.07960846275091171
epoch 21900  clean testing loss: 0.042623866349458694
epoch 22000  training loss: 0.08010409772396088
epoch 22000  clean testing loss: 0.042779844254255295
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 22100  training loss: 0.07997004687786102
epoch 22100  clean testing loss: 0.04273834452033043
epoch 22200  training loss: 0.080183245241642
epoch 22200  clean testing loss: 0.04287975654006004
epoch 22300  training loss: 0.07959175854921341

 23%|██▎       | 23291/100000 [00:43<02:22, 540.07it/s]
epoch 22400  training loss: 0.079636350274086
epoch 22400  clean testing loss: 0.04313499480485916
epoch 22500  training loss: 0.07952475547790527
epoch 22500  clean testing loss: 0.042225535959005356
epoch 22600  training loss: 0.08050534874200821
epoch 22600  clean testing loss: 0.043762292712926865
epoch 22700  training loss: 0.07966470718383789
epoch 22700  clean testing loss: 0.042469993233680725
epoch 22800  training loss: 0.08006846904754639
epoch 22800  clean testing loss: 0.043168243020772934
epoch 22900  training loss: 0.08005823194980621
epoch 22900  clean testing loss: 0.042640503495931625
epoch 23000  training loss: 0.07939393073320389
epoch 23000  clean testing loss: 0.042601779103279114
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 23100  training loss: 0.07954373210668564
epoch 23100  clean testing loss: 0.0425964817404747
epoch 23200  training loss: 0.07931627333164215
epoch 23200  clean testing loss: 0.04249995946884155
epoch 23300  training loss: 0.07943134754896164
 23%|██▎       | 23346/100000 [00:43<02:23, 533.52it/s]wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3 seconds.), retrying request
 24%|██▍       | 24390/100000 [00:45<02:19, 542.86it/s]
epoch 23400  training loss: 0.07906821370124817
epoch 23400  clean testing loss: 0.043235018849372864
epoch 23500  training loss: 0.07904630899429321
epoch 23500  clean testing loss: 0.04226617142558098
epoch 23600  training loss: 0.08001567423343658
epoch 23600  clean testing loss: 0.044141121208667755
epoch 23700  training loss: 0.07973220944404602
epoch 23700  clean testing loss: 0.042935363948345184
epoch 23800  training loss: 0.0793352797627449
epoch 23800  clean testing loss: 0.04278193414211273
epoch 23900  training loss: 0.07887878268957138
epoch 23900  clean testing loss: 0.042963963001966476
epoch 24000  training loss: 0.07923102378845215
epoch 24000  clean testing loss: 0.042631372809410095
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 24100  training loss: 0.07875028252601624
epoch 24100  clean testing loss: 0.0428774356842041
epoch 24200  training loss: 0.07888208329677582
epoch 24200  clean testing loss: 0.04274437949061394
epoch 24300  training loss: 0.07864576578140259
epoch 24300  clean testing loss: 0.04283542186021805
epoch 24400  training loss: 0.07867500185966492

 25%|██▌       | 25436/100000 [00:47<02:17, 540.43it/s]
epoch 24500  training loss: 0.07874137908220291
epoch 24500  clean testing loss: 0.04348323866724968
epoch 24600  training loss: 0.0791262686252594
epoch 24600  clean testing loss: 0.0435199998319149
epoch 24700  training loss: 0.07861700654029846
epoch 24700  clean testing loss: 0.043007805943489075
epoch 24800  training loss: 0.07858684659004211
epoch 24800  clean testing loss: 0.043078165501356125
epoch 24900  training loss: 0.07851734012365341
epoch 24900  clean testing loss: 0.042987290769815445
epoch 25000  training loss: 0.07849620282649994
epoch 25000  clean testing loss: 0.04369354248046875
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 25100  training loss: 0.07841034978628159
epoch 25100  clean testing loss: 0.04315880313515663
epoch 25200  training loss: 0.07840602844953537
epoch 25200  clean testing loss: 0.04308578744530678
epoch 25300  training loss: 0.07861968129873276
epoch 25300  clean testing loss: 0.04304205998778343
epoch 25400  training loss: 0.07866428792476654
epoch 25400  clean testing loss: 0.04334145039319992
epoch 25500  training loss: 0.07841485738754272

 27%|██▋       | 26538/100000 [00:49<02:15, 541.72it/s]
epoch 25600  training loss: 0.0785035714507103
epoch 25600  clean testing loss: 0.04362024739384651
epoch 25700  training loss: 0.07875192910432816
epoch 25700  clean testing loss: 0.044171616435050964
epoch 25800  training loss: 0.07835850864648819
epoch 25800  clean testing loss: 0.04324227198958397
epoch 25900  training loss: 0.07883350551128387
epoch 25900  clean testing loss: 0.04361330345273018
epoch 26000  training loss: 0.07829895615577698
epoch 26000  clean testing loss: 0.04349076747894287
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 26100  training loss: 0.07821309566497803
epoch 26100  clean testing loss: 0.043417833745479584
epoch 26200  training loss: 0.07837150245904922
epoch 26200  clean testing loss: 0.043182991445064545
epoch 26300  training loss: 0.07828645408153534
epoch 26300  clean testing loss: 0.04438066482543945
epoch 26400  training loss: 0.07808052748441696
epoch 26400  clean testing loss: 0.0433974489569664
epoch 26500  training loss: 0.07851549237966537
epoch 26500  clean testing loss: 0.0439833402633667
epoch 26600  training loss: 0.07816822826862335

 28%|██▊       | 27582/100000 [00:51<02:13, 544.03it/s]
epoch 26700  training loss: 0.07817862182855606
epoch 26700  clean testing loss: 0.04325149953365326
epoch 26800  training loss: 0.07816261053085327
epoch 26800  clean testing loss: 0.0433562770485878
epoch 26900  training loss: 0.07795480638742447
epoch 26900  clean testing loss: 0.04355925694108009
epoch 27000  training loss: 0.0781913548707962
epoch 27000  clean testing loss: 0.04332965239882469
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 27100  training loss: 0.07790099084377289
epoch 27100  clean testing loss: 0.043607767671346664
epoch 27200  training loss: 0.07782890647649765
epoch 27200  clean testing loss: 0.04372081533074379
epoch 27300  training loss: 0.07780703157186508
epoch 27300  clean testing loss: 0.04372747987508774
epoch 27400  training loss: 0.07778401672840118
epoch 27400  clean testing loss: 0.04343235120177269
epoch 27500  training loss: 0.07778047770261765
epoch 27500  clean testing loss: 0.04382095858454704
epoch 27600  training loss: 0.07776137441396713

 29%|██▊       | 28683/100000 [00:53<02:11, 541.70it/s]
epoch 27700  training loss: 0.0780363604426384
epoch 27700  clean testing loss: 0.043885987251996994
epoch 27800  training loss: 0.07775915414094925
epoch 27800  clean testing loss: 0.043724335730075836
epoch 27900  training loss: 0.07806538790464401
epoch 27900  clean testing loss: 0.04428030550479889
epoch 28000  training loss: 0.07771362364292145
epoch 28000  clean testing loss: 0.04399231821298599
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 28100  training loss: 0.07772579044103622
epoch 28100  clean testing loss: 0.04388430342078209
epoch 28200  training loss: 0.07773514837026596
epoch 28200  clean testing loss: 0.043604083359241486
epoch 28300  training loss: 0.07758403569459915
epoch 28300  clean testing loss: 0.04376498609781265
epoch 28400  training loss: 0.07767681777477264
epoch 28400  clean testing loss: 0.043459124863147736
epoch 28500  training loss: 0.07757788896560669
epoch 28500  clean testing loss: 0.04402565211057663
epoch 28600  training loss: 0.07752642035484314
epoch 28600  clean testing loss: 0.044022493064403534
epoch 28700  training loss: 0.07773818075656891

 30%|██▉       | 29710/100000 [00:55<02:11, 535.56it/s]
epoch 28800  training loss: 0.07743363082408905
epoch 28800  clean testing loss: 0.043856021016836166
epoch 28900  training loss: 0.07747101038694382
epoch 28900  clean testing loss: 0.04384610429406166
epoch 29000  training loss: 0.0776224434375763
epoch 29000  clean testing loss: 0.044316988438367844
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 29100  training loss: 0.07782924920320511
epoch 29100  clean testing loss: 0.04380934685468674
epoch 29200  training loss: 0.0778701975941658
epoch 29200  clean testing loss: 0.04443243518471718
epoch 29300  training loss: 0.0775066465139389
epoch 29300  clean testing loss: 0.04389631748199463
epoch 29400  training loss: 0.07767751067876816
epoch 29400  clean testing loss: 0.04398532956838608
epoch 29500  training loss: 0.07778972387313843
epoch 29500  clean testing loss: 0.04449818655848503
epoch 29600  training loss: 0.07726085186004639
epoch 29600  clean testing loss: 0.04412081465125084
epoch 29700  training loss: 0.07728583365678787

 31%|███       | 30752/100000 [00:57<02:08, 538.26it/s]
epoch 29800  training loss: 0.07722500711679459
epoch 29800  clean testing loss: 0.04386531561613083
epoch 29900  training loss: 0.07724294811487198
epoch 29900  clean testing loss: 0.04409642145037651
epoch 30000  training loss: 0.07738641649484634
epoch 30000  clean testing loss: 0.044344462454319
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 30100  training loss: 0.07712094485759735
epoch 30100  clean testing loss: 0.04409078508615494
epoch 30200  training loss: 0.07717659324407578
epoch 30200  clean testing loss: 0.04400850832462311
epoch 30300  training loss: 0.0772302895784378
epoch 30300  clean testing loss: 0.04407292976975441
epoch 30400  training loss: 0.07709499448537827
epoch 30400  clean testing loss: 0.04413195326924324
epoch 30500  training loss: 0.0770234540104866
epoch 30500  clean testing loss: 0.04438261687755585
epoch 30600  training loss: 0.07720983028411865
epoch 30600  clean testing loss: 0.0444563552737236
epoch 30700  training loss: 0.0771556869149208
epoch 30700  clean testing loss: 0.044149063527584076
epoch 30800  training loss: 0.0770290270447731

 32%|███▏      | 31851/100000 [00:59<02:06, 540.65it/s]
epoch 30900  training loss: 0.07720450311899185
epoch 30900  clean testing loss: 0.044113077223300934
epoch 31000  training loss: 0.07708118110895157
epoch 31000  clean testing loss: 0.04416476935148239
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 31100  training loss: 0.07699821889400482
epoch 31100  clean testing loss: 0.04455103352665901
epoch 31200  training loss: 0.07697007805109024
epoch 31200  clean testing loss: 0.04435931518673897
epoch 31300  training loss: 0.07714980095624924
epoch 31300  clean testing loss: 0.04433276131749153
epoch 31400  training loss: 0.07717244327068329
epoch 31400  clean testing loss: 0.044476091861724854
epoch 31500  training loss: 0.0769224464893341
epoch 31500  clean testing loss: 0.04423423111438751
epoch 31600  training loss: 0.07685307413339615
epoch 31600  clean testing loss: 0.04436487704515457
epoch 31700  training loss: 0.07686243951320648
epoch 31700  clean testing loss: 0.0443258062005043
epoch 31800  training loss: 0.07683055847883224
epoch 31800  clean testing loss: 0.04454689845442772
epoch 31900  training loss: 0.07677902281284332

 33%|███▎      | 32951/100000 [01:01<02:03, 541.01it/s]
epoch 32000  training loss: 0.07686129212379456
epoch 32000  clean testing loss: 0.0444861464202404
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 32100  training loss: 0.0769818127155304
epoch 32100  clean testing loss: 0.04514242708683014
epoch 32200  training loss: 0.07705280184745789
epoch 32200  clean testing loss: 0.0449831523001194
epoch 32300  training loss: 0.07678866386413574
epoch 32300  clean testing loss: 0.04450920596718788
epoch 32400  training loss: 0.07677296549081802
epoch 32400  clean testing loss: 0.04423685371875763
epoch 32500  training loss: 0.07671911269426346
epoch 32500  clean testing loss: 0.04454668611288071
epoch 32600  training loss: 0.07692214846611023
epoch 32600  clean testing loss: 0.044611621648073196
epoch 32700  training loss: 0.07684002071619034
epoch 32700  clean testing loss: 0.045092012733221054
epoch 32800  training loss: 0.07665804028511047
epoch 32800  clean testing loss: 0.04465286061167717
epoch 32900  training loss: 0.0767831951379776
epoch 32900  clean testing loss: 0.044845353811979294
epoch 33000  training loss: 0.07684766501188278
epoch 33000  clean testing loss: 0.044685449451208115

 34%|███▍      | 33999/100000 [01:03<02:01, 544.56it/s]
epoch 33100  training loss: 0.07660126686096191
epoch 33100  clean testing loss: 0.04466881975531578
epoch 33200  training loss: 0.07661794126033783
epoch 33200  clean testing loss: 0.04477559030056
epoch 33300  training loss: 0.07663551717996597
epoch 33300  clean testing loss: 0.04464860260486603
epoch 33400  training loss: 0.07657110691070557
epoch 33400  clean testing loss: 0.044600047171115875
epoch 33500  training loss: 0.0765361413359642
epoch 33500  clean testing loss: 0.04473140090703964
epoch 33600  training loss: 0.07658540457487106
epoch 33600  clean testing loss: 0.04463466256856918
epoch 33700  training loss: 0.07652314752340317
epoch 33700  clean testing loss: 0.04445803165435791
epoch 33800  training loss: 0.07655803114175797
epoch 33800  clean testing loss: 0.044557590037584305
epoch 33900  training loss: 0.07669943571090698
epoch 33900  clean testing loss: 0.045055314898490906
epoch 34000  training loss: 0.07651498913764954
epoch 34000  clean testing loss: 0.044550571590662
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 34100  training loss: 0.07651067525148392

 35%|███▌      | 35100/100000 [01:05<02:00, 539.43it/s]
epoch 34200  training loss: 0.07652796059846878
epoch 34200  clean testing loss: 0.045134324580430984
epoch 34300  training loss: 0.07650534063577652
epoch 34300  clean testing loss: 0.045091040432453156
epoch 34400  training loss: 0.07653244584798813
epoch 34400  clean testing loss: 0.04474745690822601
epoch 34500  training loss: 0.07651010900735855
epoch 34500  clean testing loss: 0.0448978915810585
epoch 34600  training loss: 0.07653427124023438
epoch 34600  clean testing loss: 0.044813524931669235
epoch 34700  training loss: 0.07647255808115005
epoch 34700  clean testing loss: 0.045072536915540695
epoch 34800  training loss: 0.07639771699905396
epoch 34800  clean testing loss: 0.045266907662153244
epoch 34900  training loss: 0.07664769142866135
epoch 34900  clean testing loss: 0.045374397188425064
epoch 35000  training loss: 0.0764719769358635
epoch 35000  clean testing loss: 0.04494984447956085
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 35100  training loss: 0.07651569694280624

 36%|███▌      | 36147/100000 [01:07<01:59, 534.06it/s]
epoch 35200  training loss: 0.07640353590250015
epoch 35200  clean testing loss: 0.04491512104868889
epoch 35300  training loss: 0.07634270191192627
epoch 35300  clean testing loss: 0.045183099806308746
epoch 35400  training loss: 0.07634993642568588
epoch 35400  clean testing loss: 0.044704485684633255
epoch 35500  training loss: 0.07627703994512558
epoch 35500  clean testing loss: 0.044843412935733795
epoch 35600  training loss: 0.07625655829906464
epoch 35600  clean testing loss: 0.04519740492105484
epoch 35700  training loss: 0.07632316648960114
epoch 35700  clean testing loss: 0.044958025217056274
epoch 35800  training loss: 0.07624746114015579
epoch 35800  clean testing loss: 0.04523686692118645
epoch 35900  training loss: 0.07629666477441788
epoch 35900  clean testing loss: 0.044923797249794006
epoch 36000  training loss: 0.07622047513723373
epoch 36000  clean testing loss: 0.04492665454745293
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 36100  training loss: 0.07617839425802231
epoch 36100  clean testing loss: 0.04518205299973488
epoch 36200  training loss: 0.07618259638547897

 37%|███▋      | 37242/100000 [01:09<01:56, 539.16it/s]
epoch 36300  training loss: 0.07615108042955399
epoch 36300  clean testing loss: 0.0450267568230629
epoch 36400  training loss: 0.07617245614528656
epoch 36400  clean testing loss: 0.045221392065286636
epoch 36500  training loss: 0.07624258100986481
epoch 36500  clean testing loss: 0.04534045606851578
epoch 36600  training loss: 0.07619737088680267
epoch 36600  clean testing loss: 0.04505390301346779
epoch 36700  training loss: 0.07616761326789856
epoch 36700  clean testing loss: 0.04525776207447052
epoch 36800  training loss: 0.07620345801115036
epoch 36800  clean testing loss: 0.04515902325510979
epoch 36900  training loss: 0.07612742483615875
epoch 36900  clean testing loss: 0.045011572539806366
epoch 37000  training loss: 0.0761633962392807
epoch 37000  clean testing loss: 0.0453408807516098
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 37100  training loss: 0.0761525109410286
epoch 37100  clean testing loss: 0.04529925063252449
epoch 37200  training loss: 0.07614167034626007
epoch 37200  clean testing loss: 0.04511452093720436
epoch 37300  training loss: 0.07617871463298798

 38%|███▊      | 38343/100000 [01:11<01:54, 540.42it/s]
epoch 37400  training loss: 0.07614921778440475
epoch 37400  clean testing loss: 0.0451994426548481
epoch 37500  training loss: 0.07613588124513626
epoch 37500  clean testing loss: 0.04530896991491318
epoch 37600  training loss: 0.07604382932186127
epoch 37600  clean testing loss: 0.04538594186306
epoch 37700  training loss: 0.07599959522485733
epoch 37700  clean testing loss: 0.04517008736729622
epoch 37800  training loss: 0.07600157707929611
epoch 37800  clean testing loss: 0.04518232122063637
epoch 37900  training loss: 0.0759810209274292
epoch 37900  clean testing loss: 0.045359596610069275
epoch 38000  training loss: 0.07603450119495392
epoch 38000  clean testing loss: 0.04561767354607582
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 38100  training loss: 0.07597293704748154
epoch 38100  clean testing loss: 0.04524059221148491
epoch 38200  training loss: 0.07621413469314575
epoch 38200  clean testing loss: 0.045159146189689636
epoch 38300  training loss: 0.07597441226243973
epoch 38300  clean testing loss: 0.04541291296482086
epoch 38400  training loss: 0.07598742842674255

 39%|███▉      | 39385/100000 [01:13<01:51, 542.06it/s]
epoch 38500  training loss: 0.07595721632242203
epoch 38500  clean testing loss: 0.04533468931913376
epoch 38600  training loss: 0.07599595934152603
epoch 38600  clean testing loss: 0.045637574046850204
epoch 38700  training loss: 0.07588817924261093
epoch 38700  clean testing loss: 0.045327767729759216
epoch 38800  training loss: 0.07606416940689087
epoch 38800  clean testing loss: 0.04601055011153221
epoch 38900  training loss: 0.07589053362607956
epoch 38900  clean testing loss: 0.04535975307226181
epoch 39000  training loss: 0.07595523446798325
epoch 39000  clean testing loss: 0.04537971690297127
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 39100  training loss: 0.07585965842008591
epoch 39100  clean testing loss: 0.04558142274618149
epoch 39200  training loss: 0.0758284255862236
epoch 39200  clean testing loss: 0.0453481450676918
epoch 39300  training loss: 0.0758926123380661
epoch 39300  clean testing loss: 0.04543570801615715
epoch 39400  training loss: 0.07584457844495773

 40%|████      | 40489/100000 [01:15<01:49, 544.55it/s]
epoch 39500  training loss: 0.07581158727407455
epoch 39500  clean testing loss: 0.04533388093113899
epoch 39600  training loss: 0.07584524154663086
epoch 39600  clean testing loss: 0.04554833844304085
epoch 39700  training loss: 0.0758359283208847
epoch 39700  clean testing loss: 0.04543989524245262
epoch 39800  training loss: 0.07582282274961472
epoch 39800  clean testing loss: 0.045700959861278534
epoch 39900  training loss: 0.0757681280374527
epoch 39900  clean testing loss: 0.04544844105839729
epoch 40000  training loss: 0.07584378123283386
epoch 40000  clean testing loss: 0.0454641692340374
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 40100  training loss: 0.07576585561037064
epoch 40100  clean testing loss: 0.04544591158628464
epoch 40200  training loss: 0.07577879726886749
epoch 40200  clean testing loss: 0.045601461082696915
epoch 40300  training loss: 0.0757710412144661
epoch 40300  clean testing loss: 0.045386653393507004
epoch 40400  training loss: 0.07575880736112595
epoch 40400  clean testing loss: 0.04560791328549385
epoch 40500  training loss: 0.07575397193431854

 42%|████▏     | 41538/100000 [01:17<01:48, 539.29it/s]
epoch 40600  training loss: 0.07576169818639755
epoch 40600  clean testing loss: 0.045713648200035095
epoch 40700  training loss: 0.0757148489356041
epoch 40700  clean testing loss: 0.04546481370925903
epoch 40800  training loss: 0.07576170563697815
epoch 40800  clean testing loss: 0.045716967433691025
epoch 40900  training loss: 0.075727678835392
epoch 40900  clean testing loss: 0.04547605663537979
epoch 41000  training loss: 0.07571130990982056
epoch 41000  clean testing loss: 0.045619990676641464
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 41100  training loss: 0.07566972821950912
epoch 41100  clean testing loss: 0.04576129466295242
epoch 41200  training loss: 0.07571133971214294
epoch 41200  clean testing loss: 0.04545077309012413
epoch 41300  training loss: 0.07569731771945953
epoch 41300  clean testing loss: 0.04555877670645714
epoch 41400  training loss: 0.07570429146289825
epoch 41400  clean testing loss: 0.04582640156149864
epoch 41500  training loss: 0.07563172280788422
epoch 41500  clean testing loss: 0.045746807008981705
epoch 41600  training loss: 0.07565860450267792

 43%|████▎     | 42644/100000 [01:19<01:45, 541.91it/s]
epoch 41700  training loss: 0.07578282803297043
epoch 41700  clean testing loss: 0.045592453330755234
epoch 41800  training loss: 0.07561876624822617
epoch 41800  clean testing loss: 0.04564018175005913
epoch 41900  training loss: 0.07565566152334213
epoch 41900  clean testing loss: 0.045916274189949036
epoch 42000  training loss: 0.07561109960079193
epoch 42000  clean testing loss: 0.04565683379769325
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 42100  training loss: 0.07556021213531494
epoch 42100  clean testing loss: 0.04562677443027496
epoch 42200  training loss: 0.07554387301206589
epoch 42200  clean testing loss: 0.04575257748365402
epoch 42300  training loss: 0.07559256255626678
epoch 42300  clean testing loss: 0.045731257647275925
epoch 42400  training loss: 0.07554382085800171
epoch 42400  clean testing loss: 0.04576494172215462
epoch 42500  training loss: 0.0755482167005539
epoch 42500  clean testing loss: 0.045659616589546204
epoch 42600  training loss: 0.07563018798828125
epoch 42600  clean testing loss: 0.045599229633808136
epoch 42700  training loss: 0.07550215721130371

 44%|████▎     | 43690/100000 [01:21<01:43, 542.60it/s]
epoch 42800  training loss: 0.07548762857913971
epoch 42800  clean testing loss: 0.0457574799656868
epoch 42900  training loss: 0.07550177723169327
epoch 42900  clean testing loss: 0.04562504217028618
epoch 43000  training loss: 0.07556817680597305
epoch 43000  clean testing loss: 0.0460231639444828
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 43100  training loss: 0.07543551176786423
epoch 43100  clean testing loss: 0.04568488523364067
epoch 43200  training loss: 0.07537303119897842
epoch 43200  clean testing loss: 0.0454886257648468
epoch 43300  training loss: 0.07534216344356537
epoch 43300  clean testing loss: 0.045495059341192245
epoch 43400  training loss: 0.0753641426563263
epoch 43400  clean testing loss: 0.045807063579559326
epoch 43500  training loss: 0.07531267404556274
epoch 43500  clean testing loss: 0.04565800726413727
epoch 43600  training loss: 0.07531192153692245
epoch 43600  clean testing loss: 0.04555387794971466
epoch 43700  training loss: 0.07534120976924896
epoch 43700  clean testing loss: 0.04572424292564392
epoch 43800  training loss: 0.07532896846532822

 45%|████▍     | 44788/100000 [01:23<01:41, 541.75it/s]
epoch 43900  training loss: 0.07529138028621674
epoch 43900  clean testing loss: 0.045615553855895996
epoch 44000  training loss: 0.07524903863668442
epoch 44000  clean testing loss: 0.04560237377882004
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 44100  training loss: 0.07533734291791916
epoch 44100  clean testing loss: 0.04574626311659813
epoch 44200  training loss: 0.07520544528961182
epoch 44200  clean testing loss: 0.045575618743896484
epoch 44300  training loss: 0.07522301375865936
epoch 44300  clean testing loss: 0.04553227126598358
epoch 44400  training loss: 0.07519599050283432
epoch 44400  clean testing loss: 0.0456312894821167
epoch 44500  training loss: 0.07518397271633148
epoch 44500  clean testing loss: 0.04598298296332359
epoch 44600  training loss: 0.07517626881599426
epoch 44600  clean testing loss: 0.04561237618327141
epoch 44700  training loss: 0.07521557807922363
epoch 44700  clean testing loss: 0.045644618570804596
epoch 44800  training loss: 0.07515771687030792

 46%|████▌     | 45821/100000 [01:25<01:41, 535.51it/s]
epoch 44900  training loss: 0.07515889406204224
epoch 44900  clean testing loss: 0.04563800245523453
epoch 45000  training loss: 0.07515104115009308
epoch 45000  clean testing loss: 0.045756060630083084
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 45100  training loss: 0.07510509341955185
epoch 45100  clean testing loss: 0.04581510275602341
epoch 45200  training loss: 0.07509622722864151
epoch 45200  clean testing loss: 0.045749224722385406
epoch 45300  training loss: 0.07509245723485947
epoch 45300  clean testing loss: 0.04586759954690933
epoch 45400  training loss: 0.07507387548685074
epoch 45400  clean testing loss: 0.04576839506626129
epoch 45500  training loss: 0.07507367432117462
epoch 45500  clean testing loss: 0.045779816806316376
epoch 45600  training loss: 0.07506954669952393
epoch 45600  clean testing loss: 0.04579745605587959
epoch 45700  training loss: 0.07507622241973877
epoch 45700  clean testing loss: 0.045815255492925644
epoch 45800  training loss: 0.07507135719060898
epoch 45800  clean testing loss: 0.045661889016628265
epoch 45900  training loss: 0.0750584602355957

 47%|████▋     | 46922/100000 [01:27<01:38, 540.68it/s]
epoch 46000  training loss: 0.07504213601350784
epoch 46000  clean testing loss: 0.04584823176264763
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 46100  training loss: 0.07502955943346024
epoch 46100  clean testing loss: 0.045912258327007294
epoch 46200  training loss: 0.07503049820661545
epoch 46200  clean testing loss: 0.045851126313209534
epoch 46300  training loss: 0.07501934468746185
epoch 46300  clean testing loss: 0.045855045318603516
epoch 46400  training loss: 0.07504801452159882
epoch 46400  clean testing loss: 0.04590389505028725
epoch 46500  training loss: 0.07499274611473083
epoch 46500  clean testing loss: 0.04575280100107193
epoch 46600  training loss: 0.07500746101140976
epoch 46600  clean testing loss: 0.04599916189908981
epoch 46700  training loss: 0.07498110830783844
epoch 46700  clean testing loss: 0.04583895951509476
epoch 46800  training loss: 0.07496784627437592
epoch 46800  clean testing loss: 0.045925624668598175
epoch 46900  training loss: 0.07498116046190262
epoch 46900  clean testing loss: 0.04588492959737778
epoch 47000  training loss: 0.07498098164796829
epoch 47000  clean testing loss: 0.045898616313934326

 48%|████▊     | 47963/100000 [01:29<01:35, 543.19it/s]
epoch 47100  training loss: 0.07495411485433578
epoch 47100  clean testing loss: 0.04602030664682388
epoch 47200  training loss: 0.07496821880340576
epoch 47200  clean testing loss: 0.04581430181860924
epoch 47300  training loss: 0.07492905110120773
epoch 47300  clean testing loss: 0.0459478385746479
epoch 47400  training loss: 0.07491857558488846
epoch 47400  clean testing loss: 0.04599831625819206
epoch 47500  training loss: 0.07490900903940201
epoch 47500  clean testing loss: 0.045931294560432434
epoch 47600  training loss: 0.07493611425161362
epoch 47600  clean testing loss: 0.0459074042737484
epoch 47700  training loss: 0.07491019368171692
epoch 47700  clean testing loss: 0.04596354067325592
epoch 47800  training loss: 0.07490246742963791
epoch 47800  clean testing loss: 0.046032410115003586
epoch 47900  training loss: 0.07489610463380814
epoch 47900  clean testing loss: 0.04588811844587326
epoch 48000  training loss: 0.07491177320480347
epoch 48000  clean testing loss: 0.046011485159397125

 49%|████▉     | 49066/100000 [01:31<01:34, 537.89it/s]
epoch 48100  training loss: 0.07486940920352936
epoch 48100  clean testing loss: 0.04600037634372711
epoch 48200  training loss: 0.07484112679958344
epoch 48200  clean testing loss: 0.04600604623556137
epoch 48300  training loss: 0.07485727965831757
epoch 48300  clean testing loss: 0.04595944657921791
epoch 48400  training loss: 0.07484486699104309
epoch 48400  clean testing loss: 0.04599255695939064
epoch 48500  training loss: 0.0748525857925415
epoch 48500  clean testing loss: 0.04602736979722977
epoch 48600  training loss: 0.0748310312628746
epoch 48600  clean testing loss: 0.04598378762602806
epoch 48700  training loss: 0.0748388022184372
epoch 48700  clean testing loss: 0.046075183898210526
epoch 48800  training loss: 0.0748182088136673
epoch 48800  clean testing loss: 0.04603675752878189
epoch 48900  training loss: 0.07483439892530441
epoch 48900  clean testing loss: 0.04614020138978958
epoch 49000  training loss: 0.0748337134718895
epoch 49000  clean testing loss: 0.04619462043046951
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 49100  training loss: 0.07479263842105865

 50%|█████     | 50111/100000 [01:33<01:33, 532.89it/s]
epoch 49200  training loss: 0.07479497045278549
epoch 49200  clean testing loss: 0.045987457036972046
epoch 49300  training loss: 0.07478070259094238
epoch 49300  clean testing loss: 0.046120770275592804
epoch 49400  training loss: 0.07479744404554367
epoch 49400  clean testing loss: 0.04599195346236229
epoch 49500  training loss: 0.07476790249347687
epoch 49500  clean testing loss: 0.04609115049242973
epoch 49600  training loss: 0.074775330722332
epoch 49600  clean testing loss: 0.04605114832520485
epoch 49700  training loss: 0.07476706057786942
epoch 49700  clean testing loss: 0.0461157001554966
epoch 49800  training loss: 0.07478304952383041
epoch 49800  clean testing loss: 0.04613432288169861
epoch 49900  training loss: 0.07473768293857574
epoch 49900  clean testing loss: 0.046124935150146484
epoch 50000  training loss: 0.07475773990154266
epoch 50000  clean testing loss: 0.04604300111532211
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 50100  training loss: 0.07475008815526962
epoch 50100  clean testing loss: 0.04616820067167282
epoch 50200  training loss: 0.07471273094415665

 51%|█████     | 51203/100000 [01:35<01:31, 533.19it/s]
epoch 50300  training loss: 0.07472072541713715
epoch 50300  clean testing loss: 0.04606717452406883
epoch 50400  training loss: 0.07470369338989258
epoch 50400  clean testing loss: 0.04617203772068024
epoch 50500  training loss: 0.07471832633018494
epoch 50500  clean testing loss: 0.04627225548028946
epoch 50600  training loss: 0.07469829171895981
epoch 50600  clean testing loss: 0.04625322297215462
epoch 50700  training loss: 0.07474031299352646
epoch 50700  clean testing loss: 0.04632065072655678
epoch 50800  training loss: 0.07472971081733704
epoch 50800  clean testing loss: 0.04613995552062988
epoch 50900  training loss: 0.07471738010644913
epoch 50900  clean testing loss: 0.04614441096782684
epoch 51000  training loss: 0.07466915994882584
epoch 51000  clean testing loss: 0.04621613398194313
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 51100  training loss: 0.07465378940105438
epoch 51100  clean testing loss: 0.046178173273801804
epoch 51200  training loss: 0.07466959208250046
epoch 51200  clean testing loss: 0.04617587476968765
epoch 51300  training loss: 0.074655681848526

 52%|█████▏    | 52301/100000 [01:37<01:28, 538.28it/s]
epoch 51400  training loss: 0.07463818788528442
epoch 51400  clean testing loss: 0.0462271124124527
epoch 51500  training loss: 0.07463423162698746
epoch 51500  clean testing loss: 0.04621635749936104
epoch 51600  training loss: 0.07462747395038605
epoch 51600  clean testing loss: 0.046164851635694504
epoch 51700  training loss: 0.0746484100818634
epoch 51700  clean testing loss: 0.04624565318226814
epoch 51800  training loss: 0.07462814450263977
epoch 51800  clean testing loss: 0.04621444270014763
epoch 51900  training loss: 0.0746450200676918
epoch 51900  clean testing loss: 0.0461849682033062
epoch 52000  training loss: 0.07464125007390976
epoch 52000  clean testing loss: 0.04615437984466553
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 52100  training loss: 0.07461864501237869
epoch 52100  clean testing loss: 0.04622365161776543
epoch 52200  training loss: 0.07460487633943558
epoch 52200  clean testing loss: 0.04622460529208183
epoch 52300  training loss: 0.07459163665771484

 53%|█████▎    | 53347/100000 [01:39<01:26, 539.64it/s]
epoch 52400  training loss: 0.07461199909448624
epoch 52400  clean testing loss: 0.04620927944779396
epoch 52500  training loss: 0.07460828125476837
epoch 52500  clean testing loss: 0.04634004458785057
epoch 52600  training loss: 0.07457239180803299
epoch 52600  clean testing loss: 0.04625226929783821
epoch 52700  training loss: 0.07457458227872849
epoch 52700  clean testing loss: 0.04617410525679588
epoch 52800  training loss: 0.07456294447183609
epoch 52800  clean testing loss: 0.046344298869371414
epoch 52900  training loss: 0.07455340027809143
epoch 52900  clean testing loss: 0.04635085165500641
epoch 53000  training loss: 0.07455435395240784
epoch 53000  clean testing loss: 0.046229105442762375
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 53100  training loss: 0.07454387098550797
epoch 53100  clean testing loss: 0.04622606933116913
epoch 53200  training loss: 0.07456619292497635
epoch 53200  clean testing loss: 0.04622301459312439
epoch 53300  training loss: 0.07453414052724838
epoch 53300  clean testing loss: 0.04627108946442604
epoch 53400  training loss: 0.07452590018510818

 54%|█████▍    | 54449/100000 [01:41<01:24, 541.43it/s]
epoch 53500  training loss: 0.07452888786792755
epoch 53500  clean testing loss: 0.04628518968820572
epoch 53600  training loss: 0.07452092319726944
epoch 53600  clean testing loss: 0.04631780460476875
epoch 53700  training loss: 0.07452487200498581
epoch 53700  clean testing loss: 0.046315934509038925
epoch 53800  training loss: 0.07451310008764267
epoch 53800  clean testing loss: 0.04627900943160057
epoch 53900  training loss: 0.0745137557387352
epoch 53900  clean testing loss: 0.04642773047089577
epoch 54000  training loss: 0.07450755685567856
epoch 54000  clean testing loss: 0.04632502794265747
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 54100  training loss: 0.0744853988289833
epoch 54100  clean testing loss: 0.04627498984336853
epoch 54200  training loss: 0.07448114454746246
epoch 54200  clean testing loss: 0.0463729165494442
epoch 54300  training loss: 0.07448071986436844
epoch 54300  clean testing loss: 0.046362634748220444
epoch 54400  training loss: 0.0744713768362999
epoch 54400  clean testing loss: 0.046340085566043854
epoch 54500  training loss: 0.07447775453329086

 55%|█████▌    | 55492/100000 [01:43<01:22, 538.30it/s]
epoch 54600  training loss: 0.0744636282324791
epoch 54600  clean testing loss: 0.046320535242557526
epoch 54700  training loss: 0.07446815073490143
epoch 54700  clean testing loss: 0.04639044404029846
epoch 54800  training loss: 0.07447828352451324
epoch 54800  clean testing loss: 0.046401116997003555
epoch 54900  training loss: 0.07445226609706879
epoch 54900  clean testing loss: 0.046384263783693314
epoch 55000  training loss: 0.07446524500846863
epoch 55000  clean testing loss: 0.04632635787129402
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 55100  training loss: 0.0744502991437912
epoch 55100  clean testing loss: 0.046477217227220535
epoch 55200  training loss: 0.07443948835134506
epoch 55200  clean testing loss: 0.0464361347258091
epoch 55300  training loss: 0.07442568242549896
epoch 55300  clean testing loss: 0.04639866203069687
epoch 55400  training loss: 0.07444062829017639
epoch 55400  clean testing loss: 0.046299707144498825
epoch 55500  training loss: 0.0744214802980423
epoch 55500  clean testing loss: 0.04638263210654259
epoch 55600  training loss: 0.07441429048776627

 57%|█████▋    | 56591/100000 [01:45<01:19, 544.53it/s]
epoch 55700  training loss: 0.07441092282533646
epoch 55700  clean testing loss: 0.04630938172340393
epoch 55800  training loss: 0.0744113177061081
epoch 55800  clean testing loss: 0.04650767520070076
epoch 55900  training loss: 0.07439300417900085
epoch 55900  clean testing loss: 0.04638341814279556
epoch 56000  training loss: 0.07439638674259186
epoch 56000  clean testing loss: 0.04648999124765396
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 56100  training loss: 0.07437781244516373
epoch 56100  clean testing loss: 0.046403102576732635
epoch 56200  training loss: 0.07439395040273666
epoch 56200  clean testing loss: 0.04646122828125954
epoch 56300  training loss: 0.07436816394329071
epoch 56300  clean testing loss: 0.04647314175963402
epoch 56400  training loss: 0.07437686622142792
epoch 56400  clean testing loss: 0.04641101136803627
epoch 56500  training loss: 0.07436791062355042
epoch 56500  clean testing loss: 0.04641793295741081
epoch 56600  training loss: 0.07435259968042374
epoch 56600  clean testing loss: 0.04636582359671593
epoch 56700  training loss: 0.07434272766113281

 58%|█████▊    | 57689/100000 [01:47<01:18, 542.28it/s]
epoch 56800  training loss: 0.0743430107831955
epoch 56800  clean testing loss: 0.04647127911448479
epoch 56900  training loss: 0.0743408054113388
epoch 56900  clean testing loss: 0.04646977037191391
epoch 57000  training loss: 0.07432308048009872
epoch 57000  clean testing loss: 0.046549346297979355
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 57100  training loss: 0.07432206720113754
epoch 57100  clean testing loss: 0.04644998535513878
epoch 57200  training loss: 0.0743139386177063
epoch 57200  clean testing loss: 0.04645286872982979
epoch 57300  training loss: 0.07432405650615692
epoch 57300  clean testing loss: 0.046505071222782135
epoch 57400  training loss: 0.07430865615606308
epoch 57400  clean testing loss: 0.04656147584319115
epoch 57500  training loss: 0.07429598271846771
epoch 57500  clean testing loss: 0.046498853713274
epoch 57600  training loss: 0.07429587841033936
epoch 57600  clean testing loss: 0.046587955206632614
epoch 57700  training loss: 0.07429805397987366

 59%|█████▊    | 58732/100000 [01:49<01:16, 540.36it/s]
epoch 57800  training loss: 0.07428288459777832
epoch 57800  clean testing loss: 0.04644767940044403
epoch 57900  training loss: 0.0742914006114006
epoch 57900  clean testing loss: 0.04648889973759651
epoch 58000  training loss: 0.0742749348282814
epoch 58000  clean testing loss: 0.0464944951236248
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 58100  training loss: 0.07427041977643967
epoch 58100  clean testing loss: 0.04652222618460655
epoch 58200  training loss: 0.07426843792200089
epoch 58200  clean testing loss: 0.046546317636966705
epoch 58300  training loss: 0.07426481693983078
epoch 58300  clean testing loss: 0.04650288447737694
epoch 58400  training loss: 0.07426051050424576
epoch 58400  clean testing loss: 0.04645552486181259
epoch 58500  training loss: 0.0742565467953682
epoch 58500  clean testing loss: 0.04658247530460358
epoch 58600  training loss: 0.07424860447645187
epoch 58600  clean testing loss: 0.04656155779957771
epoch 58700  training loss: 0.07424431294202805
epoch 58700  clean testing loss: 0.04653823375701904
epoch 58800  training loss: 0.07424712926149368

 60%|█████▉    | 59834/100000 [01:51<01:14, 540.85it/s]
epoch 58900  training loss: 0.07423102110624313
epoch 58900  clean testing loss: 0.04655713960528374
epoch 59000  training loss: 0.07423140108585358
epoch 59000  clean testing loss: 0.04662052169442177
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 59100  training loss: 0.07422438263893127
epoch 59100  clean testing loss: 0.04651709273457527
epoch 59200  training loss: 0.07423479855060577
epoch 59200  clean testing loss: 0.046518824994564056
epoch 59300  training loss: 0.07423334568738937
epoch 59300  clean testing loss: 0.04651761054992676
epoch 59400  training loss: 0.07421202212572098
epoch 59400  clean testing loss: 0.04656928405165672
epoch 59500  training loss: 0.07421153783798218
epoch 59500  clean testing loss: 0.04657264053821564
epoch 59600  training loss: 0.0742194876074791
epoch 59600  clean testing loss: 0.04654307663440704
epoch 59700  training loss: 0.074208565056324
epoch 59700  clean testing loss: 0.046557653695344925
epoch 59800  training loss: 0.0742136687040329
epoch 59800  clean testing loss: 0.04667682573199272
epoch 59900  training loss: 0.07420001924037933

 61%|██████    | 60875/100000 [01:53<01:12, 540.37it/s]
epoch 60000  training loss: 0.07419100403785706
epoch 60000  clean testing loss: 0.04660162702202797
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 60100  training loss: 0.07418239116668701
epoch 60100  clean testing loss: 0.04661174863576889
epoch 60200  training loss: 0.07418370246887207
epoch 60200  clean testing loss: 0.046683188527822495
epoch 60300  training loss: 0.07417351007461548
epoch 60300  clean testing loss: 0.04664991423487663
epoch 60400  training loss: 0.07417377084493637
epoch 60400  clean testing loss: 0.04655608907341957
epoch 60500  training loss: 0.07417149096727371
epoch 60500  clean testing loss: 0.046597499400377274
epoch 60600  training loss: 0.0741647407412529
epoch 60600  clean testing loss: 0.04659660533070564
epoch 60700  training loss: 0.07416506856679916
epoch 60700  clean testing loss: 0.04658006876707077
epoch 60800  training loss: 0.07416079938411713
epoch 60800  clean testing loss: 0.04670471325516701
epoch 60900  training loss: 0.07415798306465149
epoch 60900  clean testing loss: 0.046581536531448364
epoch 61000  training loss: 0.07415128499269485
epoch 61000  clean testing loss: 0.04660675302147865

 62%|██████▏   | 61915/100000 [01:55<01:11, 533.68it/s]
epoch 61100  training loss: 0.074148029088974
epoch 61100  clean testing loss: 0.04660525172948837
epoch 61200  training loss: 0.07414178550243378
epoch 61200  clean testing loss: 0.04657930135726929
epoch 61300  training loss: 0.074140764772892
epoch 61300  clean testing loss: 0.046612225472927094
epoch 61400  training loss: 0.07413481175899506
epoch 61400  clean testing loss: 0.046625733375549316
epoch 61500  training loss: 0.07413623481988907
epoch 61500  clean testing loss: 0.04663733392953873
epoch 61600  training loss: 0.07413424551486969
epoch 61600  clean testing loss: 0.04663246497511864
epoch 61700  training loss: 0.07412652671337128
epoch 61700  clean testing loss: 0.04664131626486778
epoch 61800  training loss: 0.07412879168987274
epoch 61800  clean testing loss: 0.04662188142538071
epoch 61900  training loss: 0.07412640750408173
epoch 61900  clean testing loss: 0.04673300310969353
epoch 62000  training loss: 0.0741247907280922
epoch 62000  clean testing loss: 0.04663535952568054

 63%|██████▎   | 63016/100000 [01:57<01:09, 529.90it/s]
epoch 62100  training loss: 0.07411113381385803
epoch 62100  clean testing loss: 0.04667633771896362
epoch 62200  training loss: 0.07411327958106995
epoch 62200  clean testing loss: 0.04667143523693085
epoch 62300  training loss: 0.07410601526498795
epoch 62300  clean testing loss: 0.04665857180953026
epoch 62400  training loss: 0.07409720867872238
epoch 62400  clean testing loss: 0.046609897166490555
epoch 62500  training loss: 0.07409894466400146
epoch 62500  clean testing loss: 0.04666681960225105
epoch 62600  training loss: 0.07409112900495529
epoch 62600  clean testing loss: 0.04670248553156853
epoch 62700  training loss: 0.07408346980810165
epoch 62700  clean testing loss: 0.04670996591448784
epoch 62800  training loss: 0.07409060001373291
epoch 62800  clean testing loss: 0.04658828303217888
epoch 62900  training loss: 0.07408864051103592
epoch 62900  clean testing loss: 0.04678603261709213
epoch 63000  training loss: 0.07407284528017044
epoch 63000  clean testing loss: 0.04668031632900238
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 63100  training loss: 0.07406257092952728

 64%|██████▍   | 64062/100000 [01:59<01:07, 536.08it/s]
epoch 63200  training loss: 0.07406018674373627
epoch 63200  clean testing loss: 0.04668603464961052
epoch 63300  training loss: 0.07406109571456909
epoch 63300  clean testing loss: 0.04670985788106918
epoch 63400  training loss: 0.07405794411897659
epoch 63400  clean testing loss: 0.04669761285185814
epoch 63500  training loss: 0.07405556738376617
epoch 63500  clean testing loss: 0.04665478691458702
epoch 63600  training loss: 0.07406091690063477
epoch 63600  clean testing loss: 0.04670549929141998
epoch 63700  training loss: 0.07405351847410202
epoch 63700  clean testing loss: 0.04665057733654976
epoch 63800  training loss: 0.07405269145965576
epoch 63800  clean testing loss: 0.046694766730070114
epoch 63900  training loss: 0.07404372096061707
epoch 63900  clean testing loss: 0.046692073345184326
epoch 64000  training loss: 0.07403779774904251
epoch 64000  clean testing loss: 0.04673422500491142
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 64100  training loss: 0.07403700798749924

 65%|██████▌   | 65160/100000 [02:01<01:04, 536.29it/s]
epoch 64200  training loss: 0.074033722281456
epoch 64200  clean testing loss: 0.046694546937942505
epoch 64300  training loss: 0.07402697205543518
epoch 64300  clean testing loss: 0.04671500250697136
epoch 64400  training loss: 0.0740271508693695
epoch 64400  clean testing loss: 0.04672187194228172
epoch 64500  training loss: 0.07402046024799347
epoch 64500  clean testing loss: 0.0467500165104866
epoch 64600  training loss: 0.07402163743972778
epoch 64600  clean testing loss: 0.046697694808244705
epoch 64700  training loss: 0.07401955872774124
epoch 64700  clean testing loss: 0.04676347225904465
epoch 64800  training loss: 0.0740152895450592
epoch 64800  clean testing loss: 0.04675548896193504
epoch 64900  training loss: 0.07401005178689957
epoch 64900  clean testing loss: 0.04677160084247589
epoch 65000  training loss: 0.07400302588939667
epoch 65000  clean testing loss: 0.04672742262482643
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 65100  training loss: 0.07400219887495041
epoch 65100  clean testing loss: 0.04676692932844162
epoch 65200  training loss: 0.0739971324801445

 66%|██████▋   | 66256/100000 [02:03<01:02, 536.87it/s]
epoch 65300  training loss: 0.07400079816579819
epoch 65300  clean testing loss: 0.0467643141746521
epoch 65400  training loss: 0.07398958504199982
epoch 65400  clean testing loss: 0.046792350709438324
epoch 65500  training loss: 0.07398730516433716
epoch 65500  clean testing loss: 0.046735651791095734
epoch 65600  training loss: 0.07398885488510132
epoch 65600  clean testing loss: 0.0467563271522522
epoch 65700  training loss: 0.07398723065853119
epoch 65700  clean testing loss: 0.04676779732108116
epoch 65800  training loss: 0.07398419827222824
epoch 65800  clean testing loss: 0.04679874703288078
epoch 65900  training loss: 0.07397876679897308
epoch 65900  clean testing loss: 0.04677971452474594
epoch 66000  training loss: 0.07397406548261642
epoch 66000  clean testing loss: 0.04678702726960182
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 66100  training loss: 0.07396919280290604
epoch 66100  clean testing loss: 0.04680117219686508
epoch 66200  training loss: 0.07396445423364639
epoch 66200  clean testing loss: 0.04674352705478668
epoch 66300  training loss: 0.07396586239337921

 67%|██████▋   | 67296/100000 [02:05<01:00, 541.61it/s]
epoch 66400  training loss: 0.07396240532398224
epoch 66400  clean testing loss: 0.04675557464361191
epoch 66500  training loss: 0.07395589351654053
epoch 66500  clean testing loss: 0.04680173099040985
epoch 66600  training loss: 0.07395486533641815
epoch 66600  clean testing loss: 0.04677911102771759
epoch 66700  training loss: 0.07395250350236893
epoch 66700  clean testing loss: 0.04679689183831215
epoch 66800  training loss: 0.07395059615373611
epoch 66800  clean testing loss: 0.04678913950920105
epoch 66900  training loss: 0.07394953072071075
epoch 66900  clean testing loss: 0.04679084196686745
epoch 67000  training loss: 0.07394193857908249
epoch 67000  clean testing loss: 0.046818897128105164
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 67100  training loss: 0.07394257187843323
epoch 67100  clean testing loss: 0.04684697091579437
epoch 67200  training loss: 0.0739392563700676
epoch 67200  clean testing loss: 0.04681050404906273
epoch 67300  training loss: 0.07393421977758408
epoch 67300  clean testing loss: 0.046825651079416275
epoch 67400  training loss: 0.0739346519112587

 68%|██████▊   | 68391/100000 [02:07<00:58, 542.09it/s]
epoch 67500  training loss: 0.07393179088830948
epoch 67500  clean testing loss: 0.04683254286646843
epoch 67600  training loss: 0.07392740994691849
epoch 67600  clean testing loss: 0.04686187207698822
epoch 67700  training loss: 0.07392797619104385
epoch 67700  clean testing loss: 0.0468377061188221
epoch 67800  training loss: 0.0739213079214096
epoch 67800  clean testing loss: 0.04682863876223564
epoch 67900  training loss: 0.07392696291208267
epoch 67900  clean testing loss: 0.04683030769228935
epoch 68000  training loss: 0.07391701638698578
epoch 68000  clean testing loss: 0.04681007191538811
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 68100  training loss: 0.0739142894744873
epoch 68100  clean testing loss: 0.04687861353158951
epoch 68200  training loss: 0.0739118680357933
epoch 68200  clean testing loss: 0.046847451478242874
epoch 68300  training loss: 0.07391015440225601
epoch 68300  clean testing loss: 0.0468047633767128
epoch 68400  training loss: 0.07390857487916946
epoch 68400  clean testing loss: 0.046857934445142746
epoch 68500  training loss: 0.07390250265598297

 69%|██████▉   | 69493/100000 [02:09<00:56, 544.56it/s]
epoch 68600  training loss: 0.07389908283948898
epoch 68600  clean testing loss: 0.046817995607852936
epoch 68700  training loss: 0.07390009611845016
epoch 68700  clean testing loss: 0.04685414209961891
epoch 68800  training loss: 0.07389143109321594
epoch 68800  clean testing loss: 0.04687820002436638
epoch 68900  training loss: 0.07389314472675323
epoch 68900  clean testing loss: 0.04687535762786865
epoch 69000  training loss: 0.07388933002948761
epoch 69000  clean testing loss: 0.046862613409757614
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 69100  training loss: 0.07388413697481155
epoch 69100  clean testing loss: 0.046860285103321075
epoch 69200  training loss: 0.07388372719287872
epoch 69200  clean testing loss: 0.04686690494418144
epoch 69300  training loss: 0.07388107478618622
epoch 69300  clean testing loss: 0.04684329777956009
epoch 69400  training loss: 0.07387910038232803
epoch 69400  clean testing loss: 0.04689060524106026
epoch 69500  training loss: 0.07387372106313705

 71%|███████   | 70543/100000 [02:11<00:54, 541.47it/s]
epoch 69600  training loss: 0.07387247681617737
epoch 69600  clean testing loss: 0.046881575137376785
epoch 69700  training loss: 0.07386864721775055
epoch 69700  clean testing loss: 0.04687504842877388
epoch 69800  training loss: 0.07386693358421326
epoch 69800  clean testing loss: 0.046860817819833755
epoch 69900  training loss: 0.07386508584022522
epoch 69900  clean testing loss: 0.04687731713056564
epoch 70000  training loss: 0.07386314868927002
epoch 70000  clean testing loss: 0.04685341939330101
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 70100  training loss: 0.07386079430580139
epoch 70100  clean testing loss: 0.04688527435064316
epoch 70200  training loss: 0.07385857403278351
epoch 70200  clean testing loss: 0.04685841500759125
epoch 70300  training loss: 0.07385507225990295
epoch 70300  clean testing loss: 0.04688941314816475
epoch 70400  training loss: 0.07385478168725967
epoch 70400  clean testing loss: 0.04688823223114014
epoch 70500  training loss: 0.07385209202766418
epoch 70500  clean testing loss: 0.046874675899744034
epoch 70600  training loss: 0.07384732365608215

 72%|███████▏  | 71641/100000 [02:13<00:53, 534.36it/s]
epoch 70700  training loss: 0.07384810596704483
epoch 70700  clean testing loss: 0.04688962921500206
epoch 70800  training loss: 0.07384512573480606
epoch 70800  clean testing loss: 0.04691594839096069
epoch 70900  training loss: 0.0738399401307106
epoch 70900  clean testing loss: 0.046891096979379654
epoch 71000  training loss: 0.07384022325277328
epoch 71000  clean testing loss: 0.04686795920133591
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 71100  training loss: 0.07383807003498077
epoch 71100  clean testing loss: 0.04692335054278374
epoch 71200  training loss: 0.07383622974157333
epoch 71200  clean testing loss: 0.04692784324288368
epoch 71300  training loss: 0.07383058220148087
epoch 71300  clean testing loss: 0.04690241441130638
epoch 71400  training loss: 0.07382889091968536
epoch 71400  clean testing loss: 0.04688878357410431
epoch 71500  training loss: 0.07382800430059433
epoch 71500  clean testing loss: 0.04691796749830246
epoch 71600  training loss: 0.07382811605930328
epoch 71600  clean testing loss: 0.046913519501686096
epoch 71700  training loss: 0.07382449507713318

 73%|███████▎  | 72680/100000 [02:15<00:50, 542.46it/s]
epoch 71800  training loss: 0.07382196187973022
epoch 71800  clean testing loss: 0.04693899676203728
epoch 71900  training loss: 0.07382066547870636
epoch 71900  clean testing loss: 0.04692579060792923
epoch 72000  training loss: 0.07381561398506165
epoch 72000  clean testing loss: 0.0469241589307785
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 72100  training loss: 0.07380957901477814
epoch 72100  clean testing loss: 0.04691937938332558
epoch 72200  training loss: 0.07380835711956024
epoch 72200  clean testing loss: 0.04690754786133766
epoch 72300  training loss: 0.07380680739879608
epoch 72300  clean testing loss: 0.046920474618673325
epoch 72400  training loss: 0.07380605489015579
epoch 72400  clean testing loss: 0.04693603515625
epoch 72500  training loss: 0.07380575686693192
epoch 72500  clean testing loss: 0.04694107919931412
epoch 72600  training loss: 0.07380253076553345
epoch 72600  clean testing loss: 0.04696245864033699
epoch 72700  training loss: 0.07380250096321106
epoch 72700  clean testing loss: 0.04693205654621124
epoch 72800  training loss: 0.07379753142595291

 74%|███████▍  | 73781/100000 [02:17<00:48, 543.30it/s]
epoch 72900  training loss: 0.0737961009144783
epoch 72900  clean testing loss: 0.04691179841756821
epoch 73000  training loss: 0.07379265874624252
epoch 73000  clean testing loss: 0.04693510755896568
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 73100  training loss: 0.07379071414470673
epoch 73100  clean testing loss: 0.04693468660116196
epoch 73200  training loss: 0.07379034906625748
epoch 73200  clean testing loss: 0.04692307487130165
epoch 73300  training loss: 0.07378733158111572
epoch 73300  clean testing loss: 0.04696023091673851
epoch 73400  training loss: 0.07378502190113068
epoch 73400  clean testing loss: 0.0469445139169693
epoch 73500  training loss: 0.07378441095352173
epoch 73500  clean testing loss: 0.04693366959691048
epoch 73600  training loss: 0.0737801119685173
epoch 73600  clean testing loss: 0.046976376324892044
epoch 73700  training loss: 0.07377714663743973
epoch 73700  clean testing loss: 0.04695802927017212
epoch 73800  training loss: 0.07377398759126663

 75%|███████▍  | 74883/100000 [02:19<00:46, 544.21it/s]
epoch 73900  training loss: 0.07377337664365768
epoch 73900  clean testing loss: 0.04692833870649338
epoch 74000  training loss: 0.07377143949270248
epoch 74000  clean testing loss: 0.04695766046643257
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 74100  training loss: 0.07377005368471146
epoch 74100  clean testing loss: 0.0469539575278759
epoch 74200  training loss: 0.0737685039639473
epoch 74200  clean testing loss: 0.04694278538227081
epoch 74300  training loss: 0.07377059012651443
epoch 74300  clean testing loss: 0.04698709398508072
epoch 74400  training loss: 0.07376030087471008
epoch 74400  clean testing loss: 0.04696355387568474
epoch 74500  training loss: 0.07376116514205933
epoch 74500  clean testing loss: 0.04695955291390419
epoch 74600  training loss: 0.07375984638929367
epoch 74600  clean testing loss: 0.04698539897799492
epoch 74700  training loss: 0.07375509291887283
epoch 74700  clean testing loss: 0.046940531581640244
epoch 74800  training loss: 0.07375708222389221
epoch 74800  clean testing loss: 0.046948082745075226
epoch 74900  training loss: 0.07375070452690125

 76%|███████▌  | 75928/100000 [02:21<00:44, 539.88it/s]
epoch 75000  training loss: 0.07375095784664154
epoch 75000  clean testing loss: 0.046972423791885376
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 75100  training loss: 0.07374081015586853
epoch 75100  clean testing loss: 0.04696384444832802
epoch 75200  training loss: 0.07373762875795364
epoch 75200  clean testing loss: 0.04695764556527138
epoch 75300  training loss: 0.07373557239770889
epoch 75300  clean testing loss: 0.046954233199357986
epoch 75400  training loss: 0.07373414933681488
epoch 75400  clean testing loss: 0.046937305480241776
epoch 75500  training loss: 0.07373082637786865
epoch 75500  clean testing loss: 0.046946167945861816
epoch 75600  training loss: 0.07372775673866272
epoch 75600  clean testing loss: 0.04696079343557358
epoch 75700  training loss: 0.07372836023569107
epoch 75700  clean testing loss: 0.04694224148988724
epoch 75800  training loss: 0.07372606545686722
epoch 75800  clean testing loss: 0.046977847814559937
epoch 75900  training loss: 0.0737222284078598
epoch 75900  clean testing loss: 0.046955280005931854
epoch 76000  training loss: 0.07371953874826431
epoch 76000  clean testing loss: 0.04695425182580948

 77%|███████▋  | 77022/100000 [02:23<00:43, 527.16it/s]
epoch 76100  training loss: 0.07371759414672852
epoch 76100  clean testing loss: 0.04696173965930939
epoch 76200  training loss: 0.0737205520272255
epoch 76200  clean testing loss: 0.04697562754154205
epoch 76300  training loss: 0.07371494174003601
epoch 76300  clean testing loss: 0.04695918411016464
epoch 76400  training loss: 0.0737122967839241
epoch 76400  clean testing loss: 0.04695243388414383
epoch 76500  training loss: 0.07370845973491669
epoch 76500  clean testing loss: 0.04698857665061951
epoch 76600  training loss: 0.07370661944150925
epoch 76600  clean testing loss: 0.04696408659219742
epoch 76700  training loss: 0.07370555400848389
epoch 76700  clean testing loss: 0.04698403179645538
epoch 76800  training loss: 0.07370192557573318
epoch 76800  clean testing loss: 0.04699818417429924
epoch 76900  training loss: 0.07370361685752869
epoch 76900  clean testing loss: 0.04697258397936821
epoch 77000  training loss: 0.07369977235794067
epoch 77000  clean testing loss: 0.04700164124369621
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 77100  training loss: 0.07369580864906311

 78%|███████▊  | 78057/100000 [02:25<00:41, 528.95it/s]
epoch 77200  training loss: 0.07369677722454071
epoch 77200  clean testing loss: 0.047002069652080536
epoch 77300  training loss: 0.07369447499513626
epoch 77300  clean testing loss: 0.04702170193195343
epoch 77400  training loss: 0.07369151711463928
epoch 77400  clean testing loss: 0.046991005539894104
epoch 77500  training loss: 0.07368882745504379
epoch 77500  clean testing loss: 0.04703071713447571
epoch 77600  training loss: 0.0736861452460289
epoch 77600  clean testing loss: 0.04701189696788788
epoch 77700  training loss: 0.07368442416191101
epoch 77700  clean testing loss: 0.04702315852046013
epoch 77800  training loss: 0.07368222624063492
epoch 77800  clean testing loss: 0.047020457684993744
epoch 77900  training loss: 0.07368113845586777
epoch 77900  clean testing loss: 0.04700696840882301
epoch 78000  training loss: 0.0736771672964096
epoch 78000  clean testing loss: 0.04702909663319588
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 78100  training loss: 0.07367729395627975

 79%|███████▉  | 79098/100000 [02:27<00:39, 535.39it/s]
epoch 78200  training loss: 0.07367309927940369
epoch 78200  clean testing loss: 0.04702851176261902
epoch 78300  training loss: 0.07367218285799026
epoch 78300  clean testing loss: 0.04702314734458923
epoch 78400  training loss: 0.07366961985826492
epoch 78400  clean testing loss: 0.046992335468530655
epoch 78500  training loss: 0.07366858422756195
epoch 78500  clean testing loss: 0.04702543839812279
epoch 78600  training loss: 0.07366670668125153
epoch 78600  clean testing loss: 0.04701324552297592
epoch 78700  training loss: 0.07366418838500977
epoch 78700  clean testing loss: 0.04704062640666962
epoch 78800  training loss: 0.07366305589675903
epoch 78800  clean testing loss: 0.047035377472639084
epoch 78900  training loss: 0.07366081327199936
epoch 78900  clean testing loss: 0.04704996943473816
epoch 79000  training loss: 0.07366027683019638
epoch 79000  clean testing loss: 0.04703836143016815
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 79100  training loss: 0.07365759462118149
epoch 79100  clean testing loss: 0.04706105589866638
epoch 79200  training loss: 0.07365719974040985

 80%|████████  | 80190/100000 [02:29<00:36, 539.57it/s]
epoch 79300  training loss: 0.07365532964468002
epoch 79300  clean testing loss: 0.04705272614955902
epoch 79400  training loss: 0.07365333288908005
epoch 79400  clean testing loss: 0.04705080762505531
epoch 79500  training loss: 0.07365201413631439
epoch 79500  clean testing loss: 0.047061480581760406
epoch 79600  training loss: 0.07364961504936218
epoch 79600  clean testing loss: 0.047061737626791
epoch 79700  training loss: 0.07364950329065323
epoch 79700  clean testing loss: 0.04703078046441078
epoch 79800  training loss: 0.07364596426486969
epoch 79800  clean testing loss: 0.04705843701958656
epoch 79900  training loss: 0.07364454865455627
epoch 79900  clean testing loss: 0.04706211015582085
epoch 80000  training loss: 0.07364380359649658
epoch 80000  clean testing loss: 0.04706006869673729
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 80100  training loss: 0.07364173978567123
epoch 80100  clean testing loss: 0.04707343876361847
epoch 80200  training loss: 0.07364127784967422
epoch 80200  clean testing loss: 0.04707755148410797
epoch 80300  training loss: 0.07363792508840561

 81%|████████▏ | 81288/100000 [02:31<00:34, 540.87it/s]
epoch 80400  training loss: 0.07362959533929825
epoch 80400  clean testing loss: 0.04703087732195854
epoch 80500  training loss: 0.07363009452819824
epoch 80500  clean testing loss: 0.04704862833023071
epoch 80600  training loss: 0.07362726330757141
epoch 80600  clean testing loss: 0.04704277217388153
epoch 80700  training loss: 0.07362566143274307
epoch 80700  clean testing loss: 0.04704475402832031
epoch 80800  training loss: 0.07362648844718933
epoch 80800  clean testing loss: 0.047073520720005035
epoch 80900  training loss: 0.07362164556980133
epoch 80900  clean testing loss: 0.047060832381248474
epoch 81000  training loss: 0.07362080365419388
epoch 81000  clean testing loss: 0.04706405848264694
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 81100  training loss: 0.07361679524183273
epoch 81100  clean testing loss: 0.0470670647919178
epoch 81200  training loss: 0.07361498475074768
epoch 81200  clean testing loss: 0.047076884657144547
epoch 81300  training loss: 0.07361416518688202

 82%|████████▏ | 82334/100000 [02:33<00:32, 537.40it/s]
epoch 81400  training loss: 0.07361334562301636
epoch 81400  clean testing loss: 0.04706218093633652
epoch 81500  training loss: 0.07361068576574326
epoch 81500  clean testing loss: 0.04706298187375069
epoch 81600  training loss: 0.07360934466123581
epoch 81600  clean testing loss: 0.04706067219376564
epoch 81700  training loss: 0.07360918074846268
epoch 81700  clean testing loss: 0.047070346772670746
epoch 81800  training loss: 0.07360608875751495
epoch 81800  clean testing loss: 0.04707071930170059
epoch 81900  training loss: 0.07360540330410004
epoch 81900  clean testing loss: 0.04707328975200653
epoch 82000  training loss: 0.07360353320837021
epoch 82000  clean testing loss: 0.047087412327528
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 82100  training loss: 0.0736021175980568
epoch 82100  clean testing loss: 0.047081269323825836
epoch 82200  training loss: 0.0736004188656807
epoch 82200  clean testing loss: 0.047091104090213776
epoch 82300  training loss: 0.07359854876995087
epoch 82300  clean testing loss: 0.0470866933465004
epoch 82400  training loss: 0.07359837740659714

 83%|████████▎ | 83432/100000 [02:35<00:30, 539.75it/s]
epoch 82500  training loss: 0.07359661906957626
epoch 82500  clean testing loss: 0.04708322510123253
epoch 82600  training loss: 0.07359526306390762
epoch 82600  clean testing loss: 0.04709642380475998
epoch 82700  training loss: 0.07359325140714645
epoch 82700  clean testing loss: 0.04708101227879524
epoch 82800  training loss: 0.07359079271554947
epoch 82800  clean testing loss: 0.047093551605939865
epoch 82900  training loss: 0.07359027117490768
epoch 82900  clean testing loss: 0.04709727689623833
epoch 83000  training loss: 0.0735878050327301
epoch 83000  clean testing loss: 0.047105785459280014
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 83100  training loss: 0.0735870897769928
epoch 83100  clean testing loss: 0.047104012221097946
epoch 83200  training loss: 0.07358626276254654
epoch 83200  clean testing loss: 0.0471072793006897
epoch 83300  training loss: 0.07358551025390625
epoch 83300  clean testing loss: 0.04710311442613602
epoch 83400  training loss: 0.07358360290527344
epoch 83400  clean testing loss: 0.04710395261645317
epoch 83500  training loss: 0.07358139753341675

 84%|████████▍ | 84472/100000 [02:37<00:29, 525.23it/s]
epoch 83600  training loss: 0.07357943803071976
epoch 83600  clean testing loss: 0.04709895700216293
epoch 83700  training loss: 0.07357815653085709
epoch 83700  clean testing loss: 0.0471179261803627
epoch 83800  training loss: 0.07357748597860336
epoch 83800  clean testing loss: 0.047110430896282196
epoch 83900  training loss: 0.0735749751329422
epoch 83900  clean testing loss: 0.04710923135280609
epoch 84000  training loss: 0.0735747292637825
epoch 84000  clean testing loss: 0.04711545631289482
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 84100  training loss: 0.07357132434844971
epoch 84100  clean testing loss: 0.0471205860376358
epoch 84200  training loss: 0.07357115298509598
epoch 84200  clean testing loss: 0.047133445739746094
epoch 84300  training loss: 0.07357042282819748
epoch 84300  clean testing loss: 0.0471222847700119
epoch 84400  training loss: 0.07356822490692139
epoch 84400  clean testing loss: 0.04712879657745361
epoch 84500  training loss: 0.07356788963079453
epoch 84500  clean testing loss: 0.047127436846494675

epoch 84600  training loss: 0.07356592267751694
epoch 84600  clean testing loss: 0.04711686819791794
epoch 84700  training loss: 0.0735643282532692
epoch 84700  clean testing loss: 0.04713540896773338
epoch 84800  training loss: 0.07356487959623337
epoch 84800  clean testing loss: 0.04712826386094093
epoch 84900  training loss: 0.07356232404708862
epoch 84900  clean testing loss: 0.0471399687230587
epoch 85000  training loss: 0.07356082648038864
epoch 85000  clean testing loss: 0.04712468385696411
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 85100  training loss: 0.07355967164039612
epoch 85100  clean testing loss: 0.04713023453950882
epoch 85200  training loss: 0.07355768233537674
epoch 85200  clean testing loss: 0.04713687673211098
epoch 85300  training loss: 0.07355772703886032
epoch 85300  clean testing loss: 0.04713756963610649
epoch 85400  training loss: 0.0735560953617096
epoch 85400  clean testing loss: 0.047143660485744476
epoch 85500  training loss: 0.07355460524559021
epoch 85500  clean testing loss: 0.04713546857237816
epoch 85600  training loss: 0.07355378568172455

 87%|████████▋ | 86607/100000 [02:41<00:25, 535.36it/s]
epoch 85700  training loss: 0.07355265319347382
epoch 85700  clean testing loss: 0.04713340848684311
epoch 85800  training loss: 0.07355090975761414
epoch 85800  clean testing loss: 0.04714599996805191
epoch 85900  training loss: 0.07355079054832458
epoch 85900  clean testing loss: 0.04712895303964615
epoch 86000  training loss: 0.0735507532954216
epoch 86000  clean testing loss: 0.047152094542980194
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 86100  training loss: 0.07354795187711716
epoch 86100  clean testing loss: 0.047151751816272736
epoch 86200  training loss: 0.07354659587144852
epoch 86200  clean testing loss: 0.04714606702327728
epoch 86300  training loss: 0.07354551553726196
epoch 86300  clean testing loss: 0.04714920371770859
epoch 86400  training loss: 0.0735449492931366
epoch 86400  clean testing loss: 0.04715085029602051
epoch 86500  training loss: 0.07354322820901871
epoch 86500  clean testing loss: 0.047147754579782486
epoch 86600  training loss: 0.07354192435741425
epoch 86600  clean testing loss: 0.047143206000328064
epoch 86700  training loss: 0.07354065030813217

 88%|████████▊ | 87705/100000 [02:43<00:23, 530.48it/s]
epoch 86800  training loss: 0.07353871315717697
epoch 86800  clean testing loss: 0.04715676233172417
epoch 86900  training loss: 0.0735381469130516
epoch 86900  clean testing loss: 0.0471673384308815
epoch 87000  training loss: 0.07353708893060684
epoch 87000  clean testing loss: 0.047161005437374115
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 87100  training loss: 0.07353512942790985
epoch 87100  clean testing loss: 0.047156620770692825
epoch 87200  training loss: 0.07353388518095016
epoch 87200  clean testing loss: 0.04715414717793465
epoch 87300  training loss: 0.07353301346302032
epoch 87300  clean testing loss: 0.04716644436120987
epoch 87400  training loss: 0.07353337854146957
epoch 87400  clean testing loss: 0.047175005078315735
epoch 87500  training loss: 0.0735316351056099
epoch 87500  clean testing loss: 0.04716399312019348
epoch 87600  training loss: 0.0735301598906517
epoch 87600  clean testing loss: 0.047162964940071106
epoch 87700  training loss: 0.0735292062163353
epoch 87700  clean testing loss: 0.04716837778687477
epoch 87800  training loss: 0.07352793961763382

 89%|████████▉ | 88804/100000 [02:45<00:20, 536.20it/s]
epoch 87900  training loss: 0.07352742552757263
epoch 87900  clean testing loss: 0.04716019704937935
epoch 88000  training loss: 0.07352661341428757
epoch 88000  clean testing loss: 0.04717354103922844
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 88100  training loss: 0.07352540642023087
epoch 88100  clean testing loss: 0.04716368392109871
epoch 88200  training loss: 0.0735236406326294
epoch 88200  clean testing loss: 0.04716549441218376
epoch 88300  training loss: 0.0735233724117279
epoch 88300  clean testing loss: 0.047164659947156906
epoch 88400  training loss: 0.07352233678102493
epoch 88400  clean testing loss: 0.04716627672314644
epoch 88500  training loss: 0.07352179288864136
epoch 88500  clean testing loss: 0.04717901721596718
epoch 88600  training loss: 0.07352013885974884
epoch 88600  clean testing loss: 0.04717409610748291
epoch 88700  training loss: 0.07351943105459213
epoch 88700  clean testing loss: 0.04716697707772255
epoch 88800  training loss: 0.07351762801408768
epoch 88800  clean testing loss: 0.04717286303639412
epoch 88900  training loss: 0.07351702451705933

 90%|████████▉ | 89851/100000 [02:47<00:18, 538.48it/s]
epoch 89000  training loss: 0.07351553440093994
epoch 89000  clean testing loss: 0.04718613624572754
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 89100  training loss: 0.07351471483707428
epoch 89100  clean testing loss: 0.04718048498034477
epoch 89200  training loss: 0.07351396232843399
epoch 89200  clean testing loss: 0.047183092683553696
epoch 89300  training loss: 0.07351253181695938
epoch 89300  clean testing loss: 0.04717593640089035
epoch 89400  training loss: 0.07351158559322357
epoch 89400  clean testing loss: 0.047177888453006744
epoch 89500  training loss: 0.0735115259885788
epoch 89500  clean testing loss: 0.04718821123242378
epoch 89600  training loss: 0.0735108032822609
epoch 89600  clean testing loss: 0.047173310071229935
epoch 89700  training loss: 0.07350874692201614
epoch 89700  clean testing loss: 0.047186970710754395
epoch 89800  training loss: 0.0735081359744072
epoch 89800  clean testing loss: 0.0471990741789341
epoch 89900  training loss: 0.07350713014602661

 91%|█████████ | 90949/100000 [02:49<00:16, 539.53it/s]
epoch 90000  training loss: 0.07350655645132065
epoch 90000  clean testing loss: 0.04718450456857681
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 90100  training loss: 0.07350535690784454
epoch 90100  clean testing loss: 0.047185465693473816
epoch 90200  training loss: 0.07350432127714157
epoch 90200  clean testing loss: 0.047193605452775955
epoch 90300  training loss: 0.07350354641675949
epoch 90300  clean testing loss: 0.04718681052327156
epoch 90400  training loss: 0.0735025703907013
epoch 90400  clean testing loss: 0.04719503968954086
epoch 90500  training loss: 0.07350101321935654
epoch 90500  clean testing loss: 0.047190893441438675
epoch 90600  training loss: 0.07350041717290878
epoch 90600  clean testing loss: 0.04719218611717224
epoch 90700  training loss: 0.07350020110607147
epoch 90700  clean testing loss: 0.04719458892941475
epoch 90800  training loss: 0.07349875569343567
epoch 90800  clean testing loss: 0.047197870910167694
epoch 90900  training loss: 0.07349836081266403
epoch 90900  clean testing loss: 0.047200173139572144
epoch 91000  training loss: 0.07349710166454315
epoch 91000  clean testing loss: 0.047200556844472885

 92%|█████████▏| 91993/100000 [02:51<00:14, 542.65it/s]
epoch 91100  training loss: 0.07349614053964615
epoch 91100  clean testing loss: 0.04720040410757065
epoch 91200  training loss: 0.07349637150764465
epoch 91200  clean testing loss: 0.04720480740070343
epoch 91300  training loss: 0.07349499315023422
epoch 91300  clean testing loss: 0.04720788821578026
epoch 91400  training loss: 0.07349435240030289
epoch 91400  clean testing loss: 0.04720308259129524
epoch 91500  training loss: 0.07349339872598648
epoch 91500  clean testing loss: 0.04720481112599373
epoch 91600  training loss: 0.07349256426095963
epoch 91600  clean testing loss: 0.0472000390291214
epoch 91700  training loss: 0.07349152117967606
epoch 91700  clean testing loss: 0.047215837985277176
epoch 91800  training loss: 0.07349073141813278
epoch 91800  clean testing loss: 0.0472029447555542
epoch 91900  training loss: 0.07349002361297607
epoch 91900  clean testing loss: 0.047200821340084076
epoch 92000  training loss: 0.07348889857530594
epoch 92000  clean testing loss: 0.04721211642026901
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 92100  training loss: 0.07348858565092087

 93%|█████████▎| 93091/100000 [02:53<00:12, 534.98it/s]
epoch 92200  training loss: 0.07348740100860596
epoch 92200  clean testing loss: 0.047206465154886246
epoch 92300  training loss: 0.07348627597093582
epoch 92300  clean testing loss: 0.04720187559723854
epoch 92400  training loss: 0.07348576188087463
epoch 92400  clean testing loss: 0.0472111813724041
epoch 92500  training loss: 0.07348459213972092
epoch 92500  clean testing loss: 0.04721195995807648
epoch 92600  training loss: 0.07348399609327316
epoch 92600  clean testing loss: 0.047209154814481735
epoch 92700  training loss: 0.07348275929689407
epoch 92700  clean testing loss: 0.04720635339617729
epoch 92800  training loss: 0.07348190993070602
epoch 92800  clean testing loss: 0.047217678278684616
epoch 92900  training loss: 0.07348121702671051
epoch 92900  clean testing loss: 0.047216594219207764
epoch 93000  training loss: 0.0734805166721344
epoch 93000  clean testing loss: 0.047223277390003204
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 93100  training loss: 0.07347923517227173
epoch 93100  clean testing loss: 0.04721562936902046
epoch 93200  training loss: 0.07347889244556427

 94%|█████████▍| 94123/100000 [02:55<00:13, 434.39it/s]
epoch 93300  training loss: 0.07347765564918518
epoch 93300  clean testing loss: 0.04721479117870331
epoch 93400  training loss: 0.07347732782363892
epoch 93400  clean testing loss: 0.047217126935720444
epoch 93500  training loss: 0.07347653806209564
epoch 93500  clean testing loss: 0.04722137749195099
epoch 93600  training loss: 0.0734763965010643
epoch 93600  clean testing loss: 0.047225471585989
epoch 93700  training loss: 0.07347479462623596
epoch 93700  clean testing loss: 0.047226108610630035
epoch 93800  training loss: 0.0734744518995285
epoch 93800  clean testing loss: 0.04721662402153015
epoch 93900  training loss: 0.07347379624843597
epoch 93900  clean testing loss: 0.04722347855567932
epoch 94000  training loss: 0.07347314804792404
epoch 94000  clean testing loss: 0.04722801595926285
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 94100  training loss: 0.07347241044044495
epoch 94100  clean testing loss: 0.0472278855741024
epoch 94200  training loss: 0.07347173988819122

 95%|█████████▌| 95218/100000 [02:57<00:08, 533.73it/s]
epoch 94300  training loss: 0.07347137480974197
epoch 94300  clean testing loss: 0.047224633395671844
epoch 94400  training loss: 0.07347038388252258
epoch 94400  clean testing loss: 0.047227829694747925
epoch 94500  training loss: 0.07346934080123901
epoch 94500  clean testing loss: 0.04722670093178749
epoch 94600  training loss: 0.07346902787685394
epoch 94600  clean testing loss: 0.04722955822944641
epoch 94700  training loss: 0.07346876710653305
epoch 94700  clean testing loss: 0.04722800850868225
epoch 94800  training loss: 0.07346753031015396
epoch 94800  clean testing loss: 0.04722951352596283
epoch 94900  training loss: 0.07346675544977188
epoch 94900  clean testing loss: 0.04722573608160019
epoch 95000  training loss: 0.07346580177545547
epoch 95000  clean testing loss: 0.04722905158996582
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 95100  training loss: 0.07346617430448532
epoch 95100  clean testing loss: 0.04723725840449333
epoch 95200  training loss: 0.07346458733081818
epoch 95200  clean testing loss: 0.047231417149305344
epoch 95300  training loss: 0.07346385717391968

 96%|█████████▋| 96259/100000 [02:59<00:06, 537.11it/s]
epoch 95400  training loss: 0.07346335053443909
epoch 95400  clean testing loss: 0.04723150655627251
epoch 95500  training loss: 0.07346275448799133
epoch 95500  clean testing loss: 0.04723908379673958
epoch 95600  training loss: 0.07346192002296448
epoch 95600  clean testing loss: 0.047238923609256744
epoch 95700  training loss: 0.0734611228108406
epoch 95700  clean testing loss: 0.04723280295729637
epoch 95800  training loss: 0.07346074283123016
epoch 95800  clean testing loss: 0.04723659157752991
epoch 95900  training loss: 0.073459692299366
epoch 95900  clean testing loss: 0.04724299535155296
epoch 96000  training loss: 0.07345867902040482
epoch 96000  clean testing loss: 0.04724061116576195
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 96100  training loss: 0.07345852255821228
epoch 96100  clean testing loss: 0.04724309593439102
epoch 96200  training loss: 0.07345742732286453
epoch 96200  clean testing loss: 0.04723844304680824
epoch 96300  training loss: 0.07345683872699738

 97%|█████████▋| 97355/100000 [03:01<00:04, 537.64it/s]
epoch 96400  training loss: 0.07345608621835709
epoch 96400  clean testing loss: 0.04724234342575073
epoch 96500  training loss: 0.07345551252365112
epoch 96500  clean testing loss: 0.0472441203892231
epoch 96600  training loss: 0.07345525175333023
epoch 96600  clean testing loss: 0.04724812135100365
epoch 96700  training loss: 0.07345450669527054
epoch 96700  clean testing loss: 0.047247063368558884
epoch 96800  training loss: 0.07345368713140488
epoch 96800  clean testing loss: 0.047244537621736526
epoch 96900  training loss: 0.07345307618379593
epoch 96900  clean testing loss: 0.04724738374352455
epoch 97000  training loss: 0.07345282286405563
epoch 97000  clean testing loss: 0.04724389687180519
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 97100  training loss: 0.0734521821141243
epoch 97100  clean testing loss: 0.047245800495147705
epoch 97200  training loss: 0.07345157861709595
epoch 97200  clean testing loss: 0.04725067317485809
epoch 97300  training loss: 0.07345075160264969
epoch 97300  clean testing loss: 0.04725243151187897
epoch 97400  training loss: 0.07345021516084671

 98%|█████████▊| 98399/100000 [03:03<00:02, 543.60it/s]
epoch 97500  training loss: 0.07344964891672134
epoch 97500  clean testing loss: 0.047247570008039474
epoch 97600  training loss: 0.07344897836446762
epoch 97600  clean testing loss: 0.047251082956790924
epoch 97700  training loss: 0.07344870269298553
epoch 97700  clean testing loss: 0.04724910855293274
epoch 97800  training loss: 0.07344821095466614
epoch 97800  clean testing loss: 0.04725487902760506
epoch 97900  training loss: 0.07344738394021988
epoch 97900  clean testing loss: 0.047249943017959595
epoch 98000  training loss: 0.07344639301300049
epoch 98000  clean testing loss: 0.047250308096408844
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 98100  training loss: 0.07344576716423035
epoch 98100  clean testing loss: 0.047251779586076736
epoch 98200  training loss: 0.07344523072242737
epoch 98200  clean testing loss: 0.04725077003240585
epoch 98300  training loss: 0.07344450801610947
epoch 98300  clean testing loss: 0.0472530797123909
epoch 98400  training loss: 0.0734444186091423
epoch 98400  clean testing loss: 0.04725778102874756
epoch 98500  training loss: 0.07344295084476471

 99%|█████████▉| 99497/100000 [03:05<00:00, 540.95it/s]
epoch 98600  training loss: 0.07344259321689606
epoch 98600  clean testing loss: 0.04725603014230728
epoch 98700  training loss: 0.07344170659780502
epoch 98700  clean testing loss: 0.04725975915789604
epoch 98800  training loss: 0.07344116270542145
epoch 98800  clean testing loss: 0.04726108908653259
epoch 98900  training loss: 0.0734405443072319
epoch 98900  clean testing loss: 0.047255560755729675
epoch 99000  training loss: 0.07344052940607071
epoch 99000  clean testing loss: 0.0472557470202446
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...
epoch 99100  training loss: 0.07343919575214386
epoch 99100  clean testing loss: 0.04726331681013107
epoch 99200  training loss: 0.07343880087137222
epoch 99200  clean testing loss: 0.047261569648981094
epoch 99300  training loss: 0.07343842089176178
epoch 99300  clean testing loss: 0.047257594764232635
epoch 99400  training loss: 0.07343758642673492
epoch 99400  clean testing loss: 0.04726165160536766
epoch 99500  training loss: 0.07343728840351105
epoch 99500  clean testing loss: 0.047267161309719086
epoch 99600  training loss: 0.07343678921461105

100%|██████████| 100000/100000 [03:06<00:00, 535.31it/s]
epoch 99700  training loss: 0.07343585789203644
epoch 99700  clean testing loss: 0.04726647585630417
epoch 99800  training loss: 0.07343542575836182
epoch 99800  clean testing loss: 0.047263603657484055
epoch 99900  training loss: 0.07343501597642899
epoch 99900  clean testing loss: 0.04726245254278183
Saving the clean test loss file into log/new_plot/output_dim2_width1024_layers2_relu_size500_noise1.00e-01_invop0_lr0.005 ...